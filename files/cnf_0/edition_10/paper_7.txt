Visualizing

the Non-Visual:
with information

Spatial analysis and interaction
from text documents

James A. Wise, James J. Thomas, Kelly Pennock, David Lantrip,
Marc Pottier, Anne Schur, Vern Crow
Pacific Northwest Laboratory
Richland, Washington
query’ tools on document bases [5,8], but the
information returned is documentsin their text form-which the user still must read to cognitively process.
The need to read and assesslarge amountsof text that
is retrieved through even the most efficient meansputs
a severeupper limit on the amount of text information
that can be processedby any analyst for any purpose.
At the same time, “Open Source” digital
information--the kind available freely or through
subscription over the Internet--is increasing
exponentially. Whether the purpose be market
analysis, environmental assessment,law enforcement
or intelligence for national security, the task is to
peruse large amounts of text to detect and recognize
informational ‘patterns’ and pattern irregularities
across the various sources. But modern information
technologieshave made so much text available that it
overwhelms the traditional reading methods of
inspection, sift and synthesis.

Abstract
This paper describes an approach to IV that
involves spatializing text content for enhanced visual
browsing and analysis. The application arena is large
text document corpora such as digital libraries,
regulations andprocedures, archived reports, etc. The
basic idea is that text content from these sources may
be transformed to a spatial representation that
preserves informational characteristics from the
documents. The spatial representation may then be
visually browsed and analyzed in ways that avoid
language processing and that reduce the analysts’
mental workload. The result is an interaction with text
that more nearly resemblesperception and action with
the natural world than with the abstractions of written
language.

1: Introduction
Information Visualization (IV), extendstraditional
scientific visualization of physical phenomena to
diverse types of information (e.g.text, video, sound,
or photos) from large heterogenousdata sources. It
offers significant capability to different kinds of
analysts who must identify, explore, discover, and
developunderstandingsof complex situations.
IV has been studied for many centuries,integrating
techniquesfrom art and sciencein its approach[7,9].
The information analyst’s perspective illustrates that
their process involves more than envisioning
information. [4] It is both the visual representations
and the resultant interactions with it that entail the
analyst’s work.
Current visualization approaches demonstrate
effective methods for visualizing mostly structured
and/or hierarchical information such as organization
charts, directories, entity-attribute relationships, etc.
[3,9]. Free text visualizationshave remainedrelatively
unexamined.
The idea that open text fields themselves or raw
prose might be candidatesfor information visualization
is not obvious. Some researchin information retrieval
utilized graph theory or figural displays as ‘visual

O-8186-7201-3/95$04.00 0 1995 IEEE

Proceedings of the Proceedings on Information Visualization (INFOVIS '95)
0-8186-7201-3/95 $10.00 © 1995 IEEE

2:

Visualizing text

True text visualizationsthat would overcomethese
time and attentional constraintsmust representtextual
content and meaning to the analyst without them
having to read it in the manner that text normally
requires. These visualizations would instead result
from a content abstraction andspatialization of the
original text document that transforms it into a new
visual representation that communicates by image
instead of prose. Then the image could be understood
in much the way that we explore our worldly visual
constructions.
It is thus reasonableto hypothesizethat acrossthe
purposes for perusing text, some might be better
satisfied by transforming the text information to a
spatial representationwhich may then be accessedand
explored by visual processes alone. For any reader,
the rather slow serial process of mentally encoding a
text document is the motivation for providing a way
for them to instead use their primarily preattentive,
parallel processingpowers of visual perception.
The goal of text visualization, then, is to spatially
transform text information into a new visual

51
See Color Plates, page 140.

the opportunity for the text visualizations describedin
this paper. For example, reading a text document to
extract it’s semanticmeaningis different from learning
that a document is of a certain relative size, type, or
authorship, with particular content themes. But both
semanticand content knowledge can be valuable to an
analyst. Identifying publishing activity on particular
subjects from particular authors at certain places and
times is useful, especially if one does not have to read
all of the documentsto determinethat pattern.
In digital form,written text can be treated
statisticallyto extract information about it’s contentand
context, if not semantic meaning. While this does not
necessarily entail natural language processing
algorithms, it does require a set of special purpose
processesto convert text to an alternative spatial form
that can be displayed and utilized without needing to
read it.
The first component of a software architecture to
visualize text is the document database or corpora.
Documents contained within such databases are
derived from messages,news articles, regulations,
etc., but contain primarily textual material. The next
component is the text processing engine, which
transforms natural language from the document
database to spatial data. The output from the text
engine is either stored directly in a visualization
database,or projected onto a low dimensional, visual
representation. Other componentsof the architecture
are the Graphical User Interface (GUI), the display
software (such as visualization packages), the
Applications Interface (API), and auxiliary tools.

representation that reveals thematic patterns and
relationshipsbetweendocumentsin a mannersimilar if
not identical to the way the natural world is perceived.
This is becausethe perceptual processesinvolved are
the results of millions of years of selectivemammalian
and primate evolution, and have become biologically
tuned to seeing in the natural world. The human eye
has it’s own contrast and wavelength sensitivity
functions. It has prewired retinal “textons”, or
primitive form elements used to quickly build up
components of complex visual images. Much of this
processingtakes place in parallel on the retinal level,
and so is relatively effortless, exceptionally fast, and
not additive to cognitive workload. Even at the visual
cortex, perception appears to rely on spatially
distributed parallel construction processes in a
topography that corresponds to the real physical
world. The central conjecture behind the approachto
text visualizationdescribedhere is that the samespatial
perceptual mechanismsthat operate on the real world
will respond to a synthetic one, if analogouscues are
present and suitably integrated. The bottleneck in the
human processingand understandingof information in
large amounts of text can be overcome if the text is
spatialized in a manner that takes advantage of
common powers of perception.
3. Visualization transformations:
text to pictures

from

Four important technical considerationsneed to be
addressedin the creation of useful visualizationsfrom
raw text. First, there must be a clear definition of what
comprisestext and how it can be distinguished from
other symbolic representations of information.
Second,there must be a way to transform raw text into
a different visual form that retains much of the high
dimensional invariants of natural language, yet better
enables visual exploration and analysis by the
individual. Third, suitable mathematical procedures
and analytical measures must be defined as the
foundation for meaningful visualizations. Finally, a
database management system must be designed to
store and managetext and all of its derivative forms of
information.
For the purpose of this paper, text is a written
alphabetical form of natural language. Diagrams,
tables, and other symbolic representationsof language
are not considered text. Text has statistical and
semantic attributes such as the frequency and context
of individual words, and the combinations of words
into topics or themes, The differences between text’s
statistical and semanticcompositionsprovide much of

3.1:

The primary requirements of a text processing
engine for information visualization are: 1) the
identification and extraction of essentialdescriptorsor
text features, 2) the efficient and flexible
representation of documents in terms of these text
features, and 3) subsequent support for information
retrieval and visualization.
Text features are typically one of three general
types, though any number of variations and hybrids
are possible. The first type is frequency-based
measureson words, utilizing only first order statistics.
The presence and count of unique words in a
document identifies those words as a feature set. The
second type of feature is based on higher order
statisticstaken on the words or letter strings. Here, the
occurrence, frequency, and context of individual
words are used to characterize a set of explicit or
implicitly (e.g. associations defined, by a neural
52

Proceedings of the Proceedings on Information Visualization (INFOVIS '95)
0-8186-7201-3/95 $10.00 © 1995 IEEE

Processing text

3.2:

network) defined word classes. The third type of text
feature is semanticin nature. The associationbetween
words is not defined through analysis of the word
corpus, as with statistical features, but is defined a
priori using knowledge of the language. Semantic
approaches may utilize natural or quasi-natural
language understanding algorithms, so that the
semanticrelationships (i.e., higher-order information)
are obtained.
Text features are a “shorthand” representation of
the original document, satisfying the need of a text
engine to be an efficient and flexible representationof
textual information. Instead of a complex and
unwieldy string of words, feature sets become the
efficient basis of document representations and
manipulations. The feature set information must be
complete enough to permit flexible use of these
alternatives.Text engines support both efficiency and
flexibility, though thesecriteria are often in opposition.
The third requirement of the text engine is to
support information retrieval and visualization. The
text processing engine must provide easy, intuitive
accessto the information contained within the corpus
of documents. Information retrieval implies a query
mechanism to support it. This may include a basic
Boolean search, a high level query language, or the
visual manipulation of spatialized text objects in a
display. To provide efficient retrieval, the text
processing engine must pre-process documents and
efficiently implement an indexing scheme for
individual words or letter strings.
The more visual aspect of information retrieval is
known as information browsing. The specificity of
querying has a counterpoint in the generality of
browsing. The text processing engine or subsidiary
algorithms can support browsing by providing
composite or global measures which produce an
intuitive index into topics or themes contained within
the text corpus. A set of measureswhich characterize
the text in meaningful ways provide for multiple
perspectives of documents and their relationships to
one another. One example of such a measure is
“similarity”. Based on the occurrenceand the context
of key words or other extracted features, measuresof
similarity can be computed which reflect the
relatedness between documents. When similarity is
representedas spatial proximity or congruity of form,
it is easily visualized. A diversity of measures is
essential,given that documents can be extraordinarily
complex entities containing a large number of
imprecise topics and subtopics. Clearly, no single
visualizable snapshotof a document base can provide
the whole picture.

Composing a spatial representationfrom the output
of the text analysis engine is the next step to
visualizing textual information. Spatializationitself is
composed of several stages. The first involves
representing the document, typically as a vector in a
high dimensional feature space. The vector
representation is the initial spatial expression of the
document, and a variety of comparisons, filters, and
transformationscan be made from it directly.
To represent each of these documents, an initial
visualization may consist of a scatter plot of points
(one for each document), collocated according to a
measureof similarity based on vector representations.
Since visualization of the textual information requiresa
low-dimensional representation of documents that
inhabit a high-dimensional space, projection is
necessary. Typically, linear or non-linear principal
Components Analysis or metric Multi-Dimensional
Scaling (MDS) can be used to reduce dimensionalityto
a visualizable subspace. One serious concern with
these techniques, is their exponential order of
complexity, requiring that dimensionality reduction
and scaling be consideredsimultaneouslysince a large
corpus may contain 20,000 or more documents. For
large document corpora, alternatives to the projection
of each document point are necessary.In these cases,
clustering can be performed in the high-dimensional
feature space and the cluster centroids become the
objects to be visualized. For a review of clustering
and metric issues,see [ 111.
3.3: Managing the representation
There are two basic classes of data that must be
managed. The first is the raw text files for each
document. The text itself as well as a variety of header
information fall into this category. This first class of
data is static in nature, simple in structure, and
therefore easy to manage. The second broad class of
data is the visual forms of the text. This classof data is
derived from the numerous algorithms designed to
cluster, structure, and visually present information,
and is both extensiveand dynamic.
For the current text visualization endeavor, an
object-oriented database was selected for managing
text and its various visual forms. This paradigm was
chosen for its flexibility of data representation, the
power of inheritance, and the ease of data access
where complexity of the data structuresto be managed
is great. The structures contain both high and low
dimensional spaces,substructuressuch as clusters and
53

Proceedings of the Proceedings on Information Visualization (INFOVIS '95)
0-8186-7201-3/95 $10.00 © 1995 IEEE

Visualizing output from text processing

representations for the visualization and analysis of
textual information. These approaches have been
showcased in SPIRETM, the Spatial Paradigm for
Information Retrieval and Exploration, which was
developed to facilitate the browsing and selection of
documents from large corpora (20,000+ documents ).
Described below are the two major visualization
approachesor views which were developed in the first
year of this project: Galaxies and Themescapes.
Starfields and topographical maps were selectedas
display metaphorsbecausethey offer a rich variety of
cognitive spatial affordancesthat naturally addressthe
problems of text visualization. Starfields create point
clusterswhich suggestpatterns of interest. Maps offer _
topographies of peaks and valley that can be easily
detectedbased on contour patterns. Both these spatial
arrangements allow overview and detail without a
change of view. Each view, however, offers a
different perspective of the same information and
serves as the organizing points for knowledge
construction.

super clusters, entities such as documents and cluster
centroids, and a variety of other components. The
class structure of the database also permits the
common elementsto be shared(inherited) through the
hierarchy of data classes, while the differences
betweenthe structurescan be specified at lower levels.
The selectedobject-orienteddatabasealso implements
databaseentities as persistentobjects,where the access
and manipulation of the data are one and the same,
eliminating the need for a query mechanismas such.
3.4:

Interface design for text visualization

To achievedirect engagementfor text visualization
[6], the interface must provide 1) a preconsciousvisual
form for information 2) interactions which sustain and
enrich the process of knowledge building, 3) a fluid
environment for reflective cognition and higher-order
thought, and 4) a framework for temporal knowledge
building.
Three primary display types are made available to
the analyst. Tools are arranged along the perimeter of
the display monitor and can be used as operators on
the representations.Conversely,the representationsor
selected areas in the representations can be dragged
and dropped onto the tools to spawn the appropriate
.action. The analyst can work on the primary
information views [l] in an area known as the
backdrop, which serves as a central display resource
for visual information; alternatively, she can move the
views to the workshop or the chronicle. The
workshop is a grid where selected views or parts of
views can be placed for work and/or visual review.
The grid has a number of resizable windows to hold
multiple views. The chronicle is a space where
representations of more enduring interest can be
placed. Views placed in this areacan be linked to form
a sequenced visual story where decision points are
highlighted. The workshop and the chronicle take
advantageof the phenomenaof visual momentum; the
ability to extract information across a set of
successivelyviewed displays [lo] that can be a series
of static or dynamic images. The characteristicsof the
backdrop, workshop,. and chronicle, known
collectively as storylmmg, provide the ability to
capture and visually organize situations across the
time-past, present, and future. This endows the
analyst with the ability to summarizetheir experience
of knowledge building [2].

4.1:

The Galaxies visualization displays cluster and
document interrelatedness by reducing a high
dimensional representation of documents and clusters
to a 2D scatterplot of ‘docupoints’ that appear as do
stars in the night sky. Although the resulting
visualization is simple, it provides a critical first cut at
sifting information and determining how the contents
of a document base are related. The key measurement
for understanding this visualization is the notion of
document “similarity”. The more similar that clusters
and documents are to one another in terms of their
context and content, the closer or more proximate they
are located in the 2D space. By exploring and
animating this visualization, analystscan quickly gain
an understanding of patterns and trends that underlie
the documentswithin a corpus. At the highest level of
representation, Galaxies displays corpus clusters and
the gisting terms which describe them. (Figure 1)
A simple glance at this spatial representation
reveals the fundamental topics found within the
corpus, and provides an avenue of exploration which
can be followed by simply clicking on a cluster of
interest to reveal the documents within. These
documents can then be grouped, gisted, annotated, or
retrieved for more detailed analysis. In addition to
simple point and click exploration of the document
base, a number of sophisticatedtools exist to facilitate
more in-depth analysis. An example of such a tool is
the temporal slicer. Designed to help tie document

4: Examples from the MVAB Project
The Multidimensional Visualization and Advanced
Browsing project is currently exploring a number of
54

Proceedings of the Proceedings on Information Visualization (INFOVIS '95)
0-8186-7201-3/95 $10.00 © 1995 IEEE

Galaxies

spatialpatterns with temporal ones, this tool utilizes
document timestamps to partition the document base
into temporal units. The granularity of these units can
be defined by the user as years, months, days, hours
or minutes. Slicing a database entails moving a
“temporal window” through the documents, and
watching the visualization populate itself with
documents. (Figure 2)
The resulting emergence of clusters can indicate
temporal links that relate topics. When viewed in terms
of known historical events and trends, thesegrowing
clusterpatternscan provide insight into external causal
relationshipsmirrored in the corpus.
4.2:

epics or themes found within the corpus, without the
cognitive load encounteredin reading such content. A
thematic terrain simultaneouslycommunicatesboth the
primary themes of an arbitrarily large collection of
documentsand a measureof their relative prevalencein
the corpus. Spatial relationships exhibited in the
landscape reveal the intricate interconnection of
themes,the transformation of themes acrossthe whole
of the document corpus, and the existence of
information gap, or “negative information.”
The ThemeScapes’ visual representation has
several advantages. First, a ThemeScape displays
much of the complex content of a document database.
Elevation depicts theme strength, while other features
of the terrain map such as valleys, peaks, cliffs, and
ranges represent detailed interrelationships among
documentsand their compositethemes. At a glance, it
provides a visual thematic summary of the whole
corpus. The second major advantage of thematic
terrain is that it utilizes innate human abilities for

ThemeScapes

ThemeScapes are abstract, three-dimensional
landscapesof information that are constructed from
document corpora (Figure 3). The complex surfaces
are intended to convey relevant information about

Figure

1:

Galaxies visualization of documents
database.

55

Proceedings of the Proceedings on Information Visualization (INFOVIS '95)
0-8186-7201-3/95 $10.00 © 1995 IEEE

and

document

clusters

in a text

pattern recognition and spatial reasoning. The
complexity of the terrain is perceived and analyzed
with parallel and preattentive processingwhich do not
tax serial, attentional resources. This greatly expands
the bandwidth of communication between the tool and
the user. A third major advantage of the terrain
implementationis its communicativeinvariance across
levels of textual scale. An entire document corpus, a
cluster of documents, individual documents, or even
documentcomponentssuch as paragraphsor sentences
can all be equally well visualized in a ThemeScape.
This feature allows the ThemeScape to be used for
automated document summarization as well as
summarizationof the whole document base,explicitly
displaying the multitude of topics in a single image.
Finally, ThemeScapespromote analysisby promoting
exploration of the document space. Utilizing the
metaphor of the landscape, associatedtools allow the
analyst to take ‘core samples’and ‘slices’through the
thematic terrain to see its composition and to
understandhow thematic topics come to relate to one
anotherin the underlying documents.
5: Conclusions and directions
research and development

future

The MVAB project has startedwith a visualization
(Galaxies)that Drovidesa simmified universal view of
the relationshipsamong documentsin an entire corpus.
We have then proceeded to the Themescape
visualization, which does the same for the thematic
content expressedin those documents. In doing so,
we have gone from a metaphor of points in space to
one of a landscape.We are now pursuing development
of a third visualization that would handle specific
entity-attribute relationships found in the documents,
such as treated by Link Analysis. This layering of
informational detail and abstractionappearsnecessary
for large document bases where investigating global
structure is a primary concern yet relationships
betweenindividual objects are also important. It gives
real meaning and form to the notion of ‘data mining’.
So far, the R &D efforts on the MVAB project
have shown that there appears to be substantial
justification to the idea that text visualizations can
overcomemuch of the user limitations that resultsfrom
accessing and trying to read from large document
bases.Even with the relatively simple first Galaxies
visualization of documents as stars in a 2-D space,
analystshave returned reports of enhancedinsight and
time savings such as “discovering in 35 minutes what
would have taken two weeks otherwise.” Analysts

Figure 2a, b, c: Users can slice a corpus
to relate document patterns with temporal
ones.

56

Proceedings of the Proceedings on Information Visualization (INFOVIS '95)
0-8186-7201-3/95 $10.00 © 1995 IEEE

for

Figure 3:

A ThemeScape

of an entire week of CNN newstories
document
corpus

a

choicesof Boolean logic. Touching a Themescapecan
be a way to initiate a weighted query in terms of the
themesthat proportionally composethe elevationof the
terrain. This allows the analyst to seek documentsthat
talk about combinationsof topics in a selectedrelative
abundancebased on the analyst’s interests. Querying
and analytical manipulation come together in a single
visualization.
Users’ experience also justifies the initial
conviction that text visualizations will have to access
and utilize the cognitive and visual processes that
enable our spatial interactions with the natural world.
This suggests visual metaphors that recapitulate

have also been quite creative with the tool, using the
time slicer to do pattern recognition and comparisonon
evolving and historically documentedsituations. This
kind of adaptation of what is essentially a visual
browser has encouraged us to pursue analytical
visualizations and to drop some distinctions among
analysts’tasks that exist in the purely textual realm.
For example,querying a documentbase by meansof a
Boolean text string is different from reading the
documents returned from the query. However, the
Themescape described above, although meant for
visual analysis,also permits a different kind of visual
querying than was ev er possible under the all-or-none
57

Proceedings of the Proceedings on Information Visualization (INFOVIS '95)
0-8186-7201-3/95 $10.00 © 1995 IEEE

comprising

experiences of viewing the night sky and traversing
landscapes.
Another observation echoed in the growing
popularity of Visual Data Analysis (VDA) programsis
that perceptionand action are provocative complements
to one another. An image must be acted on in some
way, which in turn suggestsnew facets of its character
that stimulate further visual inspection. Galaxies
successwith analysts is in no small part due to the
abilities to pan, group and timeslice the docupoints in
the display. The successof other text visualizations
will likely be determined by whether the user can
manipulate them along the lines of their analytical
intuitions.
Future efforts will elaboratethe visual metaphors
described above, as well as new ones that effectively
capture how conceptsand decisions ‘come into form’.
Much of the analyst’s world is a dynamic changing
information terrain. Seeking coheranceand patterns in
this environment carries a high price in time and effort.
Capturing the development of a story or the threads of
a concept communicated in prose is a high order for
text visualizations. But there appearsto be no formal
reason why at least some of these aspects cannot be
capturedas well in image as they can in words.
Other extensions of this researchare suggestedby
the addition of sensorymodalities like sound to the text
visualization. If text content or connections can be
captured in three dimensional solid forms, then those
forms might also be given other properties, like
density,that characterizetheir appearanceand behavior
in the real world. Through enhancedmeans of ‘virtual
interaction’, these properties could reinforce and
extend the impressions gained by visual inspection
alone, and start to give much more of the affective
content and tone that well written prose conveys.
It is evident that the potentials of text visualization
are just beginning to be explored and realized. With
them, the incredible diversity and volumes of written
information available around the world may yet be
made more accessibleand comprehensiblethrough this
perceptual restructuring. And the limitations of an
Information Age will not be set by the speed with
which a human mind can read.

References
t11 Bannon, L. I., and Bodker,
Encountering

Artifacts

S., Beyond the Interface:
in Use. In Carroll J. M. @cl.)

Designing Interaction: Psychology at the Human
Computer Interface pages227-253. Cambridge, Cambridge
University Press, 1991.

PI Henniger, S., Bell&
Stratigies

for

N., Znterfkes Zssues and Znteration
Znformation Retireval Systems. ACM

Computer Interaction Tutorial Workbook #19, April 1994.
[31 Johnson, J. A., Nardi, B. A., Zarmer, C. L., and Miller, J.
R., 1993. Information Visualization Using 3D Interactive
Animation. Communications of the ACM, 36(4):40-56.
141 Keller, P. R., and M. M. Keller. Visual Cues: Practical
Data Visualization.
IEEE Computer Society Press, Los
Alamitos, California. 1993.

151 Korfhage, Robert R. To See, or Not to See--Is That the

Query? Communications of the ACM, 34, pages 134-141,

1991.
[61 Laurel, B. Computers as Theatre. Addison-Wesley,
Reading, Massachusetts,1993.
[71 Robertson, G. C., Card, S. K., and Ma&inlay, J.D.
1993. Information Visualization Using 3D Interactive
Animation. Communications of the ACM, 36(4):56-72

181 Spoerri, Anselm. InfoCrystal:

A visual tool for
information retrieval. Proceedings of Visualization ‘93,
pages 150-157. IEEE Computer Society Press, Los
Alamitos, California, 1993.

t91 Tufte, E. R. Envisioning Information.
Cheshire, Connecticut, 1990.

Graphics Press,

1101Woods, D. D.,
Cognitive

Visual Momentum: a Concept to Improve
Coupling
of Person
and Computer.

International Journal of Man-Machine Studies 21: 229-m.
1984.

[HI York, J. and Bohn,
Reduction

S. Clustering and Dimensionality
Presented at the Automated
in SPIRE.

Intelligence Processingand Analysis Symposium, Mar 2830,1995, Tysons Comer, VA.

58

Proceedings of the Proceedings on Information Visualization (INFOVIS '95)
0-8186-7201-3/95 $10.00 © 1995 IEEE

