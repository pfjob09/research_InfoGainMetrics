2009 13th International Conference Information Visualisation

A Memory-saving and Efficient Data Transformation Technique for Mixed
Data Sets Visualization
Sun Yang, Zhao Xiang, Tang Daquan, Xiao Weidong
National University of Defense Technology, Changsha, Hunan, P. R. China
victor_830514@yahoo.com.cn
options to deal with mixed data sets. The first is to
divide the continuous variables into categories.
However, the effect of visualization depends entirely
on the domain knowledge, and blindly transforming of
numeric values into categorical displays may bring in
artificial patterns. Moreover, these visualizations only
show the statistical information of data sets well, but
are not sufficient for the distribution characteristic of
data items. The second is to quantify the categorical
attributes, i.e. to assign order and distance to the
categories. This takes advantage of numerical
visualization tools and gives the user a quick and exact
reading of distribution and patterns of the target data
sets. However, if categories are quantified manually, it
will generate the same problem as the first. Thus,
algorithms have been proposed to quantify categorical
data. Johansson et al. [2] presented an interactive
method to quantify categories making use of domain
knowledge. It employs clustering algorithm to
categorize the continuous data, and uses Multiple
Correspondence Analysis to compute the order and
distance among categories.
As far as we concern, there are at least two points
to be addressed in further research: (1) clustering is
utilized to categorize continuous data, but no details of
this application is available, questions such as which
continuous attributes to cluster are obvious; (2) there is
not a complete solution to the difficulty of large
numbers of variables generating excessive processing
time and memory. Inspired by the work of Johansson
et al., this paper suggests a refined approach to
visualize mixed data, particularly details on applying
clustering algorithms to categorize continuous
variables, and proposes a set of strategies (named
Cardinality Reduction Strategies) to reduce the number
and cardinality of variables involved. In general, the
main contribution of this paper can be concluded as: (1)
a full description of applying clustering to
categorization of continuous variables; (2) a set of
cardinality reduction strategies to pre-process mixed
data sets with large variables and high cardinality; and

Abstract
Although there have been effective visualizations for
simplex continuous or categorical variables, mixed
data sets are still difficult to visualize, since no direct
approaches are available for them. This paper presents
a memory-saving and efficient data transformation
technique for mixed data sets visualization,
particularly details on describing the application of
Correspondence Analysis to quantify categorical
variables, and proposes a set of cardinality reduction
strategies to reduce the numbers of variables and their
values involved in computations. A series of empirical
studies are carried out in a Star Coordinates-based
environment to evaluate the visualization of mixed data
sets. Finally it is concluded that the visualization gives
a good graphical view of mixed data sets, with the data
transformation technique being efficient in both time
and memory.

1. Introduction
Existed in many application areas, the data sets that
need to be explored often contain millions of objects
described by tens, hundreds or even thousands of
various types of attributes (variables). Various data
types are used to define these attributes (basic data
types, e.g., integer, float, double, character, string, and
advanced data types, e.g., interval, ratio, binary,
ordinal, categorical, etc). According to the semantics of
attributes, one can always find a mapping between the
related data types [1]. In this paper, so we concentrate
on the mixed data sets that comprise two general data
types, numeric and categorical, for others can be
mapped to one of these two.
Mixed data sets are difficult to analyze since most
existing visual exploration displays are designed to
handle simplex numeric or categorical variables
respectively, whilst the difference between numeric or
categorical data visualizations is clear. In order to reuse
the existing visualizations, there are at least two
978-0-7695-3733-7/09 $25.00 © 2009 IEEE
DOI 10.1109/IV.2009.11

260

(3) a Star Coordinates-based visualization for
effectively and efficiently visualizing mixed data sets.

clustering to categorize every numeric variable and
then employ CA to quantify categories of all variable.

2. Related work

3. Transformation of mixed data set

Several approaches have been proposed to visualize
categorical variables. A common solution to display
categories is to represent them by visual entities scaled
according to their corresponding frequency, such as
sieve diagrams [3], mosaic displays [4], fourfold
displays [5]. Adapted from Parallel Coordinates [6],
Parallel sets [7] utilizes a set of boxes that are sized
according to the category frequency to represent
categories of a categorical variable; mixed data sets are
also supported by dividing the continuous variables
into bins, but split-up bars may become too small to
visualized properly if there are many variables that
have many categories to visualize. All those techniques
are designed to explore the relationships and
associations among categorical data, and do not need
to map the categorical values onto numeric values.
Unfortunately, only the statistical and frequency
information of data sets are visualized, without the
distribution information. Besides, none of them are
able to handle data sets with large number of
categorical variables and high cardinality, which are
yet commonly found in application areas.
On the other hand, a number of excellent techniques
designed to handle numeric variables have been
proposed, including Parallel Coordinates [6], Radviz
[8], Star Coordinates [9], etc. Such techniques are
easily capable of visualizing multivariate quantitative
data well and can be used for exploring outliers,
clusters, and relationship of data. But the common
drawback they share is that they only work well with
numeric data. When importing data sets with
categorical values into such visualizations, most efforts
to date are rather simplistic, treating categories as
special cases with only a few values.
Possible solutions to map categorical variables into
numbers would include assigning order of categorical
data by arbitrary ordering (e.g., alphabetical order) and
ordering based on another variable (e.g., time). Yet,
these often create artificial patterns. Ma and Hellerstein
[10] ordered the categories by minimizing the
distances between clusters, where the order was
assigned without spacing. Beygelzimer et al. [11]
utilized a spectral method with scalability unreported.
Later, Rosario et al. [12] quantified categorical data by
incorporating Correspondence Analysis (CA) [13],
which is only capable of quantifying the categorical
data, and unsuitable for mixed data sets. To process
mixed data sets in a unified way, we firstly utilize

3.1. Notation
Definition 1: In a data set G ( X ) , objects {X1 , X2 ,", Xn}
are from the same domain, represented by the same set
of attributes A1 , A2 ,", Am . Each attribute Ai describes a
domain of values, denoted by DOM ( Ai ) . If attribute Ai
is numeric, domain DOM ( Ai ) is represented by
continuous values; If attribute Ai is categorical, the
domain DOM ( Ai ) is defined as finite and unordered,
e.g., for any ai1 , ai 2 ∈ DOM ( Ai ) , either ai1 = ai 2 or ai1 ≠ ai 2 .
Definition 2: An object X in G ( X ) is represented as a
vector [x1c , x2c ,", xcp , xrp+1,", xmr ] logically, where the first p
elements are categorical and the rest are numeric,
x j ∈ DOM ( Aj ) , 1 ≤ j ≤ m . Every object has m attribute
values, not allowing attributes having missing values.

3.2. Correspondence analysis
Correspondence Analysis (CA) is a multivariate
statistical technique, which is designed to analyze the
association of categorical variables. CA is similar to
Principal Component Analysis (PCA) except that CA
is used for categorical variables while PCA is for
numeric variables. There have been several variations
of CA for different uses, such as Simple
Correspondence Analysis (SCA), which is applied to
two
categorical
variables,
and
Multiple
Correspondence Analysis (MCA), which is employed
to analyze more categorical variables. SCA takes a
two-way contingency table like Table 1 as input, where
ai • ( a j • ) is one category (categorical value) in
DOM ( Ai ) ( DOM ( A j ) ), and ci • j • indicates the number

of cases containing certain values of ai • and a j • . While
MCA is applied to a multi-way Burt table like Table 2,
the meaning of which can be deducted according to
two-way contingency table. Besides, we count the
variables in the first column of the table target
variables, and the variables in the first row of the table
analysis variables.
In this way, a multidimensional space can be
defined by columns in a contingency or Burt table, and
the rows can be regarded as points in the space. CA
extracts new dimensions that are independent of each
other in the space. Based on Optimal Scaling [12],
each target categorical variable values can be mapped

261

onto several scale values on the first independent
dimension (the first principal axis) that explains most
of the variance within the space, which is the output of
CA.

belonging to the cluster formed by variable Ak
simultaneously.

3.4 Quantification of categorical variables

Table 1 Two-way contingency table
a j1

aj2

…

ai1

ci1 j1

ci1 j 2

…

ai 2

ci 2 j1

ci 2 j 2

…

…

…

…
…

After all continuous variables are categorized, MCA
is applied to the Burt table like Table 3, and the
quantified categorical values are computed from the
first CA independent dimension coordinates using
Optimal Scaling. In this way, all categories in the data
set can be transformed into numbers and numerical
visualization tools, such as Star Coordinates, can be
integrated to give a visual view of the transformed
mixed data. The whole procedure for visualizing mixed
data sets is now complete, providing users with a
compact graphical display of the mixed data set.

Table 2 Multi-way Burt table
a j1

aj2

…

ak1

ak 2

…

ai1

ci1 j1

ci1 j 2

…

ci1k1

ci1k 2

…

ai 2

ci 2 j1

ci 2 j 2

ci 2 k1

ci 2 k 2

…

…

…

…
…

…

…

…
…

4. Cardinality reduction strategies

3.3. Categorization of continuous variables

Along with the increasing number and cardinality of
variables in the mixed data sets, the memory-intensive
and time-consuming problem of MCA will be more
and more noteworthy. Rosario et al. proposed Focused
Correspondence Analysis (FCA) [12] as an alternative
to MCA to process a large number of categorical
variables, some of which possibly have high
cardinality. FCA does not simultaneously analyze all
variables like MCA, which is less computationally
efficient, but more memory-saving when compared to
MCA. FCA analyzes the target categorical variable
against its top k associated analysis variables instead of
all the other variables, resulting the lost of information
that is originally contained in the unused variables.
Moreover, FCA is not directly capable of
correspondence analysis of mixed data sets directly.
Aimed at computing mixed data sets with a great many
variables or high cardinality variables, a set of
strategies is presented, which is referred as cardinality
reduction, using less memory than MCA and being
more efficient than FCA.
As mentioned in section 3.3, k-means is applied to
each continuous variable so that the number of analysis
variables equals the number of variable of the mixed
data set. The Burt table will have many columns if the
mixed data set contains many continuous variables. In
the cardinality reduction strategies, k-means works on
all continuous variables, the output of which is clusters
as to all the continuous variables. Hence, the column
number in the Burt table is reduced forming a table like
Table 4, where cluster•r is a new category formed by
applying clustering to all continuous variable, ci • r •
indicates the number of cases containing certain values
of
,
and
belonging
to
the
ai •

Since CA is only effective for categorical variables,
the continuous variables of a mixed data set have to be
categorized first before applying CA. Clustering
algorithm is adopted to be applied to each continuous
variable Ai ( p < i ≤ m) , and each continuous variable is
categorized according to the distance among data
items.
It is recognized that k-means is quite efficient in
clustering large numerical data sets, thus it is a good
viable choice to divide data items into clusters by each
continuous variable and categorize the variable into
bins. Other numeric clustering algorithms, such as
BIRCH [14], CLARANS [15], can be alternatives,
though the performance may differ from case to case.
Table 3 Burt table after categorization
ai1

a j1

aj2

…

bink1

bink 2

…

ci1 j1

ci1 j 2

…

ci1k1

ci1k 2

…

ci 2 j1

ci 2 j 2

ai 2
ci 2 k 2
… ci 2 k1
…
…
…
…
…
…
…
…
Through clustering, numerical data are grouped into
clusters whose values can be nominally represented by
certain categorical values, named bink • . Then the
newly-computed nominal categorical values can be
imported into the table, together with the original
categorical values in a unified way. This forms tables
like Table 3, i.e. the production of clustering is that the
mixed data are transformed and filled into Table 3,
where bink • is a new category formed by applying
clustering to continuous variable Ak , ci • k • indicates the
number of cases containing certain values of ai • , and

262

e.g. k-prototype [1]. This is named Mixed-Clustering
based Correspondence Analysis (MCCA).
However, the few mixed clustering approaches, all
of have shortcomings like lack of accuracy, robustness
and predictability. A recent finding in cluster ensemble
[16] that has good stability and capability to deal with
irregular or noise data, as well as sound scalability
suggests an option to combine multiple clusters
without accessing the original features. For the details
of applying cluster ensemble, please refer to [16]. This
strategy is Cluster Ensemble based Correspondence
Analysis (CECA). The Burt table of MCCA and
CECA are presented as Table 7, where cluster• are
formed by mixed clustering algorithms or cluster
ensemble.

cluster cluster•r simultaneously; likewise, the meanings
of other letters in the table can be deducted
accordingly. This method is named r-Clustering based
Correspondence Analysis (RCCA), where r drives at
that it is a strategy implemented by clustering all the
numeric variables.
Table 4 Burt table of RCCA
a j1

aj2

ai1

ci1 j1

ci1 j 2

ai 2

ci 2 j1

ci 2 j 2

…

cluster1r

cluster2r

…

…

ci1r1

ci1r 2

…

ci 2 r1

ci 2 r 2

…
…
…
…
…
…
…
…
…
If the mixed data mostly comprises categorical
variables, clustering for categorical variables can be
used to reduce the number of analysis variables of Burt
table. The categorical items in the Burt table are then
replaced by the clusters formed as to all categorical
variables. Among the categorical clustering algorithms
available, k-mode algorithm [1] is employed here for
its efficiency and convenience. The original long table
will be transformed to tables like Table 5,
where cluster•c are formed by applying k-mode to all
categorical variables. This method is named cClustering based Correspondence Analysis (CCCA),
where c drives at that it is a strategy implemented by
clustering all the categorical variables. As a
combination of RCCA and CCCA, cr-Clustering based
Correspondence Analysis (CRCA) is proposed, which
applies k-means and k-mode to continuous and
categorical variables respectively and simultaneously,
as RCCA and CCCA are independent from each other.
The Burt table of CRCA is Table 6.

Table 7 Burt table of MCCA and CECA

cluster2c

…

bink1

…
…
…

…

…

ai1

ci1c1

ci1c 2

ai 2

ci 2 c1

ci 2c 2

…

…

…

bink 2

…

ci1k1

ci1k 2

ci 2 k1

ci 2 k 2

…
…
…

ai1

cluster2c

ci1c1

ci1c 2

…

cluster1r

cluster2r

ci1r1

ci1r 2

ci1cluster 2

ai 2

ci 2 cluster1

ci 2 cluster 2

…

…

…

…
…
…
…

The validity of the data transformation technique is
assessed by comparing visual displays of MCA-based
implementation and arbitrary quantification (arbitrary
ordering with uniform spacing) based implementation.
The memory-saving and time-efficiency of cardinality
reduction are demonstrated by comparing different
strategies implementations. Here the definitions of
MCA and FCA are extended to include the processes
of continuous variable categorization. To this end,
FCA can be applied to Burt tables to process mixed
data sets.
Star Coordinates has been selected as the
visualization of prototype; it is adept at assisting users
in discovering trends, outliers, and clusters in numeric
data sets in the early stage of data-understanding tasks.
The data sets used in experiments are two real data sets,
auto and flag, which are both available on-line at:
http://www.ics.uci.edu/~mlearn/MLRepository.html.

Table 6 Burt table of CRCA
cluster1c

cluster2

ci1cluster1

5. Empirical results

Table 5 Burt table of CCCA
cluster1c

cluster1
ai1

…

5.1 Quality of visual display

…
…
ai 2
ci 2 c1
ci 2 c 2
ci 2 r1
ci 2 r 2
…
…
…
…
…
…
…
…
…
Since simplex clustering algorithms are applied to
categorical and continuous variables respectively to
reduce the column number, we can also group data
items using mixed clustering algorithms against
categorical and continuous variables simultaneously,

Since the auto data set is typical and easy to
interpret, it is incorporated to compare the effects of
the basic data transformation technique proposed and
the arbitrary quantification approach for mixed data
sets.

263

cluster together and certain connotative information
can be revealed as to this. And it will be easy to
discover more information accurately and quickly with
further interaction and exploration.

5.2 Memory space and processing time
The most memory-consuming part of the
implementation is the application of CA, which is
agreed with Rosario et al. [12]. So the memory space
needed by CA in all cardinality reduction strategies are
focused and compared here. Since MCA uses the most
memory (sum_of_cardinality)2 by ignoring any
specific memory optimization that may be
implemented in CA, we compare the normalized
memory space used by different strategies in Figure 4,
using

Figure 1 Arbitrary quantification

Normalized Memory
Space(%)

FCA/ RCCA/ CCCA/ CRCA/ MCCA/ CECA_ MemorySpace
*100% .
MCA_ MemorySpace
100
80
60
40
20
0
Flag

Auto

MCA
FCA
RCCA
CCCA
CRCA
MCCA
CECA

Figure 4 Memory-using of different strategies
In Figure 4, it is clear that different cardinality
reduction strategies have different effects on different
kinds of data sets, that is, the effect of certain strategy
may differ according to the constitutions of data sets.
For example, RCCA does not work well with the flag
data set, even no better than FCA; while CCCA is
quite memory-saving on the flag data set, because the
flag data set has only two continuous variables. As for
the auto data set, in which the proportion of continuous
variables and that of categorical variables are about the
same, the capability of RCCA/CCCA is similar, better
than FCA. CRCA has the advantages of both RCCA
and CCCA, thus it is better than either of them. Further,
MCCA and CECA save the most memory.
Figure 5 shows the normalized run time of different
cardinality reduction strategies. In general, FCA does
not analyze all categorical variables simultaneously,
and has more columns in the Burt table, both of which
result in more computation time of CA. So we
normalize run time of different cardinality reduction
strategies using

Figure 2 MCA-based quantification

Figure 3 Quantification of variable-make
Figure 1 is the initial phase of visualization without
interaction using arbitrary quantification. The points
representing the cases are distributed confusedly, and
no connotative information of the data set can be
obtained directly; while Figure 2 is the initial phase of
visualization without interaction after applying the
proposed data transformation. In the latter, the
(dis)similarities between categories are clear. Take the
attribute make for instance, whose quantification result
is presented in Figure 3, all the car makes are clearly
partitioned into 5 groups. Mazda, Chevrolet, Dodge,
Plymouth, Mitsubishi, Honda and Subaru follow a
similar pattern, different from Mercedes-Bens when
taking the whole data set into consideration, hence they
are ordered close but far away from Mercedes-Bens.
Moreover, a part of the data items (in the red circle)

FCA / RCCA / CCCA / CRCA / MCCA / CECA _ RunTime
*100% .
MCA _ RunTime

264

Normalized
RunTime(%)

[1] Z. Huang. Extensions to the k-means algorithm for
clustering large data sets with categorical values. Data
Mining and Knowledge Discovery. Hingham, MA, Kluwer
Academic Publishers, 2(3):283-304, 1998.
[2] S. Johansson, M. Jern, J. Johansson. Interactive
Quantification of categorical variables in mixed data sets. In
Proceedings of IV 2008. IEEE Computer Society, 3-10, 2008.
[3] M. Friendly. Visualizing categorical data. Cognition and
Survey Research. New York, John Wiley & Sons, Inc., 319348. 1999.
[4] M. Friendly. Mosaic displays for multi-way contingency
tables. Journal of the American Statistical Association,
89:190–200, 1994.
[5] M. Friendly. A fourfold display for 2 by 2 by K tables.
Technical Report 217, York Univ., Psychology Dept., 1994.
[6] A. Inselberg and B. Dimsdale. Parallel coordinates: A
tool for visualizing multidimensional geometry. In
Proceeding of Visualization 90. IEEE Computer Society,
361-78, 1990.
[7] F. Bendix, R. Kosara, H. Hauser. Parallel sets: Visual
analysis of categorical data. In Proceedings of InfoVis 2005,
IEEE Computer Society, 133-140, 2005.
[8] P.E. Hoffman. Table visualizations: A formal model and
its applications. PhD Thesis, Lowell, Massachusetts:
University of Massachusetts, 1999.
[9] E. Kandogan. Visualizing multi-dimensional clusters,
trends, and outliers using star coordinates. In Proceedings of
ACM SIGKDD 2001. ACM Press, 107-116, 2001.
[10] S. Ma and J.L. Hellerstein. Ordering categorical data to
improve visualization. In Proceedings of InfoVis 99. IEEE
Computer Society, 15-18, 1999.
[11] A. Beygelzimer, C.S. Perng, S. Ma. Fast ordering of
large categorical datasets for better visualization. In
Proceedings of ACM SIGKDD 2001. ACM Press, 239-244,
2001.
[12] G.E. Rosario, E.A. Rundensteiner, D.C. Brown, M.O.
Ward, and S. Huang. Mapping nominal values to numbers
for effective visualization. Information Visualization,
3(2):80-95, 2004.
[13] M. Greenacre. Correspondence Analysis in Practice, 2nd
ed.. Chapman & Hall, 2007.
[14] T. Zhang, R. Ramakrishnan, M. Livny. BIRCH: An
efficient data clustering method for very large databases. In
Proceedings of ACM SIGMOD 96. ACM press, 83-94, 1996.
[15] R. Ng, J. Han. Very large data bases. In Proceedings of
VLDB 94, Berkeley, CA, VLDB Endowment, 144-155, 1994.

MCA

100

FCA
RCCA

50

CCCA
CRCA

0

MCCA

Flag

Auto

CECA

Figure 5 Run times of different strategies
Although cardinality reduction strategies cannot
analyze all categorical variable simultaneously either,
they are more efficient than FCA in CA process,
because there are fewer columns in Burt table, and that
the clustering algorithms are faster in most cases. But
RCCA is slower than FCA at the flag data set, because
its cardinality just reduced a little after RCCA. As a
combination of RCCA and CCCA, CRCA is timeefficient at both data sets. MCCA is sometimes even
more efficient than MCA, for its cost caused by the
irreusability of certain calculations in CA could be
complemented by reducing column number of Burt
table. In general, CECA has a little more run time than
MCCA, though they have the same Burt table, because
the pre-process, i.e. cluster ensemble, takes more time
in optimization than those mixed cluster algorithms.
However, adopting MCCA is not recommended for
practical application, due to its limitation mentioned in
Section 4, though MCCA consumes less memory and
time than others. In all, it is best to pick one cardinality
reduction strategy according to the constitutions of
data sets, or use CECA/CRCA as a default.

6. Conclusion and future work
This paper presents a memory-saving and efficient
data transformation technique for mixed data sets
visualization. Firstly, a detailed application of CA to
quantify categorical variables is described. Then, to
deal with mixed data sets with large variables, as well
as high cardinality, a set of cardinality reduction
strategies are proposed, including RCCA, CCCA,
CRCA, MCCA and CECA. They are applicable for
fields where fewer variables and lower cardinality are
needed. Finally, these were evaluated in terms of visual
quality, memory space and run time required in a Star
Coordinates-based visualization environment. Future
efforts are planned to more evaluations and userfriendly interactions. On top of that, how to choose
proper variables in mixed data sets to uncover
connotations is also an open problem.

[16] A. Strehl, J. Ghosh. Cluster ensembles-A know
ledge reuse framework for combining partitions.
Journal on Machine Learning Research, 3: 583-617,
2002.

References

265

