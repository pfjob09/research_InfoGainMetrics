2011 15th International Conference on Information Visualisation

A 3D molecular visualization system with mobile devices
Mariko Sasakura, Akira Kotaki, Junya Inada
Computer Science Department
Okayama University
Okayama, Japan
sasakura@momo.cs.okayama-u.ac.jp

direction of lean or movement of an iOS device from its 3D
acceleration sensors and using them as input of a computer.
3D acceleration sensors detect only acceleration. It means
that they don’t directly detect velocity or distance of movement of iOS device. Therefore, the direction of movement
must be generated from value of 3D acceleration sensors.
We are developing an algorithm and library by which we
can get a direction of lean or movement from the values
of 3D acceleration sensors. And we have developed a 3D
molecular visualization system with mobile devices by using
the library.
In section II, we review related works on 3D object
manipulation. In section III, we describe how our library
detects a direction of lean and movement from acceleration
sensors of an iOS device. In section IV, we introduce our
molecular visualization system using mobile devices, and we
conclude in section V.

Abstract—It is not very intuitive to manipulate objects
visualized in 3-dimension by a mouse, because a mouse can
only move in 2-dimension space. We propose an interaction
technique to manipulate 3D objects by mobile devices with
acceleration sensors. We have developed a 3D molecular
visualization system which displays results of a simulation
of the molecular dynamics method. In the system, we can
rotate 3D objects by leaning a mobile device and change a
viewing location by moving a mobile device. We discuss how
we implement the interaction technique in this paper.
Keywords-Interaction technique; Mobile devices; Acceleration sensors; 3D objects;

I. I NTRODUCTION
Since graphics workstations become widely used, computer graphics has improved a lot. Nowadays, we can see
beautiful 3D computer graphics even on displays of personal
computers. It is used for designing mechanical machine
such as cars, amusing games, and visualizing many things.
Technologies of computer graphics have also been improved.
We can easily make a program of 3D computer graphics or
animation by using free libraries such as OpenGL or Flash.
However, the major manipulation device for objects produced by computer graphics has never changed from the
very beginning. It is a mouse. A mouse is an excellent and
inexpensive device for 2D applications, but it is not enough
intuitive to manipulate objects visualized in 3D, because it
can move only in 2D space.
Therefore, many studies have been done for manipulating
objects in 3D (for short 3D objects) intuitively. For example,
data gloves for virtual reality, a 3D mouse, haptic devices,
and an Wiimote are used to manipulate 3D objects. But all
of them have a disadvantage. That is a user must buy the
extra device.
In this paper, we propose a technique to manipulate
3D objects by mobile devices and develop a molecular
visualization system in which we manipulate molecules by
mobile devices. The advantage of using a mobile device,
such as a mobile phone or mobile music player, is that
almost of us usually take along.
We are developing an interaction technique using 3D
acceleration sensors of mobile devices, such as iOS devices
(iPhone / iPod touch / iPad). We are planning to detect a
1550-6037/11 $26.00 © 2011 IEEE
DOI 10.1109/IV.2011.103

II. 3D

OBJECTS MANIPULATION

Molecular simulation systems show chemical reactions
usually obtained by simulating movements of molecules.
Many Visualization techniques for the results of simulations
represent each molecular as a 3D object and show temporal
change of molecules as animations [6], [9].
To manipulate 3D objects, there have been many studies.
The representable one may be virtual reality [1], [2], [5].
Virtual reality represents 3D objects in virtual 3D space,
and typically manipulates them by using data gloves. But,
we need big devices to construct a virtual reality system,
such as big displays or a head-mounted display, data gloves,
and complicated programs.
There are other works to manipulate 3D objects by
cheaper and easily-obtainable devices, such as Wiimotes.
The Wiimote has acceleration sensors and a CMOS sensor,
and we can buy it at a low price. Some researches have used
the Wiimote as a pointing device for a personal computer in
place of a mouse [7], [10], [11]. Since the Wiimote can be
moved in 3D space, it may be more intuitive than a mouse
for manipulating 3D objects.
Similarly, mobile devices, especially mobile phones, are
used to researches as input devices for computers. Nowadays, most people have their own mobile phone of which
performance is as good as computers one generations ago.
429

don’t change the position of the device but change the
angle. “Movement” means that we change the position of the
device without changing the angle of it. Our research shows
the difference of the patterns are like in the Figure 3. The
horizontal direction of the ﬁgure shows the time axis, and
the vertical direction indicates the output value of the sensor.
The pattern circled by red is appeared when a user moves an
iOS device. The pattern circled by green is appeared when
a user leans an iOS device.
We have developed a 3D acceleration library which can
detects a direction of lean and movement of an iOS device
based on Table I. The library has the following functions:
• Return the orientation free direction of moving.
• Return the orientation free direction of leaning.
• Return the observed value of acceleration sensors.
• Set the interval of measurement of acceleration sensors.
The library is provided for Objective-C programmers. They
can use their original programs by using the library.
We discuss how many situations can be detected by the
library. For moving, We have three axes and each axes can
have three status : moving plus direction, moving minus
direction and no moving. Therefore we can detect 33 − 1 =
26 situations, in theory. But by our experience, it is difﬁcult
for users to make composition movement with the direction
of front-back, such as forward-right, or forward-right-up and
so on. Then, we can provide stable detection for 10 situations
for moving: right, left, up, down, right-up, right-down, leftup, left-down, forward and backward.
For leaning, we also have three axes and each axes can
have three status. But for leaning, we cannot detect the
change of angle on the axis which detects gravity. And
composition movement can hardly be imaged by users.
Therefore we can use 4 situations practically: right, left,
forward and backward.
Hence, we can use 14 situations by the library.

Some mobile phones, such as iPhone, have acceleration
sensors so that we can use them to manipulate 3D objects.
Kim proposes a technique which uses the touch screen of an
iOS device as an input device for CAVE which is a famous
virtual reality system [4]. Some researches try to use mobile
devices as an input/output device for computers [3], [8].
III. A

LIBRARY FOR USING ACCELERATION SENSORS

iOS devices have 3D acceleration sensors. Figure 1 shows
the three axes of acceleration sensors. Notice acceleration
sensors detect acceleration, not speed. Therefore, we cannot know the exact distance of movement by acceleration
sensors, but we can know the direction of movement.
The acceleration sensors always sense the gravity. Therefore, if we assume that the iOS device stays still, we can
guess how the user hold it. For example, if we hold an iOS
device as the home button is downside, like the leftside of
ﬁgure of Figure 1, the y axes of the device senses gravity.
Although the y axes of a device senses gravity, we cannot
know whether the screen of the device faces the user or the
back of the device faces the user, because in these two cases,
the acceleration sensors show the same value. We suppose
that a user always holds the device as its screen faces the
user so that we can know how a user holds the iOS device
from which axis detects the gravity.
When we know how a user holds an iOS device, we
can achieve the detection of orientation free direction of
movement. The detection of orientation free direction of
movement is that we detect the direction of movement from
the user’s viewpoint regardless of how to hold the device.
We show examples in Figure 2. The three ﬁgures in Figure 2
an iOS device in held in different way. The gravity is sensed
by minus force of y axis in the left ﬁgure, plus force of x
axis in the middle ﬁgure and plus force of y axis in the right
ﬁgure. The force of the arrow in the ﬁgure is detected by
plus force of x axis, plus force of y axis and minus force of x
axis, respectively. But, we would like to detect the direction
of movement is right in all cases.
Table I shows the relation of the axis which detects
gravity, the axis which detects movement, and the orientation
free direction of movement. In all cases, we suppose that the
screen of the device faces the user. In the case of the gravity
detected as z+ and z−, we suppose that the user holds the
device as its home button stays below.
The judgment of direction is performed for each axis of
acceleration sensors separately. For example, in the case
of y− gravity, if we detect the change of plus value of x
acceleration sensor, the direction is Right. If we detect the
change of plus value of y acceleration sensor, the direction
is Up. If both of x and y acceleration sensors make plus
change, the library detects Right and Up.
We have found that we can distinguish between lean and
movement because an acceleration sensor makes different
pattern between the case of them. “Lean” means that we

IV. A

MOLECULAR VISUALIZATION SYSTEM

We have developed a molecular visualization system with
mobile device by using the library. This system visualizes
the result of simulation of molecular dynamics method (MD
method). The system has features which are the same as
typical molecular visualization systems:
• The input of the system is a ﬁle written by MFG which
is an input format of AVS1 .
• The system visualizes a molecular as a sphere.
• The system can do standard 3D object manipulation
: rotation, translation, scaling up/down and displaying
cross-section.
• The system can present the result of simulation as an
animation.
The original feature of the system is that we can manipulate 3D object by mobile devices. Figure 4 shows the
1 http://www.avs.com

430

Figure 1.

The three axes of acceleration sensors in the iOS device.

Figure 2.

The detection of orientation free direction of movement.

architecture of the system. This system consists of a personal
computer and several mobile devices. The personal computer
works as a server. The result of simulation is visualized on
the screen of the computer. One or more than one mobile
devices can connect to the server and get data of the result
of simulation. We can manipulate visualized 3D objects by
moving or leaning one of the connected mobile device.

axis, that is forward-backward direction, 3D objects rotate
to forward-backward direction. The right-upside ﬁgure in
Figure 5 shows the case of right rotation, and the rightdownside ﬁgure in Figure 5 shows the case of forward
rotation.

Figure 5 shows how we can manipulate 3D objects by
a mobile device. The system displays the same 3D objects
on the PC display and mobile device’s screen so that a user
can manipulate 3D objects, checking both of the screens.
The leftside ﬁgure in Figure 5 shows the initial state. In the
system, we adopt holding the device on z− gravity in the
initial state, since we can match the direction of movement
of the device and the 3D objects. When we lean the device
on the y axis, that is right-left direction, 3D objects rotate
to right-left direction. When we lean the device on the x

We have developed an interaction technique using 3D
acceleration sensors of mobile devices. We make a library
for providing the technique to programmers and show a 3D
molecular visualization system which uses the library. Our
preliminary user testing shows positive results, that is users
prefer our interaction technique using mobile device than
the traditional mouse for its intuitive operations.
Future works are:
• Improve accuracy of detecting directions.
In some cases, the library return different direction

V. C ONCLUSIONS

431

Table I
T HE DIRECTION DETECTED FROM THE VALUE OF ACCELERATION SENSORS .
The value of acceleration sensor
x+
x−
y+
y−
z+
z−
Gravity
x+
down
up
right
left
forward backward
up
down
left
right
forward backward
x−
left
right
down
up
forward backward
y+
y−
right
left
up
down forward backward
right
left
up
down forward backward
z+
z−
right
left
up
down forward backward
Notes: In all cases, we suppose that the screen of the device faces the user. In the case of z+ and z− on gravity, we suppose that the user holds the
device as its home button is on the downside.

Figure 3.

•

•

Patterns detected by an acceleration sensor.

from user’s intension. We have to improve accuracy
of detection for avoiding such cases.
Improve response time of detection.
Using the 3D molecular visualization system, users
sometimes complain the response of interaction is slow.
We have to improve the response time of detection for
comfortable interaction.
Evaluate the technique.
We plan to evaluate the advantage and disadvantage
of the proposed interaction technique compared with a
mouse by usability testing.

[6] Pettersen, E. F., Goddard, T. D., Huang, C. C., Couch, G.
S., Greenblatt, D. M. Meng, E. C. and Ferrin, T. E.: UCSF
Chimera - a visualization system for exploratory research and
analysis, Journal of Computational Chemistry, vol. 25, no. 13,
pp. 1605–1612, 2004.
[7] Santos B. S., Prada, B., Ribeiro, H., Dias, P., Silva, S. and
Ferreira, C.: Wiimote as an input device in Google Earth
visualization and navigation: a user study comparing two
alternatives, 14th International Conference Information Visualisation, pp. 473–478 2010.
[8] Sasakura, M., Fujioka, S. and Yamasaki, S.: Interaction with
computers using mobile devices Proceedings of 14th International Conference on Information Visualization(IV10), pp.122127, July 27-29, 2010.

R EFERENCES
[1] Bryson, S.: Virtual reality in scientiﬁc visualization Communications of the ACM, vol. 39, no. 5, pp. 62–71, 1996.

[9] Satoh, H., Aoki A. and Asaoka, H.: ChemoJun: Open Source
Chemical Graphics Library, Journal of Computer Aided
Chemistry, vol.7, pp.141–149, 2006.

[2] Cruz-Neira, C., Langley, R. and Bash, P. A.: VIBE: a virtual
biomolecular environment for interactive molecular modeling
Computer Chem. vol. 20, no. 4, pp. 469–477, 1996.

[10] Sheridan, J. G., Price, S. and Pontual-Falcao, T.: Wii remotes as tangible exertion interfaces for exploring actionrepresentation relationships, Whole Body Interaction 2009, A
SIGCHI 2009 Workshop 2009.

[3] Diehl, J., Kramer, J.-P. and Borchers, J.: A framework for using
the iPhone as a wireless input device for interactive systems,
UIST’ 08, 2008.
[4] Kim, J.-S., Gracanin, D., Matkovic K. and Quek F.:
iPhone/iPod touch as input devices for navigation in immersive
virtual environments, IEEE Virtual Reality 2009, pp. 261–262,
2009.

[11] Wingrave, C. A., Williamson, N., Varcholik, P. D., Rose, J.,
Miller, A., Charbonneau, E., Bott, J. and LaVIola Jr., J. J.: The
Wiimote and beyond: spatially convenient devices for 3D user
interfaces, IEEE Computer Graphics and Applications, vol. 30,
no. 2, pp. 71–85 2010.

[5] Nakano, A., Kalia, R. K. and Vashishta, P.: Scalable moleculardynamics, visualization, and data-management algorithms for
materials simulations., Computing in Science & Engineering,
vol.1, no.5, pp.39–47, 1999.

432

Figure 4.

The System architecture of the molecular visualization system with mobile devices.

Figure 5.

Manipulating 3D objects in a computer by a mobile device.

433

