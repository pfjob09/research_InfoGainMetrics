2011 15th International Conference on Information Visualisation

Accelerating Tumour Growth Simulations on Many-Core Architectures:
A Case Study on the Use of GPGPU within VPH
Baoquan Liu1, Gordon J. Clapworthy1, Feng Dong1, Eleni Kolokotroni2, Georgios Stamatakos2
1
2

Centre for Computer Graphics & Visualisation, University of Bedfordshire, UK

Institute of Communication and Computer Systems, National Technical University of Athens, Athens, Greece
the rapidly increasing power of the Graphics Processing
Unit (GPU) and have thus failed to take advantage of the
immense potential afforded by general purpose GPU
programming. The motivation for this paper is to
demonstrate its value to the VPH community and to bring
to its attention the level of performance gain that use of the
GPU can provide. We are not suggesting that GPUs should
supersede large-scale HPC installations for huge computeintensive applications, but we do contend that they could
usefully play a much larger role in VPH than currently.
Contra Cancrum is developing an advanced multiscale
simulation platform of tumour growth and response to
treatment, driven by real clinical needs, and is instigating
clinical translation of the simulation system within the
context of clinical trials/tests. The project has developed
molecular-level and tissue-level models and integrated
components concerned with patient-specific tissue
biomechanics and medical image analysis. A dedicated
repository has been provided to allow remote access to a
large number of multi-modal and temporal datasets of
glioma and lung cancer patient data. The initial validation
experiments with models have been both data-driven and
data-driving, as novel concepts on cross-scale model
integration have demanded the acquisition of further
molecular, patient-specific information. The ultimate goal
is the demonstration of its clinical usefulness in current
treatment practice and cancer therapy optimisation.
Within Contra Cancrum, the particular application that
forms the focus of this paper relates to the modelling of
tumour growth. Statistical approaches to tumour growth
using a Monte Carlo method have been in use for some
time [1,2]. They may require hundreds of simulations to be
run to provide a statistical picture of the likely tumour
behaviour due inter alia to the uncertainties in the
estimation of various model parameters within the clinical
context. Depending upon the outcome, the clinician may
subsequently need to slightly tune a few parameters to
obtain a new simulation result, so the interactive response
time of the simulator is critical.
Ideally, for efficient interaction, each execution should
be performed in seconds. However, for the type of data
used in this application, a simulation instance will generally
take several dozens of minutes on a desktop PC, so the
process cannot take place interactively. This severely limits
the level of experimentation that can take place. The work
described below was designed to overcome this problem.

Abstract
Simulators of tumour growth can estimate the evolution
of tumour volume and the quantity of various categories of
cells as functions of time. However, the execution time of
each simulation often takes several dozens of minutes
(depending upon the dataset resolution), which clearly
prevents easy interaction. The modern graphics processing
unit (GPU) is not only a powerful graphics engine but also
a highly parallel programmable processor featuring peak
arithmetic performance and memory bandwidth that
substantially outpaces its CPU counterpart. However,
despite this, the GPU is little used in the context of the
Virtual Physiological Human (VPH).
This paper provides a case study to demonstrate the
performance advantages that can be gained by using the
GPU appropriately in the context of a VPH project in
which the study of tumour growth is a central activity. We
also analyse the algorithm performance on different
modern parallel processing architectures, including multicore CPU and many-core GPU.
Keywords
Tumour simulation, Virtual Physiological Human,
VPH, in silico oncology, CUDA, GPGPU, multi-GPU

1. Introduction
This paper describes a case study in which CPU-based
code being used in a VPH project was replaced by
equivalent GPU code. This work took place within the
Contra Cancrum project.
The rapid increase in resolution of many of the devices
used to produce biomedical data and the multiscale nature
of much of the work on the Virtual Physiological Human
(VPH) has led to most VPH projects being confronted with
huge amounts of data. This, in turn, has tended to cause a
concentration on the use of Grid and other highperformance computing (HPC) resources to process it.
A survey undertaken by the authors found that, apart
from Contra Cancrum, only 3 of the original VPH projects
made any use of GPUs and all of these used them purely
for tasks related to visualisation and imaging – collision
detection, image processing, etc.
From the above, it is clear that, as a whole, VPH
projects have largely overlooked the possibilities offered by
1550-6037/11 $26.00 © 2011 IEEE
DOI 10.1109/IV.2011.45

601

improvement in performance at double precision, which
further extends the performance gap over CPUs.

The remainder of the paper is arranged as follows.
Section 2 provides an overview of the salient features of the
GPU that make it particularly suitable in the application
described and Section 3 introduces the application and the
processes by which the results are obtained. Section 4
describes the original program structure and how it is
parallelised, while Section 5 explains how the parallelised
code is then mapped to the GPU architecture of a single
GPU. Section 6 discusses how the GPU code is adjusted to
deal with a multi-GPU approach. Section 7 presents the
results and Section 8 provides a summary of the outcomes.

2. The GPU
Parallel computing offers fast computing by splitting
tasks into small components and distributing them among
multiple processors/threads. Many computing tasks exhibit
a parallel nature and are hence suitable for parallel
computing. Conventional parallel computing takes place
using multi-core CPUs or via distributed, grid, high
performance computers. The remarkably increased power
of the GPU in recent years offers a very attractive
alternative, which can handle many demanding tasks by
harnessing the local computing resources to be found in
low-cost computer platforms.
Probably the most important development in GPUs in
recent years has been the increase in their versatility as a
result of recent advances in GPU hardware and software
architecture. Although GPUs were initially designed for use
in highly visual tasks, mostly associated with computer
games development, they are now being used in many
computational areas - this is known as general purpose
GPU programming (GPGPU). A state-of-the-art GPU can
perform 1.35 trillion arithmetic operations per second [3],
and this represents a tremendous computational resource
when utilised for general purpose computing. The GPU
does, however, demand very specific skills to ensure that
its potential is fully realised.
The GPU has always offered multi-thread processing,
but it has now become the most powerful processor in a
desktop computer – its development continues to outpace
progress in CPUs due not only to its highly data-parallel
nature but also to its ability to achieve higher arithmetic
intensity. Figs. 1 and 2 show the huge advantage of the
latest GPUs over CPUs in terms of both GFLOPS 1 and
memory bandwidth 2 , and as the gap continues to widen,
this trend is set to become more extreme in the future.
The major factors inhibiting GPU use have previously
been low on-board memory and poor double-precision
performance. These have largely been overcome in the
current generation of GPUs and GPU clusters, with the
current NVIDIA GPUs (codename Fermi) having an 8-fold
1

GFLOPS: Giga Floating Point Operations Per Second

2

Memory bandwidth: the rate at which data can be moved
between memory and the processor

Figure 1. CPU vs GPU Performance in GFLOPS
(image courtesy of NVIDIA)

Figure 2. CPU vs GPU Performance in Memory Bandwidth
(image courtesy of NVIDIA)

Another significant factor is that GPU computational
power is inexpensive and is now widely available in many
moderate computers with basic configurations (e.g. desktop
PCs, laptops). A typical latest-generation card costs only a
few hundred euros, and these prices drop rapidly as new
hardware emerges. Moreover, off-the-shelf GPU clusters
are now commercially available at low cost, for example,
the latest-generation NVIDIA Tesla S2050 4-GPU cluster
retails at around €8,500. These can be set up with virtually
no technical knowledge and they deliver exceptional
computing power on the desktop.
The parallel nature of the GPU can provide vast speed
gains for applications in which the computational
requirements are large and parallelism is substantial. Given
their wide availability, GPUs are particularly suitable for
medium-sized computing tasks in which frequent
interaction and adjustments of parameters are needed. Even
if the final target for an application is a remote
supercomputer, early testing and experimentation is often
important before a major commitment is made to the use of

602

high performance computing facilities, which are normally
expensive and require advance booking.
Originally, the programming of the GPU used highlevel shading languages which were designed for graphics
rendering and thus require some familiarity with computer
graphics. At that time, adapting these for general-purpose
computation was less than straightforward.
In 2006, the NVIDIA Corporation released a new
computing architecture for the GPU, the Compute Unified
Device Architecture (CUDA) [3]. This is the generalpurpose parallel-computing architecture of modern
NVIDIA GPUs. Having been designed for general-purpose
usage, CUDA greatly lowers the knowledge threshold for
using GPUs for non-graphical computation. In CUDA, the
GPU is regarded as a multi-threaded coprocessor to the
CPU with a standard C language interface.
The CUDA programming model is based upon the
concept of a kernel: to define the computational task for the
GPU, programmers should provide a C-like function – the
kernel. This is a function that is executed multiple times in
parallel, each instance running in a separate thread. A
unique thread ID is given to each thread in order to
distinguish between them.
The threads are organised into one-, two- or threedimensional blocks, which in turn are organised into oneor two-dimensional grids. The blocks are totally
independent of each other and can be executed in any
order. However, threads within a block are guaranteed to be
run on a single multiprocessor. A feature that proved very
useful in this application is that this makes it possible for
them to synchronise and share information efficiently using
the on-chip memory, as CUDA allows all threads in a block
to share data via fast on-chip shared memory to avoid
redundant memory access.
CUDA maintains a separated view of the two main
actors in the computation – the host (CPU system) and the
device (GPU card/system). The host executes the main
program, while the device acts like a coprocessor.
The above discussion focused on NVIDIA GPUs because
these were used in the work described later. Other
manufacturers’ cards are generally similar in character.

matrices…of (matrices
or
vectors or
scalars)
corresponding to the anatomic region of interest [4-7].
The following parameters are used to identify a cluster
of biological cells (BCs) belonging to a given equivalence
class within a particular GC at a given time point:
I. the spatial coordinates of the discrete points of the
discretisation mesh with spatial indices i,j,k,
respectively; it is noted that each discrete spatial point
lies at the centre of a GC
II. the temporal coordinate of the discrete time point with
temporal index l
III. the mitotic potential category (i.e. stem or progenitor
or terminally differentiated) of the BCs with mitotic
potential category index m
IV. the cell phase (within or out of the cell cycle) of the
BCs with cell phase index n; the following phases are
considered: {G1,S,G2,M,G0,A,N,D}, where G1
denotes the G1 cell cycle phase, S the DNA synthesis
phase, G2 the G2 cell cycle phase, M mitosis, G0 the
quiescent (dormant) G0 phase, A the apoptotic phase,
N the necrotic phase, and D the remnants of dead
cells.
For the BCs belonging to a given mitotic potential
category AND residing in a given cell phase AND
accommodated within the GC whose centre lies at a given
spatial point AND being considered at a given time point;
in other words, for the BCs clustered in the same
equivalence class denoted by the index combination ijklmn,
the following state parameters are provided:
i. local oxygen and nutrient provision level,
ii. number of BCs,
iii. average time spent by the BCs in the given phase,
iv. number of BCs hit by treatment,
v. number of BCs not hit by treatment.
The initial biological, physical and chemical state of the
tumour has to be estimated based on the available medical
data through the application of pertinent algorithms. This
state corresponds to the instant just before the start of the
treatment course to be simulated.
The simulation can be viewed as the periodic and
sequential application of a number of sets of algorithms
(operators) on the hypermatrix of the anatomic region of
interest, which are performed in the following order:
A. Time updating i.e. increasing time by a unit (e.g. 1h),
B. Estimation of the local oxygen and nutrient level.
C. Estimation of the effect of treatment (therapy) – this
refers mainly to cell hitting by treatment, cell killing
and cell survival. Available molecular and/or
histological information is integrated at this point.
D. Application of cell cycling, possibly perturbed by
treatment. Transition between mitotic potential cell
categories such as transition of the offspring of a
terminally divided progenitor cell into the terminally
differentiated cell category is also tackled here.
E. Differential expansion or shrinkage or, more
generally, geometry and mechanics handling.

3. Tumour simulation
In the simulation method used in Contra Cancrum, a
cubic discretising mesh is superimposed upon the
anatomical region of interest to create a regular set of
geometric cells (GCs) on which the tumour simulation is
computed. This regular structure provides a suitable
foundation on which to base the parallelisation.
A set of basic biological rules is applied locally to each
of the GCs at regular timesteps (generally an hour) to
model the spatiotemporal evolution of the tumour system.
The local biological, physical and chemical dynamics of
the region are described, explicitly or implicitly, by the use
of a hypermatrix, i.e. a mathematical matrix of matrices of

603

F Updating the local oxygen and nutrient provision
levels following application of the remaining
algorithm sets at each time step. Stochastic
perturbations about mean values of several model
parameters are considered (hybridisation with the
Monte Carlo technique).
Utilisation of the models described above is designed to
take place within the Oncosimulator [5]. Fig. 3 shows a
synoptic diagram of its envisaged functioning [5,6].

is a spatially macroscopically homogeneous tumour of
spherical shape – while this construct is simple, it is, in
fact, a reasonable model for an early breast tumour [7].
As mentioned in Section 3, a cubic discretising mesh is
superimposed upon the anatomic region of interest to create
an array of GCs. This is scanned every hour, at which time
a set of rules is applied locally within the GC to find the
changes that will occur in the next time period.
In this paper, a GC corresponds to a volume of 1 mm3.
A standard assumption, particularly in radiobiological
models [8], is a cell density of 106 cells/mm3, so each GC
belonging to the tumour is considered initially to
accommodate 106 BCs. This (mean) cell density is
conserved throughout the simulation.
Each GC of the discretising mesh (which constitutes the
region of interest around a tumour) contains a number of
BCs. All cells in all GCs follow cytokinetic diagrams (see
Fig. 4), which are general cytokinetic models that can be
adapted and/or expanded for specific tumour data and drugs
under consideration by adjusting the corresponding
simulation parameters (e.g. the probabilities of the various
transitions between phases, the cell cycle durations, etc.)
[1,2,7]. The discrete character of the simulation model
enables the consideration of various exploratory initial
percentages of the cells in the various equivalence classes.
Fig. 4 depicts the cytokinetic model adopted for tumour
growth. An extension of this diagram can be used in order
to model chemotherapy-treated tumour cytokinetics. The
following types (categories) of cells can be identified:
• stem/clonogenic cells – cells assumed to possess
unlimited proliferative potential,
• limp (limited mitotic potential) or progenitor cells –
cells with limited mitotic potential (3 divisions are
assumed before terminal differentiation occurs),
• differentiated (diff) cells – terminally differentiated
cells,
• necrotic cells – cells that have died through necrosis
• apoptotic cells – cells that have died through apoptosis.
A more detailed description of the tumour growth (and
response to treatment) model is provided in [7]. Two sets of
real clinical spatiotemporal tumour data have been used for
the clinical adaptation of the model in that paper. The
basics of the model under consideration have been used
inter alia for the implementation of the entire
ContraCancrum project [9].
Commodity PCs are now typically built with general
purpose CPU hardware containing up to two or four cores
(dual core or quad core) on the same die, with higher core
counts on the horizon. They deliver high performance by
exploiting modestly parallel workloads arising from either
the need to execute multiple independent programs or
individual programs that themselves consist of multiple
parallel tasks, yet maintain the same level of performance
as single-core chips on sequential workloads [10].

Figure 3. Use of the Oncosimulator
The Oncosimulator reflects multilevel integrative
cancer biology. It is a complex algorithmic construct, a
biomedical engineering system and (eventually, in the
future) a clinical tool to support the clinician in optimising
cancer treatment in the context of the individual patient by
allowing experiments to be conducted in silico, i.e. on the
computer, across a range of different scenarios.
Additionally, it is a platform for simulating,
investigating, improving understanding and exploring the
natural phenomenon of cancer, supporting the design and
interpretation of clinicogenomic trials and training doctors,
researchers and interested patients, alike.

4. CPU implementation and parallelisation
In this paper, the data for the modelling is the same as
that in a recent study on breast cancer [7]. The initial state

604

In our experiments, we used an AMD Phenom 9650
Quad-Core CPU processor, which is an x86-based multithreaded multi-core architecture that offers four parallel
cores on the same die, running at 2.3 GHz. Each core is
backed by a 512KB L2 cache, and all four cores share a
2MB L3 cache. On such a multi-core system, the multiple
CPU threads will actually run at the same time, with each

core running a particular thread or task. So we can split up
the computational task according to the number of available
cores, and assign different parts of the GCs to different
CPU threads for parallel computing. Since different
threads in the same process share the same address space,
this allows concurrently-running code to couple tightly and
conveniently.

Figure 4. The generic cytokinetic model for tumour growth
same way. We use parallel threads to perform the
computation for each GC independently and execute hourly
scanning steps via parallel GPU kernels, which allow the
local application of basic biological rules. In this way, the
tumour evolution is computed by iteratively scanning the
biological parameters in the GCs, and at the same time
applying the biological rules to them to spatiotemporally
simulate the evolution of the tumour system. By buffering
the parameters of neighbouring GCs in the shared memory,
we can reduce the number of memory transactions hugely.
In a carefully structured way, at each iterative scan, we
assign one GPU thread to perform the computation
associated with a single GC. To simulate tumour expansion
and shrinkage, we execute the following 3 scanning steps
via parallel GPU kernels.
1) Cell growth: each thread computes all the cell-cycle
phase transitions and cell deaths due to chemotherapy
or radiotherapy that have occurred inside the GC.
2) Cell transfers are computed in parallel by unloading
excess cells from the current GC into the 26 adjacent
GCs, using 27 subpasses that interleave the 27
neighbouring GCs at each subpass. This novel
implementation takes full advantage of all the GPU
resources available under the CUDA programming
model. Cell transfers among the 27 local neighbouring
GCs (a box) are evaluated in a single thread, with each
thread block responsible for a row of boxes. All threads
in a block simultaneously iterate through the
neighbouring GCs in shared memory, computing the
transfers on the boxes in their individual registers. Since
all threads in a block access the same shared memory

5. Adaptation to a single GPU
To accelerated the C program, we create a CPU thread
that communicates with, and sends orders to, the GPU. The
pre-processing and initialisation is still handled by the
CPU, but, the data is transferred to the GPU memory at the
beginning of the time-step procedure. Then, each routine
that was previously performed on the CPU by looping over
each iterative scan of the GCs, is replaced by CUDA
routines that process all cells in parallel on the GPU.
To accelerate such numerical calculation for tumour
simulation on stream processors, we designed algorithms
using CUDA to parallelise the tumour simulation based on
the biological mathematical model.
The CUDA architecture is built around a scalable array
of multithreaded streaming multiprocessors. NVIDIA’s
current GPU consists of an array of multiprocessors, each
able to support up to 1024 co-resident concurrent threads.
Our decomposition is based on fine-grain task parallelism
that balances the load among the GPU multiprocessors.
The GPU and CPU have separate memory spaces
requiring data to be copied into the GPU or CPU memory
before the processing can take place. Data transfers of this
type occur over the PCI-express bus at a relatively slow
speed (compared with the GPU memory bandwidth of up to
144 GB/s). We try to minimise data transfer by moving as
many routines as possible on to the GPU – we gather all the
result data from the GPU into a single buffer to reduce the
size and number of the memory copies to the CPU.
The overall process is as described in Section 3. In their
initial state, the tumours are assumed to be spatially
macroscopically uniform and all GCs are initialised in the

605

task. In our implementation, we try to minimise data
transfers or other communication flow between the GPUs.
We only send data from the host to the GPUs or read back
the resulting data from the GPUs to host. We also move as
many routines as possible to the GPU, since the GPU has a
much higher bandwidth than the PCI-express bus, over
which the data transfers between GPUs take place.
The NVIDIA CUDA Runtime API gives the
programmer the possibility to select the device on which to
execute the kernels. By default, device 0 is used, and the
devices can be numbered progressively for the other GPUs.
The general idea of multi-GPU computing is to split up
the computational task according to the number of available
GPUs. To do this, we let each part of the array be handled
by one of the installed GPUs to achieve the greatest
utilisation of the multiple GPUs.
To use multiple CUDA contexts (one for each GPU),
we can associate them with different CPU threads, one for
each GPU. For the multi-GPU implementation, each CPU
core runs a separate thread and controls one of the GPUs by
using the corresponding CUDA context. For optimal
performance, the number of CPU cores should be greater
than, or at least equal to, the number of GPUs in the
system. Our bench host CPU satisfies this requirement.
To use multiple GPUs in our implementation, we spawn
4 CPU worker threads from the CPU master thread (usually
each will run on a different CPU core), one for each
individual GPU. A worker thread will hold a CUDA
context and be responsible for an individual GPU, while the
CPU master thread can send messages or data to the 4
worker threads. Thus, we have a one-to-one relationship
between the CPU threads and the GPU devices. As a result,
the 4 worker threads can launch the 4 GPUs simultaneously
and run the kernels in parallel.
The idea is that each CPU host thread, the worker
thread, will attach to a different GPU device with a unique
device ID for each CPU thread.
All data to be allocated and manipulated on the GPU
should be created in the context of the CPU thread that is
attached to its appropriate GPU device. By this means, we
can run the GPU kernels from these CPU threads with
different parts of the data that we want to process. Finally,
after all four GPUs finish their computation, we copy the
results back from the GPUs to the CPU master thread.
In this way, all the GPUs run the same code but operate
on different parts of the input dataset in a parallel mode.

location, data are broadcast to all threads by the
hardware, and no bank conflict penalty is incurred.
3) Differential tumour shrinkage is dealt with by freeing
the GCs containing too few cells, or creating new GCs
for differential tumour expansion. Tumour contiguity is
also restored if fragmentation has taken place.
The above process is repeated continuously until the
completion of the time interval Tinterval (in hours) being
studied. Finally, we read back the results from the GPU
memory to the CPU buffer over the PCI-express bus.

6. Multi-GPU implementation
Here, we investigate the performance factors of a multiGPU system for tumour simulation. In particular, we focus
on NVIDIA’s Tesla multi-GPU solution, which combines
four GT200 GPUs, making up to 4 TFLOPS of
computational power available. Our test bench, the
NVIDIA Tesla S1070, can be connected to a single host via
two PCI Express connections (shown in Fig. 5).
We show that the multi-GPU system greatly benefits
from using all four of its GPUs on very large data volumes
– computation using the four GPUs was only slightly short
of four times faster than using a single GPU.
Performance was measured on an NVIDIA Tesla S1070
containing four GT200 GPUs. The S1070 contains 30
multiprocessors, each with 8 streaming processors (for a
total of 240 processor cores), 16KB 32-bit registers and 16
KB of shared memory. The theoretical global-memory
bandwidth is 102 GB/s and the available global memory of
each GPU is 4GB. The Tesla S1070 has up to 4 TFLOPS of
computational power.

Figure 5. Tesla S1070 System Architecture
(image courtesy of NVIDIA)

7. Results

The connection to the host CPU is through PCIe Host
Interconnection Cards (HIC), with a single PCIe slot on the
host being connected to two GPUs using a PCIe HIC card.
This provides a transfer rate of up to 12.8 GB/s between the
host CPU and the Tesla S1070.
The GPUs are linked through the host system. This kind
of interconnection requires communication to set up
cooperation in order to solve a massive data parallelism

7.1 Baseline CPU and GPU implementation
We performed our experiments of free tumour growth
(based on cytokinetic models) on a desktop computer with
AMD Phenom 9650 Quad-Core CPU processor, which has
4 CPU cores all running at 2.30 GHz.
At first, we tested the baseline CPU implementation,
which used only a single CPU thread. The first GPU

606

The performance improvement of the multi-thread CPU
implementation compared to the baseline single thread
CPU implementation is shown in Table 2, where timet is
the multi-thread CPU computing times in milliseconds for
different numbers of CPU threads. From Table 2, we can
see that the performance is slightly below linear for threads
up to 4 in number and, thereafter, it does not improve.
The best performance of the parallel multi-thread CPU
implementation is achieved when the number of threads is
equal to the number of cores in the CPU hardware. In this
case, each thread runs on a real CPU core, so that the
horsepower of the multi-core CPU hardware can be fully
utilized. More or fewer threads can only result in worse
performance, since fewer threads cannot fully employ the
power of the multi-core hardware, while more threads will
entail more overheads than necessary.

hardware in the experiments is an NVIDIA GTX 285 GPU,
which contains 30 multiprocessors, each of which contains
8 streaming processors (for a total of 240 processor cores).
We implemented our single GPU algorithm using the
CUDA programming language [3]. The performance
improvement of the GPU implementation compared to the
baseline CPU implementation is shown in Table 1, where
timeb and timeg1 are the computing times (in milliseconds)
of the baseline single CPU thread and the GTX 285 GPU
implementation, respectively.
From Table 1, it can be seen that the more demanding
the calculation becomes, the greater the benefit derived
from using the GPU. The speedup increases both with an
increase in Tinterval and an increase in the number of GCs
(that is, an increase in spatial resolution).
TABLE 1
BASELINE CPU AND GPU PERFORMANCE
resolution
of GCs

Tinterval
(hours)

timeb
(ms)

timeg1
(ms)

speed-up
factor

323

500

8604

173

49.7

3

5000

85332

1563

54.6

643

5000

970888

7905

122.8

32

7.3 Multi-GPU implementation
We performed the multi-GPU experiments on tumour
growth based on cytokinetic models on an NVIDIA Tesla
S1070 computing system, which (as mentioned earlier)
contains four GT200 GPUs. We implemented the GPU part
of the algorithm using the CUDA programming language
[3] and the CPU parts of algorithm using C++.
The performance of the multi-GPU computation
compared to that on a single GPU is shown in Table 3,
where timeg1 and timeg4 are the computation times for one
GPU and four GPUs, respectively, in milliseconds.

This is due to an increase in the GPU occupancy (that
is, the proportion of the hardware’s threads that are actively
in use) which, in essence, determines how successfully the
hardware is kept busy. This can also help to reduce the
effect of memory latency and dependencies.
The performance gain is particularly noticeable in the
643 example, in which the processing time was reduced
from 16 minutes to 8 seconds, which can radically change
the approaches that users employ to investigate their data.

TABLE 3
PERFORMANCE OF MULTI-GPU v. SINGLE GPU

7.2 Parallel multi-thread CPU implementation

TABLE 2
MULTI-THREAD CPU PERFORMANCE
# of
threads

Tinterval
(hours)

643

5000

1

970888

1

643

5000

2

492580

1.97

643

5000

4

263522

3.68

643

5000

8

264655

3.67

timet
(ms)

Tinterval
(hours)

643

5000

timeg1
(ms)
7905

timeg4
(ms)
2157

speed-up
factor
3.66

This result shows that the multi-GPU system greatly
benefits from using all of its GPUs on a very large dataset.
Four GPUs were almost 4× faster than a single GPU.
Tables 1 and 3 show that a computation that took 16
minutes on the single-core CPU was completed in 2.157
seconds on the Tesla S1070, a speed up of over 450×.
We also found that the multi-GPU implementation may
be slower than a single GPU implementation when the
amount of work to be performed per GPU is very small (for
example, when the volume resolution is very low); this is
due to the overheads associated with creating multiple CPU
threads to take care of each GPU separately.
So, the multi-GPU implementation is only worthwhile
when you have a significant amount of work to perform per
GPU (for example, very large data volumes), so that the
overhead of creating multiple CPU threads can be
amortised. If that is the case, the acceleration with the
number of GPUs can be fairly close to linear.

The multiple-thread CPU implementation took place on
an AMD Phenom 9650 Quad-Core CPU processor with 4
CPU cores running at 2.30 GHz. On this multi-core
system, we split the computational task according to the
number of available cores and assigned different parts of
the GCs to different CPU threads for parallel computing.
The multiple CPU threads run at the same time, with each
core running a particular thread, and each CPU thread
processes a different part of the data in parallel.

resolution
of GCs

resolution
of GCs

speed-up
factor

607

This paper considered a successful existing approach to
tumour growth simulation and developed code specifically
to run such simulations on a variety of platforms including
multi-core CPUs and many-core GPUs. The existing code
was designed to run on a single-core CPU, and this acted as
a reference point for the experiments that followed.
In the application, tumour simulation was performed by
executing hourly scanning of a set of geometric cells
representing the tumour and its close neighbourhood. The
method simulates the cell-cycle phase transitions based on
biological rules, and the cell deaths due to chemotherapy or
radiotherapy that have occurred inside each GC. As a
result, we can estimate the tumour volume and the quantity
of cells (stem, proliferating, etc.) as a function of time from
a given set of input parameters.
As the speeds provided by the GPU mean that users no
longer have to compromise on resolution to achieve
acceptable computation times, our discussion below
concentrates on the highest resolution case investigated.
Compared to the baseline version running on a single
core, our parallel implementation delivered a speed up of
approximately 3.66× when using the quad-core capabilities
of the same CPU.
We also proposed a GPU-based approach to tumour
growth simulation that is carefully constructed to take full
advantage of the particular architecture of the GPU. We
assign GPU threads to perform the tumour simulation by
executing the hourly scanning via parallel GPU kernels
under the CUDA programming model.
Use of a single previous-generation GPU produced a
speed up of approximately 122.8× over the baseline. The
experiments showed that the performance gain in using a
GPU is particularly noticeable for cases in which there is
high spatial resolution or a long scanning time.
A multi-GPU parallelisation was also performed using a
Tesla S1070, and this delivered a 450× speed-up over the
baseline CPU. In this, we split the computational task
according to the number of available GPUs, so that each
GPU computes only a part of the array. In this way, all the
available GPUs in the system can run in parallel. Our
experiments showed that the multi-GPU system greatly
benefits from using all of its four GPUs on very large data
volumes. We found that the four GPUs were almost four
times (3.66×) faster than using a single GPU.
A single latest-generation GPU provided a speed up of
approximately 2.94× over the previous generation GPU,
equivalent to a speed up of 361× over the baseline CPU.
GPU use thus proved to be an effective way of reducing
the computational time in an application similar to many
others in VPH projects. The result was that the users can
treat the data differently. A single run of the application
previously took over 16 minutes but the latest-generation
single GPU reduced this to 2.7 seconds. This means that
interactive data investigation can now be considered for
large datasets, even on commodity hardware, offering users

7.4 Implementation on the new GTX480 GPU
Both the S1070 and GTX285 used in the above
experiments belong to the category of GT200 GPU, where
each GPU has 240 processor cores, 16KB registers per
multiprocessor and 16KB shared memory. Below we
perform experiments on the Geforce GTX480 (from the
current generation of NVIDIA GPUs, as this is written),
which has 480 processor cores, 32KB registers per
multiprocessor and 48KB shared memory; it also has a
much faster memory clock.
The performance improvement of the GTX480 GPU
compared to that of the GTX285 is shown in Table 4,
where timeg1 and timeg2 are the computation times for
GTX285 and GTX480, respectively, in milliseconds.
TABLE 4
PERFORMANCE ON GTX480 GPU
resolution
of GCs

Tinterval
(hours)

643

5000

timeg1

timeg2

(ms)
7905

(ms)
2684

speed-up
factor
2.94

The experiment showed that the GTX480 GPU is 2.94
times faster than GTX285 in this application due to a
number of factors associated with the greater number of
cores, larger register and shared memory, and the faster
memory clock on the GTX480 GPU.

7.5 Precision
Current GPUs fully support single-precision float
arithmetic and conform to the floating point standard in the
same way as the SIMD units in CPUs do. Numerical codes
executing on these architectures today typically yield bitidentical results, and any discrepancies are within the
floating point standard [11].
Unfortunately, in previous-generation GPUs (e.g. the
NVIDIA GTX 285), the double-precision arithmetic is not
very mature, so we used only single-precision float
arithmetic in both the CPU and the GPU implementations.
We intend, in the near future, to update our implementation
into double-precision arithmetic on the newer NVIDIA
Fermi GPU (e.g. the Tesla S2050), which has been
specifically designed to offer unprecedented performance
in double precision [12], and we anticipate even greater
performance gains when we do.

8. Conclusion
GPU technology is currently greatly under-utilised in
the context of the Virtual Physiological Human, and this
paper was written as a case study in applying GPGPU
programming within a VPH project to highlight its benefits.
The gain in performance in this application clearly
demonstrates that the GPU warrants a much more
prominent role in the future development of the VPH than
it has had the opportunity to play in the past.

608

Response to Therapeutic Schemes in vivo. Some Operator
Properties, Cancer Informatics 7:239–251
[5] Stamatakos, G.S., Dionysiou, D.D., Graf, N.M., Sofra, N.A.,
Desmedt, C., Hoppe, A., Uzunoglu, N. & Tsiknakis, M. 2007
The Oncosimulator: a Multilevel, Clinically Oriented
Simulation System of Tumor Growth and Organism
Response to Therapeutic Schemes. Towards the Clinical
Evaluation of in silico Oncology, Proc IEEE Eng Med Biol
Soc., Lyon, France, 23-26 Aug. 2007
[6] Stamatakos, G.S. 2010 In silico Oncology: PART I Clinically
Oriented Cancer Multilevel Modeling based on Discrete
Event Simulation”, In Multiscale Cancer Modeling. (eds.
T.S. Deisboeck, G.S. Stamatakos) Chapman & Hall
[7] Stamatakos, G.S., Kolokotroni, E.A., Dionysiou, D.D.,
Georgiadi, E.Ch. & Desmedt, C. 2010 An advanced discrete
state - discrete event multiscale simulation model of the
response of a solid tumor to chemotherapy: Mimicking a
clinical study. Journal of Theoretical Biology 266, 124-139
[8] Steel, G. 2002 Basic Clinical Radiobiology. London: Arnold
[9] Marias, K., Sakkalis, V., Roniotis, A., Farmaki, C.,
Stamatakos, G., Dionysiou, D., Giatili, S., Uzunoglu, N.,
Graf, N., Böhle, R., Messe, E., Coveney, P.V., Manos, S.,
Wan, S., Folarin, A., Nagl, S., Büchler, P., Bardyn, T., Reyes,
M., Clapworthy, G.J., McFarlane, N., Liu, E., Bily, T., Balek,
M., Karasek, M., Bednar, V., Sabczynski, J., Opfer, R.,
Renisch, S. & Carlsen, I.C. 2009 Clinically Oriented
Translational
Cancer
Multilevel
Modeling:
The
ContraCancrum Project. In World Congress 2009 on Medical
Physics and Biomedical Engineering (eds. O. Doessel &
W.C. Schlegel), Sept 7-12, Munich, Germany, IFMBE
Proceedings 25/IV, 2124-2127
[10] Garland, M. & Kirk, D.B. 2010 Understanding throughputoriented architectures. CACM 53(11): 58-66
[11] Brodtkorb, A.R., Dyken, C., Hagen, T.R., Hjelmervik, J.M.
& Storaasli, O.O. 2010 State of the Art in Heterogeneous
Computing, Journal of Scientific Programming, 18(1):1-33
[12] NVIDIA 2010 Fermi Compute Architecture Whitepaper.
NVIDIA

the prospect of much greater experimentation with
parameters and settings than was previously possible.
In Monte Carlo and other statistical methods in which
multiple runs of the same simulation are required in order
to build up a probabilistic picture of the outcomes, it also
becomes feasible to increase the numbers of experiments,
possibly leading to more robust outcomes.
The current cost of a GTX480 is approximately €400.
That such performance gains can be achieved for such a
small investment in hardware is truly remarkable.

9. Acknowledgment
This work received partial support from the European
Commission within the project Contra Cancrum (FP7-ICT223979) and the Marie Curie Fellowship GAMVolVis
(023610). Dr D. Dionysiou is acknowledged for her
contribution to the model development. Feng Dong is
supported by the Open Project Program of the State Key
Lab of CAD&CG (Grant No. A1012), Zhejiang University.

References
[1] Stamatakos, G.S., Antipas, V.P. & Uzunoglu, N.K. 2006 A
spatio-temporal, patient-individualized simulation model of
solid tumor response to chemotherapy in vivo: the paradigm
of glioblastoma multiforme treated by temozolomide, IEEE
Trans Biomedical Engineering, 53(8):1467-1477
[2] Dionysiou, D.D. & Stamatakos, G.S. 2006 Applying a 4D
multiscale in vivo tumor growth model to the exploration of
radiotherapy scheduling: the effects of weekend treatment
gaps and p53 gene status on the response of fast growing
solid tumors, Cancer Informatics, 2:113-121
[3] NVIDIA 2010 CUDA programming guide, NVIDIA
[4] Stamatakos, G.S. & Dionysiou, D.D. 2009 Introduction of
Hypermatrix and Operator Notation into a Discrete
Mathematics Simulation Model of Malignant Tumor

609

