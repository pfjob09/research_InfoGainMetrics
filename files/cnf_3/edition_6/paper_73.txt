A Deterministic Multidimensional Scaling Algorithm for Data Visualisation
Anthony Don, Nicolas Hanusse
LaBRI, Domaine universitaire 351, cours de la lib´eration, 33405 Talence Cedex, France.
{don, hanusse}@labri.fr.
Abstract
In this paper, we present I-PACK , a deterministic layout algorithm for embedding a data set X in 2D provided that distances (δuv )u,v∈X between data items are
given or can be computed. The layout reﬂects well similarities and dissimilarities between items and it is computed in quasi-linear time. Experimental comparisons
with other multidimensional scaling algorithms show
that : i) our algorithm has similar performance when the
maxu,v (δuv )
aspect ratio A = minu,v
(δuv ) is small (i.e. log2 A < 10)
and ii) the larger the aspect ratio, the better I-PACK performs with respect to other MDS algorithms. This is also
true when data can be “naturally” clustered.

1 Introduction
The embedding of multivariate data in small dimension has received a real attention since it can be used
in many applications. In the literature, this operation is
often called multidimensional scaling (MDS).
For instance, images and video data can be indexed
by low-level or high-level descriptors. The low-level descriptors include MPEG-7 descriptors (dominant color
descriptor, color layout descriptor, etc) [6] and an intense research deals with high-level descriptors (face
recognition, indoor /outdoor scenes, etc). A frequent
work consists in tuning a metric space, in which points
correspond to descriptors values, so that the metric space
represents a perceptive distance between images. Given
a descriptor and its dedicated metric space (often coded
by high-dimensional numeric vectors), one can compute
a distance between any pair of images within the collection. A user could be interested in a 2D-layout that
would help him navigate within an image collection.
The main difﬁculty consists in ﬁnding an embedding
with small distortion: similarities and dissimilarities of
the original metric should be well reﬂected in low di-

Proceedings of the Information Visualization (IV’06)
0-7695-2602-0/06 $20.00 © 2006

IEEE

mensional space. These two goals are antagonist: take
n equidistant points and try to lay them down on the Euclidean grid of dimension D. The distortion 1 will be
Ω(n1/D ) for any embedding.
The presence of clusters in data and the ability of
a MDS algorithm to well represent clusters in a 2Dembedding is also an important feature for data visual analysis. Usual MDS algorithms are not dedicated
to this task and metric spaces are considered globally.
There is a tacit hope that if we were able to embed a
metric space in 2D with a low distortion, clusters might
naturally appear.
In order to compare algorithms according to this feature, we need some data sets that contain clusters. A
well-deﬁned corpus of clustered data is difﬁcult to ﬁnd,
moreover there are many ways of deﬁning clusters. This
is why we propose a method to produce data sets of arbitrary size with an associated metric and the ability to
add many compact clusters.
The two main approaches for MDS consist either of
an analysis of the eigenvectors of the matrix of dissimilarities (the statistical approach of Principal Component
Analysis) or the use of physical models : spring or forcedirected models (see [10, 8]). In physical models, the
general idea is to start from a random location of data
items and to let some attraction and repulsion forces act
2
in order to move the items so that the total energy of
the system (also known as the Stress of the embedding)
reaches a minimum.
The force-directed MDS can be preferred in information visualization because of their iterative nature which
allows the user to visualize the evolving system and to
interact with it.
In both approaches, the main drawback is time complexity. In a general setting, time complexity is O(n3 ),
n being the number of data items. For physical models,
1 In

this case, the aspect ratio of the embedding
are computed so that the 2D euclidean distance between
data tend to the original distance
2 Forces

some improvement has been done to decrease time complexity (O(n2 ) in [5], O(n3/2 ) in [19] and O(n log n)
in [15]) without degrading dramatically the Stress of the
2D embedding for almost uniform metric spaces. Although these previous algorithms perform well for standard data sets, experiments reveal that the distortion is
much larger whenever the data sets are very clustered or
when the aspect ratio of the metric space is large.

1.1

Intrinsic Dimensionality of Metrics

Recent work on efﬁcient data structures for accessing
to nearest-neighbours in a data set [16, 4, 17, 11] use the
characterization of the intrinsic dimensionality of metric spaces. This measure inﬂuences the time complexity
of queries in these data structures. Two measures have
been proposed : the grid dimension and the doubling dimension. The grid dimension or the expansion of the
u (2r)|
metric space X is log2 (maxu,r |B
|Bu (r)| ), Bu (r) being
the ball centered at point u of radius r, that is the set
of points at distance at most r from point u. Roughly
speaking, the grid dimension corresponds to a characterization of data and gives the maximum number of
new points reached whenever the exploration radius is
doubled. For instance, if we take all the points that are
distributed like a grid in dimension D and the L1 − or
L2 −norm, Bu (r) = Θ(rD ) and the grid dimension is
D. Another interesting deﬁnition of the dimension is
the doubling dimension [1, 13]. The doubling dimension dd(X) of a metric space X is the logarithm in base
2 of the maximum number of balls of radius r required
to cover any ball of radius 2r. Note that the balls need
to be centered at the points. In case of uniform distribution, both deﬁnitions of dimension are similar. The
doubling dimension is often smaller than the grid dimension but much more complex to compute. To our
knowledge, only approximation algorithms exist for the
doubling dimension computation [14, 12]. Huang [14]
proposes to approximate the doubling dimension within
a multiplicative factor 4. Computations on a dozen of
real data sets with up to 60,000 items show that the doubling dimension of the underlying datasets is within the
range [2, 12]. This experiment conﬁrms the low intrinsic
dimensionality of real data sets.

1.2

Our contributions

In this paper, we propose :
• A low distortion 2D-layout of data, called I-PACK ,
provided that distances between items can be computed or retrieved (see Section 3).

Proceedings of the Information Visualization (IV’06)
0-7695-2602-0/06 $20.00 © 2006

IEEE

• A methodology to generate random data sets tuned
simultaneously by different parameters among :
cardinality, doubling dimension, aspect ratio, cluster size (see Section 4.2).
• Benchmarks on synthetic and real data sets. Experiments show that the runtime and the quality measures of I-PACK are particularly interesting as soon
as aspect ratio is large or data sets are naturally
clustered. We also propose a new quality measure,
namely the Average Displacement of the layout, in
order to quantify the change of a layout whenever
some new items are added to the collection. In Section 6, we apply our algorithm to collections of indexed images . (see Sections 5 and 6).

1.3

Related work

In Section 5, we make a comparison with usual and
efﬁcient MDS algorithms based upon physical models.
As mentioned in the introduction, the main drawback of
force-based models is the time needed to converge to an
equilibrium. In terms of distortion measure, GEM [9]
is one of the most efﬁcient algorithm. It performs O(n)
runs of a step that computes every interaction between
the n points in O(n2 ). However, the O(n) repetitions
do not guarantee that the equilibrium will be reached.
Moreover, it starts from an arbitrary 2D-embedding that
does not take into consideration any property of the metric space.
Several improvements with respect to time complexity are based on random sampling of points : (O(n2 )
in [5], O(n3/2 ) in [19] and O(n log n) in [15]). The
key idea shared by these algorithms consists in ﬁnding√a good layout of a small sample (typically of size
O( n)) and to place other points with respect to the
closest points of the sample. These heuristics perform
well in practice. However, in the case of small clusters
separated by large distance scales, there is no hope for
many points that there exists a close point in the sample. Experiments of Section 5 tend to conﬁrm this point.
These algorithms could derive beneﬁt from the construction of a parsimonious sample.

1.4

Principle of I-PACK

The starting point of our algorithm consists of
quickly designing a parsimonious sample of the given
data set. By parsimonious, we mean that (1) the distance
between any pair of items of a given sample Si should
be greater that a given threshold ti and (2) the distance
between any item of the data set X and a sample S is as

small as possible. Repeating iteratively such a construction, we get a multi-level sampling Sl ⊆ Sl−1 . . . ⊆
S0 = X of the data set. This step can be done using
recent data structures dedicated to metric of low doubling dimension (see Section 2.2). From any of these
data structures, a tree T approximating the metric can
be easily extracted.
Once the tree is computed, the layout phase is based
upon the following scheme : a set of items x ⊆ Si having the same closest item in Si+1 is arranged in the same
bounding square in such a way that the distance between
any pair of items of x is at least ti . We call this original step the I-PACK algorithm since it iteratively packs
similar items within squares. We propose the formal description of this part in Section 3.

2 Preliminaries
2.1

We now introduce several notations that we use in the
rest of this paper :
• (X, δ) : metric space of the data set X with
cardinality |X| = n,
• δuv : distance between items u, v ∈ X,
maxu,v (δuv )
minu,v (δuv )

: aspect ratio of X,

• dd : doubling dimension of X [4],
• Δ : maximum degree of tree T ,
• ρ : X → R2 : 2D embedding of X,
• h = log2 A : number of distance scales in the data
set.
The distortion of the embedding is measured by two
functions : i) the Stress, which is a global measure
of quality of the embedding of X and ii) the Stretch
which gives the distortion between the low-dimensional
distance and the original distance of two points. let
u, v ∈ X, let |ρ(u)ρ(v)| be the Euclidean distance between u and v in the 2D embedding, we deﬁne :
• the Stress of the embedding as :
Stress =

Approximating the metric space
with a tree

Hierarchy of nodes : our algorithm is based on a hierarchical sampling of the data : let Sh ⊆ Sh−1 ⊆ . . . ⊆
S0 = X be a sequence of data subsets. The construction
of sets Si should guarantee two properties :
• the coverage property : ∀u ∈ Si with i < h , ∃v ∈
Si+1 such that δuv 2i+1 ,

The tree T

: For each level i

u,

u stores :

• a parent : v ∈ Si+1 , noted Pui , such that δuv
2i+1 . Pui = u if i < u ,
• its children : the set of nodes Cui = {v ∈
Si |Pvi−1 = u}.
i
For each i
u , we deﬁne the tree Tu rooted on the
copy of u at level i. For u ∈ Sh , T = Tuh is the tree
used in our 2D-layout.

s

t
u

u

S2

r
s

r

u

v

S1

u

v

S0

v

− |ρ(u)ρ(v)|)2
2
u<v |ρ(u)ρ(v)|

Stretchuv =

δuv
|ρ(u)ρ(v)|

Proceedings of the Information Visualization (IV’06)

IEEE

Each item u is associated with a level u corresponding to the highest index i such that u ∈ Si . The highest
level, h = log2 A, contains at least one item.
From the hierarchical sampling, we can build a tree
T that approximates the metric (see Figure 1).

u<v (δuv

• the Stretch between u and v in ρX , denoted by
Stretchuv as :

0-7695-2602-0/06 $20.00 © 2006

2.2

• the separation property : ∀u, v ∈ Si with u = v ,
δuv 2i .

Notations

• A=

For the readability of the paper, we present our algorithm assuming that the minimal distance in X is 1. If
it is not the case, there is no need to normalize distances
or compute the minimal distance, as the algorithm would
stay unchanged.

r

a)

s

t

b)

Figure 1. Example of tree T . a) Dataset X
with 5 points in the plane. b) One possible
Tree T for X with 3 levels.

We claim that T approximates the metric since two
close points that belong to Si are likely to choose the
same parent in Si+1 . Recently, different constructions
efﬁciently provide a design of such trees [4, 17, 11].

q

Lemma 1 ([4, 17, 11]) For a metric space (X, δ) of
doubling dimension dd, Tree T can be built in
O(2O(dd) n log A) time.

w

An interesting property deals with the relationships
between the doubling dimension of the metric (X, δ)
and the degree of the tree T .
Tree T provides a precise approximation of the doubling dimension dd of the metric space (X, δ). If the
largest degree within T is Δ then dd
log2 Δ. Note
that, depending of the inserting order of the points, different trees Tj with different highest degree Δj can be
built implying that dd
minj {log2 Δj }.On the other
hand, in [11], the authors prove that the maximal degree
of T is 5dd . Thus, for a given metric of doubling dimension dd, Δ 5dd .
Lemma 2 Let T be a tree associated with (X, δ) and Δ
be its maximum degree, then log5 Δ dd log2 Δ.

3 2D-layout of the metric space
The 2D-layout algorithm I-PACK described in Algorithm 1 takes as input the rooted tree T . The principle
consists in assigning to each node of T a square containing its subtree. This operation is done recursively.
We start from the leaves with a square of unit area and
empty rings of increasing width (with respect to level
within T ) are preserved.
The function PACK(Q, w) takes as input a set of
squares Q and computes a placement without overlapping of Q within a square q of width w. The principle
is to place the squares in decreasing width order, row
by row, inside q. If |Q| = 1 then the single square is
centered within q. We start in the lower left corner and
whenever a square would go outside q, is is used to start
a new row (see Figure 2). Moon and Moser [18] proved
that taking w = w1 + s − w12 (w1 is the largest width
among Q) is enough in order to place the whole set Q of
total area s. Moreover, for this last value of w, we can
note that the PACK function is a 2 approximation of the
optimal packing since Q is of area less than 2s.
Let qui be the square associated with node u ∈ X at
level i. Let Qiv be the set of squares associated with node
v’s children at level i.

Proceedings of the Information Visualization (IV’06)
0-7695-2602-0/06 $20.00 © 2006

IEEE

Figure 2. A set of squares Q (grey squares)
is packed within square q with width w.

Algorithm 1 I-PACK
Input: A rooted tree T ;
Assign a unit square, qu0 , to each leaf u ∈ T ;
for node v ∈ T do
for level i from 1 to v do
Let w1 be the width of the biggest
square among the set Qiv = {qui−1 |u ∈
Cvi };
Let s be the sum of the area of squares
in Qiv
Let w = max(2i , w1 + s − w12 );
Place the set Qiv within qvi using
PACK (Qiv , w).
Assign the coordinate of the center of square qu0 to
each leaf u ∈ T ;

Lemma 3 Algorithm I-PACK computes the 2D-layout
of the tree T , of size N and maximum degree Δ, associated with (X, δ) in time O(N Δ log Δ).
There are N = O(n log A) nodes in T and at each
node, the PACK function sorts Δ = 2O(dd) (from
Lemma 2) squares in time O(Δ log Δ).
Proposition 4 The proposed method computes a 2Dlayout of any metric space of doubling dimension dd in
O(N Δ log Δ) time.
Proposition 4 follows from Lemma 1 and Lemma 3.
In practice, for the data sets that we use in this paper, both aspect ratio and doubling dimension can be
bounded by a constant, namely log2 A < 10 and dd <
10 (see Table 1). Therefore, the time complexity of IPACK is quasi-linear in n.

4 Test data sets
In this section, we introduce the data that we use to
compare I-PACK with some selected MDS algorithms.

4.1

2
For instance, Um
can be seen as a 2D grid as shown in
Figure 3.

Available data sets

Table 1 sums up the features of the different data ﬁles
that we refer to in Section 5. These data ﬁles are all
collections of n numeric vectors with d components. We
use the L2-norm as distance function between numeric
vector. Due to Lemma 2, we can give an approximation
of the doubling dimension, dd of each data set.

um−1,0um−1,1um−1,m−3 um−1,m−2

um−1,m−1

um−2,m−1
um−3,m−1

Name
SwissRoll∗
Face∗
TREC∗∗
QTFI
Aqua

n
7494
698
4000
394
166

d
3
4096
12
12
12

ddinf - ddsup
1.49 - 3.46
2.38 - 5.52
3.70 - 8.59
2.49 - 5.78
1.72 - 4

Table 1. Approximation of the doubling dimension (dd) of data ﬁles used in this paper. (∗ available from the isomap homepage [21]. ∗∗

u1,m−1
u0,0

ui,j

2

j

ui,j+1

u0,m−1

2
Figure 3. Grid Um
of size m2 .

Proposition 5 For given L, the aspect ratio of the grid
L
is Θ(2m+log2 L ).
Um

key-frames available from [20]).

The SwissRoll data is a collection of coordinates of
3D points sampled from a 2D manifold. The Face data is
a collection of grey-scale pictures of size 64x64 of a 3D
face model rendered under different pose and lighting
conditions. The Aqua, QTFI and TREC data is made of
one MPEG7 Color Layout Descriptor [6] per key-frame
extracted from the following video documents : “Aquaculture en M´editerran´ee” c SFRS, “Quel temps font-ils
?” c SFRS, the TRECVID 2002 Corpus.

4.2

Synthetic data

In this section, we present 2 method for generating
synthetic data sets. In each case, the minimal distance in
the data set is one unit.
Data sets with large aspect ratio In Section 5.3, we
show that I-PACK provides a better 2D-embedding than
other considered MDS algorithms when the aspect ratio
A of data sets is increasing.
In order to compare with other algorithms, we propose to build synthetic data with many distance scales,
i.e large aspect ratio A.
Let Um = u0 . . . um−1 be a sequence of points.
The distance between points uj and uk with j < k is
k−1
δuj uk = i=j δui ui+1 and δui ui+1 = 2i . It is easy to
check that the aspect ratio of the point set is 2m−1 and
that there is one point per distance scale. Consider now
L
.
the set of points deﬁned by the Cartesian product Um

Proceedings of the Information Visualization (IV’06)
0-7695-2602-0/06 $20.00 © 2006

IEEE

Clustered data sets In this section, we show how to
generate many data sets of given doubling dimension
with well separated clusters. Such a task is quite difﬁcult since we aim at designing a large class of metrics
parametrized by different characteristics : size, doubling
dimension, clusters size. We deﬁne a cluster as a subset
of points whose distance between any pair of elements
is less than a given threshold (2 times the minimum distance in our case).
The basic idea consists of generating random trees
sharing same topological parameters. Section 2.2 shows
that a metric can be coded by a tree whose leaves (resp.
the logarithm of the largest degree) correspond to the
elements (resp. an approximation of the doubling dimension). From our deﬁnition, a cluster is represented
by leaves that have the same parent. Roughly speaking,
the “shape” of the tree characterizes the distribution of
distance scales of the metric.
Let us sketch Algorithm DDG ENERATE that returns
a metric space of given doubling dimension. Due to
space limitations, we only detail the ﬁrst phase, namely
the random tree generation, which is the most technical
part. It takes as input 3 parameters : the metric cardinality n, the cluster size k and a probability distribution
Π = (Π(i))i=0...2dd such that Π(2dd ) = Ω(1/n).
Algorithm DDG ENERATE works as follows : (1)
Build a random
√ tree of approximate size N (up to an additive factor N ) whose degree follows the distribution
of probability Π; (2) Extend leaves adding new nodes
so that all leaves are at the same height within the tree;
(3) Append k nodes to each leaf; (4) Assign weights to

the edges of the resulting tree T such that the weight between level i and i + 1 is 2i . (5) The metric X is deﬁned
by the set of leaves of T and the distance between two
elements of X corresponds to the distance between the
corresponding leaves within T .
Figure 4 illustrates steps 1, 2 and 3 of the DDG EN ERATE algorithm.

5 Experimental results
5.1

Execution time

This section presents experimental results about the
improvement of I-PACK ’s time complexity with respect
to existing MDS algorithms. Indeed, the theoretical upper bound on the time complexity of I-PACK is quasilinear when the doubling dimension and the aspect ratio of data can be bounded by constants in practice (see
Proposition 4). We compare to :
• GEM* algorithm is an adaptation of Frick’s Graph
Embedder [9] where the desired edge length parameter is scaled according to the dissimilarity
measure δuv . Its time complexity is O(n3 ).

Figure 4. Generation of clustered data. A
random tree of size N is created (white
nodes). Leaves are given height h (grey
nodes). k leaves are appended to existing
leaves. (black nodes).

Proposition 6 Algorithm DD GENERATE generates
metrics √of doubling dimension dd, with cardinality
n + O( n) and cluster size k 2dd in linear time.

Proceedings of the Information Visualization (IV’06)
0-7695-2602-0/06 $20.00 © 2006

IEEE

• Jourdan is a force-based MDS algorithm described
in [15]. Its time complexity is O(n log n).
A C++ implementation of each algorithm was run on
subsets of the SwissRoll data set on a Pentium IV CPU
2.8GHz. The execution time in seconds is reported in
Figure 5.

200
"GEM*"
"Chalmers03"
"Jourdan"
"I-PACK"

180
160
140
time in seconds

The ﬁrst phase is done using a Galton-Watson tree
[7] construction : according to distribution of probability Π, nodes draws at random their degree. More precisely, the random generation process is done level per
level. Each node u of the last level chooses i children
with probability Π(i). Whenever the last level has no
children and the cardinality of the current tree |T | belongs to the desired interval,
√ the resulting tree is kept.
N or the process stops with
As soon as |T
|
>
N
+
√
|T | < N − N , the current tree is canceled and a new
tree is built. Using this construction, all the trees with
the same degree distribution can be generated with an
equal probability. It would not be the case if we would
decide to truncate a tree as soon as its cardinality would
reach N . Moreover, tight analysis of this scheme shows
that the expected time of such construction is linear if the
degree expectation is less or equal√to 1. In order to get a
metric space of cardinality n+O( n), doubling dimenn
sion dd and cluster size k 2dd , we set N = kΠ(0)
and
dd
Π(2 ) = Ω(1/N ). This last tuning guarantees that the
largest degree is 2dd with constant probability. If such a
degree is not reached, a constant number of tree generation is sufﬁcient to get a tree with the desired properties.
Note also that cluster sizes can be tuned independently.

• Chalmers03 is a force-based MDS algorithm described in [19]. Its time complexity is O(n3/2 ).

120
100
80
60
40
20
0
0

500

1000

1500

2000

2500

3000

3500

size of data set

Figure 5. Execution time in seconds of
each algorithm on the SwissRoll data.
As shown in Figure 5, I-PACK , Chalmers03 and Jourdan are much faster than GEM*. On this particular data
set, I-PACK is about 3 times faster than Chalmers03’ and
Jourdan’s algorithms for n = 4000 and similar Stress
values.

4000

GEM* [9]
Chalmers03 [19]
Jourdan [15]
I-PACK

Stress
Aqua
0.06
0.21
0.20
0.34

Stress
QTFI
0.08
0.23
0.25
0.23

Stress
TREC
0.08
0.19
0.20
0.23

Table 2. Values of Stress for different MDS
algorithms on Aqua, QTFI and TREC. All
values of Stress are averaged over 10 runs
except for the I-PACK algorithm.

0.12
"GEM*"
"I-PACK"
"Chalmers03"
0.1

0.08

* 100%

Layout Algorithm

0.06

0.04

0.02

0
0

0.5

1

1.5

2

2.5

3

3.5

4

4.5

Stretch

5.2

Distortion measures

In this section, we compare our algorithm with the
MDS algorithms, presented in Section 5.1, according to
the quality of the placement. First, we use the Stress
function used in MDS theory to compare the layout
algorithms, then we resort to the distribution of the
Stretch to give a more detailed comparison.
In [19] and [15], the authors assess the quality of the
output of a force-based algorithm with the Stress of the
conﬁguration of elements in 2D. Intuitively, the lower
the Stress, the better the layout, as original distances between objects are well represented in 2D.
Stress values obtained with different MDS algorithms
are given in Table 2. The best result is obtained using the
GEM* algorithm, which produces a small Stress at each
run, the remaining MDS algorithms perform slightly
worse with a sensible variability from run to run. Our
method performs similarly to other MDS algorithm.
For a fraction of pairs of elements, the 2D distances
does not reﬂects their original distances. This is measured by the Stretch of the layout.
Figure 6 shows that the GEM* algorithm leads to a
more important proportion of pairs of elements with a
Stretch around 1, which means that the 2D distance between these pairs is representative of the original distance. The Chalmers03’ [19] distribution is less centered on the value 1 than GEM*’s (25.2% have Stretch
> 2 and 0.4% are under 0.5). With respect to the Stretch,
our algorithm leads to a comparable trend with slightly
less values above 2 than Chalmers03 [19] (21.9% have
Stretch > 2 and 3.8% are under 0.5). Jourdan’s algorithm [15] leads to a distribution of Stretch similar to
that of Chalmers03’ (not shown on Figure 6 for legibility).

Proceedings of the Information Visualization (IV’06)
0-7695-2602-0/06 $20.00 © 2006

IEEE

Figure 6. Histogram of the Stretch between
every pair of objects in data set QTFI.

5.3

Data set with large aspect ratio

Table 3 shows the Stress values of the embedding of
2
as described in Section 4.2. The coora 2D grid U15
dinates of the m2 points of the grid and the associated
distance have been used with each of the 4 algorithms
and the average Stress measures obtained on 10 runs of
each algorithm are reported in Table 3. It is clear that according to the Stress measure, I-PACK produces a better
embedding of the considered data set than the other algorithms.
Layout Algorithm
GEM* [9]
Chalmers03 [19]
Jourdan [15]
I-PACK

Stress
1.90
16.36
5.25
0.11

2
Table 3. Stress measure on the U15
Grid.

I-PACK performs well on data with large aspect ratio
because of the hierarchical sampling of data and the IPACK layout guarantees the separation property in the
2D embedding : for all pairs u, v ∈ Si , δuv > 2i and
|ρ(u)ρ(v)| > 2i using I-PACK . Indeed, u and v are
placed at distance at least 2i from each other in the 2D
embedding by the PACK function.

5

Layout Algorithm
GEM* [9]
Chalmers03 [19]
Jourdan [15]
I-PACK

n = 250
0.42
7.24
9.07
0.59

n = 500
0.60
2.21
3.69
0.99

n = 1000
0.52
4.94
8.94
0.78

Table 4. Stress values for the data set generated using Tn,20,Π .

5.4

Clustered data sets

In this section, we compare the Stress level of 2D embeddings obtained with different algorithms on synthetic
data sets with clusters designed by Algorithm DDG EN ERATE in Section 4.2.
Results are reported in Table 4. The probabilities
Π(i) for a node of the random tree to have a degree equal
to i were set to Π(i) ∝ i12 . 10 data sets were generated
for each value of parameter n with dd = 5, which leads
to Δ = 32, and k = 20.
GEM* and I-PACK always produce the best result in
all cases with a slight advantage for GEM*. However,
remind that GEM* also takes more time. I-PACK ’s performances can be explained by the fact that elements
u from a same cluster are covered by the same parent
of level 1, Pu1 , will be placed within a square area of
O( deg(Pu1 )), deg(Pu1 ) being the degree of the parent within the tree, thus reﬂecting their similarity in 2D.
Moreover, elements from different, but close, clusters
will be packed in the square associated with their nearest
common ancestor in T . As the nearest common ancestor of “close” clusters is likely to be close to them, they
will be packed within an area proportional to their distance. Note that this 2D layout is optimal, according to
the Stretch measure, in the case of Δ equidistant items.

5.5

Mental map persistence

In this section, we propose to compare the proposed
layout algorithm with the O(n3 ) MDS algorithm based
on GEM [9]. We show that I-PACK better preserves the
user’s mental map of data when adding new items to an
already displayed collection of items.
A human’s perception of the world is known as a
mental map. In the context of information visualization,
a mental map of abstract data can be proposed to the user
with a well-adapted layout algorithm and several visual
attributes. Here, we propose to give a representation of
data according to a measure of dissimilarity. In Section

Proceedings of the Information Visualization (IV’06)
0-7695-2602-0/06 $20.00 © 2006

IEEE

5.2, we assess the adequacy between the 2D distance
and the measure of distance. Let us now assume that
the used measure of dissimilarity provides a good mental map of the abstract data, that is, the user can easily
navigate in the mental map, then it would be desirable
to get the same mental map for the same collection with
a few more items. We call this feature the mental map
persistence (MMP).
In [3], the authors introduce the “layout distance
change function”, as a metric on the space of treemap
layouts, to quantify the change of treemap layouts as
data is updated. As treemap nodes are displayed asrectangles, the layout change function measures the distance between rectangles. Let r1 = (x1 , y1 , w1 , h1 ) and
r2 = (x2 , y2 , w2 , h2 ) be 2 rectangles deﬁned by the coordinates of their upper-left corner and by their width
and height, then, the distance between r1 and r2 is
(x1 − x2 )2 + (y1 − y2 )2 + (w1 − w2 )2 + (h1 − h2 )2
In order to assess the MMP of our method, we measure the average displacement of a reference set of
items, between consecutive runs of a layout algorithm
applied to a growing collection of items. The Average
Displacement (AD) measures the modiﬁcations of an
existing 2D-embedding when adding new items to the
collection.
Let n = |X|, let X0 ⊂ X1 ⊂ ... ⊂ Xk = X
be a series of √
subsets of X such that |X0 | = n2 and
|Xk+1 /Xk | = n, let ρXi denote the embedding of the
set Xi . We deﬁne AD as the average displacement of
the elements of X0 between ρXi and ρXi+1 for a given
layout algorithm as :
AD(ρXi ρXi+1 ) =

1
|X0 |

|ρXi (x), ρXi+1 (x)|
x∈X0

Before comparing consecutive layouts of increasing
data sets, the 2D embeddings ρXi , ρXi+1 , are ﬁrst scaled
so that the largest distance between points in each layout is equal to DMAX = 100. This is done to be able
to compare AD for different layout algorithms which
could produce outputs with different scales. Tables in
Figure 5 show the average value of AD for 5 different
series of subsets of X.
As shown in Table 5, the average values of AD obtained with the I-PACK algorithm are always less than
these associated with the GEM* algorithm. Therefore,
our algorithm is less sensitive to the insertion of new
items than this MDS algorithm. Moreover, for the same
set of elements, several runs of our algorithm produces
the same layout (AD = 0), whereas the GEM* MDS

Trial
1
2
3
4
5

GEM* I-PACK
33.70
10.22
40.39
12.21
36.76
10.37
34.63
5.90
36.47
14.31
a) n = 166

Trial
1
2
3
4
5

GEM* I-PACK
34.01
7.84
35.42
9.72
36.31
7.84
35.62
6.73
33.33
8.20
b) n = 394

collection of items according to δ. Figure 8b shows a
group of different pictures at level S0 which share common content.

Table 5. Average value of AD on each of
5 random series. a) Result for the Aqua
data. b) Result for the QTFI data.
a)
produces different layouts (mean AD = 30.23 for 5 runs
on the same set of items).
The instability of GEM can be easily explained : the
addition of a single item can disturb the fragile equilibrium of the force model and GEM will converge to
a quite different equilibrium. I-PACK wastes a bit of
area in order to guarantee the separation property. But,
it turns out that this drawback becomes an advantage for
the mental map persistence as new items can be placed
without changing the width of their bounding squares.

6 Application to the visualization of images collections
In this section, we use I-PACK to organise large collections of images according to their content’s similarity.
We developed I-PACK as a plug-in in the Tulip framework [2] as it provides efﬁcient data structures for graph
manipulation and a 3D rendering of graphs with millions
of elements. For the construction of T , we used either
a personal implementation of the Deformable Spanner
[11] or the Cover Tree implementation available on John
Langford’s homepage [4].
With our implementation and the Cover Tree preprocessing, we are able to display the 4000 key-frames of
the TREC data set. Figure 7a shows screen shots of the
obtained display. The zoomed-out view shows the inﬂuence of the packing function on the ﬁnal layout. The
other view shows how the layout helps to identify groups
of similar key-frames according to the used metric : here
the L2-norm on the MPEG7 Color Layout Descriptor
was used.
Figure 8 presents screen-shots of the Faces data set.
Figure 8a. shows that it is also possible to take advantage
of the hierarchical sampling on the data set to show only
one level of T (elements of S5 ). The separation property
ensure to display representative samples of the whole

Proceedings of the Information Visualization (IV’06)
0-7695-2602-0/06 $20.00 © 2006

IEEE

b)

Figure 8. Visualisation of the pictures associated with the Faces data. a) Images of
level S5 . b) Details of an area with pictures
of S0 that share common content (pose +
illumination).

7 Conclusion and future work
We proposed a multi-level 2D-embedding algorithm
which is based on a deterministic and multi-scale sampling of data. This approach allows :
• a fast, deterministic, low distortion 2D-embedding
of data, that takes into account the doubling dimension of the data set,
• the persistence of the user’s mental map whenever
some insertions of new items occur.
Moreover, our deterministic 2D-embedding could be
used as a good starting point for force-based MDS algorithms. We suspect that it will speed up the convergence
toward an equilibrium.

References
[1] P. Assouad. Plongements lipschitziens dans r n . Bull.
Soc. Math. France, 111(4):429–448, 1983.
[2] D. Auber. Graph Drawing Software, chapter Tulip - A
Huge Graph Visualization Framework. Verlag, 2003.
[3] B. B. Bederson, B. Shneiderman, and M. Wattenberg.
Ordered and quantum treemaps: Making effective use
of 2d space to display hierarchies. ACM Trans. Graph.,
21(4):833–854, 2002.
[4] A. Beygelzimer, S. Kakade, and J. Langford. Cover trees
for nearest neighbors. Preprint, 2004.

a)

b)

Figure 7. Visualisation of the collection of key-frames associated with the TREC collection. a)
Zoomed-out view. b) Details of an area with 2 groups of key-frames that have similar low-level
features.

[5] M. Chalmers. A linear iteration time layout algorithm
for visualising high-dimensional data. In IEEE Symposium on Information Visualization, pages 127–132,
1996.
[6] L. Cieplinski, M. Kim, J. Ohm, M. Pickering, and A. Yamada. Text of ISO/IEC 15938-3/FCD Information technology - multimedia content description interface - Part
3 Visual, March 2001.
[7] M. Drmota and B. Gittenberger. On the proﬁle of
random trees. Random Structures and Algorithms,
10(4):421–451, 1997.
[8] P. Eades. A heuristic for graph drawing. Congressus
Numerantium, 42:149–160, 1984.
[9] A. Frick, A. Ludwig, and H. Mehldau. A fast adaptive
layout algorithm for undirected graphs. In R. Tamassia
and I. G. Tollis, editors, Proc. DIMACS Int. Work. Graph
Drawing, GD, pages 388–403, Berlin, Germany, 1994.
Springer-Verlag.
[10] T. M. J. Fruchterman and E. M. Reingold. Graph drawing by force-directed placement. Software - Practice and
Experience, 21(11):1129–1164, 1991.
[11] J. Gao, L. J. Guibas, and A. Nguyen. Deformable spanners and applications. In SCG ’04, pages 190–199, New
York, NY, USA, 2004. ACM Press.
[12] S. Har-Peled and M. Mendel. Fast construction of nets in
low dimensional metrics, and their applications. SIAM
J.COMPUT., 35:1148, 2006.
[13] J. Heinonen. Lectures on analysis on metric spaces.
Springer Verlag, 2001.
[14] E. Huang. Exploiting the intrinsic dimensionality of data
for nearest neighbor search. Master’s thesis, Princeton,
2005.
[15] F. Jourdan and G. Melanc¸on. Multiscale hybrid mds. In
8th IEEE international conference on Information Visualisation, pages 388–393, 2004.

Proceedings of the Information Visualization (IV’06)
0-7695-2602-0/06 $20.00 © 2006

IEEE

[16] D. R. Karger and M. Ruhl. Finding nearest neighbors
in growth-restricted metrics. In STOC ’02: Proceedings
of the thiry-fourth annual ACM symposium on Theory of
computing, pages 741–750, New York, NY, USA, 2002.
ACM Press.
[17] R. Krauthgamer and J. R. Lee. Navigating nets: simple
algorithms for proximity search. In SODA ’04: Proceedings of the ﬁfteenth annual ACM-SIAM symposium on
Discrete algorithms, pages 798–807, Philadelphia, PA,
USA, 2004. Society for Industrial and Applied Mathematics.
[18] J. Moon and L. Moser. Some packing and covering theorems. Colloquium Mathematicum, 17:103–110, 1967.
[19] A. Morrison, G. Ross, and M. Chalmers. Fast multidimensional scaling through sampling, springs and interpolation. Information Visualization, 2(1):68–77, 2003.
[20] NIST. Trec video retrieval evaluation. Internet address: www-nlpir.nist.gov/projects/trecvid/, (last visited
20/03/2005), 2005.
[21] J. B. Tenenbaum, V. D. Sialva, and J. C. Langford.
Isomap homepage.
Internet address:
http://isomap.stanford.edu/, (last visited 20/03/2005),
2005.

