Telepresence Across Networks:
A Combined Deadband and Prediction Approach
Michael F. Zaeh 1, Stella Clarke1, Peter Hinterseer2, Eckehard Steinbach2
1. Institute for Machine Tools and Industrial Management 2. Institute of Communication Networks
Technische Universitaet Muenchen, Germany
{stella.clarke@iwb.tum.de, michael.zaeh@iwb.tum.de, ph@tum.de, eckehard.steinbach@tum.de}
Abstract
Executing
telepresence
operations
across
networks poses a number of challenges. In particular,
the transfer of certain data types requires high
sampling rates, such as haptic and velocity data. This
paper presents a two-step approach which reduces the
total amount of data sent across a network, while
attempting to reconstruct the original data series. The
first step utilises a deadband approach to eliminate the
transfer of redundant data. In this sense, redundant
refers to the fact that the data will be undetectable or
of no consequence at the receiving end. The second
step is a prediction implementation to best reconstruct
the reduced series to its original form. This combined
deadband and prediction approach is applied to
velocity data extracted from a telepresence scenario,
resulting in an 86% reduction in the amount of data
transferred, and good data reconstruction properties.

1. Introduction
Telepresence systems typically consist of the three
components: (1) an operator, (2) a teleoperator, and (3)
a communication link between the two.
Within the communication layer, the transferral of
data at high frequencies can be a problem. Because of
high sampling rates and to keep end-to-end delay as
small as possible, packets containing haptic data are
sent across the communication network between the
operator and teleoperator at rates of up to 1000Hz.
This is normally hard to maintain if the Internet should
be used as the communication infrastructure. In order
to reduce the amount of data packets communicated,
the psychophysically motivated deadband approach
presented in [1] is used in this work. The deadband
approach is based on the fact that human haptic
perception is limited. If a haptic stimulus such as force
or velocity does not change by more than a certain
perception threshold, the change cannot be sensed. The

Proceedings of the Information Visualization (IV’06)
0-7695-2602-0/06 $20.00 © 2006

IEEE

perception threshold itself linearly depends on the
magnitude of the initial stimulus (Weber’s Law). The
resulting signal after deadband application is a step
function with variable step size depending on signal
magnitude.
In previous publications on the deadband
approach, these steps were fed directly to the operator
and therefore introduced distortions into the haptic
signal. This work aims to reduce the amount of
distortion introduced by the deadband approach
through the use of prediction techniques to reconstruct
the signal at the receiver. The result is an increased
transparency of the whole system and a possible
further reduction in data packets through enabling the
use of larger deadbands.

2. Research Goals
This research aims to demonstrate a combination
of the deadband approach and prediction to assist in
the transfer of data requiring high sample rates across
networks.
Figure 1 illustrates the process of combining the
deadband approach with prediction. Each of the three
illustrated curves represents typical telepresence data
against time. Here, “telepresence data” could refer to
force feedback data or velocity data. The topmost
curve shows an original data series, where each of the
black circles is a sampled data value.
The middle data series shows the result of
implementing the deadband approach.
The
dependence of the step size of the deadband on the
absolute magnitude of the sample value can be seen.
This is because psychophysics explains that the
difference threshold (the amount of change in a
stimulus a human is able to discriminate) depends on
the magnitude of the stimulus itself (Weber’s Law).
The gray circles represent sample values which
are not sent across the communication network, there-

Signal Amplitude

Deadband
Time

Prediction
Time

Time

approaches [9] [10]. The issue of control over delayed
networks has been widely researched.
Popular
approaches include the Wave Variables theory [11]
[12] and the Time Domain Passivity approach [13].
A recent research topic in the field of virtual
reality is the prediction of head and hand movements
to compensate for computational delays.
Here,
alternatives to traditional filter approaches have shown
improved performances. For example, smoothing
algorithms were shown to produce similar results to
the Kalman filter while showing significantly faster
execution times [14].

Figure 1 Combined Deadband and Prediction

Figure 2 Combined Deadband & Prediction
Implementation
The thin black line between the operator and
teleoperator reflects the reduced amount of data sent
across the network.

3. Existing Work
The problem of time delays in manual control has
been known for many years. There exist numerous
studies which confirm the negative influence of delay
on teleoperation [2] [3] [4].
The deadband approach used in this work is based
on deadband transmission in networked control
systems presented in [5]. It is covered together with
some extensions in [1], [6], [7], and [8]. The prediction
concept in [7] differs significantly from the approach
in this work because there a very simple model based
prediction is used as the reference of the deadband and
requires two synchronized models on both sender and
receiver side whereas in this work signal
reconstruction is done on the receiver side only and
requires no change to the deadband scheme itself.
Using prediction to overcome network delays in
telepresence scenarios has also been researched. Most
studies have used the Kalman Filter or filter

Proceedings of the Information Visualization (IV’06)
0-7695-2602-0/06 $20.00 © 2006

IEEE

4. Prediction Algorithm
4.1. Algorithm Selection
In general, prediction algorithms use past data to
generate a function or a model of a system. This
system is then used to approximate the system state at
a future point in time. For prediction in telepresence
applications, two highly important characteristics are
(1) prediction accuracy, and (2) calculation time. The
first characteristic is clear, and the second is also very
important. The time it takes the algorithm to generate
a prediction is essentially time added to the initial
network delay.
Figure 3 illustrates an expected relationship
between prediction accuracy and calculation time.
Simple routines, such as linear interpolation are
extremely fast, but relatively inaccurate. At the other
extreme, complex machine learning algorithms are
expected to be able to generate highly accurate
predictions, however at the cost of calculation time.
For example, although slow, a high dimensional neural
network could be capable of learning many complex
mechanisms behind input motions. Filter approaches,
such as the Kalman filter, lie between the two
extremes, perhaps somewhat higher than illustrated in
Figure 3. The optimal zone represents algorithms with
high accuracies and low calculation times.
Prediction Accuracy

by decreasing the total amount of sent data. At the
receiving end of the network, a prediction algorithm is
implemented in an attempt to restore the data series to
its original form, as shown in the bottommost series.
Figure 2 further illustrates this combined deadband and
prediction approach.

Optimal
zone

Machine Learning
Algorithms

Kalman Filter

Simple
Routines

Calculation Time

Figure 3 Accuracy and Time Trade-off

As mentioned in Section 3, the “double
exponential smoothing” (DESP) simple routine has
been shown to produce highly accurate predictions
despite small calculation times. For virtual reality
applications, LaViola states that “DESP is
approximately 135 times faster than Kalman and
extended Kalman filter-based predictors with roughly
the same accuracy” [14]. Preliminary experiments have
been carried out on telepresence data from a
PHANToM haptic input device [15]. In this study,
DESP produced higher accuracies than a DD1 Kalman
Filter and two other machine learning algorithms,
despite a lower calculation time. Considering this
existing knowledge, the DESP algorithm is
implemented in this research. The next section briefly
explains DESP.

4.2. Double Exponential Smoothing (DESP)
Like most prediction algorithms, DESP utilises
past observations to generate future estimations. More
specifically, DESP assigns exponentially decreasing
weights to older observations.
Consider a series of observations, y1, y2 … yn,
taking place over time t1, t2 … tn. Exponential
smoothing requires the definition of a so-called
“smoothed observation” St. For a given time t, the
smoothed observation St is calculated by:

S t = αy t −1 + (1 − α )S t −1

= αyt −1 + α (1 − α ) yt −2 + (1 − α ) S t −2

Although simple, single exponential smoothing
has a poor ability to follow trends. This shortcoming is
overcome by smoothing the smoothed observation
once again. Since smoothing occurs twice, this

0-7695-2602-0/06 $20.00 © 2006

IEEE

S t = αy t + (1 − α )(S t −1 + bt −1 )

(3)

bt = γ (S t − S t −1 ) + (1 − γ )bt −1

Finding optimal values for α and γ is more
difficult than optimising α alone. A possible solution
is to use non-linear optimisation techniques such as the
Marquardt Algorithm [16].

5. Experimental Procedure
This section explains the adopted experimental
procedure. Regarding the deadband, a generic value of
10% of the amplitude of the current offset from the
allocated data origin was used [1].

5.1. Telepresence Scenario for Data Extraction
As shown in Figure 4, the employed telepresence
scenario consisted of a virtual teleoperator controlled
by a HapticMaster input device. The HapticMASTER
is a 3 degree of freedom, force-controlled haptic
interface [17].

(1)

where 0 < α = 1
This is the forecasting equation for single
exponential smoothing, where α is a predetermined socalled “smoothing constant”. This smoothing constant
represents the extent to which past (older) observations
influence the forecast.
Even at this point, the
algorithmic simplicity and fast nature of exponential
smoothing can be seen.
The smoothing process begins by setting the first
smoothed observation, S2, to y1. There exists no S1, the
first smoothed observation is S2. Thereafter, the
following smoothed values are calculated by equation
(1).
The exponential nature of this forecasting
algorithm can be seen by substituting for St-1 in
equation (1), which yields:
St = αyt −1 + (1 − α )[αyt −2 + (1 − α )St −2 ] =
(2)
2

Proceedings of the Information Visualization (IV’06)

method is known as double exponential smoothing
(DESP).
Upon introducing a second smoothing constant γ,
the two DESP equations are given by:

Virtual
Teleoperator
Haptic
Master

Operator

Figure 4 Technical Setup
The three axes of the HapticMaster were used to
translate the three virtual linear axes. These axes
enable the translation of an assembly platform in three
dimensions. However, for the sake of simplicity,
velocity data was only extracted from the x-axis for the
deadband and prediction implementations.
The
sampling rate was 100 Hz.

5.2. Implementing and Optimising the DESP
For one-dimensional data, DESP can be
implemented in two possible ways. In Figure 5, the
lower black dots indicate deadband data. The gray
dots represent data predicted with DESP.

Signal

Between alpha values of 0.2 and 1, there appears
to be no large difference in performance in terms of
RMSE. However, as shown in Figure 7, RMSE
shouldn’t be the only measurement of success.

8 9 10
5 6 7
1 2 3 4

Time

Figure 5 DESP Implementation

α = 0.2

Points 9 and 10 can be predicted by either
applying DESP to the deadband data (black dots), or
by applying DESP to the already predicted data (gray
dots). The optimal choice is not intuitively obvious.
The first point within a deadband (e.g. point 1) is more
correct than any predicted value (e.g. point 5).
However, further along the deadband, the predicted
value (e.g. point 8) could be more accurate than the
corresponding value in the deadband (e.g. point 4).
This research aims to detemine the method with the
least overall prediction error, and to optimise this
method according to HapticMaster velocity data.

6. Results
One thousand data points were extracted from the
scenario described in Section 5.1. Only the x-axis
velocities were considered in this study.

6.1. Deadband
Of the 1000 extracted velocity values, 862 turned
out to be classified within a deadband. This indicates
an 86.2% reduction in the amount of data sent across
the network.

6.2. DESP Implementation

RMSE (x 10-3 ms-1)

The results of the DESP comparison explained in
Figure 5 are shown in Figure 6.
1.4
1.3

RMSE Method 1
RMSE Method 2

1.2
1.1
1.0
0.9
0.8
0.7
0.6
0

0.2

0.4

0.6

0.8

1

1.2

alpha

Figure 6 Comparison of alpha values
“RMSE Method 1” refers to the process of
applying DESP to deadband data, and “RMSE Method
2” applies DESP to the already predicted data. Method
1 performs slightly better.

Proceedings of the Information Visualization (IV’06)
0-7695-2602-0/06 $20.00 © 2006

IEEE

α = 0.8

Figure 7 Comparison of alpha values
The dotted line in the right graph shows the
prediction for an alpha value of 0.8. Although this
series has a small RMSE value, the prediction is not
smooth and continually oscillates around the desired
prediction line. In the left graph, an alpha value of 0.2
shows a better or smoother performance, although not
necessarily a smaller RMSE.
The smoothness of each prediction was judged by
manually adjusting the alpha values and judging the
resulting predictions by eye. An alpha value of 0.2
showed the best smoothness characteristics. Similarly,
a gamma value of 0.1 demonstrated a good trade-off
between RMSE and smoothness across all alpha
values.

6.3. DESP Optimisation
Implementing a constant alpha value of 0.2
showed good performances in regions where deadband
had been implemented. However, in other regions of
continuous data which were not transformed by the
deadband process, the performance was poor, as shown
in Figure 8. The prediction algorithm performed well
on the deadband data towards the right. However, for
the smoother data between 1.2 and 1.3 on the time
axis, the performance was poor. The can be improved
upon by increasing the smoothing constant alpha to a
higher value (e.g. 0.9). However, the higher alpha
values negatively influence the deadband data.
Therefore a “dynamic smoothing constant” can be
adopted, in which the alpha value is increased (e.g. to
0.9) when it is clear that the current data is not
deadband data. The result is the improvement shown
in Figure 9. However, the best solution in this scenario
is simply to keep the original data in regions where
deadband hasn’t been implemented (Figure 10). Since
the data clearly hasn’t undergone any deadband
transformations, it makes the most sense to not apply
any prediction algorithm at all. Non-deadband data is
assumed when neither of the last three received data
points are equal. Otherwise, the DESP algorithm with
an alpha value of 0.2 and a gamma value of 0.1 is
executed.

Velocity X (ms-1)

0.025
Original Data
After Deadband
After Prediction

0.02
0.015
0.01
0.005
0
1.1

1.2

1.3

1.4

1.5

1.6

-0.005

1.7

Time (s)

-0.01

Velocity X (ms-1)

8

0.025
Original Data
After Deadband
After Prediction

0.02
0.015
0.01
0.005
0

1.1

1.2

1.3

1.4

1.5

1.6

-0.005

1.7

Time (s)

-0.01

Velocity X (ms-1)

9

0.025
Original Data
After Deadband
After Prediction

0.02
0.015
0.01
0.005
0
1.1

1.2

1.3

1.4

1.5

1.6

1.7

-0.005

Time (s)
-0.01

0

Proceedings of the Information Visualization (IV’06)
0-7695-2602-0/06 $20.00 © 2006

IEEE

k

For more complex or highly varying data, a
combination of the approaches in Figure 9 and Figure 10
is likely to produce improved results. The prediction
parameters or strategy would be adjusted according to
the behaviour of the last few received data points.
Figure 11 shows the decreasing RMSE for each of
the above outlined approaches.

[3]

[4]
[5]

0.0012

[6]

0.001

RMSE

0.0008
0.0006

[7]

0.0004
0.0002

[8]

0

Constant Alpha

Dynamic Alpha

Original Data
(conditional)

ES
[9]

7. Conclusion and Future Work
This paper presented a two-step method for the
transferral of haptic data at high sampling rates across
networks such as the Internet. Combining the deadband
approach with a fast, configurable and accurate
prediction algorithm enables a significant reduction in
the amount of data sent across the network, while
helping to preserve the original data structure.
Future work involves looking at the ability to
increase the magnitude of the deadband through the
implementation of a good reconstructing prediction
algorithm such as DESP. The extracted data in this
research involved no hard contacts. The ability to cope
with delayed networks in scenarios with hard and soft
contacts is a current research topic [18].

[10]

[11]

[12]

[13]

[14]

Acknowledgements
This work was supported by the German Research
Foundation (DFG) within the Collaborative Research
Centre SFB453 on “High-Fidelity Telepresence and
Teleaction”.

[15]

[16]

References
[1]

[2]

P. Hinterseer, E. Steinbach, S. Hirche, and M. Buss. A
novel,
psychophysically
motivated
transmission
approach for haptic data streams in telepresence and
teleaction systems. IEEE Conf. on Acoustics, Speech,
and Signal Processing, PA, USA, March 2005.
W.R. Ferrell. Remote manipulation with transmission
delay. IEEE Trans. On Human Factors in Electronics,
HFES 6(1), 1965.

Proceedings of the Information Visualization (IV’06)
0-7695-2602-0/06 $20.00 © 2006

IEEE

[17]
[18]

K. Jeffay, M. Hudson, and Parris. Beyond Audio and
Video: Multimedia Networking Support for Distributed,
Immersive Virtual Environments. Proceedings of
Euromicro, pp. 300-307, 2001.
R.H.Y. So, M.J. Griffin. Manual control with delays: A
bibliography. Computer. Graphics, 28, pp.149-154, 1991.
J. R. Moyne, P. G. Otanez, and D. M. Tilbury. Using
deadbands to reduce communication in networked
control systems. American Control Conference,
Anchorage, Alaska, USA, May 2002.
P. Hinterseer, E. Steinbach and S. Chaudhuri. Model
based data compression for 3D virtual haptic
teleinteraction. IEEE Int. Conf. on Consumer
Electronics, Las Vegas, NV, USA, January 2006.
P. Hinterseer, E. Steinbach. A Psychophysically
Motivated Compression Approach for 3D Haptic Data,
Haptics Symposium, Arlington, VA, USA, March 2006.
P. Hinterseer, E. Steinbach and S. Chaudhuri.
Perception-Based Compression of Haptic Data Streams
Using Kalman Filters, IEEE International Conference on
Acoustics, Speech, and Signal Processing, Philadelphia,
Toulouse, France, May 2006.
G. Hirzinger, J. Heindl, and K. Landzettel. Predictive and
knowledgebased telerobotic control concepts, in Proc.
IEEE Int. Conf. on Robotics and Automation, pp. 1768—
1777, 1989.
J. Baldwin, A. Basu, and H. Zhang. Panoramic Video
with Predictive Windows for Telepresence Applications,
Proc. IEEE International Conference on Robotics and
Automation, Detroit, U.S.A., May 10-15, 1999.
J.A. Esclusa, C. Preusche, and G. Hirzinger. Wave
Variables-based Bilateral Control with a Time Delay
Model for Space Robot Applications. Robotik 2004.
G. Niemeyer and J.E. Slotine. Towards Force-Reflecting
Teleoperation Over the Internet. In Proceedings of the
1998 IEEE International Conference on Robotics and
Automation, pp. 1909–1915, Belgium, 1998.
J. Ryu, D. Kwon and B. Hannaford. Stable Teleoperation
with Time Domain Passivity Control. In IEEE Intl.
Conference on Robotics and Automation, ICRA, pp.
3260–65, Washington DC, USA, May 2002.
J. LaViola. Double Exponential Smoothing: An
Alternative to Kalman Filter-Based Predictive Tracking,
In the Proceedings of Immersive Projection Technology
and Virtual Environments 2003, ACM Press, pp. 199206, 2003.
S. Clarke, G. Schillhuber, M.F. Zaeh, H. Ulbrich.
Combined Movement and Force Prediction During
Delayed Telepresence. Submitted to Presence, 2006.
M. Lourakis. A Brief Description of the LevenbergMarquardt Algorithm Implemented by Levmar.
url: http://www.ics.forth.gr/lourakis/levmar/levmar.pdf.
2005.
HapticMaster, FCS Robotics. url: http://www.fcscs.com/robotics/products/hapticmaster
A. Golle, H. Ulbrich. Contact Models for Real-Time
Simulation in Telepresence and Teleaction Applications,
8th German-Polish Workshop on "Dynamical Problems
in Mechanical Systems" Schochtitz near Bautzen,
Saxony August 31 - September 5, 2003.

