Visualizing Distributions and Classification Accuracy
Dennis P. Groth
Indiana University School of Informatics
Bloomington, IN 47408, USA.
Email: dgroth@indiana.edu

Abstract
Data mining is the search for novel, actionable information within data. It is important to note that the
number of records in the data being analyzed is only
one (and perhaps a small) factor in determining the
complexity of a given data mining technique. Most
complexity in data mining arises from the distribution of values contained in the data - not the number of records. In this paper we utilize straightforward histogram-based visualizations to gain insight
into how the performance of a well-studied data mining technique, the naive-Bayes classifier, performs
under various discretization schemes for both continuous and discrete values. The resulting visualization system provides users with a tool that describes
the underlying model of the data used by the classifier. Exploratory visualizations of the distributions
of training data can be selected based on expert domain knowledge and then combined to apply to the
test data.

1 Introduction
The goal of visualization is to gain insight into
phenomena, relationships between data elements,
or properties of data that would not otherwise be
learned through other, non-visual methods. Data
mining is the search for novel information within
data that would not otherwise be learned. These often stated definitions imply a close relationship between visualization and data mining - a relationship
that we seek to explore in this project.
There are many data mining techniques that can
be used, including association rules, clustering and
classification [5]. Each has been shown to be effective agains certain types of data. However, one
challenge for many techniques occurs when the data

Proceedings of the Information Visualization (IV’06)
0-7695-2602-0/06 $20.00 © 2006

IEEE

contains continuous values, which inevitably results
in either intractable running times, or the development of models that overfit the data.
A common step in the KDD process is referred to as data preparation [10].
This preprocessing stage might include data cleaning,
the removal of spurious values, or discretization. Discretizing, sometimes referred to as “binning”, is a process where continuous values are
grouped into bins characterized by ranges of values.
For example, the values
can be grouped into two disand
crete bins:
. The binning can be deand
.
scribed as
The challenge with binning is to decide where the
boundaries between the bins are created. Several
algorithmic strategies may be employed. In equalwidth binning, the range is divided into bins, where
of the range of values. In
each bin represent
equal-height binning, the range is divided into bins,
where each bin contains roughly the same number
of elements. Variance-based binning seeks to create
bins where the variance between the values of the elements in each bin is minimized.
Classification is a data mining technique that seeks
to assign data records to an appropriate class. For
example, if the input data contains personal information, such as salary, debt, years employed, etc.,
the classification problem could be to assign loan
applicants into risk classes: “High”, “Medium”, or
“Low”.
In this project we focus on how visualizations can
be used to both demonstrate and explain how distributions of data values effect the accuracy of classification. We utilize histograms to illustrate the distri-

butions and, by iterating over different discretization
schemes we show how the naive Bayes classifier performs under each distribution. Additional visualization techniques are employed, including confusion
matrices, and a new glyph-based technique, are used
to illustrate the accuracy of the resulting classifiers.
The goal is to use simple 2D visualization techniques
to provide an understandable model of the underlying classifier to a domain expert.
Excellent overviews of the theories behind classification are available, most notably Duda, et al [11]
and Devroye, et al [8]. The classic book by Mitchell
[9] provides background information on machine
learning algorithms. Many general overviews of data
mining provide insight into how the techniques are
employed [6, 15]. A different approach to visualizing classifier accuracy is to use receiver operating
characteristic (ROC) curves [13]. The main difference between ROC curves and our approach is that
the standard ROC curve is limited to two measures,
while our glyph-based approach shows four.
Visualization approaches for data mining are frequently reported [14]. Most relevant to our project is
work by Ankerst, et al, in which interactive visualizations are used to improve the accuracy of decision
tree classifiers [1, 2]. In particular, these projects
point to opportunities provided by integrating human
processing into the KDD process [12]. A similar
approach based on support vector machines is described in [4].
The remainder of this paper is structured as follows. In Section 2 we provide the definitions and
notations that are used in the remainder of the paper. Section 3 provides an overview of the classification problem and an example classifier that is commonly used - the naive Bayes classifier. Section 4
describes our system, and how we have used visualizations to gain insight into how a classifier is constructed. Lastly, we conclude with a discussion of
what we learned most from the project, as well as a
brief list of future work in Section 5.

2 Definitions
Let be a relation schema and r be an instance of
. Associated with
is a finite set of attributes
. For each attribute
we associate a
, called the domain
set of possible values dom

Proceedings of the Information Visualization (IV’06)
0-7695-2602-0/06 $20.00 © 2006

IEEE

of

. When considering an instance r we define
, the active domain of , to be the set of
is
values existing in r. Note that, while
may be infinite. A tuple of is a
finite, dom
. Define dom
function dom
dom
dom
.
Let
be a set of class labels. The
classification problem is to construct a classifier
that maps each tuple to a class label . We will
to signify a classifier that is
use the notation
constructed from the single attribute .
Binning of attribute values is described by a
histogram for the attribute, denoted by
. Each bin of the histogram is a tuple
, where
is
a vector of frequencies for each of the known class
a possible
labels. For example, if
binning of the data shown in Table 1 is shown in Table 2.
1
2
3
4

2
3
4
5

3
4
5
6

Table 1: Example table of values.

Table 2: Example binning of values from the data in
Table 1.

The task of constructing a classifier employs two
steps. In the first step a training dataset is used. The
training dataset contains tuples for which the class
labels are known. In the second step the constructed
classifier is used to predict the class label for the tuples in the testing dataset. The labels are also known
for the testing dataset, which provides a method for
determining the accuracy of the classifier.
We distinguish the output of the classifier into the
) True Positive; (
) False
following cases: (
) False Negative; (
) True Negative.
Positive; (

Determining the frequency of each of these cases is
easily done during the construction of the classifier
These frequencies are shown in the confusion matrix [7] depicted in Figure 1. We use extensive use
of these visualization to show levels of detail for the
classifier accuracy. For example, a classifier may be
extremely good at classifying one class, but not another.

to 1, and bad when 0. In our initial tests we have
used the simple accuracy calculation as the value to
be maximized.

3 Classification

Classification techniques are used to develop models that can be used to predict unknown values. Forover
mally, given an tuple of values
, the clasa corresponding schema
sification problem is to assign the tuple to a known
class value . The technique employs a two-phase
process that in the first step uses a training set of data
with known classes to develop a classifier. In the second step, the classifier is tested against a different set
of data, also with known classes, to determine the
overall accuracy. If the accuracy is determined to
be acceptable, then the classifier is used against data
without known classes in order to predict the most
likely class.
Classification is referred to as a “supervised”
learning process due to the known set of classes and
the a priori knowledge of data samples associated
with the known classes. Another data mining technique, clustering, has many similarities to classification, with the main difference being that the classes
Figure 1: Confusion matrix depicting the underlying are unknown prior to processing.
be the probablity of hypothesis is
Let
frequencies of classifier predictions for class A.
be the probability of , and
true given data ,
be the probability of data . Bayes theorem is
In this project we use several statistics to view defined by
. Bayes
classifier accuracy. Table 3 shows the statistics and theorem allows us to calculate a predicted hypothesis
the associated calculations.
by determining the maximum likelihood over all posterm is a constant and
sible hypotheses. The
Statistic
Calculation
has no effect on the order of the probability calulaAccuracy
tions and is consequently ignored in calculating the
Sensitivity
maximum likelihood.
Specificity
Pos. Predictive Value
3.1 Naive Bayes Classifiers
Neg. Predictive Value
We use the so-called naive Bayes Classifier techPrecision
nique for this project. This techniques makes the
Recall
assumption that the attribute values are conditionTable 3: Statistics used to describe classifier accu- ally independent of the predicted class. Let
be a set of known class labels. Using
racy.
Bayes theorem the maximum likelihood calculation
. The naive Bayes assumpis
Each of the statistics has the property that a clas- tion lets us use each attribute value independently:
. Although this notasifier is considered good when the statistic is equal

Proceedings of the Information Visualization (IV’06)
0-7695-2602-0/06 $20.00 © 2006

IEEE

tion uses discrete attribute values we can use attribute
value ranges to support continuous values. For exfor
ample,
values and . For space considerations we omit
the details of algorithms for implementing the naive
Bayes technique.

4 Visualizing Classifiers
We use the naive Bayes classifier technique in our
approach to independently construct a classifier for
each attribute in the input data. For input we have a
delimited set of data used as the training set, a set of
data to be used as the testing dataset, and parameters
chosen by the user to influence how data values are
binned. A separate parameter is used to guide the
algorithm to select classifiers based on minimizing
or maximizing accuracy, or variance of the classifier
statistics described in Section 2.
A very brief sketch of our algorithm is shown in
Figure 2. Input is a training set of data , a testing
set of data , a set of class labels and a parameter that defines the maximum number of buckets
per histogram. Line 3 of the algorithm calls a procedure that constructs different histograms for the
procedure
input attribute. The
returns the histogram for which the “best” classification accuracy is achieved. Our implementation of
procedure takes as input a testing
the
dataset, a set of histograms and a set of class labels.
procedure uses the
Note that the
procedure, but restricts the histograms
proto be for only a single attribute. The
cedure returns a new dataset augmented by the predicted class labels for each tuple.
C LASSIFY
1
2 for
3 do
4
5 return
Figure 2: Algorithm sketch

Proceedings of the Information Visualization (IV’06)
0-7695-2602-0/06 $20.00 © 2006

IEEE

4.1 Visualizing Distributions
Histogram visualizations are used to depict how class
values are distributed through the range of data values. Within each bin, the total number of values in
the bin is shown in the background (gray bar), and
the relative frequency of each class value contained
in the bin is shown in a different, user-selectable
color. For this example, we chose green to represent
“benign” and red to represent “malignant”.
Our system iterates over different numbers of bins
for each attribute until the optimal distribution with
respect to classifier accuracy is determined. Figures
and 3 show the output of the system for equal-width
binning. The data depicted in the samples was downloaded from the UCI machine learning repository [3]
Because certain data values prohibit exactly equalheight bins, our algorithm adjusts the bin size to get
as close to equal-height as possible.

Figure 3: Final distributions for Breast Cancer Data
- equal width binning. Red is the malignant class and
green is the benign class.
These visualizations are used to provide a user
with an explanation for how the classifier works.
Colors are used to identify each of the class labels
and are used consistently throughout the application.
For example, in the breast cancer data red is used to
condition, while green
identify the
.
is used for

4.2 Visualizing Accuracy
We use two different visualizations to represent classifier statistics. The first is a confusion matrix, which
shows the distribution of predicted class values for
the complete dataset. The matrix configuration allows a user to quickly identify fine details of the classifier. For example, as shown in Figure 4, cells along
the diagonal represent true positives, cells in a row
not on the diagonal are false positives, and cells in a
column not on the diagonal are false negatives.

Figure 5: Classifier statistics visualization. Each
class label has a separate glyph generated.
provides overview of the class distributions and classifier statistics within each attribute, and then overall
classifier statistics for the testing dataset.

Figure 4: Confusion matrix visualization.
The second visualization technique displays the 4
classifier statistics we compute. This technique generates a glyph for each class label that shows an outline of the statistics. The center of the glyph is the
value 0 for all statistics and the vertices represent
the value 1. A perfect classifier would have a diamond shape, while a classifier that is always wrong
would be shown as a point. Figure 5 shows the glyph
visualization for the classifier of the breast cancer
data. Note that this classifier is good identifies ev, but sometimes misses
ery case for
.
on

Figure 6: The visualizations combined into the user
interface. Each attribute classifier on the left side
We combine each of the visualizations into a sin- reports accuracy independent of the other attributes,
gle user interface. The interface, shown in Figure while the combined classifier reports on the right.
6, displays the training information on the left side
The interface supports the user’s exploration of
and the testing information on the right. The design

4.3 User Interface

Proceedings of the Information Visualization (IV’06)
0-7695-2602-0/06 $20.00 © 2006

IEEE

the space by allowing a user to view each of the
histogram distributions that were considered by the
program. In addition, the user can select specific
class values to explore in order to see whether some
classes are predicted better than others.

5 Conclusion and Future Work
We have presented a method for visualizing the distributions of discretized values that provide insight
into the performance of the naive Bayes classifier.
The procedure iteratively constructs smaller bin intervals for each attribute independently, tests the accuracy of the resulting classifier, and then combines
each of the attribute classifiers into a single classifier. The single classifier is then tested against the
data and a final accuracy is visualized.
Our future work focuses on applying our technique to archaeological data to develop predictive
models for bronze-age Greek artifacts. In particular, we will be seeking to provenace the artifacts by
combining geolical and archaeological information.
Further work will explore performance aspects of our
approach, including benchmarking the complete UCI
repository [3] to determine whether the technique
yields insight into the classification process.

References

[4] C ARAGEA , D., C OOK , D., AND H ONAVAR ,
V. G. Towards simple, easy-to-understand, yet
accurate classifiers. In ICDM ’03: Proceedings
of the Third IEEE International Conference on
Data Mining (Washington, DC, USA, 2003),
IEEE Computer Society, pp. 497–500.
[5] FAYYAD , U. M., P IATETSKY-S HAPIRO , G.,
AND S MYTH , P. From data mining to knowledge discovery: An overview. In Advances in
Knowledge Discovery and Data Mining. 1996,
pp. 1–34.
[6] H AN , J., AND K AMBER , M. Data Mining:
Concepts and Techniques. Morgan Kaufmann,
2001.
[7] KOHAVI , R., AND P ROVOST, F. Glossary of
terms. Machine Learning 30 (1998), 271–274.
[8] L UV D EVROYE , L. G., AND L UGOSI , G.
A probabilistic Theory of Pattern Recognition.
Springer-Verlag, 1996.
[9] M ITCHELL , T. M. Machine Learning. McGraw Hill, 1997.
[10] P YLE , D. Data Preparation for Data Mining.
Morgan Kaufmann, 1999.

[11] R ICHARD O. D UDA , P. E. H., AND S TORK ,
[1] A NKERST, M., E LSEN , C., E STER , M., AND
D. G. Pattern Classification (2nd Edition). WiK RIEGEL , H.-P. Visual classification: an inley, 2000.
teractive approach to decision tree construction. In KDD ’99: Proceedings of the fifth [12] S HNEIDERMAN , B. Inventing discovery tools:
combining information visualization with data
ACM SIGKDD international conference on
mining. Information Visualization 1, 1 (2002),
Knowledge discovery and data mining (1999),
5–12.
pp. 392–396.
[2] A NKERST, M., E STER , M., AND K RIEGEL , [13] S WETS , J. Measuring the accuracy of diagnostic systems. Science 240 (1988), 1285–1293.
H.-P. Towards an effective cooperation of
the user and the computer for classifica- [14] U SAMA FAYYAD , G. G. G., AND W IERSE ,
tion. In KDD ’00: Proceedings of the sixth
A. Information Visualization in Data Mining
ACM SIGKDD international conference on
and Knowledge Discovery. Morgan Kaufmann
Knowledge discovery and data mining (2000),
Publishers, 2001.
pp. 179–188.
[15] W ITTEN , I. H., AND F RANK , E. Data Min[3] B LAKE , C., AND M ERZ , C. UCI reposing: Practical Machine Learning Tools and
itory of machine learning databases.
Techniques with Java Implementations. Morhttp://www.ics.uci.edu/ mlearn/MLRepository.html, gan Kaufmann, 2000.
1998.

Proceedings of the Information Visualization (IV’06)
0-7695-2602-0/06 $20.00 © 2006

IEEE

