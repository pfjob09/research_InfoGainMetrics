An Immersive System for Editing and Playing Music
on Network-connected Computers
Noritaka OSAWA*, Kikuo ASAI*, Norio TAWSEt and Fumihiko SAITO’
*National Institute of Multimedia Education, JAPAN
t
Solidray Co. Ltd, JAPAN
fosawa,asai)@nime.ac.jp Jtakuse, saito)@olidray.co.jp
problem.
We have developed a prototype immersive music
system, which enables us to edit and control music
through direct manipulation using our hands in an
immersive environment. The prototype system works on a
personal computer or a group of computers connected
with a fast local area network where one computer
executes the application body and others process
inputloutput. The system uses distributed VO devices and
is portable.
This paper describes the prototype immersive system.
Section 2 discusses related work. An overview of the
prototype system is described in Section 3. Section 4
explains the interaction techniques used in the system.
Future work is mentioned in Section 5. Section 6 gives a
summary.

Abstract
A prototype system for immersive music editing and
playing has been developed. The system enables one to
edit musical notes and control playing in an immersive
virtual environment them using multimodal intedaces.
The immersive virtual reality is suitable as a natural
interface for many people. One can manipulate musical
notes by one’s hand, learn to read a musical score and
understand relationship between the score and sounds.
The prototype system was implemented with the Java
programming language, the Java3D class libray, the
JavaSound class library and an original library called
“it3d”. It works on a personal computer or a group of
computers connected with a fast local area network where
one computer executes the application body and others
process inpirt/output. The system is portable and expected
to work on a wide range of hardware platforms.

1.

2.

Fakespace Music [3] is a sort of immersive VR system
using a head-mounted display (HMD). Music is used for
changing virtual environments in which objects are
animated in response to the music. Fakespace Music
responds to music and musical input for entertainment
purposes. It does not handle musical scores, and does not
allow us to edit the music.
The Music Animation Machine[6] is a 2D system,
which helps us to learn the structure of music. Its main
purpose is education. The Music Animation Machine
does not use a conventional score but an animated score
that is composed of colored bars. The Music Animation
Machine is not a VR system, and does not allow us to
manipulate music.
The Structured Event Editor (SSE) [lo] is a 2D/3D
music visualization system. It can visualize music data
and manipulate animation, however, the SSE is not a VR
system.
MidiVisualiser[S] is a desktop VR system. It is an
analytic tool for both education and music composition. It
can help analysis and editing of music through direct
manipulation. However, the Midivisualiser is not an
immersive VR system. Thus it does not use multimodal
interfaces.

Introduction

The virtual reality (VR) technology can be utilized to
give many people natural interfaces. A 2D display is
insufficient for seeing 3D objects because it is difficult for
us to gain a sense of depth in 2D. Therefore a
stereoscopic view is preferable to help us to touch, grasp
and move virtual objects in 3D. An immersive 3D virtual
space can be used to utilize freedom of our body motion
for multimodal interfaces.
One can devote oneself into music editing and playing
in an immersive music environment. However, interactive
multimodal interfaces for music manipulation in the
immersive environment have not been fully studied.
Direct manipulation such as a grab-move-release (or
get-and-put) operation is basic in the immersive
environment; however, the simple replacement of
drag-and-drop operations in GUI with get-and-put
operations in 3D is insufficient because the degree of
freedom (DoF) of hand operation is larger than DoF of a
usual 2D GUI device. The design of 3D interactive
interfaces for object manipulation is an important

630
0-7695-1195-3/01 $10.00 0 2001 IEEE

Related work

3. A prototype system::Reijin
We have developed a prototype system for immersive
music editing and playing. It is named as Reijin. A
screenshot of the system is shown in Figure I . A user puts
on a sensor glove with a &DoF position tracker for
measurements of hand movement. The user wears glasses
for a stereoscopic view.
A bar having notes is floaled in the upper region of
Figure 1. It is a kind of toolbcix bar. The notes are fixed
on the bar, and cannot be moved directly but can be
copied into a score. Operations on notes are based on
copying and moving operations.
The musical score is shown in the middle, which has a
background image. The score is scrollable with a dial.
The graphics board used in the prototype system cannot
handle anti-aliasing well; therefore, some thin lines are
broken as shown in Figure 1. This will be improved by
using a better graphics board.
Timbre selection panels are displayed in the left. It
allows one to select a timbre and a pitch using 3D widgets.
The control is based on the MIDI specification.
A control button panel is located at the lower region. It
enables one to play/stop music, cleariloadisave a musical
score, and change a tempo of the music.

synthesizer is used to generate sound. An external MIDI
device is not used in the prototype system but can be used
if quality of sounds should be improved. The if3d library
performs recognition of direct manipulation and
distributed I/O device communications.
The prototype system runs on a PC workstation for an
application body and a PC for distributed VO devices.
The PC workstation is'a Compaq AP550awith'dual lGHz
processors and an Elsa Synergy' HI< graphics board
supporting dual displays. The PC for the devices is
connected with 6-DoF sensors (Polhemus, Fastrak) 'and
sensor gloves (Virtual Technologies CyberGlove). They
' '
are used for detecting the
and motion of one's
body and hands. The c
ion of the prdtotype
system is given in Figure 2.
The prototype system uses a part of equipments on an
immersive virtual reality system called TEELeX
(Tele-Existence Environment for Learning exploration)
[ I ] at the National Institute of Multimedia Education in
Japan. TEELeX is a kind of surround display system
such as the CAVE[2]. TEELeX has a large cubic screen
for immersion. Each face is 3 meters by 3 meters.
Circular polarization is employed to' give users a
stereoscopic view.
The users only need to wear
lightweight stereo glasses. The current prototype system
uses one stereoscopic screen of TEELeX. This is because
Java2 Standard Edition (J2SE) v1.2 supported only one
display when the system was developed. A snapshot of the
prototype system is shown in Figure 3.
TEELeX is equipped with SGI Onyx2 RealityMonster
that has 6 graphics pipes and 24 processors. Unfortunately,
the Onyx2 was not utilized in the prototype system
because the versions of J2SE and Java3D for the IRIX
operating system for Onyx2 were respectively V I .2.2 and
v1.1.3 in our development period. We will try to use the
Onyx2 and all surrounding screens when J2SE v1.3 and
Jav3D vl.3, which support multiple displays, will be
released for the IRIX. It will enable us to utilize all
screens fully.
100Ease-TX Ethernet

Figure 1: A screenshot of Reijin
Compaq AP550
Dual lGHz Pentium Ill
Elsa Synergy 111
porting dual displays

A prototype system has bee,n developed using the Java
programming language, the Jaba 3D class library, the Java
Sound class library, and it3d library (Interactive Toolkit
library for 3D applications) which we developed. It3d
has distributed I/O functions, useful 3D widgets and a
gesture recognition engine.
The use of the Java
enhances portability of the syslem, which would work on
a wide range of computer systems. 3D graphics is
achieved by the Java3D v1.2 class library. MIDI sound is
controlled by the JavaSound class library and a software

orks

Projectors
for left eye

CyberGlove
Polhemus Fastrak

for right eye

Figure 2: A prototype system configuration.

63 1

One can also move a note by picking it with his thumb
and middle finger, moving it and releasing it. As stated
before, notes on the toolbox bar are fixed in'the location
and cannot be moved but copied.
In the 2D GUI, a mode of copying or moving has to be
switched by a buttodmenu operation or a modifier key
such as a shift key. A hand interface in a 3D space
allows one to use one's fingers to manipulate objects as
described above. We think this way is easier than mode
switching in a conventional 2D GUI.

A copied note with

Figure 3: A snapshot of the prototype system in

a %x"transparent

TEELeX

4.

Interactions

The prototype system enables one to edit and play
music using hand motion. This section describes
interaction techniques employed in the system. We
categorize interaction techniques into direct manipulation
and interaction using 3D widgets in this section.

4.1.

(a) Picking a note from a bar

Direct manipulation

One of basic interactions is direct manipulation in an
immersive environment. The system allows one to
manipulate notes in a musical score with a virtual hand.
The fhdamental operations are to copy, move and delete
notes. They are explained below.
'

4.1.1.

Copying and moving a note

One can copy a note by picking it with his thumb and
forefinger, moving it and putting it on a musical score.
When a note is picked, a semi-transparent sphere which
indicates the picking of the new note is displayed as
shown in Figure 4 (a). When the note is moved in the
score, a position frame is displayed as shown in Figure 4
(b). As the note is moved in the score, it is sounded. One
can check the location of the note and the pitch of it by
the frame and its sound.
When one opens this hand on the score, the note is
released and its position is determined as shown in Figure
4 (c). The position of the note is automatically aligned
after it is released. A note can be copied from not only the
toolbox 6ar but also the score.
The copy operation is a kind of magic because physical
objects cannot be copied. It is easy to remember how to
copy a note.

(b) Moving a note on the score

The position of
the released
note is

automatically
aligned

(c) Releasing a note

Figure 4: Copying a note using:direct manipulation

632

4.1.2.

4.2.1.

Deleting a note

One can load a music using a 3D combobox: Figure 6
shows a screenshot of selecting a music using a 3D
combobox. When the Load button is selected on the
control button panel, a combobox appears as shown in
Figure 6 (a). Then, a music name is selected from the
menu list, the music data is loaded and displayed on the
score as shown in Figure 6 (b).

The note which is moved outside the score, or left
outside, is deleted as shown in Figure 5. When a note is
picked, a semi-transparent sphere is displayed in the same
way as copyingLandmoving. While the note is moved, the
sphere is shown 'as in Figure 5(a). When the note is
released outside the score, it is discarded or deleted as
shown in Figure 5(b).

(a) Picking and moving a note

Loading music data

(a) Selecting a music using a 3D combobox:

'

eleased outside

(b) Music data is loaded in the score

Figure 6: Loading music data using a 3D combobox

(b) Releasing the note outside the score

Figure 5: Deleting a note
4.2.2.

4.2.

3D widgets

Playing a music

One can play a music using a 3D button. It is a toggle
switch. After the Play button is touched, the music is
played repeatedly.
When it is touched again, the
performance is stopped. Figure 7 shows a screenshot just
after the play button is pushed.

In addition to direct manipulation, the prototype
system also uses various 3D widgets for controls. One can
play music, clear the score, load music data, save the
score and exit the system using the 3D widgets. One can
also select a timbre for a track using a 3D button and a 3D
list. Moreover one can scroll the score using a dial.
They are explained in this subsection.

633

the dial can be simply handled and it is easy to understand
how to use the dial in a 3D space.

Figure 7:Playing a music using 3D buttons
Figure 9: Scrolling t h e

4.2.3.

score using a dial

Selecting a timbre

A timbre of a track can be selected using a button and a
list. When the timbre selection button is touched, a timbre
selection list is displayed as shown in Figure 8. One can
select a timbre from the list, which is scrollable with the
scroll bar. One can also select a pitch of a track using up
and down buttons.

5.

Future work

We have a plan to extend the prototype system for a
learning support tool of music theory. We also have a plan
to modify the system for children. For example, each note
is given a face of some character. Its facial expression will
change when the note is touched, moved, and sounded.
Notes will also dance as animation when they sound.
Moreover, a note looks like smiling when it is a part of
harmonic chord. The children can manipulate sounds by
their hands and will experience music with fan.
We will exploit spatial sound to show the location of a

note. If the spatial sound were used, the identification of
a sounding note would be easier than in the current
implementation.

6.

We have developed a prototype immersive music
system utilizing multimodal interfaces. It works on a
group of computers connected with a fast local area
network where one computer executes the application
body and others process input/output. It was implemented
with the Java programming language, and some libraries.
The system can be easily ported to other hardware
platforms. The system will be extended to edutainment
(education and entertainment).

Figure 8: Selecting timbre using buttons a n d a list

4.2.4.

Summary

Scrolling a score

One can scroll the score using a dial. As one rotates
the dial for scrolling, the score is shifted horizontally as
shown in Figure 9. One can see and manipulate notes in a
long score.
A dial is not suitable for 2D CUI devices such as a
mouse because it is difficult to rotate the dial. However,

7.

Acknowledgements

This research was partially supported by Grant-in-Aid
for Scientific Research (1 1358002) in.Japan.

634

[4] James Gosling, Bill Joy and Guy Steele, The JavarM
Language Specification, Addison-Wesley, 1996.
[ 5 ] Alan Graves, Chris Hand and Andrew Hugill, "Interactive
Visualisation of Musical Form Using VRML", Proc. of the
Fourth UK VR-SIG Conference, pp 98-109, 1997.
[6] Stephen Malinowski, The Music Animation Machine,
http://www.welI.com/user/smalin/mam.html
(as of March
2001).
[7] Noritaka Osawa, Kikuo Asai, Yuji Y. Sugimoto, "lmmersive
Graph Navigation Using Direct Manipulation and Gestures,"
Symposium on Virtual Reality S o f i a r e & Technology 2000
(VRST 2000), pp.147-152,2000.
[8] Henry Sowizral, Kevin Rushforth and Michael Deering, The
Java 3 0 API Specification, Addison Wesley, 1998.
191 Sun Microsystems, Java Sound API specification,
http:/!java.sun.com/products/java-medidsound/(as of March
2001).
[IO] Kunze, Tobias and Taube, Heinrich. "SEE--A Structured
Event Editor: Visualizing Compositional Data in Common
Music" Proc. of the international Computer Music
Conference, 1996.

The toolkit library "it36''was developed with funding
by the Support Program for 'Young Software Researchers
in 2000, which was implemented by Research Institute of
Software Engineering (€USE) commissioned by
Information-technology Promotion Agency (IPA), Japan.
The authors would like to thank Mr. Takashi Tohyama
for working with us to develop a distributed I/O library in
it3d.

8. References
[ I ] Kikuo Asai, Noritaka Osawa, and Yuji Y. Sugimoto, "Virtual
Environment System on Llistance Education," Proc. of
EUROMEDIA '99,pp.242-2446, 1999.
121 Carolina Cruz-Neira, Daniel J. Sandin, Thomas A. DeFanti,

Robert V. Kenyon, and Joh:n C. Hart, "The CAVE: audio
visual experience automatic virtual environment." Comm.of
the ACM, Vo1.35, No.6, pp. 64-72, 1992.
[3] Fakespace Music, http://www.fakespacemusic.com/ (as of
March 2001).

635

