4D Volume Rendering With The Shear Warp Factorisation:
Extensions And Quantitative Results
Kostas Anagnostou
Department of Computeir Science
University of Warwick
Coventry CV4 7AL
United Kingdom
kostas @ dcs.warw ick .ac.uk

Tim J. Atherton
Department of Computer Science
University of Warwick
Coventry CV4 7AL
United Kingdom
tja@dcs.warwick.ac.uk

2 Related work

Abstract
We present extensions to an approach [I] for rendering time-varying data based on the Shear- Warpfactorisation. The change detection technique is adapted to process
Poisson distributed datasets, a modiJied block differencing
technique that decreases the change detection errors is presented along with a modijicaticln of the original run-length
encoding method which allows better spatial compression
for volumes with uniform and sr'owly changing background.
Results are presented on datasets originating from optical
microscopes which demonstrate the eficiency of the proposed methods.

The most prominent characteristic of time-varying volume data is a substantial coherence in time. A great percentage of voxel values do not change, or change very slowly
over time.
This fact can be exploited in time rendering. Dobashi [3]
proposed a rendering method for time-varying data by ,using orthonormal wavelets to encode time coherency. M a [6]
described a method for 4D rendering that uses quantisation
of scalar values to reduce the space .required to store the
volume, octrees to encode spatial coherence and differencing to exploit time coherence. Shen [ 101 used differencing
in order to detect changes between successive volumes employing ray-casting to fully render the first volume in the
series and subsequently updating the final image by casting
rays only from pixels that correspond to changed areas in
the volume. Further to this, in [9] the so-called Time-Space
Partitioning (TSP) Tree was introduced, which is effectively
a complete octree extended so as to capture both spatial and
temporal coherence. Silver [ 113 identifies features of interest and tracks them in time.
All the above approaches utilise ray-casting for rendering. Our approach is based on the Shear-Warp factorisation
[51.

1 Introduction
Time varying (4D) volume processing and rendering is a
relatively new research area that finds application in many
areas such as biomedicine, medicine, astronomy, simulations, CFD etc. Four dimensional imaging is a term used
to describe the processing and visualisation of volume data
sets that change over time.
The task of rendering 4D data is time consuming by its
nature, because multiple volumes must be acquired, processed and rendered at interactive rates. This vast amount
of data can provide biomedical scientists with a new view
of how things develop and change over time. Interactive
and efficient imaging techniques and data storage assume
special importance.
In this paper, which summarises and extends earlier work
[ 1 J, we consider the development and implementation of an
algorithm for processing and visualising time varying data,
originating from optical microscopes.

0-7695-1195-3/01 $10.00 0 2001 I$EE

Andrew E. Waterfall
Improvision Ltd
Viscount Centre I1
Millburn Hill Road
Coventry CV4 7HS
United Kingdom
aew @improvision.com

3

Rendering 4D data

In some cases on the fly visualisation of time varying
volume data is required, such as in the 4D Ultrasound application. Although hardware implementations of rendering
algorithms that can render static volumes in real-time [ 121
exist, current memory and U 0 bandwidth limitations make
the use of these accelerators difficult in the case of 4D data.

435

intermediate image

In some experiments, multiple viewing of the same 4D
dataset might be required, using different viewpoints, opacity functions, and various other parameters. Cases like these
make storing of the volume data a necessity for later analysis and viewing.
The amount of data that has to be stored is vast, so compression techniques assume a special importance. In general, 4 D data are, to a great extent, spatially and temporally
coherent. Eliminating this kind of redundancy leads to high
compression ratio and efficient and fast rendering.
We seek to exploit the existence of spatial and temporal
coherence in the time-varying volume data. These portions
of the volume do not necessarily have to be empty. They
might well be static but non transparent. Since not much
change is assumed to take place between successive volumes, volume rendering can be accelerated by locating and
rendering only those changes.
We identify two stages in the process of visualising 4 D
data, the preprocessing and the rendering stages. The preprocessing stage involves change detection, change encoding and saving to disk, while the rendering stage involves
loading of changed sub-volumes from the disk, updating
the volume and rendering the changed sub-volumes. In this
asymmetric rendering scheme, the preprocessing stage is
viewpoint independent and due to hardware limitations, is
not in general interactive and need not be. The rendering
stage on the other hand should be interactive and allow arbitrary viewpoints.
In the following sections we briefly review the method
introduced in [ 11and present modifications and extensions.

volume in sheared space
/

I

/

I2

Figure 1. Dividing the volume into 7 slabs
("thick slices"). The actual area that needs
to be rerendered using the slab method is
shaded. Only 3 intermediate images are affected by the change and need to be updated.
Figure taken from [l].

such as DCT compression, the basis of JPEG and MPEG,
Discrete Fourier Transform etc and lossless such as Run
length encoding, Huffman coding etc.
Lossy algorithms, although they degrade the volume data
to a certain extent, perform better than lossless ones in terms
of compression efficiency. Allowing for a user controlled
error in compressing, we can achieve a dramatic, datadependent, decrease in the required storage space without
a significant impact in the image quality.
The Shear-Warp algorithm is based on a scanline oriented compression scheme, using run-length encoding to
eliminate blank space in the dataset. Often, a large proportion of the voxels in a volume are not transparent but d o
not change significantly over time. A run-length encoding
scheme that bases its compression efficiency on the presence of transparent voxels, as used in [5] will then perform
poorly. We have modified the run-length encoding of the
volume to take into account the slow spatial variation of the
voxel values by grouping together voxels with, according to
some criterion, insignificant differences in voxel brightness.
In our implementation we define a group of similar voxels
as a set of voxels in which the deviation of each voxel from
the first voxel in the group does not exceed a given threshold. The threshold which will determine the similarity of
adjacent voxels can be user defined. Using this similarity
among the voxels of a group, we can reduce the storage
space by storing only the average value of the group. Usually a threshold of 2-5 in the absolute scalar difference of
any voxel in the group and the first voxel of the same group
leads to a good compression, which is data-dependent as
it will be demonstrated later, with small impact on image
quality and also to faster rendering since as a run is represented by the average value, we can resample once for the

3.1 Temporal and spatial compression of 4D data
Typical 4 D datasets exhibit a high degree of temporal
coherence. The rendering application can be accelerated if
only the subvolumes that actually change over time are located and rendered. In [ 11 we proposed a method to achieve
that, using slabs. The slabs cache the already rendered unchanged regions of the 4D dataset. Changed subvolumes
are updated to the volume and subsequently rendered. Finally the slabs are recomposited to produce the final image. Figure 1 summarises the procedure. In this figure a
volume in sheared space [ 5 ] is presented, which contains a
small changed area denoted by the small dotted parallelogram around the central object. In order to correctly render
the change, a much larger area that spans all volume slices
must be rendered. By slicing the volume into a number of
slabs (7 in this figure) we only have to rerender the affected
slab area which is the denoted by the small grey box in the
figure.
Although this approach eliminates temporal coherence,
we must also take spatial coherence into account. Various
compression methods are available in the literature; lossy

436

first voxel and use this resampled value for the compositing
of the run.
This technique is used in corijunction to the method for
volume updating and rendering presented in [ I ] .
Perspective rendering of the d a b structure using the SW
method is possible by scaling thl: slices in each subvolume.
There are some drawbacks of the SW method for perspective projection, i.e. it is often difficult to choose a primary
axis when the viewing point is close or inside the volume.
[5] proposes a solution to this problem which is to subdivide the subvolume by splitting it along planes oriented at
45 degrees angles relative to the slices, which increases the
complexity of the rendering algorithm. Also in some cases
of severe perspective distortion visibility errors can occur
since the method filters the volume before compositing, but
in practice the artifacts caused by this problem are expected
to be insignificant.
The first volume in a sequence is encoded, using the
modified run-length encoding method described, in full and
stored to disk. The encoding must take place 3 times, one
for each primary axis. For subsequent volumes, change detection takes place and only the blocks that are classified
as changed are run-length encoded, stored to disk, and later
during the rendering stage, rendered individually into the
corresponding slabs.

dominant noise in the data is the Poisson distributed Photon noise, that is the brightness of every voxel is Poisson
distributed with a variance equal to the expected brightness;

: is the voxel variance at position x and T(x) is
where a
the expected voxel brightness which corresponds to the real,
noise free, voxel brightness. In this case, the general equation 2, which was used in [ l ] for X 2 , is not applicable. and
also methods for noise variance estimation in the Gaussian
case will not produce correct results.
Ideally, the X 2 equation for Poisson noise would be formulated as:

) variance of voxel i at times
where a;,(,) and u ; , ( ~ +is~ the
t and t+l.
Substituting a
: = f(z):

Since the value of f(z) is unknown, we make the ap21 f(z),
that is we set the variance of each
proximation
voxel to be equal to the sampled voxel brightness [7]:

02

4 Change detection
The rendering algorithm requires the accurate detection
of changed areas in the volume in order t3 produce the correct result. Change detection takes place in the preprocessing stage.
There are a variety of change detection algorithms in the
literature, see [4] for a review. Most methods require an
accurate, data dependent definition of a threshold that will
determine whether change has taken place or not. It is generally difficult to estimate a global threshold that will work
with all datasets. We attempt to derive the threshold independently from the data.
In [l] each volume in the dataset was divided to blocks
of constant size, hypothesis tesiing was utilised to determine which block has changed. and the X 2 [2] criterion
was used to determine the significance of each decision according to a threshold T and a confidence level. The test
was formulated specifically for clatasets assuming that they
are contaminated with Gaussian noise.
In reality, data sampled by CCD cameras are contaminated with 3 kinds of noise namely the Photon noise, the
Dark noise and the Read noise [8]. The Photon noise is attributed to the statistical variation in the photon arrival rate
at a given point and is Poisson distributed. State of the art
CCD cameras are cooled and use low-noise electronics to
reduce the Dark and Read noise to negligible levels. The

Intuitively, this approximation will be good for high brightness values, due to the increased signal to noise ratio, and
will be diverging from the optimal value as the brightness
decreases. One way of improving the estimation of f ( x )
is to average the sample values, in time, in areas where no
change has taken place using the following recursive formula:
1
(5)
X(t) = i [ ( t- l)X(t - 1) + fi(t)l

3(t)

where
is the estimation of the mean value of sample
fi(t) and t denotes time.
There is a trade off between image quality and rendering speed, which depends on the confidence level set during the hypothesis testing. To make the effect of the confidence level clearer, imagine that the confidence level during change detection expresses how certain we are that the
block is unchanged. A low confidence level means that we
are not sufficiently certain that this holds true. So, low confidence levels produce more blocks and increase the rendering time per volume.
In order to estimate the X 2 value for the hypothesis testing, differencing of successive, in time, volumes must be

431

increases since the difference between the actual and the estimated blocks may increase. This reduces false negatives,
i.e. blocks that are reported as unchanged although they
are, and increases the quality and accuracy of the rendered
image.
Prior to run-length encoding, as we explained in [ 11 concatenation of adjacent, in the x and y directions, changed
blocks must take place in order to avoid redundant rendering of voxels in the shear space. In addition to eliminating
the rendering overhead, concatenation of adjacent changed
blocks leads to better compression since it allows for longer
runs in case of empty or uniform areas and further accelerates rendering by maintaining cache and memory coherence.
Concatenation of the blocks should take place both in
the x and y directions, for each primary axis and should be
performed during the preprocessing stage so as not to delay
the rendering stage.

performed. The differencing takes place on a block by block
basis to estimate the X 2 value for each block. Based on the
outcome of the hypothesis testing, we can build an estimate
of what the current volume is. Essentially we difference the
current block from the last unchanged block and not from
the previous, in time, block. Figure 2 illustrates this procedure.
TO

TI

7-2

T3

Estimate Block

If unchanged
cupy

If unchanged
copy

If unchanged
copy

Figure 2. Building a current volume estimate
to improve differencing.

5

Results-Discussion

’

We implemented that algorithms described in [ 11 adding
the improvements proposed in the above sections. The
methods are tested and the improvements in terms of rendering acceleration, storage efficiency and image quality
are reported. For the evaluation of the methods described
a drosophila embryo sequence of seven, 8bit volumes at
1 0 2 4 x 1 0 2 2 ~ 5 was
0
used (figure 3). The drosophila embryo was captured by an Hamamatsu ORCA 100 C474295 (pixel size 6.7 p m ) CCD camera mounted on a widefield
optical fluorescence microscope with a 40x0.7 NA objective
at a fluorescence wavelength of 520 nm. Three-dimensional
images were acquired by taking 2D images at depth intervals of 1 pm. Complete 3D images were acquired at intervals of 5 minutes for one hour using OpenLab software
(Improvision Ltd).
Due to the microscope’s optical distortion, the sequence
contains a semi-uniform background haze and changes
slowly over time. To composite the volume voxels we used
the Maximum Intensity Projection method, which due to
the nature of the dataset produces images with higher quality than the ”over” operator. The application was tested on
a Sun UltraSparcII 300MHz with 768MB RAM.
To test the efficiency of the modified block difference approach used we processed the drosophila sequence using a
confidence level of 70% and a block size of 83. The reason
we have chosen this sequence is that it contains many subtle changes. So intuitively, the modified block differencing
should be more efficient in assisting to detect changed areas
than simple block differencing. This is illustrated in figure
4 where the number of blocks classified as changed during hypothesis testing for simple and modified differencing
against the time step (Volume Number) are presented.

To be more specific, let us concentrate on a volume block
in several time instances. The Actual block corresponds to
a block from the current volume and the Estimate block to
a block from the current estimate of the volume. The general idea is to transfer any unchanged block in time, and
only change it when the Hypothesis testing reports it has
changed. This is made clear with the following pseudocode:
copy (actualblock[O],estimateblock[O]);
for T=l to Numberofvolumes
begin

if (change(actualblock[T],estimateblock[T-11))
copy(actualblock[T],estimateblock[T]);
else
copy(estimateblock[T-l],estimateblock[T]);
end
At first, since we have nothing to compare the actual
block at time T=O with, we just copy it across to the corresponding place in the estimate volume. Next we go over
the total number of volumes, starting from time T=O, and
we estimate the change between the actual block at time T
and the estimated block at time T-I. If there is significant
change we then copy the actual block at time T to the estimated block at time T. If the change is insignificant, we just
copy the estimated block at time T- 1 to the one at time T.
The advantage of this method is that when the hypothesis testing can’t detect any change between two successive in time blocks, due to slowly changing voxel values,
in the next iteration the possibility of detecting the change

438

Figure 3. Rendered images from the
drosophila sequence a1 time steps 0 and 3.
The Maximum Intensity Projection rendering
method was used and tlhe viewpoint was set
to 40 degrees from Y and 2 axis (courtesy of
Dr B.Sanson, Cambridge University, UK).

Figure 4. Number of changed blocks for
simple and modified differencing for the
drosophila sequence.

As expected, simple differencing marks a lot less blocks
as changed compared to the modified differencing. This is
due to the small changes in structure and brightness that
take place in time. Especially towards the end of the sequence where mostly brightness changes occur, the simple differencing proves inadequate. We have to note at this
point that the first value of the plot is zero, because it corresponds to time T=O where no change detection takes place
and the second value is the same for both methods because
for timestep T=l the estimated volume against which we
compare the current volume is the same for both methods.
The results start to diverge from timestep T=2 onwards.
Also, the number of blocks for the simple differencing case
drops to zero by time point 6 and this is due to the nature
of the dataset which contains subtle changes (mainly the
background haze changes) that can't be detected by the X 2
criterion. The modified block differencing is more effective
at detecting those subtle changes.
Since modified differencing is better at detecting subtle changes in the volume, the number of false negatives,
i.e. blocks that are reported as unchanged while they have
changed, decreases and the estimation of volume becomes
better, as figure 5 illustrates. In this figure the differences,
expressed as the mean square error, between the actual volume and the estimate volumes reconstructed using simple
and modified differencing at each timestep are presented. It
is clear that the mean square error of the volume estimation
increases with time in the simpll: differencing case while it
seems to be bounded by an upper limit and to stabilise in
the modified differencing case.
The increase in the number of changed blocks has an impact on the final, stored, volume size as is apparent in figure 6 where the spatially-only encoded version of the vol-

ume is also presented at each timestep for comparison. At
the first timestep (T=O) the full volume is run-length encoded using the modified RLE method described and stored
to disk for all methods. At the following steps only the
changed blocks are run-length encoded and stored to disk
reducing the storage space significantly. Since the modified
block differencing produces more blocks, the stored volume
will be larger than in the simple differencing case as illustrated in the figure, although the difference is not significant
compared to the size of the spatially-only encoded volume
at each timestep. Again, the second value in the figure is
the same for both methods because for timestep T=l the estimated volume is the same for both methods (as explained
above), so the rendering times are the same.
Due to the increase in the detected number of changed
blocks, rendering will be slower in the case of modified differencing as illustrated in figure 7. The times in seconds a
presented for both modified and simple block differencing.
For comparison, the times required to fully render the runlength encoded volume at each timestep are presented. On
the other hand the image quality, expressed as the Signal to
Noise Ratio in the rendered image, improves with modified
differencing (figure 8). More blocks lead to less artifacts in
the final rendered image and improved SNR according to
the figure.
The SNR in both cases decreases with time, at a rate that
depends on the confidence level selected. This is attributed
to the presence of false negatives. If an area in the volume
is not identified as changed although it was, the projected
image will not be updated and an artifact will remain in
the image until (and if) this area is updated. In time, an

439

35

r

-

aimplc dI1rmwmp--c

simple differencing

..........................................

dI

............... ..................mMlilleddllfercnclng----lull RLE ......

25
301

ZC+M

-

n
0

1

2

3

4

0

5

Volume Number

Figure 5. Volume mean square error for
simple and modified differencing for the
drosophila sequence.

I

3
Volume Numkr

4

j

6

Figure 6. Comparison of required storage
space when using simple and modified differencing, for the drosophila experiment. The
size of the fully run-length encoded volume at
each timestep is also presented. The modified RLE was used in all cases.

accumulation of such artifacts is noticed which degrades the
image quality. Altering the confidence level and using better
estimation techniques will improve the image quality but
will not eliminate the problem. A solution to image quality
degradation would be the introduction of key frames, that
is rendering a full volume periodically to refresh the image
and eliminate any accumulated artifacts. On the other hand
key frames will introduce a storage and rendering overhead
to the system, so their frequency should depend on the user
requirements for speed and image quality.
Figure 9 presents the rendered images for timestep 3 using modified and simple block differencing. Also the difference between those images and the fully rendered version of
the volume at timestep 3 is presented for comparison. It is
clear that the modified block differencing method produces
less artifacts in the rendered image.

of the volumes in the sequence a 4: 1 compression ratio over
the original RLE is maintained.
Improvement also appears in the rendering time of each
volume (figure 1 I). The rendering time of the spatiallyonly compressed volume using the original RLE is approximately 16 sec per volume, while when both spatially and
temporally compressed the rendering time reduces to an average of 2.5 sec per volume apart from the first which is
fully rendered. Using modified run-length encoding we can
further increase the speed-up. So rendering of the spatiallyonly compressed volume using the original RLE takes approximately 8 sec per volume while rendering of the subsequent volume takes on average 1.5 sec per volume, an
improvement that is IO:] over just spatial compression using the original RLE version of the sequence, and of I .5:1
over the spatially and temporally compressed version of the
sequence using the original RLE.
Although the compression ratio is high, there is virtually
no difference between rendered images of volumes encoded
with modified and original RLE (figure 12). In this figure
the images on the first row correspond to renderings (using
the same parameters) of timesteps 0 and 3 of the original
run-length encoded volume, the second row using the modified run-length encoding method presented and the third
row presents the binarised absolute difference between the
corresponding images of the first and second rows. The differences are insignificant.
Finally, since the slabs are fully rendered only for
the first volume in the sequence and since the interme-

To conclude the results section we present the comparison of the modified run-length encoding used during the
preprocessing and rendering and the original run-length encoding as used in [SI.In order to demonstrate the efficiency
of the method in rendering slowly spatially varying data
we encoded the drosophila sequence. In figure 10 the final stored volume size (in bytes) is presented using the two
discussed methods for all timesteps. It is worth mentioning that the original, raw volume size was approximately 52
MB. The original RLE managed to reduce this size by only
2 MB. Using the modified version of the RLE we reduced
the size of the volume to 10 MB using the same transfer
function and opacity threshold and using a threshold of 4
in the absolute difference of adjacent voxels, as described
above, with virtually no loss in image quality. For the rest

440

0

I

2

3

4

5

I

6

Volimc Numhcr

2

Volume N u m b

3

4

5

Figure 8. Rendered image SNR for simple and
modified differencing for the drosophila sequence.

Figure 7. Rendering time for simple and modified differencing for the (drosophilasequence.
For comparison the times required to render fully run-length encoded volumes are presented.

plained. The introduction of key frames to the system is a
topic of future work. Also we are investigatinge the feasibility of quantisation methods to further compress the volume
datasets.

diate images depend on the viewing direction, it is not
easy to change the viewing direction at an arbitrary time
point. Rendering an arbitrary volume in the sequence
would require updating the initial volume with all subvolume changes up to this point and fully rendering the required time point introducing sj3me overhead to the system.
This drawback makes the need for keyframes, which would
periodically fully store and render a time point, even greater.

7

Acknowledgements

We would like to thank Benjohn Barnes for the illuminating discussion and Dr B. Sanson, Cambridge University, UK for providing the drosophila data sequence. Also,
we gratefully acknowledge the technical and financial support of Improvision Ltd, Viscount Centre 11, University of
Warwick Science Park, Millburn Hill Road, Coventry, CV4
7HS. http://www.improvision.com. This work is the subject
of a US Patent Application.

6 Conclusions
In this paper we have introduced and discussed modifications and improvements as well as quantitative results, to
the method [ I ] of rendering 4D data using the Shear-Warp
factorisation.
A modified differencing technique was presented which
assists in reducing the false negatives and in improving the
image quality with a tolerable impact in rendering speed and
storage space. The X 2 criterion was adapted for Poisson
distributed datasets. Finally a modified version of the runlength encoding was presented which performs significantly
better than the original method when processing volumes
that contain a uniform and slowly varying background.
Results on rendering speed up, storage space requirements and image quality improvements were presented
which demonstrated the efficiency of the proposed methods.
The necessity of key frames for image quality improvement and viewpoint alteration while rendering was ex-

References
[ I ] K . Anagnostou, T. Atherton, and A. Waterfall. 4D Volume Rendering With the Shear-Warp Factorisation. In Proceedings Of Volume Visualization and Graphics Sumposium
2000, pages 129-137. IEEE Computer Society Press, Los
Alamitos, CA, 2000.
[2] T. Atherton and D. Kerbyson. Reducing False Alarm Ratio In Surveillance Imaging Using Significance Testing. In
M. Fairhusrt and P. Hobson, editors, Proceedings IEE Colloquium "Image Processing for Security Applications". IEE

London, 1997.
[3] Y. Dobashi, V. Cingoski, K. Kaneda, and H. Yamashita.
A Fast Volume Rendering Method for Time-Varying 3D
Scalar Field Visualization Using Orthonormal Wavelets.
IEEE Transactions on Magnetics, 34(5), September 1998.

44 1

5 Set07

se+n7
4 5e+07

*.+(I7
3.5~107

3e+fl7

?et07
I5ct07

I

n

I

1
Vnlumc Numkr

4

5

6

Figure 10. The final volume file size using
modified and original RLE for the drosophila
sequence.
Figure 9. Rendered images (timestep 3) from
the drosophila sequence using the simple
(left column) and modified (right column)
block differencing and the binarised absolute
difference of each image from the fully rendered one.

cal and Computer Engineering, Rutgers University,
http://www.caip.rutgers.edu/vizlab.html,
1998.
[ 121 TeraRecon Inc., http://www.rtviz.com/origindex.html.
Volume PRO.

G. Foresti. Real-Time Detection of Multiple Moving Objects in Complex Image Sequences. International Journal
oflmpging .Systems and Tectmology, 10(4):305-3 17, 1999.
P. Lacroute and M. Levoy. Fast Volume Rendering Using a
Shear-Warp Factorisation of The Viewing Transformation.
In Computer Graphics Proceedings, Annual Conference Series (SIGGRAPH '94), 1994.
K. Ma, D. Smith, M. Shih, and H. Shen. Efficient Encoding
and Rendering of Time-Varying Volume Data. Technical report, ICASE, NASA Langsley Research Center, June 1998.
D.MacCrath and J. F. G.J. Daniel. Maximum Entropy Deconvolution of Low Count Nuclear Medicine Images. In
IPA97, pages 274-278. IEE Conference Publication No 433,
1997.
R. Scientific. Low Noise: An Integral Part of HighPerformance CCD Camera Systems. Technical report,
www.roperscientific.com, 1999.
H. Shen, L. Chiang, and K. Ma. A Fast Volume Rendering Algorithm for Time-Varying Fields Using a Time-Space
Partitioning (TSP) Tree. In Visualization 99, pages 37 1-377.
IEEE Computer Society Press, Los Alamitos, CA, 1999.
H. Shen and C. Johnson. Differential Volume Rendering: A
Fast Volume Visualization Technique For Flow Animation.
In Proceedings of the Visualisation'94 Conference, pages
180-187, October 1994.
D. Silver and X. Wang. Visualizing Evolving Scalar
Phenomena.
Technical report, Dep. Of Electri-

442

0

I

t

4

5

6

Volume N u m k r

Figure 11. Rendering times using modified
and original RLE for the drosophila sequence.
Changes were detected using modified block
differencing in all cases.

Figure 12. Rendered images from the
drosophila sequence using the original RLE
(first row), the modified RLE (second row) and
the binarised absolute difference (third row)
for timesteps 0 and 3.

443

