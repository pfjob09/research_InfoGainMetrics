Efficient Simplification of Polygonal Surface
Models
Muhammad Hussain, Yoshihiro Okada, and Koichi Niijima
Graduate School of Information Science and Electrical Engineering, Kyushu University
6- 1, Kasuga-koen, Kasuga, Fukuoka 8 16, Japan.
mhussain@i.kyushu-u.ac.jp

Abstract

ports level-of-detail management.
Among various approaches to polygonal simplification,
edge collapse based techniques have,emerged to be the most
popular ones because of their simplicity and effectiveness.
One of the earliest algorithms based on this approach was
proposed by Hoppe [6] and it provides a foundation for
most existing simplification algorithms of this category. Existing edge collapse algorithms differ only in making two
decisions: where to place the substitute vertex and how to
measure the error introduced when an edge collapse takes
place. As far as the positioning of the substitute vertex
is concemed, two approaches are in common use: strbset replacement or hay-edge collapse, and optimal placement. Subset placement causes one of the endpoints to select as the target position and is the simplest strategy one
can adopt. In optimal placement, the position of the substitute vertex is allowed to float freely in space in order to minimize some error metric. In our algorithm, we have opted
for subset placement as topological operator. To determine
the sequence of edge collapses, we have proposed a new
error metric in Section 4.
The subsequent arrangement of this paper is as follows.
In Section 2, we give an overview of related edge collapse
algorithms. Section 3 gives an overview of our simplification method. Error metric used in our method has been detailed in section 4. Results of our simplification algorithm
have been reported in Section 5 and Section 6 concludes the
article.

We have proposed a new edge collapse simplification algorithm that can produce eflciently high quality approximations of closed manifold surface models. To reduce the
number of triangular faces in a polygonal model, a sequence of edge collapses is performed and to choose the
appropriate sequence of edge collapses, we have introduced
a new error metric based on a quantity proportional to the
volume of a tetrahedron. Our pmposed algorithm is simple,
fast and memory eflcient and, can eflciently reduce very
large polygonal surface models. Moreoveer, simplified models created using our method preserve the essential features
of a model and comparefavorably to many well-knownpublished simplification techniques in terms of maximum geometric error and mean geometric error and bear high visual reliability even after signijcant simplification.

1 Introduction
Advanced technological systems such as Laser range
scanners, computer vision systems, medical imaging devices, and CAD systems have given rise to vast databases
of polygonal surface models which are often very complex and highly detailed. The visualization of such models has posed the most critical and fundamental research
problem: how to store, approximate, and render the very
large data sets that define them. Polygonal simplification
is one of the various approaches that address this problem. A polygonal surface model hl consists of a fixed set
of vertices V = {vel wl .. . vr} and a fixed set of faces
F = {fo, f i , . . . , fn}. Without loss of generality, we can
assume that the faces constituting the surface model are triangular. The objective of polygonal simplification is to produce a simplification M' of an original model M such that
M' contains fewer polygons than A4 and is as similar as
possible to M.It induces hierarchical structure which sup-

2

In this section, we give an overview of some of the related edge collapse algorithms. The basic differentiating
factor among different algorithms of this kind is how to define an error metric reflecting the error introduced when an
edge collapse occurs.
Some authors have defined error metrics based on elaborate measure of error. For example, Progressive Mesh [6]

464
0-7695-1195-3/01
$10.000 2001 IEEE

Related Work

Figure 1. Edge collapse operation: edge e,
will be substituted wi1.hvertex and triangles
tl and t 2 will be eliminated.

Figure 2. (i) Tu], edges incident on vertex

u (ii) [el, triangles incident on edge e. (iii)
Le],vertices associated with e (iv) [ [ U ] ] , triangles incident on vertex w (v) L[u11, vertices
associated with vertex v (vi) [le)], edges associated with edge e (vi) [[lej11, triangles associated with edge e.

uses an error metric that is defined as the average distance
fkom the proposed new triangles in the mesh to a set of
sample points on the original model. This algorithm produces high quality results, but several distance-to-surface
measurements make it quite slow. Gueziec [5] defines a tolerance volume as a convex combination of spheres located
at each vertex of the simplification. He selects edges based
on shortest edge length and then chooses a new vertex position such that the original surface is guaranteed to lie within
that volume. This algorithm also produces good quality results, and appears to be somewhat slow, but it is faster than
Progressive Mesh [ 6 ] .

3

Overview of our Algorithm

We adopt the definitions of simplex operators 11 and 11
as given in [7], see Figure 2. Our simplification method,
like most related algorithms is a simple greedy procedure.
It involves the following steps:
i) It computes cost of collapse for each edge in the surface model using our proposed error metric and determines the sequence of edge collapses in increasing
order of the magnitude of the cost of edge collapse.

Another common and generally less expensive approach
is to define error metric using local surface properties. Ronfard and Rossignac [ 121 assign to each vertex the set of
planes associated with its incident triangles. As a result of
one edge collapse operation, two vertices are merged into
one and the new vertex inherits the planes of the merged
vertices. The maximum distance from the new vertex to
its supporting planes is used as an error metric to measure
the edge collapse cost. Garland and Heckbert [4]used this
work as the starting point of their own simplification algorithm. Instead of maintaining a list of planes, they measure
the squared distance from the collection of planes associated with triangles incident on a vertex and store them as
a symmetric 4 x 4 matrix, one matrix per vertex. While
their approach is fast and gives high quality approximations; it is not memory effic.ient; for each vertex it stores
ten floats. The Memoryless algorithm recently developed
by Lindstrom and Turk [7,S:l uses linear constraints, based
primarily on conservation of volume, in order to decide the
edge collapse sequence and the position of the new vertex.
The most interesting aspect of this algorithm is that it makes
decisions based purely on the current approximation alone;
All other algorithms mentioned above keep track of some
kind of geometric history. It produces good quality simplifications and is fairly efficient, particularly in memory consumption. But it is rather slow as compared to QSlim [4].

ii) It chooses an edge e = { W O , V I } with the minimum cost
of simplification and substitutes it either with W O or V I .
During this operation triangles e become redundant
and are discarded. The remaining edges [ Le] -{e} and
triangles [[le]]] - [el incident upon vo and V I are
updated such that all occurrences of W O (or u1) are replaced with u1( or WO).

1

1

iii) The cost of collapse for the edges fleJ1 - { e } is
reevaluated and the sequence of edge collapses is updated
Most of the simplification algorithms based on iterative
edge collapse involve this basic structure. We have preferred to use subset-replacement or hawedge collapse as
a topological operator in our algorithm because this causes
the vertices of the simplified mesh to form a proper subset of the original set of vertices. This makes progressive
transmission of meshes more effective and is crucial for integrated level of detail.
The most important task of a simplification algorithm is
to assign a cost of collapse to each edge in the mesh to form

465

a sequence of edge collapses. Many authors have proposed
various error metrics. Some of them measure global error,
are very sophisticated [5,6]. and result in high quality simplifications, but have very high computational cost. Some
others are based on local error and give rise to very fast algorithms [9, IO, 131 but result in approximations which deviate substantially from the original. Recently some error
metrics have been developed which stand in between these
two extremes [4,7,8]. The primary motivation behind our
work is also to develop an error metric which leads to an
algorithm which have a good trade off between accuracy,
time complexity and memory consumption. In section 4,
we have proposed a new error metric to achieve this goal.
The basic achievements of our algorithm are as follows:

Memory consumption: it is one of the important factors
that effects the efficiency of an algorithm. Our algorithm does not consume extra memory other than that
is necessary to store the basic geometrical and topological information of a mesh. Memory consumption
is less than half as compared to QSlim [4].

0

Computational time: our algorithm is little bit slower
than QSlim,.but is faster than Memoryless Simplification [7,8].

4

(ii)

(9

Figure 4. (i) When edge e, is collapsed, triangles to,t l , t2 are moved to t b , t:,ti and edges
eo, e l , e 2 , e3 are displaced to eh, e{ , e;, e$ respectively. (ii) Triangle t will fold over when
edge e will collapse.

Accuracy: Simplificationsresulted from our algorithm
are comparable with those by standard methods such
as QSlim and Memoryless Simplification. It preserves
the essential features of a model even after significant
reduction.

.

,

0

Figure 3. (i) Error triangle (ii) Two positions
of an adjacent triangular face before and after
an edge collapse

Error Metric

will reduce only redundancy in the mesh and will not introduce any error. In this situation Q(v) must assume zero
value but practically it does not happen. So as a remedy to
this drawback, we weight Q(v) yith the angle B between
the triangles t = (vg,v1 , vp) and t = (01, v2,v ) see Figure
3(ii).
This choice of weights has another added advantage.
Note Figure 4(ii), foldings may appear when an edge to be
collapsed is surrounded by a very concave polygon. When
edge e , = {VO, v } collapses and vo coincides with v , triangle t = (vo,211 , v2) will fold over, thus creating folds in
the mesh. In this situation, the angle between the triangles
t = (WO,V I , v2) and = (u1, v2, v) will bear greater value
and will cause to add greater value to the cost of edge collapse thereby preventing this edge collapse.
The cost of collapse of an edge will be the weighted sum
of errors associated with each edge in 1.r - e,, i.e.

We have defined an error metric based on the observation that when an edge collapse operation takes place, some
edges from 1Le] undergo displacement and some triangles
from [[Le] 11 undergo angular displacement, see figure 4(i).
The area of the triangle defined by the old and displaced
positions of an adjacent edge and the collapsed edge e , and
the angle between the old and the rotated adjacent triangles
reflect the error which will be introduced in the model as a
result of an edge collapse.
To be precise, when edge e , collapses, vo will move towards v and will coincide with U, see Figure 3(i). At the
same time, edge e01 = {vo,VI} will sweep an area equal to
the area of triangle t* = (UO,v1 , U ) . This area reflects the
introduced error. Thus error associated with edge eo1 is as
follows.
Qe,, (VI =
x bl
where a = v o - v l , : a n d b = v - v l .
In some cases, this may not measure simplification error
accurately. For example, when all triangles in 1 v 1 are
coplanar or nearly coplanar, then edge collapse operation

1

41.

X
Cost(e,) =

QeQe

(v).

e € [ v l -e,

r 1

To preserve the geometry of a model, it is necessary

466

than Memoryless Simplification. Of course, SFME is not
faster than QSlim, but it consumes less memory than QSlim
because the latter stores 10 floats per vertex.
To eliminate bias, we use Metro tool [2] to determine
the quality of simplified models created by SFME. Graphs
shown in figures 6-9 illustrate the mean geometric and maximum geometric errors, measured by Metro, between the
original and the simplified models. We plotted 1000 times
the ratio of the error and the bounding box of the original model along logarithmic y-axis and the number of faces
along logarithmic x-axis. It is apparent that our algorithm
is almost as accurate as QSlim in terms of mean geometric error and compare well with both QSlim and Memoryless Simplification in terms of maximum geometric error.
Keeping in view these and the results reported in [7], we
can claim that our method compare well with standard simplification algorithms in terms of mean and maximum geometric error.
Simplified models shown in Figures 10-14 demonstrate
that how fairly our method preserves the essential features
of a model. All the major details of the original model remain even after significant simplification. Observe model
depicted in Figure 12, it is simplified model of horse consisting of 1398 triangular faces, 1.4 % of the original. Despite this drastic simplification, ears, contours on rear leg,
nostrils and hoofs are apparent. Figure14 show the model
of hand simplified to 0.65% of the original. It can be seen
that major features of the original models remain in spite of
being highly simplified.

Figure 5. Face vertices will be collapsed first,
then edge vertices arid lastly corner vertices.

71.33

32.75

Table 1. Time taken in seconds to reduce to
one face.

that theflat vertices i.e. the vertices for which [rvll are
nearly coplanar, must be removed first; then the edge vertices vi , i.e. the vertices along a feature edge of an object
and for which triangles [[vi11 can roughly be divided into
two groups according to thcir orientation, can be removed
and their collapse must be along the feature edge. The removal of a corner vertex, i.e. the vertex at a sharp corner
of the surface, will certainly effect the geometry of the object model and so it should Ibe the least to be removed. Our
proposed metric causes to keep track of this hierarchy and
preserve the visual appearance of the model, as is obvious
from Figure 5.

6 Conclusion and Future Work
We have presented a polygonal simplification method
based on a new measure of approximation error. Our
method has very good trade off between memory consumption, computation time and accuracy. It can simplify huge
models in relatively short time.
The quality of simplifications is good. It preserves the
essential features of an object even after significant reduction. The polygonal simplification is NP hard problem [I I],
so no one of the existing methods can be regarded as the
best one. Each of these has some added advantages over the
others. Our algorithm is faster than Memoryless Simplification and consumes less memory as compared to QSlim.
It is useful for applications that require good visual fidelity,
but not tight error bounds. We intend to extend it to include
boundary constraints and surface attributes.

5 Discussion
We have tried our implementation of our algorithm
(SFME) on several large triangular models and have
achieved encouraging results. To evaluate our method, we
make comparison with QSlim [4] and Memoryless Simplification [7] because among the existing standard simplification algorithms, the former is the fastest one and the latter
generates better quality simplifications and can reduce very
large models efficiently. We: choose horse and hand as test
models because of their complex structure.
Table 1 lists the computation time taken by QSlim and
SFME to simplify horse and hand models shown in figures
IO- 14. Notice that our algorithm is almost two times slower
than QSlim. We run both the algorithms on 800MHz Intel
PentiumIII machine with 384 MB of main memory. From
the results reported in [7] , it is obvious that Memoryless
Simplification is about 5 tirnes slower than QSlim; so we
can safely conclude that our inethod is about 2.5 times faster

References
[ l ] A. Ciampalini, P.Cignoni, C. Montani, and R.
Scopigno. Multiresolution decimation based on global
error. The Visual Computer, 13:228-246, 1997.

467

Figure 6. Mean geometric error for hand
model

Figure 8. Maximum geometric error for horse
model.

Figure 7. Mean geometric error for horse
model

Figure 9. Maximum geometric error for hand
model

[2] P. Cignoni, C. Rocchini, and R. Scopigno. Metro:
Measuring error on simplified surfaces. Computer
Graphics Forum, 17(2):167-174, June 1998.

fion and Computer Graphics, 5(2):98-115,April-June
1999.

[9] Maria-Elena Algori, and F.Schmitt. Mesh simplification. Computer Graphics Forum, 15(3), August 1996.,

[3] J. Cohen, A. Varshney, D. Manocha, G. Turk, H. Weber, P. Aganval, F. Brooks, and W. Wright. Simplifi-

Proc. Eurographics '96. 1996.

cation envelopes. In Proc. SIGGRAPH'96, pages 119-

[IO] S.Melax.
polygon

A.
simple
fast
and
efficient
reduction
algorithm.
Game Developer,
pages
44-49, November
1998.
http://www.gdmag.com/backissuel998.htm#nov98.

128,1996.
[4] M.Garland, and P.S.Heckbert. Surface simplification
using quadric error metric. In Proc. SIGGRAPH'97,
pages 209-216,August 1997

[ 1 I ] Pankaj K., Agarwal, and Subash Suri. Surface approximation and geometric partitions. In Proc. 5th ACMSIAM Sympos. on Discrete Algorithms, pages 24-33,

[SI A. GuCziec. Locally toleranced surface simplification.
IEEE Transactions on Visualization and Computer
Graphics, S(2): 168-189,April-June 1999.

1994.

161 H.Hoppe. Progressive

meshes. In Proc. SIGGRAPH'96, pages 99-108,August 1996. http:// re-

[I21 R. Ronfard and J. Rossignac. Full range approximation of triangular polyhedra. Computer Graphics Forum, 15(3), 1996.Proc. Eurographics '96, 1996.

search.microsoft.cod"hoppe/

[7] P. Lindstrom, and G. Turk. Fast and memory efficient polygonal simplification. In Proc. IEEE Visualization '98, pages 279-286,Oct. 1998.

[ 131 J.C.Xia, and A. Varshney. Dynamic view-dependent
simplification for polygonal models. In Proc. Visualzzaion '96, pages 327-334,Oct. 1996.

[8] P. Lindstrom, and G . Turk. Evaluation of memoryless simplification. IEEE Transactions on Visualiza-

468

Figure I O . Original horse model with 96,966
faces

Figure 13. Original hand model with 654,666
faces

Figure 1I.Simplified model with 3996 faces

Figure 14. Simplified model with 4266 faces.
Figure 12. Simplified models 1396 faces.

469

