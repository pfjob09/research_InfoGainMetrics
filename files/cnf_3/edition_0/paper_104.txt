2012 16th International Conference on Information Visualisation

Satellite and Aerial Image Mosaicing
A Comparative Insight
Samy Ait-Aoudia, Ramdane Mahiou, Hamza Djebli, El-Hachemi Guerrout
{ s_ait_aoudia, r_mahiou, h_djebli, e_guerrout}@esi.dz
ESI - Ecole nationale Supérieure en Informatique, BP 68M, O-Smar 16270 Algier
distinctive. Points, line segments, curves are among the
characteristic features generally used in image matching (see
[Brown et al. 2007], [Harris et al. 2008], [Lee et al. 2008],
[Behrens et al. 2010]).

Abstract. Image registration or image stitching is a central
operation in many useful and important tasks in image
processing like maps construction, scanning large
documents and panoramic photos creation. In particular
image mosaicing is used to assemble several overlapping
images in order to constitute the global frame. We will focus
on a feature-point matching method to perform the
mosaicing. The SIFT algorithm is used to extract the feature
points in both images. The mosaicing result is obtained after
transforming the sensed or target image to align to the
reference image. Performing a mosaicing operation is not
sufficient to claim reaching the goal. Objective metrics must
be used to evaluate the resulting mosaic. In this paper we
present a complete mosaicing system named EsiReg and give
a brief comparative insight on results of stitching satellite
and aerial images using well known performance metrics.
Keywords. Registration, mosaicing, Satellite and Aerial
Images, Performance metrics, SIFT.
I.

In this paper we will focus on image mosaic or
mosaicing that is widely used in remote sensing. Its main use
is the registration of two or more images of the same scene,
partially overlapping, to yield an integral representation of
the scene. The focus is on aerial and satellite images. We
will rely on SIFT (Scale Invariant Feature Transform)
([Lowe 2004)] a robust algorithm for extracting features
points from reference and sensed images. The features are
invariant to image scale and rotation, and are shown to
provide robust matching ([Schwind et al. 2010]). Estimation
of the transformation or mapping function is performed
using the random sample consensus algorithm (RANSAC).
The overlapping area in the mosaic result can present a
significant brightness difference with the rest of the mosaic.
To attenuate this effect, we will use methods called blending
techniques. These techniques are used to “smooth” the
overlapping area. Performing a mosaicing is not sufficient
to claim reaching the Grail. Objective metrics must be used
to evaluate the resulting mosaic. For that purpose, we use
RMSE (Root Mean Squared Error) and Ground truth MSE
(Mean Squared Error) metrics.

INTRODUCTION

Registration methods are increasingly used by many
image analysis and processing systems. In general,
registering two images consists of transforming the sensed or
target image to align to the reference or source image.
Registration has many applications in broad fields. In
medical imaging systems, registration is used to match
anatomic structures from two or more images (CT, MRI,
PET …) taken at different times to track for example the
evolution of a disease. Image registration is also utilized in
the creation of panoramic or wide photos by stitching the
separate pieces. Well known earth viewers use registration to
allow the visualization of the earth by sticking aerial or
satellite images.

This paper is organized as follows. We present in
section II a complete mosaicing system named EsiReg1. A
detailed example is given in this section. In section III, we
give the definition of the performance metrics used
throughout this paper. Experimental results of mosaicing
aerial and satellite images are given in section IV.
Comparison with results given by the ImReg2 system is also
given in this section. Section V gives conclusions.

Registration techniques can be classified into two large
categories that are intensity based methods and feature based
methods. Detailed concepts and definitions on image
registration techniques can be found in [Brown 1992],
[Zitova et al. 2003], [Xiong et al. 2010]. Registration
intensity based methods use pixels intensities in image areas
to match or overlap the source and target images. Standard
similarity measures such as mutual information criteria or
correlation ratio are used to achieve the matching. Such
methods are often used in medical images. On the other
hand, feature based techniques perform by extracting
characteristic features from images and use these features to
carry out the registration. The features may be highly
1550-6037/12 $26.00 © 2012 IEEE
DOI 10.1109/IV.2012.113

II.

ESIREG AN IMAGE MOSAICING SYSTEM

In this section we will give an overview of our
mosaicing system called EsiReg. Figure 1 summarizes the
operation of the EsiReg system. Four major phases that are
feature point extraction, correspondence between points,
transformation parameters estimation and blending
constitute the core of EsiReg. A discussion concerning the
setting of some key parameters concludes this section. A

1
2

652

http://imase.esi.dz/
http://vision.ece.ucsb.edu/registration/

detailed example taken from [Jianchao 2001] will be given
throughout this section to explain each step of the process.
Figure 2 and figure 3 show the reference image and the
sensed images respectively.

Reference Image

Target Image

Feature Point Extraction

Feature Point Extraction

Figure 4 shows the feature points (red and green colored)
detected on both the reference and sensed images. The
distinctive colors used will be explained in the next section.

Correspondence between points

Transformation Parameters Estimation

Figure 2. Reference image.
Registered Image

Blending

Enhanced Registered Image

Figure 1. EsiReg system overview.

A. Feature Point Extraction
SIFT (Scale Invariant Feature Transform) ([Lowe 2004]) is
used to extract feature points. The features points are
invariant to image scale and rotation, and are shown to
provide robust matching. SIFT algorithm is described by the
following four major stages:
•

Scale-space extrema detection: This first step consists in
searching candidate points (local extrema) by traversing
the scale space. It is implemented by using DoG
(Difference of Gaussian). DoG guaranties feature point
identification invariant to scale and orientation.

•

Feature points localization: The first step yields too
many candidates. Non stable points must be rejected.
Feature points are selected based on measures of their
stability.

•

Orientation assignment: One or more orientations are
assigned to each feature point location based on local
image gradient directions.

•

Feature point descriptor: The local image gradients are
measured at the selected scale in the region around each
feature point. These are transformed into a
representation that allows for significant levels of local
shape distortion and change in illumination.

Figure 3. Sensed Image.
B. Correspondance between points
After detecting the feature points, the next step consists in
selecting the corresponding feature points in the reference
and sensed images. This correspondence can be done by
several means. Shortly described, a similarity measure
([Wen et al. 2008]) is calculated and only feature points with
a similarity under a predefined threshold are selected.
Figure 4 shows the corresponding feature points red colored
in both the reference and the sensed images. The green
colored feature points are rejected.
C. Image transformation
The sensed image must now be transformed so as to align to
the reference image. Given the various distortions that may
exist between the images to register, many types of
transformations can be used (rigid, affine and projective).
The parameters of the transformations are defined based on
the correspondence between the selected feature points in
both images.

653

Figure 5 shows the resulting mosaic. The sensed image was
transformed to align to the reference image.

a.

D. Blending
As we can see in figure 5, the transition on the mosaic is
rather brutal and unaesthetic. This is due to the difference of
lightening between the two images. To attenuate this effect,
a treatment called blending is performed. Different
techniques may be used. The basic technique consists in
averaging the intensities of the pixels of the overlapping
area. A drawback of this simple method is sometimes the
blurring of the overlapping area. For our purposes, we have
used two powerful techniques to achieve this goal: Graph
cuts based method and gradient based method.
Figure 6 and Figure 7 show the enhanced mosaic using
graph cuts based method and gradient based method
respectively. In the performed tests the blending using
gradient based method gives the best results on the mosaic.

Reference image

b. Sensed Image
Figure 4. Corresponding features points in red.

Figure 6. Blending using graph cuts.

Figure 5. The mosaicing result.
The parameters of the transformation are estimated by using
the least square method:

Min¦ ri ² = (T ( xi ) − x'i ²
i



ǣ   
  ǯǣ      

Figure 7. Blending using gradient.

654

E. Parameters setting
In the registration process many parameters are to be set.
The success or the failure of the registration depends on
these parameters. These settings depend on the nature of the
images being processed. In this section we will focus on the
characteristics of aerial and satellite images and will be
interested on two parameters Peak-Threshold and DistanceThreshold.
The Peak-Threshold in the SIFT algorithm is used to filter
peaks that are less than a predefined SIFT threshold. The
Distance-Threshold parameter is used to eliminate the false
correspondences. A matching between points is accepted
only if the Distance-Threshold is less than the Threshold of
correspondence.
Aerial images ([Matungka 2009], [Shao et al. 2008]) present
clear structures easily detectable. Satellite images, on the
other hand present diffuse structures hard to detect. A
statistical study of the registration tests conducted on both
aerial and satellite images led us to set the two considered
parameters to the values given in table 1.
Aerial Images

Satellite Images

SIFT threshold

12

6

Correspondence
threshold

0,5

0,7

B. Ground Truth MSE
The ground truth MSE (Mean Square Error) metric is
calculated over intensities of pixels in the overlapping region
([Azzari et al. 2008]). If IC and IT denotes respectively the
mosaic under evaluation and the ground truth mosaic, MSE
metric is defined as follows:

MSE =

1
M

¦D
x, y

=

1
M

¦ (m

C

( x, y ) − mT ( x, y )) ²

x, y

IV.

EXPERIMENTAL RESULTS

The evaluation of the mosaicing is made on sample data. In
this section, we show our results on five examples given
hereafter. The first four examples are taken from the Vision
3
Research Lab (University of California at Santa-Barbara).
The fifth example is taken from Satellite Image
4
Corporation .

PERFORMANCE METRICS

Performing a registration with “success” is not sufficient to
claim achieving the goal. Objective metrics must be used to
evaluate the resulting mosaic ([Paalanen et al. 2009]). We
will focus on two metrics widely used called RMSE (Root
Mean Squared Error) and Ground Truth MSE (Mean
Squared Error). These two metrics are somehow different in
the sense that RMSE is not the root of the MSE metric. in
the scientific literature, RMSE is used in real cases when no
ground truth mosaic is available and MSE is used when the
intended mosaic is known in advance.

ImReg

EsiReg

Example #1

1,25

0,29

Example #2

1,64

1,24

Example #3

0,81

0,24

Example #4

1,78

0,7

Example #5

failed

0,12

Table 2. RMSE values
Table 2 shows the values of the RMSE obtained by the
online demo of the ImReg system and our EsiReg system.
On these tests, EsiReg performs globally better than ImReg.
ImReg even fails on the fifth example (this failure was also
reported by yasein [yasein 2008]).
For the Ground Truth examples we have taken images from
5
Computer Vision Laboratory (University of Bologna, Italy).
The mosaics of two specific examples are illustrated in this
section. The first example is a series of three aerial images.
The resulting mosaic is given in figure 8. It yields 34,3 for
the value of MSE.

A. RMSE
Assuming the coordinates of a pair of correspondence points
are (xi, yi) in the reference image and (ui, vi) in the sensed
image. The distance Di between a point in the reference
image and the corresponding point after transforming the
sensed image is:

Di =

xy

where
mC(x, y) and mT (x, y) are corresponding pixels in IC, IT
M is the number of pixel belonging to overlapping region

Table 1. Parameters setting
III.

1 k
¦ [(U i − xi )² + (Vi − yi )²]
k i =1

RMSE =

[(U i − xi )² + (Vi − yi )²]

(U i , Vi ,1) = T (u i , vi ,1)
If k is the total number of matching points in the reference
and sensed images, then RMSE is defined as:

3

ttp://vision.ece.ucsb.edu/registration/demo/examples.shtml
http://www.satimagingcorp.com/gallery-landsat.html
5
http://vision.deis.unibo.it/MosPerf/MosPerf-Home.aspx
4

655

Reference Image

Mosaicing Result

Target Image

#1

#2

#3

#4

#5

656

[3] M. Brown, D.G. Lowe, “Automatic Panoramic Image
Stitching using Invariant Features”, International Journal of
Computer Vision 74(1), 59–73, 2007.
[4] A. Behrens, H. Rollinger, “Analysis of Feature Point
Distributions for Fast Image Mosaicing Algorithms”, Acta
Polytechnica Journal of Advanced Engineering, Vol. 50 No.
4/2010.
[5] M.A. Fischler and R.C. Bolles, ”Random Sample Consensus:
A Paradigm for Model Fitting with Applications to Image
Analysis and Automated Cartography”, in Comm. Of the
ACM, vol. 24, June 1981, pp. 381–395.

Figure 8. Mosaicing three aerial images.
The second example is a series of nine satellite images. The
resulting mosaic is given in figure 9. It yields 39.56 for the
value of MSE.

[6] C. Harris, M. Stephens, “A combined corner and Edge
Detector”, PhD thesis, University of Victoria, Canada, 2008.
[7] Y. Jianchao, “Image registration based on both feature and
intensity matching”, IEEE International Conference on
Acoustics, Speech, and Signal Processing, 2001 Vol 3. 2001.
[8] D.C. Lee, O.S. Kwon, K.W. Ko, Y.H. Ha, “Image mosaicing
based on feature points using color-invariant values”, Proc.
SPIE 6814, 681414 (2008).
[9] D.G. Lowe, “Distinctive Image Features from Scale-Invariant
Keypoints”, International Journal of Computer Vision 60(2),
91–110, 2004.
[10] R. Matungka, Y.F. Zheng, R.L. Ewing, “Aerial image
registration using Projective Polar Transform”, IEEE
International Conference on Acoustics, Speech and Signal
Processing, 2009. ICASSP 2009.
[11] P. Paalanen, J.-K. Kämäräinen, H. Kälviäinen , “Image Based
Quantitative Mosaic Evaluation with Artificial Video”, 16th
Scandinavian Conference, SCIA 2009, Oslo, Norway, LNCS
5575/2009, pp. 470-479, June 2009.
[12] G. Shao, F. Yao, M.J. Malkani, “Aerial image registration
based on joint feature-spatial spaces, curve and template
matching”, International Conference on Information and
Automation, 2008, ICIA 2008.

Figure 9. Mosaicing nine satellite images.
V.

CONCLUSION

[13] P. Schwind, S. Suri, P. Reinartz, A. Siebert, “Applicability of
the SIFT operator to geometric SAR image registration”,
International Journal of Remote Sensing, Volume 31, Issue 8,
March 2010 , pages 1959 - 1980

This paper presents a complete image mosaicing system
called EsiReg. The mosaic results are refined by the
blending operation. We attempt to evaluate the mosaicing
results by using well known performance metrics. The first
conducted tests show promising results. Nevertheless,
further works must consider various types of images in the
comparison and confront the results to other image
mosaicing systems. A statistical study must be made to draw
final conclusions.
VI.

[14] G.J. Wen, J.J. Lv; W.X. Yu, “A High-Performance FeatureMatching Method for Image Registration by Combining
Spatial and Similarity Information”, IEEE Transactions on
Geoscience and Remote Sensing, Vol. 46, N°. 4 , pp. 1266 –
1277, April 2008.
[15] Z. Xiong, Y. Zhang, “A critical review of image registration
methods”, International Journal of Image and Data Fusion,
Volume 1, Issue 2 June 2010 , pages 137 - 158

REFERENCES

[1] P. Azzari, L. Di Stefano, and S. Mattoccia, “An Evaluation
Methodology for Image Mosaicing Algorithms”, J. BlancTalon et al. (Eds.): ACIVS 2008, LNCS 5259, pp. 89–100,
2008.

[16] M.S. Yasein, “New Methods for Image Registration and
Normalization using Image Feature Points”, PhD thesis,
University of Victoria, Canada, 2008.

[2] L.G. Brown, “A survey of image registration techniques”,
ACM Computing Surveys, 24, 4, pp. 325-376, 1992.

[17] B. Zitova, J. Flusser, “Image registration methods: a survey”,
Image and Vision Computing volume 21 (2003) 977–1000.

657

