2012 16th International Conference on Information Visualisation

Graph Decomposition using Self-Organizing Trees
Nhat-Quang Doan, Hanane Azzag, Mustapha Lebbah
LIPN-UMR 7030
University of Paris 13 - CNRS
99, av. J-B Celment
F-93430 Villetaneuse, France
Email: ﬁrstname.lastname@lipn.univ-paris13.fr

numerical and visual results in Section III. In the ﬁnal Section
IV, we draw our conclusions and perspectives.

Abstract—In this paper, we present a new approach for graph
decomposition using topological and hierarchical partitioning of
data. Our method called GD-SOM-Tree (Graph Decomposition
using Self-Organizing Trees) is based on self-organizing models.
The beneﬁt of this novel approach is to represent and visualize
hierarchical relations which replace the original graph with a
summary and gives a good understanding of the underlying
problem.

II. S ELF - ORGANIZING T REES MODEL FOR GRAPH
DECOMPOSITION

Our model seeks to ﬁnd an automatic clustering that provides a new decomposition of graph using a self-organizing
map. The main idea of our algorithm is to cluster the node of
the graph by creating a new clear structure. In order to not lose
the main structure of the graph, we propose to reorganize each
cluster using tree structure, where each node of tree presents
a vertex in the original graph. In another way, our algorithm
allows simultaneously to cluster and to decompose the input
graph in a 2D map whose cells possess tree-like structures.
The tree nature of the data structure is particularly attractive
in many applications.
To describe our approach, ﬁrstly, we will introduce the basis
of Self-Organizing Map that we have used. As traditional selforganizing map, we assume that the lattice C has a discrete
topology deﬁned by an indirect graph. Usually, this graph is
a regular grid in one or two dimensions. We denote K the
number of cells in the map C. For each pair of cells (c,r) on
the map, the distance δ(c, r) is deﬁned as the length of the
shortest chain allowing to link cell r and c. If the cells are
associated with trees, this leads to the concept hierarchical
structure. In this lattice each unit c ∈ C represents a tree
structure denoted by treec . The mutual inﬂuence is deﬁned by
the function KT (δ(c, r)) = exp( −δ(c,r)
) where T represents
T
the temperature that controls the size of the neighborhood.
Let G(V, E) an input graph, where V is a set of vertices and
E a set of edges. A direct link between two vertices vi ∈ V
and vj ∈ V creates an edge (vi , vj ) ∈ E. Following spectral
graph theory [7], [8], we take the ﬁrst d smallest eigenvectors
of the Laplacian. Instead of having n × n dimensional space,
we have n observations in d dimensional space. An element
xi = (x1i , x2i , ...., xdi ) ∈ X illustrates an vertex vi ∈ V . Since a
graph G is now mapped in feature space X, therefore G can be
clustered and visualized using our self-organizing process. The
basic principle of tree construction is inspired from the selfassembly rules of AntTree method [4]. Connection of a node
to another one in tree structure is based on their similarity. In
order to present the new cost function we denote by :
• treer : the tree structure associated to each cell r. Each
node of tree presents a node of the input graph vi .

Keywords-Graph clustering and decomposition, Graph visualization, Hierarchical tree, Self-organizing models

I. I NTRODUCTION
The initial goal of this work is to present a novel algorithm for graph decomposition using topological clustering
and hierarchical approaches. The aim is to provide a new
representation that summarizes the original graph to help us
to fast visualize its components.
Much of the world’s interested data can be represented by
graphs. Mining a graph is to ﬁnd and extract useful information
lying within its vertices. Clustering algorithms can carry out
those tasks fast and simply. By the way, topology between
the vertices from the original graph might change after the
partition. Popularity and variations of clustering problem have
given birth to many methods. One of the most popular and
widely applied models is Self-Organizing Map (SOM) [1].
SOM is commonly employed to solve problems of graph clustering where the original data have high dimension in general
[2] [3]. SOM is able to preserve the topological properties of
data using a neighborhood function. Based on the topological
map provided by SOM, our study is now interesting in the
decomposition and the summarization of original graph in a
2D topological map. This map is represented as a grid where
each cell contains the drawing of a tree. Each node of tree
corresponds to a node in the graph [4]. Our approach allows a
simultaneous visualization into: topological and hierarchical.
Most of work in graph summarization suggests to reduce the
size of graph by grouping similar nodes in the same cluster
[5]. Other works propose compression techniques that consists
of choosing supernodes and superedges in original graph [6].
In this paper, we will reveal how to use a new graph clustering
for tree construction in order to decompose the original graph
and easily visualize the summarized graph.
The remainder of this paper is organized as follows: Section
II is devoted to our model. We present the experiments with
1550-6037/12 $26.00 © 2012 IEEE
DOI 10.1109/IV.2012.49

246

treevi : the subtree of data, which have vi as root and
all nodes recursively connected to it (treevi ⊂ treer ).
• wr is the leader point (or prototype) of treer .
The objective function of self-organizing map using tree
structure is written as follows:

neighbor.
3. Optimization step: assuming that φ is ﬁxed, this step is
necessary to locally minimize R(φ, W) with respect to W
in the space Rd . It is easy to see that this minimization
allows to deﬁne the prototype for each treec using Equation 4.
Instead of centroids we choose leaders [9] as the representative
vertices for all the vertices of a graph. Leader is referred to
the node vi ∈ V ( xi ∈ X) that have the highest degree in
original graph G.

•

K

K

R(φ, W) =

K(δ(φ(treevi ), r))||xi − wr ||2

c=1 vi ∈treec r=1

(1)
where W = ∪K
r=1 wr and φ is the assignment function of tree.
It is clear that using statistical characteristics provided
by trees (associated to each cell) allow to accelerate the
convergence of the algorithm. Minimizing the cost function
R(φ, W) is a combinatorial optimization problem. In this
work we propose to minimize the cost function in iterative
process with three steps:
1. Assignment step: assuming that W is ﬁxed, we have
to minimize R(φ, W) with respect to φ. This leads to use
assignment Equation 2. An observation is assigned to its
nearest prototype (or tree). To take advantage of the tree
structure, the assignment function is deﬁned as follows:

wr = arg

KT (δ(r, c)) xi − wc

2

III. E XPERIMENTAL RESULTS
In order to evaluate and compare experimental results,
we have used three databases where data have known
labels: Adjective and Noun, Football Teams, Political
Blogs. The studied databases are all available at http://wwwpersonal.umich.edu/ mejn/netdata/. All of them are undirected
graph. Database features are presented in Table I. Their
description is as following:

(2)

•

c=1..k

2. Tree construction step: In this step we seek to ﬁnd
the best position of a given data xi (vi ∈ V ) in the treec
associated to cell c. We use connection / disconnection rules
inspired from AntTree [4]. The particularity of the obtained
tree is that each node N whether it is a leaf or an internal
node represents a given data xi . In this case, Nxi denotes
the node that is connected and associated to the data xi ,
Nxpos represents current node of the tree and Nxi+ the node
connected to Nxpos , which is the most similar (closest by
distance) to Nxi . TDist (Nxpos ) is the highest distance value
which can be observed among the local neighborhood Nxpos .
xi is connected to Nxpos if and only if the connection of Nxi
further increases this value:
TDist (Nxpos )

=

M axj,k Nxj − Nxk

=

M axj,k xj − xk

2

(4)

A. Datasets

and
r

(deg(vi ))

where the local degree deg(vi ) is the number of internal edges
incident to vi in original graph G.

∀vj ∈ treevi , φ(treevi ) = φ(xj ) = φ(xi )
φ(xi ) = arg min

max

∀vi ∈treer ,vi ∈V

•

•

2

(3)

Adjective and Noun: An adjacency network of common
adjectives and nouns in the novel David Copperﬁeld by
Charles Dickens introduced by [10] where each node
corresponds to a word whose type is either ”adjective”
or ”noun”.
Football Teams: The network of American football
games between Division IA colleges during regular season Fall 2000 [11]. Vertices in the graph represent teams,
while edges represent regular-season games between the
two teams they connect.
Political Blogs: A directed network of hyperlinks between webblogs on US politics, recorded in 2005 by
Adamic and Glance [12]. The vertices are the blogs
retrieved from Internet. If a blog cited by other, an edge is
created. There are only 2 classes, the number of citations
(≥ 17 or < 17) in a blog decides the label of blog.

B. Experimental protocol
In this experiment, we ﬁrst compare efﬁciency of different
clustering algorithms: MST (Minimum Spanning Tree) that
builds tree structures [13] and Self-Organizing Maps (SOM).
In the case of SOM we adopt the same parameters
• the shape of map’s topology is rectangular. Cluster must
have at least one node, that said there is no empty cell.
• the size of map is respectively selected 3 × 3 (k = 9
clusters) for ”Adjective and noun”; 5 × 3 (k = 15) for
”Football Teams”; 5 × 5 (k = 25) for ”Political blogs”.
The motivation is to choose the map size superior to the
number of class for each labeled data set; as for others
we want to make large maps that are able to cover graph
space.

In other words, connection rules consist of comparing a
node Nxi to the nearest node Nxi+ . In the case where
both nodes are sufﬁciently far away ( Nxi − Nxi+ 2 >
TDist (Nxpos )) then the node Nxi is connected to its current
position Nxpos .
Otherwise, the node Nxi associated to
data xi is moved toward the nearest node Nxi+ . Therefore,
the value TDist increases for each node connected to the
tree. In fact, each connection of a given data xi implies a
local minimization of the value of the corresponding TDist .
Therefore a minimization of the cost function (1). At the end
of the tree construction step, each cell c of the map C will be
associated to a treec . Connection rules are based on nearest
neighbor approach. Each data will be connected to its nearest

247

TABLE I
DATA F EATURES
Datasets
Adjectif and Noun
Football Teams
Political blogs

# nodes
112
115
1490

# eges
425
616
19090

# classes
2
10
2

TABLE II
P ERFORMANCE OF QUALITY CRITERIA ON THE SELECTED DATASETS
Method

d

SOM
MST
GD-SOM-tree

5
5
5

SOM
MST
GD-SOM-tree

5
5
5

SOM
MST
GD-SOM-tree

5
5
5

Accuracy
NMI
d
Accuracy
Adjective and noun (map size: 3 × 3)
0.574
0.073
11
0.576
0.553
0.290
11
0.562
0.565
0.115
11
0.560
Football Teams (map size: 5 × 3)
0.568
0.505
11
0.406
0.330
0.299
11
0.400
0.880
0.687
11
0.878
Political Blogs (map size: 5 × 5)
0.861
0.064
39
0.827
0.530
0.148
39
0.512
0.854
0.168
39
0.767

NMI
0.072
0.280
0.134
0.544
0.313
0.685
0.056
0.141
0.178

the two criteria with both cases of d (Accuracy = 0.880 and
NMI = 0.687 using the ﬁrst 5 smallest eigenvectors of the
Laplacian). And on ”Political blogs”, we obtained a good
result of GD-SOM-tree in NMI. The purpose through this
comparison, is not to assert that our method is the best, but
to show that GD-SOM-tree method can obtain quite the same
good results as other clustering algorithms.
The Normalized Mutual Information is given by the following expression:

select
√ a number of ﬁrst smallest eigenvectors (λ =
{5, n}, n is the number of nodes) of the regularized
Laplacian.
• perform 10 different random initializations for each run
of two algorithms: SOM and GD-SOM-tree.
For MST, we build the proximity graph using Prims
algorithm [14] from the distance between observations. Then
the k − 1 longest edges are removed from the proximity
graph in order to obtain k separated clusters. Unlike others,
MST build one invariable tree which resulted in the obtained
clusters to be independent from the random initialization.
•

NMI =

N.nl,k
k nlk log2 ( Nl∗ N∗k )
Nl∗
N∗k
l Nl∗ log2 ( N )(
k N∗k log2 ( N )
l

(

(5)

The Accuracy is deﬁned as follows:
C. Numerical results
I=

To evaluate the performance, we selected two different
criteria, each of them should be maximized: Accuracy and
Normalized Mutual Information [15]. Given a set of N objects
of L classes classiﬁed into K clusters and two partitions to
compare: X = {x1 , .., xN } where xk ∈ [C1 ..CK ] a random
variable for cluster assignments, Y = {y1 , .., yN } where
yl = [B1 ..BL ] a random variable for the pre-existing labels.
Hence, the contingency table can be expressed as in Table III:
First of all, the quality of the clustering heavily depends on
the choice of d, but we intend to optimize neither the value of
d, the map size nor their inﬂuence to quality measures. In this
experimental section, we perform some experiments in order
to evaluate and compare our method along with others such
as traditional SOM and MST.
In Table II, we can notice that our approach provides comparable results. The performance values show that the quality
measures for SOM and GD-SOM-tree are mostly equal. On
”Adjective and Noun” dataset, the clustering quality of MST
appears much more better. GD-SOM-tree produces satisfactory
results. On ”Football” dataset, the proposed method dominates

k

maxl=[1..L] (nlk )
N

(6)

D. Graph visualization
We present in this section different views of the decomposed
and summarized graph. The main advantage of GD-SOMTree is to simultaneously propose a multi-level decomposition:
hierarchical and topological. These structures simplify the
exploitation of the graph by offering friendly and interactive
visualization. We used Tulip software [16] as the framework
to visualize and analyze the experimental results. We provide
here three types of view:
1. Default view (Figure 1a, 2a and 3a): the graph is
drawn from the original collection of edges and
vertices. We want to discriminate leaders from other
nodes, the size of leaders nodes varies with the value
of degree. The leader node is represented with symbol L.
2. Decomposition view (Figure 1b, 2b, and 3b): This view
shows a new organization of graph which is easier to
analyze than the default organization. The map nodes

248

TABLE III
C ONTINGENCY TABLE
R\C
B1
B2
..
.
Bl
..
.
BL
Sum

C1
n11
n21
..
.
nl1
..
.
nL1
N∗1

C2
n12
n22
..
.
nl2
..
.
nL2
N∗2

···
···
···
..
.
···
..
.
···

Ck
n1k
n2k
..
.
nlk
..
.
nLk
N∗k

(a) Default clusters view
Fig. 1.

···
···
···
..
.
···
..
.
···

CK
n1K
n2K
..
.
nlK
..
.
nLK
N∗K

Sum
N1∗
N2∗
..
.
Nl∗
..
.
NL∗
N

(b) Summarized view given by GD-SOM-tree

Graph visualization of ”Adjective and noun”. Each color represents one cell of the map.

(a) Default clusters view
Fig. 2.

(b) Summarized view given by GD-SOM-tree

Graph visualization of ”Football”. Each color represents one cell of the map.

249

(b) Summarized view given by GD-SOM-tree

(a) Default clusters view
Fig. 3.

Graph visualization of ”Political blogs”. Each color represents one cell of the map.

(a) ”Adjective and noun” : 3 × 3 GD-SOMTree map with strong links.

(b) ”Football” : 5 × 3 GD-SOMTree map with strong links.

(c) ”Political blogs” : 5 × 5 GD-SOM-Tree
map with strong links.
Fig. 4.

GD-SOM-tree topological map view.

250

with black color are located in the center surrounded by
trees. We have the same number of trees as the map size
deﬁned a prior. A tree including its root is attached to
the respective map node.

[5] S. Navlakha, R. Rastogi, and N. Shrivastava, “Graph summarization with
bounded error,” in SIGMOD Conference, 2008, pp. 419–432.
[6] H. Toivonen, F. Zhou, A. Hartikainen, and A. Hinkka, “Compression
of weighted graphs,” in Proceedings of the 17th ACM SIGKDD
international conference on Knowledge discovery and data mining, ser.
KDD ’11. New York, NY, USA: ACM, 2011, pp. 965–973. [Online].
Available: http://doi.acm.org/10.1145/2020408.2020566
[7] F. R. K. Chung, Spectral Graph Theory (CBMS Regional Conference
Series in Mathematics, No. 92). American Mathematical Society, Feb.
1997.
[8] U. Luxburg, “A tutorial on spectral clustering,” Statistics and Computing,
pp. 395–416, December 2007.
[9] A. Stanoev, D. Smilkov, and L. Kocarev, “Identifying communities
by inﬂuence dynamics in social networks,” CoRR, vol. abs/1104.5247,
2011.
[10] M. E. J. Newman, “Finding community structure in networks using the
eigenvectors of matrices,” Phys. Rev. E, vol. 74, p. 036104, Sep 2006.
[11] M. Girvan and M. E. J. Newman, “Community structure in social and
biological networks,” Proceedings of the National Academy of Sciences,
vol. 99, no. 12, pp. 7821–7826, Jun. 2002.
[12] L. Adamic and N. Glance, “The political blogosphere and the 2004 u.s.
election: Divided they blog,” in In LinkKDD 05: Proceedings of the 3rd
international workshop on Link discovery, 2005, pp. 36–43.
[13] O. Grygorash, Y. Zhou, and Z. Jorgensen, “Minimum spanning tree
based clustering algorithms,” in Proceedings of the 18th IEEE International Conference on Tools with Artiﬁcial Intelligence, ser. ICTAI ’06.
Washington, DC, USA: IEEE Computer Society, 2006, pp. 73–81.
[14] R. C. Prim, “Shortest connection networks and some generalizations,”
Bell System Technology Journal, vol. 36, pp. 1389–1401, 1957.
[15] A. Strehl, J. Ghosh, and C. Cardie, “Cluster ensembles - a knowledge
reuse framework for combining multiple partitions,” Journal of Machine
Learning Research, vol. 3, pp. 583–617, 2002.
[16] D. Auber, “Tulip : A huge graph visualisation framework,” in Graph
Drawing Softwares, ser. Mathematics and Visualization, P. Mutzel and
M. J¨unger, Eds. Springer-Verlag, 2003, pp. 105–126.

3. Topological view : In addition, we provide in this paper
for graph allowing quick indexation of data (Figure 4).
The expert can investigate the associated nodes and their
connection to outside clusters. Thus, we introduce two
notations: strong link (pink) and weak link (gray). A weak
link is created between two neighborhood leaders in term
of topology. If an edge from the original graph is joined
by a couple of leaders located in two neighboring cells,
we consider this edge as a strong link. The size of cell
node is adjusted to the number of nodes assigned to this
cell. Node colors correspond to tree colors deﬁned default
view.
After studying the obtained decomposition we notice that
visual results given by our method lead to important insight
on the graph content. Our approach tries to improve the
standard visualization by building topological and hierarchical
ordered clusters. Atypical nodes are clearly pinpointed with
this approach and can be further studied by the analyst. The
decomposition provides a clear visualization in which the
analysts can easily navigate. A hierarchical visual exploration
is provided by topological level to the last level of trees provide
useful information graph.
IV. C ONCLUSION
We show in this paper how we have applied GD-SOMTree for graph decomposition and visualization. This novel
method provides local hierarchical trees of data allowing better
visualization of original graph organization. Our model offers
a new visualization space using a new graph clustering. GDSOM-Tree generates both 2D structured trees and topological
map. The beneﬁts of our approach allow the user to fast
analyze with different views of summarized graphs. We also
ﬁnd that this method works moderately well with several
real world datasets. As future work, we want to study an
incremental graph decomposition. We will show how subgraphs evolve over time. Another perspective is to study
biological and biomedical graph. Several problems can be
faced with hierarchical structure in the case of expressed
genes.
R EFERENCES
[1] T. Kohonen, M. R. Schroeder, and T. S. Huang, Eds., Self-Organizing
Maps, 3rd ed. Secaucus, NJ, USA: Springer-Verlag New York, Inc.,
2001.
[2] R. Boulet, B. Jouve, F. Rossi, and N. Villa, “Batch kernel som and
related laplacian methods for social network analysis,” Neurocomputing,
vol. 71, no. 7–9, pp. 1257–1273, March 2008.
[3] D. Macdonald and C. Fyfe, “The kernel self-organising map,” in
Knowledge-Based Intelligent Information and Engineering Systems,
2000, pp. 317–320.
[4] H. Azzag, G. Venturini, A. Oliver, and C. Guinot, “A hierarchical ant
based clustering algorithm and its use in three real-world applications,”
European Journal of Operational Research, vol. 179, no. 3, pp. 906–922,
June 2007.

251

