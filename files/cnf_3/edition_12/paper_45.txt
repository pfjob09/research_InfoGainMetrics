Automatic Generation of Hair Texture with Line Integral Convolution
Xiaoyang Mao, Makoto Kikukawa, Kouichi Kashio and Atsumi Imamiya
Department of Computer and Media Engineering
Yamanashi University, Japan
{mao, kiku, koh I , imamiya) @esi.yamanashi. acjp
appearance of the mapped hair texture according to the
change of view point a n d the lighting conditions.
To overcome these problems, we propose in this paper
a new solid texturing technique for automatically
generating hair textures directly on the 3D models of
human characters. Our idea was inspired by the similarity
between the texture of human hair and the texture
generated with the Line Integral Convolution(L1C)
algorithm[7], a flow visualization technique being widely
noticed recently. The proposed technique generates the
texture of human hair by using the vector field defining
the directions of hair strands as the input to the 3D LIC
algorithm[9]. A sketch based interface is provided for
allowing users to easily specify or modify the directions
of hair strands
Next section briefly surveys the existing hair image
synthesis techniques and introducing the LIC algorithm.
Section 3 describes in details how to generate the hair
texture with the 3D LIC and briefly describes the
interface for specifying the direction of hair strands.
Section 4 addressing the implementation issue and
demonstrates some images generated with the new
technique.

Abstract
Synthesis of hair image is one of the most important
and challenging computer graphics problems. In this
paper, we propose a new technique for automatically
generating realistic human hair texiure on the 3 0 models
of human character. The idea is inspired by the similarity
between the texture of human hair and the texture
generated with the LIC algorithm. The proposed
technique generates the texture of human hair by using
the vector field defining the directions of hair strands as
the input to the 3 0 LIC algorithm.

1. Introduction
Needless to say, hair is one of the most important visual
elements featuring a human character. Although a number
of novel techniques have been developed[ 1-61, modeling
and rendering human hair remains to be one of the most
difficult problem in the field of computer graphics. The
difficulty of hair image synthesis is inherently caused by
the properties of hair, such as the huge number of hair
strands, the extremely small diameters of hair stands
compared with image pixels, and the complex interaction
of light and shadow among hair strands. Current progress
of virtual space construction technique and the wide
spread of multimedia application systems such as video
game present a new challenge to the hair image synthesis.
In those applications, real time rendering of realistic
image is of most importance so as to achieve a high
interactivity and make users immersed into their virtual
environment. A simple but commonly used technique in
those applications is to model the hair style as part of the
3D polygon model of a human character, and then use the
hardware supported texture mapping facility to map a hair
texture onto the surface of the 3D model. The hair texture
used are usually obtained either by taking the picture of
desired hair style o r manually created with some 2D
painting software. In either case, however, establishing a
natural and correct mapping between the 2D hair texture
and the 3D model is usually a difficult task. In many cases,
the UV data for the mapping can only be manually
generated as the result of a long try-and-error process.
Moreover, it i s usually i m p o s s i b l e t o c h a n g e t h e

2. Back ground
2.1 Related work
All Existing hair image synthesis techniques can be
classified to be either of explicit model or volume density
model. The explicit model[ 1-51 represents individual hair
strand with some geometrical object, such as a connection
of cylinders, a curved polyline or a connected segments of
triangular prism. Those approaches are considered to be
suitable to the applications where modeling of hair motion
is required. Dynamic simulation of hair behavior can be
performed by taking into consideration the properties of
hair and the effects of external forces, such as gravity and
wind, at the vertices consisting the geometry objects of
hair strands[2,4]. On the other hand, however, such kind
of brute-force methods usually suffers from two serious
problems inherently caused by the special properties of
human hair. One such problem is the high computational
cost due to the large number of hair strands required for

303
0-7695-0743-3100$10.00 0 2000 IEEE

the global property, as well as the details of local
structures of a vector field. Researches have been carried
out for improving the computational efficiency of LIC[S]
and for extending the original 2D algorithm for 3D
surfaces[9].

generating a realistic image. Typically, there can be
10,0000 to 150,000 individual hair strands on a human
scalp. The other is the aliasing problem. The diameter of a
human hair can be as thin as 0.05 mm and hence can be
less than the size of a pixel for most practical scenes.
Although several techniques have been developed for
partially solving these two problems[ 1,3], they remain to
be the major reasons preventing the explicit model based
approaches being widely used in the real applications. In
stead of individual hair strand, the volume density model
represents the entire hair style macroscopically as a 3D
distribution function of hair density. Perhaps the most
famous and successful example of volume density model
is the texel technique developed by Kajiya and Key for
rendering fur-like objects[6]. Although the resulting
image of the teddy bear is spectacular, the volume ray
tracing of the texel volumes can be too time consuming.
Moreover it is not clear how the technique can be applied
to long human hair and how the texel volume data itself
can be generated.

(4

':

(b)

2.3 Similarity between LIC texture and hair
texture

(4

Figure Line integralconvolution.
(a) vector
field (b) input white noise (c) output image.

Why do we come to the idea of using LIC for the
synthesis of human hair textures? To answer this question,
let us look at the two images shown in Figure 2. Figure
2(a) is a photo of human hair. Taking a glance at the photo,
we get the impression of long hair strands combed to flow
in a certain direction. However, if we look at the photo
more carefidly by zooming into any local area of it, we
can find the direction of hair strands and the intensity of
pixels varies randomly. The variance of intensity on the
picture is caused by the complex interaction of light and
shadow among the hair strands of varying directions and
densities. The LIC image shown in Figure 2(b) presents
the very similar property as the hair picture. Since an LIC
image is obtained by low-pass filtering the input image
along the streamlines of a vector field, we can see long
strokes in the directions of streamlines. On the other hand,
the intensities of pixels within any local area vary
randomly as the input image to the LIC was a white noise.
Such similarity between the output textures of LIC and
the picture of human hair suggests us that we can imitate
the rendered image of human hair with an LIC texture and
thus can avoid the complex shading calculation required
for generating a real hair image.

2.2 Line integral convolution

Line Integral Convolution(L1C) is a texture based
vector field visualization technique which was first
presented by Cabral and Leedom in 1993[7]. Given a
vector field represented as a regular Cartesian grid, the
LIC algorithm takes as input a white noise image of the
same size as the vector field and generates an output
image wherein the texture has been locally blurred in the
direction of the vector field. There is a one-to-one
correspondence between the grid cells of the vector field
and the pixels of input and output image. To decide the
value for each pixel in the output image, a local
streamline passing through the corresponding grid cell in
the vector field is generated. Then a one-dimensional lowpass filter kernel is defined on the local streamline and the
pixels lying on the streamline in the input image is
convoluted with the low pass-filter kernel. Figure I(c)
shows an LIC image generated with the vector field
shown in Figure l(a) and the input white noise shown in
Figurel(b). LIC is now attracting large attentions as an
effective visualization technique being able to reveal both

(4

@)

Figure 2: Comparison of a hair texture and an
LIC texture. (a) hair texture (b) LIC texture.

304

3. Generating hair image with LIC

int Noise(float x,y,z)

3.1 Solid texturing of human hair with 3D LIC

int i;
i = INDEX[Lx] & OxOOOOOOffl + INDEX[Ly] & OxOOOOOOffl

Given a 3D model of a human character together with
the vector field representing the directions of hair strands
on the scalp, our new technique generates the hair texture
on the 3D model directly by using the 3D LIC algorithm,
which was previously developed by Mao, e t al. for
visualizing the flow on a 3D surface[9]. The input to the
3D LIC algorithm is a 3D triangle mesh with vectors
stored at its vertices. Here the vector stored at each vertex
represents the local direction of hair strands. Figure 4(a) is
an example of the input 3D model. Figure 3 depicts the

+ INDEX[L~]&oxoooooofq ;
retwn (WHITE-NOISE[i YOTABLEN]);

c

Here, WHITE-NOISE is a table of randomly generated
binary noise values and TABLEN is the size of the
TABLE. INDEX contains pseudo-random integer values
as the indirectional table of indices to the table
WHITE-NOISE. Figure4 (b) is the solid noise generated
on the 3D model of Figure 4(a) and the resulting hair
textures are shown in Figure 4(c) and (d). The detailed

View point
Figure 3: Generating hair texture directly on a 3D
model with 3D LIC algorithm.

principle of the algorithm. For a given view point and
lighting condition, to generate the hair texture on the
surface of a 3D model, we shoot a ray from viewpoint
through each screen pixel into the 3D surfaces. Only at
the visible ray-surface intersections, we calculate the local
streamline lying o n the 3 D surface and perform the
convolution of 3D white noise values and a low-pass filter
kernel defined along the local streamline. Finally, the
ambient and specular components of the illumination
equation are evaluated with the lighting conditions and
sums together t o give the value o f the screen pixel.
The solid white noise value at a point P(x,y,z) on the
3D surface is evaluated procedurally with its coordinate
values using following hash-like pseudo-random function:

Figure 4: Generating hair texture with 3D LIC.
(a) input 3D model (b) solid noise
(c)(d) resulting hair textures.
method of streamline integration on a 3D surface can be
found in 191. During the integration of a streamline, the
vector at an arbitrary position is interpolated from the
three vectors stored at the vertices of the triangle
enclosing the position using the area weighted

305

interpolation method[9]. Only the vector component
tangential to the 3D surface is used in the streamline
integration. As the directions of hair strands near by are
usually strongly co-related, the interpolation of vector
field naturally resulting a realistic image. A user only
need to specify the direction of hair strands at few
representative positions as shown in Figure 4(a) and the
algorithm automatically interpolates those vectors to
generate the hair image of high density as shown in
Figure 4(c),(d) and Figure 6.

3.3 Results

3.2 Interactive hair style design tool

The 3D LIC algorithm for generating hair texture
directly on the surface of a 3D model is implemented as a
user module of commercial visualization software AVS'
and the interactive hair style design tool is implemented
using OpenGL graphics library. In Figure 4 we showed
the textures of short hair directly generated on the 3D
model of a human head. Figure 6 is the case where the
texture is generated on the 3D model of the long hair style.
As it can been seen kom Figure 6, with the specular effect,
we succeeded in creating the effect of glossy hair.

An interactive tool is also developed for allowing users
to design their own hair styles. With this tool, a user can
specify the growing area, the parting and the directions of
hair by painting curved lines on the 3D model directly,
just as they use pencil to sketch a hair style on a piece of
paper. To generate the hair texture on a 3D model, the
user is asked to specify the growing area and the parting
of hair(Figure 5(a)) first. Then a default vector is
generated for each vertex within the specified growing
area of hair(Figure 5(b)) by taking into consideration the
effect of gravity. Finally the user is allowed to modify the
direction of hair strands at an arbitrary position by
painting the new direction at the position(Figure 5(c)).
The 3D model can be rotated interactively and users can
sketch on the 3D model from any angles they like. Each
line segment of a specified polyline is projected back onto
the 3D surface based on the current viewing parameters of
the 3D model and is taken as the vector at the nearest
vertex of the 3D model.

Figure 6: Generating hair texture on the 3D model
of a long hair style.

Figure 5: Sketching a hair style with the
interactive design tool. (a) specification of the
growing area and the parting of hair (b) default
directions of hair strands (c) specifying or
modifying the directions of hair strands

Figure 7: Different images obtained by adjusting
the parameters of LIC algorithm.

AVS is a trade mark of Advanced Visual System Inc

306

Figure 7 demonstrates how we can easily achieve some
different hair images simply by adjusting the parameters
of the LIC algorithm. For example, using more white
pixels in the input white noise results in the image of the
white mustache(1eft image), shortening the length of local
streamline results in the image which looks more shortly
cut(midd1e image) compared with the image shown in
Figure 4(c) and (d), using white noise of coarse
granularity results in an image of lager hair wisp(right
image) compared with image shown in Figure 6.
The execution time for generating the images shown
here is about 10 seconds on a SGI 0 2 work station with a
R5000 I8OMHz CPU. Although the 3D LIC algorithm is
view dependent and can not make use of texture mapping
hardware, we have developed several techniques to
improve the execution speed of the algorithm[ 101. First,
an extension to the fast LIC algorithm developed by H.
Battke, et al. [8] is used for streamline integration and the
convolution of white noise and low pass filters. Second,
as only the visible ray-surface intersection is required, it
can be quickly obtained by utilizing graphics hardware.
Instead of calculating all the ray-surface intersection in a
brute force way, we first render the 3D model with
graphics hardware, Then the visible ray-surface
intersection can be easily calculated from the value in the
2-buffer and the position in the frame buffer, as the Zbuffer should hold the Z coordinate and the position in the
frame should be the X,,Y coordinate of a visible raysurface intersection. H. Battke, et al.[ 1 I ] developed a
technique which pre-computes the LIC texture for a 3D
surface and packs the texture into texture memory so as to
take the advantage of texture mapping hardware for high
speed rendering. Using such technique makes it possible
for our hair texture generation algorithm to be used in real
interactive applications.

4. Conclusion and future work
This paper has presented a new method for
automatically generating the hair texture on the 3D model
of human character using existing line integral
convolution algorithm. An interactive design tool which
allows users to directly sketch their own hair styles on the
3D models of human characters is also presented.
Modeling the avatars in a virtual communication system
can be a promising application of the proposed technique.
As the texture is generated procedurally on the fly, our
technique does not requires the transference of large raster
data of hair texture together with the UV data for
performing the texture mapping. The only data required is
the vector data representing the directions of hair strands
at some representative positions. One important future
work is to further improve the image quality. For example,
we need to deal with those area at the boundary of hair
and skin specially to have the result look more like a real

hair image, By taking into consideration the directions of
hair strands in shading calculation, we may be able to
generate other effects such as the high light like a halo.
We are currently developing an image-based hair
modeling system which automatically constructs the 3 D
model of hair style and the direction of hair strands from
2D pictures.

Acknowledgements
The authors would like to thank Issei Fujishiro from
Ochanomizu University for his helpful comments and
continuous support. This work was partially supported by
Telecommunications Advancement Organization of
Japan.

References
A. M. LeBlanc, R. Turner and D. Thalmann,
“Rendering Hair using Pixel Blending and Shadow
Buffers”, The .Journal od Visualizatioii arid
Cowlpiiter Animation, Vol. 2, PP. 92-97, 1991.
R.. R. Rosenblum, W. E. Carlson and E. Tripp 111,
“Simulating the Structure and Dynamics of Human
Hair: Modeling, Rendering and Animation.”, The
Journal of Visualization and Computer Animation,
Vol. 2, PP. 111-118, 1991.
Y.Watanabe & Y.Suenaga, “A Trigonal Prism-Based
Method for Hair Image Generation”, l E E E
Computer Graphics & Applications, pp47-53,
January 1992.
K.Anjyo, Y.Usami and T.Kurihara, “A Simple
Method for Extracting the Natural Beauty of Hair”,
Cornpuler Graphics, Vo1.26, No.2, pp I 1 1 - I 20, July
1992.
JL. Chen, S. Saeyor, H. Dohi and M. Ishizuka, “A
System of 3D Hair Style Synthesis based on the
Wisp Model”, Visual Computer; Vol. 15, PP. 159170, 1999.
T.Kajiya & T.L.Kay, “RENDERING FUR WITH
THREE DlMENTlONAL TEXTURES”, Computer
Graphics, Vol.23, No.3, pp271-280, July 1989.
B. Cabral and C. Leedom, “Imaging Vector Field
Using Line Integral Convolution”, SIGGRA PH93
Proceeding, pp263-270, 1993.
H. Battke, D. Stalling, H-C. Hege, “Fast Line
Integral Convolution for Arbitrary Surfaces in 3 D 7 ,
SIGGRA PH9.5,~ ~ 2 4 9 - 2 5 1995.
6,
X.Mao, M.Kikukawa, N.Fujita, A.lmamiya, “Line
Integral Convolution for Arbitrary 3D Surfaces
though Solid Texturing”, In Proceedings of 81h
Eurograhics Workshop on Visualization in Scientific
Computing, pp67-76, 1997..

[ I O ] N. Fujita, M. Kikukawa, X. Mao and A. Imamiya,
“Acceleration of Solid Texturing-Based 3 D LIC”, In
Proceedings of IASTED International Conference
on Computer Graphics and Imaging, pp175-178,
1998.
[I I ] H. Battke, D. Stalling, H-C. Hege, “ Fast Line
Integral Convolution for Arbitrary Surfaces in 3D’,
In Visualization and Mathematics, PP. 181- 195,
1997.

308

