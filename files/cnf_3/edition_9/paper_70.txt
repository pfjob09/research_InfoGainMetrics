Visualising and Sharing Human Performance Anlaysis Knowledge
Ian Douglas
Learning Systems Institute/Computer Science
Florida State University
Innovation Park, 2000 Levy street,
Tallahassee, Florida, USA, 32310
idouglas@lsi.fsu.edu

Abstract
When professionals are given the task of analyzing a
domain, it is likely that it is not the first time this task has
been done. Rather than build upon what is already done
they will often redo the work. The key problem that
sustains this repetition of effort is the lack of a standard
and centralized way to communicate and share the
knowledge that results from the analysis. Software
architecture for reuse and sharing of analysis knowledge
is described, which incorporates a number of internet
technologies. The architecture is based around a visual
modeling scheme and can be configured to adapt to the
requirements of different organisational requirements.

1. Introduction
A number of domains involve the analysis of human
performance, for example operations research,
knowledge engineering, human factors engineering and
instructional design. There are many mechanisms for
doing knowledge analysis, and many possible formats for
documenting the resulting knowledge. If the output of
analysis work is in the form of documents which have no
defined standards and restricted distribution, it is difficult
to avoid replication of effort. In effect many hours of
intellectual effort are invested in rediscovering existing
knowledge.
There have been a number of attempts to describe
methodologies that support some form of reuse in various
domains, for example knowledge engineering [1,2,3],
software engineering [4], and human performance
analysis [5], but as yet there is no widely established
mechanism. Many of the approaches conceive of the
knowledge component or object as the end-product of the
analysis process.
The web potentially provides a vehicle to allow

reuse and sharing of knowledge, but current search
technology is of limited use. The increasing use of XML
and the move towards the concept of the semantic web
will improve this situation [6]; however, there is an
immediate need to improve using existing technology.
Packaging of knowledge into standardized reusable
objects in a central repository can help in the location of
relevant knowledge, especially when combined with
visual models and a collaborative environment.

2. Reusing analysis knowledge
There is currently much work involving the
technology, standards and repositories for what is often
termed learning objects [7,8]. These are essentially small
self contained units that can be assembled into learning
and support systems. The object approach seeks to
promote greater cost-effectiveness in learning systems
development through maximizing the reuse of existing
materials. This work is supported by consortiums of
learning organizations, and government initiatives, e.g.
the US department of defence’s advanced distributed
learning initiative (http://www.adlnet.org/). Resulting
from this work are clear technical standards for
packaging and meta-tagging knowledge content.
In addition to reusing and sharing content objects in
the building of solutions it also makes sense to package
and reuse the analysis of problems that led to the
production of the solution objects. It is anticipated that
repositories will become an increasingly prevalent means
of facilitating reuse in knowledge domains [9], they are
already having some impact on software development
[10]. Centralizing knowledge in repositories can reduce
the search space but can also result in systems that are
difficult to use and manage. One approach to dealing
with this problem is to structure the information within a
visual model. Visual modelling allows a system to be

Proceedings of the Seventh International Conference on Information Visualization (IV’03)
1093-9547/03 $17.00 © 2003 IEEE

viewed as whole while exposing more detail available on
demand for specific parts of the system [11]. Effective
models can also facilitate discussion among stakeholders
during an analysis process.
In textual presentations of analysis knowledge it is
often too difficult to get a good structured picture of the
system, its components and interactions. This problem
can be solved by creating standard notations to represent
diagrammatically the different categories of knowledge
and how they are related. Standard models with
appropriate data attached can contribute to a unified
understanding of a particular problem domain.
Van Heijst et al [12], in considering methodology for
reusable knowledge engineering, assert that it should be
based around task model, knowledge role and ontology.
Thus the components of the domain analysis are shared.
If this analysis is framed using standard object modeling
techniques there is the possibility for matching the
analysis components against any existing solution
components. This may help to speed the connection
between knowledge analysis and knowledge support
system development.

3. A visual notation for analysis
The unified modelling language (UML) has become
a widely used approach to object-based systems analysis
and design [13]. Although UML was originally
conceived to facilitate the modelling of computer
systems, it has been adapted to model other types of
systems [14]. An adaptation of part of this language, use
cases [5], is particularly suited for human performance
analysis. Use case notation has the advantage of being
easy to learn for non-technical stakeholders.
Rather than refer to ‘use cases’ which suggest a case
where someone uses a system, the term performance
cases is used in the current context. Performance cases
have two main graphical elements. Firstly, the stick
figure to represent a specific performance role, e.g.
customer service agent. Secondly, the ellipse to represent
a performance goal, which is a specific performance that
someone in the role can achieve in a particular situation,
e.g. open new customer account.
Performance case diagrams can be embedded within
each other, allowing knowledge analysis to start at a high
level and then focus down to a more detailed level. Thus
a high level performance case may be named ‘create new
bank account’, clicking on this case would open another
diagram that had more specific performance cases, e.g.
‘set-up overdraft facility’. At the lowest level a
performance case would contain data on what specific
knowledge and skills the person in the performance role
would need in order to achieve the performance goal.

Performance case models can provide a framework
for examining knowledge used in reaching performance
goals and storing metrics indicating different levels of
performance. The documentation for each performance
goal will provide the foundation for developing
knowledge-based systems, documentation, operations
redesign, training or any other form of human
performance support. The documentation will also help
analysts determine the levels of performance possible.
Different organizations, and different types of
analysts, may wish to set different standards for what is
documented within a performance case. Standards are
emerging that will allow the exchange of information
between organizations, for example one consortium is
looking at a standard for human competency description
[15]. However in the short term there are likely to be a
variety of different mechanisms. Inter-organizational
sharing may take some time to attain, but intraorganizational sharing is an achievable goal. In addition
to standards, technology that supports collaborative
analysis and sharing of knowledge is important. One
such approach is the automated object-oriented
performance analysis (AOOPA) system which
demonstrates a configurable architecture for supporting
analysis.
A high level view of the AOOPA system
architecture to facilitate reuse and sharing of analysis
knowledge is illustrated in Figure 1. The system is
project based and assumes a group of stakeholders are
focusing on the needs for a particular domain. The
system architecture is composed of three main sections.
These are the configurable user interface components;
web-services based middleware layer and the analysis
knowledge repository.
The system is designed to support various

Proceedings of the Seventh International Conference on Information Visualization (IV’03)
1093-9547/03 $17.00 © 2003 IEEE

Figure 1. Architecture for a system to support the
visualization and sharing of analysis knowledge

knowledge acquisition methodologies in the gathering of
analysis data. Each component can be independently
configured to suit the needs of a particular organization.
The user interfaces provide the structure for enforcing a
chosen methodology. Each interface interacts with the
same set of web services, allowing the information to be
reused across various methodologies with relative ease.
Additionally, the user interfaces can be written on a
number of different platforms. This allows the most
appropriate platform to be chosen in all cases.
The drawing tools used to create visual models are
currently written using a Windows based component.
Unlike traditional visual modeling tools, the output is not
stored in a local file; both the positioning of each
graphical element and the data associated with each
element are stored in a project database via a web
service. A collaborative interface is also available
through a web browser, see figure 2.

knowledge analysis process. Rather than invite a few
stakeholders to expensive face-to-face meeting, a
continual review of thinking can be conducted on-line
through the collaborative groupware.
Although the visual appearance of a diagram cannot
be changed, the image map allows online users to access
and edit all of the data that is associated with each
diagram element, see figure 3. The illustrated data is an
example of one type of analysis method that can be
linked to the illustrated performance goals.

Figure 3. An example of the information contained in a
performance case

Figure 2. A web view of a model accessible through
project groupware
The web-services exist to channel access to the
knowledge repositories and provide all of the business
logic and processing required for storing, searching,
retrieving, modifying and reusing the contents of the
knowledge repositories. It is the web services that enable
the configuration options for the system. The web
services provide a consistent API to which all the various
user interfaces must conform.
For example, one of the web services will take the
data from the database and generate a jpg file of the
current version of a diagram and an image map of the
relative position of all the model elements in the image.
This is then available to all the project team members
through a groupware facility accessible through a
browser. This enables collaborative analysis with a
number of participants providing perspectives on the
shared analysis data. If domain models can be developed
collaboratively on-line there is scope for greatly
increasing the involvement of stakeholders in the

The specific method is known as gap analysis, where
gaps are identified between the desired and actual
performance for a particular performance goal. The
groupware component of the system enables a threaded
discussion to be generated and linked to any element of a
diagram.
A support component of the architecture provides
advice on the process of analysis used in a particular
configuration. This functions as an independent resource
supporting those tasked with analysis, see figure 4. The
support system is accessed from other subsystems
through context sensitive links. Both the support system
and groupware are separate from the modeling tools to
enable the system to be configured to include
organizational specific tools. For example, in the current
configuration a commercial package for collaboration is
linked into the system.
Data from the project is stored in a project specific
database. In addition to a project specific database there
is a database repository that will act as a central store of
reusable analysis knowledge; this will allow sharing of
analysis knowledge across projects. The knowledge
repository can exist on one or more database servers. The
web-services provide the means to search and reuse
across multiple database servers. The analysis repository

Proceedings of the Seventh International Conference on Information Visualization (IV’03)
1093-9547/03 $17.00 © 2003 IEEE

contains links to reusable solution objects in a solution
object repository. Thus, if a new project team discovers
in the analysis repository some prior analysis of
relevance to the current problem, they will also discover
any components of a solution that resulted from the
analysis.

done in a distributed environment and increase
reusability when they know and record not only what the
modeled system is, but also why it was put together that
way and why other approaches/alternatives were
discarded.
Rationale management [17, 18] is concerned with
capturing the knowledge that leads to the construction of
a system. In particular, it requires an auditing of the
decision making when choosing problem solutions. Most
analysts will be able to produce reasons for their analysis
decisions; the distinction in giving a rationale is that there
should be the following:
x
x
x
x
x

Figure 4. An example of the customised support for a
specific methodology
It should be stressed that the creation of the models
is an on-going collaborative process. These models are
not meant to result in each goal being refined and
documented to the lowest level. Once created refinement
is an on-going process. Over time models will begin to
interlink within a central repository effectively creating a
comprehensive evolving model of knowledge within
different domains.
Completed models, model components and the
attached data, become artifacts that can be stored in the
central analysis repository. These artifacts will be
available to be reused and repurposed in the future. An
analysis team must be able to locate, understand, and
quickly integrate reusable knowledge into its own
analysis solution. Reuse mechanisms should go beyond
browsing, since browsing and searching capabilities in
the repository are not enough to ensure reuse [16]. It is
likely that users will be discouraged from using a
resource that requires a lot of browsing in order to
determine if relevant information exists. Automated taskaware, context sensitive search of the analysis repository
is possible. Thus, as soon as any new item is created in a
project, a web service will check the repository for the
existence of potential pre-existing artifacts or artifact
components that may be reused. The service alerts the
user when they enter the name of any element which
already has an entry in the centralized repository.
An important attribute of the system which is not
apparent in the model presented in figure 1 is rationale
management. Analysts improve coordination of work

A description of the issues that were addressed
prior to the design decision.
A list of the alternative solutions considered.
The criteria used in the selection.
The argumentation used to support each
alternative.
The decision.

The benefit of rationale management is that it
requires the knowledge analyst to make their decisionmaking explicit. It discourages decisions based on whim
or prejudice; as such decision making will not have a
clear rationale. Rationale management within the system
is handled in two ways, informally by collecting on-line
discussions in the context of the analysis models and
formally by requiring the ruling in and out of
performance goals during the development of diagrams.
The system automatically records the change history for a
given project.

4. Conclusion
Reuse is as important in analysis as it is in
construction. The Internet has the potential to greatly
widen the scope for collaborative creation and reuse of
analysis knowledge. Web-accessible repositories of
reusable knowledge, using agreed documentation
standards, are an important requirement for achieving
this. An easily understood graphical notation, is a key
component in structuring knowledge during analysis and
in resulting documentation. UML use cases notation is a
good candidate for this purpose.
In additon to a notation flexible technology is also
required to support groups of analysts, subject matter
experts and end-users in the development of models.
Such technology should be configurable to specific
methods and facilitate the identification of relevant
reusable knowledge from prior analyses.
The system architecture presented here includes a
system for modelling human performance, which can be

Proceedings of the Seventh International Conference on Information Visualization (IV’03)
1093-9547/03 $17.00 © 2003 IEEE

configured for a variety of purposes using different data
schemes. The system allows for collaboration and
sharing of knowledge. Using such a system over time
would lead to comprehensive and evolving models for
whole domains of expertise. This would provide a
framework for the reuse of previous analysis knowledge,
which can also be directly linked to related reusable
objects used in the design and construction of support
systems.

5. References
[1] L. Steels, “Components of expertise”. AI Magazine,
1990, 11 (2), pp. 30-49.
[2] B.J. Wielinga, A.T. Schreiber, and J.A. Breuker,
“KADS: A modelling approach to knowledge
engineering.” Knowledge Acquisition, 1992, 4(1), pp. 553.
[3] M. Musen, “Modern Architectures for Intelligent
Systems: Reusable Ontologies and Problem-Solving
Methods.” In: C.G. Chute(ed.), Proceedings of AMIA
Annual Symposium, Orlando, FL, 1998, pp. 46-52.
[4] I. Jacobson, M. Griss, and P. Jonsson, Software
Reuse: Architecture, Process, and Organization for
Business Success. Addison Wesley, Reading, Mass:1997.
[5] I. Douglas and S. Schaffer, “Object-oriented
performance analysis” Proceedings of the Interservice
/Industry Training, Simulation and Education
Conference (I/ITSEC), 2002, pp.367-377.
[6] T. Berners-Lee, Weaving the Web: The original
design and ultimate destiny of the world wide web.
Harper Collins, New York: 1999.
[7] I. Douglas, “Instructional design based on reusable
learning objects: applying lessons of object-oriented
software engineering to learning systems design”. IEEE
frontiers in education conference, 1999, F4E, pp. 1-5.
[8] D. A. Wiley, “Connecting learning objects to
instructional design theory: A definition, a metaphor,
and taxonomy”. In D. A. Wiley (ed), The Instructional
Use of Learning Objects. Available from:
http://www.reusability.org/read/

[9] T. Looms and C. Christenson, Emerging and
enabling technologies for the design of learning object
repositories. Advanced Distributed Learning Initiative.
Available from: www.adlnet.org.
[10] A.Milli and R.M.Mittermeir. “A survey of software
reuse libraries.” Annals of Software Engineering, 1998,
5, pp. 349-414.
[11] G.van Heijst, A.T. Schreiber and B.J. Wielinga,
“Using explicit ontologies in KBS development”.
International Journal of Human-Computer Studies,
1997, 46, pp. 183-292.
[12] M.Sierhuis, and A.Selvin, “Towards a Framework
for Collaborative Modeling and Simulation.” NYNEX
Science & Technology Technical Memorandum,
1996. Available from:
http://www.compendiuminstitute.org/compendium/paper
s/SierhuisSelvin-CSCW-1996.PDF
[13] G. Booch, “UML in action”. Communications of the
ACM. 1999, 42 (10), pp. 26-28.
[14] C. Marshall, Enterprise modelling with UML.
Addison Wesley, Reading, Mass: 2000.
[15] IMS Reusable Definition of Competency or
Educational Objective, 2002, Available from:
http://www.imsproject.org/competencies/index.cfm
[16] Y. Ye and G. Fischer, “Supporting reuse by
delivering task-relevant and personalized information.”
Proceedings of the Twenty-fourth International
Conference on Software Engineering, 2002, pp. 513523.
[17] J. Burge and D. C. Brown, “Reasoning with design
rationale.” In John Gero (ed.) – Artificial Intelligence in
Design 2000, Kluwer Academic Publishers, Dordrecht,
The Netherlands, 2000, pp.611-629.
[18] T.P. Moran and J.M. Carroll, Design rationale:
concepts, techniques, and use. Mahwah, NJ: Lawrence
Erlbaum Associates: 1996.

Proceedings of the Seventh International Conference on Information Visualization (IV’03)
1093-9547/03 $17.00 © 2003 IEEE

