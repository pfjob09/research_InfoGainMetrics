Using Motion Platform as a Haptic Display for Virtual Inertia Simulation

Zhijie Xu and Dave Taylor
School of Computing and Engineering
University of Huddersfield

Abstract
Haptic displays serve great importance in creating
the immersiveness sense that block Virtual Reality (VR)
users from the contradictory impressions from the real
world. This paper introduces the general structure of
Virtual Reality systems. It reports common approaches in
constructing different virtual scenarios and the way they
are utilised. The main objective of this project is to
integrate a motion platform with an application program
interface (API) based virtual environment authoriser to
provide force feedback for simulating inertia related
applications such as virtual gliding, driving, and
snowboarding.
Keywords: Virtual Reality, Haptic Device, Motion
Platform

1 Introduction
Virtual Reality (VR) and Virtual Environments
(VEs) have become media-focus for the last decade.
Whether we call it virtual reality, virtual environments, or
virtual worlds, this field encompasses an astonishing
range of multidisciplinary researches. This has enabled a
convergence of hardware and software, and of science,
engineering, and art, all in the service of real-time,
immersive and 3-dimensional (3D) interaction [1].
The question of whether desktop 3D environments
should be treated as true virtual environments has long
been debated. It is widely recognised, although having its
distinctive advantages especially cost effectiveness, a
desktop display (i.e., a PC monitor) hardly blocks out the
real world, does not present virtual-objects in life size,
and therefore does not create the illusion of immersion
[2]. In my view, a desktop VE display can be treated as a
dedicated graphics pipeline providing constant updates of
visual signals. Depending on how this environment was

interacted with, the system can be divided as a desktop
type (see through a window and communicated by mouse
and keyboard) or an immersive one (feeling presence and
visually and physically isolated from the real
environment).
Except visual displays, body and head tracking
interfaces, aural (acoustic) and haptic (force and touch
feedback) displays serve great importance in creating the
immersiveness sense that block VR system users from the
contradictory impressions received from the real world.
Figure 1 illustrates an integrated VR system where the
interaction with the environment was carried out through
innovative VR peripheral, such as Head-Mounded Device
(HMD), trackers, 3D acoustic devices and haptic displays.
Based on the data flow direction (going in or coming out
from the host computer), those devices can be divided as
input devices or output devices, where wired/wireless and
stand-alone/networked data channels will enable data
communications.

2 Literature review
Current virtual environment construction toolkits
can be classified as geometric library-based programming
functions, interpreted environment modelling scripts, and
of the most popular method, commercial VE authorisers.

2.1 Virtual reality modelling language
The Virtual Reality Modelling Language (VRML) is
a script language to describe VEs and has become an ISO
standard (International Standard ISO/IEC 14772) for
specifying 3D virtual worlds networked via the Internet.
The VRML environment on the World Wide Web
(WWW) can link to or be linked from other sources on
the Internet. VRML files describe 3D objects and worlds
using the hierarchical scene structure. The scene structure
contains nodes that describe objects and their properties.
It contains hierarchically grouped geometry to provide an

Proceedings of the Seventh International Conference on Information Visualization (IV’03)
1093-9547/03 $17.00 © 2003 IEEE

audio-visual representation of objects, as well as nodes
that participate in the event generation and routing
mechanism. Entities in a VRML program are referred as
nodes. VRML 2.0 defines 54 different node types,
including geometry primitives, appearance properties,
sound and sound properties, and various types of
grouping nodes.

2.3 API based approach
Application program interface (API) methods rely
on stand-alone or built-in 3D programming libraries or
interface functions that enable advanced users to write
system code using, say, C/C++ and Java languages. The
code developed by the users is normally built into an

Desktop VE

Integrated Devices
HMDs and CAVEs

Environment
Visualiser

3D Acoustic Displays
World
Editor

Communication
Interface
To Networks

Geometric
Modeller

Tracking Devices
Haptic Displays
Other Novel Displays
Volumetric Modellers

Figure 1 Immersive virtual environment structure

2.2 Graphical VE authorisers
Currently, the most common way to build a virtual
environment is using an environment authoriser, which is
a graphical user interface that works in a drag-and-drop
manner similar to an ordinary CAD system. For example,
the SuperscapeVRT is an integrated visual-based virtual
environment developing tool set. It consists of two
browser platforms (one for desktop application and one
for Internet usage) and a suite of seven editors. Virtual all
the development work involved in the process of
constructing an virtual environment can be completed in
the VRT, from creating 3D objects to organising their
spatial positions, from editing sound clips to painting
background images.
Similar to the VRT, Sense8 World Up is also an
Integrated Development Environment (IDE) from which
you create objects and properties, and design simulations.
WorldUp supports the import of 3D models from industry
standard modellers. To add behaviours to objects,
developers can author customer behaviours or change a
property of an existing behaviour by writing scripts using
the BasicScript language, or use property change events
to trigger behaviours.

executable program or a series of interpretable "class"
files that generates a dedicated virtual environment.
WorldToolkit (WTK) from Sense8 Co.Ltd is a
library of over 1000 functions written in C that enable
user to develop new virtual reality applications [3]. WTK
functions are organized into over 20 classes. These
classes include the Universe (which manages the
simulation and contains all other objects), Geometries,
Nodes, Viewpoints, Windows, Lights, Sensors, Paths,
Motion Links, and others. Functions are included for
things such as device instancing, display set up, collision
detection, loading geometry from a file, dynamic
geometry creation, specifying object behaviour,
manipulating textures, and controlling rendering. The
architecture of the WTK incorporates the power of scene
hierarchies which is a tree-like structure that manages all
the contents and contexts in a virtual environment. By
calling different functions, user can build a simulation by
assembling “nodes” into a hierarchical scene graph, which
dictates how the simulation is rendered and allows all of
the efficiencies of a state-preserving, stack-oriented
rendering architecture. Each “node” of the scene graph (or
scene graphs) represents part of the simulation. Other
commercial APIs include, Render386 API, MRToolkit
and Sun’s Java3D.

Proceedings of the Seventh International Conference on Information Visualization (IV’03)
1093-9547/03 $17.00 © 2003 IEEE

Except those commercial programming libraries
mentioned above, There are also various research-based
APIs reported, such as Metis [4] (a toolkit for building
immersive virtual environment developed in the
University of Maryland) and Maverik [5] (developed by
the Advanced Interface Group in the University of
Manchester).

2.4 Motion platform and its applications
Human motion sensing is based primarily on the
visual and vestibular systems with some contribution by
forces on the rest of the body [6]. One important
observation has been that impulse or changes to
acceleration is often more important than sustained
acceleration, particularly in combination with visual cues.
This leads to the extensive use of “onset cues” or short
bursts of acceleration followed by a gentle reduction in
force known as “washout”. This technique allows a
device with a relatively small range of motion to work
effectively. The forces on the rider are the sum of gravity
and the platform accelerations. Some sustained forces can
be achieved using gravity on a tilted platform. When a
sustained force is desired, a centrifuge or very large linear
device is required.
Motion Platforms are often characterized by the
range of motion, load capacity, degrees of freedom (DOF)
, and types of actuators used to move the platform. A 6
DOF motion platform provides limited linear (x/y/z) and
rotational (roll/pitch/yaw) motion. A common
configuration for these systems is the “Stewart Platform”
or “hexapod”, originally described by D. Stewart [7]. This
is a frame with six or more extendable legs (actuators)
connecting a fixed base to a moveable platform. An
“inverted hexapod” secures the upper platform to a frame
and allows the lower base to be moved. The most
common types of actuators are pneumatic, electrical, and
hydraulic. Hydraulic systems are more powerful and
accurate but also more costly. Pneumatic and Hydraulic
systems require compressors that may be noisy. Electric
systems are quiet but not nearly as responsive.
Motion platforms are mature products that have been
used on various areas including theme park rides and
aircraft simulators. Researchers in South Korea [8] have
been using motion platform for designing dual-projection
lightweight motion-based driving simulator. In 2000, the
IEEE VR conference had a dedicated haptic interface
panel where a series motion platform-based application
projects were presented, including “2D omni directional
treadmill-the TreadPort” [9], “Development of Ground
Surface Simulator for Tel-E-Merge System” [10], and
“Virtual Roller Coaster” [11].
In this project, an API (Sense8 WorldToolKit) based
environment construction and visualisation approach was
taken. So the simulation loop could be accessed regularly,

where data necessary for driving the motion platform
could be extracted and processed in real-time. The
objectives of this project are:
x to interface a third-party VE API with a motion
platform control program.
x to integrate a VE simulation loop with a motion
cycle of the platform
x to simulate inertial force feedback required by
various application scenarios
x to collimate visual displays and simulators to
provide high level realism at low acquisition and
life cycle costs.

3 VE-based inertial force feedback system
design
The system design included two phases, the first
stage was to set up the motion platform hardware, and
second phase was to synchronise the motion platform
control program with the VE API where environment was
constructed and other devices integrated.

3.1 Motion platform architecture
The system design requires the physical set up of the
electrical motion platform design and manufactured in the
Motionbase Co.Ltd. It has been installed in a dedicated
VR project room in the School of Computing and
Engineering at the University of Huddersfield. The
orientation of the motion platform’s top frame is
controlled by varying the length of one or more actuators
that connect the top and bottom frames. There are six
actuators on the installed platform. A brushless dc
servomotor whose rotary position is measured using an
optical encoder drives each actuator. Each motor is
controlled by its own servo-amplifier that is housed
within an electrical enclosure called the Motor Drive Unit
(MDU). Hall effect sensors within each motor allow the
amplifier to commutate the motor. The motion platform
control unit is connected with the host computer through
the Motion Control Card (MCC). The MCC is an
intelligent ISA based servo control card that resides
within the host computer. It occupies two full-length, full
height ISA slots and backplates within a host PC. In this
project the host computer for the motion platform is also
the host computer for generating and updating the
application environment.

3.2 System control mechanism
The manufacturer has provided Application
Programmer Interface (API) libraries in C format which
can be used to write a complete motion control program.
The DSP based MCC executes a control program that

Proceedings of the Seventh International Conference on Information Visualization (IV’03)
1093-9547/03 $17.00 © 2003 IEEE

implements various task-specific code blocks at different
stages, namely a few, servo loop closure, actuator state
limiting, profile generation, kinematic transformations,
filtering, and state machine.

of freedom (DOF) to actuator lengths. A state machine
(created when an application needs to communicate with
the platform) handles control of the motion base and
MDU from initial power up, through simulation and
shutdown. The state machine uses hardware inputs and

System Start

Visualiser Initialisation and Motion Platform Calibration

VE construction
MP Enter Start/Stop Mode
Reading Sensors

Calling Simulation Function
Generating Motion Cues

Updating Objects

Performing Individual Tasks

Playing Paths

Rendering Universe and Driving Motion Platform

Exit
Figure 2 Integrated simulation manager and operation loop
The API is bundled into two libraries. The first
library is an essential part of a host application. This
library contains functions that communicate with the
default motion control procedures. The second library is
an optional part of a host application. It contains
functions that read text-based parameter files into data
structures that may be subsequently downloaded to the
MCP. Each library is supported by a set of C header files
that include type definitions and function prototypes.
The kinematic transformation is automatically
carried out by the MCC and the host computer every time
a new set of motion data was extracted. It converts
platform positions and orientations expressed in degrees

data received via the API to determine when to make a
transition from one state to another.
In addition, the host computer will perform other
system tasks to those required by the motion platform,
including:
x construct and visualise application environment

Proceedings of the Seventh International Conference on Information Visualization (IV’03)
1093-9547/03 $17.00 © 2003 IEEE

x
x
x
x

control of an virtual environment simulation loop
implement application dynamic models
create Human-Computer Interface (HCI)
communicate with other system devices, i.e.
head tracker, Steering wheel, and joystick

x

set up and control of multimedia devices, i.e.
sound card

Figure 3 Snapshots of the glider VE

3.3 Application program infrastructure
There are certain tasks that a host computer and the
simulation manager of an application environment must
perform in order to support a motion platform. In this
research, it is achieved by accessing the WTK simulation
manager that dominates the simulation loop of the
application. A simulation manger looks after every aspect
of the simulation takes place in the universe. It is entered
at runtime by calling a WTK function –
“WTuniverse_go” - and is exited by calling
“WTuniverse_stop”. Figure 2 shows the default order of
events in the simulation loop. Once started, the simulation
loop does not exit until the stop function is called.
However, an application can obtain control through a
universe action function or through a task function
provided by WTK. The universe has a user-specifiable
action function set by calling “WTuniverse_setactions”,
which is called before the rendering occurs for each
frame. Individual objects can also have task functions,

which are called for the object once per frame. The
principle is similar to the “callback” or “event” functions
typically provided by a window management system.
When a WTK application is running, the simulation loop
is repeatedly executed. So in this program structure, the
motion platform is served with action data drawn from the
WTK simulation loop at runtime. It can be data worked
out by an equation describing an object’s behavior, or
data received from a tracking device, or consisted of
multiple data sources. Those data will be filtered, and
translated into the format the motion platform can
understand.
When executed, the application program will drive
the platform in following procedures. Firstly, parameters
must be read from a file (or using default parameter
values) to initialise the platform, including parking and
neutralising positions and filters. Secondly, platform’s
API function “initialiseStateMachine” will be called to
get the MCP running. And then, a function
“serviceStateMachine” are called regularly to serve data
to the motion platform. Finally, “shutdownStateMachine”
function is called to unload the MCP and reset the MCC.
The state machine attached to the application
program (generated by a motion control program) can
serve at a programmable frequency up to 150Hz, which
serves more than enough for the simulation rate (equal to
the frame rate) of a medium scale WTK environment. In
ordinary leisure applications, the state machine normally
run at the same rate as a media player at around 30Hz.

4 System implementation
A virtual glider simulation environment was
developed to test the system. The input device of the
environment – the control bar – was tested on a mock-up
at start, with life-size heavy-load metal hanging frame
mounted on the platform after the test.

4.1 Environment construction
The virtual gliding environment is composed of 3D
terrain, sky, river, helicopter, balloon and other
background objects. To increase the level of realism fog
node is also included and can be adjusted to simulate real
weather conditions. Most of the 3D models adopted were
created and exported from 3D Studio MAX. Figure 3
shows the simplified scene of the application environment
with a glider model and a terrain model. Models requiring
independent movements were encapsulated in the socalled “movnodes”, where translation and rotational
information were kept from other objects. However, the
lighting and misty states could still accumulate and
propagate along the scene graph tree.

Proceedings of the Seventh International Conference on Information Visualization (IV’03)
1093-9547/03 $17.00 © 2003 IEEE

Function Name
Glider_Up
Glider_Down
Glider_Left
Glider_Right
Collision_Detection
Switch_Viewpoints
Take_Off
Landing
Record_Path
Load_and_Play
Others

Actions
increase altitude,
reduce speed
descend and accelerate
steer to left
steer to right
check collisions
change viewpoint
initialise position and
speed
speed, altitude, and
posture checking
record flight path
playback
individual tasks

Arguments
sensor inputs (joystick)

Return Value
null

sensor inputs (joystick)
sensor inputs
sensor inputs
glider bounding box
viewpoint number
null

null
null
null
true/false
null
true/false

null

true/false

null
filename
n/a

true/false
true/false
n/a

Table 1 Virtual glider environment simulation functions
Some important features of the simulation are
designed as state variables in the program, for example:

The characteristics of the environment were
designed as WTK tasks or universal action functions in

Figure 4 The glider structure mock-up and control mechanism
x
x
x
x
x

Glider Position - current location in the world
frames
Glider Orientation – posture of the glider in
quaternion
Glider Speed – current glider speed
Air Speed and Direction – require complex
dynamic model to simulate (not used)
Viewpoint Mode – could be set as predetermined
static positions or attached with the glider (with
adjustable offset)

the program. As shown in the Table 1, these functions
when applied could change the values of state variables.

4.2 Data filtering and communication
In this integrated system, the motion platform is an
output device that provides force display to the system
user. The input of the system is gained through a gameport joystick (USB joystick is also applicable). The
hanging frame mounted on the MP’s top frame interacts

Proceedings of the Seventh International Conference on Information Visualization (IV’03)
1093-9547/03 $17.00 © 2003 IEEE

with the environment (projected on a large screen in front
of the platform) through changing the joystick’s position
parameters so it can be pushed forward/backward or
shifted along sideways. As shown in Figure 4, the glider
control bar and the joystick are connected by 4 strings
(with weak springs close to the joystick handle) from 4
perpendicular directions (2 DOF). The joystick is
calibrated at start to be position at centre to simulate the
initial orientation of the glider and to match with the
home position and posture of the motion platform. When
the host application has initialised the platform
parameters, it starts service the state machine. Each time
the state machine runs it checks hardware feedback from
the MDU, executes commands sent to it from the host
application, accepts motion data from the host application
via an platform API function, and signals the host
application that it requires servicing.
Consider different application requirements, three
level of simulation scenarios were designed. For the
beginners to use the system as a safe environment to
exercise basic controls, the system provides a “smooth
rife” mode. The data been abstracted and sent to the
motion platform will use a motion-to-motion filter which
controls actuator displacements by the six outputs of the
kinematics block. For the intermediate player, more
hazardous or even hostile environment can be generated
through the WTK portal functions. Different terrain can
be loaded with spatialised wind sound applied. The
sensation of flying can be augmented more by using wind
fans in the dark room where the only thing user can see is
the life size environment projected on the front screen.
For the advanced users, the design is to implement air
dynamics into the simulation, where sudden surge of side
winds or change of speed could be simulated. The
motion-to-motion mode applied in the first two designs
will not be suitable to this one due to the limited platform
moving and accelerating range. A high-pass filter mode
enabled by the platform manufacture will be adopted for
this kind of applications, where the rapidly changing
glider accelerations can be accurately reproduced while
ensuring that the simulator tends to return to its neutral
position with acceleration rates that are imperceptible to
the occupants.

for the glider environment so more real-life scenarios can
be simulated. For example, when the glider is flying close
to a cliff, it will be “push” away be the wind. In this case,
more than one filter output can be connected to one
platform kinematics input, where the resulting signal is
the sum of the filter outputs.

Acknowledgements
The authors would like to specifically thank Russell Fella,
a final year student in the Virtual Reality System pathway
at the School of Engineering, University of Huddersfield,
for contributing on the virtual environment design and
system testing.

References
[1] Feiner, S. and Thalmann, D, 2000. Message from the
Program Co-Chairs. The Proceedings of IEEE Virtual Reality
2000 Conference, ISBN 0-7695-0478-7.
[2] Brooks, F. P., 1999, What’s Real About Virtual Reality?
IEEE Computer Graphics and Applications 1999, ISSN 02721716/99, pp16-27.
[3] WorlToolKit Reference Manual,
Animation, Inc. Sese8 Product Line.

1999

Engineering

[4] Turner, R., Li, S., and Gobbetti, E., 1999. Metis – an ObjectOriented Toolkit for Constructing Virtual Reality Applications.
Computer Graphics Forum, Vol.18, No.2, pp122-130.
[5] Cook, J., Hubbold, R., Keates, M. Virtual Reality for LargeScale Industrial Applications, Future Generation Computing
Systems, Vol. 14, No. 3/4, pp.157-166, ISSN 0167-739X.
[6] Isdale, J., 2000. Motion Platforms – Technology Review.
VR News, Volume 9 Issue 3, April 2000.
[7] Stewart, D., 1965. UK Institution of Mechanical Engineers
Proceedings 1965-66 Vol. 180, Pt1, No 15.
[8] Sang-hum Nam, Dong-hoon Lee, Jang-Hwan Im, and
Young-Ho Chai, 2000. Dual Projection-Based VR System for
the Light Weight Motion-Based Driving Simulator, The
Proceedings of VRST 2000, Seoul, Korea. ACM 1-58113-3162/00/0010

5 Conclusions and future work
The motion platform-based haptic display provides
realistic sensation of acceleration. Although it might be
argued the glider application introduced in the context
only applied position control rather than real motion
control so far, nonetheless, the system user will obtain
natural force feedback through angular accelerations (the
user is hanging under the supporting frame on the
platform, just like in real training). Researches have been
carried out to develop advanced aerial dynamic models

[9] Hollerback, J., 2000. 2D omnidirectional treadmill-the
TreadPort. The Proceedings of IEEE Virtual Reality 2000, ISBN
0-7695-0478-7.
[10] Noma, 2000. Development of Ground Surface Simulator
for Tel-E-Merge System. The Proceedings of IEEE Virtual
Reality 2000, ISBN 0-7695-0478-7.
[11] Shih, 2000. Virtual Roller Coaster. The Proceedings of
IEEE Virtual Reality 2000, ISBN 0-7695-0478-7.

Proceedings of the Seventh International Conference on Information Visualization (IV’03)
1093-9547/03 $17.00 © 2003 IEEE

