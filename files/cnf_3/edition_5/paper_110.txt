Tree Encoding and Transitive Closure Compression
Yangjun Chen
Department of Applied Computer Science
University of Winnipeg
Winnipeg, Manitoba, Canada R3B 2E9
ychen2@uwinnipeg.ca

Abstract
Tree encoding is a very useful mechanism to check ancestordescendant relationships of the nodes in a tree structure, by
which each node is associated with a pair of integers that can
be used to characterize the reachability. Recently, this method is extended to directed graphs (digraph for short) G by associating each node in G with a pair sequence. However, no
approach is reported to minimize such pair sequences. In this
paper, we address this issue and propose an efficient algorithm that is always able to generate minimized pair sequences. The algorithm runs in O(b⋅e + b⋅n⋅ b ) time and
O(b⋅n), where n and e are the numbers of the nodes and edges
of a DAG, respectively; and b is the DAG’s width.

1. Introduction
Let G(V, E) be a directed graph. Digraph G* = (V, E*) is the
reflexive, transitive closure of G if (v, w) ∈ E* iff there is a
path from v to w in G. In other words, the transitive closure
of a digraph is all ancestor-descendant pairs. Obviously, such
ancestor-descendant pairs can be stored as a matrix M in
which M(i, j) = 1 if there exists a path from i to j in G; M(i, j)
= 0 if there is no path from i to j. However, it is very spaceconsuming since it requires O(n2) space to store such a matrix. Therefore, it is desired to find a way to compress transitive closures, but without sacrificing too much the query
time.
During the past decade, much research has been done on this
issue [4, 5, 7, 11]. In [7], a heuristic method was suggested,
by which a DAG (directed acyclic graph) is decomposed into
a set of disjoint paths. Then, each node v is associated with a
pair of integers. The first integer indicates a path, on which v
appears, and the second integer indicates the position of v on
that path. To facilitate the reachability checking (whether a
node is reachable from another node through a path), each
node is also associated with a pair sequence with each pair in
it dominating a path. Therefore, the length of each pair sequence is bounded by O(β), where β represents the number
of the disjoint paths. The query time is bounded by O(logβ).
However, in the worst case, the number of paths is on O(n)
and thus the space overhead is still O(n2).
In the context of programming languages, the so-called
Packed-Encoding (PE-Encoding) [5] and PQ-Encoding [11]
are proposed. Both PE-Encoding and PQ-Encoding can be
characterized as bit-vector based strategies. Using PE-Encoding, each node is associated with a label (an integer) and
a bit-vector, which is used to record all its ancestors. Using
PQ-Encoding, each node is associated with an interval and a
bit-vector that is of the length equal to the number of slices.
A slice is just a subset of types and subtypes involved in a
program, and the size of a slice is bounded by a constant.
This encoding is based on the concept of PQ-trees, a data

11th International Conference Information Visualization (IV'07)
0-7695-2900-3/07 $20.00 © 2007

structure proposed in [11], which is used to test for the consecutive 1’s property in binary matrices. In both PE-Encoding and PQ-Encoding, the length of a bit-vector is on O(n),
where n is the number of the types (subtypes) involved in a
hierarchy. Therefore, they are suitable only for small graphs.
However, they work well for implementing compilers since
even in a large program, the number of types and subtypes involved is small in comparison with a graph stored in a database. In addition, the above two encodings cannot be used to
label a graph containing cycles, nor can they be used to develop efficient algorithms for compressing transitive closures.
In [4], an interesting algorithm is proposed to compress transitive closures by generating a branching for the DAG that is
in fact a forest covering all nodes of the DAG. Using this algorithm, a transitive closure can be stored in O(nα) space and
the querying time is bounded by O(logα), where α is the
number of the leaf nodes of the branching generated for a
given DAG. To create such a compressed representation of
the transitive closure, O(eα) time is required, where e is the
number of the DAG’s edges.
However, α can be very large, which makes the compression
not so effective. For this reason, in [4], a k-level compression
is suggested. But doing so, the querying time is dramatically
increased.
In this paper, we continue the effort of [4] and discuss an algorithm that is able to find a branching with the least number
of leaf nodes. Therefore, α is minimized to b, the DAG’s
width, defined to be the largest set U ⊆ V, such that for every
pair of nodes u, v ∈ U, there does not exist a path from u to
v or from v to u. The algorithm runs in O(b⋅e + b⋅n⋅ b ) time.
Accordingly, a compressed transitive closure can be stored in
(eb) space, and generated in O(nb) time. The querying time
is bounded by O(logb).
The remainder of the paper is organized as follows. In Section 2, we show what is tree encoding and how it can be utilized for the transitive closure compression. In Section 3, we
discuss a DAG stratification strategy and review some concepts related to bipartite graphs, on which our algorithm
bases. Section 4 is devoted the description of the algorithm
for finding a branching with the least number of leaves. Finally, a short conclusion is set forth in Section 5.

2. Tree Encoding and Transitive Closure Compression
In [4], a new algorithm for compressing transitive closures
was discussed based on the tree encoding, which can be
briefly described as follows.
Consider a tree T. By traversing T in preorder, each node v
will obtain a number pre(v) to record the order in which the
nodes of the tree are visited. In a similar way, by traversing T

in postorder, each node v will get another number post(v).
These two numbers can be used to characterize the ancestordescendant relationships as follows.
Let v and v’ be two nodes of a tree T. Then, v’ is a descendant
of v iff pre(v’) > pre(v) and post(v’) < post(v). See Exercise
2.3.2-20 in [8].
As an example, have a look at the pairs associated with the
nodes of the tree shown in Fig. 1. The first element of each
pair is the preorder number of the corresponding node and
the second is its postorder number. Using such labels, the ancestor-descendant relationships can be easily checked.
For instance, by checking the label associated with b against
the label for f, we see that b is an ancestor of f in terms of
Proposition 1. Note that b’s label is (2, 4) and f’s label is (4,
1), and we have 2 < 4 and 4 > 1. We also see that since the
pairs associated with g and c do not satisfy the condition given in Proposition 1, g must not be an ancestor of c and vice
versa.
(1, 7)

a
(2, 4)

g (6, 5)

b

(3, 2) c
f

(7, 6)

h

e (5, 3)

Fig. 1. Labeling a tree

a

b

c
(2, 5)

h
i

f

a

(1, 8)

d

g

e

(9, 10)

e

g
i

f

(3, 1)

(1, 8)

(2, 5)

h

d

(7, 6) (8, 7) (10, 9)

j

a

b

(4, 2) (5, 3)

j (6, 4)

c
e
(3, 1)

(7, 6)

g
(8, 7)

f
(4, 2)

i

(5, 3)

b

(9, 10)

d

(10, 9)

h
j (6, 4)

(a)

(b)
(c)
Fig. 2. A DAG and its branching
The branching found by using the method suggested in [4]
(which is in fact a depth-first searching) is shown in Fig.
2(b). By labeling the branching as above, we will get the initial pair sequence for G as shown in Fig. 2(c).
Then, we search the DAG bottom-up and for each encountered node v we merge its pair with the pair sequences of all
its child nodes. In this way, we will get a pair sequence for
each node in G as illustrated in Fig. 3.
a

2, 8

d
c

4, 1

b
e
f

5, 2

6, 3

7, 4

8, 6

9, 7

11, 9

5, 2

6, 3

7, 4

8, 6

9, 7

10, 10

3, 5
4, 1
4, 1
5, 2

g

4, 1

5, 2

8, 6

h

6, 3

7, 4

9, 7

i

6, 3

j

7, 4

(1, 7)

c
e

(2, 2)
(3, 1)

g
f

a

h

(4, 4)
(5, 3)

(6, 6)

i

(7, 5)

b
d
j

(8, 10)
(9, 9)
(10, 8)

(a)

Fig. 4. Another branching and the
corresponding pair sequences

a

1, 7

10, 8

b

3, 1

4, 4

6, 6

8, 10

c

2, 2

5, 3

7, 5

10, 8

d

3, 1

4, 4

6, 6

9, 9

g

3, 1

4, 4

h

6, 6

10, 8

e

3, 1

f

5, 3

i

7, 5

j

10, 8

(b)

The number of leaf nodes of this branching is 4 while the
number of the leaf nodes of the branching shown in Fig. 2(b)
is 7.
The pair sequences generated according to this branching is
shown in Fig. 4(b). The longest pair sequence is 4. In addition, the total number of pairs is smaller than that shown in
Fig. 3.
An interesting question is: can we always find a branching
with the least number of leaf nodes in an efficient way? In the
rest of this paper, we answer this question.

(4, 1)

Let (p, q) and (p’, q’) be two pairs associated with nodes u
and v, respectively. We say that (p, q) is subsumed by (p’, q’),
denoted (p, q)
(p’, q’), if p > p’ and q < q’. Then, u is a
descendant of v if (p, q) is subsumed by (p’, q’).
In order to check the reachability of the nodes in a DAG G,
G is first decomposed into a forest B that cover all the nodes
in G and assign each node in B a pair of integers as above,
which can be considered as an initial pair sequence for each
node v in G. It will then be modified by merging it with the
pair sequences of all v’s child nodes.
To have a better understanding, we reproduce the DAG given
in [4] in Fig. 2(a).
c

as shown in Fig. 4(a).

Fig. 3. Illustration for label sequences

However, for the same DAG, we can find another branching

11th International Conference Information Visualization (IV'07)
0-7695-2900-3/07 $20.00 © 2007

3. Bipartite graph and graph stratification
Our method is based on a DAG stratification strategy and an
algorithm for finding a maximum matching in a bipartite
graph. Therefore, the relevant concepts and techniques
should be first reviewed and discussed.
3.1 Stratification of DAGs
Let G(V, E) be a DAG. We decompose V into subsets V1,
V2,..., Vh such that V = V1 ∪ V2 ∪ ... Vh and each node in Vi
has its children appearing only in Vi-1, ..., V1 (i = 2, ..., h),
where h is the height of G, i.e., the length of the longest path
in G. For each node v in Vi, we say, its level is i, denoted l(v)
= i. We also use Cj(v) (j < i) to represent a set of links with
each pointing to one of v’s children, which appears in Vj.
Therefore, for each v in Vi, there exist i1, ..., ik (il < i, l = 1, ...,
k) such that the set of its children equals C i1 ( v ) ∪ ... ∪ C ik ( v ).
Such a DAG decomposition can be done in O(e) time, by using the following algorithm, in which we use G1/G2 to stand
for a graph obtained by deleting the edges of G2 from G1; and
G1 ∪ G2 for a graph obtained by adding the edges of G1 and
G2 together. In addition, (v, u) represents an edge from v to
u; and d(v) represents v’s outdegree.
Algorithm graph-stratification(G)
begin
1. V1 := all the nodes with no outgoing edges;
2. for i = 1 to h - 1 do
3. { W := all the nodes that have at least one child in Vi;
4. for each node v in W do
5.
{let v1, ..., vk be v’s children appearing in Vi;
6.
Ci(v) := {v1, ..., vk};
7.
if d(v) > k then remove v from W;};
8.
G := G/{(v, v1), ..., (v, vk)};
9.
d(v) := d(v) - k;}
10. Vi+1 := W;
11. }
end
In the above algorithm, we first determine V1, which contains
all those nodes having no outgoing edges (see line 1). In the

subsequent computation, we determine V2, ..., Vh. In order to
determine Vi (i > 1), we first find all those nodes that have at
least one child in Vi-1 (see line 3), which are stored in a temporary variable W. For each node v in W, we then check
whether it also has some children not appearing in Vi-1,
which can be done in a constant time as demonstrated below.
During the process, the graph G is reduced step by step, and
so does d(v) for each v (see lines 8 and 9). We notice that after
the jth iteration of the out-most for-loop, V1 , ..., Vj+1 are determined. Denote Gj(V, Ej) the reduced graph after the jth iteration of the out-most for-loop. Then, any node v in Gj,
except those in V1 ∪ ... ∪ Vj+1, does not have children appearing in V1 ∪ ... ∪ Vj. Denote dj(v) the outdegree of v in Gj.
Thus, in order to check whether v in Gi-1 has some children
not appearing in Vi, we need only to check whether di-1(v) is
strictly larger than k, the number of the child nodes of v appearing in Vi (see line 7).
In this process, each edge is accessed only once. So the time
complexity of the algorithm in bounded by O(e).
As an example, consider the graph shown in Fig. 2(a) once
again. Applying the above algorithm to this graph, we will
generate a stratification of the nodes as shown in Fig. 5.
V4:

b

V3:

a

V2:

c

V1:

e

C2(b) = {d}
C1(a) = {c, g, h} d
C1(c) = {e, f, i, j} g
f

C1(d) = {g, h}
C2(d) = {j}
C1(g) = {e, f}
i

h

C1(h) = {i, j}

j

Fig. 5. Illustration for DAG stratification
The nodes of this DAG are divided into four levels: V1 = {e,
f, i, j}, V2 = {c, g, h}, V3 = {a, d}, and V4 = {b}. Associated
with each node at each level is a set of links pointing to its
children at different levels.
3.2 Concepts of bipartite graphs
Now we restate two concepts from the graph theory which
will be used in the subsequent discussion.
Definition 2. (bipartite graph [2]) An undirected graph G(V,
E) is bipartite if the node set V can be partitioned into two
sets T and S in such a way that no two nodes from the same
set are adjacent. We also denote such a graph as G(T, S; E).
For any node v ∈ G, neighbour(v) represents a set containing
all the nodes connected to v.
Definition 3. (matching) Let G(V, E) be a bipartite graph. A
subset of edges E’ ⊆ E is called a matching if no two edges
have a common end node. A matching with the largest possible number of edges is called a maximal matching, denoted
as MG.
Let M be a matching of a bipartite graph G(T, S; E). A node
v is said to be covered by M, if some edge of M is incident
with v. We will also call an uncovered node free. A path or
cycle is alternating, relative to M, if its edges are alternately
in E/M and M. A path is an augmenting path if it is an alternating path with free origin and terminus. In addition, we
will use freeM(T) and freeM(S) to represent all the free nodes
in T and S, respectively.
Much research on finding a maximal matching in a bipartite
graph has be done. The best algorithm for this task is due to
Hopcroft and Karp [6] and runs in O(e⋅ n ) time, where n =
|V| and e = |E|. The algorithm proposed by Alt, Blum, Mel1.5
e ⁄ ( log n ) ) time. In the case
horn and Paul [9] needs O( n

11th International Conference Information Visualization (IV'07)
0-7695-2900-3/07 $20.00 © 2007

of large e, the latter is better than the former.
3.3. Algorithm description
The main idea of the algorithm is to construct a series of bipartite graphs for G(V, E) and then find a maximum matching
for each of such bipartite graphs using Hopcroft-Karp algorithm. All these matchings make up a set of disjoint paths and
the size of this set is minimum.
During the process, some new nodes, called virtual nodes,
may be introduced into Vi (i = 2, ..., h; V = V1 ∪ V2 ∪ ... Vh)
to facilitate the computation. However, such virtual nodes
will be eventually resolved to get the final result.
In the following, we first show how a virtual node is constructed. Then, the algorithm will be described.
We start our discussion with the following specification:
Mi -the found maximum matching of G(Vi+1, Vi; Ci), where
Ci = Ci(v1) ∪ ... Ci(vk) with vl ∈ Vi+1 (l = 1, ..., k).
Mi’ -the found maximum matching of G(Vi+1, Vi’; Ci’),
where Vi’ = Vi ∪ {all the virtual nodes added into Vi}.
Ci’ = Ci ∪ {(u, v) | u ∈ Vi+1, v is a virtual node in Vi’}.
In addition, for a graph G, we will use V(G) to represent all
its nodes and E(G) all its edges.
Definition 4. (virtual nodes for free nodes) Let G(V, E) be a
DAG, divided into V1, ..., Vh (i.e., V = V1 ∪ ... ∪ Vh). Let v
be a free node in free Mi ′ ( Vi ′ ) (if i = 1, we take M1 as M1’).
Add a virtual node v’ into Vi+1 (i = 1, ..., h -1), labeled as follows.
1. If there exist some covered nodes u1, ..., uk (relative to
Mi’) in Vi’ such that each ug (g = 1, ..., k) shares a covered
parent node wg (i.e., (wg, ug) ∈ Mi’) with v, label v’ with
v[(w1, {(n11, S11), ..., ( n1j1 , S 1j1 )}), ..., (wk, {(nk1, Sk1),
..., ( n kjk , S kjk )})],
where ngj (g = 1, ..., k; j = 1, ..., jg) is an even number to
indicate a position on the alternating path starting at wg,
and Sgj is a subset of Vi+2. Each node in Sgj is a parent of
the node pointed to by ngj.
2. If no such a covered node exists, v’ is labeled with v[ ].
In addition, for a virtual node v’ (generated for v), we will establish an edge (u, v’) for every u ∈ S11 ∪ ... ∪ S 1j1 ∪ ... ∪
Sk1... ∪ S kjk . v’ will also inherit all the edges incident to v except the edges from a node in Vi+1 to v. That is, for each parent w of v, we will have an edge (w, v’) if w is not a node in
Vi+1. A virtual edge (v’, v) will be constructed to facilitate the
virtual node resolution process. Finally, we set Vi+1’ to be
Vi+1 ∪ {all those virtual nodes}, and Ci+1’ to be Ci+1 ∪ {(u,
v) | u ∈ Vi+2, v is a virtual nodes in Vi+1’}.
The following example helps for illustration.
Example 1. Consider the graph shown in Fig. 6(a). The bipartite graph made up of V2 and V1, G(V2, V1; C1), is shown
in Fig. 6(b). A possible maximum matching M1 of it is shown
in Fig. 6(c).
Relative to M1, we have two free nodes f and k in V1.
For the free node f, we will construct a virtual node f’, labeled with f[(a, {(4, {i})}), (c, {(6, {i})})] for the following
reasons.
(i) The covered node d and g share the parent a and c with f,
respectively.
(ii)On the alternating path starting at a, the 4th node e has a
parent i that appears in V3. (Fig. 6(d) shows the alternating
path starting at a. On the path, a solid edge represents an

edge belonging to M1 while a dashed edge to C1/M1.) On
the alternating path starting at c, the 6th node e has a parent i that appears in V3.
h

i

a

b

d

e

a

b

d

e

c

(a)
g

f

b
e

c
g

f

k

c
g

f

V2: a
V1: d

k

a

b

a

i
b

d

e

d

e

(c)

(d)

(b)

k

V3: h

i
b

(a)

c

k’

f’
h

i

a

b

(c)

c

b

f’

c

k’

d

e

f

g

k

V1: e

g
f

i

h
j

(a)

c

g

e

f

k’

f’

(b)

h
i

j

(b)

Fig. 8. A bipartite graph and a maximum matching

Relative to M1, we have a free node i in V1.
For the free node i, we will construct a virtual node i’, labeled
with i[(c, { }), (h, {(2, {d})})]. See Fig. 9(a) for illustration.
In addition, an edge (d, i’) is established. We notice that in
the label, (c, { }) contains only an empty set and can be simply removed.
The graph shown in Fig. 9(a) is the second bipartite graph,
G(V3, V2’; C2’). Assume that the maximum matching M2’
found for this bipartite graph is a graph shown Fig. 9(b).
Relative to M2’, g and h are two free nodes in V2’. For them,
two virtual nodes g’ (labeled with g[(b, { })]) and h’(labeled
with h[(d, { })]) will be created as shown in Fig. 9(c).
The graph shown in Fig. 9(c) is the third bipartite graph,

11th International Conference Information Visualization (IV'07)
0-7695-2900-3/07 $20.00 © 2007

g

V3’: a

Fig. 7. A bipartite graph and a maximum matching
A possible maximum matching M2’ of this bipartite graph is
shown in Fig. 7(b).
Now we consider M1 ∪ M2’. It is a set of 5 paths shown in
Fig. 7(c). In order to get the final result, all the virtual nodes
appearing on those paths have to be resolved.
In the whole process, we may also need to generate virtual
nodes for free virtual nodes themselves, which can be done
in the same way as actual nodes.
Example 2. Let’s have a look at the graph shown in Fig. 2(a)
once again. The bipartite graph made up of V2 and V1, G(V2,
V1; C1), is shown in Fig. 8(a) and a possible maximum
matching M1 of it is shown in Fig. 8(b).
V2: c

(a)
h

i’

V4:

i

a

b

d

b
g’

d

d

c

g

i’

h’

h

(b)

b

(c)

f

(e)

h

V3: a
V2’: c

Fig. 6. A bipartite graph and a maximum matching
The motivation of constructing such a virtual node is that it
is possible to use (i, e) as an edge in the branching to be generated if we transfer the edges on an alternating path starting
at a (or at c), which makes e free. Then, we can connect i and
e, as well as a and f without increasing the number of leaves,
as shown in Fig. 6(e). This can be achieved by the virtual
node resolution process.
In a similar way, we construct a virtual node k’ for k, labeled
with k[(c, {(6, {i})})].
The bipartite graph made up of V3 and V2’ is shown in Fig.
7(a).
V2’: a

G(V4, V3’; C3’). The unique maximum matching M3’ for this
is contains only one edge (b, d).
Now we consider M1 ∪ M2’ ∪ M3’. This is a set of four paths
as shown in Fig. 10(d).

a

g’

d

h’

c

g

i’

h

(d)

Fig. 9. Illustration for virtual
e
i
f
j
node construction
From the above discussion, we can see that the algorithm
should be a three-phase process. In the first phase, we generate virtual nodes and paths. In the second phase, we resolve
all the virtual nodes on the paths. In the third phase, we generate the final branching.
- phase 1
Algorithm path-generation(G’s stratification)
input: G’s stratification.
output: a set of paths
begin
1. find M1 of G(V2, V1; C1); M1’ := M1; V1’ := V1; C1’ := C1;
2. for i = 2 to h - 1 do
3. {construct virtual nodes for Vi according to Mi-1’;
4. let U be the set of the virtual nodes added into Vi;
5. let W be the newly generated edges incident to the virtual
nodes in U;
6. let W’ be a subset of W, containing only the edges from
Vi+1 to U;
7. Vi’ := Vi ∪ U; Ci’ := Ci ∪ W’;
8. find a maximum matching Mi’ of G(Vi+1, Vi’; Ci’);
9. }
10.return M1 ∪ M2’ ∪ ... ∪ Mh -1’.
end
The algorithm works in two steps: an initial step (line 1) and
an iteration step (lines 2 -8). In the initial step, we find a M1
of G(V2, V1; C1). In the iteration step, we repeatedly generate
virtual nodes for Vi and then find a Mi’ of G(Vi+1, Vi’; Ci’).
The result is M1 ∪ M2’ ∪ ... ∪ Mh-1’.
After the paths for a DAG are generated, we will resolve all
the virtual nodes appearing on them in the second phase.
- phase 2
We distinguish between two kinds of virtual nodes: anchored
virtual nodes and unanchored virtual nodes. An anchored
virtual node has a parent along the corresponding path such
as node i’ in Fig. 9(d). An unanchored virtual node does not
have a parent such as the nodes g’ and h’ in Fig. 9(d).
The virtual nodes will be resolved along the paths level by
level in a top-down way:
1. If v’ is an unanchored node, remove v’ from the corresponding path. If its child along the path is also a virtual
node, then that child virtual node becomes unanchored.
2. If v’ is an anchored node, resolve it according to the following rule.
(i) Assume that v’ is reached along an edge (u, v’). Assume
that v’ is labeled withv[(w1, {(n11, S11), ..., ( n 1j1 ,
S 1j )}), ..., (wk, {(nk1, Sk1), ..., ( n kj , S kj )})].
1

k

k

(ii)If there exists an nij such that u is a parent of the
node w pointed to by nij, do the following operations:
- Transfer the edges on the alternating path starting at wi and ending at the node pointed to by nij.
Add (wi, v).
- Remove (u, v’) and v’.
- Add (u, w).
Otherwise, remove v’ and connect u to the child
node of v’ along the path.
See the following example for a better understanding.
Example 3. Consider the paths shown in Fig. 9(d). After
the virtual nodes g’ and h’ are resolved, we will have a
set of paths as shown in Fig. 10(a). We notice that both
g’ and h’ are unanchored virtual nodes and simply removed from the corresponding paths.
b
a

Especially, the label of a virtual node may contain redundant data, which can be easily removed. To have a
clear picture, let’s have a look at the label associated
with f’ in Fig. 7(a) once again. It is f[(a, {(4, {i})}), (c,
{(6, {i})})]. To generate the first entry (a, {(4, {i})}), we
will search an alternating path starting at a shown in Fig.
6(d). To generate the second entry (c, {(6, {i})}), we will
search an alternating path (starting at c) as shown in Fig.
12, by which the first alternating path is searched for a
second time.
b
a

h

d

c

g

e

f

h
i

j

(a)

i

a

b

c

d

e

f g

k

(b)

Fig. 11. Two branchings

b

d

(a)

a

d

c

g

i’

h

c

g

e

f

i

j

e

f

(b)
h

i

j

Fig. 10. Illustration for virtual node resolution
Next we will meet i’ (through the edge (d, i’)). i’ is an
anchored node labeled with i[(c, { }), (h, {(2, {d})})] =
i[(h, {(2, {d})})]. To resolve it, we will do the following.
(i) transfer the edges on the alternating path starting at h
and ending at the node pointed to by 2 (i.e., node j),
which contains only one edge (h, j) (see Fig. 8(b))
that is removed by the edge transferring; add (d, j).
(ii) remove (d, i’) and i’, and
(iii)add (i, h).
See Fig. 10(b) for illustration.
The following algorithm is the formal description of this
process, in which we use Ui to stand for all the path
nodes on the ith level and represent all the paths as U1 ∇
... ∇ Uh.
Algorithm virtual-resolution(C)
input:C - a path set obtained by executing the algorithm
path-generation, represented as U1 ∇ ... ∇ Uh.
output: a set of paths containing no virtual nodes.
begin
1. for i = h downto 2 do
2. {for each v ∈ Ui do
3. { if v is unanchored virtual node then remove it;
4.
if v is anchored virtual node then resolve it according to 2-(i) and (ii) given above;}}
end
- phase 3
In the third phase, we connect each free node in Ui to
one of its parent nodes in some Uj (j > i). If it has more
than one parent, choose any one of them (by which the
tie is resolved arbitrarily).
For example, by connecting g and h to a in Fig. 10(b),
we will get a branching as shown in Fig. 11(a). Similarly, by executing the second and the third phase over the
paths shown in Fig. 7(c), we will get paths shown in Fig.
11(a). Then, by connecting k to c, we will obtain a tree
structure as shown in Fig. 11(b).
3.4 On the construction of virtual nodes
The construction of virtual nodes dominates the cost.

11th International Conference Information Visualization (IV'07)
0-7695-2900-3/07 $20.00 © 2007

This part is repeatedly accessed.

a

c
f

d

b
e

Fig. 12. Illustration for redundancy

To eliminate this kind of redundancy, we do the following:
(i) When we establish a label L for a virtual node, we assign an order number to each entry in L when it is created.
(ii)Each entry is augmented with an index. That is, an
entry of the form (wi, {(ni1, Si1), ..., ( n ijk , S ijk )}) in
the label will be changed to (wi, {(ni1, Si1), ..., ( n ijk ,
S ij )}, (ai, bi)), where ai (< i) is a number for some
k
entry in the same label and bi is a number indicating
the position on the corresponding alternating path,
which shares the alternating path related to the entry
numbered with ai.
For example, the label f[(a, {(4, {i})}), (c, {(6, {i})})]
will be changed to
f[(a, {(4, {i})}, (_, _)), (c, {(1, 3)})].
In the first entry, the index is (_, _) since when we generate it, we find no other alternating path sharing an segment with its alternating path. In the second entry, the
index is (1, 3), indicating that part of the alternating path
related to this entry (from the 3rd position to the end) is
the same as the alternating path related to the first entry.
Note that bi can be a negative integer. To see this, assume
that in the above label the entry (c, {(6, {i})}) is created
before (a, {(4, {i})}). Then, the real label should be
i[(c, {(6, {i})}, (_, _)), (a, {(1, -3)})].
The negative integer -3 in the second entry indicates that
the second alternating path starts from the 3rd position
on the first alternating path.
In this way, any redundancy can be avoided.
In the following, we consider the edge inheritance.
As
with
the
data
structure C i1 ( v ) ∪
...

∪ C i k ( v ) associated with node v to store its child nodes,
we can associate v with another data structure P j1 ( v ) ∪

... ∪ P jl ( v ) to store its parents, where Pj r ( v ) (1 ≤ r ≤ l)
represent a set of links with each pointing to one of v’s
parents, which appears in V jr . Both child and parent
links can be organized into linked lists as illustrated in

Fig. 13(a).

h–1

v

v’

... ...
Pj1(v)

Pj2(v)

Pjl (v)

Pj2(v)

... ...

work is O(
Pj (v)
l

v

(a)

Pj1(v)

(b)

Fig. 13. Illustration for redundancy
When we create a virtual node v’ for v (at level j1 - 1), all
the edges incident to v, except the edges from the nodes
at level j1 to v, will be inherited to v’. To do this, we simply graft part of the linked list associated with v to v’ as
illustrated in Fig. 13(b). Obviously, this operation needs
only a constant time.

4. Correctness and computational complexities
In this section, we show the correctness of the algorithm
and analyze its computational complexities.
Proposition 1. The number of the leaf nodes of the generated branching is minimum.
Proof. First, we notice that the number of the leaf nodes
of the generated branching is equal to
|V1| + free M 1 ( V2 ) + freeM 2 ′ ( V 3 ) + ...
+ free M ( h – 1 ) ′ ( V h ) .
In conjunction with the use of virtual nodes, HopcroptKarp’s algorithm guarantees that free M1 ( V2 ) and each
free M ′ ( Vj + 1 ) (j = 2, ..., h - 1) are minimum.
j
In the following, we analyze the computational complexities of the algorithm.
Proposition 2. The time complexity of the whole process to decompose a DAG into paths is bounded by O(be
+ bn b ).
Proof. The cost for generating a virtual node v’ (added
to Vi) for node v can be divided into two parts: cost1 and
cost2. cost1 is the time spent on establishing new edges,
Vi

which is bounded by O( ∑ d ij ), where dij represents the
indegree of node j at levelj i.
cost2 is the time for the edge inheritance from node v. It
is bounded by a constant since the edges from a node to
its parents are implemented as a linked list.
The time for finding a maximum matching of G(Vi+1,
Vi’; Ci) is bounded by O( V i + 1 + Vi ′ ⋅ C i ′ ) (see [6]).
Therefore, the cost for the generation of paths is bounded by
h–1

V

 i
O( ∑  b ∑ d ij +
i = 1 j


V i + 1 + Vi ′ ⋅ C i ′  )



h–1

≤ O((be + b ∑ b ⋅ V i ) = O(be + bn b ).
i=1

The time on resolving virtual nodes at each level i is also
Vi

bounded by O(b ∑ d ij ). So the total cost of this part of
j

11th International Conference Information Visualization (IV'07)
0-7695-2900-3/07 $20.00 © 2007

Vi

∑ b ∑ d ij ) = O(be).
i=1

j

The space complexity of the whole process is bounded
by O(be) since the number of edges in each bipartite
graph G(Vi+1, Vi’; Ci’) is bounded by O(b|Vi+1|), and the
total size of all virtual nodes is bounded by O(be).

5. Conclusion
In this paper, a new algorithm for finding a branching for
a DAG G is proposed. The algorithm needs O(be +
bn b ) time and O(be) space, where n and e are the number of the nodes and the edges of G, respectively; and b
is the width of G. The main idea of the algorithm is the
DAG stratification that generates a series of bipartite
graphs which may contain virtual nodes. By executing
Hopcropt-Karp’s algorithm, we find a maximum matching for each of such bipartite graphs, which make up a
set of disjoint paths. A next step is needed to resolve all
the virtual nodes appearing on the paths. In the third
step, we form a tree by connecting each free node at each
level to one of its parents. Accordingly, a compressed
transitive closure can be stored in (eb) space, and generated in O(nb) time. The querying time is bounded by
O(logb).
References
[1] H. Alt, N. Blum, K. Mehlhorn, and M. Paul, Computing a maximum cardinality matching in a bipar1.5
m ⁄ ( log n ) ), Information
tite graph in time O( n
Processing Letters, 37(1991), 237 -240.
[2] A.S. Asratian, T. Denley, and R. Haggkvist, Bipartite Graphs and their Applications, Cambridge
University, 1998.
[3] R.P. Dilworth, A decomposition theorem for partially ordered sets, Ann. Math. 51 (1950), pp. 161166.
[4] Y. Chen and C. Cooke, On the Transitive Closure
Representation and Adjustable Compression, in:
Proc. of ACM Symposium on Applied Computing
(SAC), Dijon, France, April 2006, pp. 450-455.
[5] N.H. Cohen, “Type-extension tests can be performed in constant time,” ACM Transactions on
Programming Languages and Systems, 13:626629, 1991.
[6] J.E. Hopcroft, and R.M. Karp, An n2.5 algorithm
for maximum matching in bipartite graphs, SIAM
J. Comput. 2(1973), 225-231.
[7] H.V. Jagadish, “A Compression Technique to Materialize Transitive Closure,” ACM Trans. Database Systems, Vol. 15, No. 4, 1990, pp. 558 - 598.
[8] D.E. Knuth, The Art of Computer Programming,
Vol.1, Addison-Wesley, Reading, 1969.
[9] K. Mehlhorn, “Graph Algorithms and NP-Completeness: Data Structure and Algorithm 2”
Springer-Verlag, Berlin, 1984.
[10] J. Tarjan: Finding Optimum Branching, Networks,
7. 1977, pp. 25 -35.
[11] Y. Zibin and J. Gil, “Efficient Subtyping Tests with
PQ-Encoding,” Proc. of the 2001 ACM SIGPLAN
conf. on Object-Oriented Programming Systems,
Languages and Application, Florida, October 1418, 2001, pp. 96-107.

