Working with patterns in large multivariate datasets - Karnaugh-Veitch-Maps
revisited
Thorsten May
Fraunhofer Institute for Computer Graphics, Germany
thorsten.may@igd.fraunhofer.de
Abstract
We present an interactive visualization method for the
multivariate analysis of large and complex datasets, based
on the layout of Karnaugh-Veitch-diagrams. Working on
data categories, we additionally provide an interactive
partitioning of value ranges of ordinal types. Multivariate
dependencies manifest on the map in characteristic color
patterns. These patterns are representations of subsets of
the data or attributes which embody significant information. While the task of the user is to identify visual patterns
of particular interest to him by clicking on the map, the
software identifies a minimal representation of the corresponding subset and gives a visual feedback. Hence, user
and machine cooperate on the basis of a strong visual coupling in short iterative cycles. During this process the
trade-off between the accuracy and simplicity of a representation, which is crucial for any type of the building of
analytical models, can be found in an effective way.
Keywords— Visualization Coupling, Multivariate Data
Analysis, Matrix Based Layout, Classifiers, HumanComputer-Interaction

1

Introduction

Finding ’meaningful’ information in multivariate
datasets is a difficult task with respect to both computational and human effort. A vast number of possible interdependencies are hidden in the complexity and size of the
datasets, which cannot be extracted by purely automatic
means, which would leave the user with large amount of
statements both ’fuzzy’ and ’sharp’ and both significant
and unimportant. It must be the user, which is the ultimate authority in giving the direction of the analysis along
his specific task and it must be the system, which must provide effective means of communication to concentrate on
this task.
This paper proposes a highly interactive visualization
method for large scale multivariate datasets, based upon
a layout known from Karnaugh-Veitch-maps for the minimization of Boolean expressions. Our approach, how-

11th International Conference Information Visualization (IV'07)
0-7695-2900-3/07 $20.00 © 2007

ever, widens the range of data types, which can be worked
with. As the original Karnaugh-map worked for Boolean
data (with two categories per variable/attribute), we provide an interactive classification scheme for the mapping
of attributes of arbitrary value ranges onto different meaningful categories, which in turn can be used in the multivariate visualization.
The visualization displays the correlations of a selected
number of attributes and value ranges with a subset of
the dataset as a color-pattern. We see visualization as
the medium of a semi-automated analytical process, where
human and machine cooperate and contribute with their
specific distinct capabilities for the most effective result.
Hence information visualization may not stop in simply
displaying data in different perspectives. Much can be won
if an effective information flow from the user back to the
system can be established.
As a core feature in our approach, we propose a method
using semi-automated pattern detection, by which the user
enters a dialogue with the machine with the goal to identify
a specific significant pattern in the dataset. While the pattern refers to a subset of the dataset, it is up to the machine,
to find a minimal representation to identify an ’effective
rule’. The communication loop is closed, as the machine is
able to recreate a visual representation of this rule. Using
the same display, the minimal pattern proposed by the machine can easily be matched in an intuitive, iterative process, until the ’meaningful’ subset is clearly defined and
ready for a more refined analysis.
As a complete analysis of a dataset may cover the identification of a large number of elemental rules, we further introduce an auxiliary visualization which supports the navigation in the analysis space and helps keeping track of the
interesting pattern discovered during an extensive analysis
session.

2

Related work

The Karnaugh-Veitch logic diagrams [1] are primary
source of inspiration to this visualization (see figure 2).
Although not interactive in its original version, it shares

one significant property with our work - the identification of a minimal representation of a function (or more
generally speaking: a functional connection). The main
differences are described in section 4.

Figure 1: Four dimensional Boolean function displayed
in the Karnaugh-Veitch diagram (left) and its value-table
(right). Minimization of Boolean terms is done by identification of boxes consisting of 2n cells.
When putting our work into a more contemporary context, we can classify our visualization as a pixel-based
visualization method, for which Keim [2] gives a methodological overview. To be more specific, our layout is a
matrix-based recursive layout which are discussed in general by Keim et al. [3], while the approach presented by
Langton et al. [4] is designed for a specific application
in the field neurosciences. While also presenting the data
in the form of characteristic patterns, the number of data
attributes in this approach is fixed as is the number of categories for every attribute and they propose no interactive
method to establish a dialogue between user and machine,
instead they focus on the significance of the ordering of
attributes in the display. A more general variant with a
closely related layout is presented in a publication from
Sniezynski et al. [5], which also has the goal of finding
classification rules, yet does not appear to have a flexible categorization scheme for ordinal or numerical data
attributes. Van Ham [6] again presents a more specific
application of the matrix based layout.
Finding general classifiers is a task which is so important
in itself, that it can be expected that is has been tackled by
other visual means, some of which are presented by Yang
et al. [7] and Bishop et al. [8]. Bendix [9] proposes a
variant of the parallel coordinates technique by Inselberg
[10] by opening its usage to categorical data - conceptually
similar to our approach for another visualization method.
Aside from the actual matrix-visualization our approach of
navigating in the analysis space is conceptually linked an

11th International Conference Information Visualization (IV'07)
0-7695-2900-3/07 $20.00 © 2007

approach presented by Rodriguez et al. [12], which also
connects different views in a hierarchy in order to decrease
the amount of information to the viewed at the same time.
We use this approach as a basis for the display of metainformation generated through the analysis. The idea of
establishing a strong feedback between user and classifier
functions via relevance feedback is presented by Tao et
al. [11] in the context of image recognition to overcome
stability and overfitting problems in classifier functions.
Several other results contribute to our work on a technical
rather than conceptual level. We use ideas from cushion
tree-maps from van Wijk et al. [13] to overcome the problem of drawing separators for (matrix)-cells, we also use
a graph-layout scheme based on a force-feedback model,
for which Herman [14] gives a survey and the Shannonentropy model is used in identifying a minimal set of significant attributes of a pattern identified by a user.
Finally Kenwright [15] gives a valuable discussion about
the general usefulness of a semi-automated approach for
the analysis of complex data.

3

Data and task

One design goal in our approach was the flexibility of
our system, regarding the data it can be applied to. The system proposed must be able to cope with large and complex
data sets, which are sometimes difficult to come by. As
a test-base we chose the ’Public-Use-Microdata-Sample’
(1% or 5% of the US-census), which has both of these
properties and additionally can be expected to ’hide’ interesting information (i.e. multivariate dependencies).
As we has no a-priori-knowledge about the data other than
implied by its semantics, we also had the advantage to
test undirected searching, for which - as we assumed - the
Karnaugh-Veitch-layout should be very appropriate. Another long-term goal was the creation of a system which
can be used to visually identify multi-dimensional classifiers for arbitrary (sub-)sets or at least giving effective
hints about the significant and the unimportant parts of the
datasets - a generic tool, which can be the outset for an
unbiased analysis.
Fortunately the problem of handling the size of the dataset
can be completely shifted from the visualization to the
database management system, because we do not operate
on the ’raw’ data, but on a division, which actually sorts
all data items into buckets. This confronts us with the
problem of establishing a method of finding ’meaningful’
value-ranges for this division, which will be described below in greater detail. The problem of the complexity of
a data set (i.e. the number of attributes available), however, directly translates into the need of creating a flexible
layout, which enables us to effectively select attributes
and specific value ranges for the layout, which will be de-

scribed in the next section.
Our approach depends on the ability to create a partitioning
Pa of the value range Ra of every attribute a considered
into a small number of disjoint categories. In such case the
partitioning constitutes a hash-mapping Pa : Ra → N for
its attribute which maps any value in the value range onto
its category number. |Pa | can be defined as the number of
categories in this partitioning.
For Boolean data, a small ’native’ partitioning exists, as
there are only two values to be considered (|Ra | = |Pa | =
2). Unfortunately in most datasets (including the PUMS
dataset), most of the attributes are nominal, ordinal or numerical types which a large range of values. We can not
expect to make a successful analysis, if we do not have an
initial categorization which makes ’sense’. What makes
sense - on the other hand - depends on the semantics of the
attribute and its context in the analysis and is - for now not accessible for automated processing. The only solution
to this is to leave the partitioning of the value ranges open
and controllable during analysis.
The visual interface which controls the partitioning for every attribute is described below in section 4.2. For later
use we define a partition combination as a tuple of natural
numbers (p0 , p1 , ..., pn ) ∈ {N}n , where n is the number of
attributes in the dataset. Every item in the dataset can be
assigned to exactly one partition combination. In the next
sections, we define the techniques and methods to present
the data and to define the interaction technique which establish an intuitive dialogue between user and machine,
respectively.

4

Modified Karnaugh-Veitch-Layout

The original Karnaugh-Veitch-Diagram provides a way
to display arbitrary Boolean functions and to analyze and
determine minimal Boolean normal forms visually. Even
if it was not interactive by the time it was invented, it
nonetheless marked a serious step to replace the tedious
computational effort by spotting patterns on a visual display.
In Karnaugh-Veitch-Diagrams Boolean min- and maxterms are mapped onto a 2-dimensional map. For n attributes the diagram consists of 2n cells each referring to
one possible combination of ’true’ or ’false’ values of the
Boolean function. Every attribute may be selected for either horizontal or vertical layout. Depending on the complexity of the dataset, not all attributes may be visualized at
once, however. The Gray code of all ’horizontal’ attributes
determines the horizontal ordering of cells and likewise for
the attributes arranged vertically. In terms presented above
the Karnaugh-Veitch-Diagram is a mapping of a partition
combination to x and y coordinates where |Ra | = |Pa | = 2
for all attributes.

11th International Conference Information Visualization (IV'07)
0-7695-2900-3/07 $20.00 © 2007

Our layout is a modified version of this layout with regards
to the following aspects:
1. The number of partitions for any given attribute is
not fixed. It can be changed to introduce a more refined categorization if the need arises.
2. The ordering of cells is not determined by the Gray
code - this is at least partially an implication of the
first aspect.
3. For the display of a Boolean function it is sufficient
to draw the cells with their Boolean values (min- or
maxterms), but this does not reflect the nature of our
datasets in virtually all cases. Instead the information displayed is a statistical correlation coefficient,
which we will describe in detail in the next section
4.1.
The first aspect covers the need to be flexible in our
choice of partitionings. A partitioning defines similarities
and differences of the data items, but it is not known a priori, which value ranges map to significant information and
how many partitions are needed to cover this information.
Note that the number of partitions used may differ for every attribute.
The actual layout function is a generalized variant of the
b-adic representation of numbers. Let {v0 , v1 , ...vt } be an
index subset of t attributes arranged vertically. Further let
pvi = Pavi (item), so that pv0 , pv1 , ..., pvt denotes the part
of the partition combination relevant for the vertical layout
of the corresponding —-bucket—- in the dataset. The x coordinates for every cell are derived from this combination
as:
Cx =pvn +|Pavn |·(pvn−1 +|Pavn−1 |·(pvn−2 +...|Pav1 |·pv0 ))

(1)

The same scheme applies to the y coordinates using the
partition combination for attributes aligned horizontally.
Note that pvi < |Pavi | for all attributes. Hence, the function is invertible and if (for example) |Pav0 | = |Pav1 | =
... = |Pavn | = b this scheme exactly matches the badic representation of a number. The modified KarnaughVeitch-Layout subdivides the visual display into a number
of cells, based upon the number of attributes shown and
a partitioning of their respective value ranges. In the next
subsection we will describe which information actually is
displayed.

4.1

Statistical Correlation Coefficients

As stated above one of the main goals is to identify patterns, which correspond to significant information regarding specific attributes. A typical elementary analysis scenario consists of a subset of the data items being given,

which is the target set T . This subset may or may not have
significant internal similarities and/or is distinct from all
other data items not in the target set. Finally attributes and
value ranges which characterize the target set provide additional inherent information about the data set which we
may call ’knowledge’. With a large number of possibly
significant attributes at hand, our strategy is first to discard
unimportant attributes and later to refine the partitionings
to get significant value ranges and to get a clear distinction.
Every cell in the display corresponds to a specific partition
combination, which in turn represents a specific subset of
the overall dataset, called bucket. The method of choice is
to compute the statistical correlation coefficient between
every bucket and the target set: For any given bucket B
we count the number of data items contained in the bucket,
and the number of those items which additionally lie in T
(T, B) =

E(i∈T ∩B)−E(i∈T )·E(i∈B)

√

V ar(i∈T )·V ar(i∈B)

(2)

with i being an item in the dataset. E() and V ar()
denote the statistical expectancy and variance functions
respectively. The resulting value lies in the interval
[−1.0..1.0] and can easily be mapped onto a color spectrum. These values, however, are only theoretical boundaries and can only be reached if exactly one bucket matches
the target set or if exactly one bucket excludes the target
set.
In most cases, depending on the distribution of the target
set across the buckets, the coefficients lie close to zero
- even if they represent significant information. For the
analysis and for the identification of patterns it is more
important to spot qualitative differences rather than the actual numerical values (i.e. negative coefficients (blue and
green) must clearly be distinguished from positive (yellow
and red) or close-to-zero (white) coefficients). Hence the
colormap has the highest contrast close to zero. Depending
on the actual minimum and maximum coeffients the highcontrast-area can simply be adjusted via the mouse-wheel.

4.2

Histogram control

One of the main differences to the original KarnaughVeitch-layout is that the number of partitions for any given
attribute is not fixed as is required for a successful analysis for non-Boolean data. Most of the attributes in the
dataset available are numerical or at least ordinal value
types. Hence to control the partitioning, the mapping of
the value range of an attribute onto a (multi-)slider became
a nearly obvious solution.
Every partitioning consists of at least a single partition.
Further partitions can be inserted or removed by splitting
or merging of existing value ranges. The sliders can be
moved arbitrarily within the boundaries of the adjacent
partitions. Every operation causes an update of the internal

11th International Conference Information Visualization (IV'07)
0-7695-2900-3/07 $20.00 © 2007

view configuration which in turn issues a recomputation
of the buckets affected. Usually the insertion of new partitions causes the patterns to ’sharpen’ as the data set is
divided into smaller fractions.
With the general goal to find a minimal representation a
feasible strategy is to include as much categories as possible and then merge adjacent partitions which cover the
same information regarding the target set. The only limit
to this approach is the number of categories which can be
used for visualization. To give an additional hint for the
selection of partitioning boundaries, we included a histogram of the distribution of attribute values to the multislider. Being a completely passive display it nonetheless
may serve as a hint for an initial partitioning.

Figure 2: Multislider histogram for a single attribute.
The histogram itself shows the distribution of attribute
values in the dataset (height of columns), the correlation
of every individual value-bucket with the targetset (color
of columns) and the actual partitioning of the valueset
with the multislider. The color serves as a hint to find a
’meaningful’ initial partitioning in terms of submitting
information about the relation between this attribute and
the target set in the map.

4.3

View configuration

In theory, every cell in the display can be mapped to
cover a single pixel, but aside from sampling issues this
would not be feasible for working with the data, (which
will include mouse-clicking, see section 5). The number
of cells in x or y direction depends on the number of attributes selected for horizontal or vertical layout and the
partitioning size.
Having at least two categories for every attribute there is
a space for 16-18 attributes on an average-sized desktop
display. Because the number of cells in horizontal or vertical direction is limited, a trade-off must be made between

the number of categories assigned to one or more attributes
and the number of attributes to be visualized. Depending
on the complexity of the dataset, it is impossible to show
the complete dataset with this approach in many usage scenarios.
To solve this problem we choose not to increase the complexity of the visualization, but to encourage a step-by-step
strategy for a data analysis. With every step a decision is
made about the significance of the attributes selected in the
visualization. The analysis refines the representation of the
target set in two directions: One of the goals is to discard
a number of unimportant attributes simply to make room
for new attributes into the visualization. Another aspect is
that a successively smaller subset of the data is chosen for
visualization, which should be an approximation of the target set with increasingly better accuracy. The represent the
current state in the visualization there are several aspects
to consider: It consists of
• the subsets of attributes which are arranged in horizontal or vertical fashion,
• the current partitioning of every attribute,
• a flag for every partition indicating if it is actually
selected for display,
• and the target set
Note that this configuration slightly differs from the layout
described above in this section. For simplicity we did not
mention that not all categories of a partitioning must be
visible. It is sufficient to know, that if |Pa | only denotes
the number of visible categories of an attribute a, the layout scheme works as described.
The main difference is rather technical: An item, which
has an attribute value which does not lie in a visible value
range, simply must be discarded by the partitioning function Pa . This is the actual point where the successive
approximation of the target set is done. The target set can
actually be any subset of items in the data set, e.g. given as
an explicit list.
In order to the increase the chance to create target sets with
a ’meaning’ and to gain more flexibility, we use the same
histograms which steer the visualization for the definition
of the target set. In this case the target set is defined as
a conjunction of attribute categories. As a result, we are
free to choose two (disjoint) subsets of attributes. The
first one defines the target set (e.g. all households which a
’high’ tax property amount) and second one as a collection
of attributes visualized in the layout to verify if there is a
multivariate correlation between the attributes visualized
and the ’target’ attributes.
What actually is a ’high’ tax property amount is subject to

11th International Conference Information Visualization (IV'07)
0-7695-2900-3/07 $20.00 © 2007

the refinement of the target set definition: Depending on
the significance of the patterns detected, the definition of
the target set can be changed in same way as the categorization of the visualized attributes, which would be typical for
an undirected search, where the actual target is not clearly
outlined a priori. The two attribute subsets must be disjoint, because otherwise this would introduce unnecessary
trivial dependencies into the Karnaugh-Veitch-map. How
the visual analysis process intuitively supports strengths of
the human visual cortex is part of the next section.

5

Enhanced Interaction - Visual identification of patterns in the data

Finding a representation of the target set is not the main
goal of an analysis - even a simple list would be a viable
representation. The core task is to find a minimal representation which is completely independent from the one given.
Indepedency means, that it does not contain dependent attributes which are already in the initial representation and
it guarantees that the new representation represents ’new’
knowledge. The representation should be minimal in terms
of the number of literals.
From m ’clicks’ into the map, m partition combinations
can be gathered. From this information, a minimal represention of the significant combination should be derived.
In turn this minimal representation corresponds to a specific set of cells in the modified Karnaugh-Veitch-layout
(much like the boxes of min- or maxterms in the original
Karnaugh-Veitch-map), which are supplementary marked
by the system to ’await approval’ by the user. The systems
instantly reacts upon these ’clicks’ because of two reasons:
1. A complete pattern in the display may consist of a
large number of cells and it can be tedious to mark
them all.
2. Outliers or other patterns must be distinguishable
from the specific pattern currently analyzed, because
they stress the ability of the system to find an efficient minimal representation.
The feedback of the system provides a visual matching between patterns that the user can see (as a color pattern) and
patterns that the software reproduces (as a luminance pattern) from its estimated minimal representation, which can
be compared in the same display to ensure that both machine and user refer to the same subset.
The visual identification of patterns in the data is one of
the core features of the system. Technically it is semiautomatic process which establishes a close-knit link between machine and the human user on the basis of the visualization layout presented above. In any current view configuration the user is able to mark features which seem to

be significant in the context of the current analysis, simply
by clicking on some cells on the map, for example those
with an exceptional high or low correlation. Under the assumption that the interaction has a specific target (i.e. it is
not chaotic), the information gathered may follow a characteristic pattern (see figure 3). This information basically
consists of the cell layout coordinates (Cx , Cy ) which can
easily be mapped onto the corresponding bucket and its
partition combination.
For simplicity we do not divide attributes by their horizontal or vertical layout, since this is not necessary to describe
this method. Let {(pa0 , pa1 , ...pan )i }i=1..m be a set of m
partition combinations. The general idea is as follows:
We examine every attribute individually. Then the series
{(pa )i }i=1..m match a characteristic distribution for any
given attribute a. Remember that (pa ) < |Pa | is the identification number of the category. If these series is evenly
distributed among the current categories of the attribute,
the distribution does not confer information that any set
partition is ’preferred’ over others. Such an attribute would
not be selected for a minimal representation.
In contrast, if the distribution prefers a single category
above all others, it confers the information that this category is very likely to be preferred in the selection of cells
and consequently should be in included in a minimal representation. The problem is that between those two extreme
cases lies a wide range of possible ’fuzzy’ distributions,
which finally must be mapped onto a selection of specific
attributes and partitions. To assess the significance of a
distribution for our approach, we use the formula for wellknown Shannon-entropy. Let h1 /m, h2 /m, ..., h|Pa | /m
be the normalized distribution of selected partitions of an
attribute a, then
Φa = −

|Pa |
i=1

1
log2 |Pa |

(hi /m) · log2 (hi /m)

(3)

yields the normalized entropy in the interval [0.0..1.0].
The higher this entropy value is, the lower is the significance of the attribute.
The goal of this scheme is to give a visual hint, which pattern information is extracted from the user input. The idea
is to decrease the brightness value of any cell, depending
on the estimated likelihood of the cell belonging to the
input pattern. Every cell corresponds to a unique combination of partitions, each of which has a different significance, hence we calculate a ’luminance factor’ L for each
cell with the product:
L (Cx , Cy ) = 1 −

n
i=0

(φ(hi /m) · (1 − Φai ) + Φai )
(4)
The function φ() returns a value in [0.0..1.0] depending
on the significance of a attribute ai and of the significance

11th International Conference Information Visualization (IV'07)
0-7695-2900-3/07 $20.00 © 2007

of the specific partitions pai associated with the cell. In
essence φ() : [0..1] → [0..1] stretches the interval to increase contrasts around the ’neutral value’ ν = (1/n) .
With a alpha exponent α, it is defined as:
ν−ν·
φν (x) =

ν + (1 − ν) ·

ν−x α
ν
α
x−ν
1−ν

for x < ν
for x ≥ ν

(5)

Thus the luminance of a cell is a combination of the overall significance of an attribute 1 − Φai and a specific value
for the corresponding partition φν . The product ensures
that partition combinations, which match the selected cell
in most or all significant attributes, are preferred superproportionally. Cells belonging to the pattern matching the
one selected by the user appear darker by their matching
degree. It is sufficient to mark only a few cells in a pattern to get a feedback on the minimal representation. This
method has to important implications:
1. The type of expressions, which can represented using this scheme is always a conjunction of partition
subsets of the (significant) attributes.
2. There may be more than one simple pattern displayed in the map, see (see figure 4).
The first implication means that a single pattern must
have a relatively simple form, the second one implies that
it might be necessary to tell different patterns from each
other. As only one pattern can be examined in detail (via
zooming), the identification of different patterns marks a
’branching’ point in the analysis, where the correlation between the target set and the current set of visual attributes
turns out to be a complex rule, which can not be minimized
in one simple expression, which is the topic of section 5.1.

5.1

Navigation in the analysis space - pinning interesting information

The problem which arises in an extensive analysis process is that the current visualization configuration only
covers the current state. In common analysis scenarios,
the session does not progress in a linear fashion or concludes with a single final result. More often the analysis
reaches a point, where all interesting features in the data
set are partial results, which are gathered and consolidated
to produce input for the next step. This requires that all
interesting features can be easily distinguished from uninteresting information and that a ’strategic’ overview exists,
which covers the analysis process as a whole, from which
the interesting parts in the hierarchy can be revisited, if
necessary.
This kind of navigation model is not limited to specific use

for the maps presented here. Its actual requirement for use
is a formal model for a view configuration (which might
include more than one visualization). The idea is to create
an abstract view of the analysis, where every view configuration is depicted as a node in a graph. With every significant change in the view configuration (removing/inserting
visual attributes, merge/split partitions, redefine the target
set) a new node is created in this graph. Every branching
point in the analysis usually is a point, where the analysis
starts to focus on a more refined subset of the data or of the
attribute set.
If an analysis path is exhausted (no additional information
can be gathered in a branch), it is necessary to identify the
last ’interesting’ point in the analysis hierarchy and to jump
back. A ’mouse-click’ on the node in the hierarchy issues
the command to return to its view configuration.
For explicitly identifying a interesting view or an interesting pattern, we choose a visual metaphor well known from
other office work: The modified Karnaugh-Veitch-Map is
equipped with a virtual pin-board. Every pattern, which
might be interesting but currently lies beyond the focus of
analysis, can be marked for later use, by dragging a pin
onto a cell. Additionally this pin is represented as a marker
on the corresponding node in the analysis tree, indicating
a view configuration, which contains a branching point, or
even a point, from which a partial result can be derived.
Hence this scheme is useful for a valid navigation in the
analysis space and for a collection of the final results.
Actually the ’interestingness flag’ set for a view configuration is just a start. The analysis hierarchy is the frame,
where a large number of meta information can be stored
in for later use. Currently the graph layout is a purely automated process (using an iterative force-feedback scheme
known from graph-based visualization of relations), which
is independent from other meta information. Yet the abstract view on the analysis leaves much room for ideas beyond the scope of this paper, some of which are briefly
discussed in the last section 6.

6

Conclusion and future work

We made an undirected analysis of the PUMS-dataset
with the methods presented here. Having no prior knowledge about the actual data, we started an analysis with
households with a ’low’ tax-amount as a targetset and a
random selection of attributes to be considered. After few
steps, we were able to tell if there are multivariate dependencies which are worth a closer look at. The feedback
ensures, that we are able to identify outliers or concurring
patterns at an instant. Because the valid patterns are not of
an arbitrary shape and they do not form a contiguous block
in most cases, some training effort is needed to able to spot
different patterns at a glance, but this also applies to the
’original’ Karnaugh-Veitch-Diagrams.

11th International Conference Information Visualization (IV'07)
0-7695-2900-3/07 $20.00 © 2007

We presented visualization method for the multivariate
analysis of large and complex datasets. We combined this
method with a flexible interface for the categorization of
value ranges of virtually arbitrary types to ensure a broad
range of applicability. The quality of the categorization
used is visible in the contrast of characteristic color patterns in the map. The patterns itself are representations of
subsets of the data or attributes which embody significant
information.
The Identification of patterns and the optimization of their
representation are two tasks which are distributed onto user
and machine respectively which cooperate on the basis of a
strong visual coupling in short iterative cycles. The resulting mapping from subsets of the data onto a minimal representation is used to delve deeper into the dataset (because
unimportant attributes or categories can be discarded leaving room for others) or - at the end of an analysis branch be used as an elemental result.
To keep track of the results in all branches of an analysis session, we couple the analysis with a parallel creation
of a hierarchy of ’views’ reflecting the analysis paths as a
tree, which in turn can be used for navigation. Pins used
as ’landmarks’ in the analysis space, can be used to mark,
revisit and finally gather, important partial results in an extensive analysis session.
Our future work on this topic clearly heads in two directions: The first one is a stricter formalization of statements
about data with a special reference to the need to visualize and work with them on a broad basis. Fundamental to
the generation of concepts and hypothesis, the combination of elemental analysis artifacts is one issue which also
should be supported by direct visual manipulation and verification with raw or aggregate data, which is done here
for relatively simple Boolean statements. The other major
topic is the extension of the visualization of the analysis.
Independent from the actual application, this visualization
should answer questions which may appear in virtually any
analysis: Is this important? Have I been here before? Am
I finished here? Is there a connection between different
branches in the analysis? For a visual definition of the
analysis space, the graph layout could be derived from a
generic metric, defining the similarity of view configurations, among many other possibilities, visual quality markers can be embedded in the node visualization. The goal of
such a navigation is to organize the process and to establish
a coherent strategic perspective as foundation to communicate and collaborate.

References
[1] Maurice Karnaugh. The Map Method for Synthesis of
Combinational Logic Circuits, Transactions of American Institute Of Electrical Engineers, part I Vol. 72,
No. 9 p593-599

[2] Daniel A. Keim Designing Pixel Oriented Visualization Techniques: Theory and Applications, IEEE
Transactions on Visualization and Computer Graphics, Vol. 6, No. 1, 2000

[12] Jose Rodrigues, Agma Traina, Caetona Traina. Visualization Tree, Multiple Linked Analytical Decisions, 5th International Symposium on Smart Graphics 2005

[3] Daniel A. Keim, Hans-Peter Kriegel and Mihael
Ankerst. Recursive Pattern: A Technique for Visualizing Very Large Amounts of Data, IEEE Visualization,
Proceedings of the 6th Conference on Visualization
95, p279f

[13] Jarke von Wijk and Huub von de Wetering. Cushion
Treemaps: Visualization of Hierarchical Information,
IEEE Symposium on Information Visualization 1999

[4] John T. Langton, David K. Wittenberg and Timothy
Hickey. Leveraging Layout with Dimensional Stacking and Pixelization to Facilitate Feature Discovery
and Directed Queries, View 2006, Paris, France
[5] Bartlomiej Sniezynski, Robert Szymacha and
Ryszard Michalski. Knowledge Visualization Using
Optimized General Logic Diagrams, Proceedings
of the Intelligent Information Processing and Web
Mining Conference, IIPWM 2005, Gdansk
[6] Frank van Ham. Using multilevel call matrices in
large software projects IEEE Symposium on Information Visualization 2003
[7] Jing Yang, Matthew O. Ward and Elke A. Rundensteiner. Visual Hierarchical Dimension Reduction for
Exploration of High Dimensional Datasets, ACM
Proceedings of the Symposium on Data Visualization
2003, p19-28
[8] Christopher M. Bishop and Michael E. Tipping. A
Hierarchical Latent Variable Model For Data Visualization, IEEE Transactions on Pattern Analysis and
Machine Intelligence, Vol. 20, No. 3, 1997
[9] Fabian Bendix. Visual Analysis Tool for Categorical
Data - Parallel Sets , Proceedings of the 9th Central European Seminar on Computer Graphics 2005,
http://www.cescg.org/proceedings.html
[10] Alfred Inselberg and Tova Avidan. Classification and
Visualization for High-Dimensional Data, ACM Proceedings of 6th SIGKDD on Knowledge discovery
and data mining p370-374
[11] Dacheng Tao, Xiaoou Tang, Xuelong Li and Xindong
Wu Asymmetric Bagging and Random Subspace for
Support Vector Machines-Based Relevance Feedback
in Image Retrieval, IEEE Transactions on Pattern
Analysis and Machine Intelligence, Vol. 28, No. 7,
2006

11th International Conference Information Visualization (IV'07)
0-7695-2900-3/07 $20.00 © 2007

[14] Ivan Herman, Guy Melancon and M. Scott Marshall.
Graph Visualization and Navigation in Information
Visualization: a Survey, IEEE Transactions on Visualization and Computer Graphics, Vol. 6, No. 10,
2000
[15] David Kenwright. Automation or Interaction: What’s
best for big data? Visualization 1999, Proceedings,
p491-495

Figure 3: Interactive pattern evolution. One by one 8 cells are been marked (b)-e)), and in every step the system tries to
identify a ’best match’ and reproduces the pattern on a luminance scale in the same display. A single outlier (see f)) is easily
identified. Note that the cells which have been selected manually appear black, the others appear in shades of gray. Without
setting an a priori threshold the process may be stopped at any given step.

Figure 4: Global view to an analysis session. The correlation value is mapped to blue (strong negative), green (weak negative), white (zero) then yellow (weak positive) and red (strong positive) colors. We start with two attributes with four
categories each a). The number of attributes is increased to seven b) until a color pattern emerges, which seems to be worthy
of further investigation. This pattern is identified by a few mouse clicks c) (see also figure 3) until the luminance pattern
matches the color pattern on the screen. As a partial result the pattern can be marked by a pin d) and is displayed in the
’strategic view’ of the analysis tree.

11th International Conference Information Visualization (IV'07)
0-7695-2900-3/07 $20.00 © 2007

