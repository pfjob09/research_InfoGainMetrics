Information Highlighting
Timothy Ostler
Anaphora Ltd.
anaphora@cogarch.com

Abstract
This paper reports on an empirical study in which, for
the purposes of developing an automatic highlighting
tool, 11 subjects were asked to highlight important
passages in an 1111-word text. These results were crossreferenced with a range of word attributes in order to
test hypotheses about the principles underlying
highlighting decisions. With this data a combination of
selection criteria was proposed that was able to predict
probability of highlighting with a correlation of
approximately 0.56, compared with an average
correlation of 0.47 amongst the test subjects, and a
figure of 0.30 for Word97’s highlighting feature. The
paper argues that the common factor behind the most
successful hypotheses was that they are all signals
denoting “new” as opposed to “given” information at
the discourse level. Although based on a very limited
sample this observation seems clear enough to make
detecting such signals a promising candidate for further
research.

1. Introduction
1.1 Highlighters as an established tool
The practice of using yellow fibre or felt pens to
highlight text appears to have begun in the USA during
the 1960s, but it was not until 1971 that Schwan-Stabilo
of West Germany launched the first highlighter pen to
use fluorescent ink.
Today highlighters are in widespread use, and there is
an intuitive impression that for a student the process of
highlighting (or other forms of visual cueing such as
underlining or bars on the margin) and annotation itself
plays a vital process in the revising process, perhaps by
encoding or priming material that is then incorporated
into long-term memory during revision. This view is
supported by the findings of Hult et al. [2], who found
that note-taking does indeed involve semantic encoding.

Highlighters are also used to mark up a text for the
selective attention of another person and, because of its
clear application to the problem of information overload,
it is this function that was chosen to study with a view to
developing TextLight, an automatic highlighting tool
(this paper describes only a brief subset of the research:
see the original paper for a study of the cognitive
function of highlighting and more extensive examples
[1]). To this end, an experiment was conducted to define
suitable heuristics for text selection.

2. Previous work
2.1. Criteria for word selection
Herbert Dreyfus once asked if the ability to
discriminate between the important and the unimportant
was a fundamentally human cognitive operation ([3],
reported in [4]). However, many genres have become
formalised with tacit agreement on the conventions
signalling different stages in a discourse. So while it may
never be possible to tell what seems important for every
person, arguably we can broadly distinguish what is
being presented as important.
A weakness of all research into visually cued text has
been the absence of formal rules governing which text
should be cued. Here Foster’s research of 1979 [5] is
perhaps most apposite. 26 students and lecturers were
given a 3400-word text and asked to underline sentences
that they thought contained the key ideas the author was
trying to put over. Foster asked his subjects to use
sentences as the minimal unit for underlining.
The terms of the experiment were tightly drawn. In
one condition, subjects were told not to underline more
than 16 sentences. In the other, not more than eight.
In the first case the 213 selections spanned 80
sentences, with only nine sentences being selected by six

Subject
Sex
Total highlighted
Percentage highlighted
Correlation

M1
M
50
4.5
0.28

F1
F
291
26.19
0.48

M2
M
132
11.88
0.42

F2
F
396
35.64
0.67

F3
F
306
27.54
0.47

F4
F
167
15.03
0.34

M3
M
283
25.47
0.63

F5
F
257
23.13
0.32

M4
M
204
18.36
0.43

M5
M
97
8.73
0.35

M6
M
341
30.69
0.41

Ave
M
166.8
15.01
0.43

Ave
F
283.4
25.51
0.45

Ave
MF
231.8
20.86
0.43

Table 1. Test results with averages by sex and overallg

Total highlighted
Percentage highlighted
Correlation

Situation
203
18.27
-0.19

Problem
461
41.49
-0.01

Solution
153
13.77
0.28

Evaluation
294
26.46
-0.05

Table 2. Problem-Solution model status vs. probability of highlighting

Total highlighted
Percentage highlighted
Correlation

Prox to
Seg S

Prox to
Para S

0.33

0.16

Present
tense
600
54.01
0.21

1st ass
(dseg)
185
16.65
0.44

1st ass
(quote)
108
9.72
0.23

List
status
42
3.78
0.17

Sol’n
Status
153
13.77
0.28

Hybrid
Hypoth
398
35.82
0.56

Subj ave
MF
231.8
20.86
0.43

Best
hypoth
398
35.82
0.56

Table 3. Alternative criteria vs. probability of highlighting

Total highlighted
Percentage highlighted
Correlation

Word97
Cond. 1
155
13.95
0.2

Word97
Cond. 2
405
35.82
0.3

Data
Hammer
353
31.77
0.02

Subj ave
M
166.8
15.01
0.43

Subj ave
F
283.4
25.51
0.45

Table 4. Comparison of highlighting selection strategies

or more judges. In the second, 102 selections were
distributed over 52 sentences, with only two being
selected by six or more. Foster concluded that it would
be difficult to identify sections of text for cueing.
In other experiments the information on word
selection was more incidental and merely records what
the experimenters chose to do with their test materials
rather than what subjects were found to do in an
experiment. Klare et al, [6] cued single words. Dearborn
et al. [7] emphasised the one word carrying the “peak
stress” in a sentence but did not describe how this word
was selected. Crouse & Ildstein [8] and Fowler & Barker
[9] cued statements or sentences. The most specific
suggestions came from Hershberger & Terry [10], whose
“core” content made up one third of the total text length
and consisted of new key words, familiar key words, key
statements, basic core statements, key examples and
rephrasing of key statements.
How much text should be cued has also remained an
open question. Foster [5] suggested that in a particularly
dense text, more text might be considered to be “core”
than “enrichment”, leading to most of the text being
highlighted and a figure-ground reversal making the
enrichment and not the core most prominent. Crouse &
Ildstein [8] suggested that the density of cued material
influences its effect. Foster [5] commented that the
optimal proportion of text to be highlighted had still not
been established. Fowler & Barker [9] pointed to the
large variance (4.2% to 32.1%) observed in the
proportion of text highlighted by members of the test
group who were asked to highlight for themselves. Asked
to highlight passages of structural importance, Rickards

& August’s [11] test subjects all chose passages that
Rickards & August considered relatively unimportant
when they themselves highlighted the text.

2.2 Experiment
2.2.1. Procedure. 11 subjects — 6 male and 5 female —
were provided with an 1111-word article from the
Financial Times IT Supplement [13], brief instructions
and a questionnaire. They were asked to imagine they
were corporate librarians identifying the key points in an
article for a board member. The questionnaire sought
details about subjects’ past experience of highlighting,
their criteria for text selection, at what points during the
process they made their selection, and other comments.
2.3.2. Performance metric. The article itself was input
into a spreadsheet as a column spanning 1111 rows (one
word per row). Along each row were entered the
attributes associated with each word, which fell into 36
categories. For each word the probability that it lay
within a highlighted passage was given a decimal figure
between 0 and 1.
All other parameters were also rebased to give figures
falling between 0 and 1. Some parameters, such as the
part of speech of a particular word, already existed as
Boolean values, treated here as 1 or 0. Other parameters,
such as the proximity of words to the beginning of
dicourse units such as sentences or paragraphs, were
expressed as a decimal number between 1 and 0 (1 for
the first word in the unit, 0.5 for the middle word and so

on). In this way it was possible to calculate the
correlation of any given parameter with the probability
that a word fell within a highlighted group of words. The
degree of correlation was calculated using Excel’s
CORREL() function.
2.3.3. Results. The results are given in Tables 1 to 5.
They show a wide variance in terms of the number of
words highlighted, from a minimum of 50 (4.5%) to a
maximum of 396 (35.64%). There was also a marked
difference between male and female subjects, the males
averaging 15% and the females 25.5% In general there
was little correlation between part of speech/syntactic
role and probability of highlighting, but there was a
noticeable association with longer words.
Although the experiment generated 39,996 data
elements the results are open to question as serious
experimental data especially as all this data was
generated from only one text. Nevertheless this is an
aspect of human reading activity that has been
insufficiently studied in the past and the results are
enough to suggest ample pointers to future research in
this area.
Most importantly, it provided a basis for generating
hypotheses about human highlighting decisions, and for
testing those hypotheses. Comments by subjects
indicated that none of them made their highlighting
decisions before having read at least a paragraph. A large
majority (70%) delayed highlighting until the whole
passage had been read. This suggests that.decisions were
made at a discourse-analytical and not a strictly linguistic
level.
The variance in the proportion of words highlighted
was strikingly close to that observed in Fowler & Barker
[9]: 4.5%-35.64% as against 4.2% to 32.1% in the earlier
study. This offers a guide for where to set upper and
lower limits in highlighting proportion for TextLight
.The form in which these results appear makes them
hard to compare with Foster [5]. The average correlation
between any one person’s highlighting decisions and the
scores for probability of given words being highlighted
was 0.44. However, for any individual word the
probability of being highlighted varied between 0 and
0.83, offering clear guidelines for assessing any trial
selection criteria

3. Development of selection heuristics
3.1. Derived criteria
Correlation with the percentage proximity of each
word to the beginning of the paragraph proved relatively
strong at 0.16. More strikingly, correlation with the same
measure as applied to discourse segments (parsed by
hand) was 0.33. Parsing of the article into the constituent

parts of the Problem-Solution model was not a simple
task because of the degree of recursive nesting. However,
when this analysis was carried out (again by hand) there
was a strong positive correlation with Solution and a
slightly weaker negative correlation with Situation.
Attempts were made to combine these and other criteria
that seemed promising. However, some of these
weakened in combination with other criteria.
The most successful combination was found to be the
satisfaction of any one of four criteria:
1)
The word should be part of the first assertion in
a discourse segment
2)
The word should be part of the first assertion in
a quotation that was not an immediate continuation of a
previous quotation.
3)
The word should be part of a list.
4)
Given an analysis of the text according to the
“Problem-Solution” discourse structure, the word should
be part of a passage in the “Solution” category.
The best hypothesis produced a 0.56 correlation with
actual highlighting probability. Bearing in mind that the
performance metric was governed by a list of
probabilities that individual words would be highlighted,
we should not expect any test subject to achieve a
correlation of 1.00 with the consensus. In fact this figure
varied between 0.28 and 0.63, with an average of 0.43. In
other words, selecting text according to the specified
criteria achieved a correlation with the consensus
selection that was greater than all but one of the test
subjects achieved, and considerably higher than the
average.
The percentage of the article highlighted using these
criteria was, at 35.82%, at the top of the range of
percentages shown by the test subjects (perhaps
coincidentally, this proportion was similar to the
proportion allocated to “core” content by Hershberger &
Terry [10]).
For the purposes of additional comparison the study
text was passed through the program Data Hammer [12]
at a specified percentage of the original article that was
as close as practicable to that resulting from the best
hypothesis. The retained words were charted alongside
those retained by Word97’s Auto-Summarization feature.
They showed no significant correlation with the words
highlighted by the experimental subjects. This
demonstrates the difference between retained in a
summary and those chosen for highlighting. In the
former, unimportant words must be retained in order to
give context; in the latter, they can be more or less
ignored as they remain visible. Even so, the words
highlighted by Word97’s statistically-based feature as
“key points” are indeed the same as those retained in the
equivalent summary, and the correlation performance
proved moderately positive, at 0.3.
Although the results achieved by the specified criteria
derived from the experiment seem good, the rules

observed are only secondary characteristics that depend
upon identifying the markers denoting more basic
discourse elements, namely the following:
1)
Discourse segment boundaries
2)) Simple assertions
3)
Lists
4)
Passages that fall into the “solution” category

3.2. Identifying primary markers
3.2.1. Discourse segments. Because the test article was
manually segmented the efficacy of one means of
discourse segmentation rather than another is not strictly
relevant. Nevertheless the identification of cohesive
markers and their physical relationship to the passages to
which they cohere offers fruitful possibilities for
discourse segmentation in any attempt to create an
automatic highlighter.
3.2.2. Simple assertions Paragraphs normally begin with
a proposition, sometimes preceded or followed by a
question or other linguistic feature that maintains
cohesion makes the proposition’s relevance to the
preceding text clear. This feature is referred to as a
coherence relation, and is analogous to clause relations
that provide similar connection at the sentence level. The
text that follows tends to fill out details and/or provide
supporting evidence for the assertion.
Discourse segments most commonly coincide with the
beginning of paragraphs, and so also normally begin with
a proposition. The rule that was found to emulate
subjects’ highlighting choices at the beginning of
segments most effectively was to select the segment’s
opening proposition in its simplest form, without any
introductory coherence relation before it. Where one
sentence is embedded inside another, as in: “Mr Courtot
is keen to point out that Topic is far more effective than
the popular Internet search engines because it reads
each document and therefore returns a more accurate
answer to queries.” (highlighted words in bold). the
embedded sentence is selected, together with the
causative clause supporting it.
3.2.3. Lists. What for the purposes of this exercise we
refer to as lists comprise the first of six categories of
prediction in expository text identified by Tadros [14]:
enumeration, advance labelling, reporting, recapitulation,
hypotheticality and question. Each category consists of a
pair of members: a V member, which is predictive, and a
D member that fulfils the prediction.
3.2.4. The “Solution” category. As yet, no unifying
overall theory of discourse structure analysis exists, and
it remains an imprecise science. The more a genre is
subject to formal convention, however, the more likely it

is we can overlay this structure literally on a text.
It is outside the scope of this study to present a
comprehensive list of the range of discourse structures.
However, one particular schema recurs frequently across
a range of genres. This is the “Situation-ProblemSolution-Evaluation” structure, usually referred to as the
Problem-Solution structure. It is as characteristic of
narrative structures (e.g. Boy meets girl—Boy loses
girl—Boy regains girl—Boy & girl live happily ever
after) as of feature articles (e.g. Dogs make great pets—
However they can get fleas—Winalot have now launched
a new anti-flea dog food—Owners all over Britain have
declared it a success). News stories, however, tend to
follow a somewhat different schema [18].
The structure can be nested recursively: for example,
an account of a previously resolved problem may form
part of the Situation; equally, if a Solution is evaluated
negatively it becomes a new Problem. For example, if in
the example above the final clause was “Owners all over
Britain say that it’s useless”, there would be an
expectation that this would be followed by “So Winalot
have brought out a new formulation—This one is
reported to work very well”.
How do we recognise the elements of this structure?
Hoey [15] demonstrates how it can often be recognised
by means of lexical signalling cues, i.e. certain words or
word roots tend to be associated with particular stages of
a discourse. At the most basic level, the stage labels
themselves may occur within the text, viz.
“Cars are a common way of getting from A to B.
However, the congestion that they cause is a problem.
The solution is to get people to use public transport. In
this way everyone can get to work quickly.”
Hoey argues that discourse structure is essentially
evaluative. For instance, in the case of the sentence “If
thyristors are used to control the motor of an electric
car, the vehicle moves smoothly but with poor efficiency
at low speeds” its status as a Problem is signalled by the
negative evaluation “poor”.This suggests that we may b
categories simply by spotting cue words or phrases in a
given passage.
Because in the experiment it was only the Solution
category that was found to have a significant correlation
with highlighting, we can afford to concentrate
exclusively on words and phrases associated with this
category.
Hoey cites two examples of such signals: the use of
words to do with “solving”, “developing” or “inventing”,
and the change of verb form into the present perfect
tense, indicated by “have -ed”. Once the response has
been generally described, the form reverts to the simple
non-past to denote that a new situation exists, which
results from the application of the solution.

4. Discussion

4.1. “Given” and “new” information
Why were the best algorithms more effective than
others? What indications did they convey for possible
extensions to the specified criteria? An insight first
expressed by members of the Prague School before the
Second World War [16], is that information is composed
of a mixture of “given” and “new” information.
From the experiment, there is clear evidence for an
interpretation that the essential factor behind the choice
of text to highlight is that they are all ways in which
“new” information is signalled at the discourse level.
This hypothesis is supported by the frequency (80%)
with which subjects stated that they were highlighting
words that “marked significant stages in the narrative.”
The acceptance of the word “stage” implies a view that
the text is organised as an ordered whole that moves
successively from one topic to the next. As to the use of
the word “important”, it is this author’s opinion that an
idea’s perceived importance is judged according to the
extent to which it is:
a) new as opposed to given, and
b) matches a perceived gap in the structure of the
reader’s domain knowledge.
Another concept of importance in a discourse topic is
given by Brown & Yule [16]: “A hypothesis underlying
much of the work we shall report is that there is a
specific connection between “discourse topic” and
“discourse content”. The former can be viewed as, in
some sense, comprising the “important” elements of the
latter.
An author will judge information to be important if he
expects it to be new in the context of the intended
audience’s knowledge base. Meanwhile, when a person is
highlighting on behalf of someone else, he has to make
an informed judgement on which information might fall
into this category as far as the ultimate reader is
concerned.
Halliday [17] concluded that in spoken discourse,
intonation is used to signal to the listener what the
speaker understands to be new information. It does not
take too great a leap to equate the process of highlighting
a passage in written text with raising the pitch of one’s
voice to indicate new information. If we do, we can
conclude that the large amount of research that has been
carried out on intonation and prosody in speech will have
much to contribute to what we might presume to call a
“theory of highlighting.”
We have seen how paragraphs usually begin with an
assertion, preceded by a coherence relation to the
foregoing text and followed by supporting information.
In the case of discourse segments, the relation is less
with the preceding paragraph and more with the overall
strategic structure of the argument. In these terms, the
assertion at the beginning of a paragraph can be

considered as a supporting (and supported) structure for
the assertion at the beginning of the discourse segment
that contains it. Meanwhile this assertion operates as one
of a small number of primary assertions that contain the
major part of the “new” information in the document.
An assertion within a quotation is a special case. The
quotation will not in most cases be the only thing the
person being quoted said, but instead a passage
assembled or selected by the author from a finite set of
verbatim statements. Given this limited supply, quoted
statements hold a special status that increases their
apparent significance to the reader within a mass of text
for which the author otherwise has an unlimited range of
statements available.
The common highlighting of list elements is also
consistent with the “new” information hypothesis, as lists
typically act as a systematic and concentrated tabulation
of what the author believes to be important (i.e. “new”
and relevant) information. A speaker conveying the same
information might very well emphasise this by counting
the points off using the fingers of his hand.
Finally, the preference for highlighting Solution
stages can also be viewed in terms of “new” information.
In the typical Problem-Solution organisation, the
Situation stage places the text meaningfully in relation to
the author’s model of the reader’s knowledge base (this
stage showed a strong negative correlation with
highlighting). The Problem stage prepares the ground for
the new piece of information imparted in the next stage.
In terms of cohesive relations, it draws attention to a
discordant factor in the previously reported Situation
(that is, one particular aspect of the reader’s assumed
knowledge base). Thus prepared, the Solution presents
itself as important new information that resolves, or
partly resolves, the discordant aspect of the Situation
represented by the Problem. Finally, the Evaluation
defines the degree to which the Solution resolves the
original Problem.
In this context, the Solution can be viewed as a
climactic point of novelty in the Problem-Solution
schema, thus justifying its status as “highlightable” text.
If it were possible to model the article as a histogram
with sentences represented by columns plotted against a
scale of new information content, we can imagine the
highlighting process as being akin to slicing across the
graph with a threshold value. Figuratively speaking, the
highest peaks in a mountain range are selectively lit at
sunrise.

4.2. Implications for “new” information as a
criterion.
If we accept the idea that novelty of information is the
fundamental criterion for highlighting text, it follows
that:

a)

The efficiency with which we shall be able to select
text for highlighting will depend upon our ability to
recognise signals indicating new information.
b) Any other signals commonly associated with new
topics but not present in the experimental text are
prime candidates for selection criteria.
Conversations with subjects suggested that the criteria
adopted for each function and the typical highlighting
procedure would have been very different in the case of
quasi-revision, where decisions would have been made
on a shorter-range basis. Arguably, this kind of
highlighting produces highlighting that is more
spontaneously applied and spanning fewer words.
We can hypothesise that this is so because a reader
has a more detailed knowledge of what constitutes “new”
information to himself than he has to a third party.
Highlighting can therefore be done in real time (i.e.
while reading as opposed to after having read the text)
and with greater precision (e.g. at the word or clause
level rather than the sentence or paragraph level.
The responsibility of interpreting an article for
someone else eliminates this spontaneity. In the subject
article, users not only perceived that it was “about” a
specific product: they had also been informed that they
were corporate librarians marking up a text for a board
member. This scenario conjures up a range of frames and
scripts. Two functions of the corporate librarian that
subjects might have recalled or inferred are:
a) to keep management informed about the developing
state of business knowledge, and
b) to inform management of new products that may be
of value.
An alternative hypothesis is that the perceived novelty
of information occurs at a number of levels. Within a
sentence, particular words can be perceived as new.
Within a paragraph, some sentences can be interpreted as
new and others as contextual or supporting information.
Meanwhile, within a discourse segment or discourse, still
longer passages may be perceived as containing “new”
information (see discussion of the Solution category
above).

5. Conclusion
5.1. Highlighting as Information Visualization
TextLight [1], the software tool for which this
research was carried out, is designed to detect certain
attributes of a text’s cognitive structure, encode them in
visual, non-lexical form, and superimpose them on the
corresponding text in the same physical location. In this
sense, it can be viewed as a form of information
visualization, exploiting the brain’s capacity for
processing visual data such as colour and shape to which
it is optimally adapted. Like a geographical information
system (GIS) it can reveal attributes of its data set that
would otherwise be obscured, throwing the underlying
structure into high relief.
However it does not pay to make the signals
communicated via this additional channel too complex
[11], and there seem to be no benefits for readers from
using different colours for different categories of “new”
information. For authors and text analysts, however, an
extension of TextLight to identify attributes within text
that are of interest to them would be as valuable to them
as the colouring of objects on different layers is to
architects.
Content-driven visual cues can be presented as a way
of visualizing the logical or conceptual structure of a
text. In this way, the brain’s predisposition to visual
understanding is exploited to enhance the understanding
of text, or to guide the eye quickly to the most important
passages.
This principle is widely demonstrated by the syntaxhighlighting in text-editors for programmers. Here the
need to visualize logical structure is acute, and
programming languages offer a finite and precise set of
words for editors to detect and colour. The most striking
use of this principle is SeeSoft, one of a suite of text
structure visualization tools developed by Stephen Eick
at Lucent (formerly Bell) Laboratories.
Software
engineers typically operate at the scale of thousands of
lines of code. With SeeSoft, each line of code is reduced
to a line of single pixel thickness, coloured according to
a range of user-specified criteria. Thousands of lines of
code can be displayed on the screen at once, enabling a
strategic grasp of the status of different parts of the
program and their importance to the whole.
The same principle could be applied to help writers.
Adding one or more layers of annotation to a text, based
upon attributes such as readability or levels of
completion would be like a knowledge discovery system
for authors. Using it we could expect significant insights
about the subject-matter to flow from being able to
compare the occurrence of different parameters.
Such forms of visualization would help us to navigate
a text “architecturally”. In other words by having a

clearer idea of a fragment’s place in the overall cognitive
structure of the document, we can more easily gauge its
importance. Its degree of isolation from other highlighted
text, or its location within a dense area of other
highlighted sentences would give us an intuitive grasp of
the structure of the entire document.

5.2. Future directions
The study of the selection of words for highlighting is
an area that has previously been neglected  perhaps
because the potential contribution of automatic
highlighting has itself been ignored in the struggle
against information overload. Yet as a class of
information processing agent, highlighters possess
several virtues. Their output is familiar to users.
Highlighting has been shown to be helpful in content
recall. Finally, it addresses the issue of confidence:
unlike conventional summarization tools, highlighting
acts not as a censor but as a guide, leaving non-selected
text (and therefore the context) always in view.

6. References
[1] Ostler, T. “TextLight: Towards an Intelligent Text
Browser”. MSc. Dissertation, University of Westminster,
1998. URL: http://www.cogarch.com.
[2] Hult, R E., Jr., et al. “Different effects of note taking
ability and lecture encoding structure on student
learning.” Paper presented at the Annual Meeting of the
Eastern Educational Research Association, 1984.
[3] Dreyfus, Hubert & Stuart. “Making a Mind versus
Modelling the Brain”, in Graubard, Stephen R., (ed.) The
Artificial Intelligence Debate: False Starts, Real
Foundations. Cambridge: MIT Press, 1988.
[4] Crevier, D. AI: The Tumultuous History of the Search
for Artificial Intelligence. Basic Books, New York,
1993:126.
[5] Foster, J.J. “The use of visual cues in text,” in Kolers,
P.A., Wrolstad, M.E., Bouma, H. (ed.) Processing of
visible language. New York/London: Plenum Press,
1979: 189-204.
[6] Klare, G R, Mabry, J E & Gustafson, L M. “The
relationship of patterning (underlining) to immediate
retention and to acceptability of technical material”.
Journal of Applied Psychology. 39(1), 1955: 40-42.
[7] Dearborn, W.F., Johnston, P.W., & Carmichael, L,
“Oral stress and meaning in printed material”. Science, v.

110, 1949: 404.
[8] Crouse, J.H., & Idstein, P, “Effects of encoding cues
on prose learning.” Journal of Educational Psychology,
63, 1972: 309-313
[9] Fowler, R.L & Barker, A. S. “Effectiveness of
highlighting for retention of text material”. Journal of
Applied Psychology. 39 (3) 1974: 358-364.
[10] Hershberger, W.A. & Terry, D.F. “Typographical
cuing (sic) in conventional and programed (sic) texts”.
Journal of Applied Psychology, 49, 1965: 55-60
[11] Glucose Inc. URL: http//www.glucose.com/
[12] Rickards, J.P., & August, G. .J., “Generative
underlining strategies in prose recall.” Journal of
Educational Psychology, 67, 1975: 860-865.
[13] Anon. “Coping with the Deluge of Data”, in
Financial Times Information Technology Supplement, 5
May 1997.
[14] Tadros, A.”Predictive Categories in Expository
Text”, in Advances in Written Text Analysis, Coulthard,
M. (ed.). Routledge London, 1994.
[18] van Dijk, Teun A. News as Discourse. Hillsdale:
Lawrence Erlbaum Associates, 1988.
[15] Hoey, M. “Signalling in discourse: a Functional
Analysis of a Common Discourse Pattern in Written and
Spoken English.” In Coulthard, M. (ed.) Advances in
Written Text Analysis, London: Routledge 1994: 26-45.
[16] Brown, G. & Yule, G. Discourse Analysis.
Cambridge University Press, Cambridge, 1983.
[17] Halliday, M.A.K. A Course in Spoken English:
Intonation. Oxford: Oxford University Press, 1970

