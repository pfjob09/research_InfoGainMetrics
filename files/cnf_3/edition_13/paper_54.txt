Towards Interactive Finite Element Analysis
of Shell Structures in Virtual Reality
A. Liverani*, F. Kuester**, B. Hamann**
* DIEM - University of Bologna, Italy
a.liverani@mail.ingfo.unibo.it
** Center for Image Processing and Integrated Computing (CIPIC)
Department of Computer Science
University of California - Davis, CA 95616, USA
(kuester,hamann)@cs.ucdavis.edu

Abstract

factors and usability studies, manufacturing, and
simulation-based design. Nevertheless, most of these
applications use immersive or augmented VR technology
primarily to visualize or interact with pre-defined data
neglecting some of its powerful features in the area of
content creation. As companies focus on streamlining
productivity in the pursuit of global competitiveness, the
migration to computer-aided design computer-aided
manufacturing and computer-aided engineering systems
has established a new backbone of modern industrial
product development. While most of these technological
advances are of high benefit to the engineering and design
community they still lack some of the important visual
and haptic features crucial to efficient human computer
interfaces that can be addressed using the available VR
hardware.

A prst step towards a semi-immersive Virtual Reality
(L!R) interface for Finite Element Analysis (FEA) is
presented in this paper. During recent years, user
interfaces of FM solvers have matured from characterbased command-line driven implementations into easy-touse graphical user interfaces (GUS). This new
generation of GUIs provides access to intuitive and
productive tools for the management and analysis of
structural problems. Many pre- and post-processors have
been implemented targeting the simplification of the manmachine interface in order to increase the ease of use and
provide better visual analysis of FEA solver results.
Nevertheless, none of these packages provides a real 3Denabled interface. The main objective of this project is to
join state-of-the-art visualization technology, VT? devices,
and FM solvers into the integrated development
environment VRFM.

1.1 Motivation
In classic FEA environments engineers usually
spend 40% of their working time on 3D shape modeling,
30% on mesh generation (the definition of boundary
conditions and simulation parameters), 20% on result
analysis and review and only 10% on running the FEA
solvers.
The observation that modeling, mesh generation and
adjustment, specification of simulation parameters and
result analysis tasks are responsible for 90% of the
workload indicates that further technological advances
are required. A significant number of the areas prone to
improvement require the visualization of scientific data,
and intuitive 3D-display technology could be successfully
involved in a solution approach.

Keywords
Virtual Reality, Interactive Modeling, Finite
Element Analysis, 3D Modeling, Simulation.

1. Introduction
Primarily driven by product quality, cost, and timeto-market considerations, most automotive and aerospace
companies heavily invested into the development and
implementation of new VR technology during the last
five years. These newly created synthetic environments
have matured into valuable tools in the areas of human

340
O-7695-0210-5/99 $10.00 0 1999 IEEE

Furthermore, VR devices can aid the designer in
content creation and design verification during the preprocessing and the evaluation and interpretation of results
during the post-processing phase. The primary focus of
this paper is on those tasks that can be performed in realtime. This paper is intended as a first step towards the
development of a fully integrated modeling and
simulation environment, combining VR and FEA.
The design goal was to provide a visualization frontend, which easily interfaces with either, the traditional
command line driven FEA applications or newer plug-in
based technology. Furthermore, the visualization
component had to enable smooth transitions between
standard on-screen and VR-enabled modeling tasks.
Therefore, support for stereo output devices, additional
VR specific input hardware such as spatial trackers and
data gloves had to be provided besides the standard
workstation specific display modes.

Emitter for magnetic trackers

Figure 1: Hardware setup.

position and hand movements is tilly incorporated into
the environment. We briefly describe the input devices:
l

1.2 Related work
Recent experiments performed at Iowa University
[l] have used VR approaches in FEA to evaluate
“parameter sensivity” and facilitate design. This means
that VR is not really integrated into the FEA modeling
and analysis procedure, but it is only used as a
visualization tool to seek optimal design parameters.
Our environment, VRFEA, was designed to
overcome the integration gaps between VR and FEA. In
this environment the designer uses immersive VR tools to
manage a FEA model, manipulate nodes or shells, create
or adjust the mesh, specify boundary conditions, and
visualize the results.

l

Stylus. Using a fixed transmitter as reference, this
pencil-like system accurately computes position (x, y
and z coordinates) and orientation (yaw, pitch and roll)
of a tiny receiver contained in the stylus. In addition, it
provides an integrated button that can be used for
picking actions.
Gloves. The pinch system uses cloth gloves with
electrical sensors in each fingertip. Contact between
any two or more digits completes a conductive path,
providing a variety of possible “pinch” gestures that
can be associated with distinct actions. Additionally,
an attached electromagnetic tracker captures the
position of each glove.

2.2 Software

One of the governing development goals was to
provide a platform-independent visualization front-end
for FEA applications, which supports either plug-in
technology or the traditional command line interface. In
addition, a smooth transition between conventional and
VR display modes had to be possible. To facilitate these
requirements OpenInventor was selected as the
implementation language of choice for the visualization
component.

2. Setup
2.1 Hardware
VRFEA was designed for a new generation of stereo
projection systems currently marketed under names like
Immersive Workbench, Responsive
Workbench a n d
ImmersaDesk [21,22]. We used the ImmersiveWorkbench
from Fakespace which allows stereo projection of 3D
computer-generated images onto an approximately
2m*lSm wide projection area. A four-processor SGI
Onyx2 InfiniteReality (225MHz, RlOOOO processor)
system was used as the rendering and computation engine.
The basic hardware setup is illustrated in Figure 1. The
user is wearing shutter glasses with integrated head
tracking for stereoscopic viewing and uses a set of pinch
gloves combined with a stylus device for interaction with
VRFEA. The spatial data-set describing the user’s head

2.2.1 Open Inventor. Open Inventor is an objectoriented developer’s toolkit that simplifies 3D graphics
developing high-performance
programming and
interactive 3D programs. The rich Inventor set of preprogrammed building blocks defines a full-featured,
extensible framework upon which entire applications can
be developed.
It includes a wide variety of geometry, property, and
group objects as well as manipulators for user interaction,

341

and high-level viewers and editor components.
The underlying object hierarchy produces for each
shape model change and motion an on-screen
visualization. Additionally, OpenInventor establishes a
file format standard for 3D data exchange that is the basis
for the Virtual Reality Modeling Language (VRML).

# NUM. MATERIALS
1
# IND. MAT. FILE NAME
0 MAT08,MAT
# NUM. NOD1
4
#IND. x Y z
0 0.00 0.00 0.00
1 1.00 0.00 0.00
2 1.00 1000.00 0.00
3 0.00 1000.00 0.00

2.2.2 Device Drivers under Inventor. A new set of
device plug-ins was developed to provide OpenInventor
with the real-time support for VR input devices, including
the Fakespace pinch glove and the Polhemus Fastrack
system. Furthermore, a new object selection method was
introduced to bypass standard libraries for mouse-based
object selection.
This modification was essential to enable real-time
transition between keyboard-mouse and semi-immersive
modeling metaphors. In fact, a generic event-based
collision detection routine continuously checks for object
collisions. Verified collisions trigger intuitive visual and
audio feedback. These additions to the OpenInventor
toolkit have substantially increased its VR potential.

#BEAM SHELL BRICK
0 1 0
# BEAM ELEMENTS:
# SHELL ELEMENTS:
# ind id_laminato
#
n0 nl n2 n3
0 0
0 1 2 3

3. Finite Element Code
# NUM. CONSTRAINTS
2
0 0 G
6 1 2 3 4 5 6
1 3 G
6 1 2 3 4 5 6

3.1 Solver

The FE solver was implemented as a console-type
application using ANSI C for portability reasons.
Commands are passed to the solver through a command
line interface (see Figure 2) and a generic file description
language.

# NUM. LOADED NODES
1
0 2
0.000 0.000 0.000
0.000 0.000 50.000
# NUM. GIVEN DISPLACEMENTS
0
# GIVEN DISPLACEMENTS.
# id_nodo x y z
#
r x r y I-z
The FE model can be described with either solid 3D
elements as bricks, with shell elements for thin parts or a
combination thereof. A classic frontal method was
implemented to solve linear and non linear equation
systems. This solver demonstrated good performance,
solving small meshes (around 200 nodes) in less than two
seconds and large models (around 3000 nodes) in about
one minute. The command line-based interface style was
chosen to simulate and test the visual front-end for its
suitability with off-the-shelf products.

Figure 2: FE solver command line interface.

The file format supports geometry information in
mesh format, node coordinates, a variety of element
types, boundary conditions and modeling parameters such
as forces or displacements applied to particular nodes.
An input file might look like this:

342

4.3 Interactive Node Displacement Application

To enable complete simulation in a VR environment,
a very interesting FEA example could push VR and
interface technology. In many test environments for
ergonomic and usability studies, the designer needs to
investigate the capabilities of the structure strength under
displacements.
This test could easily be performed by simulating
node displacement and computing the resulting surface
deformation. To underlay the node displacements, a
symmetric constraint set can be chosen (Figure 5).

Figure 4: Decreasing force value.
The magnitude of these force vectors can be easily
adjusted through associated gestures or actions provided
by the stylus and glove interaction devices. If the stylus
proxy is in the upside position, the force increases (Figure
2) otherwise it decreases (Figure 3).
However, this enhancement does not exclude the
presence and use of multi-purpose menus, but it can
dramatically reduce the frequency with which the menus
have to be accessed and thus intuitive modeling
efficiency is increased.
Object selection is based on a collision detection
algorithm that continuously monitors the input device
proxy in relation to the FE model. At any time the FE
solver can be accessed to interactively update the model
parameters. The surface is colored based on strain or
displacement information obtained from the solver. For
our test cases the solver latency was minimized to be
lower than a three-second threshold.

Figure 6: Symmetric constraint set.

As in the previous example, nodes or shell elements
can be selected. However, in this setting forces are
applied implicitly through the displacements applied to
the elements. Figure 6 shows such a displacement test
and the results obtained from the solver (Figure 7).

Figure 7: Applying node displacement.
Figure 5: Color-coded results.

344

ENG-48 (and B335358, B347878), and the North Atlantic
Treaty Organization (NATO) under contract CRG.971628
awarded to the University of California, Davis. We also
acknowledge the support of Silicon Graphics, Inc., and
thank the members of the Visualization Thrust at the
Center for Image Processing and Integrated Computing
(CIPIC) at the University of California, Davis.
8. References
HI

PI
Figure 8: Color-coded results.

5. Conclusions

131

A new interaction method for FEA was introduced
in this paper. While modern pre-processor and postprocessor software for FEM/FEA primarily utilizes 2D
interfaces, this interface prototype represents an essential
step towards proving the benefits of VR to FE
applications, and goes beyond visualization and
navigation of results.
The use of 3D input devices and stereo rendering
systems has the potential to transform how engineers
interact with design environments enhancing model
manipulation, examination and modification efficiency
and product quality.

141

[51
161

[71

[81

6. Future Work
[91

So far, the current research focus has been on the
integration of fully interactive 3D meshing techniques
and the associated interactive meshing interface. With
increasing system performance and the growing
availability of a new generation of force-feedback devices
we plan to develop an improved version of VRFEA in the
near future.

[lOI
1111

[121

7. Acknowledgements
1141

This work was supported by the National Science
Foundation under contract AC1 9624034 (CAREER
Award), the Office of Naval Research under contract
N00014-97-1-0222, the Army Research Office under
contract AR0 3659%MA-RIP, the NASA Ames Research
Center through an NRA award under contract NAG212 16, the Lawrence Livermore National Laboratory
through an ASCI ASAP Level-2 under contract W-7405-

[171
1181

345

Tsung-Pin Yeh, Vance, Judy M.: “Combining
MSClNastran, sensivity methods, and Virtual Reality to
facilitate Interactive Design”, MSC/Nastran Web site:
http://www.macsch.com/techfpaperl/paperl .html
Sastry, L, J. V. Ashby, D. R. S. Boyd, R. F. Fowler, C.
Greenough, J. Jones, E. A. Turner-Smith and N. P.
Weatherill, “Virtual Reality Techniques for Interactive
Grid Repair”, Numerical Grid Generation in
Computational Field Simulations, Ed.
J.F. Thompson, B. Soni, N. Weatherill, “Handbook of
Grid Generation”. CRC Press, 1999 (ISBN 0-8493-26877).
Foley, J. D., Van Dam, A., Feiner, S. K. and Hughes, J. F.,
1992, “Computer Graphics, Principles and Practice”,
Addison-Wesley Publishing second edition.
Newman, W. M. and Sproull, R. F., “Principles of
Interactive Computer Graphics”, McGraw-Hill, 1979.
Kalawsky, R.S., “The Science of Virtual Reality and
Virtual Environments”, Addison-Wesley, 1994, ISBN O201-63171-7.
“HIT Lab Overview and Projects” Human Interface
Technology Laboratory Seattle/WA/USA, Technical
ReportNo. HITL-P-91-1, 1991.
Hollerbach, J.M., Cohen, E.C., Thompson, W.B., and
Jacobsen, S.C., “Rapid Virtual Prototyping of Mechanical
Assemblies”, Proc. 1996 NSF Design and Manufacturing
Grantees Conf., (Albuquerque, NM), Jan. 2-5, 1996, pp.
477-478.
Ballard, D., Brown, C.: “Computer Vision”, Prentice Hall,
1982.
Persiani, F., Liverani A.: “Virtual Reality CAD Interface”,
ADM Proceedings, Florence 17-l 9 Sept. 1997.
Liang, J., Green, M.: “JDCAD: A Highly Interactive 3D
Modeling System”, Computers and Graphics, Vol. 18, No.
4, pp. 499 - 506,1994.
Butter-worth, J., Davidson, A., Hench, S., Olano, T. M.:
“3DM: A Three Dimensional Modeler Using a HeadMounted Display”, Proc. 1992 Symposium on Interactive
3D Graphics, Cambridge, Massachusetts, pp. 135 - 138,
March 29 - April 1 1992.
Wang, Sidney W., Kaufman, Arie E., “Volume Sculpting”
1995, Symposium on Interactive 3D Graphics, Monterey
CA USA, ACM Press, 1995.
Williams, L. “3d paint” in: Computer Graphics,
24(2):225-233, March 1990.
Murakami, T.: “Direct and intuitive input device for 3D
shape design”, DE-Vol. 83, 1995 Design Engineering
Technical Conferences, Vol. 2, pp. 695-701, ASME,
1995.

[ 193 Sachs, E., Roberts, A., Stoops, D. : “3Draw: A Tool for
Designing 3D Shapes”, IEEE Computer Graphics and
Applications, Vol. 11, pp. 18-24, 199 1.
[20] Sutherland, I. E.: “SKETCHPAD: a man-machine
graphical communication system”, MIT Lincoln
Laboratory, Lexington, MA. Technical Report, TR-296,
1965.

[21] Krueger, W., Froehlich, B. “Visualization Blackboard:
The Responsive Workbench”, IEEE Computer Graphics
and Applications, 14(3):12-15, May 1994.
[22] Rosenblum, L., Durbm J., Doyle, Tate, D., “Projects in
VR: Situational Awareness Using the Responsive
Workbench. IEEE Computer Graphics and Applications
17(4):12-13, July/August 1997.

346

