Enhancing Graphical Information System Models with VRML
Jouni Huotari
School of Information Technology
Jyväskylä Polytechnic, Finland
jouni.huotari@jypoly.fi
Abstract
Current CASE tools lack efficient techniques to visualise
information system (IS) design repository. One important
aspect in visualising graphical IS models is to preserve
structure, which can have semantic value. Another key
issue is to provide both focus and context in order to
understand how detailed information relates to other
design elements. The third aspect to consider is to trace
between diagrams and other design documents. Our
VRML implementation integrates different types of
diagrams in one whole. We applied elision technique for
decomposition of data flow diagrams (DFD) and added
visible lines to link parts of DFD to entity-relation
diagrams. In our laboratory experiment, we collected
users' subjective opinions and performance in information
search tasks. Based on the promising results, we give
suggestions for further exploration.

1. Introduction
Information system (IS) specifications consist of a
collection of design documents. These documents contain
a various number of diagrams and other depictions to
visualise the target system. When the size and number of
design documents and diagrams increase, understanding
relationships between diagrams becomes difficult. It is
especially demanding to visualise how different types of
diagrams, e.g. semi-structured entity-relationship (ER)
diagram and multileveled (decomposed) data flow
diagrams, relate to each other. During IS development, it
is very important to find inconsistencies and other errors
as early as possible. Moreover, new designers, reviewers,
and testers need to understand how design information
relates in a larger context. This problem known as focus
and context relates to showing both small-scale and largescale structure in order to understand large structures.

Marketta Niemelä
Department of Computer Science and Information Systems

University of Jyväskylä, Finland
niemark@cc.jyu.fi
specifications [1]. Despite the suggested importance of
visualisation for IS design tasks, currently available CASE
tools do not provide efficient techniques that visualise the
design documents and graphical IS models in them.
Typical CASE tools include textual browsers and twodimensional diagrams that are located in multiple
windows. Even though several viewpoints and
decomposing diagrams to many levels of detail help
dealing with complexity, it is difficult to achieve overall
understanding from separate diagrams.
Information visualisation (IV) techniques offer many
promising features that could be utilised in visualising and
integrating IS models. The problem is that the current
solutions typically visualise only one type of structure,
e.g. network or its special case hierarchy by using
techniques such as hyperbolic tree [2]. It could be
confusing if a network structure is represented with a tree
or a hierarchy is represented with a network. Therefore,
algorithms that regenerate the structure are used. For
example, Ware et al. [3] present a layout algorithm for
visualising large software structures in 3D. A challenge in
IS modelling is to create one visualisation for all graphical
IS models that help designers to integrate and interpret
information effectively.
Now, when computers have an increased capability
to show graphics efficiently, we are able to develop
powerful representations. This paper investigates technical
aspects in representing graphical IS models both in two
and three dimensions. Human aspects are considered in
the actual implementation but these are discussed
elsewhere, e.g. [4]. We describe a VRML (Virtual Reality
Modelling Language) implementation and summarise the
experiences of using this implementation in typical IS
information search tasks.

CASE tools can help professional IS developers in
producing,
transforming,
maintaining,
approving,
inspecting, managing, or translating information systems

Proceedings of the Sixth International Conference on Information Visualisation (IV’02)
1093-9547/02 $17.00 © 2002 IEEE

2. Problems in CASE and potential
visualisation solutions
Kelly and Smolander [5] summarise nicely
representational, conceptual, methodological, and
implementation problems in customisable CASE
environments called metaCASE. One of the
representational problems is to decide whether to use
(hyper-) text, matrices, or graphics. Another problem is to
decide what representational properties a graphical
symbol has. For example, it is important to visualise
duplicates, decomposition, or relationships attached to that
symbol. In multi-user environments, one would like to
know whether an object is locked and who has locked it,
or who is the creator, owner, or modifier of an object and
for what possible reason. Lastly, the object's position or
direction of flow of a relationship can have semantic
value. For example, entity-relationship diagrams (ERD)
are semi-structured representations of data where the
position of an entity has a meaning. For all these reasons,
the object's characteristics must be displayed in a
consistent and semantic-preserving way.
Typical data representational elements in 2D are the
use of colour, size, position, and shape (semantic
symbols). For example, different kind of object, e.g.
entities and properties, can have distinctive colours,
patterns, or line weights. Surprisingly, current CASE tools
do not encourage using this opportunity.
Conceptual problems are such as storing and
processing recursive structures. As one example, the
decompose operation shows those component objects and
their relationships, from which an object is made up.
Taking SA [6] as an example, data flow diagrams are
formed from multi-layered, more and more detailed
information consisting processes. The reverse operation
for decompose is condense, which shows the parent object
of the selected object(s). Decomposition in place is a
demanding operation in a graphical representation,
because there must be space for detailed objects.
Distortion [7], elision [8], and intelligent zoom [9]
are but a few techniques that could solve conceptual
problems. Kaipala and Huotari [10] show several ways
how to apply distortion-based techniques in CASE.
Elision technique enhanced with an intelligent zoom
system, which shows parts of the structure when they are
needed and simultaneously adjusts the entire graph to
make more space for the expanded object, is also a
promising solution.
Methodological problems are difficult to solve. For
example, how to check whether a UML class diagram

corresponds to ERD based on SA. In a model level, we
must check consistency [11]. Parts of DFD, data stores,
are related to one or more entities in ERD. These
relationships should be checked so that there is a
meaningful counterpart in another diagram. Although
some CASE tools check this horizontal consistency they
are not bulletproof. For example, relationship from a data
store can be attached to a wrong entity. In addition,
vertical consistency, i.e. semantically equivalent
descriptions on different levels of abstraction, should be
checked. For example, ER-model should have an
equivalent data base schema. Therefore, human reviewers
are needed. We claim that efficient visualisations would
help humans in finding errors and inconsistencies.
From the focus and context techniques [2],
highlighting could be applied when checking horizontal
consistency between IS models. Highlighting visualises
individual micro-level items, which differ from the macro
level. Another solution is to add visible lines between
corresponding objects in different diagrams. These lines
can be hidden until they are needed.
Implementation problems relate to creating repository
support. For example, versioning of data items,
dependence on versions, and relationships between
versions must be explicitly stored. After that, a designer
could see what parts are used in different configurations
and in what parts a change in a design or in
implementation affects.
Adding a dimension has a potential to show large
amounts of data in a limited screen area. The earlier
experiments [12] indicate that displaying data in three
dimensions instead of two can make it easier for users to
understand the data. In addition, Irani and Ware [13, 14]
show that 3D shaped and coloured objects are recalled
better than flat, grey-shaded objects. Especially when
there are many crossing lines, three-dimensional
representation
will
help
distinguishing
visible
relationships between items either by rotating a model or
adding stereo effect [15]. Gil and Gent [16] present a
series of 3D graphical notations demonstrating effective
use of the third dimension. We expect that third dimension
could be used in various ways, e.g. as a time scale, and
helping to see historical and dependency information, and
is thus a potential solution for implementation problems.

3. VRML implementation
Our solution differs from the current IV solutions
especially in one respect: it integrates different types of
diagrams in one whole preserving the original layout of

Proceedings of the Sixth International Conference on Information Visualisation (IV’02)
1093-9547/02 $17.00 © 2002 IEEE

objects. Our solution is designed around two visualisation
techniques: elision and visible lines.

3.1 Selection of the implementation language
As the time of the implementation, there were not
many alternatives to be considered as implementation
language and tool. The main requirements for choosing a
language were:

symbol, by choosing a predefined viewpoint that is inside
a LOD, or "flying" inside a LOD's effective area.
Our third solution is to apply VRML's PROTO,
which is efficient way to reduce the length of the code. In
the same time, we can easily redefine properties of an
object, e.g. change colour or shape. Additional benefit is
that the change of a property affects to all objects.
One of the difficulties in a VRML implementation is
keeping text readable. The basic elements of text are size
and font. VRML contains an additional element:
Billboard. With Billboard we keep text readable so that
text is are always facing the reader.

•

it had to support 3D modelling

•

it had to enable using a focus and context technique

•

it had to support both "hand-crafted" semantic
preserving and automatic generation of code [17]

•

it should be commonly used so that implementation
can be reused

3.4 Positioning of objects and viewpoints

•

it should enable development and testing in both PC
and Unix platforms

•

it should enable testing a stereo effect

We could have generated the VRML code including
the positions of the objects automatically from a design
repository, but we wanted to have exactly the same
positions for the objects as in the original models.
Therefore, we positioned the objects manually in our
experiment. In addition, we wanted to first experiment
what are the best visualisation solutions. After that we
would have sufficient information for deciding the logic
behind a VRML code.

Languages that support three-dimensional modelling
include Open Inventor, VRML, Java3D, and x3D,
amongst
others.
The
Web3D
repository
(www.web3d.org/vrml/) lists some of the available tools
in more detail. All of these have different versions and
different characteristics. For example, level of detail
(LOD) can be implemented in various ways. After testing
approximately 10 products, we chose Open Inventor and
it's successor VRML (version 97) as implementation
language because only them fulfilled all the requirements.

3.2 Selection of implemented diagrams
We used SA [6] to model our experimental system. It
was modelled from two perspectives. The first perspective
used an ERD representing a static data structure view of
the system. The second view, DFD, represented a
functional view (i.e., the processes) of the system. DFD
allow hierarchical decomposition and the system was
represented accordingly on three level of detail. First
level, context diagram, shows the system and its external
users. This is decomposed to 0-level processes, which in
turn are illustrated in more detail.

# Example of a property
myProperty {
myPlace 14 0 -7
myTextPlace 0 0 0
myText [ "CourseCode" ]
myPoints [ 10 2 -5, 12.5 0.5 -7 ]
}

In the previous example, myPoints contains
information about the beginning and ending points of a
line between an entity and a property. We could have
placed objects around another object by using a spring
algorithm [18] or similar, but that would have caused a
mapping problem: what was the object's position in the
original visualisation. Thus the positioning information
must be obtained from the CASE repository. In our
exploration, this information is quite easy to export to an
intermediate file, which is then converted to VRML file
(Figure 1).

3.3 The logic behind a VRML description
Our first solution is to add visible lines between
different types of diagrams to enable horizontal
consistency checking. Second, hierarchically organized
diagrams, which are partitioned into several levels of
detail, are visualized with an elision method where parts
of the hierarchical structure are hidden by collapsing them
into icons. This can be done in three ways: by clicking a

Proceedings of the Sixth International Conference on Information Visualisation (IV’02)
1093-9547/02 $17.00 © 2002 IEEE

Repository
Repository

Intermediate
Intermediate
file
file

VRML file(s)
file(s)
VRML

Figure 1. Generating VRML from repository.

3.6 Traceability
In our implementation, there are two basic solutions
to provide traceability: visible lines and hyperlinks, which
are connected to other diagrams. For hyperlinks, we can
either add a VRML anchor to an object or we can use
VRML Inline, which opens another file. By clicking an
anchored object, view is changed (by using animation) to
connected object.

Figure 2. (Inversed). ER diagram on the left and
decomposed DFD on the right. The lines between
diagrams connect corresponding objects.
The first (beginning) viewpoint is positioned so that
all diagrams are shown. Other viewpoints are generated
for all diagrams so that entire diagram is visible. The
name of the viewpoint is the same as the name of the
diagram, process etc. If a diagram contains layers, there is
an additional viewpoint for all these layers. Viewpoints
form a tree-like structure and are available in a VRML
browser's drop-down list.
# Example of a starting viewpoint:
DEF fromFront Viewpoint {
orientation 0 1 0 0.785
position 20 0 43
description "Beginning"
}

3.5 Use of dimensions
The third dimension was used in positioning single
objects and also the ERD and the DFD, which were in
(approximately) 120 degrees angle to each other (as an
open book: ERD on the other and DFD on the other page).
The links between the ERD and the DFDs were shown as
wires from a book’s one page to another, thus seen from
above the structure resembles a triangle (Figure 3). In this
way, the crossing lines are easier to distinguish and see
where they are connected either by rotating the view or by
using stereo equipment.
ERD

DFD
Screen

The user
Figure 3. The diagrams in 3D version (seen
from above). As in Fig. 2, the lines between
diagrams connect corresponding objects.

#Example, which connects DFD's Course data store
#to ERD's Course entity
Anchor { url "#course" }

The use of VRML's Inline has one particular
problem: it is difficult to include exact ending point
coordinates for connecting lines between different
diagrams. Nevertheless, it would be efficient way to
divide a huge VRML code in manageable pieces.
#Example, which opens detailed information
Inline { url "0-level.wrl" }

3.7 Elision and information hiding; using level of
detail and scripting
We used VRML's level of detail (LOD) and scripting
for elision and information hiding in general. If an item is
clicked, item's detailed information is shown. Because
clicking an object can have several meanings, we should
enable setting its desired function. For example, user may
want to give commands such as "show/hide details",
"show/hide connections", or "trace connections". For
automation, several programming and scripting languages
are available. In the following, we give two examples how
we applied LOD and JavaScript to elision and information
hiding.
#Level of detail is shown when a "pointer" is
#inside the objects area
LOD {
range [55]
level [ # show all nodes
]
}

Information hiding can be implemented also by using
JavaScript and VRML's ROUTE. TouchSensor is inside
object's code followed by a list of objects that will be
hidden or shown.
DEF click TouchSensor{}
DEF SwitchScript Script{
eventIn SFBool pChange
eventOut SFInt32 myChoice
field
SFInt32 iNrChoices 2
field
SFInt32 count 0
url "javascript:
function pChange(v){
if(v==TRUE) myChoice = ++count%iNrChoices;
} " }
ROUTE click.isActive TO SwitchScript.pChange
ROUTE SwitchScript.myChoice TO change.whichChoice

Proceedings of the Sixth International Conference on Information Visualisation (IV’02)
1093-9547/02 $17.00 © 2002 IEEE

4. Experiment

The first condition was a control experiment,
performed with conventional paper graphs. The other four
conditions were implemented with VRML.

4.1 Case

2D no context (2Dnc) was implemented to rule out
the effects of the screen (size and fidelity), and also the
novelty of the situation. The experiment was performed in
CAVE, but the diagrams, although presented on the large
screen, remain similar to those in the control experiment.

We decided to implement a university student
register system as an example. One of the reasons was that
every participant had some prior understanding of the
domain. In the beginning, we asked the participants’ level
of knowledge of the register system structure and
function. All students reported having little or no previous
experience in planning a student register system.
Altogether, the studied system model included 102
visual symbols and their inter-relationships indicated by
arrows. The studied system model was not large but
complex enough to simulate some real world challenges
when analysing and reading graphical IS models.

4.2 Apparatus
The study environment for investigating conditions
implemented with VRML (Virtual Reality Modelling
Language) was a one-wall CAVE (Cave Automatic
Virtual Environment). The implementation enables to
show and rotate three-dimensional objects on a large twodimensional display. The computer generated VRML
representations were projected by a video-projector on a
2.4 m x 2.4 m (8 feet x 8 feet) screen. The screen can be
controlled with a control stick, computer mouse, or
through keyboard.
A subject sat on a chair in front of the screen
approximately 2 m in front of the screen (see Figure 3). In
the stereo 3D experiment subjects wore the stereo glasses.
The experimenter operating the projecting computer sat
behind a subject in the same room, and controlled the
view on the screen based on the subject’s oral orders. In
addition, the participant could command the experimenter
where to move in system description (left, right, up, down,
zoom in, zoom out, or directly to the specific diagram).
Participants direct interaction was prevented to minimize
the effects of the skill level, controller hardware, and the
user interface on the reaction times.

4.3 Research design
We conducted a controlled laboratory experiment.
105 subjects, 60 male and 45 female, participated in the
experiment. Their average age was 25.1 years. They were
randomly assigned to the five conditions, 21 participants
per condition. In all conditions, the participants answered
the one-by-one given questions by extracting the answers
from the diagrams.

In 2D context (2Dc), only the ERD and a special
DFD, context diagram, were shown on the first screen.
The more detailed (child) processes were implemented
within the 0-level DFD. Choosing a view or getting near
enough showed child processes, after which the parent
“divides” as children (elision).
3D context (3Dc) condition was similar to 2Dc
experiment, but with a difference that 3D features were
used. 3D context with stereo view (3Ds) was a duplicate of
the 3Dc experiment; only that the screen was in stereo
mode and the participants wore stereo glasses.

5. Results
We measured subject's reaction times (RT) and error
rates. In addition, we collected demographic data and
asked personal opinions.
As the time of writing, statistical analysis is still in
progress. In our preliminary analysis, a one-way ANOVA
indicated differences between the conditions [F(4,100) =
3.75, p = .007]. The error rate of the no-context conditions
was higher than of the context conditions [t(60.7) = 3.05,
p = .003]. No difference was found when the 2D
conditions were compared to the 3D conditions [t(103) =
1.49, p = .140]. RT and error rate did not correlate [r =
-.012., p = .900].
We also calculated the number of perfect answers.
An answer was defined as perfect if the subject did not
make any mistakes when answering to the question. The
best condition in this respect was 3Ds (2.1 perfect answers
on average), where as the 3Dc was the worst (1.0).
The control condition was evaluated significantly
lower than the other conditions [t(14.53) = 5.80, p < .001].
From the subjective opinions, the use of elision technique
was praised. "It is nice that one is able to go deeper and
then easily back to the upper level". Some people liked the
visible lines connecting two diagrams; only one subject
complained that lines caused additional clutter.

Proceedings of the Sixth International Conference on Information Visualisation (IV’02)
1093-9547/02 $17.00 © 2002 IEEE

6. Conclusion and future directions
The major result of this study is that the contextproviding methods, elision and visible lines, helped the
users to be more accurate in searching information in an
IS model visualization. This is a little surprising since
earlier the elision method has been reported to have effect
on task completing time but not on accuracy if compared
to use of multiple graphs [19]. One of the explanations for
this accuracy effect is the semantic nature of information
in IS model. After more precise analysis, we are able to
say if the increased accuracy is due to elision, visible
lines, or a combination of both.
We experienced several problems in the CAVE
environment. Text is difficult to keep constantly readable,
especially in the edges. When the text floats in the 3D
space, clear focus to all texts (front and further behind) is
difficult to maintain. This is partly due to the quality of
the equipment, e.g. stereo glasses and the resolution.
These technical difficulties had natural implications to the
readability. In addition, participants seemed to have
varying ability to adapt to the 3D stereo representation.
Some people complained about the fuzziness of the
representation. We identify two main reasons for that.
First, when changing view from upper level to the lower
one in the stereo version, some people saw two different
pictures, one for each eye. It was impossible to have full
control disabling that effect. The second reason for
fuzziness is individual differences to see things in stereo
[4]. Nevertheless, there were over two times more perfect
answers in stereo condition than in plain 3D. This
suggests that stereo effect helps seeing connections
between elements and thus improves traceability.
We expect that in the future, when the quality of
CAVE improve and computers with stereo capability are
more common, our solution will prove to be more
effective. We also expect to see more computers with real
3D screen, where no glasses are needed. This demands
that real 3D interface is developed within an operating
system. After that we will be seeing emerging number of
applications that utilise this new facility.

References
[1] K. Lyytinen, K. Smolander, and V.-P. Tahvanainen,
“Modelling CASE Environments in Systems Development,”
in Proceedings of the first Nordic Conference on Advanced
Systems. Stockholm: SISU, 1989.
[2] S. K. Card, J. D. Mackinlay, and B. Shneiderman, Readings
in information visualization: using vision to think. San
Francisco: Morgan Kaufmann Publishers, Inc., 1999.

[3] C. Ware, Franck, G., Parkhi, M. Dudley, T., “Layout for
visualizing large software structures in 3D,” presented at
Visual’97. Second International Conference on Visual
Information Systems, San Diego, 1997.
[4] C. Ware, Information Visualization: Perception for Design.
San Francisco: Morgan Kaufmann Publishers, 2000.
[5] S. Kelly and K. Smolander, “Evolution and Issues in
MetaCASE,” Information and Software Technology, vol.
38, pp. 261-266, 1996.
[6] E. Yourdon, Modern Structured Analysis. Englewood
Cliffs, NJ, USA: Prentice-Hall, 1989.
[7] G. W. Furnas, “Generalized Fisheye Views,” presented at
Proceedings of ACM CHI'86 Conference on Human Factors
in Computing Systems, 1986.
[8] G. Parker, G. Franck, and C. Ware, “Visualization of Large
Nested Graphs in 3D: Navigation and Interaction,” Journal
of Visual Languages and Computing, pp. 299-317, 1998.
[9] L. Bartram, Ovans, R., Dill, J., Dyck, M., Ho, A., and
Havens, W.S., “Contextual Assistance in User Interfaces to
Complex, Time Critical Systems: The Intelligent Zoom,”
presented at Graphics Interfaces ’94, 1994.
[10] J. Kaipala and J. Huotari, “Towards Advanced Visualisation
Techniques in CASE: Initial Findings and Suggestions,”
presented at Information Systems Development - ISD'98,
Bled, Slovenia, 1999.
[11] P. Marttiin, K. Lyytinen, M. Rossi, V.-P. Tahvanainen, and
J.-P. Tolvanen, “Modeling requirements for future CASE:
issues and implementation considerations,” in Proceedings
of The 13th International Conference on Information
Systems, Dec. 13-16, 1992, Dallas, Texas, 1992, pp. 9-20.
[12] G. S. Hubona, G. W. Shirah, and D. G. Fout, “3D Object
Recognition with Motion,” presented at CHI'97, 1997.
[13] P. Irani and C. Ware, “Diagrams based on structural object
perception,” presented at Conference on Advanced Visual
Interfaces (AVI'2000), Palermo, Italy, 2000.
[14] P. Irani and C. Ware, “Should the Elements of Diagrams Be
Rendered in 3D?,” presented at IEEE Information
Visualization, Salt Lake City, Utah, 2000.
[15] C. Ware and G. Franck, “Evaluating stereo and motion cues
for visualizing infomation nets in three dimensions,” ACM
Transactions on Graphics, vol. 15, pp. 121-140, 1996.
[16] J. Gil and S. Kent, “Three Dimensional Software
Modelling,” presented at International Conference on
Software Engineering (ICSE'98), Kyoto Japan, 1998.
[17] K. Andrews, “Visualizing Cyberspace: Information
Visualization in the Harmony Internet Browser,” presented
at InfoVis'95, New York, 1995.
[18] A. F. Kumar, R.H., “A Spring Modeling Algorithm to
Position Nodes of an undirected Graph in Three
Dimensions,” Department of Computer Science, University
of Texas – Pan American, Technical Report 1996.

Proceedings of the Sixth International Conference on Information Visualisation (IV’02)
1093-9547/02 $17.00 © 2002 IEEE

[19] D. Schaffer, Z. Zuo, S. Greenberg, L. Bartram, J. Dill, S.
Dubs, and M. Roseman, “Navigating hierarchically
clustered networks through fisheye and full-zoom methods,”
ACM Transactions on Computer-Human Interaction, vol. 3,
pp. 162-188, 1996.

Proceedings of the Sixth International Conference on Information Visualisation (IV’02)
1093-9547/02 $17.00 © 2002 IEEE

