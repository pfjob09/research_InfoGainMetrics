Physics-based animation of a trotting horse in a Virtual Environment
S.A. Marsland

R.J. Lapeer

School Of Computing Sciences, University of East Anglia, Norwich, UK
E-mail: scott.marsland@uea.ac.uk,rjal@cmp.uea.ac.uk
Abstract

The technique of key-frame based animation is inexpensive
but takes time and does not produce very realistic movement. Motion captured sequences produce more realistic
results though require expensive equipment - unless done
using video, though this restricts capturing to 2D. Both
techniques have difﬁculties to allow user interaction, which
is usually accomplished (e.g. in games) by swapping prestored sequences in or out. The advantage of (physics) dynamics models is that they allow unlimited user interaction
and, provided a good model is used, guarantee realism. The
latter is of course the problem at the current state of the art,
and therefore a combination of the above techniques is often
the best option.
In this paper, we suggest a dynamic model of a trotting horse. The constraints and corresponding motion patterns are obtained from video sequences (video-based motion capturing). Physical dimensions (size, mass) of the
horse’s main bodyparts are obtained from the literature [8].
The horse is subjected to (earth’s) gravity and a proportional
controller is used to keep the horse in upright position.
The next section describes related work. This is followed
by a description of the method we used to create the animation. We further report current results and conclude the
paper with a discussion and future research directions.

In this paper we describe the implementation of a
physics-based animation of a trotting horse in real-time.
The horse is modelled as a collection of connected bodies
using the Open Dynamics Engine library to simulate gravity. The animation is created by comparing the current state
of the horse with a desired state and applying torques proportionally to the errors present between the two. The desired state is obtained from frames of video footage of a
trotting horse. P-controllers are used to minimise the error between current and desired angle positions as well as
global positioning and orientation of the horse’s trajectory.
Results show realistic movement patterns as compared to
the video footage and realistic ground reaction force patterns of each individual leg.
Keywords— computer animation, physics-based animation,
controllers, forward dynamics.

1 Introduction
Computer animation of characters or animals in a Virtual Environment (VE) can be achieved using the following
three methodologies, either separately or as a combination:

2 Related work

1. Key-frame based animation: geometric models are
placed in key-frame positions. Intermediate positions
are obtained through interpolation (in-betweening).
Forward and/or inverse kinematics (IK) may be used
to arrive at key-frame and/or intermediate positions.

Computer graphics research has produced a number of
models for physically realistic motion of animals. These
studies have explored humans [1, 3], horses [2, 8], kangaroos [6] and other animals [7, 11]. Other ﬁelds, such as Perceptual Control Theory (PCT), have investigated animallike robots (or computerised simulations thereof), for example a quadruped as described by Kennaway [4].

2. Motion capture of characters using specialist equipment or simply from video. Captured movements are
imposed on a character or animal in the VE.

2.1 Forward and Inverse dynamics

3. Physics based modelling: the movement of the character/animal and the forces/torques around the joints and
muscles, which generate these movements, are modelled using the laws of dynamics.

Forward dynamics methods create motions of objects
that abide the laws of physics via the application of forces.
In contrast, inverse dynamics methods take the motions and
1

Proceedings of the Ninth International Conference on Information Visualisation (IV’05)
1550-6037/05 $20.00 © 2005 IEEE

the current state of the object and the desired state, one or
more controllers are used to create forces and torques that
are applied to the object to achieve the desired animation.
Controllers have been implemented for animal animation in
a VE by Raibert and Hodgins [6].

calculate the required forces to recreate that motion. Forward dynamics and inverse dynamics can be combined and
used to produce animations where some motions are deﬁned
while other motions are generated from applied forces [9].

2.2 Space-time constraints approaches

3 Methodology

First proposed by Witkin and Kass [10], space-time constraints take an animation and transform it into a physically
realistic animation. A user speciﬁes a desired animation,
the objective of the animation, for example it should use the
least amount of energy, the object’s physical structure, for
example mass and skeletal structure, and ﬁnally the physical resources available to the character to accomplish the
animation, for example the character´s muscles, the environment, etc. The method takes these inputs and outputs an animation that satisﬁes the constraints while minimising the
objectives.

3.1 Key-Frame Animation versus video-based
motion capture
The ﬁrst part of the method was to create a kinematic animation of a trotting horse. This was created and animated
in 3D Studio Max and is part of the input for the dynamic
model.
A skeleton was created based on the 20-piece segment
model described in [9] and was animated using key-frame
animation. A key-frame encompasses a collection of rotations and translations for particular bones at a particular time in the animation. These key-frames are then used
for creating intermediate frames of animation by interpolating a bone’s position and rotation between the key-frames
(in-betweening). The key-frames for the trotting animation
were created by estimating each bone’s rotation and position from a series of still pictures of a trotting horse.
This model was subsequently improved and validated by
segmenting a full trotting cycle from the video using active
contours to track the four limbs of the horse [5]. Desired positions/rotations were evaluated for each frame rather than
from key-frames, which is otherwise a non-trivial task to
determine these from a video sequence.
As the motion capture is 2D, the legs on the opposite
side of the camera are occasionally (partially) occluded by
those closest to the camera. However, as the articulations of
the legs are rigid objects, it is usually trivial to extrapolate
from a visible vertex to its occluded counterpart. Note that
there was never a case of an articulation being completely
obscured.

2.3 Controllers
A desired motion or pose of an object is deﬁned and a
controller is used to compute forces and torques to achieve
this desired motion or pose. This works by taking the current state of the object and comparing it to the desired state.
A controller can be made up of a combination of three elements: proportional (P), integral (I) and derivative (D).
• The proportional element creates an update that is proportional to the difference between a measured value
and a desired value. The higher its weight, the ‘faster’
the response.
• The integral element creates an update that is proportional to the amount of time the error is present
(steady-state).
• The derivative element outputs a value that is proportional to the rate of change in the error with respect to
time. Its weight determines the amount of dampening
the error ﬂuctuation.

3.2 Dynamic Model

These three elements are thus weighted to adjust their effect on the calculated result. The weight values can either
be found by trial and error or can be generated automatically. Equation 1 illustrates a PID controller with update,
u, error, e, and weights, kp , ki and kd for each of the three
elements:

To create the dynamic environment we used the Open
Dynamics Engine (ODE) API 1 , which is an open source
library for simulating rigid body dynamics.
An ODE ‘island’ (a collection of connected bodies that
cannot be pulled apart) was created from the skeleton created for the key-frame animation. Each bone in the skeleton
was represented in ODE by a single body with its mass,
centre of mass position, and inertia tensor set to values as
reported in [9]. Each body was represented geometrically

de
(1)
dt
Controllers can be used to animate an object with the
use of forward dynamics. A desired pose or ‘key-position’
for an object is deﬁned from motion capture or other kinematic animation techniques. Based on the error between
u = kp e + k i

edt + kd

1 see

2

Proceedings of the Ninth International Conference on Information Visualisation (IV’05)
1550-6037/05 $20.00 © 2005 IEEE

http://ode.org/

as a box with a width, depth and height corresponding to
average values of the corresponding bone.
All bodies were connected via hinge joints whose joint
limits were set by taking the maximum and minimum joint
angles from the key-frame animation, with a tolerance of
10% of the total range.

Figure 1. The path the horse takes with and
without the heading control. (A) is the start
position and (B) is the goal position.

3.3 Animation Controller
To animate the horse, a controller was used to make each
hinge joint reach a desired angle by applying a torque proportional to the error between the current and desired angle:

∆α = kp,h φ
This increment was then used to increase or decrease
the joint torques generated by the animation controller (before they were applied) to the front leg in contact with the
ground at that point. A test was used to determine whether
the horse was moving left or right of the desired direction
and to determine subsequently the increase or decrease of
joint torques. Therefore, a plane was created with a normal vector perpendicular to the vector that points towards
the goal position. A test was then performed to determine
which side of the plane the goal-directed vector is.

T = kp,a (θ − θ0 (t))
where T is the torque, kp,a is the gain (weight), θ is
the current angle of the hinge joint and θ0 (t) is the desired
joint angle. As described earlier, desired joint angles were
taken from each frame (not key-frame) of the video animation. The values of these angles had to be converted into
the hinge joint’s rotational circle of motion, as on creation,
a hinge joint is initialised to zero. Also due to the nature
of active contour-based segmentation of each pair of legs,
small errors caused asymmetric walking cycles. To resolve
this problem, the angles for one leg were copied over to its
opposite counterpart and offset by a position corresponding
to half the animation cycle. Note that two different gains
(kp,a1 and kp,a2 ) were used: one for ground contact and
one when no ground contact was yet established.
The animation controller needed approximately 75 iterations to reach the desired angle before the latter was
changed for the next frame in the animation.

4 Results
Figure 1 shows the path the horse takes with and without
the use of the heading P-controller.
Figure 2 shows a comparison between selected frames
from the video MoCap animation and the physics-based animation.
Figure 3 shows the ground reaction forces taken from the
horse. The ground reaction forces were taken using ODE’s
feedback function to return the force that the contact joints
apply onto the two bodies (one being the ground) that they
are attached too.

3.4 Heading Controller
Unfortunately the animation controller was not sufﬁcient
to create a stable animation, as the horse would not move directly in the direction it was facing but instead wander off to
the left. This meant that the asymmetry problem, previously
discussed, was not completely resolved. As a matter of fact,
this is not unrealistic anyway, as nobody, neither animal nor
human, is symmetrically built. The reason why we manage
to walk in a straight line, is because our brain automatically
compensates for any deviation of the original trajectory.
In other words, we needed another controller to control
the direction. Hence, a heading P-controller was introduced
that would steer the horse towards its goal position.
The heading controller works by taking two vectors: one
vector is ﬁxed to the torso of the horse and points in the
horse’s current direction; the second vector points towards
the goal position. The angle (φ) between the two vectors is
calculated and multiplied by a gain (kp,h ) to produce a ﬁnal
angle increment (∆α).

5 Discussion
Figure 1 shows the route the horse would take with and
without the heading controller. Using a simple P-controller
seems sufﬁcient to resolve this problem.
The physics-based animation and its corresponding
video-based animation are shown in Figure 2. Except for
the stride, the positions of each articulation of each leg are
similar in both models. The difference in stride, and occasional slight differences in magnitude of joint angles, are
caused by errors in tracking the legs from video. Currently,
the animation controller acts on each frame of the videobased MoCap sequence, which may cause the above artefacts which result in a slight jitter in the physics-based animation. Using key-frames instead of all frames may solve
3

Proceedings of the Ninth International Conference on Information Visualisation (IV’05)
1550-6037/05 $20.00 © 2005 IEEE

this problem, however as mentioned before, determining
key-frames from a video sequence is an error-prone process as well. Moreover, a simple P-controller would likely
be insufﬁcient to control the now larger errors between
neighbouring key-frames, with a sufﬁciently fast response
to guarantee real-time performance.
Figure 3 shows the ground reaction forces of the horse
measured across one cycle of the animation sequence.
Firstly, assessing the force patterns across the four legs, we
see a clear alternating pattern of periods of peak force (leg
on the ground and generating force) to no force (leg off the
ground). Secondly, the ground reaction forces generated by
the hind legs are larger than the forces of the front legs,
which is what we would expect. Note that these forces are
measured with the heading controller on so no effect in the
y-direction (drifting) is observed here.

[4] J. R. Kennaway. Control of a multi-legged robot based on
hierarchical pct. Journal on Perceptual Control Theory,
1(1):1–7, 1999.
[5] A. W. M. Kass and D. Terzopoulos. Snake: Active Contour Model. International Journal of Computer Vision, Vol.
1(4):321–331, 1988.
[6] M. Raibert and J. Hodgins. Animation of Dynamic Legged
Locomotion. Proceedings of SIGGRAPH, pages 349–358,
1991.
[7] X. Tu and D. Terzopoulos.
Artiﬁcial ﬁshes:
Physics,locomotion, perception, behaviour.
Proceedings of SIGGRAPH, pages 43–50, 1994.
[8] A. van den Bogert. Computer Simulation of Locomotion in
the Horse. PhD thesis, Utrecht, 1989.
[9] A. J. Van Den Bogert, H. C. Schamhadt, and A. Crowe. Simulation of quadrupedal locomotion using a rigid body model.
J.Biomech., 22(1):3341, 1988.
[10] A. Witkin and M. Kass. Spacetime constraints. Proceedings
of SIGGRAPH, pages 159–168, 1988.
[11] J. Wu and Z. P. c. Realistic Modeling of BirdFlight Animations. Proceedings of SIGGRAPH, pages 888–895, 2003.

6 Conclusion
We have implemented a method for the creation of a
physics-based animation of a trotting horse in real-time. We
used a combination of traditional video-based animation to
deﬁne the constraints on the rotations of the limbs. We introduced the model into a dynamic environment using the
ODE API and applied torques to each limb articulation to
simulate movement. An animation P-controller was used to
attain desired angles and corresponding positions. An additional P-controller was used to steer the horse towards a
goal position. It should be noted that, although our current
interest is in physics-based modelling of horses, this method
can be used for any quadruped, provided a video sequence
of at least one full cycle of the animal’s movement pattern
is available.
Future work will address issues such as the stride difference between the video-based model and the dynamic
model. The need of PID controllers should be investigated
further to address improved accuracy and update speed.
More complex patterns such as normal gait, galloping and
transitions from these to trotting and vice versa will be studied as well. Furthermore, full user control, which is the
ultimate objective and motivation of using a physics-based
model, will be investigated.

References
[1] A. Bruderlin and T. W. Calvert. Goal-Directed, Dynamic
Animation of Human Walking. Computer Graphics 23,
3:233–242, 1989.
[2] H. M. Herr and T. A. McMahon. A Galloping Horse Model.
International Journal of Robotics Research, Vol. 20:26–37,
2001.
[3] D. B. J. Hodgins, W. Wooten and J. OBrien. Animating
Human Athletics. Computer Graphics, Proceedings of SIGGRAPH, pages 71–78, 1995.

4

Proceedings of the Ninth International Conference on Information Visualisation (IV’05)
1550-6037/05 $20.00 © 2005 IEEE

Figure 2. Turn landscape; A comparison of selected (key) frames from different models: (top) skinned
horse model (physics-based); (middle) skeleton of physics-based model; (bottom) skeleton of video
motion-captured model.

5

Proceedings of the Ninth International Conference on Information Visualisation (IV’05)
1550-6037/05 $20.00 © 2005 IEEE

Figure 3. Ground reaction force graphs. From top to bottom: the front left leg, the front right leg, the
back left leg and the back right leg.

6

Proceedings of the Ninth International Conference on Information Visualisation (IV’05)
1550-6037/05 $20.00 © 2005 IEEE

