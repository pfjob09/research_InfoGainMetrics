Enhanced SIC (Synergistic Image Creator) for Artistic Use
Atsushi KASAO, Kazunori MIYATA
Tokyo Polytechnic University, Japan Advanced Institute of Science and Technology

{kasao@acm.org, miyatak@acm.org}
Abstract
We are studying non-photo realistic rendering
(NPR) with the goal of developing an image expression
tool to create artworks by the NPR technique. The
purpose of most NPR researches is to simulate typical
painting styles, so they focus on techniques to create
brushstrokes. These superficially modified images cannot
deviate far from the source photo. If a rendered image is
seen from a distance, it is difficult to tell the difference
from the source photo. This fact makes us realize that
other important elements to add artistic expression to the
photographs exist. We supposed that the distribution of
bright and dark parts over the painting is essential and
proposed the effective way to modify that. Our novel
technique is based on knowledge about human optical
illusions and basic visual design rules. We integrate this
technique into our NPR system, which was used to make
the artworks selected by SIGGRAPH 2002 2D art gallery.
Furthermore, we present new features that allow
artist to select appropriate area for extreme expressions,
to create many types of brushstrokes, and to choose more
than two types of brushstrokes for a single artwork.
Keywords---non-photorealistic rendering, CG

1. Introduction
It has become commonplace for designers and artists
to create their works by using a mouse or a pen-tablet.
To increase productivity and to create high quality
computer graphics (CG), a more user-friendly interface
is necessary. An interface for drawing pictures directly
on a 3D-CG model is even being researched [Kalnins et
al. 2002]. In relation to 2D-static-imaging, interfaces
have been greatly improved. However, creation of 2Dartwork for self-expression without a mouse or a pentablet is just beginning.
Some artists who create CG by filters in Photoshop
or Painter such as Simon Weinstock [Singh 2002-1] and
John Best [Singh 2002-2] have appeared recently. They
choose a variety of filters instead of a mouse or a pentablet to create their art works, which are not
representational, but abstract. Processing filtered source
images into representational art works has been

researched in the field of non-photo realistic rendering
(NPR), and they create high quality images. However,
most of them are simulations of brushstrokes. We expect
that these researchers and artists will meet in the near
feature and create a new field of artistic expression
where artworks are created algorithmically without a
mouse or a pen-tablet. This kind of encounter should
bring science and art much closer together.
In this paper, we discuss the problems that artists
and designers face when they try to use NPR for their
artworks, and we present a novel image expression tool
for 2D-static artworks for self-expression. We focus on
2D-images because that style of art has been attracting
people since the beginning of human history.
To encourage artists to try such a tool, it must be
able to create artworks with striking originality. Thus, no
matter how well conventional NPR techniques produce
fine expressions, if such a technique creates only similar
expressions, then an artist probably would not use such
techniques. Simple variation, such as adjusting the width
of brushstrokes, is insufficient; the technique needs the
ability to allow an artist to create some expressions from
a variety, and control them depending on a motif and the
artist’s thought.
The stochastic method is one means of increasing
the range of expressions. Even if a wide variation were
possible, expressions like noise, which is difficult for
humans to appreciate, is nonsense. For not only wide
variations, but charm to appeal to people, the tool needs
to know how to treat certain phenomena with respect to
human visual perception. This can be understood from
the work DeCarloe and Santella [2002] did human vision.
To do this, it is necessary to focus NPR research on
human vision, because if one thinks of a source photo
image as an image on a retina, the first half of the NPR
process must correspond to human vision and the other
half to image creation.
The goal of our work is to present an image
expression tool that can create new and many types of
expressions with artists’ ideas and originality.
The remainder of this paper is organized as follows.
In Section 2, we review background information and
related work. Section 3 explains the synergistic image
creator (SIC), which we chose as a framework for the

Proceedings of the Ninth International Conference on Information Visualisation (IV’05)
1550-6037/05 $20.00 © 2005 IEEE

image expression tool. We then discuss the functions the
image expression tool needs and how to implement these
functions. Several novel expressions given by the
functions discussed in Section 3 are shown in Section 4.
Results are given in Section 5 and discussed in Section 6.
Conclusions are also given in Section 6.

3. Image Expression Tool an Artist Wants
In this section, we start with an explanation of the
SIC process, then present our new method of merging
segments and compensating for human optical illusion.

3.1. The flow of SIC

2. Background
NPR research has been focused on the creation of
brushstrokes similar to those found in famous paintings
from source photos. Examples include techniques for
pen-and-ink images (e.g., [Winkenbach and Salesin
1994; Salisbury et al. 1996; Salisbury et al. 1997;
Kowalski et al. 1999; Hertmann and Zorin 2000]), oil
paintings (e.g., [Barbara 1996; Litwinowicz 1997;
Hertzmann 1998; Shiraishi and Yamaguchi 2000]), water
paintings (e.g., [Curtis 1997]), automatic technical
illustrations (e.g., [Gooch et al. 1998]), and creation of
oriental water ink paintings [Zhang 1999].
As you can see from above examples, one special
technique has been prepared to create one certain type of
expression. If one wants to create a new expression, new
algorithms need to be created from the beginning. For
the NPR technique to be applied to image expression
tools, it is necessary to clear this problem. We think there
is a need for a technique that has the potential to create
quite a few expressions from only one basic algorithm.
Many NPR techniques like Haeberli [1990] and
Litwinowicz [1997] treat source photo images as a type
of teaching information. In other words, the rendered
image is regarded as a deviation from an original source
photo image; therefore, it must have a strong influence
form the source photo. Artists need tools that treat source
photos as materials for creating their artworks for selfexpression.
Among these functions outlined above, the most
important is the ability to create quite a few expressions
from only one basic algorithm. To implement our new
tool, we select SIC. Basic algorithm of SIC was
explained in Kasao and Nakajima [1998-1].
SIC segments a source photo image into the small
areas, converts the small segments into vector data, then
creates artwork from these vector data. Once vector data
are created, the source photo is no longer needed, so
artwork creation is basically unhampered by the source
photo. However, this tool also has the following two
problems:
1. Its artwork looks like a painting from a short
distance, but looks like a photograph from a distance.
2. It cannot apply different types of brushstrokes
according to the portion of an artwork.
Problem 1 results from the fact that SIC makes
brushstrokes using only photo data around the
brushstroke; therefore the novel SIC we present needs a
function to utilize data from a broad area of the source
photo.

SIC consists of independent processes. We show
the processes in the order that they are processed.
1. Color space transformation
Every process is executed in a L*a*b* color space.
2. Directionality extraction
The next image segmentation process uses not only
the color but also the texture of the source image.
Therefore, this process extracts the directionality of
pixels and saves the results into a file.
3. Image segmentation
This process segments the source photo by using a
color source image, which is the result of process 1
and a texture source image, which is the result of
process 2. To reduce the long process time required
for segmentation, a divided K-means Method [Kasao
and Nakajima 1998-2] was adopted as the
segmentation algorithm. This segmentation process
allocates a number to every segment and calculates
segment centroid, average color, pixel number,
segment direction and strength of direction, then
these values are saved into Map1. Segments created
by this segmentation are finally transformed into
brushstrokes.
4. Vectorization of Map1 data
In this process, vector segment data are calculated
from both data arranged in Map1 and the distribution
of segmented pixels. Concretely speaking, secondmoments are calculated from the distribution of
pixels that form the segment, then two parameters
corresponding to segment direction and segment
thinness are calculated from the above two secondmoment parameters. More detail is show in Kasao
and Nakajima [1998-1]. As a result of this process,
the segment centroid, average color, segment
direction and strength of direction, and the number of
pixels included a segment are saved in Map2.
5. Brushstroke Creation
The processes mentioned above are for analyzing
source images; however, the processes from now on
are for artwork creation. Above them, this process is
the most important, so we will explain the process
precisely. Because Map2 mentioned above contains
information on every segment, brushstrokes can be
created by deciding which pixel belongs to which
segment with reference to Map2. We show how to
decide which brushstroke a pixel n should be
included into.
First of all, list the centroids of segments around the
pixel n in order of proximity. Figure 1 shows that the
pixel n is included in the segment that has the
smallest value among distances calculated by
Equation (1). By modifying Equation (1), the shaped

Proceedings of the Ninth International Conference on Information Visualisation (IV’05)
1550-6037/05 $20.00 © 2005 IEEE

of brushstrokes are changed. Data in Map2 are shown
below.
Coordinate of current pixel n:
Centroid of segment j:
Direction of segment j:
Thinness of segment j:
Number of pixels included in segment j:

(xn, yn)
(Xj, Yj)
Dj
Fj
Nj

brushstroke is quite useful for an artist to create an
original artwork. Modifying the parameters and
functions: Fj, Dj, G(Fj), H(Dj), Nj, L*, a*, b*, Xj , Yj
(meaning to modify the distance function (1)) allows
the artist to create a variety of brushstroke types.
A brushstroke is shaped from simple vector data
shown above. The brushstrokes, therefore, are
distorted by other brushstrokes around them.
Consequently, undulation every brushstroke has
makes us feel natural feeling.
6. Coloring of Brushstrokes
Each brushstroke is colored by an average color of a
segment saved in Map2. If a more complex color is
desired, a gradation or something can be used.

3.2. Picturesque Characteristics

Figure 1: The current processing pixel n
belongs to the brushstroke having the
smallest value in distance function in the
process of Brushstroke Creation.

The distance function for creating a general
brushstroke shape is shown below.

There are not many cases where a painter had taken
a photograph of the place he or she painted. The catalog
named by "Pictures and Paintings by Jyunkichi Mukai
[Hashimoto and Kimura 2002], however, contains
photographs and paintings of the same place.

(Lj, n)2 = ((xn -Xj)2+(yn -Yj)2)(1+G(Fj)H(Dj))2/Nj (1)
where -1 < H(Dj) < 1, 0 < G(Fj) < 1 .
Suppose that every segment is an ellipse. Note
that this assumption does not mean actually created
brushstrokes will be ellipses nor symmetrical shapes.
A function H(Dj) is chosen to meet basic condition
that when the pixel n is near the long axis of the
segment, then H(Dj) will decrease, and when the
pixel n is near the short axis, then H(Dj)will increase.
When pixel n takes the position shown in Figure 1,
and Lj, n < Lj’, n , then pixel n is included in
brushstroke j instead of brushstroke j', which is
actually nearer pixel n. Consequently, the shape of
brushstroke will be stretched along the long axis.
Note that the distance function also depends on Fj. If
Fj is small (it means the segment is round), then the
distance function does not strongly depend on Dj, but
if Fj is large (meaning the segment is needle-like), the
distance function comes to depend on Dj. A function
G(Fj) is used to adjust the effect shown above. If
G(Fj) and H(Dj) are constructed by sigmoid functions
shown below, natural brushstrokes are created [Kasao
& Nakajima 1998-1].
In this paper, if there is no description, artworks
are instead created by
H(Dj) = 2/(1+exp(7(0.3-Dj)))-1
G(Fj) = 1/(1+exp(7(0.5-Fj)))

(2)
(3)

Furthermore, the larger the segment area is, the
smaller the distance function should be. To consider
this fact, Equation (1) is divided by Nj.
If H(Dj) = 0, a brushstroke becomes round;
however, this simple shape is not appropriate for
simulating painting styles. Nevertheless, this

Figure 2: The left image is a painting by Junkichi Mukai,
and the right one is a photograph of the same place also
taken by Junkichi Mukai. The bright parts in the painting
are scattered across the image more than in the photograph

Figure 3: The left image is a painterly expression created
by SIC from the photograph on the right. From a
distance, it is difficult to tell the difference between the
two images.

Figure 2 is an example. The left image is a painting
he painted in the place where the right photograph was
taken. There are some differences in the distribution of
bright and dark parts between the picture and the
painting. In the painting, the bright and dark parts are
evenly placed over the painting. On the other hand, the
painterly rendering created by SIC and its source photo
are shown in Figure 3. Brushstrokes are created by the
method explained in the previous section, and each
brushstroke’s color is dispersed by a random number.
The left image looks a painting from a short distance but
both images look similar from further away. It is clear

Proceedings of the Ninth International Conference on Information Visualisation (IV’05)
1550-6037/05 $20.00 © 2005 IEEE

that there are fundamental difference between the two
paintings in Figure 2 and Figure 3.
These examples show that to add brushstrokes and
to randomly disperse their colors are not effective
methods to free artists from the influence of source photo
images. We think the difference is caused by the human
visual system, so we have proposed the following
hypothesis.
[Hypothesis]: When a person paints a picture, as it
is impossible to see every part at once like a camera does,
objects must be seen as separate parts that are then
integrated on a canvas. At that time, human eyes can
adjust to the dynamic range of luminosity for each part
of the picture. In other words, a painting should be akin
to a collage of photos separately taken by an automatic
exposure-controlled camera. Consequently, both bright
parts and dark parts are placed evenly on the painting.
Of course, some painters like Rembrandt create
paintings that have strongly separated bright parts and
dark parts. This hypothesis is not valid for these painters'
works.

3.3. Image merging in consideration of optical
illusion

theory. However, our goal is not to implement retinex
theory precisely, but to give image picturesque
characteristics based on optical illusion. We present a
simple procedure to compensate brightness using only
brightness difference from surrounding segments, as
outlined below.
1 Merging
2 Extracting the segments on the fringe of the merged
area.
3 Calculation of brightness differences between
segments extracted in different merged areas.
Apply this procedure to the image in Figure 4(a).
Figure 4(a) has two merged areas, shown in Figure 4(d).
The magnified image presented in Figure 4(e) shows a
place around a center gap. The red-marked segment
represents a segment being currently processed, known
from this point on as the “current segment” for simplicity,
and the nearest 8 segments to the current segment being
processed are marked by blue spots. Here, we define a
fringe segment.
[Fringe segment]
If more than 2 segments of nearest 8 segments are
included in a different merged group to the merged group
that the current segment is in, then the current segment is
called a “fringe segment,”

To give original SIC picturesque characteristics, it is
necessary to implement our hypothesis with software.
The first step of this implementation is image-merging to
identify bright or dark areas.
There are many techniques for merging after
segmentation, from a simple one shown by Horowitz and
Pavlidis [1974] to a complex one adopting genetic
algorithms shown by Ho and Lee [2000]. These methods
are, however, not appropriate, We present a new merging
method based on the rule that connecting adjacent
segments that have difference of brightness less than
certain threshold like chain. This merging process will be
continued while raising the threshold gradually. When
every merging area has appropriate number of segments,
this process will be stopped.
This merging method can naturally separate areas
even source image is illusion pattern. Figure 4(a) shows
Craik-Cornsweet effect. Brightness on extremely right
side and one on extremely left side are same but the
brightness on right half side gradually increases toward
center and the one on left half side gradually decreases
toward center. Just center brightness gap makes us show
that completely dark left half side and bright right half
side. If ordinary merging method is used, the result
should be shown in Figure 4(c). This result can not agree
with our vision. Our new method, however, can separate
area to agree with our vision and the result is shown in
Figure 4(d). Only natural separation, however, is not
enough because whole left half side looks dark and
whole right side looks bright. This pattern needs
brightness compensation in accordance with human
vision. The above illusion is also explained by retinex

Proceedings of the Ninth International Conference on Information Visualisation (IV’05)
1550-6037/05 $20.00 © 2005 IEEE

(a)

(b)

(c)

(d)

(e)

(f)

Figure 4: (a) Craik-Cornsweet effect; (b) segmented
image; (c) merged areas only by values of L*; (d) merged
areas by our method; (e) red segments get negative
compensation values of L*, and yellow segments get
positive compensation values of L*; (f) compensated
image.

In Figure 4(e), three blue-dot segments are in
different merged areas to the one the current segment is
in, so this current segment is a fringe segment. Fringe
segments in the right-side merged area are colored
yellow and ones in the left-side merged area are colored
red. If the current segment j is a fringe segment, a
compensation value is calculated by the following
procedures.
[Color difference]
Calculate average: MLj of L* segments in other
merged areas (in Figure 4(e), shown by red segments
with a blue spot).
Next, calculate the color difference: ∆Ck for merged
group k by
∆Ck = Σjεk(MLj - L*j) .

Figure 6 shows the image expression tool created by
enhancing the SIC incorporated in our new merging
process. Revised parts are from process 5 to process 8.
Merging in process 5 was just explained above. This
process creates a merged map containing a merged
group’s information. Brightness Compensation, in
process 6, compensates the brightness of segments and
modifies the merged map and Map2 with calculated
compensation values. These two new maps give the
following process the ability to create a wide variety of
expressions. The original SIC was designed to enable
users to easily add their own new algorithm for original
artwork creation. We add a new algorithm in Brushstroke
Creation (process 7) and add a new coloring process in
process 8. Both processes use a new merged map.

(4)

[Compensation value]
Calculate a compensation value: L*kcor for merged
group k by
L*kcor = L*k + K2∆Ck ,
where, K2 is a constant.

(5)

The compensated image is shown in Figure 4(f),
where K2=0.5.
As before, the purpose of this process is not to
precisely simulate optical illusion but to give picturesque
characteristics based on retinex theory. For the reason,
K2 should be decided according to user’s esthetic sense.
Compensation of optical illusion has been discussed;
however, there are some illusions for which this method
cannot work; for example, McCourt's Grating Induction
Effect [McCourt 1982].

Figure 6: The flow chart of image data processed by 8
image processing parts in the image expression tool:
1) Color Transfer (from RGB to L*a*b*),
2) Directionality Extraction, 3) Image Segmentation,
4) Factorization, 5) Merging, 6) Brightness
Compensation, 7) Brushstroke Creation, 8) Coloring.

We expect this process to create many new types of
aesthetic expressions because it is created taking into
account human vision and a design rule. As it is difficult
to be proved, we show examples created by our image
expression tool in the next section.

4. Artworks by Proposed Image Expression
Tool

(a)
(b)
Figure 5: (a) A dog image with brightness compensation;
(b) A dog image without compensation.

Compare a brightness compensated image and a
non-compensated image. Figure 5(a) shows an image of
a dog created with a compensated merge map. Figure
5(b) is a control image with a non-compensated merge
map. The difference between both images is clear when
examining the kennel and the dog’s chest. In Figure 5(a),
bright parts are scattered across the image, enabling
people to feel picturesque characteristics.

As a painter imitates many types of art, the original
SIC can emulate several types of expression, e.g., pastellike expression, oil painting-like expression, and sketchlike expression. These brushstrokes were created by
simply changing the colors and the shapes of segments.
However, as our goal is making an image expression tool
that can create images as artworks by the NPR technique,
this tool needs to have the ability to create many more
types of brushstrokes from Map2 and a merged map.
The way of controlling highlights in brushstrokes,
changing size of brushstrokes adaptively, transferring
brushstrokes, and drawing different types of brushstrokes
according to the portion of an artwork will be shown in
this chapter. These processes are important for
expanding a scope of expressions. We will explain how
to enhance our image expression tool to create new
expressions and examples of artworks created by this
process will be shown. Brushstroke creating and coloring
processes in Figure 8 will be mainly modified.

Proceedings of the Ninth International Conference on Information Visualisation (IV’05)
1550-6037/05 $20.00 © 2005 IEEE

4.1. Modification of Brushstroke Creation
In the original SIC, the shapes of brushstrokes were
created by Equation (1) and data in Map2. As Map2 has
centroids, but no fringe data for brushstrokes, fringe
areas of brushstrokes cannot be modified. What the
original SIC can do is coloring by average color, or
linear gradation from its average color. This creation
method could not produce subtle artistic expressions. We
present the modified Brushstroke Creation function to
give segments solid impression.
Brushstroke Creation assigns a brushstroke index
number to each pixel and these values are saved in the
image file. The image file is shown by a red frame in
Figure 6. We will call this image file a “Brushstroke
image” in the remainder of this paper. In the next process,
Coloring, the created brushstroke need to be colored by
the average color of the segment, according to index
number in Map2.
To give brushstrokes the impression of being solid at
fringe areas, highlights and shades need to be added to
the brushstrokes. So, the process needs to know where
the fringe of a segment is; however, the position of fringe
cannot be calculated only from the centroid in Map2,
because every shape of brushstroke varies by the
arrangement of surrounding brushstrokes.
As shown in Figure 1, the current processing pixel n
belongs to brushstroke j, which has the shortest value of
distance function in the Brushstroke Creation process. At
the border of a brushstroke, the difference between the
shortest distance function and the second shortest
distance function is almost zero. At pixel positions near
the brushstroke center, the value of the difference
becomes maximum. Our new Brushstroke Creation
process saves these difference values (we call these
values proximity to the border of pixel n in segment j:
Ej,n) in a brushstroke image, so that the next coloring
process will be able to use this information. Figure 7(a)
shows the new brushstroke image with Ej,n. In this image,
brushstroke borders are expressed in black.

4.2. Solid Brushstrokes
We present a method giving segments to solid
impression, using Ej,n. Whether a pixel lies in the lit side
or the shaded side of a brushstroke is judged by the
direction of a line connecting the center of the
brushstroke j to the pixel n.

Assuming that the light comes from the top, if a
brushstroke is an ideal ellipse, the lit side is the upper
side between two contact points of tangential lines at the
extreme right side and at extreme left side, as shown in
the middle figure of Figure 7(b). Actually, the two
contact points are obtained by searching a pixel at the
extreme right and one at the extreme left because a
brushstroke is not an ideal ellipse,
However, if a brushstroke is very thin, the lit side of
the segment is the upper side of the long axis, as shown
in left figure of Figure 7(b). On the other hand, if a
brushstroke is round, the lit side of the segment is the
upper side of a horizontal line through the center.
Figure 8 shows an artwork that was created by
adding very thin segments with the solid impression onto
an image created by daubing a merged area with average
color. As these brushstrokes are so thin, we apply the left
case in Figure 7(b) for the calculations. As the upper side
of long axis is thought of as the lit side, these thin
segments add highlights by the following method.

Figure 8: Brushstrokes with highlights on merged areas

In the case where pixel n is in the upper side of the
long axis of brushstroke j,
if (30 < Ej,n < 70 and 100 < Ej,n< 140 ),
then L*j,n = L*j ,
else L*j,n = L*j + 20(Emax j - Ej,n),
in the case where pixel n is in shaded side of brushstroke j,
L*j,n = L*j - 20(Emax j - Ej,n),
where Emaxj is a maximum value of Ej,n in brushstroke j.
Because highlights in stripes look much brighter
than just gradation, the segment j is colored by L*j in the
range of 30 < Ej,n < 70 and 100 < Ej,n < 140.

(a)

(b)

Figure 7: (a) an image with visualized fringe
information by density; (b) red lines mean bright parts
and black lines mean dark parts when a ray comes from
an upper direction.

4.3. Expression to Change Shapes of
Brushstrokes
The original SIC automatically controls the width
and length of each brushstroke according to the richness
of texture. A lightly textured area like blue sky is drawn

Proceedings of the Ninth International Conference on Information Visualisation (IV’05)
1550-6037/05 $20.00 © 2005 IEEE

by wide brushstrokes, whereas a richly textured area like
hair is drawn by thin brushstrokes. This relation is the
same as in the real world. In this section, we present
strange brushstrokes whose space is controlled by the
thinness of the segment as it is not in the real world. To
implement this, let
H(Dj) = 8.5
instead of Equation (2).

(6)

To create Figure 11, H(Dj) was basically defined by
Equation (6) and G(Fj) by Equation (3); however,
hemispherical brushstrokes were created by setting
H(Dj)=10000 when pixels where in the shaded area in
the left case of Figure 9(b). All segments have brightness
gradations that enable the viewer to see each brushstroke
as a sphere. This artwork resembles the cubism style of
painting by Brach.

Here, H(Dj) is a constant value that causes
brushstrokes to tend to a round shape. If the user wants
to create a natural brushstroke, let -1< H(Dj) <1, but for
self-expression, the user can choose a value more freely.
When H(Dj) is a large number, brushstrokes in lightly
textured areas become extremely large, while
brushstrokes in richly textured areas become relatively
small. Consequently, large strokes appear between small
brushstrokes. This is apparent in the background of the
hair area in Figure 9.

Figure 10: An expression similar to Cubism

4.4. Expression of Accent Lines by Merged
Areas

Figure 9: A work with extremely small
brushstrokes at contour areas.

Figure 9 is created by the following procedure. First,
reasonably thick segments (Fj < 0.95) are merged and
daubed with an average color, as is Figure 8. Second,
only very thin segments (Fj >=0.95) are transformed into
round brushstrokes by the method shown above. Last,
highlights are added to the created round segments. As
segments on hairs and contours of a face are very thin,
they are expressed by small, round brushstrokes with
highlights.
If the user wants to simulate actual highlights, he or
she needs to choose highlights according to the righthand case in Figure 7(b). However, if he or she chooses
such highlights, the image comes to give a very static
impression. To avoid this, in Figure 9 we chose the same
type of highlights as in Figure 8. This technique also
produces a luster, like jewelry, in a brushstroke.
Figure 9 was created with only round brushstrokes,
but Figure 10 was created by spherical brushstrokes (if Fj
>= 0.95), and hemispherical brushstrokes (if Fj < 0.95).

Figure 11 shows the other use of merged areas. This
image is given accents by black lines. Coloring is
processed from left to right on a brushstroke image.
When the process reaches the next merged area, if the
new merged area is brighter than the previous one, it
makes the next series of 8 pixels black. This rule creates
Figure 11. If all contours are colored by black, the image
looks unnatural.

Figure 11: A work with accent lines added to
contours of merged area.

Black accent lines in the proper places give good
tension to the artwork. Conversely, black accent lines in

Proceedings of the Ninth International Conference on Information Visualisation (IV’05)
1550-6037/05 $20.00 © 2005 IEEE

inappropriate places spoil the artwork. If a conventional
merging technique is used, many black lines would
appear on the floor in Figure 11; these lines would annoy
the viewer. Even if colors at both ends of the gradation
scale are very different, if the gradation is smooth, our
merging method can merge such a gradation area into
one broad space because it connects similar color
segments like a chain. Consequently, accent lines can be
drawn in at the appropriate places in Figure 11.

4.5. Distorted Placement of Segments with
Merged Areas

area), are the black sky in the background, which is
expressed by spherical brushstrokes. The second highestpriority merged area, A2, is the biggest flash of fireworks,
which is painted by vivid pastel-like brushstrokes. Other
high-priority merged areas with Ai (2 < i < 9) are a town
around the river and some parts of the fireworks, which
are painted by brushstrokes that look like marks carved
by an engraving knife. Merged areas with Bi (1 < i < 9,
low-contrast areas) are small, strong flashes that are
painted by brushstrokes that look like scratches.
Unmerged areas with “edges” are expressed by sketch
lines. The original SIC cannot use more than one
brushstroke at a time.

Accurate placement of brushstrokes is one factor
that gives an artwork photo-like appearance. As with
color, random distortion does not work well. We propose
a new distortion method. As example is given in Figure
12, where an artwork is created by shrinking every
segment 20% toward the center of the merged area in
which the segment is merged.
The centroid of merged area m is defined by
(Xm, Ym). After replacing (Xj, Yj) in Map2 by
(Xm + 0.8(Xj - Xm), Ym + 0.8(Yj - Ym)), the rest of the
processes (Brushstroke Creation and Coloring) are
performed. Figure 12 has no white gaps between
shrunken segments. This flexibility of creation is another
advantage of using vector data.
It is possible to not only shrink toward the center of
the merged area, but also to expand coordinates of
segments away from the center. This process allows an
artist to choose the direction of movement as he or she
likes.

Figure 13: An example of applying differenttypes strokes to several parts in the same image.

5. Results

Figure 12: A work created by slightly moving
segments toward the center of the merged group.

4.6. Expression by Many Types of Brushstroke
The visual parameters are added in the Merging
Process. The visual parameter is classified according to
priority of a merged area. In Figure 13, according to the
visual parameters different types of brushstrokes can be
expressed in a merged area.
The source image of Figure 13 shows fireworks. The
highest-priority merged areas, A1 (high priority unifying

This paper we presented the basic framework of the
image expression tool. The NPR technique has not yet
been used to create artworks as a form of self-expression.
To enable the NPR technique to create a wide variety of
expressions, we proposed a novel merging process by
using knowledge of human vision. The results of the
merging process gives our expression tool the ability to
compensate for optical illusion, to modify positions of
brushstrokes, and to combine many types of brushstrokes
in one artwork. By introducing a parameter (Ej,n) of
length from a border of a brushstroke, brushstrokes could
express the solidity and glitter.
Thus, we showed that many type of expressions can
be created without a mouse or a pen tablet. Although this
tool uses photography as its source, the created artwork
is not strongly bound by the source photograph, so an
artist has more freedom to express him- or herself. This
new tool still needs further improvements; however, we
have shown the possibility of an image expression tool.

Proceedings of the Ninth International Conference on Information Visualisation (IV’05)
1550-6037/05 $20.00 © 2005 IEEE

Conclusions
The original SIC can produce brushstrokes created
not only by color but the artist can also add texture
information. Moreover, SIC can create brushstrokes that
modify each other synergistically, and by using this
ability it can create an artwork suggestive of Van Gogh.
To combine these original SIC functions and our new
results, our image expression tool is expected to be able
to produce a wider range of expressions.
Our new method inherits vector-based processing
from the original SIC. As image data should be saved as
symbols in human brain, it is worthwhile to create an
image expression tool that vectorizes photograph images.
Vector image processing can create many type of
expression, but its process is very simple. We expect
many people to try to create new processes for selfexpression based on this framework.
As this method uses neither mouse nor pen tablet, it
can direct every process to artwork creation. Referencing
recorded processes, other artists can create new
expressions. If processes of many artists are recorded, it
will play an important role in research to harmonize
science and art in the future.

References
[1]
[2]

CMV2004 url: http://www.cvev.org/cmv2004/index.html
Barbara, J. M. 1996. Painterly rendering for animation.
In Proceedings of ACM SIGGRAPH 1996, 477-484.
[3] Curtis, C. J., Anderson, S. E., Seims, J.E., Fleischer, K.
W., and Salesin, D. H. 1997. Computer-Generated
Watercolor. In Proceedings of ACM SIGGRAPH 1997,
401-406.
[4] Dondis, D. A. 1973. A Primer of Visual Literacy. The
Massachusetts Institute of Technology.
[5] DeCarlo D., and Santella A. 2002. Stylization and
Abstraction of Photographs. In Proceedings of ACM
SIGGRAPH 2002, 779-776.
[6] Gooch, A. A., Gooch, B., Shirley, P., and Cohen, E. 1998.
A non-Photorealistic lighting model for automatic
technical illustration. In Proceedings of ACM
SIGGRAPH 1998, 447-452.
[7] Hashimoto, Y., and Kimura, Y., 2002. Paintings and
Pictures of Jyunkichi Mukai, Setagaya Art Museum.
[8] Haeberli, P. E. 1990. Paint By Numbers: Abstract Image
Representations. In Proceedings of ACM SIGGRAPH
1990, 207-214.
[9] Hertzmann, A. 1998. Painterly redering with curved
brushstrokes of multiple sizes. In Proceedings of ACM
SIGGRAPH 1998, 453-460.
[10] Hertzmann ,A., and Perlin K. 2000. Illustrating smooth
surfaces. In Proceedings of ACM SIGGRAPH 2000,
517-526.
[11] Ho, S. Y., and Lee, K. Z., 2000. A Simple and Fast GASA Hybrid Image Segmentation Algorithm, In
Proceedings of the 2000 Genetic and Evolutionary
Computation Conference ,1 , 718-725.
[12] Horowitz S. L., and Pavlidis, T., 1974. Picture
segmentation by a directed split-and-merge procedure. In
Proceedings of 2nd International Joint Conference. on
Pattern Recognition, 424-433.

[13] Kalnins, R. D., Markosian, L., Meier, B. J., Kowalski, M.
A., Lee, J. C., Davidson P. L. Webb, M., Hughes, J. F.,
and Finkelstein, A., 2002. WYSIWYG NPR: Drawing
Strokes Directly on 3D Models. In Proceedings of ACM
SIGGRAPH 2002, 755-762.
[14] Kasao, A., 2002 Sapporo. Electronic Art and Animation
Catalog of ACM SIGGRAPH 2002, 42-43.
[15] Kasao, A., and Nakajima M., 1998-1. A Resolution
Independent Nonrealistic Imaging System for Artistic
Use, In Proceedings of the International Conference on
IEEE Multimedia Computing and Systems, 358-367.
[16] Kasao, A., and Nakajima M., 1998-2. K-Means
Algorithm Using Texture Directionality for Natural
Image Segmentation. In Proceedings of ࡮8 International
Workshop on Advanced Image Technology in Cheju
Korea, 23-28.
[17] Kowalski, M. A., Markosian, L., Northrup J. D., Bourdev,
L., Barzel, R., Holden, L. S.,and Hughes, J. 1999. ArtBased Rendering of Fur, Grass, and Trees. In
Proceedings of ACM SIGGRAPH 1999, 433-438.
[18] Litwinowicz, P. 1997. Processing Images and Video for
an Impressionist Effect. In Proceedings of ACM
SIGGRAPH 1997, 407-414.
[19] Marr, D., 1982. Vision: A Computational Investigation
into the Human Representation and Processing of Visual
Information, W.H. Freeman and Company.
[20] McCourt, M. E., 1982. A spatial frequency dependent
grating-induction effect. Vision Research 22(1) ,119-134.
[21] Ohlander, R., Prince, K., and Reddy, D. R., 1978. Picture
segmentation using a recursive region splitting method.
Computer Graphics and Image Processing ,8 , 3, 313333.
[22] Richards W., 1998. Natural Computation, The
Massachusetts Institute of Technology.
[23] Salisbury, M. P., Anderson, E., Barzel, R. and Salesin, D.
H. 1996, Scale-Dependent Reproduction of Pen and Ink
Illustrations. In Proceedings of ACM SIGGRAPH 1996,
461-468.
[24] Salisbury, M. P., Wong, M. T., Hughes, J. F., Salesin, D.
H., 1997. Orientable Textures for Image-Based Pen-andInk Illustration. In Proceedings of ACM SIGGRAPH
1997, 401-406.
[25] Shiraishi, M., and Yamaguchi, Y. 2000. An algorithm for
automatic painterly rendering based on local source
image approximation. In Proceedings of the First
International Symposium. on Non-photorealistic
Animation and Rendering, 53-58
[26] Singh, G. 2002-1. Shedding Light on His World. IEEE
Computer Graphics AND APPLICATIONS, 22, 5, 4-5.
[27] Singh, G. 2002-2. Shedding Light on His World. IEEE
Computer Graphics AND APPLICATIONS, 22, 6, 4-5.
[28] Winkenbach, G., Salesin, D. H., Rendering Parametric
Surfaces in Pen and Ink. In Proceedings of ACM
SIGGRAPH 1994, 91-100.
[29] Zhang, Q., Yoetsu, S., Takahashi, J., Muraoka, K., and
Chiba, N., 1999. Simple Cellular-Automaton-Based
Simulation of Ink Behavior and Its Application to
Suibokuga-like 3D Rendering of Trees. The Journal of
Visualization and Computer Animation, 10, 27-37.

Proceedings of the Ninth International Conference on Information Visualisation (IV’05)
1550-6037/05 $20.00 © 2005 IEEE

