Visualising an Image Collection?
Khurshid Ahmad, Bogdan Vrusias and Meng Zhu
Department of Computing, University of Surrey, Guildford, Surrey. GU2 7XH. UK
{ k.ahmad,b.vrusias,meng.zhu }@surrey.ac.uk

Abstract
A system for the visualization of large collections of
images, facilitated by an automatically constructed
visual thesaurus, is reported. A corpus-based method
for extraction of terminology and ontology of a
specialist domain, scene-of-crime, is outlined. The
challenge when capturing information in a crime scene
is how to later visualise the scene, when all exhibits
have been removed or altered. Experiments on experts
dealing with describing a visual domain (the crime
scene) suggest that the inter-indexer variability is
limited.

1. Introduction
A systematically organised image collection is
perhaps the most visual artefact of its kind. Such a
collection can be aggregated along different conceptual
and visual features of the images. Examples of such
collections include art galleries, medical images (of
specific parts of human body suffering from a
particular ailment), and parts’ catalogues. The
conceptual features are generally articulated using
specialist terminology and frequently elaborated in
short text like captions. In each case experts are
involved in defining the key conceptual and visual
features, in selecting important images, and in revising
captions for the collections at regular intervals.
However,
as
imaging
technologies
and
dissemination systems, particularly the Internet,
become cheaper and more accessible, there are fewer
and fewer of the systematically organised image
collections and more and more of the undifferentiated
image repositories. The situation is similar to the
inception of modern information visualisation: it was
becoming easier and easier in the 1970’s and 1980’s to
capture and generate ever larger data sets due to the
developments in sensor technologies and data base
management systems, that led to fewer and fewer
organised data bases of numbers and more and more of
repositories of numbers.

Visualisation is defined as ‘the display of data with
the aim of maximizing comprehension rather than
photographic realism’. What we have for image
repositories is photographic realism, which may or
may not maximize comprehension. Consider a large
collection of images in repository; there may be objects
in an image that may be critical to an inquiry and that a
set of images when put together throws light on given
objects or events. Each image then has to be indexed
on a range of features possessed by object(s) within the
image and then there may be features that are
characteristic of an image as a whole. By extension, a
collection of images may have idiosyncratic features
associated with the collection. The task of indexing an
image appears quite labour intensive. This is certainly
the case in a number of fields particularly in
surveillance mediated by digital photographs, both still
and moving, and in the forensic examination of scenes
of crime. In these fields large volumes of mission- and
security-critical images are collected almost on a daily
basis. Questions of visualization of the contents of an
image database become critical when an unusual event
has happened, for instance a crime, and the entire
collection has to be searched meticulously using some
or all the features.
Content-based image retrieval (CBIR) systems
currently dominate the image-storage/retrieval
research, development and applications.
Using
sophisticated computer-vision algorithms, a CBIR
system automatically extracts the key visual features of
an image including colour, shape and texture: images
are essentially indexed using the measure of the visual
features. Usually the end-user of a CBIR system
presents the system with a query image or sets of
visual features. The system, then, computes the
similarity of appearance between a query and images
in a database [1]. For CBIR systems such content is
captured either through a model-based approach,
generic but limited to a given domain, or through
relevance feedback, domain independent but unable to
capture knowledge in a systematic manner. The low
take-up of CBIR systems has been attributed to the fact
that humans do not intuitively use visual features for

Proceedings of the Ninth International Conference on Information Visualisation (IV’05)
1550-6037/05 $20.00 © 2005 IEEE

storing and retrieving images: forensic scientists have
argued that for ‘the vast majority of users do not want
to retrieve images simply on the basis of similarity of
appearance’ [2]
One can argue that there is a semantic gap in the
performance of current CBIR systems. The gap is
between the visual features of an image and the
meaning that is associated with the objects depicted in
the image. The limitations of the models, and that of
relevance feedback, can be obviated by the use of
keywords, whether manually assigned or derived from
collateral texts, together with the visual features and
relevance feedback [3],[4],[5]. The visualisation of an
image collection through a balanced mixture of visual
and linguistic features is the objective of our research.
The question of what are keywords of a specialist
domain and how to obtain the keywords is one of the
central questions in information sciences. For image
visualisation, what is required is a visual thesaurus that
contains a range of words and phrases used to describe
a set of images. The manual construction of a visual
thesaurus is a time consuming task which takes
between 7 minutes for indexing a stock photograph in a
museum collection and up to 40 minutes for slide
collection for an academic lecture [6]. The automatic
construction of a visual thesaurus is central to the
future development of CBIR systems.

2. Motivation
Modern image storage and retrieval systems use a
number of surrogate description of an image: partial
scene description – visual features mainly; conceptual
descriptions – largely keywords; and, unique/specific
descriptions -facial images or images of well-defined
objects either as photographs or as drawings. There
are systems that rely on meta-level, image external
descriptions of an image for creating and visualising
the contents of an image collection. GoogleTM’s
Picassa is one such system that ‘automatically locates
all the pictures & sorts them into visual albums
organized by date with folder names you will
recognize’. Picassa offers facilities for annotating
images using keywords by hand.
The use of natural language text to index an image
immediately poses questions related to any linguistic
annotation: Misspellings of keywords by indexers and
searchers; sparsity and inconsistency of textual
descriptions; changes in the vocabulary of a domain,
with older terms less frequently for the new images and
newer terms that cannot be used for older images [6].
There are specialised image collections of different
domains, for example, architectural objects, parts
catalogues and weaponry, where each image comprises

well-defined objects that are described in the specialist
language of the domain [7]. Specialists may differ in
detail but usually are careful in their use of
terminology – something where training and
experience helps. Specialist language is lexically rich,
and has restricted syntax and semantics [8] for
avoiding ambiguity of description that characterises
descriptions in language of everyday usage. Specialist
texts are written by using a consensus-based
terminology that is organised according to a conceptual
framework –or ontology- agreed by the members of a
specialist domain.
The framework allows the
expression of relationships between terms – taxonomic,
part-whole, cause-effect – and as such can be used in
query expansion, elaboration and summarisation [9].
Systems have been developed to extract terminology
and automatically construct an ontology of a specialist
domain - genomics for instance - from the literature of
the domain [10].
Methods and techniques for
terminology extraction [11] and ontology construction
[12], potentially applicable generally, have been
reported as well.

3. A method for linguistic annotation of
images
Images are sometimes accompanied with texts:
Picture captions in print media, news captions in
television news are examples of collateral use of text
with images. Keywords extracted by hand from
collateral texts have been used to annotate images
[14],[15]. Systems have been developed that learn to
associate images with keywords– auto-annotation- and
learn to associate keywords with images – autoillustration [16]. In both cases the keywords are either
pre-selected from the collateral texts by a system
developer or the system developer uses a pre-annotated
set of images respectively. The creation of a visual
thesaurus has not been discussed explicitly in [15],[16]
although the notion of such a thesaurus dates back at
least 10 years [17].
We describe a computer-based method for
constructing a visual thesaurus for a specialist domain
of knowledge from a range of collateral texts. The texts
include picture captions (closely-collateral) and
specialist texts that relate to the specialist domain in a
broad sense (broadly-collateral).
The broadly
collateral texts include definitions of objects found in
an image, research papers and monographs produced
by the members of the discipline.

Proceedings of the Ninth International Conference on Information Visualisation (IV’05)
1550-6037/05 $20.00 © 2005 IEEE

3.1. A corpus-based method of creating
thesauri
Modern lexicographical methods of creating
dictionaries and thesauri use a corpus-based approach:
A large collection of texts (and speech samples)
produced by members of a linguistic community is
collated and a random sample of such texts is called a
text corpus. The corpus is then treated as the evidence
for: (a) the existence of linguistic objects – words,
phrases, clauses; and, (b) the usage of the linguistic
objects. This empirical method for building linguistic
resources is expected to supplement and minimize the
introspective bias of a lexicographer. Some of the text
corpora are available on the Web, especially the 100
million words British National Corpus and others have
been used in the construction of dictionaries, phrase
books, and grammar texts. This empirical method has
worked well in the construction of terminology
dictionaries and ontological descriptions of specialist
domains of knowledge ranging from nuclear physics to
sewerage engineering, and from philosophy of science
to forensic science and its sub-disciplines scene-ofcrime examination, bitemarks and pyrolysis [18].

3.2. Extracting Single and Compound Terms
A specialist language text, for example, written by a
physicist or forensic scientist in English, shares its
vocabulary, grammar and semantic conventions with
the other writers and readers of the English language in
general. The peers of the English physicist or forensic
scientists who speak Chinese or Hindi, will not share
the vocabulary (except for terms borrowed from
English), grammar or semantic conventions of their
different languages. But the peers share the concepts
amongst themselves but not with their ‘parent’
linguistic communities.
Consider two commonly used words in the English
language – crime and scene: The chances of the two
words being used together in, say the British National
Corpus, are far less than will be the case in research
papers or newspaper reports written about a crime
scene or crime scenes in general. The chances of
finding the larger compounds crime scene
investigator/photographer or the plurals crime scenes
are far less in the general language of everyday usage
when compared to the specialist language of forensic
science.
Compound terms in English special languages are
made up of nouns and adjectives but very seldom
include closed class words – determiners (e.g. a, and,

the), prepositions (e.g. on, of) or conjunction (e.g. but,
and).
A specialist language of a domain contains its own
terminology signature – a small number of nouns, used
in naming objects, concepts, processes and procedures,
tend to be more frequently used than any other tokens
except for the closed class words. An analysis of texts
in three different subject domains shows the existence
of the signature (Table 1):
Table 1. Terminological Signature: The terms
underlined in the 3rd Column occur as most
frequent single term.
Specialist
Most Frequent
Most Frequent
Domain
Single Terms
Compound Terms
Nuclear
Physics
(0.5 Million)

nuclei, nucleus,
nuclear, neutron,
electrons, scattering,
particle, particles,
nucleon

Theoretical
Linguistics
(0.57 Million)

gender, nouns,
agreement,
noun, form, case,
language, structure,
semantic
evidence, crime,
scene, police,
forensic,
identification, case,
court, analysis,
[..] blood

Forensic
Science
(0.58 Million)

Kinetic energy, nuclear
structure, angular
momentum,
n(ucleon)n(ucleon)transition, nuclear
reactions, target nucleus
[..] nuclear scattering
network morphology,
noun phrase, gender
system, gender agreement,
gender systems, semantic
agreement,
crime scene, forensic
evidence, court case,
blood analysis, earprint,
fingerprint, crime scenes

The lexical signature comprising single terms can
be computed by comparing the frequency of usage of
single tokens in a specialist corpus with that of the
frequency of the same term in a general language
corpus: the frequency ratio is called weirdness – the
larger the weirdness more probability there is that the
token is either a term or a misspelled word!
We have created a corpus of texts using widely used
search engines like GoogleTM with two key words
‘forensic science’ and ‘crime scene’ to collect over
1000 documents comprising 0.58 million tokens.
These documents include a range of text types and are
written mainly in American English (Table 2)
Table 2. The composition of the Surrey Forensic
Science Corpus (SFSC).
Text Type
Instance
Manuals
Research Papers
Brochures and
Marketing texts
News reports

Proceedings of the Ninth International Conference on Information Visualisation (IV’05)
1550-6037/05 $20.00 © 2005 IEEE

FBI, UK, Australian Scene of Crime Practice;
Evidence-based policing
Crime Labs; courses and conferences on
Forensics
Crime and Justice

The relative distribution of the closed class words is
about the same in the two corpora (the BNC and
SFSC) as shown by the computation of relative
frequency and weirdness ratio. But the distribution of
other tokens is quite different: The term police is used
9 times more frequently in the SFSC than in the BNC,
forensic and ballistics used 473 and 1263 time more
frequently: the terms accelarant, earprint, and
bitemark are neologisms for the BNC (Table 4)

3.4. Automatic Construction of a Thesaurus
The signature terms and associated compounds
form the basis of a thesaurus of a domain. The
relationships between the terms can be inferred from
various lexical cues used in the marking of semantic
relationships like taxonomy and meronymy.
This ‘thesuari’ can be updated regularly by simply
adding newer texts and extracting terms from the texts;
contrariwise, if terms do not appear in the newer texts
over a period of time then those terms could be
expunged.

Table 4. Weirdness computation for SFSC and the
BNC.
Token

Token

SFSC

BNC

W

pyrolysis
ballistics
accelerant
earprint

0.0139

0.00001

0.0146

0.00002

0.007
0.007

9
22
40
57

0.0115
0.0137

0
0

634
1263
∞
∞

0.001

473

bitemark

0.0187

0

∞

SFSC BNC

police
evidence
scene
crime

0.25

0.028

0.47

0.021

0.27
0.40

forensic

0.25

W

The extraction of compound terms uses an
algorithm that suggests that if there is a pair of words
not interspersed by closed class words (CCW) then the
pair is a compound term.

3.3. Ontological Relationship between Terms
The ontology –or the conceptual organisation of
terms – can be deployed in expanding a query, say
from a superordinate to an instance, for example
evidence to fibre evidence. This relationship can be
derived on the basis of collocation of the signature
terms (Table 1). The relationships between a whole
and its independent constituent are another equally
important conceptual relationship: the floor of a house
has a relationship to its doorstep, as the floor is
contiguous with the doorstep. There are three methods
that will help in identifying this ontological
relationship: First, some compound terms comprise a
taxonomic relationship wherein the one of the
constituents acts as a genus and the other as a
differentia.
Second, authors usually enumerate or list the
instances/subordinates of a superordinate terms: for
example, the word-list - trace evidence including
blood, fibre and DNA - is a list marked by (a) the word
including (or like) to enumerate the subordinates on the
right, and (b) the left hand term is super-ordinate [21].
The third method relates to the use of spatial
relationships markers as in blood spots were found
near/on/around the body: the spatial markers, like the
enumerators used for taxonomic relationships, are
limited in numbers and can be used to find such
relationship [21].

3.5. Inter-indexer variability
One criticism of keyword based indexing is that
there is some variation between terms used by different
experts. In order to investigate the variability we asked
8 expert scene-of-crime officers to describe 14 scene of
crime images (used in training at the Metroploitan
Police Training College, Hendon, London). The
descriptions provided by then experts differed only at
the level of minor detail. Consider the following
description of a knife found at a scene of crime by our
experts (Table 5)
Table 5. Free natural language description of a an
image containing a single object by eight experts.
E1
E2
E3
E4
E5
E6
E7
E8

Close up of knife. Red sides. Metal ends. On edge of pathway
marked?
Red and silver knife handle. No blade visible. Lying on ground.
Close up view of ex 3 a red handled lock knife found by right hand
corner of low extension to left of gate on garden side of gate.
Close up view of exhibit ABC/3 red and silver knife handle on
alleyway floor adjacent to building and metal gate.
close up view of exhibit 3 red handled flick knife on ground
close up item 3. knife handle.
close up of item 3, red knife
close up view item 3 -red handled knife

All the experts mention the key object in the image – a
knife. Note that all but one of the experts say that the
image is a close-up and that the colour of the knife is
red. Six experts describe the location of the knife and
two describe the type of the knife (flick- and lock
knife). The experts describe colours and shapes that
can be easily analysed by a computer-vision system,
but the name of the object, its sub-type and location
can only be described verbally. All the experts share
the keywords and there are variations at the level of
detail (Table 6):

Proceedings of the Ninth International Conference on Information Visualisation (IV’05)
1550-6037/05 $20.00 © 2005 IEEE

Table 6. Analysed description of an image of a singleobject by eight experts. (f is the frequency)
Visual
Feature
(Colour)

Visual
Feature
(Shape)

Elaboration

Object

knife
knife

Red (&
metal
sides)
Red &
silver

knife

Red
Red

handled
handled

Red

handled

flick
lock

knife
knife

Visual
Feature
(Shape)
handle

handle

Location
& other
objects

f
1
2

a.
Pathway;b
X
a. On
Ground;
b.
Alleyway
floor
Ground
Garden
extension

2

the semantic relationships between terms, starting from
a random selection of collateral texts of the domain;
and (d) learns to link image and text by using neural
networks.
The system has been developed in the JAVA
programming language and is based on a 3-tier
architecture: client, server, and database. The system
can be accessed via a local intranet.

1
1

knife

1

When there is more than one object present in a scene
the description becomes more complex (Table 7):
Table 7. Analysed description of an image of a twoobjects by eight experts. (f is the frequency)
Elaboration

Object
body

face down

body
body
body
body
body
deceased[body]

Location & other objects
Gate; Syringe (on ground)
Syringe (on ground)
Syringe (right of body)
Behind Metal gate; Green area
Syringe
On passage floor
Syringe (behind the gate)

f
1
1
1
1
1
1
1
1

For instance, one of the images in our collection
comprises a body on the ground with a syringe lying
next to it. The principal object is the body and the
syringe is used in the description of the body; the
syringe is an object in its own right and can be treated
as such. Again, there is a unanimity of description –
but the experts appear not to mention colours or
shapes. In our earlier work, we have found that there
are, nevertheless, differences between novices and
experts but these differences tend to decrease as the
training of the trainee proceeds apace [23].

Figure 1. The terms in the linguistic description are
identified automatically and presented for user approval.
The metadata is in the top half of the interface.

SOCIS can index an image from the metadata and
linguistic description provided by an expert. The
images were indexed using the descriptions of the
forensic officers (Figure 1). This is a small corpus of
text comprising 659 words.
SOCIS retrieves images not only on the basis of
terms it has been supplied, but the system also uses
ontological relationships. For example in response to a
query get all images with blood on floor, the system
will retrieve not only the images with the terms in the
query (Figure 2a):

4. Scene-of-Crime Information System
SoCIS is an intelligent CBIR system which is based
on the methods described above for automatically
building a thesaurus of terms. The system was
designed in close collaboration with serving forensic
science experts in five Police Forces in the UK and its
interface has been designed specifically for scene-ofcrime officers. SOCIS automatically: (a) labels (and
indexes) images by keywords extracted from the
descriptions provided by domain experts and with the
metadata supplied together with the image; (b) extracts
visual features of an image; (c) populates a database
comprising domain-specific terminology, together with

Figure 2a. Search result in response to the query: get all
images with blood on floor.

but will also retrieve an image which had the
description blood-like substances on the doorstep
(Figure 2b):

Proceedings of the Ninth International Conference on Information Visualisation (IV’05)
1550-6037/05 $20.00 © 2005 IEEE

the early Years. IEEE Transactions on Pattern Analysis and
Machine Intelligence, Vol. 22, (No. 12), pp. 1349-1380,
2000.

[6] Eakins, J.P. and Graham, M.E., Content-based Image
Retrieval: A Report to JISC Technology Applications
Programme.
(available
at
http://www.unn.ac.uk/iidr/report.html,
last
accessed
20/04/2005), 1999.

[7] Iqbal, Q., and Aggrawal, J.K., Retreival by classification
Figure 2b. Search result in response to the query: get all
images with blood on floor.

This query expansion has been made possible by the
taxonomic relationships, between blood and blood-like
substances, and by the spatial relationship blood on
floor/doorstep.

5. Afterword
We have put forward a case for the automatic
construction of a visual thesaurus from a corpus of
texts. This endeavour, in our opinion, will improve the
indexation and subsequent retrieval of one or more
images in a collection in a meaningful fashion. Our
thesaurus construction system can be incorporated in
widely used systems like Picassa and we are working
towards that end. The inter-indexer variability is there
to be found amongst the descriptions but the
descriptions follows a template –object, elaboration,
location and other objects. These templates can be used
to respond to, and if needed expand, a query.

References
[1] Eakins, J.P., ‘Towards intelligent image retrieval’.
Pattern Recognition. Vol 35, pp 3-14, 2002.

[2] Geradts, Z.J. and Bijhold, J. Content Based Information
Retrieval in Forensic Image Database. Journal of Forensic
Sciences, Vol. 47, pp. 285-292, 2002.

[3] Paek, S., Sable, C. L., Hatzivassiloglou, V., Jaimes, A.,
Schiffman, B.H., Chang, S-F., and McKeown, K. R.,
Integration of visual and text based approaches for the
content labelling and classification of Photographs, ACM
SIGIR'99 Workshop on Multimedia Indexing and Retrieval,
Berkeley, California, USA, 1999.

[4] Squire, McG.D., Muller, W., Muller, H., Pun, T.,
Content-Based Query of Image databases: Inspirations from
Text Retrieval. Pattern Recognition Letters, Vol. 21. No. 1314. Elsevier Science, Netherlands, pp. 1193-1198, 2000.

[5] Smeulders, A.W.M., Worring, M., Santini, S., Gupta,
A., and Jain, R., Content-Based Image Retrieval at the End of

of images containing large manmade objects using perceptual
grouping. Pattern Recognition. Vol. 35, pp 1463-1479,
2002.

[8] Harris, Z.S., Language and Information. In: Nevin, B.
(ed.) Computational Linguistics, Vol. 14, No.4, Columbia
University Press, New York, pp. 87-90, 1988.

[9] McKeown, K, R., Feniner, S.K., Dalal, M., and Chang,
S-F., Generating multimedia briefings: coordinating language
and illustration, Artificial Intelligence, Vol. 103, pp 95-116,
1998.

[10] Blaschke, C., & Valencia, A., Automatic Ontology
Construction from the Literature, Genome Informatics, Vol.
13, pp 201–213, 2002.

[11] Bourigault, D., Jacquemin, C., L'Homme, M-C., (eds.),
Recent Advances in Computational Terminology, John
Benjamins Publishers, Amsterdam, 2001.

[12] Maedche, A., Staab, S., Nedellec, C., and Hovy, E.H.,
(Eds.), IJCAI'2001 Workshop on Ontology Learning,
Proceedings of the Second Workshop on Ontology Learning
OL'2001, Seattle, USA, August 4, 2001.

[13] Maedche, A., Staab, S., Nedellec, C., and WiemerHastings, P., (Eds.), ECAI’2000 Workshop on Ontology
Learning, Proceedings of the First Workshop on Ontology
Learning OL'2000, Berlin, Germany, August 25, Ceur
Workshop Proceedings Vol. 31 (publishers), 2000.

[14] Srihari R.K., Use of Collateral Text in Understanding
Photos. Artificial Intelligence Review (Special Issue on
Integrating Language and Vision), Vol. 8, pp. 409-430, 1995.

[15] Srihari, R.K. and Zhang, Z.L., Show&Tell: a SemiAutomated Image Annotation System. IEEE Multimedia,
Vol.7, (No. 3), pp. 61-71, 2000.

[16] Barnard, K., Duygulu, P., Forsyth, D., de Freitas, N.,
Blei, D.M., and Jordan, M.L., Matching Words with Pictures,
Journal of Machine Learning Research, Vol. 3, pp 11071135, 2003.

[17] Picard, R.W., Towards a Visual Thesaurus. In: Ruthven,
I. (Ed.), Electronic Workshops in Computing, MIRO 95,
Glasgow, UK, 18-20, September 1995. (Available at

Proceedings of the Ninth International Conference on Information Visualisation (IV’05)
1550-6037/05 $20.00 © 2005 IEEE

http://ewic.bcs.org/conferences/1995/miro95/papers/paper13.
pdf, last accessed 20/04/2005)

[18] Ahmad, K., and Rogers, M.A. (2001), ‘Corpus
Linguistics and Terminology Extraction’. In (Eds.) Wright,
S.E., and Budin, G., Handbook of Terminology Management
(Volume 2). Amsterdam & Philadelphia: John Benjamins
Publishing Company. pp 725-760.

[23] Handy, C. and Ahmad, K., Indexer variability in
specialist domains. In (Eds) M. Rogers and K. Ahmad.
Proceedings of the 14th European Symposium on Language
for Special Purposes (LSP 2003). p71-76, (Available at
http://portal.surrey.ac.uk/portal/page?_pageid=798,307173&
_dad=portal&_schema=PORTAL,
last
accessed
on
25/04/2005 )

[24] Ahmad, K. & Vrusias, B. ‘Learning to Visualise High[19] Smadja, F. Retrieving Collocations from Text: Xtract.
Computational Linguistics, Vol. 19, pp 143-177, 1993.

[20] Gillam, L., Tariq, M., & Ahmad, K. Terminology and
the Construction of Ontology. Terminology 11(1), pp55-81,
2005

[21] Ahmad, K., Tariq, M., Vrusias, B. and Handy (2003) C.,
Corpus-Based Thesaurus Construction for Image Retrieval in
Specialist Domains. In (Ed). Fabrizio Sebastiani. Proc 25th
European Conf on Inf. Retrieval Research (ECIR-03, Pisa,
Italy) LNCS-2633. Heidelberg:Springer Verlag. pp 502-510.

[22] Ahmad, K., Casey, M. & Vrusias, B., Combining
Multiple Modes of Information using Unsupervised Neural
Classifiers. In (Ed.) Terry Windeatt and Fabio Rolli. 4th
International Workshop, MCS 2003.
LNCS 2709.
Heidelberg: Springer-Verlag. pp 236-245.

Dimensional Data’. In (Eds.) E. Banissi et al. Proc. of 8th
International Conference on Information Visualisation
(London, England, 14-16 July 2004). Los Alamitos: IEEE
Computer Press. pp 507-512.

Acknowledgements
Meng Zhu wishes to thank the Department of
Computing, University of Surrey for a PhD
scholarship. Khurshid Ahmad and Bogdan Vrusias
wish to acknowledge the support of the UK
Engineering and Physical Sciences Research Council
Grant (REVEAL Project, GR/M/89041). The authors
gratefully acknowledge the use of images used in the
training of scene-of-crime officers at the Metropolitan
Police Training Academy, London, particularly David
Ince, the then Head of the Academy.

Proceedings of the Ninth International Conference on Information Visualisation (IV’05)
1550-6037/05 $20.00 © 2005 IEEE

