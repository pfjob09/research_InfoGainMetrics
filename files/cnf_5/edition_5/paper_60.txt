Hairstyle Construction from Raw Surface Data
Gerrit Sobottka, Michael Kusak, Andreas Weber
Institute of Computer Science II, University of Bonn, Germany
{sobottka, kusak,weber}@cs.uni-bonn.de

Abstract
We present a novel approach to the problem of hairstyle construction from raw surface data such as the ones obtained from surface
scans. Our approach is based on a shape matching algorithm that
ﬁts individual hair ﬁbers into a given volume according to a set of
boundary conditions and additional hair density information. Our
method employs a mechanical rod model based on the special theory
of Cosserat rods. Such models can efﬁciently be used to simulate the
deformation of individual ﬁbers in subsequent manipulation steps.
Keywords—Hair modeling, hairstyle construction, hair volume,
surface data, optimization, ﬁbers, Cosserat rods

1 Introduction
Generating realistic looking hairstyles is an unresolved
problem in the realm of computer graphics. Standard approaches still require a high degree of manual effort because
the main ﬂow directions must be given in terms of guide hairs.
Whereas the problem of reconstructing local hair geometries
out of sequences of photographs has been addressed recently,
the problem of hair style generation from raw surface data
has not been incorporated in existing approaches so far.
Such surface data can be obtained from scans of sculptures.
The boundaries of the hairstyle are deﬁned by the scalp as
well as the hair volume surface. A possibility to construct
plausible hairstyles considering the volume boundaries is of
great interest for different purposes, e.g. in the context of
virtual heritage projects.
Our contribution: We present a new approach to the
problem of constructing realistic looking hairstyles from raw
surface data. In contrast to other approaches our algorithm
is automated, yet fully customizable by the user through the
speciﬁcation of only a handful of parameters. No manual
interactions are required. To model the hair ﬁbers we employ
a mechanical model based on the special theory of Cosserat
rods. Our approach is thus physical and allows us to estimate
the magnitude of forces occurring inside the hair volume.

2 Related Work
In the last few years several approaches to the hairstyle
generation problem have been introduced. Lee et al. [10] presented a system for hairstyle creation which allows interactive
manipulation of computer generated hairstyles using a motion
tracking device. Hadap and Thalmann [7] presented a method
that models the hair geometry as ideal ﬂuid ﬂow. Sources
are placed along the scalp surface to prevent streamlines
from penetrating the object boundaries. However, even high
source densities cannot guarantee a penetration free hairstyle.
This is closely related to our approach as we use linear

approximations of the object boundaries on rectilinear grids
to tackle the penetration problem. Moreover, this approach
alone cannot account for other geometries than soft curves
with small curvature. In [17] Yu pursues a similar approach
by exploiting the analogy between smooth vector ﬁelds and
hair ﬂow. Procedurally generated vector ﬁeld primitives are
superimposed to obtain complex hairstyles. In [16] Xu and
Yang presented a modeling tool based on a cluster hair
model. Simple operations are used for the interactive creation
and manipulation of hair clusters. In the same spirit, Kim
and Neumann [9] present a so called multi resolution hair
modelling system wherein hair is modeled on a per-cluster
basis. The full hairstyle in obtained from a sequence of copy
and paste, curling and moving operations of hair primitives
as well as user driven reﬁnements of individual clusters to
add more detail to the hairstyle. Recently, Choe and Ko [4]
presented a hair styling tool that is based on a pseudo-physical
approach. Similar to ours, it uses force as well as density ﬁelds
to approximate the impact of gravity and hair-hair interaction,
respectively.
The aforementioned approaches have in common that
hairstyles are manually modeled with interactive tools. The
computer vision approach, on the other hand, which primarily
aims at the reconstruction of hairstyles from a set of photos
has recently gained increased attention.
Haider and Kaneko [8] proposed an algorithm for hair
volume reconstruction from a set of video captured images.
A hairless 3D head model obtained from CT scans is used for
the registration of camera parameters. After segmentation of
the hair region in the images and the registration of the camera
positions a three dimensional hair volume is computed. The
extracted hair texture is then mapped to the model. This is
in fact a pure volume based model because no hair ﬁbers are
generated. Recently, Paris et al. [13] proposed an algorithm
for hair geometry reconstruction from a set of images taken
under variable lighting conditions. Different ﬁlter operations
are applied to these images to determine the orientation of each
pixel. From these data the full hairstyle is computed according
to the visual hull and additional information like camera
positions. The most impressing results, however, are obtained
with the image based approach of Wei et al. [15]. Only a
set of images taken under uncontrolled lighting conditions are
needed. The orientation of each hair segment is triangulated
with orientation information from multiple views. The shape
of the skull is approximated by an offset surface of the visual
hull.
The reconstruction with these approaches requires that local
orientation information are given or can at least be recon-

Proceedings of the International Conference on Computer Graphics, Imaging and Visualisation (CGIV'06)
0-7695-2606-3/06 $20.00 © 2006

3.1 Special Theory of Cosserat Rods

Fig. 1. The input for our model is given by the scalp and the hair volume
surface. The extraction of the surfaces from sculpture scans are beyond the
scope of this paper and left as a black box process.

structed. Thus, these algorithms cannot be used for sculpture
scans, by which only the boundary corresponding to the visual
hull is given.

3 Outline of the Algorithm
Our algorithm takes as input the scalp surface SS , and,
in addition, the boundary SH of an associated hair volume,
cf. Fig. 1. Starting from a sculpture scan the basic task is
to decompose the surface of the sculpture into the required
input data. One possibility to solve this difﬁcult problem is
to generate a scalp surface as an offset surface from the
hair volume boundary. However, this is a rather approximate
solution at best. A more promising approach is to search for
a similar hair-less head model in a large data set of head
models and to subtract it from the sculpture scan to obtain
the hair volume. This approach is similar to the morphable
head models of Blanz and Vetter [2]. We have not employed
a fully automated method for this preprocessing step. For our
examples we have generated some examples semi-manually.
This pre-processing step can be taken as a black box for the
following algorithm, which is the main topic of this paper.
Given the boundaries deﬁned by the scalp as well as
the hair volume surface we solve an optimization problem
in order to ﬁnd optimal terminal force-torque pairs which
deform the ﬁbers to an “optimal” conﬁguration according
to their distances from the boundaries as well as local hair
density information. Technically, we solve an unconstrained
optimization problem by formulating various “contraints” as
“soft constraints”. Since our starting basis is an empty volume
we ﬁrst generate a set of pre-guides which coarsely sample the
main ﬂow directions for principal guide generation. After the
optimization process we compute for each principal guide a
hair strand (wisp) employing a simple strand generator. We
refer to the volume encapsulated by the scalp surface and
the hair volume surface as acceptable region. The transition
between the acceptable region and the non-acceptable or
forbidden region is smooth.
In the following we will discuss in detail the components
of our system needed to generate hairstyles from raw surface
data.

To simulate a single hair ﬁber we employ a mechanical rod
model based on the special theory of Cosserat rods [1]. Let
r(s) : [a, b] ∈ R → R3 be a smooth space curve of length L
describing the centerline of a hair ﬁber. Further, let {di (s)}
be a set of orthogonal directors furnishing the space curve
such that d1 , d2 span the cross section plane and d3 = r is
tangent to space curve, where (·) denotes the derivative with
respect to arc length. The special theory of Cosserat rods [1]
used herein describes the deformation of a long thin elastic
rod subject to external loads. Since we are only interested in
the equilibrium conﬁgurations the static equations governing
this state are given as
n +f
m +r ×n+g

= 0,
= 0,

(1)
(2)

where n and m are the contact force and contact couple at
the cross sectional area, respectively. f and g are the external
forces and moments acting on the rod. Further, we have the
kinematic relation
di = u × di .

(3)

Here, u indicates the twist vector and expresses the local
bending and twist about the three directors. The relation
between local deformations expressed by the twist vector
and the material properties is given by suitable constitutive
laws. For our purposes we assume the rod to be hyper-elastic,
unshearable, and inextensible. Hence, the constitutive relation
ˆ ), where C is a diagonal
takes the simple form m = C · (u − u
matrix describing the material’s resistance against bending and
twist about the three axes:
⎞
⎛
0
0
EI1
0 ⎠.
EI2
(4)
C=⎝ 0
0
0
GA
Here, we can work with authentic material properties of
human hair of E = 3.89 · 1010 and G = 0.89 · 1010 dynes/cm
for Young’s modulus and the shear modulus, respectively. The
ˆ describes the default twist of the rod and I1,2 are
vector u
the principal moments of inertia of the cross section A (≈
1.5 · 10−5 cm2 ).
Since the ﬁlaments are clamped at the scalp and can freely
move at the other end, we obtain the following boundary
conditions: r(0) = r0 , d1 (0) = d10 , d2 (0) = d20 , f (L) = fL ,
and t(L) = tL , where fL and tL are the external force and
torque acting at s = L.
Thus, we have to solve boundary value problems for a
coupled system of ordinary differential equations. Standard
BVP solvers are often based on shooting techniques which
usually perform at slow convergence rates. In [11] a solution
method for this particular type of boundary value problem
based on the Kirchhoff kinetic analogy is proposed. In [14]
a simple energy minimization scheme is proposed that is
also capable of handling intermediate boundary conditions.
In [12] Pai introduces a rather approximate solution scheme

Proceedings of the International Conference on Computer Graphics, Imaging and Visualisation (CGIV'06)
0-7695-2606-3/06 $20.00 © 2006

by decoupling the kinematic relations from the balance laws.
Unfortunately, this approach treats forces and torques with
respect to the local systems which transforms each force into a
follower load, a problem which is discussed in more detail in
[14]. In order to enable the incorporation of different solution
schemes we parameterized our system with different solution
schemes for BVPs.
3.2 Boundary Representation
Another central problem we have to deal with is the efﬁcient
representation of the scalp as well as the hair volume surface,
such that hairs are prevented from occupying the forbidden
area outside the boundaries. For this purpose, we compute for
the surfaces SS and SH an implicit linear approximation or
distance ﬁeld ΦS which is a scalar mapping ΦS : R3 → R
such that
ΦS (x) := min {|x − q|}, ∀x ∈ R3 .
q∈S

(5)

We decided to use simple a rectilinear grid because of improved performance over octree encodings; notice that the increase in memory costs is negligible for our applications. Since
we do not assume that the mesh obtained in the preprocessing
steps is closed, we only compute a distance envelope of a
predeﬁned thickness. This is done using the method of characteristics [3]. For each feature of the underlying meshes the
corresponding Voronoi region is computed. We then calculate
the distances of all grid points within a Voronoi region to
the corresponding feature using a scan conversion algorithm.
It is possible to sign the distances by taking into account
the direction of the normal of each triangle. The normals of
the triangles indicate the “exterior” if the underlying mesh is
oriented. The signs of the distances are then chosen according
to the signs of the scalar products of the point’s local position
vectors and the normals of the triangles to which the closest
feature belongs. For a given point the distance to a surface
can be computed by means of a trilinear interpolation over
the distances at the eight corner points of the corresponding
cell.
3.3 Hair Distribution and Growth Directions
In order to allow for an uniform distribution of the hair
pores on the scalp surface SS we parameterize it using a
conformal mapping C : R3 → R2 such that the surface is
projected onto the plane by using a Floater parameterization
[5], which guarantees a one-to-one mapping. The parameter
domain is mapped onto the unit circle. We then compute
a homogeneous point distribution and map it back onto the
corresponding triangles by using the barycentric coordinates
of the points. In the examples we use authentic density values
of 200 hairs per cm. After the point distribution we cluster
points by computing a covering with circles of the 2D domain.
The center of each cluster is taken as base position for the
guides. Since the circles are allowed to overlap we randomly
associate affected points to one of the guides to which the
region belongs. This prevents sharp-edged base areas of the
ﬁnal clusters. Simple shape distortion minimizing schemes like

the above cannot avoid distortion of the texture in general.
We found that carefully chosen parameters can minimize such
effects for meshes with simple topologies like the scalp surface
which resembles a hemisphere. The remaining distortion is
advantageous in the sense that it deforms circular base areas
into more elliptical ones.
The hair density, the growth directions, and the hair length
distributions are encoded in a texture bitmap by means of
grey values. Unfortunately, little empirical facts about the real
growth direction distribution on the scalp can be found in the
literature. From our own observations we know that hair in the
temporal as well as the occipital region of the head growth in
tangential direction rather than normal to the surface. This is
an important fact to consider as it allows for more realistic
looking hairstyles, as is demonstrated by our results.
The guides are deformed according to the scheme that is
described in the following section.
3.4 Guide Generation
With the rod model deﬁned above and the deﬁnition of
the linear approximation of the boundary surfaces at hand
we can now develop an algorithm to keep the ﬁbers inside
the acceptable region and follow the ﬂow deﬁned by the preguides. We deﬁne as ηL = {fL , tL } the terminal end load
acting on a ﬁber at s = L. In particular, we seek a terminal
∗
consisting of a force and a torque that minimizes
end load ηL
an objective function which we will describe next. Thus, our
optimization problem is a six-dimensional one.
One might be wondering why a terminal force-torque pair
is sufﬁcient? However, the reason is rather obvious: using
a terminal force-torque pair allows one to model arbitrary
conﬁgurations including helices. A terminal force alone can
only generate arcs whereas the additional incorporation of
torques extends the variety of possible shapes. In principle, it is
also possible to use intermediate loads but this only increases
the dimension of the underlying optimization problem. Direct
control of bending angles as was proposed by [4] does not
guarantee a continuous curve as is the case when we use a
mechanical rod model.
Pre-Guide Generation: The pre-guides are generated according to the following scheme: First the base points for the
pre-guides are distributed with a low density of 1 ﬁber per
cm or less, cf. Sect. 3.3. Then we rotate the pre-guides into
the direction of the corresponding growth normals. After the
pre-guides took their initial positions we iteratively increase
a terminal end load until the extremities immerses into the
hair volume by a predeﬁned depth. The force has a direction
normal to the rod’s initial axes and lies within the plane deﬁned
by the normal of the triangle and the corresponding rotated
normal obtained from the growth direction distribution texture.
The immersion depth is chosen such that the frontal hairs are
close to the hair volume surface and increases according to the
geodetic height of the base points. Thus, lower guides generate
the lower hair layers of the style. The maximum possible depth
are obtained by superposition of the distance ﬁelds for the
scalp surface and the hair volume surface, respectively.

Proceedings of the International Conference on Computer Graphics, Imaging and Visualisation (CGIV'06)
0-7695-2606-3/06 $20.00 © 2006

Principal Guide Generation: The objective function to
be minimized is a weighted sum of n terms, each of which
controls a certain aspect of the underlying problem. This
function is given by
min f (η) =

wi · Fi ,

(6)

3

where Fi : R → R are scalar valued functions and wi ∈ R
are the respective weights, with
wi = 1.
The ﬁrst term F1 accounts for the directional correspondence of the current guide to its adjacent pre-guides and is
given as
1
rG rC
,
ds.
(7)
1−
F1 =
|r
0
G | |rC |
This correspondence is measured in terms of the cosine of
the angle between the local tangents of the guide and the
current ﬁber at the positions rG (s) and rC (s), respectively.
The function, thus obeys (1 − cos ϕ). That is, if the local
directions are parallel, then the function evaluates to zero, if
they are orthogonal to one and the function takes its highest
value if they are antiparallel. This function is evaluated for a
variable number of pre-guides in the vicinity of the current
guide. We found that three pre-guides are sufﬁcient. The
contribution of each pre-guide is weighted according to its
distance from the guide on the scalp. This allows for more
smooth transitions. Please note, that r (s) = d3 (s).
The second term F2 accounts for the similarity of the
current guide to the pre-guides. It is deﬁned as
F2 =

1
0

2

Δu ds

To account for hair-hair interactions and to obtain a more
homogeneous ﬁber distribution throughout the acceptable hair
region we also incorporate local density information. For this
purpose, we iteratively generate a density ﬁeld that describes
the approximate local hair density at each point of the acceptable hair region. The density ﬁeld is encoded on a rectilinear
grid. If the local density in the region that a guide and its
corresponding strand will presumably occupy is larger than
a predeﬁned threshold, then we add a high surcharge to the
energy value. If a principal guide takes its ﬁnal conﬁguration,
then the densities within a cylindrical region around the guide
are added to the voxels occupied by it. This cylindrical region
will later be ﬁlled with hair by a simple strand generator.
Here, we discuss two different density models:
•

.

|d|, if d < 0
.
cd + |d|, if d > 0

(8)

(9)

As has been mentioned before the boundary is formed by the
scalp and the hair surface, respectively. We calculate the distance of each point to the boundaries using the corresponding
distance ﬁelds, cf. Sect. 3.2. As can be seen in the equation we
punish harder if a ﬁber is outside the boundaries by adding a
constant value of cd . The function is applied for both surfaces,
the scalp and the hair volume.
The contributions of the above terms can conveniently be
controlled by the weighting parameters wi , e.g., the higher the
contribution of the similarity controlling term is the better the
match of the principal guides to the shape of the corresponding
pre-guides is.
For each guide we start the optimization process from a
straight conﬁguration (ˆ
u = 0) pointing in the direction of the
corresponding growth normal, cf. Sect. 3.3.

Binary occupancy model (BOM): In this model the
voxels occupied by a full strand are assigned the value 1.
The corresponding grid must have a high resolution such
that the region ﬁlled by a single segment remains small.
We incorporate this model into the objective function by
adding a fourth term:
F4BOM = cBOM ·

1
2

The local curvature and torsion is the used measure for the
similarity of two curves. These quantities are given by the twist
vector u, cf. Sec. 3.1. The vector Δu = uG − uC describes
the twist difference between the guide and the current curve.
Note that since the curves need not be of the same length we
use the normalized curves, thus s ∈ [0, 1].
The third term F3 deals with the problem of boundary
penetration of individual ﬁbers and is given as
F3 =

3.5 Using Local Density Information

•

δ(si ).

(10)

The function δ evaluates to 1 if segment si intersects an
occupied voxel, 0 otherwise. That is, for each segment
of a guide that penetrates an occupied cell we add a
value of cBOM . To determine the occupancy we employ
a simple voxelization algorithm that ﬁnds intersections
of grid cells with a strand by means of the separating
axis test, cf. [6]. For this, we embed each segment of the
generalized cylinder (frustum) into an oriented bounding
box (OBB). The separating axis test is performed for
each voxel within the axis aligned bounding box of the
frustum and its corresponding OBB.
Continuous Density model (CDM): For the second
model we compute a scalar density ﬁeld Φρ : R3 → R
on a rectilinear grid. For each ﬁber we calculate the ﬁbervoxel intersections using a voxel traversal algorithm. The
local density is increased by the ratio of the segment
length inside a cell and the cell diagonal. The idea is
to force the ﬁbers into the direction of equal density.
For this, the density gradient ∇Φρ is computed along
the guide curve. The corresponding term added to the
objective function writes
F4CDM = cρ ·

L
0

∇Φρ ,

r
|r |

2

ds.

(11)

That is, if the direction of the local tangent is parallel
to the gradient we add a surcharge of cρ · |∇Φρ |2 to the
energy value. If the tangent is perpendicular the surcharge
is 0 because the ﬁber’s local direction is in optimal
alignment with the direction of equal density.
The gradient of the density ﬁeld can conveniently be
approximated by a central ﬁnite difference scheme.

Proceedings of the International Conference on Computer Graphics, Imaging and Visualisation (CGIV'06)
0-7695-2606-3/06 $20.00 © 2006

In order to evaluate the degree of homogeneity before and
after the incorporation of the density function we computed a
density histogram which can be seen in the results section.
3.6 Final Cutting and Strand Interpolation
To generate the full hairstyle from the set of principal guides
we employ a simple strand generator. Grouping hairs can
be justiﬁed by the observation that real hairs tend to form
clusters. In a pre-processing step we cut hairs that penetrate
the boundaries. This occurs predominantly in the occipital
region where the distance from the pore to the boundary is
very short. We use our distance ﬁeld approach to search for
the ﬁrst segment that penetrates the hair volume. If the length
of the ﬁber outside the volume exceeds a predeﬁned threshold
before the ﬁber immerses into the volume again it is cut at
the ﬁrst boundary penetrating segment.
Given the shape of a principal guide we generate a bunch
of ﬁbers within a cylindrical region around it. This region is
formed by a generalized cylinder with varying radius along
the curve. Our scheme is very similar to that of [4] but allows
the ﬁbers of a strand to wind around the corresponding guide.

Fig. 2. The reference hair volume surfaces used to demonstrate the capabilities of our approach. Left pair: spheroidal volume and the reconstructed
hairstyle. Right pair: straight volume and the reconstructed hairstyle.

4 Results
For demonstrating the efﬁciency of our algorithm we generated two hairstyles from two different hair volume surfaces
using varying parameter sets. Speciﬁcally, we used the following two test cases:
a) a spheroidal volume obtained from a sculpture scan, and
b) a straight hair volume taken from Poser,
cf. Fig. 2. Both generated styles cover one half of a human
head model. The results from different perspectives as well
as the corresponding visual hull are depicted in Fig. 3. For
hair rendering we used the model proposed by Zinke et al.
[18]. The respective number of ﬁbers was 90 000 for the
ﬁrst model and 60 000 for the second model. The number of
guides used to sample the main ﬂow directions was 3000. The
times for hairstyle generation was approximately 1.5 minutes
on a Pentium IV (2.2 GHz). As can bee seen in Fig. 3 the
results show that our algorithm is capable of preserving all the
structural details dictated by the hair volume surface. Empty
regions inside the hair volume are caused by insufﬁcient hair
lengths, a problem that will be addressed in our future work.
The impact of the two density models CDM and BOM
(cf. Sect. 3.5) on the ﬁnal result with varying values for the
weighting parameters are shown in Fig. 4. As can be seen on
those examples the hairstyles become stringier with increasing
fraction. Furthermore, the distribution of the occupied voxels
is more homogeneous with the CDM or BOM than without
the density models, cf. Fig. 5 and Fig. 6.

Fig. 3. Overlay of the visual hull of the hair surface and the corresponding
hairstyles from different perspectives. Please note the structure preserving
capabilities of our algorithm. Empty volume is caused by insufﬁcient hair
lengths.

Fig. 4. Same hairstyle with varying contribution of the CDM. Increasing the
contribution of the density controlling term results in a stringier look.

5 Conclusion and Future Work
We have presented a new approach for automated hairstyle
generation from raw surface data obtained from sculpture
scans. This model can be used to generate initial values for
a subsequent physics based hair simulation. However, there
are still open questions, e.g., how the hair lengths and main

Fig. 5. Histogram of the density distribution. Left: Number of segments
(1-50) per cell (abscissa) and the number of cells (ordinate) obtained with the
CDM. Right: The same, but without any density model.

Proceedings of the International Conference on Computer Graphics, Imaging and Visualisation (CGIV'06)
0-7695-2606-3/06 $20.00 © 2006

Fig. 6. The picture shows the hair density distribution inside the hair volume
(center sagittal plane) obtained with the continuous density model (CDM).
Note that the hair density is a) homogeneous and b) zero inside the head.

ﬂow directions can directly be estimated from the hair volume
surface in order to further reduce the parameters that must be
handled by the user. Addressing these open questions will be
the content of future work.

6 Acknowledgements
We are grateful to A. Zinke for many helpful discussions
and his assistance in rendering the results. The presented work
is partially supported by Deutsche Forschungsgemeinschaft
under grant We 1945/3-2.

References
[1] Stuart S. Antman. Nonlinear Problems of Elasticity, volume 107 of
Appl. Math. Sci. Springer-Verlag, Berlin and New York, 1995.
[2] Volker Blanz and Thomas Vetter. A morphable model for the synthesis
of 3D faces. In Siggraph 1999, Computer Graphics Proceedings, pages
187–194, 1999.
[3] David E. Breen, Sean Mauch, Ross T. Whitaker, and Jia Mao. 3D Metamorphosis between different types of geometric models. Eurographics
2001 Proceedings, 20(3):36–48, 2001.
[4] Byoungwon Choe and Hyeong-Seok Ko. A statistical wisp model and
pseudophysical approaches for interactive hairstyle generation. IEEE
Transactions on Visualization and Computer Graphics, 11(2):160–170,
2005.
[5] Michael S. Floater. Parametrization and smooth approximation of
surface triangulations. Computer Aided Geometric Design, 14(4):231–
250, 1997.
[6] S. Gottschalk, M. C. Lin, and D. Manocha. OBBTree: A hierarchical
structure for rapid interference detection. In Proceedings of the 23rd
annual conference on Computer graphics and interactive techniques,
pages 171–180, 1996.
[7] Sunil Hadap and Nadia Magnenat-Thalmann. Interactive hair styler
based on ﬂuid ﬂow. In Computer Animation and Simulation, pages
87–100, August 2000.
[8] Ali Haider and Toyohisa Kaneko. Hair shape modeling from video
captured images and CT data. In The Proceedings of ICAT2000, pages
52–57, 2000.
[9] Tae-Yong Kim and Ulrich Neumann. Interactive multiresolution hair
modeling and editing. In ACM Transactions on Graphics (TOG), volume
21(3), pages 620–629, July 2002.
[10] Chai-Ying Lee, Wei-Ru Chen, Eugenia Leu, and Ming Ouhyoung. A
rotor platform assisted system for 3d hairstyles. In (WSCG’2002) the 10-th International Conference in Central Europe on Computer
Graphics, Visualization and Computer Vision’2002, 2002. To appear.

Fig. 7. Hairstyle examples generated with our approach shown from different
perspectives. 1) and 2): Hairstyle obtained with the spheroidal hair volume
surface. 3): This model was obtained with an increased weighting parameter
for the similarity term and a greater hair length. This results in a very smooth
look. 4) and 5): Hairstyle obtained with the straight hair volume surface. 6):
This model results from increased hair lengths.

[11] Shu Liu and Andreas Weber. A symbolic-numeric method for solving
boundary value problems of Kirchhoff rods. In Victor G. Ganzha,
Ernst W. Mayr, and Evgenii V. Vorozhtsov, editors, Computer Algebra
in Scientiﬁc Computing (CASC ’05), volume 3718 of Lecture Notes in
Computer Science, pages 387–398, Kalamata, Greece, September 2005.
Springer-Verlag.
[12] Dinesh K. Pai. STRANDS: Interactive simulation of thin solids using
Cosserat models. In Computer Graphics Forum, volume 21(3), pages
347–352, 2002.
[13] Sylvain Paris, Hector Brice˜no, and Franc¸ois Sillion. Capture of hair
geometry from multiple images. ACM Transactions on Graphics
(Proceedings of the SIGGRAPH conference), 2004.
[14] Gerrit Sobottka and Andreas Weber. Computing static electricity on
human hair. In Proceedings of Theory and Practice of Computer
Graphics 2006, 2006.
[15] Yichen Wei, Eyal Ofek, Long Quan, and Heung-Yeung Shum. Modeling
hair from multiple views. In ACM Transactions on Graphics (TOG),
2004, volume 24(3), pages 816–820, 2005.
[16] Zhan Xu and Xue Dong Yang. V-HairStudio: An interactive tool for
hair design. IEEE Computer Graphics and Application, 21(3):36–43,
May/June 2001.
[17] Yizhou Yu. Modeling realistic virtual hairstyles. In Proceedings of
Paciﬁc Graphics, pages 295–301, 2001.
[18] Arno Zinke, Gerrit Sobottka, and Andreas Weber. Photo-realistic
rendering of blond hair. In Vision, Modeling, and Visualization (VMV)
2004, volume 24(3), pages 191–198, 2004.

Proceedings of the International Conference on Computer Graphics, Imaging and Visualisation (CGIV'06)
0-7695-2606-3/06 $20.00 © 2006

