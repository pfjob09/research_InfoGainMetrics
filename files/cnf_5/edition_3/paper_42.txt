Fifth International Conference on Computer Graphics, Imaging and Visualization
Visualisation

Object Class Recognition Using NEAT-evolved Artificial Neural Network
Mozaherul Hoque Abul Hasanat, Siti Zubaidah Harun, Dhanesh Ramachandram and Mandava Rajeswari
Computer Vision Research Group
School of Computer Sciences
Universiti Sains Malaysia
{mozaher,sitiharun,dhaneshr,mandava}@cs.usm.my

Abstract

Earlier works on object recognition involve rule based algorithms such as in [4][13][20]. Although in this approach a
limited set of rules is sufficient to recognize a specific object
of a particular class, accommodating for interclass variability in terms of appearance, scale, and or rotation is not possible. For this reason rule based methods are supplanted by
statistical machine learning approaches. Algorithms such
as Bayesian model [1], Gaussian Mixture model [6], or the
more recent support vector machines (SVM) [12] are robust
to inter class variability and has high discriminative power
despite noise and clutter. While these methods have obtained promising results, they are computationally intensive
and typically require a large set of exemplar images (training data) to learn a specific class model.
In recent years artificial neural networks have been studied extensively as a non statistical approach to information
processing. Artificial neural networks are capable of processing a large amount of information simultaneously and
address problems not by means of pre-specified algorithms
but rather by “learning” from examples presented repetitively. The popularity of neural networks is primarily due
to their apparent ability to make decisions and draw conclusions when presented with complex, noisy, or partial information and to adapt their behavior to the nature of the
training data. Artificial neural networks have been applied
to a variety of data-classification and pattern-recognition
tasks and have shown to be a potentially powerful classification tool [16][23]. Despite the promising performance, network topology and connection weights needs to be carefully
crafted for any specific classification problem. To address
this issue, evolutionary algorithms can be used to evolve
neural network weights and topology at the same time and
this simultaneous evolution approach has been found to be
quite successful [3][9][24]. NeuroEvolution of Augmenting Topologies (NEAT) [17] is one such method. NEAT
has demonstrated the ability to outperform other neuroevolutionary approaches and perform well at a variety of tasks
[7][18][19].
We present a novel method for object class recognition

Object class recognition is a highly challenging area in
computer vision and machine learning. In this paper, we
introduce a novel approach to object class recognition using NeuroEvolution of Augmenting Topologies (NEAT) to
evolve artificial neural networks (ANN) capable of taking
advantage of the robust SIFT feature based descriptor histograms. We claim that NEAT can produce ANN classifier
which exhibits outstanding ability of learning from only a
few training examples without sacrificing accuracy. Our
empirical evaluations against the performance of state of
the art statistical machine learning method such as support vector machine show that NEAT-evolved ANN classifier outperforms by an average of 9.96% higher accuracy
when presented with very small training set proving its superior ability to generalize its learning.
Keywords— NEAT, Object Class Recognition, SIFT,
NeuroEvolution.

1

Introduction

Object class recognition has recently received a great
deal of attention from the vision research community. It
is a challenging problem in computer vision especially in
the presence of intra-class variation, clutter, occlusion, and
pose changes. Compared to the recognition of specific individual objects from images (e.g. different images of the
same car), object class recognition involves classification of
objects belonging to a class such as car, motorbike, or human face with different instances of the object, (e.g. images
of different cars).The difficulty of recognizing classes of objects requires methods of comparing images that capture the
variation within the class while discriminating against objects from different classes. The object class recognition
problem is also termed as generic object recognition or object categorization problem.

978-0-7695-3359-9/08 $25.00 © 2008 IEEE
DOI 10.1109/CGIV.2008.35

271

using NEAT-evolved ANN (artificial neural network) classifier which can learn an object model from a minimal number of exemplar images, yet be able to classify with a relatively high degree of accuracy.
The rest of the paper is organized as follows. Section 2
provides a brief review of NEAT. The detailed steps of our
proposed classification approach are discussed in Section
3. Empirical evaluation of our NEAT-evolved ANN with
Caltech-101 dataset is included in Section 4. In Section
5 we present the results of our experiments and provide a
comparison with SVM classifier tested on identical dataset.
Final conclusion and future work are summarized in Section
6.

2

about 50 images each. The size of each image is roughly
300 x 200 pixels. The object classes used in our work are
Car, Motorbike and Leopard. Most of the photographs are
taken in its natural context. As a result, the images have
non-uniform natural background. Out of the three classes
used, Leopard images are most difficult to recognize due to
the similarity of texture between the background and foreground objects.
Histogram descriptors are then computed for each image
in the dataset as discussed in the following section.

3.2

We used Harris-affine detectors [5] to detect the key
points in an image and SIFT (Scale Invariant Feature Transform) local features are extracted1 from the key points as
described in [15]. SIFT features have shown a higher robustness and stability than other local descriptors as shown
in [11][14]. The distinctiveness of SIFT features, as well as
their abundant presence over a large range of image scales
make them suitable for recognition in cluttered and dynamic
situation.

Review of NEAT

The algorithm used to evolve the neural network classifier is NEAT, a neuroevolution methodology proposed by
Stanley and Miikkulainen in [17]. NEAT uses genetic algorithm to simultaneously evolve the connection weights
and network topology of the of a neural network. It is distinguished from other neuroevolution algorithms by allowing crossover between networks with different topologies.
Also, NEAT uses genetic speciation to divide the population
into structurally similar subgroups. The power of NEAT
lies in its ability to minimize the search dimensionality of
weight space by minimizing and gradually growing the network topology [18] which leads to better generalization in
learning tasks. NEAT has been applied extensively in unsupervised learning problems [8][21][22]. However, its special features also make it an ideal candidate for supervised
learning required for object class recognition problem.

3

3.3

Visual Vocabulary Construction

In this step the extracted SIFT descriptors are clustered
using a clustering algorithm to construct a visual vocabulary. Instead of using k-means as in [12] we used s means
clustering algorithm by Hansheng [10]. S-means is a similarity driven clustering algorithm for tackling large scale
clustering problems. It also has some distinct advantages
over k-means in terms of sensitivity to initial partitioning,
effect of outliers on cluster centroid, and the requirement
of setting the number of cluster k beforehand. The visual
vocabulary consists of all the cluster centroids which correspond to the prototype image features. For computational
efficiency we have restricted the size of the visual vocabulary to 250 per class.

Image Classification with NEAT

We have adopted the bag of keypoint model as described
by Csurka in [1] except that s-means clustering algorithm
is used instead of k-means algorithm for visual vocabulary
construction. The reasons behind our choice of s-means
over k-means are discussed in Section 3.3 We then coupled
the model with our NEAT-evolved ANN for classification
purpose. The steps of our classification approach are detailed in subsequent sections.

3.1

Feature Extraction

3.4

Image Descriptor

Image descriptor is a representation of an image in terms
of visual vocabulary. Following the algorithm presented in
[1] a frequency vector is constructed by counting the number of times each visual word occurs within an image. The
frequency vector is also referred as descriptor histogram.
For each image the descriptor histogram will be different,
but the assumption is that throughout the image classes,
these histograms show similar patterns for images of the
same class, and dissimilar patterns for images of different
classes.

Dataset

Three object classes from Caltech 101 dataset [2] are
used to evaluate the classification performance of our
NEAT-evolved ANN classifier. The dataset was created in
September 2003 by Fei-Fei Li et. al. It contains pictures of
objects belonging to 101 different object classes. There are
about 40 to 800 images per class. Most object classes have

1 program codes provided by the Robotics department of the University
of Oxford at http://www.robots.ox.ac.uk/vgg/research/affine/

272

3.5

4

NEAT-evolved ANN for Classification

The implementation of NEAT used in this work is the
Java-based NEAT4J which is available as a SourceForge
project2 . Three ANNs are evolved independently using
NEAT algorithm to classify an image as belonging to any
of the three object classes selected in Section 3.1. Per the
NEAT paradigm the initial ANN architecture start to evolve
minimally with 250 input nodes corresponding to the 250
descriptor histogram bins, 1 hidden layer, and 1 output node
fully connected with only feed-forward connections. Initial
weight values were taken from a uniform distribution between -1 and 1. Input node activation functions are linear,
output nodes tanh-cubic, and hidden nodes tanh. The classification objective is attained when each output layer neuron
can correctly classify the image belonging to its own class
as 1 and image from other classes as 0. Therefore, the output matrix for each of the three ANN is 0,1. The output
γc of the network is a floating point number representing
the confidence of the network that the object in the image
does belong to the class in question. A threshold τ = 0.5
is used to determine the class ω of the image based on the
confidence value γc as
ω=

1, if γc ≥ τ
0, if γc < τ

Three classification problems are used to evaluate the
performance of NEAT-evolved ANNs. As mention earlier, the three object classes are: Car, Motorbike and Leopard. Each image is represented by a 250 bin descriptor histogram. For each object class we used two data sets of size
100 and 200 containing equal number of positive and negative samples. A total of six experiments are conducted using
these datasets.
For the purpose of measuring the classification accuracy,
we have applied 10-fold cross validation. In each iteration
the dataset is split up into a training set, containing ninety
percent of the data, and a test set, containing the other ten
percent.
A separate set of experiment on the 200 instance dataset
using only 10 percent of data as training set and the rest 90
percent as test set having equal number of positive and negative samples is carried out to evaluate the generalization
ability of the ANN.
The results of each experiment are compared against the
performance of an SVM classifier on the same dataset.
The parameters for the all the experiments are summarized in Table 1.

(1)

We introduce a fitness function that directly reflects the
performance of an individual network xi over the training
dataset of size N and is given by
f itness(xi ) =

2

N
N + δxi

ρx
× i
N

Table 1. NEAT parameters used for all experiments
Parameter
Population size
Epochs
Mutation rate
Crossover rate
Survival rate
Excess gene compatibility coefficient
Disjoint gene compatibility coefficient
Common weight compatibility coefficient
Speciation compatibility threshold
Add connection mutation rate
Add neuron mutation rate

(2)

In equation 2, δxi is the Euclidean distance between the
expected output γd and the actual output of network or the
class confidence value γc and is defined as
δxi =

(γd − γc )

2

(3)

where ρxi is the total number of correct classification network xi can produce. This fitness function encourages
the individual networks which minimize δxi and produce
a higher ρxi .
Each generation, upon receiving the fitness score the best
performing individuals of the population is selected for survival and reproduction through the standard genetic operators like mutation and crossover. NEAT presents three mutations operations: 1) mutate connection weight, 2) add new
connection, and 3) add new node.
A detailed account of genetic algorithm specific parameters and NEAT parameters in general for our experiments
are discussed in the following section.
2 available

Empirical Evaluation

5

Value
300
500
0.25
0.6
0.6
1
1
0.4
3
0.05
0.03

Results and Discussion

Table 2 compares the accuracy rate of our classifier
against an SVM classifier as implemented in [12] over the
same dataset.
Our NEAT-evolved ANN presents a comparable performance against the state-of-the-art statistical classification
approach. But more interestingly, it clearly out performs

at http://neat4j.sourceforge.net/

273

6 Conclusion
Table 2. Comparison of accuracy for NEATevolved ANN and SVM
Dataset size
(train/test)
Object Class:
NEAT
SVM
Object Class:
NEAT
SVM
Object Class:
NEAT
SVM

200
100
(180/20) (90/10)
Car
79%
80%
84%
80%
Motorbike
70.50%
70%
85%
66%
Leopard
71%
70%
79%
74%

Object class recognition problems are typically addressed by statistical machine learning approaches which
are computationally intensive and require a large set of
training images per class to produce satisfying results. In
this work we proposed a novel approach to object class
recognition using ANNs evolved by NEAT methodology.
NEAT is able to take advantage of the robust SIFT feature
based descriptor histograms to effectively produce classifier ANN with excellent generalization property. Through
empirical evaluations against the performance of SVM classifiers we showed that NEAT-evolved ANNs achieved 9.96
percent higher accuracy on average when trained with very
small training set. In this paper we have also introduced a
fitness function that incorporates classification accuracy and
output error to dictate the genetic evolution process.
Future work can include further investigation on reducing the dimensionality visual word frequency vector without sacrificing recognition performance as well as experimentation with NEAT parameters to improve overall performance.

200
(20/180)
61.67%
50.56%
55.88%
50%
64%
51.11%

SVM classifier when trained with a dataset significantly
smaller than the test set (only 10% of the test set). The
last column of Table 2 shows that throughout the three object classes, the ANN has achieved an average of 9.96%
higher rate of accuracy when it is trained with only 20 instances, and tested with 180 instances. These results prove
the ANN’s ability to generalize and extend the learning to
unseen object classes.
The bending of the ROC curves towards the top left border suggests a high hit rate of the evolved ANN against the
false positives. Figure 1 presents the ROC curve for all the
three classifiers tested on 100 instance dataset. The area
under the ROC curves for car, motorbike, and leopard are
0.73, 0.6, and 0.64 respectively.

References
[1] G. Csurka, C. Bray, C. Dance, and L. Fan. Visual categorization with bags of keypoints. Workshop on Statistical Learning in Computer Vision, ECCV, pages 1–22, 2004.
[2] L. Fei-Fei, R. Fergus, and P. Perona. Learning generative
visual models from few training examples: An incremental
bayesian approach tested on 101 object categories. Computer Vision and Image Understanding, 106(1):59–70, April
2007.
[3] F. Gruau. Genetic synthesis of boolean neural networks with
a cell rewriting developmental process. Combinations of Genetic Algorithms and Neural Networks, 1992., COGANN92. International Workshop on, pages 55–74, 6 Jun 1992.
[4] A. Hanson and E. Riseman. Visions: A computer system for
interpreting scenes. Computer Vision Systems, pages 303–
333, 1978.
[5] C. Harris. Geometry from visual motion. In A. Blake and
A. Yuille, editors, Active Vision, pages 263–284. MIT Press,
Cambridge, MA, USA, 1993.
[6] A. Hegerath, T. Deselaers, and H. Ney. Patch-based object recognition using discriminatively trained gaussian mixtures. 17th British Machine Vision Conference (BMVC06),
Edinburgh, UK, page in press, September, 2006.
[7] D. James and P. Tucker. Evolving a neural network active vision system for shape discrimination. In F. Rothlauf, editor,
Late breaking paper at Genetic and Evolutionary Computation Conference (GECCO’2005), Washington, D.C., USA,
25-29 June 2005.
[8] N. Kohl, K. Stanley, R. Miikkulainen, M. Samples, and
R. Sherony. Evolving a real-world vehicle warning system. In GECCO ’06: Proceedings of the 8th annual confer-

Figure 1. ROC curves for car, motorbike, and
Leopard classifier.

274

[9]

[10]

[11]

[12]

[13]

[14]

[15]

[16]
[17]

[18]

[19]

[20]
[21]

[22]

[23]

[24]

ence on Genetic and evolutionary computation, pages 1681–
1688, New York, NY, USA, 2006. ACM.
J. Koza and J. Rice. Genetic generation of both the weights
and architecture for a neural network. Neural Networks,
1991., IJCNN-91-Seattle International Joint Conference on,
ii:397–404 vol.2, 8-14 Jul 1991.
H. Lei, L. Tang, J. Iglesias, S. Mukherjee, and S. Mohanty.
S-means: Similarity driven clustering and its application
in gravitational-wave astronomy data mining. In Proceedings of The International Workshop on Knowledge Discovery from Ubiquitous Data Streams (IWKDUDS 2007). Warsaw, Poland, September 2007.
D. Lowe. Distinctive image features from scale-invariant
keypoints.
International Journal of Computer Vision,
60(2):91–110, November 2004.
F. Markowetz, L. Edler, and M. Vingron. Support vector machines for protein fold class prediction. Biometrical Journal,
45(3):377–389, 2003.
T. Matsuyama. Knowledge-based aerial image understanding systems and expert systems for image processing. Geoscience and Remote Sensing, IEEE Transactions on, GE25(3):305–316, 1987.
K. Mikolajczyk and C. Schmid. A performance evaluation
of local descriptors. IEEE Transactions on Pattern Analysis
and Machine Intelligence, 27(10):1615–1630, 2005.
K. Mikolajczyk, T. Tuytelaars, C. Schmid, A. Zisserman,
J. Matas, F. Schaffalitzky, T. Kadir, and L. Gool. A comparison of affine region detectors. International Journal of
Computer Vision, 65(1):43–72, Nov. 2005.
N. Pal and S. Pal. A review on image segmentation techniques. Pattern Recognition, 26(9):1277–1294, 1993.
K. O. Stanley and R. Miikkulainen. Evolving neural networks through augmenting topologies. Evolutionary Computation, 10(2):99–127, 2002.
K. O. Stanley and R. Miikkulainen. Competitive coevolution
through evolutionary complexification. Journal of Artificial
Intelligence Research, 21(1):63–100, 2004.
K. O. Stanley and R. Miikkulainen. Evolving a roving eye
for go. Genetic and Evolutionary Computation - GECCO
2004, 3103:1226–1238, 2004.
T. Strat. Employing contextual information in computer vision. In DARPA93, pages 217–229, 1993.
S. Whiteson, N. Kohl, R. Miikkulainen, and P. Stone. Evolving keepaway soccer players through task decomposition.
Genetic and Evolutionary Computation - GECCO 2003,
2723:201–201, 2003.
S. Whiteson, P. Stone, K. O. Stanley, R. Miikkulainen, and
N. Kohl. Automatic feature selection in neuroevolution. In
GECCO ’05: Proceedings of the 2005 conference on Genetic and evolutionary computation, pages 1225–1232, New
York, NY, USA, 2005. ACM.
Y. Wu, M. Giger, K. Doi, C. Vyborny, R. Schmidt, and
C. Metz. Artificial neural networks in mammography: Application to decision making in the diagnosis of breast cancer. Radiology, 187(1):81–87, 1993.
X. Yao and Y. Liu. Epnet for chaotic time-series prediction.
Simulated Evolution and Learning, 1285:146–156, 1997.

275

