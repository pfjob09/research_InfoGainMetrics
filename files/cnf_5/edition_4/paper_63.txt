A Novel Approach for Change Detection in Remote Sensing Image Based on
Saliency Map
Minghui Tian, Shouhong Wan, Lihua Yue
Department of Computer Science and Technology,
University of Science and Technology of China, Anhui, Hefei 230027, P.R. China
{ mhtian@mail.ustc.edu.cn, wansh@ustc.edu.cn, llyue@ustc.edu.cn }
Abstract
Detecting change of remote sensing images is very
important for some applications such as tracking of
moving objects and motion estimation. Traditional
work on change detection has largely been based on
segmentation approaches of a single feature. It
excessively depends on the threshold of the single
feature to determine whether the change of spectral
information is caused by the change of object. The
results of traditional change detection approaches can
easily be affected by noise, blur, contrast level and
brightness level. To overcome the deficiency, we
improve the Itti visual saliency model and propose an
effective and robust approach based on saliency map
to detect real changed regions between two remote
sensing images of a given scene acquired at different
times. The results of the experiments indicate that our
approach is very robust to noise, contrast level and
brightness level.
Keywords--- Change detection, Remote sensing
image, Saliency map, Visual saliency model.

1. Introduction
Change detection in remote sensing images is the
most important research area of the remote sensing
technology and application [1]. It finds important
applications within different contexts, ranging from
video surveillance to video coding, tracking of moving
objects, and motion estimation [2]. Usually change
detection in remote sensing involves the analysis of
two registered, aerial or satellite multi-spectral images
from the same geographical area obtained at two
different times. Such an analysis aims at identifying
changes that have occurred in the same geographical
area between the two times considered. There are lots
of change detection methods, which can be divided
into two categories [3], [16], [17]: the supervised

Computer Graphics, Imaging and Visualisation (CGIV 2007)
0-7695-2928-3/07 $25.00 © 2007

approach and the unsupervised approach. The former is
based on supervised classification methods, which
require a learning set with multi-temporal ground truth
while the latter perform change detection without
relying on any additional information. As the
generation of a learning set is usually a difficult and
expensive task, the use of unsupervised methods is of
great interest in many applications in which a learning
set is not available.
In remote sensing images not only the object change
can result in the change the spectral information, the
change of season, sun angle, sensor attitude and
atmosphere condition can also cause the change of
spectral information. And there are always noise and
blur in remote sensing images. A series of remote
sensing images may have different contrast level or
brightness level even if they are the same scene.
Though a great deal of effort has been expended on
change detection in remote sensing images, traditional
work on unsupervised change detection has largely
been based on statistical segment approaches of a
single feature [1], [4], [5], [6]. It excessively depends
on the critical threshold of the single feature to
determine whether the change of spectral information
is caused by the change of object [15]. And usually
setting an appropriate threshold automatically is very
difficult. The deficiency of statistical segment
detection approaches is that the detection result can
easily be affected by noise, blur, contrast level and
intensity level [20]. So finding an effective and robust
approach for change detection in remote sensing
images is necessary and urgent.
In this paper, we introduce a visual saliency model
for change detection and propose a novel approach to
detect real changed regions in two remote sensing
image of a given scene acquired at different times. Our
visual saliency model proposed in this paper is based
on a bottom-up visual saliency model which was
proposed by Itti in 1998 [7]. Comparing with
traditional threshold segmentation method based on

statistic, our approach does not need to obtain the
changed regions by computing any optimal threshold
complexly. The detection result of our approach only
depends on the final saliency map. Our approach
represents good in low-contrast experiments, noise
experiments and blurs experiments.
The rest of the paper is organized as the follows. In
the next section, the bottom-up visual saliency model
which was proposed by Itti in 1998 is introduced. In
section 3 the change detection algorithm based on Itti
model is presented. Extraction of multi-features,
computation of the saliency map for each diff-image
and multi-features saliency maps combination are
described in detail. Section 4 presents experimental
results for our detection approach. Conclusions are
drawn in Section 5.

suitable to introduce the model and improve it to detect
change in remote sensing images.

2. Visual Saliency Model

Figure 2 Our Visual Saliency Model

Figure 1 Itti Visual Saliency Model
The visual saliency model used in this paper is
based on the Itti visual saliency model which is part of
Itti visual attention model [7]. Itti visual attention
model is used for rapid scene analysis and visual
salient region search. It builds up a second
biologically-plausible architecture to explain human
visual attention [8]. In Itti model, multi-scale features
are combined into a single topographical saliency map.
And the purpose of the saliency map is to represent the
local conspicuity at every location in the visual field by
a scalar quantity and to guide the selection of attended
locations based on the spatial distribution of saliency
[7]. Different spatial locations compete for saliency
within each map, such that only locations which
locally stand out from their surround can persist. A
combination of the feature maps provides bottom-up
input to the saliency map, modeled as a dynamical
neural network. The experiments prove that Itti model
is very robust to noise and blur [7], [9], [10]. So it is

Computer Graphics, Imaging and Visualisation (CGIV 2007)
0-7695-2928-3/07 $25.00 © 2007

For low computational complexity, all feature maps
are computed and combined in the same scale in our
visual saliency model. Because most remote sensing
images are grayscale images, we choose texture [12]
instead of colors as a feature to describe the input
image. And a global saliency measurement is proposed
instead of center-surround differences. This global
saliency measurement is simpler than the computation
of center-surround differences. It describes how
different every location of the input image is from the
average saliency value in this image. Comparing with
Itti saliency model, our model is more suitable for our
change detection model. As Itti model, our saliency
model also represents a complete account of bottom-up
saliency and provides a parallel method for saliency
map computation [7].

3. Detection Algorithm
In this paper, we focus on one of the most widely
used types of unsupervised change-detection
techniques, which are based on the so-called
“difference image” [17], [18]. Comparing with
traditional approaches, our approach is an automatic
and unsupervised approach in which multi-features are
extracted, analyzed and fused into a single saliency
map. And it does not need any threshold to determine
whether the change of spectral information is caused
by the change of object. It is believed that the salient

regions in the final saliency map of the diff-image are
just the real changed regions which we want to detect.
Our experiments will prove this later.

(1)

g (θ , x, y) = K exp(−πσ 2 ( x2 + y2 )) ⋅
2
(exp( j 2πσ 2 ( x cosθ + y sinθ )) − exp( − σ ))
2

Where K is a constant value which scales the
magnitude of the Gaussian envelop. σ is another
constant value which scales the two axis of the
Gaussian envelop. θ is the rotation angle of the
Gaussian envelop which describes the orientation of
the Gabor wavelet filter. And the exact formula of the
orientation map is:

Oθ ( x, y ) = L( x, y ) ⊗ g (θ , x, y )

θ = 0 , 45 ,90 ,135
D

D

D

(2)

D

Where ⊗ means convolving here. We use discrete
moment transform (DMT) [12] to describe the texture
feature of a remote sensing image. If the size of the
kernel is 2k + 1 , the exact formula of DMT is as
follows:

T p , q ( x, y ) =

r =k

s=k

∑ ∑ L( x − r , y − s ) ⋅ r

p

⋅ s q (3)

r =− k s =− k

1,0

0,1

1,1

Actually, we only compute T , T and T to
describe the texture feature. Now, we mark each
feature map given above with a unified token Fij ( F11
which
Figure 3 Our Detect Model
Based on our saliency model, the detection is
divided into three stages as Figure 3. The first stage is
feature extraction. In this stage, for two remote sensing
images of a given scene acquired at different times,
diff-images of multi-features (including intensity,
orientation and texture) are generated. The second
stage is saliency maps generation at which the saliency
map is computed for each diff-image. The third stage is
saliency maps combination at which saliency maps of
multi-features are combined into a single topographical
saliency map. In this way, for two remote sensing
images of a given scene acquired at different times, a
series of changed regions between them are detected
by the final saliency map.

3.1. Feature Extraction
In early vision system, we choose intensity,
orientation and texture as features to describe a remote
sensing image. For a remote sensing image, we stretch
the gray value of each pixel of the input image as
intensity feature map L . Then we use 2D Gabor
wavelet Filter [11] to get the orientation feature maps.
The exact formula of the Gabor function which is used
in this paper is as follows:

Computer Graphics, Imaging and Visualisation (CGIV 2007)
0-7695-2928-3/07 $25.00 © 2007

denotes

intensity
feature
map,
F2 j ( j = 1, 2,3, 4) which denote four orientation

feature maps and F3 j ( j = 1, 2,3) which denote three
texture feature maps). We assume the two input remote
sensing images of a given scene acquired at different
times as I1 & I 2 . So the diff-image of each feature map
can be computed as follows:

DFij ( x, y ) = Fij1 ( x, y ) − Fij2 ( x, y )

(4)

3.2. Saliency maps Generation
To increase the difference between salient regions
and non-salient regions, we propose the global saliency
measurement to improve the saliency model of Itti and
compute the saliency map of each diff-image
iteratively. In our global saliency measurement, the
saliency map of each diff-image can be computed as
follows:

DSij0 ( x, y ) = DFij ( x, y )
 height width

DSijl +1( x, y) = 

∑ ∑
v=1


 u =1

(5)


DSijl ( x, y) − DSijl (u, v)  (6)

/ ( width ⋅ height )




Where width and height are the width and the height
l

of DSij , l is the times of iteration.

3.3. Saliency maps Combination
For each feature, we regularize those saliency maps
of the diff-images by the normalization operator N (.)
[7], [13], [14] and combine them into one saliency map.
So all feature maps are combined into three saliency
maps DSi (i = 1, 2, 3) which denote three features
[19]. Then the three saliency maps are still normalized
by the normalization operator N (.) and combined

Figure 4 (a) Image I1&I2

into the final saliency map DS .

1 FNumi
∑ N ( DSij )( x, y) (7)
FNumi j =1
1 CNum
DS ( x, y ) =
∑ wi ⋅ N ( DSi )( x, y) (8)
CNum i =1
DSi ( x, y ) =

CNum

∑ w = CNum
i

( wi ≥ 0, i = 1, 2,..., CNum)

i =1

Where FNumi is the number of the saliency maps

Figure 4 (b) Our result & Segmentation result

of the feature Fi , CNum is the number of feature
categories and wi is the weight of the feature Fi .

4. Experiments and Analysis
Our experiments are performed on a PC with AMD
Athlon™ XP 2600+ (1.91GHz) processor and 1G
memory. The operating system is Microsoft Windows
XP Professional Service Pack 2 and the software
development environment is Matlab 7.0.4.
In our experiments, we simulate the real noise, blur,
different brightness level and contrast level
environments in which two remote sensing images of a
given scene may be acquired at different times. Then
we compare our approach with a traditional approach
which is based on segmentation of a single feature.
And the segmentation approach which we choose here
is the minimal-error threshold segmentation based on
intensity histogram match [6]. From the results which
Figure 4 & 5 show, it is clear that our approach is more
robust to noise, brightness level and contrast level than
the segmentation approach. Because of multi-features
saliency maps fusion, our approach can hardly be
affected by the change of one single feature.

Computer Graphics, Imaging and Visualisation (CGIV 2007)
0-7695-2928-3/07 $25.00 © 2007

Figure 5 (a) Image I1&I2

Figure 5 (b) Our result & Segmentation result
Two hundred different experiments of noise, blur,
brightness level and contrast level have been
performed. Most remote sensing images used in our
experiments are Quickbird sensor images, the rest are
SPOT-5 sensor images. And the results of all
experiments indicate that our approach is very robust
to noise, brightness level and contrast level. Table 1 is
the statistical results of our approach and the
segmentation approach in two hundred different
experiments. The data of Table 1 indicates that our

approach is superior to the threshold segmentation
approach. Comparing with the segmentation approach,
both the false alarms ratio and the missed alarms ratio
are reduced. And the correct ratio of our approach can
be increased along with the increase of iteration times.
Table 1 Statistical comparison of our
approach and the segmentation approach
Correct
ratio

False
alarms
ratio

Missed
alarms
ratio

Threshold
Segmentation

80%

20%

7%

Our Approach

95%

5%

5%

Approach

5. Conclusions
We propose a novel approach for change detection
in remote sensing images in this paper. In our
approach, multi-features are extracted, analyzed, and
fused into a single saliency map. The results of our
experiments indicate that our approach is very effective
and robust for change detection in remote sensing
images. And visual saliency model can be used to
detect changes in remote sensing images. For future
work, we plan to experiment with multi-scale feature
maps fusion in order to improve the robustness of our
approach. We also plan to recognize the real changed
objects and find the relationship between the changed
regions and their surroundings.

image segmentation,” IEEE Trans Image Processing, vol. 6,
pp. 1364–1375, Oct. 1997.
[6] L. Bruzzone, D. F. Prieto, “Automatic Analysis of the
Difference Image for Unsupervised Change Detection”,
IEEE Trans. on Geoscience and Remote Sensing, 2000,
38(3):1171-1182.
[7] L. Itti, C. Koch, E. Niebur, “A model of saliency-based
visual attention for rapid scene analysis”, IEEE Trans. on
Pattern Analysis and Machine Intelligence, 1998,
20(11):1254-1259.
[8] A.M. Treisman and G. Gelade, “A Feature-Integration
Theory of Attention”, Cognitive Psychology, vol. 12, no. 1,
pp.97-136, Jan, 1980.
[9] L. Itti, “Models of Bottom-Up and Top-Down Visual
Attention”, California Institute of Technology, PhD Thesis,
2000.
[10] L. Itti, C. Koch, “Computational modeling of visual
attention”, Nature Reviews Neuroscience, 2001, 2(3):194230.
[11] Tai Sing Lee, “Image Representation Using 2D Gabor
Wavelets”, IEEE Trans. on Pattern Analysis and Machine
Intelligence, Vol. 18, No. 10, October 1996.
[12] VD. Gesu, C. Valent, L. Strinati, “Local operators to
detect regions of interest”, Pattern Recognition Letter, 1997,
18(11-13):1077-1081.

6. References

[13] L. Itti, C. Koch, “A comparison of feature combination
strategies for saliency-based visual attention systems”,
Conference on Human Vision and Electronic Imaging IV.
SPIE, Vol. 3644, 1999, pp. 373-382.

[1] Ma Jian-wen, Tian Guo-liang, “Review of development
of remote sensing change detection technology”, Advance in
Earth Sciences, 2004, Vol.19 (2), 192-196.

[14] L. Itti, C. Koch, “Feature combination strategies for
saliency-based visual attention systems”, Journal of
Electronic Imaging, 2001, 10(1):161-169.

[2] Y. Bazi, L. Bruzzone, F. Melgani, “An unsupervised
approach based on the generalized Gaussian model to
automatic change detection in multi-temporal SAR images,”
IEEE Transaction on Geo-science and Remote Sensing,
2005, in press.

[15] ChenYang, Chen Ying, Lin Yi, “Object-oriented
classification of remote sensing data for change detection”
Proc. of SPIE, Vol. 6419, 64191J, 2006.

[3] L. Bruzzone and S. B. Serpico, “An iterative technique
for the detection of land-cover transitions in multi-temporal
remote-sensing images”, IEEE Trans. Geosci. Remote
Sensing, vol. 35, pp. 858–867, July 1997.
[4] K. R. Merril and L. Jiajun, “A comparison of four
algorithms for change detection in an urban environment,”
Remote Sens. Environ, vol. 63, pp. 95–100, 1998.
[5] Y. Delignon, A. Marzouki, and W. Pieczynski,
“Estimation of generalized mixture and its application in

Computer Graphics, Imaging and Visualisation (CGIV 2007)
0-7695-2928-3/07 $25.00 © 2007

[16] Radke R.J., Andra S., Al-Kofani O. and Roysan B,
“Image change detection algorithms: A systematic survey”,
IEEE Trans. Image Processing, 14 (3):291-307, 2005.
[17] A. Singh, “Digital change detection techniques using
remotely-sensed data”, Int. J. Remote Sensing, vol. 10, no. 6,
pp. 989–1003, 1989.

[18] T. Fung, “An assessment of TM imagery for land-cover
change detection”, IEEE Trans. Geosci. Remote Sensing, vol.
28, no. 12, pp. 681–684.
[19] P. Zhang, RS. Wang, “Detecting salient regions based
on location shift and extent trace”, Journal of Software, 2004,
15(6):891-898.
[20] X. Dai and S. Khorram, “The effects of image
misregistration on the accuracy of remotely sensed change
detection,” IEEE Trans. Geosci Remote Sensing, vol. 36, pp.
1566–1577, Sept. 1998.

Computer Graphics, Imaging and Visualisation (CGIV 2007)
0-7695-2928-3/07 $25.00 © 2007

