Profile Based Information Retrieval from Printed Document Images
S.Abirami, D.Manjula
Department of Computer Science & Engineering
College of Engineering, Anna University,
Chennai, India
{abirami_s@yahoo.com, manju@annauniv.edu}
Abstract
This paper performs a profile based Information
Retrieval from printed document image collections.
Keywords are valuable indexing tools and if they can be
identified at the image level, extensive computation
during recognition will be avoided. Printed documents
can be scanned to produce document images. Instead of
converting entire document images into text equivalent,
word profiles are identified to match the word images in
Bilingual document images.(English and Tamil). During
retrieval, the same profile could be extracted from the
user specified word and can be matched with the word
images in the document. This yields a faster result even
in a quality-degraded document. This kind of
Information Retrieval (Keyword Based Search) can be
adapted in Digital Libraries, which employs digitized
documents instead of text processing. This promotes
efficient search in document images irrespective of the
language.
Keywords--- Document Images, Word Profiles.

1. Introduction
With the rapid development of computer
technology, digital documents have become popular for
storage and transmission, instead of the traditional paper
documents. The most widespread format for these digital
documents is the text in which the characters of the
documents are represented by the machine-readable
codes (e.g. ASCII codes).
Modern Technology has made it possible to produce
process and store and transmit document images
efficiently. In an attempt to move towards paperless
office, large volumes of printed documents are digitized
and stored as images in databases. Optical Character
Recognition deals with the machine recognition of
characters present in an input image obtained using
scanning operation. It refers to the process by which
scanned images are electronically processed and
converted to an editable text. The need for Information

Computer Graphics, Imaging and Visualisation (CGIV 2007)
0-7695-2928-3/07 $25.00 © 2007

Retrieval arises in the context of digitizing Tamil
documents from the ancient and old era to the latest,
which helps in sharing the data through the Internet.
Large digital libraries, such as Digital Library of India
(DLI) [1] are emerging for archiving large collection of
printed and handwritten documents. Document image
indexing and retrieval were studied with limited scope in
literature [2]. Success of these procedures mainly
depends on the performance of the OCRs, which convert
the document images into text. Much of the data in DLI
are in Indian languages. Searching in these document
image collections based on content, is not presently
possible. This is because OCRs are not yet able to
successfully recognize printed texts in Indian languages.
We need an alternate approach to access the content of
these documents [3]. A promising alternate direction is to
search for relevant documents in image space without
any explicit recognition.
This paper is organized as follows: Section 2 explains
the related works done in this area. Our proposed
architecture has been explained in Section 3. Results and
Discussion are dealt in Section 4. Section 5 states the
Conclusion.

2. Related Work
In Recent years, there has been much interest in the
area of Document Image Retrieval [4][5]. DIR is relevant
to Document Image Processing (DIP), but there are some
essential differences between them. In recent years, a
number of attempts have been made by researchers to
avoid the use of character recognition for various
document image retrieval applications. For example,
Chen and Bloomberg [6], [7] described a method for
automatically selecting sentences and key phrases to
create a summary from an imaged document without any
need for recognition of the characters in each word.
Sptiz described character shape codes for duplicate
document detection [8], information retrieval [9], word

3.1 Offline Processing
recognition [10], and document reconstruction [11],
without resorting to character recognition. Yu and Tan
[12], [13] proposed a method for text retrieval from
document images without the use of OCR. In their
method, documents are segmented into character objects,
whose image features are utilized to generate document
vectors. Some approaches have been reported in the past
years for searching keywords in handwritten and printed
[14] documents. In word searching system [15], a
weighted Hausdorff distance is used to measure the
dissimilarity between word images.
Manmatha locates a specific word in handwritten English
documents by matching image features for historical
documents [16, 17]. C.V.Jawahar addressed algorithmic
challenges for effective search in document images [18].
This paper describes the issues associated with the
implementation of a scalable system for Indian language
document images.
Based on the survey, we attempted to search for relevant
documents in image space without any explicit
recognition based on their word profile features, which
could work irrespective of the language.

3. Information Retrieval
A conceptual block diagram of our prototype system is
shown in Figure 1. Our system accepts textual query
from users. The textual query is first converted to an
image by rendering, features are extracted from these
images and then search is carried out for retrieval of
relevant documents. Results of the search are pages from
document image collections containing queried word
sorted based on their relevance to the query.

Figure 1.Information Retrieval Process
As an offline process, profile features of every word get
stored for document image collections. During online
retrieval, features of the query word has been rendered
and compared with the features of existing collections to
produce a match.

Computer Graphics, Imaging and Visualisation (CGIV 2007)
0-7695-2928-3/07 $25.00 © 2007

The input is a gray scale image obtained by scanning the
bilingual newspapers (English and Tamil). The input
document is assumed to contain only text and is thus free
from graphics, figures, maps and tables. Then the
scanned images pass through the following phases.
3.1.1. Preprocessing. As a preprocessing stage, Image
Binarization has been done. Binarization is a technique
by which the gray scale images are converted to binary
images. The most common method is to select a proper
threshold for the image and then convert all the intensity
values above the threshold intensity to one intensity
value representing either “black” or “white” value. All
intensity values below a threshold are converted to one
intensity level and intensities higher than this threshold
are converted to the other chosen intensity.
3.1.2 Segmentation. After pre-processing, the noise free
image is passed to the segmentation phase, where the
image is decomposed into lines and words. The black
pixel distribution in the image identifies the sentences
present in the identified text area using white pixel
distribution in the image (inter sentence distance). The
words can then be identified from the identified
sentences using the white pixel distribution (inter word
distance).
Algorithm for segmentation:
1. Line Segmentation is performed by identifying
the valley points in the horizontal projection
profile taken along the rows of the image.
2. Once the line bounding has been over, with the
help of vertical projection profile, words can be
identified from the lines.
Horizontal and vertical projection is shown below.
H(x) = Σ y0f(x,y)
(1)
Where f(x,y) is the 2D pixel array of the image
V(y) =Σ
Σ x0f(x,y)
(2)
Where f(x,y) is the 2D pixel array of the image
and
Once the word has been identified, then a rectangular
box bound it and its top left and bottom right coordinates
are accounted for processing.
3.1.3 Feature Extraction (Profile Generation). Profiles
of the word provide a coarse way of representing a word
image for matching. Profiles like upper word, lower
word, projection and transition profiles are used here for
word representation. Upper and lower word profiles
capture part of the outlining shape of a word, while
projection and transition profiles capture the distribution
of ink along one of the two dimensions in a word image.
3.1.3.1 Lower/Upper Profile. Upper/lower word profile

features are computed by recording, for each image
column, the distance from the upper/lower boundary of
the word image to the closest “ink” pixel. If an image

column does not contain ink, the feature value is
computed by linear interpolation between the two closest
defined values. Figure 2 and 3 shows the lower and
upper word profiles.

For matching word images we use Dynamic Time
Warping (DTW) that computes a sequence alignment
score for finding the similarity of words. DTW is a
dynamic programming based procedure to align two
sequences of signals and compute a similarity measure.
Let the word images (say their profiles) are represented
as a sequence of vectors F = F1, F2 . . . FM and G = G1,
G2, . . . , GN. The DTW-cost between these two
sequences is D (M, N), which is calculated using
dynamic programming is given by:
D (i, j) = min (D(i − 1, j − 1), D(i, j − 1), D(i − 1, j)) +

Figure 2. Lower Word Profile

(3)

d(i, j)

(4)

Figure 3. Upper Word Profile
3.1.3.2 Transition Profile. This feature records, for every

image column, the number of transitions from the
background to an “ink” pixel (black pixel distribution
determined by thresholding). Figure 4 shows the
Transitition Profile.

Figure 4. Transition Profile

(The cost in aligning the ith element of F with jth
element of G).
Results of the search are pages from document image
collections containing queried word sorted based on their
relevance to the query.

4. Experiments and Results
This system has been implemented using Java Advanced
Imaging. Inputs were obtained from various magazines,
newspapers and other such documents containing
variable font styles and sizes. The training and test
patterns have been taken, consisting of equal number of
Tamil and English words. English words have been
interdispersed in the Tamil text. Here some sample
words of various font styles of both Tamil and English
script have been used for experimentation and promising
results were obtained.
When an input image is supplied to the system, it
undergoes preprocessing which is shown in figure 5.

All the three profiles of a word gets stored in an
intermediary representation for online retrieval.

3.2 Online Processing
As an online process, our system accepts textual query
from users. The textual query is first converted to an
image by word rendering, features are extracted from
these images and then search is carried out for retrieval
of relevant documents.

Figure 5. Preprocessed Image
Segmentation of word is represented in figure 6.

3.2.1 Word Rendering. In Word Rendering process,
textural query word has been received from the user. By
capturing the coordinates of the word, we converted the
word to an image using a tool.
3.2.2 Word Image Matching. All the profiles have been
generated for the word image obtained through rendering
process. This undergoes a matching process with the
profiles generated for the existing document image
collection.

Computer Graphics, Imaging and Visualisation (CGIV 2007)
0-7695-2928-3/07 $25.00 © 2007

Figure 6. Word Segmentation

Figure 7,8 and 9 shows the different profiles of the
query word.

Figure 7. Lower Word Profile

5. Performance Measurements
Quantitative performance of the matching scheme is
computed on sample document image collection of size
more than 3000 words. Around 25 query words are used
for testing. During selection of query words, priority is
given to words with many variants. We computed recall
and precision for the query words. Percentage of relevant
words that are retrieved from the entire collection is
represented as recall; where as, percentage of retrieved
words, which are relevant, is represented as precision. It
is found that a high precision and recall is registered in
our experiment. Table 1 and Figure 12 shows the
precision measures taken for some of the queries.
Table 1. Precision
Query Word

Precision

1
2
3
4
5
6
7
8

84.28
86.38
94.7
94.7
94.7
89.11
87.5
90.33

Figure 8. Upper Word Profile

Figure 9. Transition Profile
figure 10 shows the retrieved images corresponding
to the query word.

Precision
93
92
91
PPrecision

90
89
1

2

3

4

5

6

7

8

Figure 12. Precision Graph
Figure 10. Retrieved Image
Table 2 and Figure 13 shows the recall measures drawn
for some of the queries.
Table 2. Recall

Figure 11. Retrieved Image

Computer Graphics, Imaging and Visualisation (CGIV 2007)
0-7695-2928-3/07 $25.00 © 2007

Query Word

Recall

1
2
3
4
5
6
7
8

81
81
92
78
100
84
78
75

[10] A.L. Spitz, “Shape-Based Word Recognition,” Int’l J.
Document Analysis and Recognition, vol. 1, no. 4, pp. 178190, 1999.

Recall
120
100

[11] A.L. Spitz, “Progress in Document Reconstruction,” Proc.
16th Int’l Conf. Pattern Recognition, vol. 1, pp. 464-467, 2002.

80
60
40
20
0
1

2

3

4

5

6

7

8

Figure 13. Recall Graph

6. Conclusion
In this paper, we have proposed a search system for
retrieval of relevant documents from large collection of
document images. This method of search will be
important in using large digitized manuscript data sets in
Indian languages. We have focused on computing
information retrieval measures from word images
without explicitly recognizing these images. Preliminary
experiments show that the results are promising. We are
currently working on a comprehensive test on large
collection of document images.

[12] Z. Yu and C.L. Tan, “Image-Based Document Vectors
for Text Retrieval,” Proc. 15th Int’l Conf. Pattern Recognition,
vol. 4, pp. 393- 396, 2000.
[13] C.L. Tan, W. Huang, Z. Yu, and Y. Xu, “Imaged
Document Text Retrieval without OCR,” IEEE Trans. Pattern
Analysis and Machine Intelligence, vol. 24, no. 6, pp. 838-844,
June 2002.
[14] T. Syeda-Mahmood, “Indexing of Handwritten Document
Images,” Proc. Workshop Document Image Analysis, pp. 6673, 1997.

[15] Y. Lu, C.L. Tan, W. Huang, and L. Fan, “An
Approach to Word Image Matching Based on Weighted
Hausdorff Distance,” Proc. Sixth Int’l Conf. Document
Analysis and Recognition, pp. 921-925, 2001.
[16] Rath, T., Manmatha, R.: Features for Word Spotting in
Historical Manuscripts. In: Proc. of the Seventh International
Conference on Document Analysis and Recognition
(ICDAR). (2003) 218–222

References
[1] . Digital Library of India. (at: http://www.dli.gov.in)
[2]. Doermann, D.: The Indexing and Retrieval of Document
Images: A Survey. ComputerVision and Image Understanding
(CVIU) 70 (1998) 287–298
[3]. Chaudhury, S., Sethi, G., Vyas, A., Harit, G.: Devising
Interactive Access Techniques for Indian Language Document
Images. In: Proc. of the Seventh International Conference on
Document Analysis and Recognition (ICDAR). (2003)
885–889
[4] D. Doermann, “The Indexing and Retrieval of Document
Images: A Survey,” Computer Vision and Image
Understanding, vol. 70, no. 3, pp. 287-298, 1998.
[5]
M. Mitra and B.B. Chaudhuri, “Information Retrieval
from Documents: A Survey,” Information Retrieval, vol. 2,
nos. 2/3, pp. 141-163, 2000.
[6] F.R. Chen and D.S. Bloomberg, “Summarization of
Imaged Documents without OCR,” Computer Vision and
Image Understanding, vol. 70, no. 3, pp. 307-319, 1998.
[7] D.S. Bloomberg and F.R. Chen, “Document Image
Summarization without OCR,” Proc. Int’l Conf. Image
Processing, vol. 2, pp. 229-232, 1996.

[8] A.L. Spitz, “Duplicate Document Detection,” Proc.
SPIE, Document Recognition IV, vol. 3027, pp. 88-94,
1997.
[9] A.F. Smeaton and A.L. Spitz, “Using Character Shape
Coding for Information Retrieval,” Proc. Fourth Int’l Conf.
Document Analysis and Recognition, pp. 974-978, 1997.

Computer Graphics, Imaging and Visualisation (CGIV 2007)
0-7695-2928-3/07 $25.00 © 2007

[17] 5. Rath, T., Manmatha, R.: Word Image Matching Using
Dynamic Time Warping. Proceedings of the Conference on
Computer Vision and Pattern Recognition (CVPR) 2 (2003)
521–527
[18] C. V. Jawahar, Million Meshesha, A. Balasubramanian:
Searching in Document Images. Proc. of the 4th Indian
Conference on Computer Vision, Graphics and Image
Processing (ICVGIP) (2004) 622–627

