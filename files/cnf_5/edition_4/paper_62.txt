Non Rigid Object Tracking in Aerial Videos by Combined Snake and
Optical flow Technique
E.Jayabalan 1, Dr.A.Krishnan 2, R.Pugazendi 3
1
Faculty of Computer Science,KSR College of Arts and Science,Tiruchengode,India
2
Dean, KSR College of Engineering, Tiruchengode,Tamilnadu, India
3
Faculty of Computer Science, KSR College of Arts and Science, Tiruchengode, India
ej_ksrcas@rediffmail.com,ejksrcas@redifffmail.com,pugazendi_r@rediffmail.com
Abstract
Tracking of moving objects in video streams with
considering different dynamic backgrounds is a
challenging problem in a real time dynamic
environment. The proposed approach uses an
observation model based on optical flow information
used to know the displacement of the objects present
in the scene. After finding the moving regions in the
initial frame, we are applying active contour model
(ACM) to track the moving objects in the further
frames dynamically. These models have been used as
a natural means of incorporating flow information
into the tracking.
The formulation of the Active Contour Model by
incorporating an additional force driven optical flow
field improves the tracking speed. This algorithm
efficiently works to track for low contrast videos like
Aerial videos.

1. Introduction
Determining the relative motion between the
objects is a major problem in the Computer Vision.
Detecting the motion of the objects is used to explicit
meaningful descriptions from the images for
recognizing, manipulating and understanding about
the Objects. One of the difficulty in image processing
is that the manages suffer an information loss due to
the projection from the three dimensional world to
the two dimensional retina.
Object motion provides a cue for image
understanding, such as intensity, color, texture etc. A
motion image sequence may actually be easier to
interpret than a static image, since the effects of
motion can assist in disambiguation.
As relative motion occurs, the image array
perceived by a viewer is never the same from one
moment to the next. The array changes continuously
over time and forms an apparent flow field called
optical flow. The flow assigns to every point on the

Computer Graphics, Imaging and Visualisation (CGIV 2007)
0-7695-2928-3/07 $25.00 © 2007

visual field a two dimensional “retinal velocity” at
which it appears to be moving.
This work focuses on determination of optical flow
[4] from set of frames in a video. Such that we can
able to know the motion and its positions of a object.
We extended the tracking for further frames by the
formulation of Active Contour Models(ACM).Our
work solves the One of the well known problems of
active contours as Initialization of the contour over
the region of interest. This initialization is achieved
by using the optical flow method.
There are two general types of active contour
models in the literature today: parametric active
contours [1] and geometric active contours [1]. In
this paper, we focus on parametric active contours
called Snakes, which synthesize parametric curves
within an image domain that can move under the
influence of internal forces within the curve itself and
external forces derived from the image data. The total
energy of snake consists of internal and external
forces are defined so that the snake will conform to
an object boundary or other desired features within an
image. By adding the motion information in further
frames we were easily propagate the snake to the
further frames without initializing in each frame.
There are two key difficulties [2] with active
contour algorithms. First, the initial contour is close
to the true boundary or else it will likely converge to
the wrong result. The second problem is that active
contours have difficulties progressing into concave
boundary regions. To handle these two limitations,
we present a new class of external forces for active
contour models mixed with optical flow forces. These
fields, which we call gradient vector flow (GVF)
fields, are dense vector fields derived from images by
minimizing energy functional in a variation
framework. The minimization is achieved by solving
a pair of decoupled linear partial differential
equations which diffuses the gradient vectors of a
gray-level or binary edge map computed from the
image. The active contour or snake that uses the GVF

field as its external force so this snake is referred as
GVF snake. Particular advantages of the GVF snake
over a traditional snake are its insensitivity to
initialization and ability to move into concave
boundary regions.
The combined approach works for tracking in both
cases of uniform and non uniform motion. In case of
camera motion, specifies stabilization algorithm [6]
for motion compensation. Proposed Hybrid method
works well for tracking in case of camera motion.
This hybrid approach for tracking is used in
number of real time applications[3] like Surveillance
system, Monitoring Systems and Navigation
Systems, Human motion modeling, Tracking of non
rigid sequences like human faces ,flower garden
,Clouds etc. The rest of the paper is organized as
follows. Section 2 presents the overview of the
proposed scheme. Section 3 introduces Object
motion using Optical flow approach. Section 4 & 5
details Tracking based on GVF Snake forces.
Section 6 & 7 describes the experimental results and
Section 8 concludes the paper.

2. Overview of The Proposed Scheme
In the proposed approach we extended the
formulation of active contour model using
information about the optical flow to make the
contour in less number of iterations. With out user
intervention, by using optical flow automatically
initializes a contour in the first frame and then use the
snake propagation method (Traditional Snakes/GVF
Snakes) to find the final contour, thus detecting the
object of interest in the first frame. The initializations
of the contour for frame i+1 is done by using the final
contour obtained from frame i by using motion
prediction. Thus we can achieve fast real time object
tracking using this method.
As a preprocessing stage, the frame on which the
snake is to be computed is taken and is converted into
a gray-level or binary-valued representation. Then
calculate the edge map by using canny edge detector.
Then initialize the active contour to the region of
interest (Object to be tracked) .This edge map will be
used for traditional snakes. But in case of GVF
snakes, the edge map is normalized to have all edge
intensities fall between 0 and 1. This normalized edge
map is input into the GVF solver. This will produce
the GVF field of the edge map. The active contours
can be formed by following the direction of the
gradient field vectors over a certain number of
iterations until a statistical equilibrium is reached.

Computer Graphics, Imaging and Visualisation (CGIV 2007)
0-7695-2928-3/07 $25.00 © 2007

3. Object Motion Using Optical Flow
Approach
Motions of each object regions are
estimated by using either optical flow
estimation or by its change detection. The object
motion between frames is chosen by using the optical
flow method because of its less complex procedure,
even though it provides dense estimation. The optical
flow information enables us to know the
displacement of objects present in the scene, it cannot
be used directly to displace an object model since
flow calculation techniques lack the necessary
precision. In view of the fact that probabilistic
tracking algorithms [5] enable imprecise or
incomplete information to be handled naturally, these
models have been used as a natural means of
incorporating flow information into the tracking.
Optical flow method [4] is well established method
for calculating the velocity field (u(x,y), v(x,y)) of the
apparent 2D motion of pixels in an image, by
examining the spatial and temporal changes in
intensity values. Classical optical flow is based on
two main constraints. The first constraint states that
the brightness of any object point is constant over
time. This can be written as: i(x+dx, y+dy, t+dt) =
i(x,y,t).using taylor series expansion and neglecting
higher order term gives the optical flow constraint
equation:
IXVX+IYVY+IT= 0

(1)

Where Ix, Iy and It are the spatial-temporal
derivatives of intensities of an image that can used to
compute the flow vectors for each point in the image
sequences.
The main advantage by using Optical flow
estimation is to calculate the motion vectors (Vx, Vy)
easily at each pixel location by solving the Optical
flow equation (1).But this equation is under
constrained. This equation can be solved by imposing
additional constraints, for example assuming the
neighboring pixels have the same motion. This can
be solved by using Lucas & Kanade Technique, in
which we are assuming neighboring pixels have the
same motion. We used a 5 × 5 window, and use least
squares to solve for the motion vectors (Vx, Vy)

∑w(x, y)I I V +∑w(x, y)I I V =−∑w(x, y)I I
x x x

x, y

x y

x, y

y

x t

x, y

(2)

∑w(x, y)IIV +∑w(x, y)IIV =−∑w(x, y)II
xy x

x,y

yy y

x,y

Where the summation ( ∑

yt

x,y

w (x, y)

(3)

) is taken over a

5x5 pixel Gaussian window with σ of 1 pixel.
Summing over a Gaussian window gives more
weight to the center pixels and less to those at the
peripheral, and the result is a weighted least squares
solution.
The validity of the OFE rests upon two assumptions:
Constant intensity along motion trajectory and
‘small’ motion(where ‘small’ in practice means ~1
pixel/frame). The small motion assumption is often
violated — for example, in general video sequences
we used, even the slower moving objects as
persons/cars had velocities of 3-4 pixels/frame. This
leads us to a hierarchical approach.
In a hierarchical framework, we first generate a
Gaussian pyramid of images by iteratively filtering
and sub sampling by a factor of 2.
At each level of pyramid, starting from the highest
resolution,
• Project and interpolate estimates from
previous level
• Pre-warp the neighborhood window
according to the motion estimates
computed according to the motion
estimates computed from the previous level
before performing the least squares.
• The least squares solution is added to the
initial estimates to give a refined estimate
for that level.
In this fashion as we descend the pyramid, our
motion vector estimates become more and more
accurate.
At each level, the algorithm only computes the optic
flow for rectangular areas where the motions exceed
a certain threshold. The threshold was set to 2
pixels/frame at the highest resolution level,
corresponding to a threshold 1 and 0.5 pixels/frame at
levels 1 and 2 respectively. This threshold value is
not sensitive as long as the person/ vehicle motions
are significantly larger than the global motion caused
by the camera.
To cluster the moving regions which are having
motion in the starting frame is detected by k-means
clustering
with
a
feature
vector
x = [vx, vy , i, j , R, G , B ]' .Where vx,vy are available
from least square solution. Where i, j are the pixel
locations to add spatial information to the vector and
R, G, B are the intensities of the color components at
that point.

Computer Graphics, Imaging and Visualisation (CGIV 2007)
0-7695-2928-3/07 $25.00 © 2007

4. Contour Propagation by snakes
In order to achieve the tracking for the moving
objects, Automatic initialization is achieved by
optical flow method and the deformation is achieved
by both snake and optical forces. In our approach,
Firstly the snake moves towards the features of
interest of an image and Secondly, it maintains
certain degree of smoothness in the contour. To
achieve these tasks we combine both snake forces
and flow forces. Using these forces, the equation for
updating a single snake node xi(t) can be written:
xi(t)=xi(t+1)+w1Fielastic(t)+w2Fibending(t)+w3Fiexternal(t)+
(4)
w4Fiflow(t)
Where w1,w2,w3 and w4 are weighing factors.
Fielastic(t) resists elasticity of the snake- δ2x / δi2
Fibending(t) resists smoothness of the snake- δ4x / δi4
Fiexternal(t) makes the snake moves towards the region
of interest

Eimage ( x , y ) = − | ∇ (Gσ ( x , y ) * I ( x , y )) |2

(5)

flow

Fi (t) is a type of external force used to
move towards the concave regions and this
force is directly proportional to (u (xi(t1),yi(t-1)), v(xi(t-1),yi(t-1))).
5. Tracking the moving object

Snakes are being extensively used to track
objects in real time. The initialization of the
contour in the first frame is achieved by
using optical flow method or by the user and
we use our Active Contour Model method to
find the final contour of the object thus
detecting the object of interest in the first
frame. The initialization of the contour for
frames i+1 is done by using the final contour
obtained from frame i. Thus we can achieve
fast real time object tracking using this
method.
6. Experimental Results
Our approach is implemented in both MATLAB 6.5
and JDK 1.5 with JMF 2.0 and JAI 1.0.1 .Our
implementation has two phases in MATLAB. The
first phase is detection of moving region by using
optical flow method and Second phase is to track the

path by using both Snake propagation and Optical
flow energy function.
In java we tested same method but we given the
facility to the user to select the object to be tracked.
Then our contour model is easily tracked by using the
parameters w1=0.8 ,w2=0.2 ,w3=1 and w4 = 0 or
0.01.
We tested the videos with both persons and cars to
track by using active contour models .The Fig.1
shows the first frame of the video. Figure .2 shows
the user window where user can initialize for ROI to
be tracked.
Figure (3-.5) show the tracking nature of the
boundary of a person.

Figure .2. Initialization to the ROI

Figure 1.The first frame of a video

Figure 3. Tracking boundary in the second frame of a video

Computer Graphics, Imaging and Visualisation (CGIV 2007)
0-7695-2928-3/07 $25.00 © 2007

7. Graphical Representation Of Multiple
Object Tracking In Compressed Domain
Videos
Multiple Obejct Tracking
300
y-coordiante

250
200

obejct1(cy1)

150

object2(cy2)

100
50
0
0

5

10

15

20

Frame number

Figure 6. Analysis for Multiple Object Tracking in normal
conditions
Object tracking with collision

the fourth frame of a video

y-c oordinates

Figure 4. Tracking boundary in

400
350
300
250
200
150
100
50
0

object1(cy1)
Object2(cy2)

0

5

10

15

20

25

Frame number

Figure 7. Analysis for Multiple Object Tracking with

collision

A Interpretation
Figure .6 shows tracking in case of normal
conditions (where the objects are moving from left to
right), y-coordinate of both objects gradually increase
with constant x-coordinate. Where as in Fig. 7 shows
the state of collision where the y-coordinate are
matching from 17th frame onwards with constant xcoordinate.

8. Conclusions

Figure 5. Tracking boundary in the seventh

frame of a video

Computer Graphics, Imaging and Visualisation (CGIV 2007)
0-7695-2928-3/07 $25.00 © 2007

This work describes motion of the object by using
both snake forces and optical flow forces. In active
contour propagation, tracking of a person is simulated
with both the traditional snake and GVF snakes. By
using a new external force model for snakes called
gradient vector flow solves the problem of
convergence to the boundary concavities.

Using optical flow for tracking is having several
advantages. By adding both the forces allows for
flexibility to initialize the snake to detect the regions
from the optical flow. Optical flow estimation is one
of the simplest estimation even though this approach
provides dense estimation.

9. References
[1]

Chenyang Xu and Jerry L.Prince, “Gradient Vector
Flow:A New External Force for Snakes,” IEEE
Proc. Computer Vision and Pattern Recognition
(CVPR’97), 1997.

[2]

Chenyang Xu and Jerry L.Prince, “Snakes ,Shapes
and Gradient Vector Flow,” IEEE Transactions on
Image Processing, Vol.7,No.3,March 1998.

[3]

K Althoff, G Hamarneh, M Beckman Suurküla, T
Gustavsson,“Tracking
Contrast
in
Echocardiography by a Combined Snake and
Optical Flow Technique” ,IEEE Computers in
Cardiology,Vol27,2000

[4]

Zhaoxin Pan and Joseph J. Pfeiffer Jr,“Adaptive
Estimation of Optical Flow from General Object
Motion”, ACM 0-89791-502-X/92/0002/0469 ,1992

[5]

M. Lucena, J.M. Fuertes and N. Perez de la Blanca,
“Using Optical Flow for Tracking”, CIARP 2003,
LNCA 2905, pp 87-94,2003

[6]

Ahraf M.A Ahmad and Sun-Yin Lee, “Detection
and Tracking Moving Objects for Video
Surveillance”,IEEE Proc. Computer Vision and
Pattern Recognition, Jun. 23-25,1999

[7]

Kass M. Witkin A, Terzopoulos D. Sanakes: Active
Contour Models, International Journal of Computer
Vision 1987; I(4):321-331

[8]

Horn, B. and B. Schunck “Determining Optical
Flow”, Artificial Intelligence, vol. 17,pp. 185-203,
August 1981

[9]

R.E. Kalman, “A new approach to linear filtering
and prediction problems”, Transactions of the
ASME – Journal of Basic Engineering, Vol 82, no
Series D, pp.35-45, 1960

[10]

A. Blake and M. Issard, Active Contours, Springer,
1998

[11]

J.L. Barroon, David J. Fleet and S.S. Beauchemin,
“Performance of optical flow techniques”,
International Journal of Computer Vision, vol 12,
no 1, pp.43-77, 1994

Computer Graphics, Imaging and Visualisation (CGIV 2007)
0-7695-2928-3/07 $25.00 © 2007

[12]

Keith
Jack,
Video
Demystified,
Penram
International Publishing (India) Pvt Ltd, 3rd
Edition, 2001

