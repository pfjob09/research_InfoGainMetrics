Image Denoising Through Locally Linear Embedding
Rongjie Shi, I-Fan Shen, Wenbin Chen
Fudan University
{rongjie_shi@yahoo.com.cn, yfshen@fudan.ac.cn, wbchen@fudan.edu.cn}

Abstract
This paper presents a novel scheme for image
denoising. In spite of the sophistication of recent
schemes, most algorithms show outstanding performance
under their assumption, but totally fail in general cases
and produce artifacts or destroy fine structures. Inspired
by recent manifold learning methods, especially the
locally linear embedding (LLE), our method utilizes the
underlying fact that image patches in noisy and
denoised images construct manifolds with similar local
geometry in these two distinct spaces. According to LLE,
we characterize local geometry by measuring how an
image patch represented by a feature vector can be
reconstructed by its nearest neighbors in feature space.
Besides using the training image patches to construct the
embedding, we also propose to overlap the target
denoised image patches to satisfy local compatibility and
smoothness constraints. The experimental results show
that our method is flexible with noise type and achieves
state-of-the-art performance particularly in terms of
preserving the fine structures.

1. Introduction
1.1. Image denoising and previous work
Visual information transmitted in the form of digital
images has been a major method of communication in
our age, but the course of transmission often unavoidably
destroys images with noise. Hence, image denoising is
an important processing task, both as a process itself and
as a component in other processes before received
images can be used in applications. Image denoising is to
generate a visually high quality image from one or more
noisy images and the main character of a promising
image denoising algorithm is that it can remove noise
while preserving the fine structures.
In this section, we will examine most existing image
denoising methods, such as filter approach and wavelet
based approach, and evaluate their performance
respectively. Noise type includes Gaussian noise, salt
and pepper noise, speckle noise, Brownian noise, etc. In
the usual case, selection of image denoising algorithm is
application dependent. Methods from the category of
filtering approach are proved to be the best in dealing
with images corrupted with salt and pepper noise.
Methods from the category of wavelet based approach

Proceedings of the Computer Graphics, Imaging and Vision: New Trends (CGIV’05)
0-7695-2392-7/05 $20.00 © 2005 IEEE

show better results when images are corrupted with
Gaussian noise [1]. In contrast, our method can handle
salt and pepper noise as well as Gaussian noise in a
consistent way.
Besides their being sensitive to noise type, former
image denoising algorithms also have some other
disadvantages. The Gaussian filter method is not able to
preserve edges in an effective manner [2]. Edges, which
are viewed as discontinuities in the image, are largely
removed. The anisotropic filter method can displays the
corners and high frequency features, but can’t preserve
the straight edges because of their low curvature [3]. The
Total Variation method [4, 22, 23] is inclined to make
modification on most structures and details of the image,
and even the straight edges can’t be well preserved. But
the iterated version of Total Variation method [5] show
better results in preserving the straight edges and details.
The neighborhood filter [6] preserves the contours,
texture details, flat objects and contrasted edges well, but
possesses shortcoming in keeping low contrasted edges.
The TIHWT method [7, 21] fails to preserve the edges
and high frequency features. They are erased by TIHWT
because their structures result in large enough
coefficients while somewhat lower than the threshold.
The DCT empirical Wiener filter [8, 20] has little
noticeable structure except some contours. In general,
DCT empirical Wiener filter seems to have a much better
performance than all those local smoothing filters and
other frequency domain filters. Antoni Buades points
out that its results are similar to those of a hard stationary
wavelet thresholding [9]. But smoothly varying regions
in the input noisy image are transformed into piecewise
constant regions in the output when DCT empirical
Wiener filter are used.
The search for effective image denoising algorithms is
really a valid challenge. The non presence of artifacts
and the correct reconstruction of edges, texture and fine
structure are the qualities of the restored images that all
image denoising algorithms are in pursuit of. Among the
former methods, wavelet shrinkage is a promising one
[10, 24]. When decomposing data using the wavelet
transform, this method uses filters that act as averaging
filters, and others that produce details. Some of the
resulting wavelet coefficients correspond to the details in
the image. If the details are small, they might be omitted
without substantially affecting the main features of the
image. The idea of shrinkage is to set high frequency
sub-band coefficients that are less than a particular

threshold to zero. These coefficients are used in an
inverse wavelet transformation to reconstruct the image.
After that, two recently developed discrete wavelet
transforms (DWTs), namely the double-density DWT
[11] and the double-density complex DWT [12], are also
applied to the field of image denoising, which produce
much better results than most of the former ones.
Because of its effectiveness in image denoising, we
compare our method with those based on double-density,
double-density dual-tree real [12], and double-density
dual-tree complex DWTs for noise attenuation in
photographic images.

existing techniques. Td are the original images with no

1.2. Our work

{T pdi }iN 21 , respectively. Here, N 1 and N 2 depend on the

In this paper, our work focuses on developing a
flexible method that, in principle, can be conveniently
utilized to denoise images with arbitrary noise type and
even with heavy noise. Our method contributes more in
proposing a totally novel, more general way of using the
training examples, because our method makes it possible
for multiple training examples to redound simultaneously
to the generation of each image patch in the denoised
image. This contribution is quite meaningful as
generalization over the training examples is possible and
therefore largely reduces the cost of learning. After
comparison, our method outstands in producing less
artifacts and correct reconstruction of edges, texture and
fine structures.

size of the image patch and the degree of overlapping
between adjacent patches.
In an ideal case, each patch sampled from the
denoised image I d should both be related appropriately

1.3. Paper structure
The structure of this paper is as follows. In Section 2,
we formulate the image denoising problem in a much
more general and precise way and then introduce our
method based on the principle of manifold learning. In
Section 3, we address the procedure of how to denoise
the noisy images with our method. In Section 4,
experimental results are presented and some comparisons
are also carried out there. The conclusion remarks are
presented in Section 5.

2. Methodology
2.1. Problem formulation
In consideration of our method, the image denoising
problem can be formulated in the following form. I n
represents the noised image given as input, our goal is to
reconstruct the target denoised image I d with the help
of a training set of one or more noisey images Tn and
corresponding denoised ones Td . The noise type and
degree of Tn should be the same as those of I n , which
can be implemented easily as related parameters that
represent the noise type and degree can be measured with

Proceedings of the Computer Graphics, Imaging and Vision: New Trends (CGIV’05)
0-7695-2392-7/05 $20.00 © 2005 IEEE

noise at all, from which Tn are produced.
Each noised or denoised image is represented by a set
of small overlapping image patches. I n and I d have the
same number of patches, and each noised image in Tn
and the corresponding denoised (original) one in Td also
own the same number of image patches. In this paper, we
denote the sets of image patches corresponding to I n ,

I d , Tn and Td as {I ipn }iN11 , {I ipd }iN11 , {T pni }iN 21 and

to the corresponding patch in the noised image I n and
preserve the inter-patch relationship with its adjacent
ones in I d . The former constraint insures the accuracy
while the latter one determines the local smoothness and
compatibility of I d . In order to satisfy these two
demands mentioned above as much as possible, the
sampling strategy used in our method should possess all
the following properties. Firstly, for each patch sampled
from I d , we should associate it with multiple patch
transformations learned from the training set Td .
Secondly, local relationships between the patches in I n
should be well preserved in I d . Thirdly, neighboring
patches in I d should be constrained through overlapping
to insure local compatibility and smoothness.

2.2. Manifold learning
By “manifold learning”, we mean those methods that
derive information about the local geometry structure of
the manifold at x based mostly on the training examples
around x , where the Euclidean distance or a kernel is
used. Our method is base upon the assumption that
image patches in the noised and denoised images form
manifolds possessing the similar local geometry in these
two distinct spaces. We can insure the validity of the
assumption because consequent representation is jarless
and accordingly be less sensitive to the noise in noised
images than other methods as long as the embedding is
proved to be isometric. In our method, we transform each
image patch into a feature vector, which represents a
corresponding point in feature space. For the sake of
i

i

i

i

concision, I pn , I pd , T pn and T pd are used to represent
both the small image patches and corresponding feature
vectors, and I n , I d , Tn and Td are used to mark the

images as well as the corresponding sets of feature
vectors.
In recent years, there has been a lot of work proposed
on unsupervised manifold learning, such as kernel
Principal Components Analysis (kernel PCA) [13], LLE
[14], Isomap [15], Laplacian Eigenmaps [16], and
Manifold Charting [17]. These methods are all
essentially non-parametric and represent the underlying
manifold on the basis of local neighborhood relationship.
What’s more, all the methods mentioned above
characterize the manifold through an embedding that
associates each training input object with a lowdimensional coordinate vector on the manifold. Our
method of image denoising is just elicited from these
manifold learning methods, especially the Locally Linear
Embedding.

reconstruction of a given point can be found by solving
the optimization task:
N

¦

H (W )

i 1

X i  ¦ Wij X j

neighbors and

¦

j 1

Wij

Step3. Compute embedded coordinates Yi for each

X i . Projections are found by minimizing the embedding
cost function for the fixed weights:
N

2

N

¦ Y  ¦W Y

G (Y )

i

ij

d

stand for a vector either in R or R space, depending
on the context.
The LLE algorithm is described as follows:
Step1. k nearest neighbors are found for each point

X i in R D (i 1,2,..., N ) by using Euclidean distances
to measure similarity. Then the proximity matrix A of
size k u N is built and its i -th column holds indices of
k points which are the nearest neighbors to X i .
Step2. Assign a weight to every pair of neighboring
points. The weights representing contribution to the

Proceedings of the Computer Graphics, Imaging and Vision: New Trends (CGIV’05)
0-7695-2392-7/05 $20.00 © 2005 IEEE

¦

N
i 1 i

Y

(2)

j

j 1

Subject to the following constraints:

The Locally Linear Embedding algorithm has been
recently proposed for the purpose of manifold learning. It
owns at least four attractive properties. Firstly, only two
parameters should be set. Secondly, the optimization
with LLE involves no local minima. Thirdly, it can well
preserve the local geometry of high dimensional data in
the embedded space. Fourthly, it has a single global
coordinate system of the embedded space. All these
strongpoints contribute to its advantages in image
denoising.
The geometric intuitions underlying the LLE
algorithm is very simple. Provided that there exist
N points in a high dimensional space of dimensionality
D , where these N points are assumed to lie on or near
a nonlinear manifold of intrinsic dimensionality
d (commonly d  D ). Suppose we have sampled
sufficient data points from the manifold, each data point
and its nearest k neighbors are assumed to lie on or close
to a locally linear patch of the manifold. The local
geometry of each patch can be described by the
reconstruction weights with which a data point is
reconstructed from its nearest k neighbors.
As an input, LLE takes a matrix X of size D u N
consisting of N columns representing feature vectors.
Its output is a matrix Y of size d u N ( d  D ),
where columns are coordinates of the feature vectors in
the embedded space. Furthermore, the term point will
D

0 , if X i and X j are not
1.

i 1

2.3. Locally linear embedding

(1)

j 1

Subject to constraints: Wij
N

2

N

1
N

¦

N

Y Y T and

i 1 i i

0 , which provide a unique solution. To find

Y , a new matrix M ( I  W ) T ( I  W )
is constructed and its d bottom eigenvectors starting
the matrix

from the second one are computed. These eigenvectors
span rows of Y .

2.4. Neighbor embedding method
Just as what LLE dose, our method measures the local
geometry by how well a feature vector corresponding to
an image patch can be reconstruct by its neighbors in
feature space. After given each image patch in I n , we
first calculate the reconstruction weight vector of its k
nearest neighbors in Tn by minimizing the local
reconstruction error. The denoised embedding therefore
i

N2
1

can be estimated from the training image pairs {T pd }i

by preserving local geometry. As a result, we gain local
compatibility and smoothness between adjacent patches
in I d by overlapping.
The neighbor embedding course of our method can be
described as follows:
i

N

Step1. For each image patch in {I pn }i 11 , we do:
Step1.1 Find a set

S k whose elements are the k

N2
i
pn i 1 for

nearest neighbors in {T }

current patch.

Step1.2 Calculate the reconstruction weights of the
nearest neighbors by minimizing the error of
i

reconstructing I pn .
i

Step1.3 Obtain the denoised embedding I pd by
combining the well chosen denoised patches, which
correspond to the
i

N

k nearest neighbors in {T pni }iN 21 ,

from {T pd }i 21 with the reconstruction weights.

Step2. Construct the desiring denoised image

through making full use of the local compatibility and
smoothness between adjacent patches got in Step1.3.
In Step1.1, Euclidean distance is used to measure the
i

N1
1

difference between patches from {I pn }i

and those

N

i

from {T pn }i 21 . After obtaining the k nearest neighbors
i

N2
1

from {T pn }i

, Step1.2 tries to find the optimizing
N

i

reconstruction weights for each patch from {I pn }i 11 .
This optimization can be achieved by minimizing the
i

local reconstruction error for I pn (i
equation (1), where

1,..., N 1 ) using

X i and X j can be substituted by

I ipn (i 1...N 1 ) and T pnj ( j

1...N 2 ) respectively.

Equation (1) calculates the squared distance between

I

i
pn

and its reconstruction computed by combining its

k nearest neighbors with a certain set of weights,
k

subject to the constraint

¦W

ij

1 . As is known,

j 1

minimizing H (W ) subject to the constraint is just a
problem of solving a least squares under some
constrained conditions. Accordingly, a local Gram
matrix

Gi is introduced for I ipn :
G i ( I ipn 1T  M ) T ( I ipn 1T  M )

(3)

Where 1 stands for a column vector of ones and
M stands for a D u k matrix, whose columns are the

k nearest neighbors of I ipn . Furthermore, we
encapsulate the k weights of the neighbors to form a k dimensional vector marked wi , and then the constrained
least squares problem is rewritten in the following form:

wi

Gi11
1T Gi11

(4)

To avoid the trouble arising from inverting

Gi , we

convert it into a problem of solving the system of linear
k

equation

Gi wi

1 under the constraint of

¦W

ij

1

j 1

(

wi

(Wi1 ,Wi 2 ,..., Wik ) )which can be solved in a

more efficient way. After repeatedly executing Step1.1
and Step1.2 for N 1 times, we obtain the reconstructing
i

k

Id

N

weights for each patch in {I pn }i 11 , all the weights form
a weight matrix marked W .
In Step1.3, we calculate the initial image patch of

I ipd (i 1,..., N 1 ) by :

I ipd

¦W T
ij

j
pd

(5)

j 1

which is derived from equation (2).
In Step2, a simple and efficient strategy is introduced
to enforce the relationship between adjacent image
patches. As most of the pixels in one image patch are
calculated more than once. One straight idea is to
average the sum of the values of the same pixel by the
total times it is computed. But experiments show that
averaging the values of one pixel each time its new value
comes produces more effective result.

3. Experiments
3.1. Choosing features
In our experiment, each image patch is converted into
a feature vector. The strategy for choosing features
should be the same for both noised and denoised images.
In the usual case, Color images are represented in
RGB color space. Based on the fact that people are more
sensitive to luminance changes than color changes, we
use YIQ color space instead of the former one. In YIQ
color space, image data consists of three components:
luminance (Y), hue (I), and saturation (Q). Luminance
represents grayscale information, while the last two
components make up chrominance. Conversion between
YIQ and RGB color space can be implemented easily
through a linear transformation with a fixed matrix. In
our method, Y, I and Q channels are used to define the
features respectively, and they are dealt with separately
and then are composed simply to produce the result.
The strategy for defining a feature vector is to
concatenate the channel values of all the pixels in the
corresponding image patch. Although this scheme is
simple, the experimental result is quite satisfactory.

3.2. Model parameters
Only a quite small training set is required in our
experiment. One possible setting is explored here. We
utilize a separate set of training images. Figure1 shows
the images we used in one experiment. Other setting can
also be developed when some particular circumstance,
such as small training set, occurs.
There are three parameters left to determine for us.
This first one is the size of the image patch. For both the
noised and denoised images, we use 4 u 4 patches. The
second one is the degree of overlapping between
adjacent image patches. Our choice is to overlap them
with one pixel. The last one is the number of nearest
neighbors k for each neighbor embedding. In our
experiment k 8 is a good choice.

4. Experimental results
An illustrative experiment is shown here. We
compare our method with median filtering and three

Proceedings of the Computer Graphics, Imaging and Vision: New Trends (CGIV’05)
0-7695-2392-7/05 $20.00 © 2005 IEEE

newly proposed denoising methods based on two
recently developed discrete wavelet transforms (DWTs),
namely the double-density DWT, the double-density
dual-tree real DWT and the double-density dual-tree
complex DWT.
Figure2 shows the experimental results after applying
different denoising methods to the noisy image shown in
Figure 1 (b). Our method gives the best result in
preserving edges, texture and fine structures. For
example, the head of onion shown in the original image
(figure 1 (a)) produces a clear shadow, but this shadow is
removed by the denoising methods based on DWTs.
Compared to other methods, our method also produces
less artifact effects. Let’s take a close look at the
capsicum and the leaf in the left below corner and we
will find the well preserving of the fine structures and
texture of our method makes a much better recovery of
the noisy image than other methods. It is clear that our
method really outperforms these four former ones.
In another experiment, salt and pepper noise is added.
The denoised results are compared in Figure3.

way in that each reconstructed denoised image patch
depends simultaneously on multiple nearest neighbors
instead of one of the nearest neighbors in the training set,
which is a character directly derived from the manifold
learning method, LLE. This property makes it possible to
generalize over the training examples and produce more
accurate result in preserving fine structures.
In our future work, other effective means will also be
developed to define feature vectors instead of simple
concatenation of the channel values of all pixels in one
patch. Besides, we may go even further by extending our
method with the idea of non-local manifold tangent
learning [18, 19] which is proposed by Yoshua Bengio.
We are sure this extension will benefit us a lot in dealing
with noisy images possessing manifolds with more noise
or higher curvature.

Acknowledgement
This work was supported by NSFC under contract
60473104 and STCSM under contract 045115013.

(a)

(b)

(a)

(b)

(c)

(d)

(c)

(d)

(e)

(f)

Figure1. An example of Gaussian White noise:
(a) the original image; (b) the noised one
(Gaussian white noise of mean 0.2 and variance
0.01 is added); (c) the training image with no
noise; (d) the training image with the same
Gaussian white noise as (b).

5. Conclusions and future work
In this paper, we propose a novel scheme for image
denoising. It is totally different from the former methods.
Our method uses a training set to learn the structure of
the input noisy image and makes a mapping between the
feature space of the noisy images and that of the
denoised ones. The training set is used in a quite general

Proceedings of the Computer Graphics, Imaging and Vision: New Trends (CGIV’05)
0-7695-2392-7/05 $20.00 © 2005 IEEE

Figure2. Denoised results of the noisy image
shown in Figure 1.(b) with different methods: (a)
the original image; (b) median filtering; (c)
double-density DWT; (d) double-density dualtree real DWT; (e) double-density dual-tree
complex DWT; (f) our method.

[6]
[7]

[8]
[9]
(a)

(b)

[10]

[11]

[12]
[13]

(c)

(d)

[14]

[15]

[16]

[17]
(e)

(f)

Figure3. An example of salt and pepper noise
(The original images are shown in Figure1.) (a)
noisy image (salt and pepper noise of density
0.1); (b) the training image with the same noise
as (a); (c) double-density DWT; (d) doubledensity dual-tree real DWT; (e) double-density
dual-tree complex DWT; (f) our method.

[18]

References

[21]

[1]

[2]

[3]

[4]

[5]

A. Chambolle, R. De Vore, N. Lee and B. Lucier,
“Nonlinear wavelet image processing: variational
problems, compression, and noise removal through
wavelet shrinkage”, IEEE Tran. Image Proc., Vol 7, No
3, 1998, pp. 319-333.
M. Lindenbaum, M. Fischer and A.M. Bruckstein, “On
Gabor Contribution To Image Enhancement”, Pattern
Recognition 27, 1994, pp. 1-8.
P. Perona and J. Malik, “Scale space and edge detection
using anisotropic diffusion”, IEEE Trans. Patt. Anal.
Mach. Intell., 1990, pp. 629-630.
L. Rudin and S. Osher, “Total Variation based image
restoration with free local constraints”, Proc. IEEE ICIP.,
Vol 1, 1994, pp. 31-35.
L. Vese and S. Osher, “Modeling textures with total
variation minimization and oscillating patterns in image
processing”, Journal of Scientific Computing, 2003, pp.
553-572.

Proceedings of the Computer Graphics, Imaging and Vision: New Trends (CGIV’05)
0-7695-2392-7/05 $20.00 © 2005 IEEE

[19]

[20]

[22]

[23]

[24]

L.P. Yaroslavsky, “Digital Picture Processing – An
Introduction”, Springer Verlag, 1985.
J. Starck, E. Candès, D. Donoho, “Very high quality
image restoration by combining wavelets and curvelets”,
Wavelet and applications in signal and image processing
IX, Volume 4478, 2001, pp. 9-19.
L. Yaroslavsky, M. Eden, “Fundamentals of Digital
Optics”, Birkhauser, Boston, 1996.
A. Buades, B. Coll, J.M. Morel, “On image denoising
methods”, I’ANNEE, 2004.
T.F. Chan and H.M. Zhou, “Total variation improved
wavelet thresholding in image compression”, Proceeding
of ICIP’2000, Volume 2, 2000, pp. 391-394.
I.W. Selesnick, “The Double Density DWT”, In
Wavelets in Signal and Image Analysis: From Theory to
Practice, Boston, 2001.
I.W. Selesnick, “The Double-Density Dual-Tree DWT”,
In IEEE Transactions on Signal Processing. May 2004.
B. Schölkopf, A. Smola, and K.-R. Müller, “Nonlinear
component analysis as a kernel eigenvalue problem”,
Neural Computation, 1998.
S. Roweis, and L. Saul, “Nonlinear dimensional
reduction by locally linear embedding”, Science, 2000,
pp. 2323-2326.
J. Tenenbaum, V. de Silva, and J. Langford, “A global
geometric framework for nonlinear dimensionality
reduction”, Science, 2000, pp. 2319-2323.
M. Belkin, and P. Niyogi, “Using manifold structure for
partially labeled classification”, In Advances in Neural
Information Processing System 15, MA. MIT Press,
Cambridge, 2003.
M. Brand, “Charting a manifold”, In Advances in Neural
Information Processing System 15, MIT Press, 2003.
Y. Bengio and M. Monperrus, “Non-local Manifold
Tangent Learning” In Advances in Neural Information
Processing Systems 17, MIT Press, 2005.
Y. Bengio and M. Monperrus, “Discovering shared
structure in manifold learning”, In IRIS Machine
Learning Workshop, June 2004.
L. Yaroslavsky, “Local Adaptive Image Restoration and
enhancement with the use of DFT and DCT in a running
window”, In Proceedings, Wavelet applications in signal
and image processing IV, SPIE Proc, 1996, pp. 1-13.
J. Starck, E. Candès, D. Donoho, “The curvelet transform
for image denoising”, In IEEE Transactions on image
processing, 2000, pp. 670-684.
S. Osher, M. Burger, D. Goldfarb, J. Xu and W. Yin,
“Using Geometry and iterated refinement for inverse
problems (1): Total variation based image restoration”,
CAM-Report, 04-13 UCLA, 2004.
S. Osher, A. Sole, and L. A. Vese, “Image decomposition
and restoration using total variation minimization and H-1
norm”, In Multiscale Modeling and Simulation: A SIAM
Interdisciplinary Journal, 2003, pp. 349-370.
R.R. Coifman and A. Sowa, “Combining the calculus of
variations and wavelets for image enhancement”, In
Applied and Computational harmonic analysis, 2000, pp.
1-18.

