Skin-Active shape model for face alignment
Lu Huchuan, Shi Wengang
School of Electronic and Information Engineering, Dalian University of Technology, Dalian
116023, China
lhchuan@dlut.edu.cn , oplm0082@yahoo.com

Abstract
Active shape model is considered as one of the most
useful methods for face alignment. In this paper, we
propose using a skin color likelihood transformation
method, instead of using a gray level, to model the
local profile around each landmark point of Active
shape model. The goal of using this method is to model
the local profile more accurate and to decrease the
influence from different races and lighting conditions.
To solve the detail losing phenomena problem when
using the skin color likelihood transformation method,
combination of skin color likelihood and gray-level in
multi-resolution is suggested.

1. Introduction
Recently, researches on face alignment had been
done a lot. Active shape model (ASM), first proposed
by cootes etc, is considered to be an available method
for face alignment.
Lots of approaches had been proposed to improve
both accuracy and efficiency of this algorithm [1,
2,3,5]. Our recent work has aimed at improving the
accuracy of Active shape model for face alignment. In
traditional ASM, appearance model is got by modeling
the local gray profile around each landmark point
statistically. Experiments have done on analyzing the
gray-level profile got from face images with either
different races or different lighting conditions. And we
found that their gray level profile vary in a large range.
This leads to an inaccurate local appearance model.
Color is another feature on human faces [4]. In
order to decrease the influence of different races and
lighting conditions, we propose using a method called
skin color likelihood transformation on the model.
Experiment shows that this method improves the
accuracy rate of the algorithm in a certain degree.

When using the transformation method, detail losing
phenomenon on some organic region comes out. A
combination of using skin color likelihood and graylevel is proposed to solve this problem, which is used
in different resolution level separately.

2. Active Shape model overview
ASM is generally divided into three parts: a shape
model, an appearance model and the search procedure.

2.1. Shape model
In ASM, a face is represented by a set of labeled
points. Each represents the position of a particular part
of the structure to be located [2]. The model is trained
by marking landmark points on each of a set of
training images. Statistical analysis of the relative
positions of the landmarks in different examples allows
both the average shape and shape variation to be
modeled. With these, a new face shape can be
presented using the equation:

x x  Pb
T
where x ( x0 , y0 , x0 , y0 ......, xn 1 , y n 1 )
n is the number of landmark points;
( xk , y k ) is the k th model point;

(1)

x represents the mean shape;
P is a 2n * t matrix of t unit column vectors
b (b1 ...bt )T is a set of shape parameters
2.2. Appearance model
In ASM, local normalized derivative is used to
describe the profile around each landmark [3]. It is
calculated using the following method:

Proceedings of the Computer Graphics, Imaging and Vision: New Trends (CGIV’05)
0-7695-2392-7/05 $20.00 © 2005 IEEE

Denote the gray level profile along the landmark j
as gj , its length is n p .

g j [ g j 0, g j1, ...g jnp1, ]T
and the derivative profile of length

(2)

np 1 becomes

dgj [gj1 gj0, gj2 gj1,..,gjnp1 gjnp2]T

(3)

The normalized derivative profile is given by

dg

yj

j

(4)

np 2

¦ | dg

jk

|

k 0

2.3. Search procedure
Face alignment is carried out by finding the desired
movement for each landmark with an initial position.
Desired movement is got by finding the most match
sub-profile, which passing by the original landmark
point, in a longer profile ( n s pixel). Denote h ( d ) as
the sub-profile centered at the d th pixel of profile n s ,
we can get the most match sub-profile by minimizing
the following square error function [1]:
_

f (d )

T

_

(5)

(h(d )  y j ) (h(d )  y j )

where y j is mean of the normalize derivate profile of

In this paper, we use a skin color likelihood
transformation method to make the profile focus more
on the skin color. ASM that using skin color likelihood
transformation method is called Skin-ASM.
The transformation method is composed of 3 steps:
(1) color space translation; (2) likelihood calculation;
(3) likelihood to gray image projection;

3.1. Step 1: color space translation
Most color face images use a RGB representation;
However, RGB is not necessarily the best color
representation for characterizing skin-color [7]. So we
first translate RGB into a new color space that separate
colors from intensity [4]. In our model, we choose the
YCrCb color space as our skin color representation
space. Space translation formula is showed below:
0.299R

 0.587G

0.169R

 0.331G

 0.114B
 0.500B

Cr

0.500R

 0.419G

 0.081B

3.2. Step 2: likelihood calculation
In [6], the authors declared that the distribution of
skin colors can be considered as a 2D Gaussian
2

model G( x , V ) . So, we can calculate the likelihood
value P between the pixel’s color value X and the
mean skin color using equation:

P

th

the j landmark point. Then the new shape, composed
by a set of landmark points which have a new
coordinate, will be affined into the shape PCA space
with equation (1) to constrain itself as a face shape.
This search technique can be improved by using a
multi-resolution approach, with the models applied
first to a coarse, low resolution version of an image,
then refined on higher resolution versions [5].

Y
Cb

e ( D ( X  X )

Where: X

T

C 1 ( X  X ))

(6)

(C r , C b ) T is the color value of the pixel.

X
(C r , C b ) T is the mean matrix of skin
color’s 2D Gaussian model.
is
the
C E [( X  X )( X  X ) T ]
Covariance matrix of 2D Gaussian model.
D is a constant value between [0,1].

3. Skin color likelihood transformation

3.3. Step 3: likelihood to gray level projection

In traditional active shape model for face alignment,
local profile is modeled using normalized derivate of
gray level. Our experiment shows that such kind of
modeled local profile is affected largely by races and
illumination. This makes the appearance model not
accurate enough.
Color is one of the features on human faces. In [6],
authors revealed that skin colors cluster in a small
region in a color space. Also their study shows that
human skin colors differ more in intensity than in
colors. At the same time, different skin color has a

The calculated result of step 2 is a probability value
between [0, 1]. In step 3, we will project it into the
value between [0, 255] as the gray level using equation
(7).

same 2D Gaussian distribution model G( x , V

2

g ij

Pij
Pmax

* 255

(7)

where Pmax is the maximum likelihood value of all the
pixels in a image.

3.4. Transformation result

).

Proceedings of the Computer Graphics, Imaging and Vision: New Trends (CGIV’05)
0-7695-2392-7/05 $20.00 © 2005 IEEE

After projection, a new gray level image is created.
Fig. 1 shows some face images, their gray level image
and their skin color likelihood transformation result.

(a)

(b)

(c)

(d)

(e)

(f)

(g)

(h)

(i)

Fig.1 comparisons of color image, gray image, skin color
likelihood image with different races and lightening effects.
(a)(d)(g)original image; (b)(e)(h) gray level image; (c)(f)
(i)skin color likelihood image;

Comparing images (b)(e)(h) with images (c)(f)(i) in
Fig 1 intuitively, we can find profile on face in images
(c)(f)(i) seems to be more consistent than in images (b)
(e)(h).

and eyes e.g. , on face is projected out while its detail
is decreased. This may makes the searching procedure
not exact enough. In this paper, we call phenomena
like this as a detail losing phenomena.
In order to decrease the error alignment rate caused
by the detail losing phenomena, we try to combine the
skin color likelihood and gray-level for modeling
appearance profile. ASM using this combination is
called Combined-ASM.
In Combined-ASM, skin color likelihood is used for
modeling the profile in coarse lower resolution of
image pyramid while gray-level is used in the original
image.
Set a 3 level ASM as an example. In level 1 and 2,
pyramid images for modeling is created from the skin
color likelihood transformation result image. In level 0,
the highest resolution, the original color face image is
used for modeling. In level 1 and 2, ASM just search
for an approximate position. So the detail losing
phenomena seems not to be an important factor for
accuracy of algorithm. Instead, the projecting of the
organic contour help to search the approximate
position more accurate and quick. In level 0, the
profile detail for each organ on face seems to be more
important when getting the final exact position. So
detail losing phenomena of using skin color likelihood
transformation is quiet a problem. The gray-level
which keeps the profile detail more is used.
For traditional ASM, pyramid images are created
from the original images in both training and search
phases. In Combined-ASM, they are created from the
skin color likelihood transformation result image.

4. Combination of skin color likelihood
transformation and gray-level in multiresolution search.
Cootes etc suggested to use Multi-Resolution search
in ASM in [5].A multi-resolution pyramid is created by
using Gaussian smoothing and sub-sample. Level 0 in
such pyramid is the original image. Level 1 is an image
with half the number of pixels along each pixel [5].
For ASM with multi-resolution, model was trained
on image created at responding resolution. So for an
ASM with 3 level resolutions, each landmark point has
3 local profile models in total. The profile in level 2 is
got on a coarse pyramid image, while in level 0 is got
on the original image.
From images (c)(f)(i) showed in Fig.1, we can see
that the approximate contour of some organs, mouth

Fig.2 Combined-ASM in multi-resolution search

Fig.2 shows this method used to model profile in
multi-resolution search.

5. Experiments
We use the FERET face database [8] for the
evaluation of our algorithm. 60 frontal face images,
whose size is 512*768, in the database are selected
randomly as the training set and other 92 ones as the
testing set. Images in training set and testing set have
various races and lighting condition. Then we labeled
103 landmark points for each images in the training set
manually. At last we use the testing set to compare the

Proceedings of the Computer Graphics, Imaging and Vision: New Trends (CGIV’05)
0-7695-2392-7/05 $20.00 © 2005 IEEE

searching rate of ASM, Skin-ASM and CombinedASM.
An approximate shape of face is given using a face
detector algorithm. The search profile when training is
11 pixels length while it is 31 pixels length when
searching. The width of search profile is 3 pixels. The
percentage for total retained variation of PCA is 98%.
The resolution level is 3 and the maximal iterative time
for each level is 100.
The mean matrix of skin color’s 2D Gaussian
distribution model got from the 60 training images is:

X

(115.5,158.55)T

And covariance matrix is:

C

Skin-ASM 60
76
16
82.6%
Combined 60
83
9
90.2%
-ASM
Fig.3 shows some face images’ alignment result using
the three kinds of ASM.

(2)

From the translation result showed in Fig1 (c)(f)(i),
we can find that the skin color likelihood
transformation method translate the color image into a
new color space that decrease the influence from races
and lighting condition. Experiment result in section 5
shows its improvement on algorithm’s accuracy. From
the experiment result in section 5, we can also find that
the Combined-ASM enhances the accuracy of SkinASM in a certain degree.

Acknowledgments

12.16 º
ª162.1ǂǂ
«12
»
300.4 ǂ
¬ ǂ.16 ǂǂ
¼

Table 1 shows the searching rate for ASM, Skin-ASM
and Combined-ASM.
Table 1: Testing result
Algorithm Trainin
correc false Searchin
g
t
g rate
images
ASM
60
63
29
68.4%

(1)

6. Conclusion

(3)

(4)
(5)
(6)
Fig.3 Alignment result using ASM, Skin-ASM and
Combined-ASM; (1)(4) alignment result using ASM;
(2)(5): alignment result of Skin-ASM; (3)(6)
alignment result of Combined-ASM;

Portions of the research in this paper use the Color
FERET database of facial images collected under the
FERET program. We also sincerely thank suggestions
of Senior Research Scientist Wataru Ito and Dr.
Yuanzhong Li at Imaging Software Technology
Center ˈResearch & Development Management
Headquarters of FUJI PHOTO FILM CO., LTD.

Reference:
[1] Ghassan Hamarneh; Active Shape Models, Modeling
Shape Variations and Gray Level Information and an
Application to Image Search and Classification,
[2] T. F. Cootes, C. J. Taylor, and A. Lanitis. “Active shape
models : Evaluation of a multi-resolution method for
improving image search”. In E. Hancock, editor, 5th British
Machine Vison Conference, pages 327–336, York, England,
Sept. 1994. BMVA Press.
[3] Ordas, S.; Boisrobert, L.; Huguet, M.; Frangi, A.F.;
“Active shape models with invariant optimal features (IOFASM) application to cardiac MRI segmentation”, Computers
in Cardiology, 2003 , 21-24 Septˈ.Pages: 633-636,
[4]Yi cong qin, Li li, Meng chuan liang,”Face Detection in
color image based on skin segmentation”, Journal of
GuiZhou University of technology, Vol. 32
[5] T.F.Cootes , C.J.Taylor, A.Lanitis, “Multi-Resolution
Search with Active Shape Models”, Proc. International
Conference on Pattern Recognition Vol I., Jerusalem, Oct.
1994. pp 610-612.
[6] J. Yang, W. Lu and unknown, "Skin-color Modeling and
Adaptation", Proceedings of ACCV'98, Vol. II, 1998, pp.
687-694.
[7] Jie Yang; Waibel, A.;”A real-time face tracker”;
Applications of Computer Vision, WACV '96., Proceedings
3rd IEEE Workshop on 2-4 Dec. 1996 Page(s): 142 – 147
[8] P. J. Phillips, H. Moon, S.A.Rizvi and P. J. Rauss, The
FERET Evaluation Methodology for Face Recognition
Algorithms, IEEE Trans. Pattern Analysis and Machine
Intelligence, Volume 22, October 2000, pp. 1090-1104.

Proceedings of the Computer Graphics, Imaging and Vision: New Trends (CGIV’05)
0-7695-2392-7/05 $20.00 © 2005 IEEE

