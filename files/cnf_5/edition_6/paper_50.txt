3D Scene Transmission for Web-based Shiphandling Training
Xie Cui
Nautical Science and
Technology Institute, Dalian
Maritime University, Dalian,
China
xiecuidlmu@sohu.com

Liu Xiuwen
Nautical Science and
Technology Institute, Dalian
Maritime University, Dalian,
China
liuxw@dlmu.edu.cn

Abstract
In this paper, we describe a powerful 3D scene
transmission approach for web-based shiphandling
training. Our optimization algorithm achieves this by
selectively transmitting only visible geometric objects
of the scene that will maximizing the visual quality
rendered at the client, based on a cumulative benefit
measure along the predicted viewpoint movement by a
Dead Reckoning algorithm and the available network
bandwidth. The visual quality of the virtual
environment can adapt to the available bandwidth
fluctuations and an acceptable shiphandling-training
is possible even when bandwidth is low.

1. Introduction
The development of network technology, web
graphic (the Virtual Reality Modeling Language)
(VRML) [1], and platform independence of Java [2]
contributes greatly to the popularization of the multiuser applications on the Web environment, such as
online training, cooperative design, teleconferencing,
telemedicine, and electronic commerce in a 3D virtual
environment. However, the on-line shiphandling
training allowing several trainers interact with each
other in a virtual environment across the network has
the challenge of transmitting simulation training
information (virtual environment, trainers positions,
actions, etc) to remote clients, usually referred to as the
latency problem. This is a hard problem to solve, as
transmitting complex environments with lots of
geometry and texture can be very expensive.
This paper aims to design a powerful 3D scene
transmission policy for our web-based shiphandling

Jin Yicheng
Nautical Science and
Technology Institute, Dalian
Maritime University, Dalian,
China
jycdmu@dlmu.edu.cn

training system. The system takes the high fidelity
shiphandling simulation into it and provides a training
platform for marine education and training on the web.
It allows marine personnel to pursue the effective
training from anywhere, any time, via a PC’s Web
browser, and then enhances the marine personnel’s
navigation learning and skills. The characteristic of our
system is that a virtual ship is an avatar of the trainer
and it is the only type of the dynamic objects, changing
their locations and orientations along with a trainer’s
control within the virtual environment. Therefore, the
system virtual camera is located just above the rudder
and is bound with the ship, viewing direction is along
the course heading. That is to say, at any time, the
ship’s position is the same as the position of viewpoint
and the relative position between own-ship and
viewpoint dose not change in the navigation training.
In our system, ship’s position is updated every 0.5
second based on the result from the manoeuvring
mathematical model of ship. During this period, the
position of the avatar is extrapolated using the motion
predictor and the client’s s local timer. All participants
share in the same virtual environment can see each
other by their avatar.
Our 3D navigation scene (including the locations
and geometric shapes of virtual objects) maintained in
a server is on moderate scale and is composed of many
objects with different complexity and various
representations. Each object can be represented as a
collection of models at different levels of detail, precomputed imaged-based impostor (billboard) or a
progressive meshes (PM). Since the surface textures or
billboard used in our system is compressed as JPEG
image, each size is small (less than 300K bytes), so we
focus on solving the graphic transmission problem for
our web-base training. A trainer using a client machine

Proceedings of the Computer Graphics, Imaging and Vision: New Trends (CGIV’05)
0-7695-2392-7/05 $20.00 © 2005 IEEE

connected to the Internet may access and visit the
virtual navigation environment provided by the server.
When the trainer navigates through the environment,
information of virtual objects located within the visible
range of the trainer will be conveyed to the client
machine for rendering. The server selects a
transmission sequence of object representations that
will provide the client the optimal rendering quality
throughout the navigation training, under the existing
constraints of relatively low Internet bandwidth, while
the client is free to choose the best one among the
received different representations of objects for the
current view at any time under a least frame rate(20fps)
constrain. This transmission schedule is determined by
an online optimization algorithm at server that decides
which representation to be sent at any given moment.
The main contribution of this paper is an efficient
policy for the optimal transmitting a scene across a
limited bandwidth connection, which combines a
cumulative benefit/cost measure with a Dead
Reckoning (DR) technique. The rest of the paper is
organized as follows: In Section 2 previous works
related to the transmitting 3D-geometry objects over
the web is presented. In Section 3 3D scene structuring
and encoding is addressed. A powerful 3D scene
transmission scheme is introduced in Section 4. Finally,
in Section 5 and 6 show the result and the conclusion
respectively.

2. Related Work
Two main approaches have been proposed to
distribute virtual objects from the server to the clients
in distributed virtual environments (DVE) [3]. Most
systems, such as DIVE [4], SIMNET [5], and VLNET
[6], employ a complete replication approach to
distribute all geometry data to the clients before the
start of the application. Since the geometry database is
usually large in size, this approach assumes the use of a
high speed network in order to reduce preloading time
and may not be suitable for our training system. A few
systems employ the on-demand transmission [7]
approach to distribute geometry data within the area of
interest (AOI)[8, 9] of the user to the clients [10], [11]
at runtime, Although this approach may reduce startup
time and the amount of scene content needed to be
downloaded during runtime, it may still suffer from
some transmission problems.
First, we need to fetch the visible objects from the
server in advance so that they can be available in the
client when they are needed, in order for the training
application to be interactive. Second, traditionally, the
geometry information of individual objects is
transmitted as a whole to the client. However, a large

model can easily use up the available network
bandwidth for a considerable period of time, affecting
the user interactivity. Third, within the AOI of a user,
the importance of individual objects, i.e., the order of
objects, is usually not considered in model
transmission. Hence, a user may receive less important
objects before the critical ones, which considerably
reduce the fidelity of the training system. Consequently,
various solutions for these problems were proposed.
For the first problem, in [7,12], authors
investigated the pre-fetching and caching methods for
just-in-time graphics data transmission in network
virtual environments. Chim[13]focused on the ondemand transmission approach with pre-fetching and
caching mechanism in a web-based distributed virtual
walkthrough environment. However, their method did
not consider the visual importance of all the visible
objects being rendered to the client at any given
moment, so their method could not ensure an optimal
transmission sequence for all visible objects being
rendered in each frame. To solve the second problem,
Progressive Meshes (PM), introduced by Hoppe [14,15]
is very effective for transmission of individual complex
objects. Therefore, this method did not constitute a
complete solution for interactive training in virtual
environments. Schneider et al [16] presented a complex
performance model where an optimal transmission
method is chosen depending on network performance,
available resources and user preferences. However,
they focus on transmission of individual 3D models,
rather than on interactive navigations complex virtual
worlds containing many different objects. For the third
problem, Teler[17] proposed an optimization
transmission method, which can determine what object
data to send by a benefit/cost measure for a certain
viewpoint. But their method is complex for
computation and doesn’t consider transmission
problem of dynamic environments to multi-user as our
system required. George [18] proposed a scheduling
policy for multiple multi-resolution 3D-geometry
objects over congested network links. But his
prediction method of viewpoint motion is a random
walk model. We use Dead Reckoning method that is
more simple and common to predict user locations and
reduce transmitted data in distributed virtual
environments (DVEs). Moreover, we consider
transmission of static as well as dynamic ships with
multiple representation modalities each to multi-users.
We focus on scene organization and scheduling
policies for transmission of graphic environments
between server and clients.

3. Scene Structuring and Encoding

Proceedings of the Computer Graphics, Imaging and Vision: New Trends (CGIV’05)
0-7695-2392-7/05 $20.00 © 2005 IEEE

A virtual navigation world is composed of a
collection of 3D objects, such as ocean, islands,
mountains and harbor (including cranes and buildings
nearby) etc. So it requires a large volume of data
(including geometric properties and texture etc.)
describing the scene. Due to the web limitations and
real-time interaction requirement of our system, all
models should not only have enough fidelity but also
be as simple as possible to accelerate the data transfer
and rendering.
Firstly, we create different representations for the
entities in the virtual world according to their
complexity. Simplest static object representation is an
image-based imposter (i.e. trees are show in a
“billboard”); Complex models like mountain are
prepared in PM format for optimal transmission and
rendering. Other moderate-complex objects like
buildings nearby the harbor are created with one or
more level-of-detail (LOD) representation each.
Combining different representations for representing
models can achieve better transmission and rendering
performance than the use of a ”one-size-fits-all”
strategy.
Then we construct the scene-graph with quad-tree
scene-partitioning technology to accelerate the
visibility determination of a certain viewpoint in the
scene and support the progressive downloading of the
3D scene according to the current viewpoint. The
virtual environment is partitioned regularly into a
number of rectangular cells. Each cell may contain a
list of references to a number of visible objects. To set
up a training, for each object we add a reference of it to
all the cells that overlaps with the object.
Note that since each geometry model may have
one or more than one representations (i.e. a precomputed collection of models at different levels of
detail, progressive meshes or a pre-computed imagebased impostor), we consider each of them as a
transmission primitive and organize all the geometry
models in a unified data structure. We refer to each of
these transmission primitives as a modeling unit, which
may be represented as a base record followed by an
ordered list of progressive records. The base record
contains the minimal information for reconstructing
model at its lowest resolution. The modeling unit of
each model should be transmitted successively for
detail reconstruction at the client.
When an object is to be transmitted to the trainer,
we would check each of its primitives to see which
need to be transmitted and which are already
transmitted to ensure that only one copy of each
primitive is transmitted. We may also preload the base
meshes of all or some of the objects and their texture
images in the environment. Since the size of a base

mesh and it’s textures can be small, preloading the
them may reduce the system latency at the cost of only
slightly increased preloading time, but the practical
navigation of the scene is possible even if the
transmission bandwidth is low.

4. Scene Transmission Scheme
Once a client successfully establishes a connection
to a server, the server will immediately provide the
user with general information such as scene layout and
base information of visible objects (texture/impostor,
base meshes and LOD models at the lowest resolution)
during the initial waiting time. After the client starts
moving about the virtual world, he/she periodically
(twice per seconds) sends to the server the current
viewing parameters, including viewpoint position,
velocity and orientation. The server determines
visibility by a 2D visibility-culling algorithm, performs
motion prediction based on DR algorithm and decides
which representations of which objects to transmit to
the client by an online optimization policy, and then
sends back proper data accordingly. The received data
are cached at the client side and can be reused for the
remainder of the training. The online optimization
policy selects object representations that will improve
the rendering quality maximally throughout the
shiphandling training, subject to the limitations
imposed by the available bandwidth.
Our work is strongly inspired by the work done by
Teler [17] and George [18], the major difference is that
we use DR algorithm to predict the viewpoint motion
and use a concept of “cumulative benefit” to determine
what object data to send. The “cumulative benefit”
means the summing up the value of the benefit
computed at every DR extrapolation between two
successive viewpoint-update intervals. This approach
is simpler compared with Teler’s and has less overall
error than George’s.

4.1. Representation cost and benefit
The 3D objects are stored at the server as a
sequence of transmission primitives, such as PM
blocks (a block means a sequence of the aggregate
successive progressive records from the same object)
or as several discrete LODs. Note that both of them are
marked as representations for simplification and
unification in the following sections. Let rij denotes
representation j of object i, Ri is the set of different
representations of object i, Rij is the set of
representations from ri0 to rij. Each object
representation rij has an associated view-dependent
benefit measure that can be calculated for any

Proceedings of the Computer Graphics, Imaging and Vision: New Trends (CGIV’05)
0-7695-2392-7/05 $20.00 © 2005 IEEE

viewpoint, which reflects the accuracy of the
representation with respect to a given virtual camera,
the visibility of the object, and its importance etc. It
also has an associated cost, which is its expected
transmission duration [17,19].
In our web-based marine training system, the cost
associated with a particular object representation can
be estimated as the size of the representation divided
by the available bandwidth, plus some constant
overhead cost. In practice, the effective connection
bandwidth varies according to network load. Thus, the
average bandwidth Bw over a recent time window
should be used in the cost estimation (see the formula
(1)). The size of the representation S˄rij˅is easy to
compute for predefined object representations, such as
pre-generated LODs and PM blocks, each block’s size
may be unequal.
In our system, we use a benefit measure to reflect
the accuracy of displaying an object in the viewing
area: (see the formula (1)). Where S(rij) is size(bits) of
rij, S(Rij) is size (bits) of Rij and S(Ri) the size (bits) of
Ri; RadAOI is the radius of the viewing area( the angle
of viewing of field here is [-S/8ҏ, S/8ҏ]); Radi is the
radius of object bounding sphere; To is the angular
distance of the object from the viewer’s line of sight
and the Di is the distance between the viewpoint and
the object; N is the number of objects in the viewing
area.

cost(r ij )

S(r ij )
Bw



implementation, we assume that the viewer’s line of
sight is at the center of the screen. The formula
establishes that larger objects closer to the viewpoint
and nearer the viewer’s line of sight are more
important to the viewer (as they will appear larger on
the screen). We used this formula instead of the area
(in pixels) on the screen occupied by the object [17], a
measure more difficult to compute at the server.
When the server considers rij as a candidate for
transmission it must estimate how much rij will add to
the object benefit B(ri,j-1) given the representations
already available at the client side at this viewing
parameters in time. The “added benefit” b(rij) for a
particular viewpoint is then defined as B(rij)- B(ri,j1),see expression 2 below:
3
3
§§
·
¨ ¨ 1  S(R i, j-1 ) ·¸  §¨ 1  S(R ij ) ·¸ ¸  
¨
¸
¨
¸
¨
S(R i ) ¹
S(R i ) ¹ ¸
©
©©
¹

b ( rij )

§
Di
¨¨ 1 
Rad
AOI
©

·
¸¸  Rad i * cos T o 
¹
M! ĂĂ

(the normalization term

1

§
Dl
¨¨1 
¦
Rad AOI
l 1©
N

·
¸¸  Rad l
¹

was dropped as it

doesn’t affect the computation of maximum benefit.

4.2. Optimal Transmission Policies

§ § S(Rij) ·3 ·
¸ ¸ 
BRij  ¨1 ¨¨1
¨ © S(Ri ) ¸¹ ¸
©
¹
§
Di ·
¸¸  Radi *cosTo
¨¨1
© RadAOI ¹



§
D ·
¨¨1 l ¸¸  Radl
¦
RadAOI ¹
l 1©
(DiİRadAOI)ĂĂĂĂ
N

Here we only consider two factors: the accuracy of
representation of the geometry object (first term in
formula 1) and the importance of the object (the
second). The accuracy of representation of the
geometry object was chosen as in [12], based on the
observation that the dependence of visual perception
on the representation quality of the graphic model can
be modeled as a cubic function. The importance of the
object varies linearly with the distance between the
viewpoint and the geometry objects and it is also
proportional to the radius of the bounding sphere of the
object. Meanwhile, the peripheral visual details
degrade with increasing of the angular distance of from
the viewer’s line of sight [20],[21].In our

Using above definitions, our policy for optimal
transmission of m multi-resolution representations of
visible 3D-geometry objects a time unit ǻt over a
limited network bandwidth Bw can be stated as follows:
Where, ǻt equals 0.5 second and it is identical
m

Maximize :

¦ ¦ b(r

ij

) ĂĂ

i 0 j Ri

m

Subject to :

¦¦
i 0 jRi

S (rij )
't

d Bw

with the time of the viewpoint update.
This formula aims to maximize the overall visual
quality at the client, visible representations with the
maximum value of benefits divided by the cost of
transmission is selected for transmission. The
representations to be transmitted are selected from any
object in the queue with the constraint that
representations from the same object are transmitted
successively. Namely, the constraint: “for each object,

Proceedings of the Computer Graphics, Imaging and Vision: New Trends (CGIV’05)
0-7695-2392-7/05 $20.00 © 2005 IEEE

implemented like [18] by a multilevel queue where
geometry objects are continuously added as they enter
the visible area. Each level contains the list of
representations from the same object. Objects are
deleted from the queue as they disappear from the
visible region. The greedy algorithm traverses the
queue in a round robin mode [22] and selects the
representations with the maximum benefit to cost ratio
and inserts them in a first-in-firs-out (FIFO) sending
buffer. The maximum size of the sending buffer is set
according to the estimated effective network bandwidth
Bw and the frequency of the viewpoint updates
received from the client Fupdate: Buffersize <=
(Bw/Fupdate) such that a full buffer is transmitted
between two successive viewpoint updates. This
prevents the reordering of the buffered data during the
transmission of static environments.
In our system, ship is the only dynamic object
representing a training participant as an avatar. Since
the update frequency of all ship information is
uniformly set to be 2 times every second. Also, all
participants’ viewpoint is conformably updated 2 times
every second. We combine a cumulative benefit
measure with DR algorithm to reduce the error
y

…
P2N

…

representation i can be scheduled only is representation
i-1 was scheduled” must be satisfied.
The size of the representations affects the
scheduling effort and the visual error: the larger the
representations the smaller the scheduling effort but the
larger the visual error of the transmitted environment.
A good rule of thumb is to choose the size of the
blocks an order of magnitude smaller than the size of
the sending buffer. This scheduling policy only
requires knowledge of object position, angle distance
to the viewer’s line of sight and size (e.g. pre-stored
bounding sphere size) and the update of client’s
viewpoint position. Since the optimum solution for the
above knapsack optimization problem has NP
complexity. Our online optimization algorithm is based
on a simple greedy algorithm described in the
following section.
Additionally, in our Web-base shiphandling
system, the 3D scene data is transmitted continuously
and is not synchronized with the rendering of the
frames. Although the server received the updated
viewing parameters form the client, it does not know
the exact viewpoint position for near the future due to
the network latency and the amount of time for model
transmission. So it is necessary to predict the changed
viewpoint based on the information received from the
client. George [18] used a random walk model and
required a significant amount of processing time to
determine the probability parameter. In practice, we
use DR algorithm to predict the viewpoint motion.
Since DR is a simple and common prediction method
and can reduce transmitted data in distributed virtual
environments (DVEs). Furthermore, DR techniques
can reduce the overall error by extrapolation from the
current motion to predict future motions. A DR period
equals the interval between two successive viewpoint
update received from the client. It should be noted that,
in every DR period, our DR algorithm also predicts
viewpoint motion of the next DR period (see figure 1)
to reduce the effect of the network delay, and sum up
the benefit of rij at every step of DR extrapolation
along the predicted viewpoint motion of the next DR
period in order to estimate the cumulative benefit of
transmitting rij . This online process will be discussed
in more detail in the section 4.4.
The added benefit sum of rij is estimated over the
process of the viewpoint movement predicted in every
DR period

PN

PN+1

x

P1
o

P0

y

W W
 Fupdate
W Wÿ

W W
 Fupdate

…
P2N

…
PN
P1
P0

4.3. Greedy scheduling algorithm
x

The greedy algorithm at each step selects for
transmission the representations that improve most the
visual quality at the client. The greedy algorithm is

Proceedings of the Computer Graphics, Imaging and Vision: New Trends (CGIV’05)
0-7695-2392-7/05 $20.00 © 2005 IEEE

o
Figure 1. Prefeching with dead reckoning

introduced by object movement, which can change the
importance of the 3D object between two successive
viewpoint motions.
The scheduling effort for greedy algorithm grows
linearly with the number of 3D geometry
representations to be transmitted. As mentioned above,
the size of the representations is determined as tradeoff between the scheduling effort and the resolution of
the visual quality measure; a poor resolution will lead
to transmission of lesser quality environments per each
rendered frame in conditions of bandwidth constraints.

4.4. Prediction and Prefeching Policy
In this process, we use figure 1 to illustrate our DR
algorithm and pre-fetching method. At time t’, the
server received the updated viewing parameters, it start
to predict the direction and the speed at which the user
seems to be advancing by performing 2N times DR
algorithm in one period of viewpoint update.
Meanwhile predict the viewpoint position in the next
period of the viewpoint update. The visibility condition
is evaluated at every time of DR extrapolation. The
time need for performing one DR extrapolation is
1/NFupdate (s). As the figure 1 shows, time t'+1/ Fupdate

¦

¦

b ( rij , k )

k

k

where:

&
P

&
P

k

&
P

&
*
§
Pk  O i
¨
' Accuracy  1 
Rad
¨
©

N 1Ă1ĂĂ

*
p update

Z
NF

N Ă1Ă1

T

0

T update

is the k-th position of the viewpoint
&
extrapolated by DR; O k is the k-th position of the
object extrapolated by DR algorithm; v ҏis the motion
speed of viewpoint; © k is the k-th extrapolated
direction of the viewpoint and it is as same as the ship
heading direction; T is angle distance between object i
Where,

AOI

·
¸  Rad * cos T 
i
oi
¸
¹

v
iT

 e k 1 N Ă1Ă1
k 1
NF

T k T k 1 
*
p0

and t'+2/ Fupdate indicate the N-th DR extrapolation and
the 2N-th DR extrapolation respectively. It should be
noted that only the objects entering the visible greyarea (estimated on the viewpoint from PN to P2N)
within the next period of the viewpoint update are prefetched, their associated benefit is computed at every
DR extrapolation, and then only the computed benefits
of the same representation in 2nd period of viewpoint
update (from t'+1/ Fupdate to t'+2/ Fupdate) is summed up.
The expression (4) shows the estimate of the
cumulative benefit of rij with DR extrapolation in one
period of viewpoint update. Finally, the representations
with maximum cumulative benefit divided by the cost
of transmission will be added to the sending buffer
(scheduling queue) for transmission before the next
viewpoint update coming.
This Pre-fetching policy considers the next two
period of viewpoint update to improve the validity of
the visible objects in navigation process. The DR
algorithm can reduce the overall error of the virtual
environment. The frequency of the DR extrapolation
estimation is limited by the precision in prediction,
scheduling time and the frequency of the viewpoint
update. So N is an experiential value for different
application.

k

frequency of the viewpoint update informed by the
client; ҏ 1/NF is the time of one DR extrapolation.

&
P

and T 0 is the updated position and direction of
the viewpoint from the client.
update

5. Results

oi

and the viewer’s line of sight, since the movement of
ship is not rapid, so we take it as a constant during the
DR period and updated with every viewpoint update;
W is the angular velocity; Ƹ Accuracy is the
improvement in the accuracy due to the transmission of
the representation (first part of equation (2)); F is the

Our transmission strategy is tested in our webbased marine training system. In our current
experiment, Dalian harbor with total geometric data
size of 30M bytes and all textures taking under 300K.
The 3D objects were positioned on a flat terrain
according to their real geographical layout.

Proceedings of the Computer Graphics, Imaging and Vision: New Trends (CGIV’05)
0-7695-2392-7/05 $20.00 © 2005 IEEE

Object representations are transmitted through the
512Kbps connections without any kind of compression,
except surface textures, which are stored as JPEG
images and transmitted first compared with graphic
data. The computer at the client side is Pċ933, 256M
memory, TNT2M64 display adaptor. Experiment result
shows that the 512Kbps bandwidth is enough for
decent quality representations of the objects arriving in
a timely fashion. Initially, the ocean tiles are received
first, crude image-based impostors and LODs start to
arrive subsequently. About tens of seconds later, we
can see crude representations for all objects with base
information on the screen and the initialization is
finished, the interactive shiphandling training begin
now with a frame-rate not less than 20fps. Certainly it
will provide better quality if the higher bandwidth
connection (10Mbps or 100Mbps) is used. Figure 2 is a
snapshot of the training environment (Dalian harbor)
running in our prototype system.

and image-based impostors in a single online
optimization formulation. Meanwhile, we would like to
extend our framework to incorporate compression
techniques for more efficient transmission of object
models and further effort is to improve the system
scalability.

7. References
[1]
[2]
[3]

[4]

[5]

[6]

[7]

[8]

[9]
Figure 2. A snapshot of the training

6. Conclusions
We have described a powerful moderate-scale 3Dscene transmission approach that allows trainers to
perform navigation training in a moderate-scale
networked virtual environments. Our approach
employs an online optimization algorithm for
transmission of multiple multi-resolution geometry
objects over limited links. It schedules object
transmissions based on the sum of benefit computed at
every DR extrapolation between next two successive
viewpoints. The representation with the best benefit to
cost ratio are transmitted first, which will maximize the
visual quality rendered at the client. Experiment result
shows that the approach can adapt well to different
connection bandwidths and various trainer’s rendering
capability with different visual quality.
This paper describes work in progress. We would
like to extend our framework to support both geometric

[10]

[11]

[12]

[13]

[14]

Proceedings of the Computer Graphics, Imaging and Vision: New Trends (CGIV’05)
0-7695-2392-7/05 $20.00 © 2005 IEEE

Web3D web site. http://www.web3d.org
Java web site. http://java.sun.com
S. Singhal and M. Zyda. Networked Virtual
Environments: Design and Implementation. Addison
Wesley, 1999.
C. Carlsson and O. Hagsand, “DIVE—A multi-user
virtual reality system,” in Proc. IEEE VRAIS, 1993, pp.
394–400.
J. Calvin, A. Dicken, B. Gaines, P. Metzger, D. Miller,
and D. Owen, “The SIMNET virtual world
architecture,” in Proc. IEEE VRAIS, 1993, pp. 450–
455.
I. Pandzic, T. Capin, E. Lee, N. Thalmann, and D.
Thalmann, “A flexible architecture for virtual humans
in networked collaborative virtual environments,” in
Proc. Eurographics ’97, 1997, pp. 177–188.
D. Schmalstieg and M. Gervautz, “Demand-driven
geometry transmission for distributed virtual
environments,” in Proc. Eurographics ’96, 1996, pp.
421–432.
J. Falby, M. Zyda, D. Pratt, and R. Mackey. NPSNET:
Hierarchical Data Structures for Real-Time ThreeDimensional Visual Simulation. Computers &
Graphics, 17(1):65̢69, 1993.
M. Macedonia, M. Zyda, D. Pratt, D. Brutzman, and P.
Barham. Exploiting Reality with Multicast Groups: A
Network Architecture for Large-scale Virtual
Environments. Proc. IEEE VRAIS, pp.38̢45, 1995.
J. Falby,M. Zyda, D. Pratt, and R. Mackey, “NPSNET:
Hierarchical data structures for real-time threedimensional visual simulation,” Comput.Graph., vol.
17, no. 1, pp. 65–69, 1993.
G. Singh, L. Serra,W. Png, and H. Ng, “Bricknet: A
software toolkit for network-based virtual worlds,”
Presence: Teleop. Virtual Environ., vol. 3, no. 1, pp.
19–34, 1994.
Chim, J., M. Green, R. Lau, H. V. Leong, and A. Si,
“On caching and prefetching of virtual objects in
distributed Virtual Environments,” In Proceedings of
ACM Multimedia '98, ACM Press, pp. 171-180, 1998.
Chim, J.H.P., Lau, R.W.H., Leong, H.V. and Si, A.
CyberWalk: a web-based distributed virtual
walkthrough environment. In IEEE Transactions on
Multimedia, volume 5, number 4, pages 503-515,
December 2003
Hugues Hoppe. Progressive meshes.
ACM
SIGGRAPH 96 Conference Proceedings, pp. 99-108,
1996.

[15] Hugues Hoppe. Efficient implementation of
progressive meshes. Computer & Graphics, Vol. 22,
No. 1, pp. 27-36, 1998.
[16] B.-O. Schneider and I. M. Martin. An adaptive
framework for 3D graphics over networks. Computers
and Graphics, 23(6):867–874, Dec. 1999.
[17] E. Teler and D. Lischinski, “Streaming of complex 3D
scenes for remote walkthroughs”, Computer Graphics
Forum, 20(3), Sep. 2001.
[18] George V. Popescu, Zhen Liu: On Scheduling 3D
Model Transmission in Network Virtual Environments.
DS-RT 2002: 127-133.
[19] T. A. Funkhouser and C. H. Séquin. Adaptive display
algorithm for interactive frame rates during
visualization of complex virtual environments. In

Computer Graphics Proceedings, Annual Conference
Series, pp. 247–254, Aug. 1993.
[20] T. Ohshima, H.Yamamoto, and H. Tamura, “Gazedirected adaptive rendering for interacting with virtual
space,” in Proc. IEEE VRAIS, July 1996, pp. 103–110.
[21] B. Watson, N. Walker, and L. Hodges, “Effectiveness
of spatial level of detail degradation in the periphery of
head-mounted displays,” in Proc. ACM CHI’96, April
1996, pp. 227–228. databases, mobile computing,
internet computing, and digital libraries.
[22] Faisstnauer, A., Schmalstieg, D., Purgathofer, W.,
Priority Round-Robin Scheduling for Very Large
Virtual Environments, IEEE Virtual Reality
Conference 2000, New Brunswick, New Jersey

Proceedings of the Computer Graphics, Imaging and Vision: New Trends (CGIV’05)
0-7695-2392-7/05 $20.00 © 2005 IEEE

