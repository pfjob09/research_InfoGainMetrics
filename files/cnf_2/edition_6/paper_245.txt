DOI: 10.1111/j.1467-8659.2010.01818.x

COMPUTER GRAPHICS

forum

Volume 29 (2010), number 8 pp. 2516–2529

Fullsphere Irradiance Factorization for Real-Time
All-Frequency Illumination for Dynamic Scenes
D. Michael and Y. Chrysanthou
Computer Science Department, University of Cyprus, Cyprus
{despinam, yiorgos}@cs.ucy.ac.cy

Abstract
Computation of illumination with soft-shadows from all-frequency environment maps, is a computationally expensive process. Use of pre-computation add the limitation that receiver’s geometry must be known in advance, since
Irradiance computation takes into account the receiver’s normal direction. We propose a method that using a new
notion that we introduce, the Fullsphere Irradiance, allows us to accumulate the contribution from all light sources
in the scene, on a possible receiver without knowing the receiver’s geometry. This expensive computation is done
in a pre-processing step. The pre-computed value is used at run time to compute the Irradiance arriving at any
receiver with known direction. We show how using this technique we compute soft-shadows and self-shadows in
real-time from all-frequency environments, with only modest memory requirements. A GPU implementation of the
method, yields high frame rates even for complex scenes with dozens of dynamic occluders and receivers.
Keywords: real-time illumination, dynamic scenes, soft-shadows, factorization
ACM CCS: I.3.7 [Computer Graphics]: Colour, shading shadowing and texture

1. Introduction
Correctly accounting for the illumination and shadows produced by complex environmental lighting, greatly improves
the visual realism of real-time applications such as training
simulators, computer games, CAD programs, etc. The process is computationally intensive since it requires a weighted
integral over all light sources in the scene, taking into account expensive occlusion calculations. The cost increases
with the number of light sources in the scene. Thus, typically
the quality is compromised by not considering all-frequency
environments [SKS02, KK03, RWS∗ 06].
Real-time illumination methods, in order to reduce
the computations needed at run time, make use of precomputations that usually have heavy memory requirements
for storing the pre-processing values. In addition, the use of
pre-computations adds the limitation that static parameters
must be used, such as static or rigid receivers [IDYN07].
In this paper, we introduce a technique that can be used
for real-time illumination with shadows from all-frequency
c 2010 The Authors
Computer Graphics Forum c 2010 The Eurographics
Association and Blackwell Publishing Ltd. Published by
Blackwell Publishing, 9600 Garsington Road, Oxford OX4
2DQ, UK and 350 Main Street, Malden, MA 02148, USA.

environment maps, for fully dynamic receivers, Figure 1, and
with only moderate needs in memory space.
The method is based on a reformulation of the Irradiance computation that allows us to factor out the direction of
the receiver’s normal, for diffuse surfaces, [WHG99, Wil00,
LLAP05]. We introduce a new notion, the Fullsphere Irradiance (FI) that is a modification of the Irradiance in that
it takes into account energy arriving at a point from all the
light sources in the scene, not only those that lie in the positive hemisphere of the receiver. Using the factorization, we
are able to encode the FI within a 3-D vector, called Fullsphere Irradiance Vector (FIV), whose values are valid for
any direction of the receiver.
We applied our technique for computing in real-time interand intra-object soft-shadows by encoding also the occluded
irradiance using FIVs. A FIV can be pre-computed for the
part of the environment hidden by each occluder, placing
the occluder each time at a position of a dense set of sample
points. Then, at run time, given a point on a scene surface, we
can use the FIV values to quickly compute the unoccluded

2516

D. Michael & Y. Chrysanthou / Fullsphere Irradiance Factorization

2517

Figure 1: Real-time illumination with soft-shadows for fully dynamic receivers from all frequency environments.
Irradiance using merely a dot product per occluder, per colour
channel, of the receiver’s normal.
The contribution of our paper is two-fold: (i) it introduces
the notion of the FIVs, which allow a pre-integration of
light sources contribution, independently to the receiver’s
normal and (ii) it proposes a simple and scalable method
that employs this novel idea and computes both soft and
hard shadows in complex scenes from all-frequency lighting conditions (environment maps). Our results, show a
GPU implementation of the latter yielding high frame rates
even for scenes with dozens of dynamic occluders and
receivers.

2. Related Work
Illumination algorithms have been at the core of computer
graphics from the very early days. Most recent related work
on real-time illumination has been focusing on accelerating
the illumination calculation by pre-computations. We briefly
review work relevant to our method.
In Pre-computed Radiance Transfer (PRT) the visibility
is pre-computed and stored, along with the BRDF, as basis
functions per vertex of the object. These basis functions are
then multiplied with the illumination at run time. PRT was
originally proposed for low-frequency illumination [SKS02,
KSS02] and later extended to account for more general incident light and BRDF [LSSS04, NRH04, SM06]. PRT is
more general than our method, in terms of the reflectance
properties of the objects. However, it is inherently geared
towards static scenes since the visibility is pre-computed per
vertex of the object.
PRT has been used with dynamic scenes. Kautz et al.
[KLA04] propose a method for on-the-fly rasterization of
the visibility for each vertex, however it is doubtful whether
this method can scale to larger scenes. Mei et al. [MSW04]
and Zhou et al. [ZHL∗ 05] store the visibility in separate maps
while [SM06] extend wavelet product integrals to separate
local and global visibility. Despite the progress, the memory
requirements typically remain extremely large, and the cost
of the on-line step limits the method to scenes with a small
number of occluders.

The literature is rich with many different approaches to
soft-shadow computation [HLHS03]. Some of the more popular ones are extensions of hard shadows computation approaches, taking into account multiple samples on an area
light source [GBP06, SS08]. More recent approaches, aim
to produce soft-shadows from a full environment map, usually making approximations either to the occluders geometry
[RWS∗ 06] or to the environment map [ADM∗ 08].
Occlusion computation is typically the most time consuming part of any high quality illumination algorithm. It is thus
not surprising that the idea of pre-sampling the occlusion of
objects for dynamic scenes, has been around for a while in
various applications: radiosity [OCL96], ambient occlusion
[KL05, MMAH07], shadows [ZHL∗ 05] and inter-reflections
[MSW04]. Among these, the method of Zhou et al. [ZHL∗ 05]
is closer to ours, since it also allows the inclusion of allfrequency illumination. In their method, for each sample
view taken around an occluder, a complete occlusion field
is stored. In contrast, in our method, the occlusion field is
only used at pre-processing, as an intermediate step to compute the FIV of the occluded part of the environment map.
Although their approach can also account for local lights, it
requires storing hundreds of MBytes of memory per object
and incurs a computational intensive run time step. Our factorization reduces the memory requirement by two orders of
magnitude and more than an order of magnitude speed up
at run time, at the expense of having a fixed environment
map.
The idea of decoupling the receiver’s normal form the incident radiance have been employed before. Everitt [Eve00]
used this idea to perform per pixel illumination when this was
not feasible with graphics hardware, but the method works
only for a single light source. The Vector Irradiance, as the
part of the Irradiance that is independent of the normal is
called, have been used for Radiosity computation [WHG99,
Wil00, LLAP05]. However in these cases, it is known in
advance which light sources (or emitting patches) lie in the
positive hemisphere of the receiving patch. In PRT, Sloan
[Slo06] used the idea of decoupling the normal from incident Irradiance, in order to handle normal maps. However
since the radiance transfer is pre-computed, this technique
cannot handle fully dynamic receivers and works only for
rigid objects.

c 2010 The Authors
Computer Graphics Forum c 2010 The Eurographics Association and Blackwell Publishing Ltd.

2518

D. Michael & Y. Chrysanthou / Fullsphere Irradiance Factorization

3. Fullsphere Irradiance Vectors
The reflected radiance Lout in direction ωo at a point p, with
surface normal Np and BRDF fp (ωi , ωo ) is given by the
following equation:
Lout,p (ωo ) =

+
Np

Lin,p (ωi )fp (ωi , ωo ) cos Np , ωi dωi ,
(1)

where Lin,p (ωi ) is the radiance coming from direction ωi and
+
is the positive hemisphere of the point p.
N
p

Assuming diffuse reflectance only, the BRDF is constant
and the term f (ωi , ωo ) can be substituted by a reflectance
factor ρdif which can be factored out from the integral and
thus the radiance equation for diffuse surfaces becomes

Note that in cases when all light sources in the scene, are in
the positive hemisphere of the receiver, then the values of the
Irradiance and the FI are equal
Ip (Np ) = FI p (Np ) when M = M + .

(7)

In the Irradiance equation, Equation (5), the normal Np of
the receiving point p is within the summation. This means
the Irradiance can be accumulated only once the normal Np
is known. For dynamic receivers this implies that this costly
computation will necessarily have to be computed online.
The Irradiance equation can be rearranged to factor out the
normal from the summation. By replacing the cosine of the
unit vectors Np and ωi , with the dot product of the two
vectors, the summation can be broken into three components.
Ip (Np ) =

[Lin (ωi ) cos Np , ωi ]
ωi ∈M +

Lout,p (ωo ) = ρdif

+
Np

=

Lin,p (ωi ) cos Np , ωi dωi

[Lin (ωi )(ωix Nx + ωiy Ny + ωiz Nz )]
ωi ∈M +

Lout,p (ωo ) = ρdif Ip (Np ),

(2)

= Nx

[Lin (ωi )ωix ] + Ny
ωi ∈M +

where Ip (Np ) is the Irradiance arrived at the point p from all
directions in the positive hemisphere of p, that is,
Ip (Np ) =

+
Np

Lin,p (ωi ) cos Np , ωi dωi .

(3)

We introduce here a new term, Fullsphere Irradiance (FI),
that differs from the Irradiance equation in that the integral
is over all directions of the sphere Np .
FI p (Np ) =

Lin,p (ωi ) cos Np , ωi dωi ,

(4)

Np

where

Np

denotes all directions over the whole sphere.

Conceptually, the FI differs from the Irradiance, in that
‘we let’ lighting behind the surface of the point p to affect the
value of FI p (Np ). Note that cos Np , ωi may have negative
values.
Assuming distant lighting, light sources become directional and thus the computation of the Irradiance becomes
independent of the position’s coordinates of the receiving
point p. This is the case when the illumination is computed
from an environment map [Deb98]. We will refer to this
environment map, as the lighting environment, Env. For M
discrete directional light sources in the scene, from which
the M + lie in the positive hemisphere of the receiver the
equations of the Irradiance and FI become as below
Ip (Np ) =

[Lin (ωi ) cos Np , ωi ]

(5)

[Lin (ωi ) cos Np , ωi ].

(6)

ωi ∈M +

FI p (Np ) =
ωi ∈M

+ Nz

[Lin (ωi )ωiy ]
ωi ∈M +

[Lin (ωi )ωiz ]
ωi ∈M +

= (Nx , Ny , Nz )

⎧
⎨
⎩

[Lin (ωi )ωix ],
ωi ∈M +

[Lin (ωi )ωiy ],
ωi ∈M +

[Lin (ωi )ωiz ]
ωi ∈M +

Ip (Np ) = Np ∗ IV(EnvM + ),

⎫
⎬
⎭
(8)

where IV(EnvM + ) is the Irradiance Vector of an environment
map or a scene Env with M + light sources lying in the positive
hemisphere of p, similar to the Vector Irradiance used for
radiosity computation in [WHG99, Wil00, LLAP05]. The
Irradiance Vector is a 3-D vector per colour channel. Having
computed the IV(EnvM + ) the Irradiance can be calculated
using only a dot product between the normal of the receiver
Np and the IV(EnvM + ), see Equation (8). However we still
have the issue of determining the M + light sources which
still depend on the orientation of the receiving surface.
To eliminate this constrain of the dependency on the normal of the receiver, we introduce here the term of Fullsphere
Irradiance Vector (FIV). The FIV is similar to the Irradiance
Vector in the same way that the FI is similar to the Irradiance.
That is, in the FIV we consider to the calculation all the light
sources, even those that are in the negative hemisphere of the
receiver.
⎧
⎨
[Lin (ωi )ωix ],
[Lin (ωi )ωiy ],
FIV(EnvM ) =
⎩
ωi ∈M
ωi ∈M
⎫
⎬
[Lin (ωi )ωiz ] .
(9)
⎭
ωi ∈M

c 2010 The Authors
Computer Graphics Forum c 2010 The Eurographics Association and Blackwell Publishing Ltd.

D. Michael & Y. Chrysanthou / Fullsphere Irradiance Factorization

2519

Figure 2: The Irradiance Ip arriving at a point p that lies
under the bunny (left-hand panel), is equal to the total Irradiance Itot,p (middle panel) minus the Irradiance intercepted
by the bunny Iocc,p (right-hand panel).

Figure 3: The total diffuse Irradiance Itot from the whole
environment map, for each possible normal direction Ni of
the receiver (left-hand panel) is precomputed and stored in
a cube texture (right-hand panel).

Note that in the same way we prove the Equation (8), we
can prove that

FIV for the whole environment, FIV(EnvM ), and FIVs for
occluded parts of the environment placing each occluder in
a number of sample positions.

FI p (Np ) = Np ∗ FIV(EnvM ).

(10)

Since FIV does not have any dependency on the normal of
the receiver, FIV for any Env, can be pre-computed once and
be valid for any dynamic receiver.
4. Illumination Using FIVs
4.1. Overview
Irradiance Ip (Np ) at any given point p in the scene can be
computed as the total Irradiance from the whole environment
assuming no occluders in the scene Itot (Np ) minus the Irradiance intercepted by the occluders Iocc,p (Np ) [DSDD07], see
Figure 2.
Ip (Np ) = Itot,p (Np ) − Iocc,p (Np ).

The pre-computed data are used at run time to compute Irradiance Ip (Np ), arriving at each point p of the geometry seen
from each pixel. To evaluate Irradiance Ip (Np ), taking into
account occlusions by other objects, pre-computed values of
Itot,p (Np ) and FIVs are used. In case of self-shadows the FIVs
are used among the FIV(EnvM ) of the whole environment.
In both cases, computation of shadows and self-shadows,
the equality between FI and Irradiance, is used whenever is
valid, see Equation (7), to transform from the notion of FI
for which we have pre-computed information, to the notion
of Irradiance that is what we want to evaluate.
In the next sections, we describe in detail pre-process and
run time stages.

(11)
4.2. Pre-processing

This can be proved as it is shown in the Appendix. In a
similar way we can prove that
FI p (Np ) = FI tot,p (Np ) − FI occ,p (Np ).

At the pre-processing step we have to compute two categories
of data that will be needed at run time:

(12)

Note that FIV(EnvM ) which can be used to calculate
FI tot,p (Np ) is independent of the normal of the receiver since
for any Np we sum up all M light sources of the environment
map. This is not the case for Itot,p (Np ) since in IV(EnvM + ), the
determination of the M + light sources require prior knowledge of Np .
Our algorithm uses the Equations (11) and (12) proved
above, to compute at run time the Irradiance arrived at a
point p of a dynamic receiver, for shadows and self-shadows
respectively. The proposed algorithm has two stages; the
pre-processing and the run time stage. At the pre-processing
we pre-compute values that are independent of the dynamic
parameters of the scene, such as occluders positions and
receivers’ geometry.
Pre-computed data include: Irradiance arriving for each
possible normal direction assuming no occlusion, Itot,p (Np ),

• Total diffuse Irradiance for each sample normal direction,
assuming no occlusion.
• A FIV for a number of environment maps (the Lighting
and Occluded Environment Maps).
In both cases we treat the environment map as a distant
scene [Deb98]. The distant scene is considered far enough
from the objects so its incoming light is seen as directional
and the Irradiance arriving at any point of the local scene is
independent of its absolute position. The Irradiance at a point
is affected though, by the relative position of the other objects
in the scene (local scene), due to shadows. In other words,
each point is illuminated as the whole scene is translated to
place that point, in the origin of the coordinate axes.
For the pre-computation of the total diffuse Irradiance we
create the Diffuse Environment Irradiance Map, (DifMap)
[MH84]. It is stored in an HDR Cube Texture, Figure 3.

c 2010 The Authors
Computer Graphics Forum c 2010 The Eurographics Association and Blackwell Publishing Ltd.

2520

D. Michael & Y. Chrysanthou / Fullsphere Irradiance Factorization

Figure 5: The binary mask denoting the part of the environment map covered by the occluder (left-hand panel) is
ANDed with the environment map (middle panel) to get the
occluded part of the environment map (right-hand panel).

Figure 4: Sample positions of the occluders.

Each texel of the DifMap, stores the total Irradiance Itot,p (Np )
arriving at the surface with normal Np from the lighting environment Env, assuming no occluders in the scene (computed
using Equation 5). The DifMap is indexed by the direction
of the surface normal Np .
The second category of the data pre-computed, FIVs, are
computed using Equation (9), for a number of environment
maps. The FIV(Env) of the lighting environment map Env is
computed and stored in a structure of a 3-D colour vector.
This will be used to evaluate FI tot,p , that is the FI arriving at
a point p from all over the environment Env.
Moreover we compute the FIV of each Occluded Environment Map, EnvOcc. EnvOcc(ϑi ,ϕj ,ρk ) is the environment map
representing the part of the Lighting Environment Map, Env,
occluded by an occluder placed at the position (ϑi , ϕj , ρk )
in spherical coordinates (Figure 5, right-hand panel). An
EnvOcc is computed at a number of sample positions for
each occluder. The sample positions form a dense set (ϑ, ϕ)
around the center of the scene and they are taken in concentric spheres of increasing distance ρ, Figure 4, similar to
[ZHL∗ 05].
To create an Occluded Environment Map, EnvOcc(ϑi ,ϕj ,ρk ) ,
we place the occluder at the sample position (ϑi , ϕj , ρk ) and
compute the binary cube mask that defines the occluded part
of the environment (Figure 5, left-hand panel), similar to
object occlusion field in [ZHL∗ 05]. Using an ‘AND’ boolean
operation, pixel to pixel between environment map (Figure
5, middle panel) and the binary mask we get the part of
the environment map that is occluded by the occluder in the
specific sample position (Figure 5, right-hand panel).
The FIV is computed for each one of the Occluded Environment Maps created. All FIVs(EnvOcc) pre-computed,
are encoded within a floating point 2-D texture, that we call
FIVs texture, Figure 6.

Figure 6: The part of the texture that stores the precomputed FIVs for eight different distance samples for the
bunny in an environment map with one green and one red
area light sources.
4.3. Run time
In order to illuminate our scene, at run time we need to compute the radiance exiting each pixel, Lout,p . Since we assume
only diffuse objects in the scene, the radiance at any pixel
p is equal to the Irradiance Ip (Np ) multiplied by the diffuse coefficient of the material of the receiver, Equation (2).
The run time computation of Ip (Np ) is done using the precomputed values of FIVs, taking into account shadows and
self-shadows as described in the next subsections.
All run time computations have been implemented on GPU
to speed up the computation time. Moreover, the implementation in a fragment shader, allow us to have per pixel illumination.
4.3.1. Shadows
To compute the Irradiance arriving at each pixel Ip (Np )
we sum up the Irradiance occluded Iocc,p by all

c 2010 The Authors
Computer Graphics Forum c 2010 The Eurographics Association and Blackwell Publishing Ltd.

D. Michael & Y. Chrysanthou / Fullsphere Irradiance Factorization

Figure 7: Depending on the relative position of the occluder
with regard to the receiver, there are three different cases
for computing the occluded Irradiance: case A is computed
using the FIV values, case C is totally ignored and case B is
handled as special case.

2521

Figure 8: At border cases only a part of the occluder intercepts Irradiance from the receiver.

the eight nearest samples of the FIVs(EnvOcc) are trilinearly
interpolated.
occluders and deduct it from the total Irradiance, Itot (Np ),
Equation (11).

To get the Itot (Np ), within the pixel shader, we use the normal
(in world coordinates) of the geometry visible through the
pixel, to look up in the cube texture of the Diffuse Environment Irradiance Map.

In case A, the occluder and all the light sources it occludes,
are entirely in the positive hemisphere of the receiver. As a
consequence, based on Equation (7), occluded FI is equal
to occluded Irradiance, FI occ,p (Np ) = Iocc,p (Np ). The computed occluded Irradiance Iocc,p (Np ) is deducted from the
Itot (Np ) to get the Irradiance arriving at the pixel Ip (Np ).
Ip (Np ) is multiplied with the diffuse reflectance coefficient
ρdif of the object. and computed value is used to shade the
pixel.

Occluded Irradiance

Partial Occluders

To get the total occluded Irradiance Iocc,p we sum up the
occluded Irradiance from each object in the scene. Since
we assume a distant lighting environment, we only need to
consider the relative position of each occluder to the receiver.
There are three cases; the occluder may lie fully in the positive
hemisphere of the receiver (Figure 7 case A), partially in the
positive hemisphere (Figure 7 case B) or fully in the negative
hemisphere of the receiver (Figure 7 case C). Cases C, do
not occlude any Irradiance so are completely ignored in the
computations. Cases B are special cases; in the subsection
Partial Occluders we describe how we handle these cases.

In the preceding discussion we estimated the occluded Irradiance using the pre-computed FIV(EnvOcc), under the
assumption that all light sources occluded are in the positive hemisphere of the receiver. However, this is not the case
when an occluder is not fully in the positive half-space of
the receiver, case B in Figure 7. In such cases the use of
FIV(EnvOcc), result in an underestimation of the occluded
Irradiance since the result would correspond to the Irradiance
due to the light sources in the positive hemisphere (marked
with green colour in Figure 8) minus the Irradiance due to the
light sources in the negative hemisphere (marked with orange
colour in Figure 8), IFIV = FI FIV + − FI FIV− . The deduction
of FI FIV for the light sources in the negative hemisphere is
because in these cases the dot product between receiver’s
normal and light direction gives negative value.

Total Irradiance

For the occluders that lie fully in the positive hemisphere of
the receiver (case A), we can compute the occluded Irradiance
using FIVs(EnvOcc). Based on the relative position (in terms
of distance and direction) of occluder from the receiver, we
find the closest sample point and look up the corresponding
FIV(EnvOcc) in the FIVs texture. Knowing the normal of
the receiver, the occluded FI, FI occ,p (Np ), is calculated as
the dot product of the normal Np , with the FIV(EnvOcc),
as defined in Equation (10). To further enhance the results,

The correct value of the occluded Irradiance would be
equal to the occluded FI computed using only FIV + , Figure 8. However, the FIV + can not be pre-computed since it
would rely on a prior knowledge of the receiver’s orientation.
The FIV + can be approximated by scaling the FIV(EnvOcc)

c 2010 The Authors
Computer Graphics Forum c 2010 The Eurographics Association and Blackwell Publishing Ltd.

2522

D. Michael & Y. Chrysanthou / Fullsphere Irradiance Factorization

based on the percentage of the occluder that lies in the positive hemisphere over p. The percentage of the occluder in
the positive hemisphere, is approximated with (d + R)/2R,
at run time in a similar way that Malmer et al [MMAH07]
do at their pre-processing step; d is the distance of the centre of the occluder from the plane of the receiver and R
is the radius of the bounding sphere of the occluder. We
count as occluded Irradiance Iocc,p (Np ) the approximation
of FI FIV+ . The fact that the Irradiance is cosine weighted
minimizes any error, that may occur by the approximation,
Figure 17.

Multiple Occluders
In scenes with multiple occluders, pixels are shadowed by
more than one occluder. In cases where two occluders hide
a common part of the environment, the Irradiance occluded
by the overlapping part, should be deducted only once from
the total Irradiance. For clarity in the description, we explain
in this section how we handle cases only of two overlapped
occluders. The same concept can be used for an arbitrary
number of overlapped occluders.

Figure 9: The occlusion part of overlapping occluders is
taken into account only once.

Occluded Irradiance by two overlapping occluders Iocc,p
at the receiving point p, is equal to the summation of the
occluded Irradiance by each individual occluder Ioccluderi ,p
minus the occluded Irradiance by the overlapped part of the
two occluders, Ioverlapped,p .
Iocc,p = Ioccluder1 ,p + Ioccluder2 ,p − Ioverlapped,p .

(13)

The occluded Irradiance by each occluder, Ioccluderi ,p , is
computed as described at the Section 4.3.1. The occluded
Irradiance of the overlapping part is approximated as the
percentage Overlapped% of the area of the overlapping part
Areaoverlapped , over the summation of the area of the parts covered by the two occluders Areaoccluderi , of the total Irradiance
occluded by the two.
Overlapped% =

Areaoverlapped
Areaoccluder1 + Areaoccluder2

Ioverlapped,p = Overlapped% ∗ (Ioccluder1 ,p + Ioccluder2 ,p ).
(14)
The area covered by each occluder, Areaoccluderi , is approximated as the area of the Unit Bounding Disc of the
occluder. We define the Unit Bounding Disc as the disc centred along the line formed by the centre of the bounding
sphere of the occluder and point p, and translated in the
space (perpendicular to the surface of p), such as to be away
from the point p a unit distance. The overlapping area of the
two occluders Areaoverlapped , is approximated by the crescent
formed by the overlapping of the two Unit Bounding Discs,
Figure 9.

Figure 10: In case of self-shadows, all the unoccluded part
of the environment EnvUnocc, always lies in the positive
hemisphere of the receiving point.

4.3.2. Self-shadows
Self-shadows are also computed using FIVs. Note that in case
of self-shadows, all unoccluded light sources, definitely lie
in the positive hemisphere of the receiving pixel p. This is
the main difference from the case of the shadows, where
all occluded light sources lie in the positive hemisphere,
and not the unoccluded. This is because in case of selfshadows all light sources in the negative half space of the
receiving point p, are occluded at least from the surface that
p lies on. Figure 10 shows with dotted red line, the part of
the environment map that the object does not self-occlude,
EnvUnocc.
Exploiting the fact that all unoccluded light sources EnvUnocc which contribute to the illumination, are in the positive hemisphere of the receiving point p, based on Equation (7), the Irradiance at a point p is equal to the FI at that
point, Ip (Np ) = FI p (Np ).

c 2010 The Authors
Computer Graphics Forum c 2010 The Eurographics Association and Blackwell Publishing Ltd.

2523

D. Michael & Y. Chrysanthou / Fullsphere Irradiance Factorization
Table 1: Pre-computation times and memory requirements for different objects at various sampling rates.

Object

Vertices

Samples

Precmp
(min)

Memory
(MB)

35 947

256 × 129 × 30
128 × 65 × 30
64 × 33 × 30
64 × 33 × 15
32 × 17 × 15

397
99
24
12
3

34.0
8.56
2.17
1.08
0.28

256 × 129 × 30

222

34.0

Bunny

Tree

20 614

FI p (Np ) is computed by deducting occluded FI
FI occ,p (Np ) from the total FI, Equation (12). FI tot,p (Np ) is
the same for all Np and has been computed once and stored
at the pre-processing. Thus, we don’t have to do anything
else than just use the pre-computed value.
To compute FI occ,p (Np ) we use the nearest sample of FIV
pre-computed with a dot product with the normal of the
receiver Np , Equation (10). In the same way as in case of
shadows, we trilinearly interpolate up to 8 nearest samples
of FIVs. Samples that fall within the geometry of the object
are not taken into account.

5. Results
The results were taken on an Intel Core 2 Duo 2.4 GHz
machine, with 2GB Ram and an NVIDIA GeForce 8800
GTS graphics card. A CPU implementation was used for the
pre-computations and a GPU implementation for run time
calculations. All images were taken with a window resolution
of 512 × 512, with trilinear interpolation of the FIVs values
and per pixel illumination. The resolution of environment
maps used for illumination are 6 × 32 × 32 pixels. The FIVs
are computed considering the whole environment map and
not only samples on it. Using a higher resolution environment
map would have caused longer pre-computation times but no
difference at the run time frames per second.
In Table 1, we show the pre-computation statistics for the
individual objects used in our experiments. We demonstrate
the results of objects with different complexity with regards
to the number of vertices, (column Vertices), and their type of
geometry. The Precmp column shows the time, in minutes,
needed to pre-compute the FIVs. Computation of the Diffuse
Environment Irradiance Map takes approximately about 1
minute. Here it is worth noting that our pre-computation was
computed entirely on CPU. A GPU implementation would
run considerably faster. As expected, the table indicates that
the pre-computation time is linear to the number of sample
points. Under the Memory column we show the memory
usage in MBytes. Memory needed to store the precomputed

Table 2: Statistics for combinations of objects for constant samples
(ϑ, ϕ, ρ) = (128,65,30) .

Scene
1 bunny
1 tree
10 bunnies
10 trees
5 × (bunny + tree)
10 × (bunny + tree)
15 × (bunny + tree)
20 × (bunny + tree)
30 × (bunny + tree)

Objects

Vertices

Memory
(MB)

FPS

1
1

35 947
20 614

8.56
8.56

112
112

10
10
10
20
30
40
60

359 470
206 140
282 805
565 610
848 415
1 131 220
1 696 830

8.56
8.56
17.12
17.12
17.12
17.12
17.12

68
68
68
46
35
29
22

values is also linear to the sample points that were used and
independent of the complexity of the object. This is illustrated
by the fact that any object needs the same memory capacity
for constant number of samples.
Table 2 shows the statistics for combinations of different objects. The Objects and Vertices columns show the total
number of objects and number of vertices in the scene. Memory needed, is increased linearly with the number of different
objects in the scene but having multiple times the same object does not increase the memory requirements. Frames per
second (shading only) depend only on the number of objects but not on their type, as it is illustrated by the different
scenes with 10 objects. FPS demonstrate that the proposed
method, scales well and achieves real-time frame rates even
for complex scenes with millions of vertices and tenths of
occluders.
Note that run time frames per second (FPS), are independent of the number of sample points used, and independent of
the complexity of objects. This allows us to increase the realism in the scene by using high quality models and a dense
FIV sample set without additional cost at run time for the
illumination process.
Figures 12 and 13 demonstrate the quality of the results
of the proposed technique. The three small images at the
bottom show: the shadow on the ground plane using the proposed method (left), the shadow using the reference (brute
force) solution (middle) and the difference of the two images (right). The difference image is displayed with high
exposure thus pixels even with small error can be noticeable.
The reference solution has been evaluated using the standard
rendering formula, Equation (2), with an overall integration
of the unoccluded part of the environment map as it is seen
from each pixel. A numerical evaluation of the difference of
the two shadow images (proposed technique and reference
solution), is given using the Normalized Root Mean Square
Error (NRMSE).

c 2010 The Authors
Computer Graphics Forum c 2010 The Eurographics Association and Blackwell Publishing Ltd.

2524

D. Michael & Y. Chrysanthou / Fullsphere Irradiance Factorization

it is hard for a viewer to perceive the difference with the
reference solution.
Figure 14 demonstrates that the algorithm works not only
for symmetric (or almost symmetric) environment maps. Figure 14 (left-hand panel), shows the shadow of one occluder
of an environment map with one green and one red area light
sources, and Figure 14 (right-hand panel) shows overlapping
shadows from two occluders using the same environment
map.

Figure 11: An object (bunny) may act as both occluder and
receiver. The bunny as a receiver (left-hand panel) has shadows cast on it, in contrast to the bunny (right-hand panel)
which act only as an occluder.
Figure 12 shows how the number of sample points used to
pre-compute FIVs affect the quality of the images. As it was
expected, increasing number of the sample points reduces
the error. However, even with few samples, the NRMSE is
only 0.023 as it is shown in Figure 12 (left-hand panel).
Note that for this image, 3 min for pre-computation step and
0.28 MBytes of memory for the FIVs are enough for a good
quality result, see Table 1.
Figure 13 demonstrates that our technique can handle all
frequency environment maps; one directional light source
(left), two area light sources (middle), Eucalyptus Grove environment map (right). The error (NRMSE) varies based on
the type of environment map, from 0.1 in case of one directional light to only 0.022 in case of the Eucalyptus Grove
environment map. Even for the one directional light source
that has the highest NRMSE (mainly because of aliasing),

The same object may act both as an occluder and as a
receiver at the same time, see the bunny in Figure 11 (lefthand panel). A receiver may be shadowed by more than one
occluder. Note that in Figure 11 (left-hand panel), the plane
is shadowed by the tree and the bunny.
Figure 17 demonstrates that our method works also well
for the cases that the occluder does not lie fully in the positive
hemisphere of the receiver. Figure 17 (left-hand panel) shows
the results using the standard proposed algorithm that uses
the values of FIVs as they pre-computed. The right-hand
panel of the Figure 17, shows the results using the modified
algorithm for the partial occluder as described in the relevant
subsection. In the latter case the error is minimized to only
0.019.
Multiple occluders are also handled by our proposed technique. Figure 15 shows that the error is minimized when the
common occluded part by the overlapped occluders, is taken
into account only once (correction enabled). Results, for different conditions in the scene with multiple occluders, are
demonstrated in the Figure 16.
Self-shadows results are demonstrated in the Figure 18.
The left-hand panel shows illumination without considering
any self-occlusions, the middle panel is the illuminated object

Figure 12: The bunny at different sampling rates (ϑ, ϕ, ρ): Samples = (32,17,15) (NRMSE = 0.023) (left-hand panel),
Samples = (64,33,30) (NRMSE = 0.008) (middle panel), Samples = (256,129,30) (NRMSE = 0.007) (right-hand panel). The
small images show the shadow only of the result of the proposed technique (left), the ground truth shadow (middle) and the
difference of the two (right).
c 2010 The Authors
Computer Graphics Forum c 2010 The Eurographics Association and Blackwell Publishing Ltd.

D. Michael & Y. Chrysanthou / Fullsphere Irradiance Factorization

2525

Figure 13: All-frequency environment maps can be used with our technique: one directional light (NRMSE = 0.1) (left-hand
panel), two area light sources (NRMSE = 0.035) (middle panel), Eucalyptus Grove Environment Map(NRMSE = 0.022)
(right-hand panel).

Figure 14: Illumination from area lights of different colour: one occluder (NRMSE = 0.019) (left-hand panel), two occluders
with overlapping shadows (NRMSE = 0.019) (right-hand panel).

with self-shadows, and the right-hand panel is the difference
of the two previous, showing the shadow isolated from the
object.

6. Conclusions and Future Work

the complexity of the occluders do not affect the computations for illumination at run time. Our technique requires
only moderate memory and relative fast computations at preprocessing step. Our method can run in real-time for very
complex scenes, Figure 20, with low measured error, Figures 12, 13, 16 and 17.

The proposed method can compute diffuse illumination with
soft-shadows for fully dynamic receivers, Figure 19, moving
occluders and all frequency environment maps at real-time
frame rates. Frame rate and memory requirements are independent of the number of light sources and the number
of vertices of the occluders. Frame rate depends only on
the number of occluders in the scene while the memory requirements depends on the number of sample points used
and the different type of objects in the scene. The size and

The main contribution of our technique is the factorization
of a new notion that we introduce, the FI. The factorization
allows us to pre-compute and store in only a 3-D colour vector, the contribution to illumination from an arbitrary number
of light sources on a reference base system, without requiring
the receiver’s normal in advance. The pre-computed values
can be transformed, in a very fast way (using only a dot product), to the Irradiance arriving from the light sources, once
the receiver and it’s normal is known.

c 2010 The Authors
Computer Graphics Forum c 2010 The Eurographics Association and Blackwell Publishing Ltd.

2526

D. Michael & Y. Chrysanthou / Fullsphere Irradiance Factorization

Figure 15: Illumination of multiple occluders: Correction for multiple occluders is disabled (NRMSE = 0.027) (left-hand
panel), enabled (NRMSE = 0.019) (right-hand panel).

Figure 16: Illumination of multiple occluders using different parameters: one area light source (NRMSE = 0.019) (left-hand
panel), Eucalyptus Grove environment map (NRMSE = 0.015) (middle panel), occluders in shorter distance (NRMSE = 0.013)
(right-hand panel).

The main limitation of our technique stems from the fact
that the pre-computed values of FIVs encode the environment
map information, rendering our technique applicable only for
scenes with static light sources.
Another limitation is that occluders can only be moved
in the space, but they can not rotate, since the placement
at sample points of the occluder at the pre-processing, define the occluded light sources for which their contribution

is encoded within the FIV. This limitation can be eliminated by taking samples, not only at different positions of
each occluder, but with different rotations as well. However, this solution will make the pre-computation more
expensive and increase the memory requirements of the
algorithm.
The proposed method currently only accounts for diffuse reflectance. Consideration of the specular reflection

c 2010 The Authors
Computer Graphics Forum c 2010 The Eurographics Association and Blackwell Publishing Ltd.

D. Michael & Y. Chrysanthou / Fullsphere Irradiance Factorization

2527

component would increase the realism of the illumination. However, it does not seem to be a straightforward
way to do that using only the factorization, so an extension to the algorithm should be developed to count for
specularities.

Figure 17: The queen lies at 15 in the negative half space
of the receiver. Illumination of the receiver having the correction for partial occluders disabled (NRMSE = 0.026)
(left-hand panel) and enabled (NRMSE = 0.019) (right-hand
panel). Small images show the difference of the corresponding result with the reference solution.

Another way that the algorithm can be improved is the
elimination of pre-computation step. Online computations of
FIVs can be computed only at samples needed (i.e. a receiving point exists), reducing the total time needed to compute
the FIVs. Using a GPU implementation we speculate that
computations of FIVs at run time, at least at interactive rates,
is feasible. For run time computation of the Diffuse Irradiance Environment Map the proposed technique of [RH01]
can be used. By having no pre-computations, we will be
able to have fully dynamic conditions such as deformable
occluders and dynamic lighting conditions.

Figure 18: Self-shadows are also computed at run time using pre-computed FIVs. Only direct illumination without considering
self-occlusions (left-hand panel), direct illumination and self-shadows (middle panel), isolated self-shadows (right-hand panel).

Figure 19: Illumination of a fully dynamic (deformable) receiver in two different times in left- and right-hand panels.
c 2010 The Authors
Computer Graphics Forum c 2010 The Eurographics Association and Blackwell Publishing Ltd.

2528

D. Michael & Y. Chrysanthou / Fullsphere Irradiance Factorization

Techniques 2006: 17th Eurographics Workshop on Rendering (Nicosia, Cyprus, June 2006), pp. 227–234.
[HLHS03] HASENFRATZ J., LAPIERRE M., HOLZSCHUCH N.,
SILLION F.: A survey of real-time soft shadows algorithms.
Computer Graphics Forum 22, 4 (2003), 753–774.
[IDYN07] IWASAKI K., DOBASHI Y., YOSHIMOTO F., NISHITA T.:
Precomputed radiance transfer for dynamic scenes taking
into account light interreflection. In Rendering Techniques
2007: 18th Eurographics Workshop on Rendering (Grenoble, France, June 2007), pp. 35–44.
[KK03] KOLLIG T., KELLER A.: Efficient illumination by high
dynamic range images. In Eurographics Symposium on
Rendering: 14th Eurographics Workshop on Rendering
(Leuven, Belgium, June 2003), pp. 45–51.

Figure 20: Complex scenes can be shaded in real-time. This
scene with multiple objects and more than 280K thousands
vertices is shaded at 68 fps.
Acknowledgments
We would like to thank Kadi Bouatouch, Isabelle Chrysanthou, Daniel Cohen-Or, Dani Lischinski and Evangelia
Samiou for their help over various periods of the project.
References
[ADM*08] ANNEN T., DONG Z., MERTENS T., BEKAERT P.,
SEIDEL H.-P., KAUTZ J.: Real-time, all-frequency shadows
in dynamic scenes. ACM Transactions on Graphics (Proceedings of SIGGRAPH 2008) 27, 3 (2008), 34:1–34:8.
[Deb98] DEBEVEC P.: Rendering synthetic objects into real
scenes: Bridging traditional and image-based graphics
with global illumination and high dynamic range photography. In Proceedings of SIGGRAPH 98 (1998), Computer Graphics Proceedings, Annual Conference Series,
pp. 189–198.
[DSDD07] DACHSBACHER C., STAMMINGER M., DRETTAKIS G.,
DURAND F.: Implicit visibility and antiradiance for interactive global illumination. ACM Transactions on Graphics (Proceedings of SIGGRAPH 2007) 26, 3 (2007),
61:1–61:10.
[Eve00] EVERITT C. W.: High-Quality, HardwareAccelerated Per-Pixel Illumination for Consumer
Class OpenGL Hardware. Master’s thesis, Mississippi
State University, Mississippi State, Mississippi, May
2000.
[GBP06] GUENNEBAUD G., BARTHE L., PAULIN M.: Real-time
soft shadow mapping by backprojection. In Rendering

[KL05] KONTKANEN J., LAINE S.: Ambient occlusion fields.
In Proceedings of ACM SIGGRAPH 2005 Symposium on
Interactive 3D Graphics and Games (Washington, DC,
2005), ACM Press, pp. 41–48.
[KLA04] KAUTZ J., LEHTINEN J., AILA T.: Hemispherical rasterization for self-shadowing of dynamic objects. In Rendering Techniques 2004: 15th Eurographics Workshop on
Rendering (Nork¨oping, Sweden, June 2004), pp. 179–184.
[KSS02] KAUTZ J., SLOAN P.-P., SNYDER J.: Fast, arbitrary
brdf shading for low-frequency lighting using spherical
harmonics. In Rendering Techniques 2002: 13th Eurographics Workshop on Rendering (Pisa, Italy, June 2002),
pp. 291–296.
[LLAP05] LECOT G., L´evy B., ALONSO L., PAUL J.-C.:
Master-element vector irradiance for large tessellated
models. In GRAPHITE ’05: Proceedings of the 3rd International Conference on Computer Graphics and Interactive Techniques in Australasia and South East Asia
(Dunedin, New Zealand, 2005), pp. 315–322.
[LSSS04] LIU X., SLOAN P.-P., SHUM H.-Y., SNYDER J.: Allfrequency precomputed radiance transfer for glossy objects. In Rendering Techniques 2004: 15th Eurographics
Workshop on Rendering (Nork¨oping, Sweden, June 2004),
pp. 337–344.
[MH84] MILLER G. S., HOFFMAN C. R.: Illumination and reflection maps: Simulated objects in simulated and real environments. Course Notes for Advances Computer Graphics Animation, SIGGRAPH 1984 (Minneapolis, Minnesota, July 1984).
[MMAH07] MALMER M., MALMER F., ASSARSSON U.,
HOLZSCHUCH N.: Fast precomputed ambient occlusion for
proximity shadows. Journal of Graphics Tools 12, 2
(2007), 57–71.

c 2010 The Authors
Computer Graphics Forum c 2010 The Eurographics Association and Blackwell Publishing Ltd.

2529

D. Michael & Y. Chrysanthou / Fullsphere Irradiance Factorization

[MSW04] MEI C., SHI J., WU F.: Rendering with spherical
radiance transport maps. Computer Graphics Forum 23, 3
(2004), 281–290.
[NRH04] NG R., RAMAMOORTHI R., HANRAHAN P.: Triple
product wavelet integrals for all-frequency relighting.
ACM Transactions on Graphics (Proceedings of SIGGRAPH 2004) 23, 3 (2004), 477–487.
[OCL96] OUHYOUNG M., CHUANG Y.-Y., LIANG R.-H.:
Reusable radiosity objects. Computer Graphics Forum 15,
3 (1996), 347–356.
[RH01] RAMAMOORTHI R., HANRAHAN P.: An efficient representation for irradiance environment maps. In Proceedings
of ACM SIGGRAPH 2001 (Los Angeles, CA, USA, 2001),
Computer Graphics Proceedings, Annual Conference Series, pp. 497–500.
[RWS*06] REN Z., WANG R., SNYDER J., ZHOU K., LIU X.,
SUN B., SLOAN P.-P., BAO H., PENG Q., GUO B.: Real-time
soft shadows in dynamic scenes using spherical harmonic
exponentiation. ACM Transactions on Graphics (Proceedings of SIGGRAPH 2006) 25, 3 (Boston, MA, USA, July
2006), 977–986.

Appendix A: Proofs from Section 4.1
Proof of the Equation (11):
M +:

The set of all light sources in the scene
in the positive hemisphere of the receiver

+
Mocc
:

The set of occluded light sources
in the positive hemisphere of the receiver

+
Munn
:

The set of unoccluded light sources
in the positive hemisphere of the receiver

+
+
M + = Mocc
∪ Munn
,

Itot,p =
Iocc,p =

[WHG99] WILLMOTT A. J., HECKBERT P. S., GARLAND M.:
Face cluster radiosity. In Rendering Techniques 1999: 10th
Eurographics Workshop On Rendering (Granada, Spain,
June 1999), pp. 293–304.
[Wil00] WILLMOTT A. J.: Hierarchical Radiosity with Multiresolution Meshes. PhD thesis, Computer Science,
Carnegie Mellon Univerity, 2000.
[ZHL*05] ZHOU K., HU Y., LIN S., GUO B., SHUM H.-Y.: Precomputed shadow fields for dynamic scenes. ACM Transactions on Graphics (Proceedings of SIGGRAPH 2005)
24, 3 (2005), 1196–1201.

[Lin (ωi ) cos Np , ωi ]
+
ωi ∈Mocc

Proof:
Ip (Np ) =

[Lin (ωi ) cos Np , ωi ]
+
ωi ∈{Munn
}

=

[Lin (ωi ) cos Np , ωi ]
+
ωi ∈{M + −Mocc
}

=

[Lin (ωi ) cos Np , ωi ]
ωi ∈M +

[Slo06] SLOAN P.-P.: Normal mapping for precomputed radiance transfer. In Proceedings of ACM SIGGRAPH 2006
Symposium on Interactive 3D Graphics and Games (Los
Angeles, CA, USA, 2006), ACM Press, pp. 23–26.

[SS08] SCHWARZ M., STAMMINGER M.: Quality scalability of
soft shadow mapping. In Graphics Interface 2008 (Ontario, Canada, May 2008), pp. 147–154.

[Lin (ωi ) cos Np , ωi ]
ωi ∈M +

[SKS02] SLOAN P.-P., KAUTZ J., SNYDER J.: Precomputed radiance transfer for real-time rendering in dynamic, lowfrequency lighting environments. ACM Transactions on
Graphics (Proceedings of SIGGRAPH 2002) 21, 3 (2002),
527–536.

[SM06] SUN W., MUKHERJEE A.: Generalized wavelet product integral for rendering dynamic glossy objects. ACM
Transactions on Graphics (Proceedings of SIGGRAPH
2006) 25, 3 (Ontario, Canada, 2006), 955–966.

+
+
Mocc
∩ Munn
=∅

−

[Lin (ωi ) cos Np , ωi ]
+
ωi ∈Mocc

Ip (Np ) = Itot,p (Np ) − Iocc,p (Np )
Proof of the Equation (12):
Note that using the following:
M:

The set of all light sources in the scene
in both hemispheres of the receiver

Mocc :

The set of occluded light sources
in both hemispheres of the receive

Munn :

The set of unoccluded light sources
in both hemispheres of the receiver

M = Mocc ∪ Munn ,

Mocc ∩ Munn = ∅

we can prove in a similar way we used to prove Equation (11),
that:
FI p (Np ) = FI tot,p (Np ) − FI occ,p (Np ).

c 2010 The Authors
Computer Graphics Forum c 2010 The Eurographics Association and Blackwell Publishing Ltd.

