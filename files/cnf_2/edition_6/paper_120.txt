DOI: 10.1111/j.1467-8659.2009.01674.x
Eurographics/ IEEE-VGTC Symposium on Visualization 2010
G. Melançon, T. Munzner, and D. Weiskopf
(Guest Editors)

Volume 29 (2010), Number 3

Multi-layer Depth Peeling by Single-Pass Rasterisation for
Faster Isosurface Raytracing on GPUs
Baoquan Liu, Gordon J. Clapworthy and Feng Dong
Department of Computer Science and Technology, University of Bedfordshire, UK

Abstract
Empty-space skipping is an essential acceleration technique for volume rendering. Image-order empty-space skipping is not well suited to GPU implementation, since it must perform checks on, essentially, a per-sample basis,
as in kd-tree traversal, which can lead to a great deal of divergent branching at runtime, which is very expensive
in a modern GPU pipeline. In contrast, object-order empty-space skipping is extremely fast on a GPU and has
negligible overheads compared with approaches without empty-space skipping, since it employs the hardware unit
for rasterisation. However, previous object-order algorithms have been able to skip only exterior empty space and
not the interior empty space that lies inside or between volume objects.
In this paper, we address these issues by proposing a multi-layer depth-peeling approach that can obtain all of the
depth layers of the tight-fitting bounding geometry of the isosurface by a single rasterising pass. The maximum
count of layers peeled by our approach can be up to thousands, while maintaining 32-bit float-point accuracy,
which was not possible previously. By raytracing only the valid ray segments between each consecutive pair of
depth layers, we can skip both the interior and exterior empty space efficiently.
In comparisons with 3 state-of-the-art GPU isosurface rendering algorithms, this technique achieved much faster
rendering across a variety of data sets.
Categories and Subject Descriptors (according to ACM CCS):
Generation—Viewing Algorithms

1. Introduction

In this paper, we accelerate GPU based isosurface raytracing by applying multi-layer depth peeling using only a single
hardware rasterising pass, during which we determine all of
the depth layers of the tight-fitting bounding geometry of
the isosurfaces. The maximum number of layers peeled by
our approach can be in the thousands with the depth of each
layer recovered in 32-bit float-point format (fp32), which is
sufficiently accurate to cover all the valid ray segments and
ensure that no details of the isosurfaces are missed in the
subsequent raytracing.

Isosurface rendering is a simple and effective approach for
visualising distinct objects present in the data. It displays a
surface representing the locus of a collection of points in the
volume that correspond to a given isovalue (i.e. greyscale intensity in the data). Isosurface rendering is used by domain
experts, such as doctors, to visualise the exact boundaries of
materials with complex shapes, such as skin, skull or perhaps a tumour. It must be accurate, as they are frequently
interested in viewing details in close up. It must also be fast
because, when they are investigating the data and seeking
to create the precise isosurface they require, the interaction
will demand that frequent changes of the isovalue are made
at runtime. In this context, methods that employ costly precomputation to build complex acceleration structures, such
as kd-trees [VMD08], which become invalid and need to be
rebuilt whenever the isovalue is changed, are generally less
efficient than methods that perform calculations on the fly.
c 2010 The Author(s)
Journal compilation c 2010 The Eurographics Association and Blackwell Publishing Ltd.
Published by Blackwell Publishing, 9600 Garsington Road, Oxford OX4 2DQ, UK and
350 Main Street, Malden, MA 02148, USA.

I.3.3 [Computer Graphics]: Picture/Image

Our major contribution is that (to our knowledge) this is
the first method that makes it possible to peel thousands of
depth layers by a single hardware rasterisation pass (comparing with the existing methods that can peel at most 32 layers
per pass). The resulting layers are used to accelerate GPU
raycasting to a degree that has not been possible previously.
More detailed contributions are given below:
1. We employ the hardwired rasterisation unit (a special-

1231

1232

2.

3.

4.

5.

Baoquan Liu et al. / Multi-layer Depth Peeling by Single-Pass Rasterisation for Faster Isosurface Raytracing on GPUs

purpose fixed-function component on the GPU) to rasterise the active cells (i.e. those through which the isosurface passes) and generate bitmasks to indicate the boundary layers.
We accurately reconstruct all of the depth layers (in fp32
format) from the bitmasks. The resulting layers generate
depth intervals bordered by two consecutive depth layers,
which define all of the valid ray segments. By tracing rays
only within these ray segments, we can efficiently skip
both the interior and exterior empty space.
To decrease the number of the ray segments, we merge
runs of set bits in a bitmask into a bit-segment (with two
borders) using a texture lookup, which is much more efficient than performing bit counting in the fragment shader.
Our method is well suited for transparent rendering of
multiple isosurface-layers as all of the generated valid ray
segments are in front-to-back order, so accurate transparent blending is straightforward.
Array texture is used for the first time for depth peeling,
and hence our output per fragment is very slim (only two
bytes), thus avoiding profligacy with memory bandwidth,
unlike previous approaches that have used extremely fat
frame buffers, i.e. multiple rendering target (MRT), and
hence need to output 128 bytes per fragment.

2. Related Work
2.1. Empty space skipping
Empty-space skipping is an essential acceleration technique
for volume rendering, which typically employs either an
image-order or an object-order approach (we refer the reader
to [HLSR09] for a comprehensive survey).
Vidal et al. [VMD08] used kd-trees, built on the CPU in
a preprocessing stage, to remove empty space. This stage
consumes about 4 seconds for 5123 data sets and must be repeated whenever the transfer function or isovalue is changed.
As a result, this approach is not suitable for dynamic data exploration. Recently, Hughes et al. [HL09] implemented KdJump, a GPU-based kd-tree scheme for isosurface raytracing. A change in isovalue requires an update of every node
of their kd-tree at every level, starting from the original volume itself; this takes 0.25 seconds for 5123 volumes with a
CUDA implementation.
Many previous researchers have sought to shorten the
ray length by applying object-order empty-space skipping
to improve GPU raycasting performance [KW03, HLSR09,
LCD09a]. However these algorithms generally skip only exterior, but not interior, empty space. The work in [LCD09b]
skipped some interior empty space but it ray-traced each active cell independently of the others. As a result, it produces
many overlapping ray segments, which are redundantly raytraced over and over again by different cells. Polygon Assisted Ray Casting (PARC) was proposed in [SA95] to accelerate volume raytracing, where the rectangular polygons

were rasterized so that the CPU-based cell-by-cell stepping
algorithm can avoid evaluating empty cells.
2.2. Depth peeling
The use of depth peeling [Eve01] makes it possible to handle complex geometries with many depth layers. In the context of GPU-based volume rendering, depth peeling has been
used on the bounding geometries of multi-volumes to generate all of the individual depth layers for CSG operations
[RBE08]. Unfortunately, depth peeling requires O(N) geometry rasterisation passes and O(N) depth comparisons per
pass, leading to a total complexity O(N 2 ), where N is the
depth complexity (the total number of layers) of the geometries. The N passes of rasterisation makes this approach unsuitable for real-time applications with complex geometries.
Peeling multiple layers by a single GPU rasterisation pass
was first proposed by Liu et al. [LWX06]. Other algorithms
followed, including K-buffer [BCL∗ 07], stencil routed Abuffer [MB07] and dual depth peeling [BM08], but all of
these can peel at most 8 layers per pass. Recently, Liu et
al. [LHLW09a] made it possible to peel up to 32 layers per
pass, but this method always produces errors when any two
layers are located close together. This potential error is acceptable for approximate rendering, as needed for games,
but not for medical applications, which require that no detail of the geometry should be missed. Another drawback is
that this method solves the multi-pass issue by profligate use
of bandwidth as it uses extremely fat frame buffers (MRT),
with 128 bytes having to be output for each fragment.
Recently Liu et al. [LHLW09b] proposed single-pass
depth peeling via a CUDA rasteriser. This leaves the hardware rasterising unit idling, and instead uses a software rasteriser, which makes extensive use of atomic operations in
global memory. It is also necessary to sort the rasterised fragments explicitly, which could become a bottleneck when the
depth complexity of the geometry is high. The maximum
layer count tested in their experiments was only 15.
Recent GPU-based binary voxelisation algorithms [ED06,
ED08] provide better performance than depth peeling, but
they derive only a binary boundary voxelisation. This works
well for approximating volumetric effects, but its binary
representation of each layer is insufficient for applications
that need full fp32 precision for each depth value, which
depth peeling can accomplish gracefully. Another drawback
is their use of MRT which, as mentioned previously, means
that 128 bytes must be output per rasterised fragment.
3. Algorithm Overview and Flowchart
In the context of isosurfacing, volume datasets tend to be
rather sparse, with many inactive voxels; these occupy much
of the total volume but make no contribution to the isosurface. Previous object-order algorithms [HLSR09, LCD09a]
c 2010 The Author(s)
Journal compilation c 2010 The Eurographics Association and Blackwell Publishing Ltd.

Baoquan Liu et al. / Multi-layer Depth Peeling by Single-Pass Rasterisation for Faster Isosurface Raytracing on GPUs

have used only two layers (the front-most and back-most
faces) of some bounding geometries to set up rays, which is
normally too coarse. Also, they can only skip exterior empty
space but not the interior empty space lying within or between multiple volume objects, as shown in Figure 1. Our
method overcomes these problems by rasterising the active
cells and generating an accurate series of valid ray segments,
and it is only along these that GPU raycasting is performed.

A1

0 1

A3

A2

B1

B2
2

3

A4

4.1. Stage 1 - active cell extraction
We define active cells as in the Marching Cubes (MC) algorithm [LC87]. From a 3D grid of N × M × L scalar-value
voxels, we form a grid of (N − 1) × (M − 1) × (L − 1) cubeshaped MC cells between the scalar values such that each
corner of the cube corresponds to a scalar-value voxel. We
maintain a regular grid of min-max values of enclosed voxels of each cell, which will be used to determine whether a
cell is active or not by testing if the isovalue is within the
range defined by the min-max pair of the cell.
Whenever the isovalue changes, we build a HistoPyramid
texture [ZTTS06] in order to extract all of the active cells
and skip all of the inactive cells, as in [LCD09b].

B3

4

5 6

B4
7 8 9 10 11

Figure 1: The active cells (red) enclose some isosurfaces (blue).
For the upper ray, A, our approach generates 2 valid ray segments
−−→
−−→
in near-to-far order: A1 A2 and A3 A4 ; while for the lower ray, B, our
−−→
approach generates 2 valid ray segments in the same order: B1 B2
−−→
and B3 B4 . Previous object-order algorithms, which used only the
first-hit and last-hit points, generated one coarse ray segment per
−−→
−−→
ray, that is A1 A4 and B1 B4 for rays A and B, respectively, as a result
−−→
−−→
they cannot skip interior empty space, such as A2 A3 and B2 B3 .

active cell
extraction

1233

single pass
rasterisation

histo-pyramid
texture

depth recovery and
raycasting pass

bitmasks in
array texture

final
image

Figure 2: A schematic view of the algorithm. Black arrows designate control flow, and green arrows designate data flow with the
ellipses standing for the textures or images in video memory.
Figure 2 shows a flowchart of our algorithm, which involves three stages. In the first stage, as soon as the isovalue
is changed, we identify and extract all of the active cells on
the GPU. In the second stage, we rasterise only these extracted cells as point primitives; for each fragment generated, we output a bitmask indicating the position of the active
cell. The resulting bitmasks are routed into an array texture,
which is used in the third stage, a full screen GPGPU pass,
to recover all of the depth layers (in fp32 format) and cast
rays only for the valid ray segments bordered by consecutive depth layers. In this way, we can skip both the interior
and exterior empty space efficiently.
4. Implementation Details
In the following subsections, we shall provide greater detail
about the 3 individual stages.
c 2010 The Author(s)
Journal compilation c 2010 The Eurographics Association and Blackwell Publishing Ltd.

4.2. Stage 2 - rasterisation pass
Most previous algorithms [SA95,HQK05,HLSR09] handled
each cell as a cube with up to 12 triangle primitives and rasterised the boundary faces of the cubes in several rendering
passes. In these cube-based approaches, rasterising a tightly
fitting bounding geometry involves many more vertex and
geometry operations than for the point-based primitive used
in [LCD09b], which handles only one primitive per cell with
only one vertex operation and no need for primitive assembly or vertex connection. We thus employ this latter technique to rasterise each active cell as a point primitive, which
leads to a round disk in the screen covering all of the pixels
on to which the cell can project, e.g. the projection of the
two cells shown in Figure 4.
Our active cell extraction and projection approaches are
similar to [LCD09b], with the significant difference that, for
each rasterised fragment, we output a 16-bit bitmask into a
layered frame buffer (array texture) by using the geometry
shader to route the projection of a cell into a certain layer of
the array texture according to the position of the cell. This
is known as layered rendering, in which a 2D array texture
(essentially a 3D texture consisting of a stack of 2D texture
slices) is bound to a frame buffer object. In contrast to the
use of MRTs, in which each fragment generated by OpenGL
outputs multiple copies of RGBA, layered rendering provides the freedom to route the output into different image
layers of the array texture at a geometry shader level by setting gl_Layer. This technique is often used for dynamic Environment Mapping, whereby the six faces of the Cube-Map
can be produced in a single rasterisation pass by using layered rendering. Here, for the first time, we use this technique
for depth peeling.
To design a slim frame buffer (GL_R16UI, that is, a 16bit single-channel frame buffer) by using an array texture,
we need to divide the range (in the major axis direction) of
the cell-slices into slabs. Each slab corresponds to a layer of
the array texture and accommodates 16 slices of cells.
−−−→
The division is shown in Figure 3. The major axis axism

1234

Baoquan Liu et al. / Multi-layer Depth Peeling by Single-Pass Rasterisation for Faster Isosurface Raytracing on GPUs

is selected according to which component of the optical axis
−−−−→
vector axiscam (of the camera) has the largest absolute value.
The sign of the optical axis signoa is set to 1 if this component is positive, otherwise it is set to −1. TotalSlice and
TotalSlab are the total cell-slice number and total slab number, respectively, in the major axis direction. These simple
variables are all calculated per frame on the CPU and transferred to the GPU shaders at runtime.

Z
ax
is

slab: TotalSlab-1

cell slice: i*16+15

slab: i +1

each having 4 channels of 32 bits). In the modern, many-core
GPU architecture, memory bandwidth is one of the most important gating factors for performance, so this could provide
a huge saving.
B1
lle
c
fo 0
k
sa 0
tm
ib
0

B
A

0 A
ll
e
0 cf
o
1 sk
a
m
0 itb

slab: i
image plane

slab: 1

cell slice: i*16+1

slab: 0

cell slice: i*16+0

Figure 4: If the camera is aligned with the major axis (blue arFigure 3: Suppose the camera points in the Z-axis direction and
the total slice number (TotalSlice) of cells is L-1, which can be divided into a series of slabs with each slab containing 16 slices of
cells, then TotalSlab = L/16.0 .

For each active cell, our vertex shader traverses the
HistoPyramid to retrieve the object-space coordinates of the
cell. Our geometry shader accepts a point primitive (an active cell) as input and outputs another point primitive with a
different size and centre; these are calculated as the size and
centre of the cell’s projection (a round disk in screen-space)
using the equations from [LCD09b]. We then set gl_Layer
according to the sequence number, seqcell , of the current cell
along the major axis. Finally we calculate a bitmask as output for the cell, with one set bit indicating the position of
the cell within the slab. We calculate the sequence number for each cell as seqcell = key_coor/sideLength , where
sideLength and key_coor are, respectively, the side length
and component coordinate of the cell along the major axis.
If the camera points in the opposite direction to the major
axis, that is, signoa = −1, we need to flip this sequence number: seqcell = TotalSlice − 1 − seqcell in order to retain the
near-to-far ordering relative to the camera position. The slab
number into which the cell falls, slabcell , and the relative position of the cell inside the slab, bitPos, can be calculated as:
slabcell = seqcell /16 and bitPos = (seqcell %16). The bitmask for the cell can then be calculated as bitmask = (1 <<
bitPos). An example of the calculation is shown in Figure 4.
In this way, our geometry shader sets gl_Layer = slabcell
to route the projection of the cell to a certain layer of the
array texture; all rasterised fragments of the cell will output the same bitmask in 16-bit integer format. Our output
to global memory per fragment is thus very slim (only two
bytes) compared with the previous fat frame buffer algorithms [ED06, ED08, LHLW09a], which output 128 bytes to
global memory per fragment (for frame buffers of 8 MRTs,

row), then Seqcell for cells A and B are 1 and 3, respectively; while
if the camera direction is in the negative direction of the major axis
(orange arrow), then Seqcell for cells A and B are 2 and 0, respectively, before flipping, while they are 1 and 3 after flipping. So finally
the bitmasks for cells A and B are 0x2 and 0x8, respectively. Here
TotalSlice is 4.

By using OpenGL’s logic operation (GL_OR), all incoming fragments will be combined into the array texture, and
each generated fragment will set one bit in a certain layer of
the array texture according to the position of the active cell.
4.3. Stage 3 - depth recovery and raycasting pass
In this full-screen GPGPU pass, we reconstruct the depth
value (in fp32 format) from the bitmasks in the array texture
and generate depth intervals, which define a series of valid
ray segments; we then raytrace only inside these ray segments to render the isosurfaces. For clarity, we provide an
overview of the fragment shader of this pass in Algorithm 1.

4.3.1. Depth recovery
Since bitmasks may contain some runs of set bits (i.e. a series of neighbouring 1s), instead of reconstructing depth values for all of the set bits, we can merge them into segments
- we then need only to reconstruct depths for the two border
bits of each segment.
This bit merging can be accomplished by a simple lookup
table, which is much more efficient than performing bit
counting in the fragment shader. We pre-compute, on the
CPU, a 1D texture maskTable with 216 = 65536 entries.
Given a bitmask (a 16-bit unsigned integer) as an entry to
look up the texture, it will return a texel with 3 channels (R,
G and B, in 32-bit integer format): R gives the number of
set-bit segments in the bitmask, while G and B respectively
c 2010 The Author(s)
Journal compilation c 2010 The Eurographics Association and Blackwell Publishing Ltd.

Baoquan Liu et al. / Multi-layer Depth Peeling by Single-Pass Rasterisation for Faster Isosurface Raytracing on GPUs

Algorithm 1 DepthRecoveryAndRaycasting
−−
→ ⇐ CalculateRayDirForT hePixel(−
−−→ gl_TexCoord[0].xy);
rayDir
camPos,
1: −
−−
→ −
−→); //This could be positive or negative
2: cosAphla ⇐ DotProduct(−
rayDir,
axis
m
3: depth0 ⇐ (voxelSlice0 − camPos_z)/cosAphla;
4: deltadepth ⇐ sideLength/cosAphla;
5: for iSlab = 0 to TotalSlab − 1 do // iterating on all slabs
6: bitmask ⇐ arrayTextureLookup(array_texture, gl_TexCoord[0].xy, iSlab);
7: cellsO f PreviousSlabs ⇐ iSlab ∗ 16;
8: bit_segments ⇐ TextureLookup1D(maskTable, bitmask).rgb;
9: for iSeg = 0 to bit_segments.r − 1 do // iterating on all segments
10:
startindex ⇐ cellsO f PreviousSlabs + RetrieveIndex(bit_segments.g, iSeg);
11:
endindex ⇐ cellsO f PreviousSlabs + RetrieveIndex(bit_segments.b, iSeg);
12:
startVoxelindex ⇐ FlipAndO f f setStartIndex(startindex , signoa );
13:
endVoxelindex ⇐ FlipAndO f f setEndIndex(endindex , signoa );
14:
startdepth ⇐ abs(depth0 + startVoxelindex ∗ deltadepth );
15:
enddepth ⇐ abs(depth0 + endVoxelindex ∗ deltadepth );
−−→ + start
−
−−
→
−
−−→ ⇐ −
16:
camPos
start
pos
depth ∗ rayDir;
−
−−
→
−−→ + end
−
−−
→
17:
camPos
end pos ⇐ −
depth ∗ rayDir;
−−
→
−−→, −
18:
[bFinding, Intersection] ⇐ RaytracingOneSegment(isovalue, −
start
pos end pos );
19:
if bFinding = ture then
20:
Shading(Intersection); //shading the first intersection,
21:
return; //and then exit
22:
end if
23: end for
24: end for

encode the start and end indices of each segment: startindex
and endindex .
For example, in Figure 1 the bitmasks for rays A and B are
"011100001100" and "010000000110", respectively (where
the least significant bit is to the right). Both bitmasks have
2 set-bit segments, with [startindex , endindex ] in pairs: {[2,3],
[8,10]} for ray A and {[1,2], [10,10]} for ray B. This information can be retrieved when a bitmask is used as an entry
to look up the 1D texture (lines 10-11 of Algorithm 1). Since
these indices are the relative position inside a slab (as shown
on the right of Figure 3), we need to recover their global position along the major axis by adding an offset equal to the
total number of cell-slices in the previous slabs (line 7 of
Algorithm 1).
In order to completely cover each valid ray segment,
we then need to do some simple flipping and offsetting
to calculate the voxel-slice indices (startVoxelindex and
endVoxelindex shown as the red solid lines in Figure 5)
from their corresponding cell-slice indices (startindex and
endindex ) for each segment. Note that "cell-slice" refers to
a slice of cube-shaped cells perpendicular to the major axis,
while "voxel-slice" refers to a plane, parallel with this, that
lies along the boundary faces of the cubes (as a cube has a
voxel at each of its 8 corners).
If the camera is aligned with the major axis (signoa =
1), they are calculated as: startVoxelindex = startindex
and endVoxelindex = endindex + 1; otherwise (signoa =
−1), we need to flip both indices in order to recover the correct position relative to voxelSlice0 (the first
voxel-slice): startVoxelindex = TotalSlice − startindex and
endVoxelindex = TotalSlice−1−endindex (lines 12-13 in Algorithm 1).
Having obtained the voxel-slice indices for a segment,
c 2010 The Author(s)
Journal compilation c 2010 The Eurographics Association and Blackwell Publishing Ltd.

0
0
elx 1
ip
eh 1
t
f
o
0
k
as
0
tm
ib
0

isx
a
Z

voxelSlice0
delta depth
end voxel-slice

start voxel-slice
delta depth
voxelSlice0

Z
ax
is
depth0

depth0
image plane

1235

image plane

Figure 5: The bitmask here is "0011000", so there is only one
set bit-segment, whose start and end indices are originally 3 and 4,
respectively. The left figure shows the case when the camera points
along the major axis Z, so startVoxelindex = 3 and we need only
to offset the end index by 1: endVoxelindex = 4 + 1 = 5; while the
right figure shows the case when the camera points in the opposite
direction to the major axis Z, in which case we need to flip both
indices: startVoxelindex = TotalSlice − 3 = 4 and endVoxelindex =
TotalSlice − 1 − 4 = 2, where TotalSlice = 7 in this case.

we can compute their fp32 depth values (distances from
camera along the ray) very easily. Firstly, for each pixel,
−
−−−
→ −−−→
we calculate cosAl pha = DotProduct(rayDir, axism ), where
−
−−−
→
rayDir is the ray direction from the camera. The distance
from camera to voxelSlice0 along this ray is calculated
as: depth0 = (voxelSlice0 − camPos_z)/cosAl pha, where
−−−−→
camPos_z is the component of camPos (the camera position vector) along the major axis. We also calculate a delta
depth between any two neighbouring slices as deltadepth =
sideLength/cosAl pha. In Figure 5, depth0 and deltadepth
are shown as the blue and green line segments, respectively.
Having these two variables ready for each pixel, we can easily compute the depth values for the start and end voxelslices using the following equations:
startdepth = abs(depth0 + startVoxelindex ∗ deltadepth )
enddepth = abs(depth0 + endVoxelindex ∗ deltadepth )(1)
4.3.2. Raycasting within valid ray segments
The start and end depths of a segment define a depth interval
and border for a valid ray segment, and the two border points
can be calculated as:
−−−→
−
−−−
→
−
−−−→ = −
start
camPos + startdepth ∗ rayDir
pos
−−−→
−−−−→
−
−−−
→
(2)
end pos = camPos + enddepth ∗ rayDir
Between the two border points of the ray segment, we can
calculate the exact intersection of the ray with the isosurface
by uniform stepping, which iteratively steps along the ray
−−→
−−−→ to −
from −
start
end pos in a near-to-far order. This is perpos
−−−→
formed until an isosurface is found or end pos is reached. If

1236

Baoquan Liu et al. / Multi-layer Depth Peeling by Single-Pass Rasterisation for Faster Isosurface Raytracing on GPUs

an isosurface is found, we refine the position of the intersection by using a binary search [LCD09b]. If higher quality
is desired, complex intersection methods such as the correct
root finding method in [MKW∗ 04] can be employed.
One important advantage of the algorithm is that, thanks
to our bit flipping, all of the peeled depth values are naturally
in a near-to-far order which obviates the need for explicit
sorting. This is a huge saving, since sorting float-point depth
values in a fragment shader is very time-consuming. Thus,
whenever an isosurface intersection is found, we can be sure
that it is the nearest one along the ray so we can safely exit
the program. Furthermore, for each frame, signoa is the same
for all pixels, so no divergent branching takes place at runtime, and all pixels of a frame always take the same path
without divergence. Hence it can fully utilize the SIMD efficiency of GPU. The maximum count of depth layers that
our approach can peel is 16 times the layer number of the array texture. If we set the layer number of the array texture to
512, we can peel up to 8192 (512 × 16) depth layers, which
is much larger than that of the MRT-based approaches, since
current GPUs can support, at most, 8 MRTs.
5. Transparent Rendering of Multiple Isosurfaces
It is easy to extend our algorithm from an opaque firsthit isosurface to the transparent rendering of multiple isosurfaces, since all the valid ray segments generated are already in front-to-back order, which makes accurate transparent blending straightforward. After we find a ray-isosurface
intersection, the program does not exit (line 21 of Algorithm 1), instead we blend the shading result to an accumulated colour - the final colour is then composited from several isosurfaces. Some results of transparent rendering are
shown in Figure 6.

data set
bonsai
aneurism256
aneurism512
foot
skull
xmasBox
xmasTree
backpack
stagbeelte
fuel
hydrogenAtom

size
2563
2563
5123
2563
2563
5123
5123
5123
10242 ∗ 512
643
1283

isovalue
40
48.5
50.5
100
48
35.5
35.5
30.5
39.5
2.5
12.5

kdjump
16.6
19.8
19.2
23.2
13.3
14.9
17.2
12.8
n.p.
6.66
16.0

ours
73.9
95.6
82.7
78.8
52.2
54.2
59.1
50.4
68.9
241.4
169.5

s
4.5
4.8
4.3
3.4
3.9
3.6
3.4
3.9
n.p.
36.2
10.6

Table 1: Performance in fps for static isovalues for kdjump and
our algorithm; s is the speedup ratio of our method over kdjump.

NVIDIA GeForce GTX285 graphics card with 1GB RAM.
All the rendering and comparisons were performed on this
computer at 1024 × 1024 screen resolution.
6.1. Quality and performance comparison
For performance evaluation, we compared our algorithm to
recently published state-of-the-art isosurface-rendering algorithms. For the fairest comparison, we ran the various test
cases under precisely the same viewing configurations for
each comparison. All framerates were obtained by rendering a view multiple times to produce an average value.
6.1.1. Comparing with an image-order algorithm
kd jump is an optimised CUDA-based isosurface raytracing
method [HL09], the source code for which was kindly provided by the authors. Without changing any algorithmic part
of the code, we measured its performance using the same
datasets, viewing configurations and hardware platform to
ensure a fair comparison with our algorithm.
In the first test, the isovalue is fixed, so kd jump can skip
the kd-tree rebuilding step and our algorithm can skip the
HistoPyramid-building step; the resulting performance statistics are shown in Table 1, from which it is obvious that
our method is much the faster.

Figure 6: Transparent rendering results. The left image shows the
nucleon dataset (with resolution of 643 ) rendered at 71.9 fps; the
right image shows the anatomia dataset (with resolution of 5123 )
rendered at 21.3 fps.

6. Results and Discussion
We tested our implementation using OpenGL/GLSL on a
desktop PC (AMD 2.3 GHz CPU with 3 GB RAM) with an

In the second case, we assume that the isovalue changes
for each frame, so that, at every frame, our algorithm must
rebuild the HistoPyramid and kd jump has to rebuild the kdtree. From Table 2, we can see that, for large datasets, our
performance advantage over kd jump is more evident for dynamic isovalues due to the higher cost associated with kdtree rebuilding. Dynamic isovalues arise when the users need
to change the isovalues frequently at runtime in order to explore the different structures in the dataset. The rendered images for these two tables are shown in Figures 7 and 8.
The quality comparison can be seen in Figure 7. Both
algorithms use a similar uniform stepping to find the isosurface intersection (using the same stepping distance, that
is, half of the voxel size) and central differences for on-thefly normal calculation, but our algorithm also uses a binary
c 2010 The Author(s)
Journal compilation c 2010 The Eurographics Association and Blackwell Publishing Ltd.

Baoquan Liu et al. / Multi-layer Depth Peeling by Single-Pass Rasterisation for Faster Isosurface Raytracing on GPUs
data set
bonsai
aneurism256
aneurism512
foot
skull
xmasBox
xmasTree
backpack
stagbeelte
fuel
hydrogenAtom

size
2563
2563
5123
2563
2563
5123
5123
5123
10242 ∗ 512
643
1283

isovalue
40
48.5
50.5
100
48
35.5
35.5
30.5
39.5
2.5
12.5

kdjump
12.1
13.7
4.57
15.2
10.4
4.3
4.4
4.1
n.p.
6.59
15.4

ours
68.9
84.6
72.8
71.9
49.5
50.4
55.2
48.2
63.0
209.9
153.7

s
5.7
6.2
15.9
4.7
4.8
11.7
12.5
11.8
n.p.
31.9
9.98

data set
bonsai
aneurism256
aneurism512
foot
skull
xmasBox
xmasTree
backpack
stagbeelte
fuel
hydrogenAtom

size
2563
2563
5123
2563
2563
5123
5123
5123
10242 ∗ 512
643
1283

isovalue
40
48.5
50.5
100
48
35.5
35.5
30.5
39.5
2.5
12.5

cuda_mc
38.7
56.3
n.p.
41.2
31.5
n.p.
n.p.
n.p.
n.p.
256.3
168

ours
68.9
84.6
72.8
71.9
49.5
50.4
55.2
48.2
63.0
209.9
153.7

1237
s
1.8
1.5
n.p.
1.7
1.6
n.p.
n.p.
n.p.
n.p.
0.8
0.91

Table 2: Performance in fps for dynamic isovalues for kdjump and

Table 3: Performance in fps for dynamic isovalues for both

our algorithm, so all the isovalue-related variables need to be recomputed from scratch for each frame; s is the speedup ratio of our
method over kdjump.

cuda_mc and our algorithm; s is the speedup ratio of our method
over cuda_mc. For large datasets with resolution of 5123 or larger,
the cuda_mc program always crashes due to running out of CUDA
memory, which is referred to as "n.p.".

search to refine the intersection. Furthermore, kd jump employs only simple diffuse lighting, whereas our method uses
full Phong shading (including diffuse and specular lighting).
Our rendering results look smoother than those of kd jump
due to these additional computations in our raycaster. Even
though our raycaster is more complex than that of kd jump,
our performance still is much faster, as mentioned above. For
very large datasets, such as stagbeetle, the kd jump program
always crashes as a result of running out of CUDA memory, which is referred to as "n.p." in Tables 1 and 2, which
demonstrates that ours has a smaller memory footprint.
6.1.2. Comparing with another image-order algorithm
Knoll et al. [KHW∗ 09] recently introduced a method for rendering isosurfaces as Dirac impulses by using peak finding.
They employed a 3D DDA algorithm for empty-space skipping and adaptive sampling, followed by a binary search to
find the isosurfaces. We do not have their source code, so it
is not possible to compare with them directly, but fortunately
their paper also tested the two public datasets aneurism256
and backpack, and their performance was measured on the
same GPU (GTX285), so we can make an indirect comparison. Their reported framerates for the two datasets are 5.3fps
and 2.1fps, respectively, while ours are 95.6fps and 50.4fps,
respectively, which are around 20 times faster. So it seems
that our empty-space skipping is much more efficient than
their image-order approach.
6.1.3. Comparing with an object-order algorithm
The object-order algorithm against which we test our
method is a CUDA-based isosurface rendering using Marching Cubes [NVI09]), for which the source code is publicly
available. We refer to it as cuda_mc. It first runs an efficient scan function (prefix sum) from the highly optimised
CUDPP library to perform stream compaction, that is, extraction of all of the active cells, and then uses MC to generate triangles. Its rendering quality is clearly worse than ours
(Figure 7), since it produces a faceted appearance (diamond
c 2010 The Author(s)
Journal compilation c 2010 The Eurographics Association and Blackwell Publishing Ltd.

artefacts), caused by its planar triangles, while our approach
uses ray-isosurface intersection to produce a smoother result. The resulting performance statistics are shown in Table 3. Our performance is faster than cuda_mc except for
the last two datasets, which have a very small data size.
6.2. Discussion
Our algorithm is a hybrid [RYL∗ 96]: the rasterisation pass
is in object order and the raycasting pass is in image order so it inherits advantages from both approaches. For imageorder methods, performance is in almost direct proportion to
the screen resolution, whereas in object-order methods, performance is relatively independent of it. Thus, for a certain
scene complexity, object-order methods suffer little impact
if the screen resolution is increased. In the f uel dataset, for
which our method is more than 30 times faster than kd jump
(Tables 1 and 2), there is little geometry to rasterise owing to
the low resolution of this dataset. In contrast, kd jump always
traces each individual pixel as usual. As a result, when the
screen resolution is high, it will be very slow, even though
the dataset itself is simple. With regard to the slow framerate for this dataset, we received a helpful communication
from the authors of [HL09], who thought this was due to the
dataset itself since some datasets can create special difficulties for kd-tree and may cause it to traverse for a long time.
As a fully object-order method, cuda_mc is faster than our
algorithm for very small-sized datasets (Table 3), but our approach has the advantages of an image-order method so its
quality is obviously higher than that of cuda_mc; further, for
larger datasets, our algorithm has not only better rendering
quality, but also faster speed. Our method has a particular
advantage over cuda_mc when the isosurfaces have many
depth layers that all contribute to the final transparent rendering before the rays reach saturation, as shown in Figure 6.
Such a case requires that all of the isosurface layers must be
rendered in a view-dependent order [CICS05], so the triangles output from Marching Cubes need to be sorted, which is

1238

Baoquan Liu et al. / Multi-layer Depth Peeling by Single-Pass Rasterisation for Faster Isosurface Raytracing on GPUs

kd jump

cuda_mc

ours

Figure 7: Quality comparison between kd jump, our algorithm and cuda_mc, using the fuel and hydrogenAtom datasets. The rendering
quality of cuda_mc is worse than ours due to its faceted appearance (diamond artefacts); kd jump uses only uniform stepping to find the
intersection; while our algorithm uses a similar uniform stepping, but this is followed by a binary search to refine the intersection. Hence our
results are slightly smoother than those of kd jump. Furthermore, kd jump uses only simple diffuse lighting, while ours uses full Phong shading.

very demanding and may dominate the total rendering time
if the number of triangles is large [GHLM05]. In contrast,
our approach generates all of the valid ray segments immediately in a near-to-far order, which makes transparent rendering of multiple layers of isosurfaces simple and straightforward.
To fully explore the performance of the technique, we
timed the 3 individual stages of the algorithm and found
that the potential bottleneck lies in the third stage, which
accounts for 85% of the total rendering time for one frame
in a typical dataset, while the first and second stages account
for 7% and 8%, respectively.
To better evaluate and demonstrate the importance of the
empty-space skipping of interior regions, we modified the
algorithm to preserve only the first and last depth layers, as
in previous methods, while keeping all other parts of the algorithm the same. In doing so, only exterior empty space is
skipped, and we found that the framerate dropped by 36%

for typical datasets. So, it appears that the ability to skip interior regions plays an important role in GPU raycasting.
6.3. Cell granularity
Our basic cells are the MC cells (each with 8 scalar-value
corners), but we can increase the cell granularity granu_c
in order to reduce the cell count and generate more efficient computation. Setting granu_c to 1 gives the basic MC
cells; otherwise, we have macro-cells, each composed of
granu_c3 basic MC cells. We found that different datasets
may need different cell granularity for optimal performance.
In our tests, granu_c for the datasets: bonsai, aneurism256,
aneurism512, f oot, skull, xmasBox, xmasTree, backpack,
stagbeetle, f uel, and hydrogenAtom are 2, 2, 4, 2, 2, 4, 4, 4,
8, 1 and 2, respectively.
7. Conclusion
To accelerate GPU isosurface raytracing, we have created
a multi-layer depth-peeling approach that uses only a sinc 2010 The Author(s)
Journal compilation c 2010 The Eurographics Association and Blackwell Publishing Ltd.

Baoquan Liu et al. / Multi-layer Depth Peeling by Single-Pass Rasterisation for Faster Isosurface Raytracing on GPUs

bonsai

aneurism512

aneurism256

skull

foot

xmasBox

stagbeetle

xmaxTree

backpack

1239

Figure 8: Rendering results of our algorithm for different dense and sparse data sets. For these viewing configurations, the corresponding
performance statistics of our algorithm, kdjump and cuda_mc are shown in Tables 1, 2 and 3.

gle hardware rasterising pass. In this, we immediately obtain
the depth layers of the tightly-fitting bounding geometry of
the isosurface, the maximum number of which can be in the
thousands, with each layer in fp32 accuracy. By raytracing
only the valid ray segments that lie between pairs of consecutive depth layers, we can skip both the interior and exterior
empty space efficiently.

c 2010 The Author(s)
Journal compilation c 2010 The Eurographics Association and Blackwell Publishing Ltd.

Acknowledgments
We would like to thank David M. Hughes and Ik Soo Lim for
the valuable discussion and for making their kd jump code
available, which was instrumental in enabling us to perform
comparisons under the same conditions. We thank also the
anonymous reviewers for their constructive comments and
suggestions. This work was partially supported by the Eu-

1240

Baoquan Liu et al. / Multi-layer Depth Peeling by Single-Pass Rasterisation for Faster Isosurface Raytracing on GPUs

ropean Commission within the Marie Curie project GAMVolVis (FP7-PEOPLE-IIF-2008-236120).
References
[BCL∗ 07] BAVOIL L., C ALLAHAN S. P., L EFOHN A., C OMBA
J O A . L. D., S ILVA C. T.: Multi-fragment effects on the GPU using the k-buffer. In I3D ’07: Proceedings of the 2007 Symposium
on Interactive 3D Graphics and Games (New York, NY, USA,
2007), ACM, pp. 97–104.

the Conference on High Performance Graphics 2009 (New York,
NY, USA, 2009), ACM, pp. 51–57.
[LHLW09b] L IU F., H UANG M.-C., L IU X.-H., W U E.-H.: Single pass depth peeling via CUDA rasterizer. In SIGGRAPH ’09:
SIGGRAPH 2009: Talks (New York, NY, USA, 2009), ACM,
pp. 1–1.
[LWX06] L IU B., W EI L.-Y., X U Y.-Q.: Multi-layer depth peeling via fragment sort. Research report, msr-tr-2006-81, Microsoft
Research Asia, 2006.

[BM08] BAVOIL L., M YERS K.: Order independent transparency
with dual depth peeling. NVIDIA OpenGL SDK, 2008.

[MB07] M YERS K., BAVOIL L.: Stencil routed A-buffer. In SIGGRAPH ’07: ACM SIGGRAPH 2007 sketches (New York, NY,
USA, 2007), ACM, p. 21.

[CICS05] C ALLAHAN S. P., I KITS M., C OMBA J. L. D., S ILVA
C. T.: Hardware-assisted visibility sorting for unstructured volume rendering. IEEE Transactions on Visualization and Computer Graphics 11, 3 (2005), 285–295.

[MKW∗ 04] M ARMITT G., K LEER A., WALD I., F RIEDRICH H.,
S LUSALLEK P.: Fast and accurate ray-voxel intersection techniques for iso-surface ray tracing. In VMV04 (2004), pp. 429–
435.

[ED06] E ISEMANN E., D ÉCORET X.: Fast scene voxelization
and applications. In I3D ’06: Proceedings of the 2006 Symposium
on Interactive 3D graphics and games (New York, NY, USA,
2006), ACM, pp. 71–78.

[NVI09]

[ED08] E ISEMANN E., D ÉCORET X.: Single-pass GPU solid
voxelization for real-time applications. In GI ’08: Proceedings of
Graphics Interface 2008 (Toronto, Ont., Canada, Canada, 2008),
Canadian Information Processing Society, pp. 73–80.

[RYL∗ 96] R EED D. M., YAGEL R., L AW A., S HIN P.-W., S HA REEF N.: Hardware assisted volume rendering of unstructured
grids by incremental slicing. In VVS ’96: Proceedings of the
1996 Symposium on Volume Visualization (Piscataway, NJ, USA,
1996), IEEE Press, pp. 55–62.

[Eve01] E VERITT C.: Interactive Order-Independent Transparency. Research report, NVIDIA Corporation, 2001.
[GHLM05] G OVINDARAJU N. K., H ENSON M., L IN M. C.,
M ANOCHA D.: Interactive visibility ordering and transparency
computations among geometric primitives in complex environments. In I3D ’05: Proceedings of the 2005 Symposium on Interactive 3D Graphics and Games (New York, NY, USA, 2005),
ACM, pp. 49–56.
[HL09] H UGHES D. M., L IM I. S.: Kd-jump: a path-preserving
stackless traversal for faster isosurface raytracing on GPUs. IEEE
Transactions on Visualization and Computer Graphics 15, 6
(2009), 1555–1562.

NVIDIA: Nvidia CUDA SDK 2.3 code samples, 2009.

[RBE08] ROESSLER F., B OTCHEN R. P., E RTL T.: Dynamic
shader generation for GPU-based multi-volume ray casting.
IEEE Comput. Graph. Appl. 28, 5 (2008), 66–77.

[SA95] S OBIERAJSKI L. M., AVILA R. S.: A hardware acceleration method for volumetric ray tracing. In VIS ’95: Proceedings of the 6th Conference on Visualization ’95 (Washington, DC,
USA, 1995), IEEE Computer Society, pp. 27–34.
[VMD08] V IDAL V., M EI X., D ECAUDIN P.: Simple emptyspace removal for interactive volume rendering. J. Graphics
Tools 13, 2 (2008), 21–36.
[ZTTS06] Z IEGLER G., T EVS A., T HEOBALT C., S EIDEL H.-P.:
On-the-fly point clouds through histogram pyramids. In VMV06
(2006), pp. 137–144.

[HLSR09] H ADWIGER M., L JUNG P., S ALAMA C. R., ROPIN SKI T.: Advanced illumination techniques for GPU volume raycasting. In SIGGRAPH ’09: ACM SIGGRAPH 2009 courses
(New York, NY, USA, 2009), ACM, pp. 1–166.
[HQK05] H ONG W., Q IU F., K AUFMAN A.: GPU-based objectorder ray-casting for large datasets. In Volume Graphics 2005
(2005), pp. 177–185.
[KHW∗ 09] K NOLL A., H IJAZI Y., W ESTERTEIGER R., S CHOTT
M., H ANSEN C., H AGEN H.: Volume ray casting with peak finding and differential sampling. IEEE Transactions on Visualization and Computer Graphics 15, 6 (2009), 1571–1578.
[KW03] K RÜGER J., W ESTERMANN R.: Acceleration Techniques for GPU-based Volume Rendering. In Proceedings IEEE
Visualization 2003 (2003), pp. 287–292.
[LC87] L ORENSEN W. E., C LINE H. E.: Marching cubes: A
high resolution 3D surface construction algorithm. SIGGRAPH
Comput. Graph. 21, 4 (1987), 163–169.
[LCD09a] L IU B., C LAPWORTHY G. J., D ONG F.: Accelerating volume raycasting using proxy spheres. Computer Graphics
Forum 28, 3 (2009), 839–846.
[LCD09b] L IU B., C LAPWORTHY G. J., D ONG F.: Fast isosurface rendering on a GPU by cell rasterisation. Computer Graphics Forum 28, 8 (2009), 2151–2164.
[LHLW09a] L IU F., H UANG M.-C., L IU X.-H., W U E.-H.: Efficient depth peeling via bucket sort. In HPG ’09: Proceedings of

c 2010 The Author(s)
Journal compilation c 2010 The Eurographics Association and Blackwell Publishing Ltd.

