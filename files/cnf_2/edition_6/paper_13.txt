DOI: 10.1111/j.1467-8659.2009.01584.x

COMPUTER GRAPHICS

forum

Volume 29 (2010), number 1 pp. 160–174

Constrained Texture Mapping using Image Warping
H. Seo1,2 and F. Cordier3
1 Department

of Computer Science and Engineering, Chungnam National University, Korea
2 LSIIT (UMR 7005 CNRS), Universit´
e de Strasbourg, France
3 LMIA, Universit´
e de Haute Alsace, France

Abstract
We introduce in this paper a new method for smooth foldover-free warping of images. It allows users to specify
the constraints in two different ways: positional constraints to constrain the position of points in the image and
gradient constraints to constrain the orientation and scaling of some parts of the image. We then show how our
method is used for texture mapping with hard constraints. We start with an unconstrained planar embedding of
the target mesh calculated with conventional methods. In order to obtain a mapping that satisfies the user-defined
constraints, we use our warping method to align the features of the texture image with those of the unconstrained
embedding. Compared to previous work, our method generates a smoother texture mapping and offers higher level
of control for defining the constraints.
Keywords: foldover, positional constraints, texture mapping, warping
Categories and Subject Descriptors (according to ACM CCS): I.3.5 [Computer Graphics]: Computational
Geometry and Object Modeling; I.3.6 [Computer Graphics]: Methodology and Techniques; I.3.7 [Computer
Graphics]: Three-Dimensional Graphics and Realism

that some of these works could be extended for constrained
texture mapping. For instance, constrained texture mapping
could be achieved with the method [DMA02] by removing
the degrees of freedom of the constrained vertices from the
objective function of the parameterization. Such approach
may not work for a large set of constraints, because it does
not guarantee to generate a one-to-one mapping.

1. Introduction
Texture mapping is a well-known technique for mapping an
image onto the surface of a 3D model to enhance its visual appearance. This technique has been adopted for a broad range
of applications such as special effects for the film industry that requires highly realistic models as well as the game
industry for efficiently creating 3D models and virtual characters. The essential step of texture mapping is the surface
parameterization of a 3D model, that is, finding a one-to-one
correspondence between the entire surface of the model and
a texture. It is often required that the mapping satisfies a set of
constraints specified in the form of correspondence between
points in the texture and on the surface.

[Lev01] have proposed algorithms that satisfy the constraints using least-squares minimization. Although this
method works well for a small number of constraints, it
may fail when the number of constraints becomes large.
[GDHZ06] have proposed a method that satisfies the constraints exactly; however, their method does not guarantee to
compute a bijective mapping.
Other researchers [ESG01, KSG03, ZWT∗ 05, LYY08]
have proposed methods that exactly satisfy the positional
constraints by adding Steiner vertices to the embedded mesh.
Unlike these approaches, our method does not require modifying the structure of the embedded mesh. In addition, these
previous methods only handle positional constraints whereas

1.1. Related work
A large body of work on texture mapping has been devoted to
global parameterization of surfaces, that is finding a bijective
function between the entire surface of a model and a planar
texture space. See [HLS07] for a survey. One may think
c 2010 The Authors
Journal compilation c 2010 The Eurographics Association and
Blackwell Publishing Ltd. Published by Blackwell Publishing,
9600 Garsington Road, Oxford OX4 2DQ, UK and 350 Main
Street, Malden, MA 02148, USA.

160

H. Seo & F. Cordier / Constrained Texture Mapping

161

ours allows constraining the gradient of the mapping as
well.
[TT09] have presented a texture mapping method that
overcomes the texture image distortions that result from the
viewpoint and the object’s 3D geometry. The aim of their
work is different from ours. Their technique does not perform
parameterization, but rather projection of the model according to the estimated local cameras. They do not consider the
issues of constrained parameterization like bijectivity.
Several researchers have worked on the embedding of a
surface with constraints into a simpler domain such as the
sphere. Alexa [Ale00] has proposed a method to compute
a constrained spherical parameterization; the constraints are
defined in the form of feature-point correspondence between
the two surfaces. This method may fail if too many feature points are given. [LLCY00, LL05] have proposed to
solve this problem using edge flipping. However, the disadvantage of this method is that it may modify the geometry of
the surface. [PSS01] have proposed a method to compute a
consistent parameterization of a set of genus-0 surfaces. This
method is based on the segmentation of each of the surfaces
into a set of patches. In some cases, it may produce badly
shaped patches, resulting into a parameterization with high
distortion. The Praun’s approach has been further extended
for the consistent parameterization of surfaces with the same
genus [SAPH04, KS04].
[BBT02] used image warping for the texture mapping. The
main difference with our method is that their warping method
does not guarantee to generate a bijective mapping and the
purpose of their work was to reduce the space allocated for
the texture image.

Figure 1: Overview of the texturing method: 3D mesh (a)
and texture (b), unconstrained planar embedding of the mesh
(c), warping of the texture image to match the features with
those of the unconstrained planar embedding (d), final textured model (e).

deformation (see Section 3.2). This is because our image
warping method is C1 continuous.

1.2. Overview
In this paper, we present a new method for image warping
which produces a foldover-free and C1 -continuous mapping.
This method allows the user to control the warping in two
different ways: either with the positional constraints or the
gradient constraints to rotate and scale parts of the image.
We then show how this warping method can be used for
constrained texture mapping. We first compute a planar embedding of the 3D mesh (Figure 1(c)). Free-boundary parameterization methods are preferred since they generate
planar embedding with much lower distortion [LPRM02,
DMA02, SLMB05]. We then use our warping method
to deform the texture image in order to align its features with those of the planar embedding (Figure 1(d)).
Compared to other constrained texture mapping methods, our approach presents all the following advantages
together:
• Our method produces a better visual result, especially for
texture mapping with constraints that introduces large

• Our method offers more flexibility; it allows the user to
modify the position, orientation and scaling of the texture image on the surface of the 3D model. In addition,
the user is allowed to place the positional constraints
anywhere on the surface of the mesh unlike existing
techniques which require the positional constraints to
be located at the vertices [ESG01, KSG03].
The paper is organized as follows. Section 2 describes the
foldover-free image warping technique. In Section 3, we give
the implementation details, the results, and limitations of the
method.

2. Foldover-Free Image Warping
2.1. Required properties of the image warping
The problem of image warping is to find a function f that
maps points in the undeformed image to the deformed image. The mapping is constrained with a set of feature points

c 2010 The Authors
Journal compilation c 2010 The Eurographics Association and Blackwell Publishing Ltd.

162

H. Seo & F. Cordier / Constrained Texture Mapping

Figure 3: Overview of the vector field based warping: the
points of the image are moved along their respective pathline
to reach their position in the deformed image.

Figure 2: Constrained texture mapping using the Radial
Basis Function (a); the resulting mapping is not bijective and
the texture shows a foldover. Constrained texture mapping
using our foldover-free image warping (b).

that are moved from their source position Pi to their target position Qi . A warping method suitable for constrained
texture mapping must satisfy the following four properties:
• Smoothness: f should produce smooth deformations;
this property is desirable in order to generate visually
pleasing texture mapping.
• Bijectivity: f should be bijective so that the constrained
texture mapping is bijective. Figure 2 shows an example
of texture mapping by a warping method that does not
guarantee the bijectivity of the mapping.
• Interpolation: f should be an exact interpolant of the
positional constraints, that is, the source positions should
map to the target positions (i.e. f (Pi ) = Qi ).
• Identity: f should satisfy the identity property. If the
source and target positions of the feature points are coincident (i.e. f (Pi ) = Pi ), f should be the identity function.

2.2. Previous work in image warping
Techniques for image warping can be classified into two
categories: techniques based on triangulation and those using
a smooth function.

The main idea of triangulation-based warping [IMH05] is
to compute the warping of the image by deforming a triangular mesh overlaid on the image; each triangle contains a
small portion of the image. [FM98] have proposed a method
based on a time-varying triangulation that provides a bijective
mapping. [LYY08] have developed a similar approach for
constrained texture mapping. Compared to our work, these
approaches have two disadvantages. The mapping using triangulation is piecewise linear; it has only C0 continuity. In
addition, they only handle positional constraints; they do not
provide a simple way to constrain the scaling and orientation
of the image.
Several warping methods using a smooth function have
been proposed [BN92, SMW06]. The most common method
[Boo89] is based on the thin-plate splines; it attempts to minimize the amount of bending in the deformation. Most of them
do not guarantee to generate a bijective mapping. Grid-based
techniques such as free-form deformations [SP86, LCS95]
use bivariate cubic splines to generate C2 warping. These
methods require the positional constraints to be arranged on
a parallelepiped lattice, which makes them difficult to use for
the constrained texture mapping; the positional constraints
can have any position. [TDR01] have proposed a generic approach to transform a mapping with foldovers into a bijective
mapping by analyzing the determinant of its Jacobian. The
authors note that their method may not always work.
Compared to the previous work, our method offers the
following features: it generates a mapping that is smooth
and foldover free and which can be controlled with positional and gradient constraints. To the best of our knowledge,
none of the existing techniques fulfills all these requirements
together.
2.3. Computation of the warping
The driving idea is to compute the warping of the image
using a time-dependant vector field. A similar technique has
been used for 3D shape deformation [VTS06]. A C1 continuous vector field v(x, y, t) is first constructed based on the
user-specified constraints. We then compute the warped position of every point psrc of the image by applying a pathline
integration of v(x, y, t) starting from psrc (Figure 3). The

c 2010 The Authors
Journal compilation c 2010 The Eurographics Association and Blackwell Publishing Ltd.

163

H. Seo & F. Cordier / Constrained Texture Mapping

Source feature
points t=0

t=0.66

Target feature
points t=1

(a)
F1(t)

F1(t)
F2(t)

F3(t)

F2(t)

F1(t)
F2(t)

F3(t)

F3(t)

(b)

(c)

Figure 4: Vector-field based warping: linear interpolation
of the position of feature points from the source to the target
positions (a), computation of the vector field of the velocity
of the texture points (b), warping of the texture image (c).
pathline of the vector field starting from psrc is a 2D function
p(t) solution of the following set of equations:
⎧
⎨ d p(t) = v(p(t), t) for t ∈ [0, 1]
dt
(1)
⎩
p(0) = psrc
The pathline starting from a point psrc is the trajectory that
this point would make as it moves with the flow of the vector
field; at any time, the velocity of the point is equal to the
value of the vector field at the location of the point.
The user specifies the constraints with a set of feature
points whose source position is Pi in the undeformed image
and the target position Qi in the image after warping. Our
problem can be summarized as follow: given the source and
target positions, we deform the image such that the source
positions Pi map to the target positions Qi .
The key idea is to smoothly move the feature points
from their source position Pi to their target position Qi
(Figure 4(a)) and to relate the velocity of the points of the
image to those of the feature points. Intuitively speaking,
the 2D warping is equivalent to performing a sequence of
2D warping generated by incrementally moving the source
points to the target positions.
The velocity of all the image points is defined as a vector field function v(x, y, t) (Figure 4(b)). Hereafter, we de-

Figure 5: Local coordinate frame defined by Fi (t) and Fj (t)
(a), time-dependant vector field constructed from the local
coordinate frame (b), warping of the image points computed
with the vector field (c).

dF

(t)

the position and velocity of the feanote Fp,i (t) and p,i
dt
ture point i respectively for t ∈ [0, 1]; Fp,i (0) and Fp,i (1)
represent the source position Pi and target positions Qi ,
respectively. The position Fp,i (t) is obtained from a linear
interpolation of Fp,i (0) and Fp,i (1). Since the mapping must
be bijective, the feature points should not violate the bijectivity property as well, that is, the feature points should not
share the same position at the same time. For all the feature
points, we have Fp,i (t) = Fp,j (t) for all i and j with i = j
and t ∈ [0, 1].
2.3.1. Vector field with positional constraints
One important feature of image warping is the possibility to
rotate and uniformly scale parts of the image using positional
constraints. Similarly to [BN92], we compute the warping
using pairs of positional constraints. Given two positional
constraints with source and target positions, we compute a 2D
similarity transformation (transformation that only includes
translation, rotation, and uniform scaling) to warp the image.
Given two feature points i and j and a point p with coordinates x and y in the image, we compute the relative coordinates xp,i,j and yp,i,j of p in the local coordinate frame
defined by Fp,i (t) and Fp,j (t) at time t (Figure 5):

c 2010 The Authors
Journal compilation c 2010 The Eurographics Association and Blackwell Publishing Ltd.

164

H. Seo & F. Cordier / Constrained Texture Mapping

Figure 7: p in the local coordinate frame defined by Mi (t).
texture mapping. First, we can easily show that the warping method based on the vector field produces smooth deformations. The Equation (3) is twice continuous differentiable with respect to x and y; therefore the vector field is C1
continuous.

Figure 6: Texture mapping with no constraint (a); constraining the orientation of the texture (b); constraining the scaling
of the texture (c). Gradient constraints are useful to modify
the orientation of the texture along the texture seam (d).

p = Fp,i (t) + xp,i,j · (Fp,j (t) − Fp,i (t)) with R90 =
+ yp,i,j · R90 (Fp,j (t) − Fp,i (t))

0

1

−1 0
(2)

Note that the local coordinate frame is defined only if
Fp,i (t) and Fp,j (t) do not have the same position. Given
the velocity of the pair of feature points i and j, Equation (2)
provides the corresponding velocity of the point p = (x, y)T .
The vector field function vi,j (x, y, t) that relates the velocity
of the point p = (x, y)T with those of the feature points i and
j is given by
vp,i,j (x, y, t) =

d
d
Fp,i (t) + xp,i,j · (Fp,j (t) − Fp,i (t))
dt
dt
d
(3)
+ yp,i,j · R90 (Fp,j (t) − Fp,i (t)).
dt

This vector field defines the velocity of all the points of
the image in a way that these points are moved according
to the similarity transformation defined by the velocity of
Fp,i (t) and Fp,j (t). In other words, if the deformed position of a point p is computed with the vector field in Equation (3), the position of p with respect to the local coordinate frame defined by Fp,i (t) and Fp,j (t) remains unchanged
(Figure 5(a)–(c)).
As stated in Section 2.1, our warping method should satisfy several properties in order to be suitable for constrained

Second, we show that the warping method maps the source
positions to the target positions. If p = (x, y)T is coincident
with Fp,i (t), the relative coordinates xp,i,j and yp,i,j are both
equal to 0. Equation (3) becomes vp,i,j (x, y, t) = dtd Fp,i (t).
The velocity of p is the same as that of Fp,i (t); this means that
the point p maps to Fp,i (1). Similarly, if p is coincident with
Fp,j (t), the vector field becomes vp,i,j (x, y, t) = dtd Fp,j (t)
and the velocity of p is the same as that of Fp,j (t).
Third, the warping method satisfies the identity property.
If the source and target positions of the feature points i and
j are coincident, dtd Fp,i (t) and dtd (Fp,j (t) − Fp,i (t)) are both
equal to 0 and the vector field is null. No deformation is
applied to the image.
2.3.2. Vector field with gradient constraints
We provide an additional way to control the texture mapping process. As shown in Figure 6, the user can modify
the orientation and size of the texture around a point on the
surface.
Feature points for constraining the gradient are identical
to other feature points, except that the users can modify the
orientation and scaling of the texture image in addition to
the position. These gradient constraints are useful to remove
the texture discontinuity along the texture seam. Placing positional constraints along seam only eliminates the C0 discontinuity. Using the gradient constraints, the artist is able
to modify the orientation of the texture and thus make the
texture appear C1 continuous.
Each feature point i is then defined by a transformation
matrix composed of a translation, a rotation and an uniform
scaling components; Mi (0) being the matrix corresponding
to the texture image (source matrix) and Mi (1) the matrix for
the planar embedding of the mesh (target matrix). The idea is
to interpolate the matrix Mi (t) from the source to the target
matrices and to compute a velocity on p such that p does
not move in the local coordinate frame Mi (t) (Figure 7). We
first decompose the matrix Mi (0)−1 Mi (1) into translation,

c 2010 The Authors
Journal compilation c 2010 The Eurographics Association and Blackwell Publishing Ltd.

165

H. Seo & F. Cordier / Constrained Texture Mapping

rotation and scaling:
⎛

0 0 Tx

⎞⎛

cos(ϕ) − sin(ϕ) 0

⎜
⎟⎜
Mi (0)−1 Mi (1) = ⎝ 0 0 Ty ⎠ ⎝ sin(ϕ)
0 0 1
⎛
⎞
S 0 0
⎜
⎟
× ⎝0 S 0⎠

cos(ϕ)

0

0

of the matrix Mi (t); the point p maps to the target position of
the feature point Fg,i (t).

⎞

⎟
0⎠

Third, the warping method satisfies the identity property.
If the source matrix Mi (0) and the target matrix Mi (1) are
equal, Mi (t) is constant with respect to t and the vector
field vg,i (x, y, t) is null. The image does not undergo any
deformation.

1

2.3.3. Combination of vector fields

0 0 1

Because the number of feature points in the texture image
is usually more than two, the position of a point is affected
by multiple feature points. The total velocity of the point
p = (x, y)T is expressed as a weighted combination of the
velocity associated with each feature point. We define a
weight βp,i,j (p, t) for each pair of positional constraints i
and j so that the influence of the feature point pair Fp,i (t) and
Fp,j (t) increases as the point p becomes closer to either of
the feature points.

Mi (t) is obtained by interpolating each component of the
matrix: Mi (t) = Mi (0) · T (t)R(t)S(t) with
⎛

0 0 tTx

⎞

⎛

cos(tφ) − sin(tφ) 0

⎜
⎟
⎜
T (t) = ⎝ 0 0 tTy ⎠ , R(t) = ⎝ sin(tφ)
0 0

1

cos(tφ)

0

0

⎞

⎟
0⎠
1

and
⎛

St

0

⎜
S(t) = ⎝ 0

S

0

0

t

0

⎞

βp,i,j (p, t) =

⎟
0⎠.

1
with dp,i = p − Fp,i (t) and
α
α
dp,i
dp,j
dp,j = p − Fp,j (t)

1

The weight for a gradient constraint i is given by
The vector field corresponding to the gradient constraint is
⎛
vg,i (x, y, t) =

⎛

xg,i

βg,i (p, t) =

⎞⎞

d ⎝
Mi (t) · ⎝ yg,i ⎠⎠
dt
1

(4)

The exponent α is set by the user to control the smoothness
of the warping (see Figure 8). These weights are normalized
such that their sum is unity for each point p = (x, y)T . Let
npos be the number of positional feature points i and ngrad the
number of gradient feature points, we compute wp,i,j (p, t)
the normalized value of βp,i,j (p, t):

(xg,i , yg,i )T is the position of the point p = (x, y)T in the
local coordinate frame of Mi (t). We denote Fg,i (t) = Mi (t) ·
(0, 0, 1)T , the origin of the coordinate system defined by
Mi (t) in the global coordinate system.

npos

l=m

l=1
m=1

⎝

l=m

n=1
n=l

α
dp,n

npos
l=1
m=1

l=m

⎝

−α
dg,l

−α −α
dp,m +
dp,l

npos
l=1,m=1

l=m

.
ngrad
l=1

−α
dg,l

These weights are rewritten as follows:

α ⎠+
dg,n

ngrad
l=1
ngrad
l=1

α
dg,l

.

ngrad
n=1

n=l

α
dg,n

npos
n=1

(5)

α
dp,n

n=m
ngrad
l=1,l=i

⎛

wg,i (p, t) =

ngrad
l=1

−α
dg,i

αg,i (p, t) =

α
dp,l
·
⎞

ngrad
n=1

−α −α
dp,l
dp,m +

wg,i (p, t), which is the normalized value of is βg,i (p, t) given
by

npos
l=1,l=i,l=j
npos

npos
l=1,m=1

Second, the warping method maps the source positions to
the target positions. If a point p = (x, y)T is coincident with
the feature point Fg,i (t), xg,i et yg,i are both equal to 0 in
Equation (4). The vector field is equal to the translation part
⎛

−α −α
dp,j
dp,i

wp,i,j (p, t) =

Similarly to the vector field in Equation (3), we check if
the warping based on the vector field in Equation (4) has
the properties listed in Section 2.1. First, we can easily see
that the warping produces smooth deformation. Equation (4)
is twice continuous differentiable with respect to x and y;
therefore the vector field is C1 continuous.

wp,i,j (p, t) =

1
with dg,i = p − Fg,i (t) .
α
dg,i

npos
n=1
n=l

α
dp,n

ngrad
n=1

α
dg,l
·
⎞

α ⎠+
dg,n

npos
l=1
ngrad
l=1

α
dp,l

.
ngrad
n=1

n=l

α
dg,n

npos
n=1

(6)

α
dp,n

n=m

c 2010 The Authors
Journal compilation c 2010 The Eurographics Association and Blackwell Publishing Ltd.

166

H. Seo & F. Cordier / Constrained Texture Mapping

We also show that wp,i,j (p, t) and wg,i (p, t) are C1 conα
α
= p − Fp,i (t) α and dp,j
= p − Fj (t) α are
tinuous. dp,i
1
C continuous with respect to the coordinates x and y of p for
α > 1. The denominator and numerators of Equations (5)
and (6) are C1 continuous with respect to x and y; it follows that wp,i,j (p, t) and wg,i (p, t) are C1 continuous as
well.
The total vector field is given by
npos

wp,i,j (x, y, t) · vp,i,j (x, y, t)

v(x, y, t) =
i,j =1 with i=j
ngrad

wg,i (x, y, t) · vg,i (x, y, t) .

+

(7)

i=1

Figure 8: Warping with different values of a equal to 1.0
(b), 2.0 (c) and 3.0 (d).

As stated in Section 2.3, we assume that no feature points
share the same position at the same time; we have Fi (t) =
Fj (t) for all feature points i and j with i = j and t ∈ [0, 1].
This implies that the denominators of Equations (5) and (6)
are always different from zero and the weights are defined
for all coordinates (x, y) of p, even when p shares the same
location as one of the feature points.
We provide a numerical example to show the values of
wp,i,j (p, t) when the position of p is the same as one the feature points. Let be Fp,1 (t), Fp,2 (t) and Fp,3 (t) the position of
three positional feature points and p having the same position
as Fp,1 (t); the three weights for the three pairs of positional
feature points are
wp,1,2 =

wp,1,3 =

α
dp,3
α
dp,1

+

α
dp,2

+

α
dp,3

+

α
dp,3

α
dp,2
α
dp,1

wp,2,3 =

+

α
dp,2

=

=

α
dp,3
α
dp,2

α
+ dp,3

α
dp,2
α
dp,2

α
dp,1
α
α
α
dp,1
+ dp,2
+ dp,3

+

α
dp,3

= 0.

These values shows that the position of p is solely defined by the two pairs of feature points (Fp,1 (t), Fp,2 (t)) and
(Fp,1 (t), Fp,3 (t)). These two pairs are those connected to the
feature point Fp,1 (t).

The warped position of a point psrc is obtained by solving
Equation (1) for t equal to 1 and p(0) equal to psrc . In our implementation, we use the 4th order Runge–Kutta integration
with adaptive step-size (similarly to [VTS06]). One integration step involves computing the intermediate solution p(t),
updating the weights wp,i,j and wg,i and the local coordinates
xp,i,j , yp,i,j , xg,i and yg,i in Equations (3) and (4) of the vector fields vp,i,j and vg,i by using p(t). Note that the pathline
integration is computed independently for each point of the
texture image. Our algorithm is parallelized by assigning the
computation of the pathline integration to different threads.
Each vector field vp,i,j (x, y, t) and vg,i (x, y, t) corresponds to a similarity transformation of the image. It follows
that the deformation induced by the vector field v(x, y, t) is a
weighted combination of the similarity transformations corresponding to each vector field vp,i,j (x, y, t) and vg,i (x, y, t).

2.3.4. Properties of the vector-field based warping
We now show that our warping method based on the vector field in Equation (7) has the four properties listed in
Section 2.1.
Bijectivity: The mapping generated with our warping
method is bijective (foldover-free). We demonstrate that the
vector field is locally Lipschitz-continuous and show that this
property is sufficient to guarantee the bijectivity [Lan95].
Theorem 1: The vector field v : R2 → R2 is called locally
Lipschitz-continuous around each point of R2 if there exists
K > 0 and L > 0 such that
v(p1 ) − v(p2 ) < K p1 − p2 , ∀p1 ∈ R2 ,
p2 ∈ R2 : p1 − p2 < L.
Because the vector field v(p, t) is C1 continuous for ∀p ∈
R2 , it is also locally Lipschitz-continuous.
Theorem 2: Let v : R2 → R2 be a continuous vector field
satisfying the Lipschitz condition around each point of R2 .

c 2010 The Authors
Journal compilation c 2010 The Eurographics Association and Blackwell Publishing Ltd.

H. Seo & F. Cordier / Constrained Texture Mapping

Then, there exists a unique pathline through any p0 ∈ R .
Furthermore, every pathline is defined over R.
2

This theorem implies that two pathlines cannot intersect
in the 3D space-time domain. This property guarantees the
bijectivity of the mapping.

167

time for larger number of positional constraints. For 100
and 200 positional constraints, the algorithm takes about
10 seconds and 1 minute, respectively.

3.2. Discussion with related work

Smoothness: Our warping method produces a smooth deformation. The vector fields defined in Equations (3) and (4)
are both C1 continuous with respect to x and y. It follows that
v(x, y, t) in Equation (7), which is the weighted summation
of these two vector fields is C1 continuous in x and y. The
warping based on the vector field v(x, y, t) is smooth.

To the best of our knowledge, the methods proposed by
[LYY08] and [KSG03] are the only ones that guarantee the
bijectivity of the mapping. Compared to [KSG03] method,
the method by [LYY08] is able to handle more challenging
constraints and generate more pleasing results. Therefore, we
compare our algorithm with that of [LYY08].

Interpolation: Our warping method maps the source positions to the target positions; this is because the warping
based on the two vector fields vp,i,j (x, y, t) and vg,i (x, y, t)
map the source positions to the target positions (see Sections
2.3.1 and 2.3.2).

We have first compared the two methods with a 2D grid
mesh composed of a small number of triangles. As can be
seen in the Figure 10, the warping computed by [LYY08]
has a better special distribution of the vertices; the variation of the edge lengths is smaller. This indicates that the
method [LYY08] produces a mapping with a lower distortion for the stretch. This result is not surprising since their
method is based on an optimization problem that minimizes
the stretch of mapping. This is verified with a quantitative
analysis. To measure the distortion of the parameterization,
we used two metrics L2 Stretch and L2 Shear that measure the
stretch and the conformality, respectively. These two metrics
are computed for each triangle using the affine mapping defined with its 3D coordinates and its 2D coordinates in the
texture space. The formula of the L2 Stretch and the L2 Shear
are given by [SSGH01] and [SLMB05] respectively. The
value of the L2 stretch for [LYY08] is slightly better than the
one for the vector-field based warping.

Identity: Our warping method satisfies the identity properties. If the source and target positions of the feature points
are the same (Fp,i (0) = Fp,i (1) for all feature points i), the
vector fields in Equation (3) and (4) are null. No deformation
is applied to the image.
3. Results and Limitations
Our method has been implemented with a Graphical User
Interface that allows the user to add/remove feature points
interactively. The texture mapping process includes the following steps: first, the user draws a simple closed curve on
the triangular mesh to specify the region of the model to
texture. A planar embedding of the region is then computed
using the Least Squares Conformal Map method [LPRM02].
Next the user places the feature points in the texture image
and the 3D model. During the placement of feature points,
the constrained texture mapping can be calculated and displayed at any time. Our method is demonstrated with several
examples of varying complexity, as shown in Figure 9 and the
demonstration video. The complexity of the models ranges
between 5 000 and 20 000 polygons and the number of feature points between 10 and 50.
3.1. Computation time
Given n positional constraints, the number of pairs of positional constraints is given by
n−1

i=
i=1

n(n − 1)
.
2

Thus, the complexity of the algorithm is quadratic in the
number of positional constraints. The computation time for
mapping a texture image with 50 positional constraints is
about few seconds on an Intel dual 2.6 GHz computer. This
number of positional constraints is usually sufficient for most
cases of texture mapping. We have measured the computation

We have then compared the two methods with models of
higher complexity. The Figure 9 shows the results of our approach and those obtained by [LYY08]. All the models have
been textured with a checker image to show the difference of
the mapping between the two methods. Our algorithm generates a smoother texture mapping; in particular, smoothness
around the constraints is not ensured with [LYY08]. The
difference between the two methods is particularly visible
for the pig model (d) and the two cow models (f) and (g).
A quantitative analysis has been performed as well to compare our approach with that of [LYY08]. The values of the
distortion metrics in Table 1 show that there is no significant
difference in the quality of the parameterization between the
two approaches, except for the models (d), (f) and (g).
The method by [LYY08] is based on the explicit minimization of a deformation energy in order to control the
distortion. The associated optimization problem is nonlinear; the convergence is slow and usually the method finds
an approximated solution, which is not the exact minimum
of the optimization problem. This explains why the method
of [LYY08] works well for meshes with small number of
triangles (models (b) and (e) in Figure 9): the convergence
is fast and a good approximation of the solution is found.

c 2010 The Authors
Journal compilation c 2010 The Eurographics Association and Blackwell Publishing Ltd.

168

H. Seo & F. Cordier / Constrained Texture Mapping

Figure 9a: Comparison of our method with [LYY08] (zoom in for detail).

c 2010 The Authors
Journal compilation c 2010 The Eurographics Association and Blackwell Publishing Ltd.

H. Seo & F. Cordier / Constrained Texture Mapping

169

Figure 9b: Comparison of our method with [LYY08] (zoom in for detail).
c 2010 The Authors
Journal compilation c 2010 The Eurographics Association and Blackwell Publishing Ltd.

170

H. Seo & F. Cordier / Constrained Texture Mapping

Figure 9c: Comparison of our method with [LYY08] (zoom in for detail).

c 2010 The Authors
Journal compilation c 2010 The Eurographics Association and Blackwell Publishing Ltd.

171

H. Seo & F. Cordier / Constrained Texture Mapping
Source feature points

Target feature points

P3

Q3

(a)

H1
Q5

P6
P4

P2

P1

Q2

Q1
Q3

P3

(b)

Q4

Q6

P5

Q9

P8
Q5

P6

P9

P4

P1

Q6

P5
P7 P2

Q1 Q7

Q4
Q8

Q2

Figure 11: Let two sets of feature points S1 = {P1 ,
P2 , P3 , P4 , P5 , P6 } and S2 = {Q1 , Q2 , Q3 , Q4 , Q5 , Q6 } (a);
the construction of the compatible triangulation of S1
and S2 requires adding 3 Steiner vertices {P7 , P8 , P9 } and
{Q7 , Q8 , Q9 } for each set.

Figure 10: Comparison of the vector-field based warping
with the warping method by [LYY08].
Table 1: Quantitative comparison between quality of the texture
mapping for the models shown in Figure 9.

[LYY08]

Model (a)
Model (b)
Model (c)
Model (d)
Model (e)
Model (f)
Model (g)
Model (h)
Model (i)

Our method

L2 Stretch

L2 Shear

L2 Stretch

L2 Shear

7.692
1.451
3.397
8.024
1.219
183.647
66.468
2.839
2.940

0.247
0.104
0.210
0.306
0.059
0.310
0.342
0.222
0.168

8.204
1.509
1.771
6.695
1.285
30.364
10.359
2.910
2.986

0.248
0.159
0.163
0.288
0.055
0.360
0.290
0.296
0.228

In the contrary, if the mesh has a large number of triangles
with large distortion in the mapping (models (f) and (g)), the
convergence is much slower and the remaining distortion is
important. In contrary, our method does not require the postprocessing step to lower the mapping distortion and therefore
performs faster than the method of [LYY08].

Another limitation of the method of [LYY08] is that it is
sensitive to the quality of the mesh. The presence of badly
shaped triangles introduces numerical errors in the optimization. This is illustrated by the pig model (d) in Figure 9 that
contains many badly shaped triangles located on the nose.
Since our vector-field warping does not depend on the quality of the triangulation, it produces better result.
3.3. Limitations
The warping method does not work when two feature points
become coincident during the warping process. There are
two reasons for this. First, the coordinate frame to compute
the vector field in Equation (3) cannot be defined if Fi (t)
and Fj (t) share the same position for the same value t (See
Section 2.3.1). Second, we assume that Fi (t) = Fj (t) for all
i and j with i = j and t ∈ [0, 1]. This assumption is required
for the bijectivity property of the feature points.
The solution to this problem is to compute the featurepoints trajectories such that they do not intersect in the 3D
space-time domain. We have implemented a simple method
that greatly reduces the possibility that feature points selfintersect. The idea is to compute a similarity transformation
to align the source feature points as close as possible to the
target feature points. [Ume91] proposes a method to compute this transformation with a least squares method that
minimizes the square distances between the source and target feature points. Although this method does not guarantee
the non-intersection of the feature-points trajectories, it has

c 2010 The Authors
Journal compilation c 2010 The Eurographics Association and Blackwell Publishing Ltd.

172

H. Seo & F. Cordier / Constrained Texture Mapping

are not taken into account for the computation of the vector
field.
Another limitation of our method is that the constrained
mapping is not necessarily bijective. This is because we compute the unconstrained planar embedding of the 3D mesh
using the Least Square Conformal Mapping [Lev01]; this
method does not guarantee to generate a bijective mapping.
Like existing constrained texture mapping methods, our
method may produce undesirable visual distortion that arises
when the mapping is highly distorted and the resolution of the
texture image is to low. The method proposed by [TBTS08]
could be used to address this problem. Their approach is to
expand image regions via texture synthesis to better fit the
3D geometry.
4. Conclusion

Figure 12: Given two compatible triangulations of the
source and target feature points, the method proposed by
[SG01] computes the trajectories of the feature points (a);
the trajectories are then used to compute the warping (b).

been successfully used for all the textured models shown in
this paper. In the next paragraph, we propose another method
that always guarantees to generate non-intersecting trajectories for the feature points.
The problem of computing the trajectories of a set of points
from their source position to their target position is a wellknown problem in morphing and has been already solved.
The computation of these trajectories is done two steps. We
first compute a compatible triangulation of the source and target feature points. Let S1 and S2 be two finite sets of points
in the Euclidean plane. Two triangulations T1 of S1 and T2 of
S2 are called compatible if the face lattices formed by their
triangles, edges, and points are isomorphic. The decision
problem determining whether two sets of point are compatible is believed to be NP-hard [Saa87, SW94] demonstrated
that two sequences of n points may be made compatible by
adding O(n2 ) Steiner points. Figure 11 shows a compatible
triangulation of two point sets with Steiner points.
Once a compatible triangulation of the two sets has been
found, we compute the morphing between these two triangulated sets using the method proposed by [SG01] (Figure 12).
Their technique, which is based on a convex representation
of triangulations, takes as input a compatible triangulation
with the same boundary and generates a valid morph in the
form of a continuous sequence of valid triangulations, that
is, the triangles do not intersect during the morph. The computed trajectories are then used to compute the vector field for
the image warping. Note that the trajectories of the Steiner
points that have been created for the compatible triangulation

We have proposed a method for constrained texture-mapping
of triangular meshes. Compared to previous work, our
method allows more flexibility for manipulating the texture
and provides a smoother mapping. As a future work, we plan
to investigate other ways to construct the vector field using
functions such as the Radial Basis Function.
Acknowledgment
We thank Tong-Yee Lee and Shao-Wei Yen for providing the
models and helping us for the experimental comparison. We
also thank Nicolas Chevallier for his helpful criticism and
comments. This work was supported in part by the Korea
Science and Engineering Foundation (KOSEF) grant (No.
R11-2007-028-02002-0) and in part by the Korea Research
Foundation grant (D00401). The first author has been partly
supported by the CNRS (Centre National de la Recherche
Scientifique).
References
[Ale00] ALEXA M.: Merging Polyhedral Shapes with Scattered Features. The Visual Computer 16, (2000), 26–37.
[BBT02] BALMELLI L., BERNARDINI F., TAUBIN G.: Spaceoptimized texture maps. In Computer Graphics Forum 21,
3 (2002). G. Drettakis and H.-P. Seidel (Eds.), 411–420.
(Proc. Eurographics’07).
[BN92] BEIER T., NEELY S.: Feature-based image metamorphosis. In SIGGRAPH ’92: Proceedings of the 19th Annual Conference on Computer Graphics and Interactive
Techniques (New York, NY, USA, 1992), ACM Press,
pp. 35–42.
[Boo89] BOOKSTEIN F. L.: Principal warps: Thin-plate splines
and the decomposition of deformations. IEEE Trans. Pattern Anal. Mach. Intell. 11, 6 (1989), 567–585.

c 2010 The Authors
Journal compilation c 2010 The Eurographics Association and Blackwell Publishing Ltd.

H. Seo & F. Cordier / Constrained Texture Mapping

[DMA02] DESBRUN M., MEYER M., ALLIEZ P.: Intrinsic Parameterizations of Surface Meshes. Computer Graphics
Forum 21, 3 (2002), 209–218.
[ESG01] ECKSTEIN I., SURAZHSKY V., GOTSMAN C.: Texture
mapping with hard constraints. Computer Graphics Forum
(Proc. of Eurographics) 20, 3 (2001), 95–104.
[FM98] FUJIMURA K., MAKAROV M.: Foldover-free image
warping. Graphical Models and Image Processing 60, 2
(1998), 100–111.
[GDHZ06] GINGOLD Y. I., DAVIDSON P. L., HAN J. Y., ZORIN
D.: A Direct Texture Placement and Editing Interface.
In Proceedings of UIST, Montreux, Switzerland, October
2006, pp. 23–32.
[HLS07] HORMANN K., L´EVY B., SHEFFER A.: Mesh parameterization: theory and practice. In ACM SIGGRAPH
Courses (San Diego, California, August 5–9, 2007). SIGGRAPH ’07. ACM, New York, NY.
[IMH05] IGARASHI T., MOSCOVICH T., HUGHES J. F.: As rigidas-possible shape manipulation. ACM Trans. Graph. 24,
3 (2005), 1134–1141.
[KSG03] KRAEVOY V., SHEFFER A., GOTSMAN C.: Matchmaker: constructing constrained texture maps. In Proceedings of SIGGRAPH (2003), pp. 326–333.
[KS04] KRAEVOY V., SHEFFER A.: Cross-Parameterization
and Compatible Remeshing of 3D Models. ACM Trans.
Graphics 23, 3 (2004), 861–869.
[Lan95] LANG S.: Differential and Riemannian manifolds,
3rd Edition. Springer, New York, 1995.
[LCS95] LEE S.-Y., CHWA K.-Y., SHIN S. Y.: Image metamorphosis using snakes and free-form deformations. In
SIGGRAPH ’95: Proceedings of the 22nd annual conference on Computer graphics and interactive techniques
(New York, NY, USA, 1995), ACM Press, pp. 439–
448.

173

[LLCY00] LIN C.-H., LEE T.-Y., CHU H.-K., YAO Z.-Y.:
Progressive Mesh Metamorphosis. Journal of Computer
Animation and Virtual Worlds 16, 3–4 (2005), 487–
498.
[LL05] LIN C.-H., LEE T.-Y.: Metamorphosis of 3D Polyhedral Models Using Progressive Connectivity Transformations. IEEE Transactions on Visualization and Computer
Graphics 11, 1 (January/February 2005), 2–12.
[PSS01] PRAUN E., SWELDENS W., SCHORDER P.: Consistent
Mesh Parameterizations. In Proc. ACM SIGGRAPH ’01
(2001), pp. 179–184.
[Saa87] SAALFELD A.: Joint triangulations and triangulation
maps. In Proceedings of the 3rd Annual ACM Symposium
on Computational Geometry (Waterloo, Canada, 1987),
pp. 195–204.
[SSGH01] SANDER P. V., SNYDER J., GORTLER S. J., HOPPE
H.: Texture Mapping Progressive Meshes. In Proc. ACM
SIGGRAPH ’01 (2001), pp. 409–416.
[SMW06] SCHAEFER S., MCPHAIL T., WARREN J.: Image Deformation Using Moving Least Squares. In Proceedings
of ACM SIGGRAPH (2006), pp. 533–540.
[SAPH04] SCHREINER J., ASIRVATHAM A., PRAUN E., HOPPE
H.: Inter-Surface Mapping. ACM Trans. Graphics 23, 3
(2004), 870–877.
[SP86] SEDERBERG T. W., PARRAY S. R.: Free-form deformation of solid geometric models. In Proceedings
of ACM SIGGRAPH (1986), ACM Press, pp. 151–
160.
[SLMB05] SHEFFER A., LEVY B., MOGILNITSKY M.,
BOGOMYAKOV A.: ABF++: fast and robust angle based
flattening. ACM Transactions on Graphics 24, 2 (2005),
311–330.
[SW94] SOUVAINE D. L., WENGER R.: Constructing Piecewise Linear Homeomorphisms. Tech. Rep. (Princeton, NJ,
1994), DIMACS, pp. 94–52.

[LYY08] LEE T.-Y., YEN S.-W., YEH I.-C.: Texture Mapping with Hard Constraints Using Warping Scheme. IEEE
Transactions on Visualization and Computer Graphics 14,
2 (March–April 2008), 382–395.

[SG01] SURAZHSKY V., GOTSMAN C.: Controllable Morphing
of Compatible Planar Triangulations. ACM Transactions
and Graphics 20, 4 (2001), 203–231.

[LPRM02] LEVY B., PETITJEAN S., RAY N., MAILLOT J.-L.:
Least squares conformal maps for automatic texture atlas generation. In Proceedings of SIGGRAPH (2002),
pp. 362–371.

[TBTS08] TAI Y.-W., BROWN M., TANG C.-K., SHUM H.-Y.:
Texture amendment: reducing texture distortion in constrained parameterization. ACM Transactions on Graphics
27, 5 (2008), 1–6.

[Lev01] LEVY B.: Constrained texture mapping for polygonal meshes. In Proceedings of SIGGRAPH (2001),
pp. 417–424.

[TDR01] TIDDEMAN B., DUFY N., RABEY G.: A general
method for overlap control in image warping. Computers and Graphics 25, 1 (2001), 59–66.

c 2010 The Authors
Journal compilation c 2010 The Eurographics Association and Blackwell Publishing Ltd.

174

H. Seo & F. Cordier / Constrained Texture Mapping

[TT09] TZUR Y., TAL A.: FlexiStickers: photogrammetric
texture mapping using casual images. ACM Transactions
on Graphics 28, 3 (2009), 1–10.

[VTS06] VON FUNCK W., THEISEL H., SEIDEL H.-P.: Vector
field based shape deformations. ACM Trans. Graph. 25, 3
(2006), 1118–1125.

[Ume91] UMEYAMA S.: Least-squares estimation of transformation parameters between two point patterns. IEEE
Transactions on Pattern Analysis and Machine Intelligence 13, 4 (April 1991), 376–380.

[ZWT*05] ZHOU K., WANG X., TONG Y., DESBRUN M., GUO
B., SHUM H.-Y.: TextureMontage: Seamless Texturing of
Arbitrary Surfaces From Multiple Images. In Proceedings
of SIGGRAPH (2005), pp. 1148–1155.

c 2010 The Authors
Journal compilation c 2010 The Eurographics Association and Blackwell Publishing Ltd.

