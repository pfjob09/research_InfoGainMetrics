DOI: 10.1111/j.1467-8659.2009.01419.x

COMPUTER GRAPHICS

forum

Volume 28 (2009), number 8 pp. 2117–2130

Adaptive Interleaved Sampling for Interactive
High-Fidelity Rendering
P. Dubla, K. Debattista and A. Chalmers
The Digital Lab, WMG, University of Warwick, UK
P.B.Dubla@warwick.ac.uk

Abstract
Recent advances have made interactive ray tracing (IRT) possible on consumer desktop machines. These advances
have brought about the potential for interactive global illumination (IGI) with enhanced realism through physically
based lighting. IGI, unlike IRT, has a much higher computational complexity. Furthermore, since non-primary
rays constitute the majority of the computation, the rays are predominantly incoherent, making impractical many
of the methods that have made IRT possible. Two methods that have already shown promise in decreasing the
computational time of the GI solution are interleaved sampling and adaptive rendering. Interleaved sampling is
a generalized sampling scheme that smoothly blends between regular and irregular sampling while maintaining
coherence. Adaptive rendering algorithms adjust rendering quality, non-uniformally, using a guidance scheme.
While adaptive rendering has shown to provide speed-up when used for off-line rendering it has not been utilized in
IRT due to its naturally incoherent nature. In this paper, we combine adaptive rendering and interleaved sampling
within a component-based solution into a new approach we term adaptive interleaved sampling. This allows
us to tailor new adaptive heuristics for interleaved sampling of the individual components of the GI solution
significantly improving overall performance. We present a novel component-based IGI framework for which we
achieve interactive frame rates for a range of effects such as indirect diffuse lighting, soft shadows and single
scatter homogeneous participating media.
Keywords: interactive, global illumination, adaptive sampling
ACM CCS: I.3.7 [Computer Graphics]: Three-Dimensional Graphics and Realism; I.3.3 [Computer Graphics]:
Picture/Image Generation

1. Introduction
Interactive high-fidelity graphics is one of the major goals of
the computer graphics research community. Progress within
interactive ray tracing (IRT) methods has made it possible
to achieve interactive rates on commodity PCs for moderately large dynamic scenes [WMG∗ 07]. Such advances have
opened up real possibilities for achieving interactive highfidelity graphics. While IRT methods handle primary rays
extremely efficiently, mainly via data structures and algorithms that exploit coherency, these methods do not unfortunately translate directly to high-fidelity effects such as physically based soft shadows, participating media and indirect
lighting.
c 2009 The Authors
Journal compilation c 2009 The Eurographics Association and
Blackwell Publishing Ltd. Published by Blackwell Publishing,
9600 Garsington Road, Oxford OX4 2DQ, UK and 350 Main
Street, Malden, MA 02148, USA.

A sampling approach that has shown significant promise
in decreasing the computational time of complex rendering solutions is interleaved sampling (IS) [KH01]. It has
already been used to substantially decrease computational
time [WKB∗ 02, SIP07b while maintaining image quality
[KH01]. Its ability to generate coherent samples over a regular grid makes it applicable for IRT and interactive applications. It does this by blending smoothly between regular
and irregular sampling, interleaving the samples of a regular grid in an irregular manner. This makes it a sampling
approach that minimizes the number of samples needed
while maintaining image quality, all traits that are utilized
to decrease the computational time needed for high-fidelity
effects.

2117

2118

P. Dubla et al. / Adaptive Interleaved Sampling for Interactive High-Fidelity Rendering

Another set of methods that have been shown to improve
the performance of rendering methods are the adaptive sampling techniques. Adaptive sampling methods compute only
those aspects of the solution which are considered more important based on some adaptive guidance scheme. The adaptive guidance strategy chosen can vary widely, from simple
methods that compute the difference between the radiance at
adjacent pixels [Whi80] to more complex techniques based
on properties of the human visual system [Mys98, YPG01].
The sampling method may depend on the adaptive guidance
and can use regular or irregular samples, subsampling or supersampling. While adaptive sampling methods have proven
useful for off-line rendering and certain interactive methods
[WDP99], because of their naturally incoherent nature, they
are yet to play a central role in IRT.
Interleaved sampling methods can provide relatively efficient ways of sampling for global illumination (GI) effects,
yet the sampling methods chosen are consistent throughout
an image and thus do not take into account possible variations
in the scene being rendered. Certain parts of the rendered
image may require more samples than others to achieve a
satisfactory solution. By adapting the interleaved sampling
to only shoot more samples when required, we make it possible to achieve reasonable computational gains without a
perceived loss in quality. Furthermore, due to the linearity
of the rendering equation, GI effects can be computed and
sampled independently. These individual effects as referred
to as components [SFWG04]. The guidance for the adaptive
interleaved sampling is tailored for each individual component further improving the performance of our method.
We demonstrate our technique using three components: soft
shadows, indirect diffuse lighting and participating media.
The computation of other high-fidelity rendering features
such as glossy effects and depth of field would follow a similar strategy.
The major contributions of our work are: extending interleaved sampling to be adaptive, computing further samples
only when necessary, and the use of adaptive interleaved
sampling for a distinct number of components, allowing us
to provide customized and efficient adaptive guidance for
each individual component. Furthermore, to the best of our
knowledge, interleaved sampling methods have never been
applied to participating media.

2. Related Work
In this section, we will discuss related work on IRT, adaptive
rendering as well as interleaved sampling.

2.1. Interactive ray tracing
Due to recent advances in computational power and the growing availability of shared memory parallel processing with the
rise in multicore CPUs, it is finally become feasible to make

ray tracing [Whi80], interactive. The first IRT publications
by Muss [Muu95] and Parker et al. [PMS∗ 99] produced the
first implementations of real-time ray tracers utilizing shared
memory multiprocessors with up to 96 processors.
Wald et al. [WSBW01] presented an IRT solution on a
cluster of PCs. They obtained their interactive rates by distributing the computation over a commodity cluster and by
carefully organizing the core data structures to exploit
cache coherence and through clever use of low-level instruction parallelism. They extended their work to include
GI effects in Wald et al. [WKB∗ 02] by using interleaved
sampling to compute the indirect lighting computation and
using photon mapping for caustics. The careful organization of data for intersection of rays with the acceleration
data structure was extended from the 4-way method used to
take advantage of SIMD instructions to full n × n packetization that improved coherence and thus rendering speeds
by Reshtov et al. [RSH05]. This method and similar ones
used structures that subdivided the traversal space in some
manner, be it uniformly or adaptively, and attempted to make
traversal and data access as coherent as possible. A large
amount of research has been conducted in this area for a
wide range of acceleration data structures such as kd-tree
[WH06], BVH [LYTM06, WBS07] and BIH [WK06]. Wald
et al. [WMG∗ 07] provides a comprehensive overview of IRT
for dynamic scenes. Such methods were also adopted by interactive ray tracers such as Manta [SBB∗ 06]. Furthermore,
the interactive ray tracer Razor [DHW∗ 07] extended these
concepts by providing level-of-detail methods for secondary
rays.

2.2. Adaptive rendering
Adaptive rendering methods for off-line systems have been
used since the earliest rendering algorithms [Whi80], where
it was recommended to remove aliasing by recursively subdividing based on the radiance at corners of areas, typically at
the corners of pixels. Other methods have been used for adaptive sampling including [PS89, Guo98] and have evolved into
rendering algorithms [Mys98, YPG01, CCW03] that account
for complex guidance systems based on the human visual
system [Dal93a, IKN98]. These methods adapt various aspects of the computation such as rays per pixel [CCW03],
indirect lighting [YPG01], components [Deb06] and participating media [ASGC06]. Debattista [DSSC05] presented
a progressive selective algorithm that provided independent
selective rendering guidance for individual components. In
addition, Walter et al. [WABG06] presented an adaptive computation for multiple components using Weber’s law based
on geometric heuristics as guidance to control the adaptation.
From an interactive perspective, a number of adaptive or
sparse sampling systems have been presented. The render
cache [WDP99, WDG02] was one of the first of such systems. The render cache rendered chosen pixels using ray

c 2009 The Authors
Journal compilation c 2009 The Eurographics Association and Blackwell Publishing Ltd.

P. Dubla et al. / Adaptive Interleaved Sampling for Interactive High-Fidelity Rendering

tracing and used a separate thread to asynchronously display the generated images. Interpolation and re-projection
were used for those pixels that were not directly updated
by the render thread. Unfortunately, the re-projection could
cause aliasing. Stamminger et al. [SHSS00] used the same
asynchronous display but avoided the artifacts present in the
render cache by rasterizing visibility for each frame and using ray tracing for specular objects. Haber et al. [HMYS01]
followed a similar approach but used a saliency map [IKN98]
to identify which non-diffuse objects to update according to
which objects were being attended to. Tole et al. [TPWG02]
presented a shading cache that used a rasterization method
and calculated radiance at each vertex using path tracing.
The geometry was adaptively sampled using a modified version of hierarchical radiosity [HSA91]. Bala et al. [BWG03]
extended the render cache using an edge-and-point map to
ensure that chosen samples were not interpolated across
boundaries. Woolley et al. [WLWD03] presented an adaptive
renderer that computed samples onto a kd-tree and interrupted the computation and displayed the resulting samples
using interpolation, through a combination of spatial and
temporal heuristics. Finally, Dayal et al. [DWWL05] used a
spatial and temporal caching of ray traced samples for their
adaptive frameless renderer.
2.3. Interleaved sampling
When correlated samples are utilized they are faster to generate and more coherent but this is at the expense of visible sampling patterns and structured noise. Decorrelation of
these samples on the other hand increases variance and therefore generates random noise. Interleaved sampling [KH01]
combats this by blending smoothly between both regular
and irregular sampling, interleaving the samples of a regular
grid, which are correlated, in an irregular way to maintain
coherency but reduce the aliasing of the sampled image.
Interleaved sampling has been used in to accelerate both
ray racing and rasterization. In the paper by Wald et al.
[WKB∗ 02] it was used to accelerate the GI solution by allowing only a subset of the virtual point lights that were generated to be sampled per pixel. Segovia et al. [SIP07b] also
proposed a real-time method for interleaved sampling where
they introduced a novel technique to maintain coherency between neighbouring pixels by splitting the rendered image
into a number of subbuffers. These subbuffers contain only
pixels from a specific part of the IS pattern. These are then
later recombined and filtered, taking into account discontinuities. In Sloan et al. [SGNS07] and Forest et al. [FBP08]
interleaved sampling is used to accelerate shadow generation
on the GPU by reducing the overall number of samples that
need to be calculated.
3. Adaptive Interleaved Sampling
In this section, we present our adaptive interleaved sampling method. Similarly to the work presented by Debattista

2119

[DSSC05], our method decomposes the standard rendering
equation as presented by Kajiya [Kaj86], with the participating media extensions as initially described by [KH84], into
individual components that have distinct adaptive guidance
mechanisms. These components (Figure 8) are direct illumination utilizing not just point but area light sources that
produce soft shadows (SS), indirect illumination or specifically indirect diffuse illumination (ID) and single scattering
homogenous participating media (PM). It would be straightforward to add other components to this framework following
a similar model. Furthermore, visibility and shading calculations are performed separately by utilizing deferred shading [DWS∗ 88]. This is done to maintain coherency when
executing shading operations as the method is designed predominantly with interactive environments in mind, where
maintaining coherency is crucial.
Our approach takes IS as presented in Keller et al. [KH01],
and later utilized by Wald et al. [WKB∗ 02] for indirect diffuse and soft shadow computation. We chose to utilize the
technique developed in [WKB∗ 02] for a number of reasons.
First, it allows us to reduce the number of samples needed
per pixel for each individual component, and given we are
attempting an interactive approach this is crucial. The use
of tiles in the technique increases spatial coherence when
computing the solution and the final step of filtering removes
the structural noise and produces a smooth and more importantly noise-free result unlike other monte carlo techniques.
The lack of noise means the technique is more stable temporally producing results that do not flicker frame to frame. The
IS when combined with adaptive sampling techniques results
in adaptive IS (AIS). This approach allows us to target components and create specific guidance metrics and heuristics
that exploit the strengths of each algorithm.
Our rendering method is illustrated in the pipeline presented in Figure 1. It computes the frame in tiles of N ×
M pixels, similar to the tiles used in traditional IS, with
one or more samples being mapped to each pixel. For each
pixel in each tile, initially the deferred shading information
is computed such as the object hit, normal and depth values and the albedo colour. Once all the deferred shading
calculations have been completed and stored, AIS is performed for each component being calculated, tile by tile.
The computation of each tile relies only on local information
and can be computed independently, making parallelization
straightforward.
For the adaptive interleaved sampling our method links
each pixel in the N × M tile to a particular subset of samples
in a component specific sampler. This is done to allow for
a reliable and repeatable sampling of the component space
with the aim of multiple iterations utilizing a disjoint subset
of samples for each pixel. Each sampler has a number of
disjoint sets of samples with each set used for a specific
sampling iteration, and each pixel being linked to a set of
samples, one from each disjoint set, which is always used for

c 2009 The Authors
Journal compilation c 2009 The Eurographics Association and Blackwell Publishing Ltd.

2120

P. Dubla et al. / Adaptive Interleaved Sampling for Interactive High-Fidelity Rendering

Figure 2: The three steps used in adaptive interleaved
sampling.
component calculations are then filtered, as per [WKB∗ 02]
as they contain structured noise due to the regular re-use of
samples as the pattern is tiled, and later composited into a
single resulting image.
Once the initial pass has been performed, an adaptive guidance metric analyses the N × M tile and determines if further
refinement is necessary. This step is performed for each individual component utilizing a component-specific heuristic.
If the guidance identifies that the number of samples used
is insufficient, a number of further iterations for each pixel
in the tile are performed with each new iteration accessing
the sample assigned to that pixel in the tile for that specific
iteration. Figure 2 demonstrates the results produced by the
three distinct stages for the SS component.

Figure 1: The pipeline for our rendering method. The primary hit calculation determines the object hit, depth and
normal calculation. The tiles shown are for illustrative purposes. They are much larger than they would be in practice
(a typical value is 3 × 3). Adaptive interleaved sampling is
computed for each tile and for every component. Adaptive
interleaved sampling of a soft shadow component for a given
tile is shown. Once adaptive interleaved rendering occurs,
all the components are filtered and composited.
that specific pixel as the tile pattern is repeated. This means
for the first sampling iteration the first pixel in the tile will
always use the same sample even as the tiling IS pattern is
repeated over the entire image. The results of each of the

Once the initial and refinement pass have been completed
for all tiles the resulting image is then filtered to remove
the structured noise that arises from the IS sampling. This is
done using an N × M discontinuity buffer [WKB∗ 02]. Unlike
[WKB∗ 02] our approach filters each individual component
separately. This is done as each components’ contribution
has a different structured noise pattern, due to their individual samplers, that when filtered individually produces a
smoother result than if the filtering were to happen after composition step. The filtering kernel utilized for these operations
is a simple box kernel, the same one utilized in [WKB∗ 02].
It should be noted that the filtering occurs on the original luminance values of each component before any tonemapping
or gamma correction has occurred.
In the end, for an N × M tile, each tile computes between
NM and PNM samples, P being dependant on the guidance as
well as the upper-bound allowed for each component. Finally,

c 2009 The Authors
Journal compilation c 2009 The Eurographics Association and Blackwell Publishing Ltd.

P. Dubla et al. / Adaptive Interleaved Sampling for Interactive High-Fidelity Rendering

2121

sections. In terms of the pseudo-code itself, the function getSample() returns a sample for the specific pixel. This sample
depends on the component being calculated and the number
of iterations that have already occurred. On lines 6 and 19 the
function contrib() calculates the contribution for a specific
component.
Listing 1: Generalized AIS workflow

Figure 3: ID adaptive guidance.

Figure 4: SS adaptive guidance.

1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19

// Initial pass
for (each pixel in tile)
pixel.col = Black
for 1 to initialIterations
sample = getSample∗(pixel)
pixel.col += contrib∗(sample)
getRefinmentInformation∗()
// Adaptive guidance
refine = getAdaptiveGuidance∗()
// Adaptive pass
if (refinementConditions∗(refine) == true)
numIterations = getIterations∗(refine)
for (each pixel in tile)
for 1 to numIterations
sample = getSample∗(pixel)
pixel.col += contrib∗(sample)

3.2. Indirect diffuse lighting
Figure 5: PM adaptive guidance.

the individual components are composited together with the
albedo colour. We decouple the albedo colour of the objects
from the lighting calculations to ensure that high frequency
detail, from textures for example, does not interfere when
filtering the individual components.
The distinct adaptive guidance utilized for each component means that, unlike standard IS, more samples are
taken in areas that contribute the most to the overall image.
Figures 3–5 show which parts of the image are adaptively
sampled for the SS, ID and PM components respectively.
Blue regions indicate areas that have not been adaptively
sampled at all while red regions indicate the amount of iterations performed (the brighter red the region is, the more
adaptive refinement has occurred).

3.1. Algorithm
In Listing 1, we show the generalized approach that is undertaken when using AIS. This algorithm is an expansion of the
second stage in the pipeline shown in Figure 1. Each function that ends with an asterisk denotes a component specific
function which is further expanded upon in the upcoming

Our indirect diffuse lighting approach is based on the same
model that is used in [WKB∗ 02]. We generate a set of VPLs
and then use these to perform the ID calculation. Once the
VPLs have been generated they are divided into subsets based
on the tile size. Therefore for a N × M tile the number of
subsets is NM. The sampler provides a sample to each pixel
in the tile indicating which of the subsets it must utilize,
ensuring that each pixel gets a unique subset. On subsequent
iterations the pixels will receive a new subset of VPLs to
sample ensuring that each pixel does not utilize the same
VPL subset more than once when refining.
As can be seen in Listing 2, the adaptive guidance runs an
initial pass on the tile while keeping track of how many VPLs
are occluded when they are sampled (Line 1). The average
ratio of the occluded VPLs to the total number of VPLs
sampled is then utilized to determine how much refinement
is needed. The amount of refinement is based on if any VPLs
were actually occluded and how many sets of VPLs have
been created (Lines 11 and 15). Figure 3 shows the amount of
adaptive ID refinement for a selection of scenes, the original
scenes can be seen in Figure 6(a) and (f).
Due to the fact that we utilize VPLs this heuristic is very
dependant on the VPL distribution as well as the scene geometry. Because the heuristic increases the sampling rate based
on VPL occlusion if a bad VPL distribution is generated or

c 2009 The Authors
Journal compilation c 2009 The Eurographics Association and Blackwell Publishing Ltd.

2122

P. Dubla et al. / Adaptive Interleaved Sampling for Interactive High-Fidelity Rendering

there is complex concave geometry present then a large number of VPLs, potentially all NM of them, will be sampled for
each pixel. This can be rectified by making sure that the generation places a sufficient number of VPLs in such a way as
to provide a good VPL distribution which takes into account
the current viewpoint, such as in [SIP07b].

Listing 2: ID pseudo-code
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17

getRefinmentInformationID() {
if (missedVPLs > 0)
totalMissedVPLs +=
missedVPLs/totalSampledVPLs
}
getAdaptiveGuidanceID() {
return(totalMissedVPLs/tile.size())
}
refinementConditionsID(refine) {
return(refine > 0.0)
}
getIterationsID(refine) {
return(refine ∗ IDmaxSamples)
}

rate a large number of samples would be wasted in any areas
that were fully lit or fully in shadow.
Listing 3: SS pseudo-code
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20

getRefinmentInformationSS() {
for (each light)
if occluded(lightSample)
missed++
missed/= numberLights
}
getAdaptiveGuidanceSS() {
return(missed/tile.size())
}
refinementConditionsSS(refine)
{
return(refine > 0.0 and refine < 1.0)
}
getIterationsSS(refine) {
return(refine ∗ SSmaxSamples)
}

3.4. Single-scattering participating media
3.3. Soft shadows
For the soft shadow computation, the sampler stores a distinct
set of sample points on the light source for each pixel in the
tile ensuring a good overall distribution without duplicating
samples between pixels in the tile. As can be seen in Listing 3,
the SS adaptive guidance, similar to the ID adaptive guidance,
runs an initial pass over the tile calculating the contribution
from the light for every pixel while storing how many of the
samples on the light are occluded (Line 1). This information,
the ratio of occluded samples to total samples taken, is then
used to determine how much refinement is needed (Line 9).
For any tile where all the pixels are not entirely lit or fully in
shadow we apply refinement.
Through empirical observation and Visual Difference Predictor (VDP) comparisons we determined that most errors
occurred inside the penumbra of the shadow and this is where
the refinement is focused. Figure 4 shows the level of adaptive
SS refinement on two scenes (Figure 6c and g).
For scenes with large area light sources, multiple area light
sources and very distant light sources the penumbra of the
shadows may make up a large part of the rendered image.
This in turn would mean a degradation in performance as
large parts of image would require refinement. While this is
a limitation of the heuristic it should be noted that a nonadaptive approach, using a fixed number of samples, would
simply provide very deteriorated shadows unless a very high
sampling rate was utilized. But in the case of a high sampling

Our PM is a single-scatter implementation that uses homogenous media. The PM utilizes a sampler that returns a starting
offset along the ray for that pixel. For a tile of N × M pixels each one is assigned a segment of space along the ray
equal to the step-size of the ray marching divided it into
NM equal parts. Each segment is then further equally subdivided according to maximum amount of refinement that
will take place. Each pixel then utilizes the starting point of
these segments as offsets along the ray. This ensures that that
each pixel in the tile will get a unique starting offset for all
iterations, and these will be equally spaced apart, causing
each ray to interleave its ray marching guaranteeing superior
coverage of the sampling space.
As can be seen in Listing 4 the adaptive guidance runs
an initial pass on the tile while keeping track of two values.
The first pertains to how many sampling points along the ray
were occluded from the light source while the ray marching
was performed (Line 6) as this detects transitions between
lit regions and regions in shadow. The second value records
how many of the sampling points along the ray are within
a certain distance of the light source. This distance is adjusted by the attenuation co-efficient of the medium (Line 9).
This focuses on another prominent effect in PM which is the
halo that develops around a light source when it is within a
medium.
As each new pixel in the tile is calculated, these two values are combined into a single metric. This value is then
compared to the value calculated for the previous pixel. If

c 2009 The Authors
Journal compilation c 2009 The Eurographics Association and Blackwell Publishing Ltd.

P. Dubla et al. / Adaptive Interleaved Sampling for Interactive High-Fidelity Rendering

2123

Figure 6: The scenes used for obtaining results. All images rendered with AIS.
these two values differ this indicates a need for refinement
(Line 14). The comparison with the previous value is arbitrary, the heuristic is trying to identify differences with
the participating media contribution for the entire tile. This
particular heuristic focuses computation in tiles that are on
shadow volume boundaries and around objects within the
volumes where the effects of participating media are most
apparent. It also focuses on areas that are in the halo produced by any light sources. Figure 5 shows the PM adaptive
guidance as applied to two of the scenes (Figure 6b and h)

4. Implementation and Results

Due to the approach of this heuristic a degradation of
performance will occur if the scene contains geometry that
creates a large number of irregular shadow volumes that
overlap in a specific view. In this case a large amount of refinement would occur affecting performance. This is a similar limitation to the one exhibited in the SS heuristic in
Section 3.3.

The implementation was designed to be extensible and
portable. The kernel currently only traces single rays at a
time. No packetization has been implemented at this stage.
The core of the ray tracing kernel consists of an implementation of dynamic bounding volume hierarchy (BVH) as described in Wald et al. [WBS07]. SIMD computation has
been limited to a single aspect of the BVH traversal, the ray

In this section, we present the implementation we used to
demonstrate our framework and show results.

4.1. Implementation
Our framework implementation was written using portable
C++. The current version of the framework compiles and
runs under MS Windows, Linux and Mac OSX.

c 2009 The Authors
Journal compilation c 2009 The Eurographics Association and Blackwell Publishing Ltd.

2124

P. Dubla et al. / Adaptive Interleaved Sampling for Interactive High-Fidelity Rendering

bounding volume intersection. The BVH currently only supports the updating of the bounding volumes of each node at
each frame.
Listing 4: pseudo-code
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43

getRefinmentInformationPM() {
// N = number of steps when ray
// marching
for I = 1 to N
for (each light)
if occluded(lightSample)
missed++
if (distLight < threshold - volume.attenCoef)
inHalo++
missed /= numberLights
// Combine values
value = 0, parts = 0
if (missed > and missed < N)
value += (missed/N)
parts++

work packets from the job queue. These work packets now
represent pixels to be filtered. When filtering is completed,
the threads wait on a barrier again before commencing the
next frame. A central thread is responsible for work packet
creation and allocation onto the job queue. It is also responsible for displaying the image.
With regard to the metric calculations the decision to keep
all refinement operations local, so that for each component
when refining only the information for that specific component for that tile was utilized, was made to ensure the
highest level of parallelism possible was achieved. This also
ensured that coherency was maintained as each component
calculation, and any further refinement calculations, were
performed at the same time. Any heuristics requiring global
information would mean a loss of either parallelism or coherence which would be undesirable in an interactive setting.
Either the first iterations for all the components would need
to be calculated before any refitment occurred or each tile
would need to calculate all the components related to it before
refining.
With regard to our indirect lighting, due to the continuous
nature of the indirect diffuse solution, this is computed at
lower resolutions. The subsampled solution is updated using a guided bilinear filter [TM98] based on joint bilateral
upsampling [KCLU07], similar to the upsampling solution
used in [SGNS07]. Our implementation uses the full resolution solution computed at the deferred shading stage as
guidance. It utilizes the depth at the individual pixels as well
as normals to keep within object boundaries and to avoid
up-sampling over discontinuities. For the guided bilinear filter we use a modified version of the joint bilateral filter and
replace the expensive Gaussian filters with simple bilinear
ones. Assuming V VPLs are generated and an IS pattern of
N × M pixels is used IGI will sample a single subset of V/NM
VPLs per pixel. Our technique will sample between V/NM
and V VPLs, IGIs maximum sampling rate being our minimum one. Therefore while we compute our indirect lighting
at a lower resolution our per-pixel cost can be substantially
higher than in IGI for pixels that need refinement.

if (inHalo > 0 and inHalo < N)
value += (inHalo/N)
parts++
if (parts > 1)
value /= parts
// Check against previous
if (prevValue != value)
different++
}
getAdaptiveGuidancePM() {
return(different/tile.size())
}
refinementConditionsPM(refine) {
return(refine > 0)
}
getIterationsPM(refine) {
return(refine ∗ PMmaxSamples)
}

The renderer is designed to be multithreaded. At the start
of every frame, each thread collects a work packet detailing
the pixels to be rendered, from a centralized job queue. For
each tile the thread computes the primary rays and all other
components. After computing a work packet the job queue
is accessed for further work packets. When no further work
packets exist on the job queue, the rendering stage is considered complete. At this stage the threads wait on a barrier.
After barrier synchronization, each thread collects further

This helps to highlight one particular aspect of our adaptive sampling. It can complement subsampling well since the
number of samples used for the component computation (in
this case ID) can adapt based on complementary heuristics.
When upsampling the ID using only one subset of the VPLs,
as in IGI [WKB∗ 02], there are occasions when none or very
few of the VPLs in that subset are visible. These conditions
often lead to flickering when upsampling, particularly in areas that are predominantly indirectly lit and highly occluded.
The AIS takes care of this problem naturally via the heuristic that detects these undersampled pixels and, if necessary,
further samples more VPLs. While there are computational
costs associated with the upsampling and extra VPL sampling our approach is still faster than IGI as can be seen in
Section 4.2.

c 2009 The Authors
Journal compilation c 2009 The Eurographics Association and Blackwell Publishing Ltd.

2125

P. Dubla et al. / Adaptive Interleaved Sampling for Interactive High-Fidelity Rendering

Figure 7: The scenes used for obtaining participating media results. All images rendered with AIS.
All the random sampling within the renderer relies on
low discrepancy sampling [KK02] to produce unbiased and
well distributed sample points and maintain spatial coherency across the multiple threads as well as temporal
coherency.
4.2. Results
The following results were generated on an 8-core Mac Pro
running at 3.2 GHz, with a 2GB of memory. We present
results for eleven scenes. For each scene we will show the
average frame rate for each component on its own as well
as an average frame rate for when all the components were
being calculated simultaneously.
We use a total of eight unique scenes for our results,
see Figure 6. The labels in Figure 6 correspond to how we
will refer to the scenes in the text. We also use subdivided,
Office and Shirely6 for the participating media results by
adding a participating media volume to those scenes, see
Figure 7.

Each scene was rendered with our novel AIS and AIS
where the maximum amount of refinement possible was performed. We will refer to these as AIS and A-MAX, respectively. We also compare directly with our IGI implementation
based on [WKB∗ 02] (referred to as IGI), for the combined
indirect lighting and soft shadow components. For all renderers the tile size was set to 3 × 3. Each scene was rendered
interactively for a total of 100 frames and the average frame
rate was computed. For the ID scenes 256 VPLs were used.
The base value for the initial pass was set to one for each
component. AIS and A-MAX use subsampling at a quarter
of the resolution, IGI is the standard version and does not.
The specific thresholds and values utilized our implementation as pertaining to the heuristics were as follows. For ID
the IDmaxSamples was set to the number of VPL subsets
which is 9. For SS the SSmaxSamples was also 9. In PM the
distance threshold was set to 1.0 as when the distance to the
light drops below one so does the divisor of the geometric
term and this is where the majority of the PM halo appears.
Finally, the PMmaxSamples for PM was also set to 9.

Table 1: Frames per seconds for the eleven scenes rendered with different components.

ID

Cornell
Deskar
Subdivided
Desk
Sibenik
Office
Conference
Shirley6
SubdividedPM
OfficePM
Shirley6PM
Average

SS

PM

FULL

A

A-MAX

A

A-MAX

A

A-MAX

A

A-MAX

IGI

10.17
5.29
15.19
9.99
3.14
6.95
4.04
14.61
15.19
6.95
14.61

3.57
1.78
5.05
3.11
1.45
3.08
1.74
5.11
5.05
3.08
5.11

9.56
5.12
17.74
12.02
5.03
8.11
8.41
16.77
17.74
8.11
16.77

5.24
3.46
8.16
4.92
1.20
4.10
4.12
7.00
8.16
4.10
7.00

–
–
–
–
–
–
–
–
3.98
6.97
5.52

–
–
–
–
–
–
–
–
1.43
2.40
1.76

6.25
3.21
11.03
6.94
2.45
5.06
3.20
9.40
3.12
3.37
4.04

2.35
1.27
3.55
2.15
1.01
2.03
1.35
3.38
1.05
1.13
1.15

1.75
0.95
2.89
1.71
0.66
1.70
0.92
2.85
–
–
–

9.65

3.46

11.40

5.22

5.49

1.86

5.28

1.86

1.68

c 2009 The Authors
Journal compilation c 2009 The Eurographics Association and Blackwell Publishing Ltd.

2126

P. Dubla et al. / Adaptive Interleaved Sampling for Interactive High-Fidelity Rendering

Table 2: Speedup for the 11 scenes rendered with different components comparing adaptive (AIS) with max adaptive (A-MAX) and interactive
global illumination (IGI).

ID

SS

PM

A vs. A-MAX

A vs. A-MAX

A vs. A-MAX

A vs. A-MAX

A vs. IGI

Cornell
Deskar
Subdivided
Desk
Sibenik
Office
Conference
Shirley6
SubdividedPM
OfficePM
Shirley6PM

2.85
2.98
3.01
3.21
2.17
2.26
2.32
2.86
3.01
2.26
2.86

1.82
1.48
2.17
2.44
4.19
1.98
2.04
2.40
2.17
1.98
2.40

–
–
–
–
–
–
–
–
2.78
2.90
3.14

2.66
2.53
3.11
3.23
2.42
2.49
2.38
2.78
2.97
2.98
3.53

3.57
3.39
3.81
4.07
3.68
2.98
3.47
3.29
–
–
–

Average

2.71

2.28

2.94

2.82

3.53

Table 1 shows the timing for each of the renderers for the
scenes and components in frames per seconds. Table 2 shows
the same results tabulated as speedups for AIS against both AMAX and IGI. The average speedup of AIS over A-MAX is
2.82 and over IGI is 3.53. As mentioned in Section 3 and later
Section 4.1 while our approach does share some common
strategies with IGI we have made significant changes. We
utilize a higher sampling rate for light sources as well as
the different approach for calculating the indirect lighting
solution. We include a comparison against IGI here as it is
the state-of-the-art interactive CPU-based GI solution and
provides a good point of comparison.

4.2.1. Validation
In order to validate the results of our renderer, we have
selected a single image (those shown in Figures 6 and 7)
rendered by our renderers for each scene and validated it
against a reference path traced (PT) image. These images
were compared using the High Dynamic Range (HDR) VDP
[MDMS05], an HDR version of the VDP psychophysical
metric, developed by Daly [Dal93b]. HDR–VDP compares
two images and identifies the perceptual differences between
those two images by taking into account limitations in the
human visual system. HDR–VDP results can be summarized
by the percentage of different pixels detected with a certain
probability. We present results for two probabilities: P(X) ≥
75% and P(X) ≥ 95%.
We present results for AIS, A-MAX and IGI, for combined
components, as computed in the previous section against
path traced images computed with 2500 samples per pixel.
Table 3 show the results of the HDR–VDP calculations
while an example of the comparison images can be found in
Figure 8. As can be seen there is very little perceptual dif-

FULL

Table 3: Results for HDR–VDP calculations in %.

AIS

A-MAX

IGI

P(X)

75%

95%

75%

95%

75%

95%

Cornell
Deskar
Subdivided
Desk
Sibenik
Office
Conference
Shirley6
SubdividedPM
OfficePM
Shirley6PM

0.86
1.09
1.15
1.86
3.52
0.41
1.48
0.08
1.90
0.26
2.10

0.41
0.57
0.62
0.97
1.68
0.17
0.97
0.03
1.07
0.11
0.96

0.55
0.80
0.83
1.21
2.91
0.12
1.46
0.02
1.12
0.25
1.35

0.25
0.42
0.36
0.74
1.38
0.03
1.02
0.00
0.69
0.09
0.57

0.80
1.26
0.81
2.14
2.54
0.41
1.66
0.18
–
–
–

0.36
0.59
0.56
1.01
1.25
0.14
1.11
0.06
–
–
–

Average

1.29

0.71

0.95

0.54

1.17

0.67

ference for the images obtained for AIS, A-MAX and IGI
compared with the path traced images and the perceptual
differences are comparable across the three renderers. These
results indicate the speedup demonstrated previously comes
at little loss of perceptual quality. After analysis of the differences that were identified when comparing with ground truth
it was found that they can largely be attributed to aliasing
in the images which we have identified as an area for future
work.

5. Conclusions and Future Work
Interactive GI remains a key challenge in computer graphics research. In this paper, we have presented a method for
rendering many of the effects associated with high-fidelity

c 2009 The Authors
Journal compilation c 2009 The Eurographics Association and Blackwell Publishing Ltd.

P. Dubla et al. / Adaptive Interleaved Sampling for Interactive High-Fidelity Rendering

2127

Figure 8: A full set of results for the Office scene (including the PM version).

graphics at close to interactive rates. Combining interleaved
sampling with an adaptive approach, together with efficient
component-specific adaptive guidance methods, has allowed
us to significantly reduce computational costs while maintaining the same high perceptual quality of the resultant
images.
Our system has been designed to enable all of the components of high-fidelity rendering to be incorporated in a
straightforward manner. All that is required is an efficient
adaptive guidance mechanism to be developed for the component being added. While only local heuristics that utilize
information for a single tile and one component have been
implemented global heuristics that use information from surrounding tiles as well as multiple components would be an
interesting avenue for future exploration.
We have not yet adopted a very fast ray tracing kernel.
However, unlike most other adaptive approaches, our method

should adapt well to fast ray tracing kernels since the guidance and sampling for each tile are computed at the same
time making it naturally coherent and potentially allowing
for packetization. Tracing the rays for the SS and ID components could be trivially packetized as multiple rays would
share an origin on a light source or at a VPL due to the
way our methods reuses samples for the same pixel in the IS
pattern as it it tiled.

Acknowledgements
This research was partially funded by UK-EPSRC grant
EP/D069874/2. We thank Greg Ward for the Office and Conference scenes from Radiance package, Marko Dabrovic for
the ibenik cathedral model and Peter Shirely for the Shirley6
model. Finally, we thank Stanford’s Graphics Group for the
Bunny model from the Stanford 3D Repository.

c 2009 The Authors
Journal compilation c 2009 The Eurographics Association and Blackwell Publishing Ltd.

2128

P. Dubla et al. / Adaptive Interleaved Sampling for Interactive High-Fidelity Rendering

Figure 8: Continued.

References
[ASGC06] ANSON O., SUNDSTEDT V., GUTIERREZ D.,
CHALMERS A.: Efficient selective rendering of participating
media. In APGV 2006 - Symposium on Applied Perception
in Graphics and Visualization (July 2006), ACM.
[BWG03]
BALA K., WALTER B., GREENBERG D. P.:
Combining edges and points for interactive high-quality
rendering. ACM Trans. Graph. 22, 3 (2003), 631–
640.
[CCW03] CATER K., CHALMERS A., WARD G.: Detail
to attention: exploiting visual tasks for selective rendering. In EGRW ‘03: Proceedings of the 14th Eurographics workshop on Rendering (Aire-la-Ville, Switzerland,
Switzerland, 2003), Eurographics Association, pp. 270–
280.

[Dal93a]
DALY S.: The visible differences predictor: an
algorithm for the assessment of image fidelity. Digital
images and human vision (1993), 179–206.
[Dal93b]
DALY S.: The Visible Differences Predictor: An
Algorithm for the Assessment of Image Fidelity. In Digital
Images and Human Vision, A.B. Watson (Ed.), MIT Press,
Cambridge, MA, 1993, pp. 179–206.
[Deb06]
DEBATTISTA K.: Selective Rendering for HighFidelity Graphics. PhD thesis, University of Bristol,
August 2006.
[DHW∗ 07] DJEU P., HUNT W., WANG R., ELHASSAN I.,
STOLL G., MARK W. R.: Razor: An Architecture for Dynamic Multiresolution Ray Tracing. Tech. Rep. TR-07-52,
The University of Texas at Austin, Department of Computer Sciences, January 24 2007.

c 2009 The Authors
Journal compilation c 2009 The Eurographics Association and Blackwell Publishing Ltd.

P. Dubla et al. / Adaptive Interleaved Sampling for Interactive High-Fidelity Rendering

[DSSC05] DEBATTISTA K., SUNDSTEDT V., SANTOS L. P.,
CHALMERS A.: Selective component-based rendering. In
GRAPHITE, 3rd International Conference on Computer
Graphics and Interactive Techniques in Australasia and
South East Asia (November 2005), ACM Press, pp. 13–
22.
[DWS∗ 88] DEERING M., WINNER S., SCHEDIWY B., DUFFY
C., HUNT N.: The triangle processor and normal vector
shader: a vlsi system for high performance graphics. In
SIGGRAPH ’88: Proceedings of the 15th annual conference on Computer graphics and interactive techniques
(New York, NY, USA, 1988), ACM, pp. 21–30.
[DWWL05]
DAYAL A., WOOLLEY C., WATSON B., LUEBKE
D. P.: Adaptive frameless rendering. In Rendering Techniques (2005), pp. 265–275.
[FBP08] FOREST V., BARTHE L., PAULIN M.: Accurate shadows by depth complexity sampling. Computer Graphics
Forum, Eurographics 2008 Proceedings (2008).
[Guo98] GUO B.: Progressive radiance evaluation using
directional coherence maps. In SIGGRAPH ’98: Proceedings of the 25th annual conference on Computer graphics
and interactive techniques (New York, NY, USA, 1998),
ACM Press, pp. 255–266.
[HMYS01] HABER J., MYSZKOWSKI K., YAMAUCHI H.,
SEIDEL H.-P.: Perceptually guided corrective splatting.
In EG 2001 Proceedings. Chalmers A., Rhyne T.-M.,
(Eds.), vol. 20(3). Blackwell Publishing, 2001, pp. 142–
152.
[HSA91] HANRAHAN P., SALZMAN D., AUPPERLE L.: A
rapid hierarchical radiosity algorithm. In SIGGRAPH ’91:
Proceedings of the 18th annual conference on Computer graphics and interactive techniques (New York, NY,
USA, 1991), ACM Press, pp. 197–206.
[IKN98] ITTI L., KOCH C., NIEBUR E.: A model of
Saliency-Based Visual Attention for Rapid Scene Analysis. In Pattern Analysis and Machine Intelligence (1998),
vol. 20, pp. 1254–1259.
[Kaj86] KAJIYA J. T.: The rendering equation. In SIGGRAPH ’86: Proceedings of the 13th Annual Conference
on Computer Graphics and Interactive Techniques (New
York, NY, USA, 1986), ACM Press, pp. 143–150.
COHEN M.,
LISCHINSKI D.,
[KCLU07] KOPF J.,
UYTTENDAELE M.: Joint bilateral upsampling. ACM Transactions on Graphics (Proceedings of SIGGRAPH 2007)
26, 3 (2007), ACM Press, p. 96.
[KH84] KAJIYA J. T., HERZEN B. P. V.: Ray tracing volume
densities. SIGGRAPH Comput. Graph. 18, 3 (1984), 165–
174.

2129

[KH01] KELLER A., HEIDRICH W.: Interleaved sampling. In
Proceedings of the 12th Eurographics Workshop on Rendering Techniques (London, UK, 2001), Springer-Verlag,
pp. 269–276.
[KK02] KOLLIG T., KELLER A.: Efficient multidimensional
sampling. Computer Graphics Forum 21, 3 (Sept. 2002),
557–563.
[LYTM06] LAUTERBACH C., YOON S.-E., TUFT D.,
MANOCHA D.: RT-DEFORM: interactive ray tracing of dynamic scenes using BVHs. In 2006 IEEE Symposium on
Interactive Ray Tracing (2006), pp. 39–45.
[MDMS05] MANTIUK R., DALY S., MYSZKOWSKI K., SEIDEL
H.-P.: Predicting Visible Differences in High Dynamic
Range Images - Model and its Calibration. Human Vision and Electronic Imaging X, IS&T/SPIE’s 17th Annual
Symposium on Electronic Imaging (2005), 204–214.
[Muu95] MUUSS M. J.: Towards real-time ray-tracing of
combinatorial solid geometric models. In Proceedings of
BRL-CAD Symposium ’95 (June 1995).
[Mys98] MYSZKOWSKI K.: The visible differences predictor: applications to global illumination problems. In Eurographics Workshop on Rendering (1998), pp. 223–236.
PARKER S., MARTIN W., SLOAN P.-P. J., SHIRLEY
[PMS∗ 99]
P., SMITS B., HANSEN C.: Interactive ray tracing. In 1999
Symposium Interactive 3D Computer Graphics (1999),
pp. 119–126.
[PS89] PAINTER J., SLOAN K.: Antialiased ray tracing by
adaptive progressive refinement. In SIGGRAPH ’89 (New
York, NY, USA, 1989), ACM Press, pp. 281–288.
[RSH05] RESHETOV A., SOUPIKOV A., HURLEY J.: Multilevel ray tracing algorithm. ACM Trans. Graph. 24, 3
(2005), 1176–1185.
[SBB∗ 06] STEPHENS A., BOULOS S., BIGLER J., WALD I.,
PARKER S. G.: An application of scalable massive model
interaction using shared memory systems. In Proceedings
of the 2006 Eurographics Symposium on Parallel Graphics and Visualization (2006), pp. 19–26.
[SFWG04] STOKES W. A., FERWERDA J. A., WALTER B.,
GREENBERG D. P.: Perceptual illumination components: a
new approach to efficient, high quality global illumination
rendering. ACM Trans. Graph. 23, 3 (2004), 742–749.
GOVINDARAJU N. K.,
[SGNS07] SLOAN P.-P.,
NOWROUZEZAHRAI D., SNYDER J.: Image-based proxy
accumulation for real-time soft global illumination. In
PG ’07: Proceedings of the 15th Pacific Conference on
Computer Graphics and Applications (Washington, DC,
USA, 2007), IEEE Computer Society, pp. 97–105.

c 2009 The Authors
Journal compilation c 2009 The Eurographics Association and Blackwell Publishing Ltd.

2130

P. Dubla et al. / Adaptive Interleaved Sampling for Interactive High-Fidelity Rendering

[SHSS00]
STAMMINGER M., HABER J., SCHIRMACHER H.,
SEIDEL H.-P.: Walkthroughs with corrective texturing. In
Rendering Techniques 2000 (Proceedings of the Eleventh
Eurographics Workshop on Rendering) (New York, NY,
2000), Peroche B., Rushmeier H. (Eds.), Springer Wien,
pp. 377–388.
[SIP07b] SEGOVIA B., IEHL J. C., P´EROCHE B.: Metropolis
instant radiosity. Computer Graphics Forum 26, 3 (Sept.
2007), 425–434.
[TM98] TOMASI C., MANDUCHI R.: Bilateral filtering for
gray and color images. iccv 00 (1998), 839.
[TPWG02]
TOLE P., PELLACINI F., WALTER B., GREENBERG
D.: Interactive Global Illumination. In SIGGRAPH’02
(2002), ACM Press.
[WABG06]
WALTER B., ARBREE A., BALA K., GREENBERG
D. P.: Multidimensional lightcuts. ACM Trans. Graph. 25,
3 (2006), 1081–1088.
[WBS07] WALD I., BOULOS S., SHIRLEY P.: Ray tracing
deformable scenes using dynamic bounding volume hierarchies. ACM Trans. Graph. 26, 1 (2007), 6.
[WDG02]
WALTER B., DRETTAKIS G., GREENBERG D.: Enhancing and optimizing the render cache, 2002.
[WDP99]
WALTER B., DRETTAKIS G., PARKER S.: Interactive rendering using the render cache. In Rendering techniques ’99 (June 1999), Lischinski D., Larson G. (Eds.),
vol. 10, pp. 235–246.
[WH06]
WALD I., HAVRAN V.: On building fast kd-trees
for ray tracing, and on doing that in o(n log n). 61–69.

[Whi80]
WHITTED T.: An improved illumination model for
shaded display. Commun. ACM 23, 6 (1980), 343–349.
[WK06]
W¨ACHTER C., KELLER A.: Instant Ray Tracing:
The Bounding Interval Hierarchy. In Rendering Techniques 2006 (Proc. of 17th Eurographics Symposium
on Rendering) (2006), Akenine-M¨oller T., HEIDRICH W.
(Eds.), pp. 139–149.
[WKB∗ 02] WALD I., KOLLIG T., BENTHIN C., KELLER A.,
SLUSALLEK P.: Interactive global illumination using fast
ray tracing. In EGRW ’02: Proceedings of the 13th Eurographics workshop on Rendering (Aire-la-Ville, Switzerland, Switzerland, 2002), Eurographics Association,
pp. 15–24.
[WLWD03]
WOOLLEY C., LUEBKE D., WATSON B., DAYAL
A.: Interruptible rendering. In SI3D ’03: Proceedings of
the 2003 symposium on Interactive 3D graphics (New
York, NY, USA, 2003), ACM Press, pp. 143–151.
[WMG∗ 07] WALD I., MARK W. R., G¨UNTHER J., BOULOS
S., IZE T., HUNT W., PARKER S. G., SHIRLEY P.: State of
the Art in Ray Tracing Animated Scenes. In Eurographics
2007 State of the Art Reports (2007).
[WSBW01]
WALD I., SLUSALLEK P., BENTHIN C., WAGNER
M.: Interactive Rendering With Coherent Raytracing. In
EUROGRAPHICS 2001 (Manchester, United Kingdom,
September 2001), pp. 153–164.
[YPG01]
YEE H., PATTANAIK S., GREENBERG D. P.: Spatiotemporal sensitivity and visual attention for efficient
rendering of dynamic environments. ACM Trans. Graph.
20, 1 (2001), 39–65.

c 2009 The Authors
Journal compilation c 2009 The Eurographics Association and Blackwell Publishing Ltd.

