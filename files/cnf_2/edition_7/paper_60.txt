Volume 28 (2009), Number 2

EUROGRAPHICS 2009 / P. Dutré and M. Stamminger
(Guest Editors)

Deblurring by Matching
Cosmin Ancuti∗ , Codruta Orniana Ancuti∗ and Philippe Bekaert∗
∗ Hasselt University -tUL-IBBT,
Expertise Centre for Digital Media,
Wetenschapspark 2, Diepenbeek, B3590, Belgium.
firstname.secondname@uhasselt.be

Abstract
Restoration of the photographs damaged by the camera shake is a challenging task that manifested increasing
attention in the recent period. Despite of the important progress of the blind deconvolution techniques, due to the
ill-posed nature of the problem, the finest details of the kernel blur cannot be recovered entirely. Moreover, the
additional constraints and prior assumptions make these approaches to be relative limited.
In this paper we introduce a novel technique that removes the undesired blur artifacts from photographs taken
by hand-held digital cameras. Our approach is based on the observation that in general several consecutive
photographs taken by the users share image regions that project the same scene content. Therefore, we took
advantage of additional sharp photographs of the same scene. Based on several invariant local feature points,
filtered from the given blurred/non-blurred images, our approach matches the keypoints and estimates the blur
kernel using additional statistical constraints.
We also present a simple deconvolution technique that preserves edges while minimizing the ringing artifacts in
the restored latent image. The experimental results prove that our technique is able to infer accurately the blur
kernel while reducing significantly the artifacts of the spoilt images.
Categories and Subject Descriptors (according to ACM CCS): Enhancement [I.4.3]: Sharpening and deblurring;
—Image Processing and Computer Vision [I.4.9]: Applications—

1. Introduction
In recent years hand-held digital cameras have become very
popular in many householders. A common problem that amateur photographs are faced with is the motion blur distortions due to the camera shake. Every slight shake during the
exposure time increases the undesired blur artifacts. Only
adjusting the exposure time may not solve entirely this trouble. For short exposure times, motion blur is still perceptible
and, in addition, the darkness and the noise can destroy important details.
Image deblurring has long been a fundamental problem
that preoccupied research community. Removing the undesired artifacts of a blurry image is translated into a deconvolution problem. However, the problem is mathematically
under-constrained.
Even though the blur kernel is given, the problem, known
c 2008 The Author(s)
Journal compilation c 2008 The Eurographics Association and Blackwell Publishing Ltd.
Published by Blackwell Publishing, 9600 Garsington Road, Oxford OX4 2DQ, UK and
350 Main Street, Malden, MA 02148, USA.

also as non-blind deconvolution, is still ill-posed and therefore the finest details are irreversibly ruined.

On the other hand, restoring the original image without
a priori knowledge of the blur kernel or PSF - point spread
function, termed as blind deconvolution, is radically more
challenging. In this case a twofold problem needs to be
solved at the same time: estimate the blur kernel and recover the latent image. Despite of the progress in the field
introduced by the recent techniques [FSH∗ 06, LFDF07,
YSQS08, SJA08], real blur kernels are complicated, being
described by various distributions, that are difficult to infer
accurately from a single image. Figure 3 presents the inferred blur kernels yielded by two recent state-of-the-art approaches [FSH∗ 06, SJA08]. Images have been synthetically
blurred and for generating the presented results we used the

620

C. Ancuti et al. / Deblurring by Matching

Figure 1: Left: A blurred photography. Middle: Image restored with method of Shan et al. [SJA08]. Right: Our result using an
additional undistorted photography (see Figure 2) of the same scene.

original code provided by the authors on their web pages†
‡
. The parameters have been tuned following the authors’
indications. Therefore, for large sizes and complex kernels,
when the existent single image deblurring techniques perform poorly, certain constraints are required.
In this paper we present a deblurring technique that takes
advantage of the common information existent in a collection of photographs. Our restoration process uses the additional information borrowed from a different photography
that shares corresponding scene region(s) with the blurry image. Although taken from the same scene, our approach is
able to deal with photographs that do not necessarily include
entirely the same information. In this work we assume that
consecutive photographs share common regions (e.g background) that can be matched in order to provide additional
information used in our restoration procedure.
Our approach relies on local feature points extracted from
the blurred/non-blurred images. The potential corresponding
points are filtered by employing a geometric invariant detector/descriptor. We opted for the widely-used SIFT (Scale
Invariant Feature Transform) [Low04] operator. In order to
increase its distinctness in the color space the SIFT signature
is mixed with the color invariant moments. When the number of extracted feature points is reduced, additional invariant feature points can be processed for a higher robustness of
the matching procedure. An efficient optimization technique
combined with several probabilistic constraints is performed
in order to reject outliers and to estimate the blur kernel reliably.
Finally, we propose a simple edge-preserving deblurring
technique to restore the latent image. Built on the classical
Richardson-Lucy combined with anisotropic diffusion the
technique is robust, preserving the finest details and reducing the ringing artifacts (see Figure 1).
We are not the first that borrow information from another
† www.people.csail.mit.edu/fergus/research/deblur.html
‡ www.cse.cuhk.edu.hk/∼leojia/projects/motion_deblurring/index.html

photography in order to deblur images. The idea of using
additional multiple images of the same scene as an additional constraint has been also used previously but when
the same image was blurred in different directions [RAP05,
CYCKQ08] or a pair of noisy/blurred images of exactly the
same scene was available [YSQS07b]. However these approaches make several assumptions (images need to be previously aligned or the direction of the blur is given) which in
general are not true in real cases. Moreover, compared with
previous approaches [RAP05,FSH∗06,YSQS07a], our technique finds corresponding patches restoring the degraded
image without involving any input of the user. The technique is able to handle blur kernels with various distributions
and with large sizes while no additional knowledge about the
kernel size or shape are required.
In the experiments the method has been tested for synthetic but also for real images. The results show that our
approach yields more pleasant results comparing with the
existent methods being able to restore the latent image accurately.

+

+

Figure 2: Additional photography (left side) with the corresponding regions (red squares) used to deblur our latent
image (right side).

2. Related Work
Image restoration is a longstanding problem in image processing and computer graphics. There are two important
sources of degradation: noise and blur. This paper addresses
the problem of restoring images degraded only by the motion
c 2008 The Author(s)
Journal compilation c 2008 The Eurographics Association and Blackwell Publishing Ltd.

C. Ancuti et al. / Deblurring by Matching

621

a.

b.

c.
Figure 3: Blind deconvolution performance. a) True kernels. b) Result of Fergus et al. [FSH∗ 06] method. c)Result of Shan et
al. [SJA08] method. The parameters have been tuned based on the author’s indications in order to produce accurate results.

blur. In the remaining part of this section we review briefly
the main deblurring technique classes: blind, non-blind and
multiple image deconvolution.
Non-blind deconvolution methods restore the latent image from the altered blurry image when the blur kernel is
assumed to be known. A comprehensive survey of the traditional non-blind deconvolution algorithms [TIK43, Kal60,
WIE64] is included in the study of Banham and Katsaggelos
[BK97]. Despite introduced decades ago, Richardson-Lucy
algorithm [RIC72,LUC74] is probably the most known technique. Richardson-Lucy is an iterative procedure that optimize a likelihood function assuming that pixels are Poisson distributed. A common signal processing technique,
known for preserving sharp discontinuities, is the total variation regularization method [RF92, CW98]. Several methods solve the deconvolution in wavelet or frequency domain
[JZ02, NB04]. The method of Yuan et al. [YSQS08] combines the joint bilateral upsampling [KCLU07] with the
standard Richardson-Lucy algorithm in order to preserve
better the image details. In general these methods have been
tested only on synthetic images with simple parametric form
of the blur kernel and no error affects the blur kernel.
Multiple image deblurring techniques use several images of the same scene in order to restore images. Several
hardware techniques have been proposed in the literature.
Hybrid cameras [BEN04,DW08,LSC∗ 08] exploit the tradeoff between spatial and temporal resolution. Raskar et al.
[RAT06] introduced the fluttered shutter camera, coding the
opening of the camera aperture during a normal exposure
period. A similar idea was used by Levin et al. [LFDF07]
that inserted a patterned occluder within the aperture of
the camera lens. Multichannel blind deconvolution methods [FSF07] are similar to dual image deblurring frameworks [RAP05, CYCKQ08] using two blurry versions of
the same image. These approaches are unfeasible in practical cases due to the fact that they require a fine alignment of the analysed images. Similar problem with ours
c 2008 The Author(s)
Journal compilation c 2008 The Eurographics Association and Blackwell Publishing Ltd.

has been considered for blurred/non-blurred image alignment [YSQS07a]. However they used a different approach
than ours exploiting only the kernel statistics. Yuan et al.
[YSQS07b] show that when two degraded versions of the
same image (blurry/noisy), previously aligned, are available,
then the latent image can be inferred by a residual deconvolution strategy. Similar problem have been addressed previously by Tico et al. [TV06].
Blind deconvolution methods are more challenging due
to the fact that both blur kernel and latent image are unknown. For early literature about this subject the reader is
referred to the survey by Kundur and Hatzinakos [KH96].
Recently, Fergus et al. [FSH∗ 06] introduced a method based
on the observation that the blur kernels often contain very
sharp edges. They estimate the kernel from a single blurry
image using natural image statistics combined with ensemble learning [MM00], a Bayes inference technique. The latent image was recovered by simply applying the standard
Richardson-Lucy [RIC72, LUC74] method. In their work,
Levin et al. [LFDF07], took advantage of the sparse prior
that concentrate derivatives at a small number of pixels. Shan
et al. [SJA08] solve a Maximum a Posteriori (MAP) problem
by integrating in a unique probabilistic model the blind and
non-blind deconvolution.
Although the results generated by these methods are very
promising, the blind deconvolution techniques are still relatively limited due to the complexity of the problem. In Figure
3 are shown the inferred kernels obtained for two blurry images when applying the existent state-of-the-art algorithms
[FSH∗ 06, SJA08].
The techniques most related with ours are the multiple
image deblurring methods. However our approach does not
need additional hardware and also does not assume a perfect
alignment of the images, as the multichannel blind deconvolution techniques do. Moreover we propose an original and
robust technique that, based on invariant local feature points

622

C. Ancuti et al. / Deblurring by Matching

and kernel statistics, is able to yield accurate results even for
large and complex blur kernels.

basic detector that computes Hessian matrix:
H=

3. Matching Blurred/Non-blurred Patches
Matching images (projection of the same 3D scene/object) is
in general performed by local feature points [TT08]. Due to
their robustness to background clutter and occlusions, local
feature points have proved efficiency in matching and recognition applications.
Extensive studies [MS04, MP07] reveal that the best
matching performances are obtained by SIFT (Scale Invariant Feature Transform) [Low04]. However, in our experiments where only small ratio scales between images are
considered, we observed that for large blur kernel sizes and
when images share relative small regions applying SIFT is
not always enough to find a decent number of correct matchings. The number of mismatches, that intensifies the ambiguity of the restoration process, increases with the kernel size.
In these cases, even applying robust fitting methods (e.g.
Ransac) it is not possible to completely reject the outliers.
The reason is due to the fact that the signature is computed
in a 16x16 region around every feature point and even if the
initial image is upsampled to a double size prior to build the
first level of the scale space pyramid, SIFT performs poorly
for large sizes of kernels.
We propose an effective method that simultaneously extracts valid matches and infers the blur kernel for two images , one sharp and one blurred, taken from the same scene.
Based on previous observations and studies our technique
is built on Lowe’s [Low04] operator. The remaining of
this section presents the implementation details of the main
stages: extract invariant local feature points, compute a distinctive signature vector for every keypoint and the matching
procedure.
3.1. Filter Invariant Local Feature Points
One drawback of the Lowe’s approach [Low04] is the repeatability score of the extracted feature points. The repeatability score [SB00] represents the ratio between the number
of point-to-point correct matches and the minimum number
of feature points detected in the images.
In the comprehensive study of Mikolajczyk et
al. [MTS∗ 05] the matching performances of the stateof-the-art detectors have been compared when different
transformations have distorted images. For blurry images
the best performance has been obtained by Hessian Affine
[MS02] operator. Therefore, when the number of the filtered
feature points is reduced, both Hessian Affine and DoG
(Difference of Gaussian) [Low04] feature points can be
used in order to increase the matching result. The Hessian
Affine is a scale-affine invariant detector, derived from the

Ix Ix
Ix Iy

Ix Iy
Iy Iy

(1)

where Ix and Iy represent local image derivatives computed
in x and y directions. The scale invariance of this operator
is due to the Laplacian properties while the affine invariance
is due to the elliptical shape region resolved by the second
moment matrix.
On the other hand DoG is built by subtracting adjacent
image-scale levels, previously blurred with a Gaussian function with a standard deviation that increases monotonically.
DoG is a close approximation of the LoG (Laplacian of
Gaussian) [Lin99] but it performs faster, extracting mostly
blob-like feature points. This approach, besides of increasing
the average repeatability score, has the advantage of covering the image regions much better.
3.2. Distinctive Signature
SIFT has shown impresive performances for matching images. Despite of recent attempts [DT05,KS04,MDS05] that
try to improve the original version, this operator remains the
most used descriptor in recognition and matching applications.
The descriptor computation is based on the image gradient magnitudes and orientations calculated in the circular
neighbor regions of the feature points. The image pyramid
level is determined by the computed characteristic scale of
the respective feature point. For every feature point a 4x4
orientation histogram is constructed on a 4x4 sub-region of
the feature point computed from a 16x16 centered region.
Each histogram has 8 bins corresponding to every 45◦ .
But this operator does not take into consideration the color
information being designed mainly for gray images. In our
application, that deals with color photographs, we need to
to increase its robustness and distinctiveness also in color
space.
Moment invariants are traditional methods used with success in many image processing applications. They represent
a simply calculated set of pixel region properties that in general are invariant to translation, scale and rotation. To add
the color information we opted for a variant introduced by
Mindru et al. [MMG99] which is mathematically expressed
as:
rgb

M pq =

Z Z

Ω

x p yq [R(x, y)]r [G(x, y)]g [B(x, y)]b dxdy

(2)

rgb

where M pq is the generalized color moment of order p+q
and degree r+b+g defined on an image region Ω that has
assigned for every point a three dimensional vector I(x,y)=
[R(x,y) G(x,y) B(x,y)]. The computation is limited up to second order resulting in a generalized 60-dimensional color
descriptor. Both SIFT and color moments are computed for
c 2008 The Author(s)
Journal compilation c 2008 The Eurographics Association and Blackwell Publishing Ltd.

623

C. Ancuti et al. / Deblurring by Matching

every extracted keypoint in their neighbor squared regions
determined by the scale and orientation information previously calculated for the feature points. Finally, our signature
vector is defined as:
⎡
⎤
χVSIFT
⎦
(3)
VDescr = ⎣
(1 − χ)VMrgb
pq

This expression concatenates by a weight factor χ the 128dimensional SIFT descriptor VSIF T ,that includes the local
properties of the pixels regions, and the color moments vector VMrgb for distinctness in the color space.
pq

3.3. Estimating Blur Kernel by Matching
In general the extracted feature points are matched by evaluating a distance metric (e.g Euclidian, Mahalanobis) based
on descriptor information. Unfortunately applying this approach is quite impractical and computationally expensive
due to the higher number of extracted keypoints (thousands)
and due to the dimension of the signature attached to every keypoint. Lowe [Low04] overcomes this problem making use of the Best-Bin-First [BL97] algorithm which is an
alternative k-d tree algorithm so that bins in feature space
are searched in the order of their closest distance from the
inquire position. The approach is not robust in the presence
of large number of outliers. Therefore, we use this method
only as a starting point in our algorithm, finding potential
valid matches that will be filtered properly by constraining
the kernel shape. We propose a technique that simultaneously matches the feature points and infers reliably the blur
kernel that previously garbled the considered latent image.
Estimating kernel blur, a highly under-constrained problem, is solved by regularization methods. The ill-posed theory is well developed in the literature [Tar05]. The simple constrained least-squares estimators are not robust since
the objective function is symmetric for all the measurements [MEE04]. Usually, the Tikhonov regression methods produce better results for blur kernel inference problems
[YSQS07b]. However, based on recent results [SJKG07]
we opted for a more effective optimization technique, l1regularized least squares. Therefore, our regularization cost
fuction El1−Reg is expressed as:
El1−Reg (k) = I ⊗ k − B

2
2 +λ

k

1

(4)

where ⊗ is the convolution operator, λ > 0 (default value is
10) is the regularization parameter and λ k 1 denotes the
l1 norm. This method has the advantage of always converging to a solution. Comparing with the Tikhonov regularization, where the optimal solution tends to zero as the regularization parameter tends to infinite (∞), l1-regularized least
squares converges for a finite value of λ. But more importantly the vector k yielded by l1-regularized least squares is
sparse containing only a few non-zero coefficients. On the
c 2008 The Author(s)
Journal compilation c 2008 The Eurographics Association and Blackwell Publishing Ltd.

other hand Tikhonov regularization typically has all the coefficients non-zero.
While the regularization cost fuction El1−Reg optimizes
for the data energy the regularities of the blur kernel need
also be refined by additional constraints. Two well known
constraints are applicable for the real motion blur kernel:
sparseness and continuity. As Fergus et al. [FSH∗ 06], inspired from natural image statistics, the distribution of the
kernel values is fitted to a mixture of exponential values:
p(ki ) ∝ (γeki /β1 + ηeki /β2 )

(5)

where ki are the elements of the blur kernel and γ,η and
β1,2 are the parameters of the exponential distribution. The
sparseness is evaluated by computing the entropy of the
probabilistic distribution p(k):
Esparse (k) = −

Z

k

p(k)log p(k)

(6)

The second constraint of the blur kernel is motivated by
the continuity of the CCD sensors during the camera shake
[CYCKQ08]. The cost function that regularizes for the blur
kernel continuity is expressed as:
Econt (k) =

Z

Ω

∇kT D(∇k)∇kdΩ

(7)

where ∇k is the local gradient and D is the anisotropic diffusion tensor.
The previous cost functions describe the inference process assuming a perfect alignment of the images. However,
our problem is more complex and this hypothesis is not generally true. Even if the feature points have been matched
correctly the geometry between surrounding patches is unknown. Practically, in this work we consider the geometry
up to Euclidian. The total energy is summarized by the equation:
Etotal (k, vg ) = El1−Reg (k, vg ) + Esparse (k) + Econt (k) (8)
with
El1−Reg (k, vg )) = PI (vg ) ⊗ k − PB

2
2 +λ

k

1

(9)

where vg = (dx , dy , s, r) is the general vector that contains the
parameters of the warping geometry (translation, scale ratio
and rotation). PI and PB represents the neighbor patches
around feature points of the non-blurred and blurred images. The problem is highly under-constrained due to the
additional geometric parameters. For converging reliably, we
need good initial values of the geometric parameters. We observed that in general the displacement vector (dx , dy ) is relatively small due to the fact that we assume a relative small
scale ratio between considered images. If the number of correct matches is higher than 50%, theoretically it is possible
to estimate roughly the parameters of the distorting geometry by applying Ransac. The values of dominant orientation
and characteristic scale, attached to every local feature points
in the previous stage, can be also exploit in order to obtain

624

C. Ancuti et al. / Deblurring by Matching

4. Image Restoration Approach
The last step of our algorithm, after the blur kernel has
been inferred, consists in restoring the corrupted image. Although, assuming the blur kernel to be known, the problem
is ill-posed having the general expression:
B = I ⊗k+N

(10)

a) Blurry images and blur kernels

b) Standard Richardson-Lucy

c) Sparse Deconvolution - Levin et. al [2007]

d) Our Results

Figure 4: Comparison between non-blind deconvolution
techniques. Our method yields better results than standard
Richardson-Lucy and Levin et al. [LFDF07] approach.

where N is the additive noise. Despite of abundant non-blind
deconvolution techniques introduced recently, RichardsonLucy [RIC72, LUC74] remains the most known and referred
deconvolution algorithm in the literature. As observed also
by Fergus et al. [FSH∗ 06], comparing with the existent
methods, R-L is very robust yielding good results not only
for synthetic examples but also for real images and, additionally, it has the advantage to be very fast, converging for
a normal photography in only few minutes (complex methods converge in hours or days).
R-L is an iterative deconvolution algorithm that searches
for the maximum likelihood solution assuming a Poisson
noise distribution model. The method has been shown to
perform better than linear methods for images with reduced
noise level. R-L restricts the estimated values to be nonnegative and moreover has the advantage to preserve the image energy during the iterative process. A higher number of
iterations, as remarked also by [YSQS08], does not necessarily recover more details but in general intensifies the
ringing artifacts.
To restore our latent image we adopt a simple and efficient
method derived from the traditional R-L. The best Bayesian
estimate of the latent image Iˆ maximizes the a posterior conditional probability density of the observed image p(B|I).
Assuming a Poisson model distribution the likelihood probability is:
p(B|I) = ∏(

appropiate initial values of the parameters. Even if there are
limitations we believe that this approach is able to improve
the convergence process yielding appropriate initial values
of the parameters.
During the estimation the best matches are determined by
sorting the corresponding pairs based on the entropy measure of the estimated kernel. The mismatches are rejected
by simply evaluating the entropy values. In our approach we
filter the outlier matches assuming that their feature points
pairs determine an estimated kernel with the entropy value
higher than ϑ, a fraction of the minimum value calculated
for the entire set of potential matches. The algorithm converges in 40-50 iterations and can be efficiently implemented
by using Fast Fourier Transform (FFT).

(I ⊗ k)B e−(I⊗k)
)
B!

(11)

Setting the partial derivatives of the likelihood probability to
zero and taking the logarithm of both sides the estimate is
obtained by minimizing the following cost function:
Iˆ = arg min ER−L (I)
I

= arg min ∑∑(I ⊗ k)(x) − B(x)log[(I ⊗ k)(x)] (12)
I

This may be derived in an iterative formulation based on the
Picard’s classical method. However the classic R-L is not
edge-preserving, yielding unpleasant ringing artifacts near
extreme edges. The ringing artifacts caused by deconvolution process can not be entirely removed from the restored
image. These artifacts are more visible in the smooth image
regions than in the highly textured parts. Therefore, forcing
the neighbor pixels of the flat image regions to preserve a
constant color contrast, we propose a new energy term that
minimizes these artifacts. The method is based on solving
c 2008 The Author(s)
Journal compilation c 2008 The Eurographics Association and Blackwell Publishing Ltd.

C. Ancuti et al. / Deblurring by Matching

625

the anisotropic diffusion equation :
∂I(x)
= div (g( ∇I )∇I)
∂t

(13)

where
g(x) =

1
1+(

|∇I| 1+α
β )

,α > 0

(14)

with ∇I the image gradient and β the diffusion constant. The
anisotropic diffusion is a classic image processing technique,
used in applications that detect and preserve sharp boundaries [BSMH98]. Combining last equations, our final iterative process is described by the following general formula:
I t+1 = I t 1 +

λ
g( ∇I )∇I
|η p | ∑
ηp

k⊗

B
It ⊗ k

(15)

where t is the iteration step, λ is the regularization factor, η p
the spatial neighborhood of a pixel p and |η p | is the number
of neighbor pixels (we used |η p | = 4 in our experiments).
Figure 4 shows a comparison between several deconvolution methods. The images are synthetically blurred with the
kernel used also in the previous studies [YSQS08, SJA08].
For the left side picture the size of the kernel blur is 29x29
and for the second one we used a kernel size of 37x37. As
can be observed our approach minimizes the ringing artifacts
recovering better also the finest details.
5. Experiments and Discussion
We have tested our approach on a variety of blurry/non
blurred pair of photographs. The photographs have been
taken with commercial digital cameras (Canon A470 with
7.1 Mpixels/3.4x optical zoom, Kodak Z740 with 5 Mpixels/10.0x optical zoom). The only exceptions are Picasso
and Birthday cake photos from Figures 3 that have been
used as test images also in previous approaches [YSQS07b,
YSQS08, SJA08].
Besides the computation of keypoints descriptor, the implementation takes into consideration only gray scale images. For processing our results we worked with the luminance channel (Y) of the YUV color space. The approach is
translated for color images assuming that there are simple
transformations (affine) that relates the luminance and color.
We generate our results by applying the technique that has
been previously used by Fattal [Fat07] in context of upsampling.
In this work we assumed that the photographs have been
distorted only by a shift-invariant motion blur (can be expressed as a single convolution). Additionally, we took into
consideration only static scenes (during the exposure there
is no relative motion between scene parts) with reduced parallax between images.
c 2008 The Author(s)
Journal compilation c 2008 The Eurographics Association and Blackwell Publishing Ltd.

Figure 5: Top: Reference unblurred and the synthetically
blurred images. Middle: Photoshop sharpening filter (left)
and our result (right). Bottom: Zoomed region of blurred,
unsharped and restored image.

In Figure 5 the blurred image is obtained synthetically being convolved uniformly with a blur kernel of 31x31. Compared with the Photoshop sharpening filter our result is substantially improved . A similar test is presented in Figure 5
but here the kernel size is larger (67x67). Borrowing information from the additional photography our approach is able
to restore the latent image very accurately.
Figures 6 shows another pair of images. Compared with
the recent technique of Shan et al. [SJA08] our technique,
due to the additional information, yields sharper results with
less artifacts.
In Figure 7 is presented a real case when the camera shake
distorted the photograph. When images are restored with the
single image deblurring technique [SJA08] the finest details
are not recovered entirely. Moreover, the introduced artifacts
are clearly reduced in the image restored by our method.
Even if the results are promising there is still room for improvement in the optimization technique. We observed that
a reduced number of seed feature points, when the geometry
that relates images can not be estimated reasonable, estimation of the geometrical parameters performs poorly. In addition, if the rotation initial value is not in a range of ±1◦ or
the ratio scale differs with more than ±5% than its real value
our procedure is not able to converge to the optimal result.

626

C. Ancuti et al. / Deblurring by Matching

However, as we mentioned, we assumed a geometry only up
to Euclidean. In some cases, a possible alternative, if the geometry can not be estimated due to the lack of inlier matches
one can use as initial parameters the ratio of characteristic
scales and the difference of dominant orientations attached
to every keypoint but again with the previously mentioned
limitation of the range. This remains an open problem that
requires more attention in the future research.
Our approach requires that the reference image to be sharp
but further investigation need to be done when additional
noise or variation of the lighting conditions alter the considered photographs.
Additionally, the accuracy of the results yielded by our
approach is highly dependent by the nature of the texture and
the size of the common regions shared by the blurred/nonblurred photographs. For reliable results we observed that at
least a 200x200 highly textured region is required.
6. Conclusion
Deblurring images is an ill-posed problem that affects irreversibly the finest details of photos. Since, as was shown,
the state-of-the-art single image techniques are limited, being unable to restore correctly images damaged by motion
blur, certain constraints are required for recovering reliably
latent images. We make use of the similar information existent in a collection of photographs that share common regions. Based on a robust procedure that matches local feature
points, described by powerful signatures, we are able to precisely estimate the blur effects that have distorted images.
We also present a simple deblurring method that preserves
edges while minimizes the ringing artifacts.
In future work we would like to improve the robustness
of our algorithm for larger geometric distortion between images and also to consider more challenging blurs (e.g. shiftvariant, out of focus). Another potential research direction is
to investigate the cases when the photographs have been altered by noise, variation of illumination or both are damaged
by unknown motion blur.
References
[BEN04] BEN-EZRA M., NAYAR S. K.: Motion-based motion deblurring. IEEE Trans. on Pattern Analysis and Machine
Intelligence 26, 6, 689-698 (2004).
[BK97] BANHAM M. R., KATSAGGELOS A. K.: Digital image restoration. IEEE Signal Processing Magazine 42, 2
(1997).
[BL97] B EIS J., L OWE D.: Shape indexing using approximate
nearest-neighbour search in highdimensional spaces. In Conference on Computer Vision and Pattern Recognition (1997), 1000–
1006.
[BSMH98] B LACK M. J., S APIRO G., M ARIMONT D., H EEGER
D.: Robust anisotropic diffusion. IEEE TRANSACTIONS ON
IMAGE PROCESSING (1998).

[CW98] C HAN T. F., W ONG C. K.: Total variation blind deconvolution. IEEE TRANSACTIONS ON IMAGE PROCESSING
(1998).
[CYCKQ08] C HEN J., Y UAN L., C HI -K EUNG , Q UAN T. L.:
Robust dual motion deblurring. Proc. of IEEE Computer Vision
and Pattern Recognition (2008).
[DT05] D ALAL N., T RIGGS B.: Histograms of oriented gradients for human detection. In In Proceedings of IEEE Conference
on Computer Vision and Pattern Recognition (Washington, DC,
USA, 2005), IEEE Computer Society, pp. 886–893.
[DW08] D AI S., W U Y.: Motion from blur. Proc. of IEEE Computer Vision and Pattern Recognition (2008).
[Fat07] FATTAL R.: Upsampling via imposed edges statistics.
ACM Transactions on Graphics (Proceedings of SIGGRAPH
2007) 26, 3 (2007).
[FSF07] F. S ROUBEK G. C., F LUSSER J.: A unified approach
to superresolution and multichannel blind deconvolution. IEEE
Trans. Image Processing, vol. 16, pp. 2322-2332 (2007).
[FSH∗ 06] F ERGUS R., S INGH B., H ERTZMANN A., ROWEIS
S. T., F REEMAN W. T.: Removing camera shake from a single photograph. ACM Trans. Graph. 25, 3 (2006), 787–794.
[JZ02] JALOBEANU A. B.-F. L., ZERUBIA J.: Estimation
of blur and noise parameters in remote sensing. In Proc. of Int.
Conf. on Acoustics, Speech and Signal Processing (2002).
[Kal60] K ALMAN R.: A new approach to linear filtering and prediction problems. Journal of Basic Engineering 82 (1) (1960).
[KCLU07] K OPF J., C OHEN M. F., L ISCHINSKI D., U YTTEN DAELE M.: Joint bilateral upsampling. In SIGGRAPH ’07: ACM
SIGGRAPH 2007 papers (New York, NY, USA, 2007), ACM,
p. 96.
[KH96] KUNDUR D., HATZINAKOS D.: Blind image deconvolution. IEEE Signal Processing Magazine, 13, 43-64 (1996).
[KS04] K E Y., S UKTHANKAR R.: Pca-sift: A more distinctive
representation for local image descriptors. In In Proceedings of
IEEE Conference on Computer Vision and Pattern Recognition
(2004), pp. 506–513.
[LFDF07] L EVIN A., F ERGUS R., D URAND F., F REEMAN
W. T.: Image and depth from a conventional camera with a coded
aperture. ACM Trans. Graph. 26, 3 (2007), 70.
[Lin99] L INDEBERG T.: Feature detection with automatic scale
selection. International Journal of Computer Vision 30, 2 (1999),
77–116.
[Low04] L OWE D.: Distinctive image features from scaleinvariant keypoints. In International Journal of Computer Vision
(2004), vol. 20, pp. 91–110.
[LSC∗ 08] L EVIN A., S AND P., C HO T. S., D URAND F., F REE MAN W. T.: Motion-invariant photography. ACM Trans. Graph.
27, 3 (2008), 1–9.
[LUC74] LUCY L.: An iterative technique for the rectification
of observed distributions. Astronomical Journal (1974).
[MDS05] M ORTENSEN E. N., D ENG H., S HAPIRO L.: A sift descriptor with global context. In In Proceedings IEEE Conference
on Computer Vision and Pattern Recognition (2005), pp. 184–
190.
[MEE04] MEER P.: Robust techniques for computer vision.
Emerging Topics in Computer Vision, 2004.
[MM00] MISKIN J., MACKAY D. J. C.: Ensemble learning
for blind image separation and deconvolution. In Adv. in Independent Component Analysis, M. Girolani, Ed. Springer-Verlag.
(2000).
c 2008 The Author(s)
Journal compilation c 2008 The Eurographics Association and Blackwell Publishing Ltd.

C. Ancuti et al. / Deblurring by Matching

627

Figure 6: Top:The reference and the blurred images. Middle: Shan et al. [SJA08] results (left side) together with estimated
blur kernel and our result (right side). Bottom: Cropped regions of the blurry and the restored image obtained by the Shan et
al. approach and our method.

[MMG99] M INDRU F., M OONS T., G OOL L. V.: Recognizing
color patterns irrespective of viewpoint and illumination. In in
Conference on Computer Vision and Pattern Recognition (1999),
pp. 368–373.

G OOL L. V.: A comparison of affine region detectors. Int. J.
Comput. Vision, (2005).
[NB04] NEELAMANI R. C. H., BARANIUK R.: Forward:
Fourier-wavelet regularized deconvolution for illconditioned systems. IEEE Trans. on Signal Processing 52, 2 (2004).

[MP07] M OREELS P., P ERONA P.: Evaluation of features detectors and descriptors based on 3d objects. Int. J. Comput. Vision
73, 3 (2007), 263–284.

[RAP05] R AV-A CHA A., P ELEG S.: Two motion-blurred images
are better than one. Pattern Recogn. Lett. 26, 3 (2005), 311–317.

[MS02] M IKOLAJCZYK K., S CHMID C.: An affine invariant interest point detector. In Proceedings of the 7th European Conference on Computer Vision (ECCV) (2002).

[RAT06] R ASKAR R., A GRAWAL A., T UMBLIN J.: Coded exposure photography: motion deblurring using fluttered shutter.
ACM Trans. Graph. 25, 3 (2006), 795–804.

[MS04] M IKOLAJCZYK K., S CHMID C.: A performance evaluation of local descriptors. IEEE Conf. on Computer Vision and
Pattern Recog. (CVPR) 30, 2 (2004), 257–263.

[RF92] RUDIN L. O. S., FATEMI E.: Nonlinear total variation
based noise removal algorithms. Physica (1992).

[MTS∗ 05] M IKOLAJCZYK K., T UYTELAARS T., S CHMID C.,
Z ISSERMAN A., M ATAS J., S CHAFFALITZKY F., K ADIR T.,
c 2008 The Author(s)
Journal compilation c 2008 The Eurographics Association and Blackwell Publishing Ltd.

[RIC72] RICHARDSON W.: Bayesian-based iterative method
of image restoration. Journal of the Optical Society of America
A 62, 55.59 (1972).

628

C. Ancuti et al. / Deblurring by Matching

a)

c)

e)

b)

d)

f)

Figure 7: a) Reference image. b) Blurred image due to the camera shake. c) Result of Shan et al. [SJA08] restoration and the
close-up result (e). d) Our result with the same magnified region (f).

[SB00] S CHMID C. M. R., BAUCKHAGE: Evaluation of interest point detectors. International Journal of Computer Vision
(2000).

[YSQS08] Y UAN L., S UN J., Q UAN L., S HUM H.-Y.: Progressive inter-scale and intra-scale non-blind image deconvolution.
ACM Trans. Graph. 27, 3 (2008), 1–10.

[SJA08] S HAN Q., J IA J., A GARWALA A.: High-quality motion
deblurring from a single image. In SIGGRAPH ’08: ACM SIGGRAPH 2008 papers (New York, NY, USA, 2008), ACM, pp. 1–
10.
[SJKG07] S.-J. K IM K. K OH M. L. S. B., G ORINEVSKY D.: An
interior-point method for large-scale l1-regularized least squares.
IEEE Journal on Selected Topics in Signal Processing (2007),
606–617.
[Tar05] TARANTOLA A.: Inverse Problem Theory and Methods
for Model Parameter Estimation. Society for Industrial and Applied Mathematics, Philadelphia, PA, USA, 2005.
[TIK43] TIKHONOV A.: On the stability of inverse problems.
Dokl. Akad. Nauk SSSR 39, 5 (1943).
[TT08] T. T UYTELAARS K. M.: Local invariant feature detectors: A survey. Foundations and Trends in Computer Graphics
and Vision, Vol. 3, nb 3, pp 177-280 (2008).
[TV06] T ICO M. T. M., V EHVILAINEN M.: Motion blur identification based on differently exposed images. IEEE International
Conference on Image Processing (ICIP) (2006).
[WIE64] WIENER N.: Extrapolation, interpolation, and smoothing of stationary time series. MIT Press (1964).
[YSQS07a] Y UAN L., S UN J., Q UAN L., S HUM H.:
Blurred/non-blurred image alignment using sparseness prior. In
ICCV 07: IEEE Conf. Computer Vision (2007).
[YSQS07b] Y UAN L., S UN J., Q UAN L., S HUM H.-Y.: Image
deblurring with blurred/noisy image pairs. In SIGGRAPH ’07:
ACM SIGGRAPH 2007 papers (New York, NY, USA, 2007),
ACM, p. 1.

Figure 8: The additional and the blurred image (top) synthetically blurred with a large kernel 67x67. Top: Additional
photo and the blurred image. Bottom: Cropped regions of
the blurred image, Fergus et al. [FSH∗ 06] and our recovered results.

c 2008 The Author(s)
Journal compilation c 2008 The Eurographics Association and Blackwell Publishing Ltd.

