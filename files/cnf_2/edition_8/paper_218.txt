DOI: 10.1111/j.1467-8659.2008.01196.x

COMPUTER GRAPHICS

forum

Volume 27 (2008), number 8 pp. 2114–2127

Diffusion Based Photon Mapping
L. Schjøth1 , J. Sporring1 and O. Fogh Olsen2
1 Department

of Computer Science, University of Copenhagen, Universitetsparken 1, 2100 Copenhagen Ø, Denmark
2 IT University of Copenhagen, Rued Langgaards Vej 7, 2300 Copenhagen S, Denmark

Abstract
Density estimation employed in multi-pass global illumination algorithms give cause to a trade-off problem
between bias and noise. The problem is seen most evident as blurring of strong illumination features. In particular,
this blurring erodes fine structures and sharp lines prominent in caustics. To address this problem, we introduce
a photon mapping algorithm based on nonlinear anisotropic diffusion. Our algorithm adapts according to the
structure of the photon map such that smoothing occurs along edges and structures and not across. In this way,
we preserve important illumination features, while eliminating noise. We demonstrate the applicability of our
algorithm through a series of tests. In the tests, we evaluate the visual and computational performance of our
algorithm comparing it to existing popular algorithms.
Keywords: ray-tracing, global illumination, photon mapping, caustics, density estimation, diffusion filtering.
ACM CCS: I.3.7 [Computer Graphics]: Three-dimensional Graphics and Realism

1. Introduction
Particle tracing algorithms are frequently used in photo realistic image synthesis. They usually employ two passes –
a first pass in which particles representing light are emitted
from light sources and reflected around a scene, and a second
pass which generates an image of the scene using the light
transport information from the first pass. The advantage of
particle tracing algorithms is that they effectively simulate all
possible light paths. In particular, they can simulate lighting
phenomena such as colour bleeding and caustics.
However, particle tracing algorithms are faced with a
severe problem. In the particle tracing pass, particles are
stochastically emitted from the light sources and furthermore
often stochastically traced through possible light paths. This
procedure induces noise. Some particle tracing methods use
density estimation to eliminate this noise during illumination
reconstruction. Unfortunately, the noise reduction imposes a
systematic error (bias) seen as a blurring of sharp illumination features. This is not necessarily a bad effect when
concerned with slowly spatially changing illumination, but it
becomes an important problem when the illumination inten-

c 2008 The Authors
Journal compilation c 2008 The Eurographics Association and
Blackwell Publishing Ltd. Published by Blackwell Publishing,
9600 Garsington Road, Oxford OX4 2DQ, UK and 350 Main
Street, Malden, MA 02148, USA.

sity changes quickly such as when concerned with caustics
and shadows.
In this paper, we present an algorithm which reduces noise
and in addition preserve strong illumination features such
as those seen in caustics. We have chosen to implement
it in photon mapping. Photon mapping is a popular particle tracing algorithm developed by Henrik Wann Jensen
[Jen96].
Our algorithm is based on a filtering method called nonlinear anisotropic diffusion. Nonlinear anisotropic diffusion
is a popular method commonly used in image processing,
it has the property of smoothing along edges in an image
instead of across edges [Wei98]. Thus, it preserves structures
in an images while smoothing out noise. We propose to use
diffusion filtering on densities of photons during the illumination reconstruction. Our method was first suggested by the
authors in [SOS06]. This paper presents a thorough investigation of the method. The method is compared to competing
methods and its performance is evaluated. Furthermore, this
paper improves on the method in respect to performance and
handling of high curvature scenes.

2114

Submitted: January 2007
Revised: February 2008
Accepted: March 2008

2115

L. Schjøth et al. / Diffusion based Photon Mapping

Figure 1: Rendering of caustics created by two interlinked toruses. Region zoom of image rendered using (a) regular photon
mapping and (b) our method.
Figure 1 illustrates two renderings; one using regular photon mapping and the other using our method. The image
shows how our method reproduces caustics in higher detail than regular photon mapping using the same number of
photons.
Here follows a brief overview of this paper: Section 2
briefly introduce classic density estimation and elaborates on
the trade-off problem between bias and variance. Following
this, diffusion filtering is explained in Section 3. Section
4 gives an overview over existing methods addressing the
mentioned trade-off problem. In Section 5, we explain how
density estimation is used in photon mapping to reconstruct
indirect illumination, and how the bias versus noise tradeoff problem manifests itself in photon mapping. We then
describe our proposed method in Section 6. In Section 7, we
evaluate our method comparing it to existing bias reducing
methods, and finally we present our conclusion in Section 8.

position for which the density function is to be approximated.
This is done using a kernel function.
The multivariate kernel estimator is defined by
f (x) =

1
khd

n

K
i=1

(x − xi )T (x − xi )
h2

(1)

where d is the number of dimensions, n is the number of data,
h is the bandwidth and K is the multivariate kernel function.
For each position x of f (x), all samples are weighted by the
kernel function centred over x.
Because of the additive form of the kernel estimator, the
estimated density function inherits the differentiability and
continuity of the kernel function used in the estimate. Another property of the kernel estimator is that it constitutes
a smoothing of the density function. In fact, the estimated
density function converges not to the true density function
but to the true density function convolved with the kernel.

2. Density Estimation
With the introduction of particle tracing and storing [Arv86],
the concept of density estimation became relevant to computer graphics.

2.2. Estimation accuracy

2.1. The kernel estimator

The bandwidth determines the degree of smoothing of the
density function, it has a huge impact on its form. An important problem in density estimation is therefore, that of
selecting the bandwidth that gives the most suitable result.
The rather imprecise term ‘suitable’ is used, because the suitability of the result depends on its utilization. A human observer might want an estimate with details, while an estimate
used for differentiation preferable is noise free. Generally,
however, a measure exists for the accuracy of an estimate.
Such a measure can be used to define the discrepancy of an
estimator, f , compared to the true density, f .

A general non-parametric density estimator is the kernel estimator. The kernel estimator approximates a density function
by weighting the samples of a dataset by their distance to the

Most often there is a trade-off between variance and bias.
Variance is the random error caused by the finite nature
of the distribution, while the bias is the systematic error

Non-parametric density estimation allows an unknown
function to be obtained by fitting an observed dataset, without prior knowledge of the data in hand. In contrast, parametric density estimation assumes the dataset fits a known
parametric function. In computer graphics, focus is on nonparametric density estimation.

c 2008 The Authors
Journal compilation c 2008 The Eurographics Association and Blackwell Publishing Ltd.

2116

L. Schjøth et al. / Diffusion based Photon Mapping

induced by the kernel density estimation. If large values for
the bandwidth are used, then it results in smoothing the density function reducing variance, while increasing the bias
of the estimate. Small values on the other hand means less
smoothing, more variance and a less biased result. This tradeoff can be quantified using the mean integrated square error
(MISE).

Two well-known adaptive kernel estimators are the kth
nearest neighbour estimator and the variable-bandwidth kernel estimator [Sim96].
The equation for the kth nearest neighbour method is
f (x) =

MISE it is defined by
MISE(f ) =

2

E f (x) − f (x) dx +

var f (x)dx (2)

where the first integral is the square bias, the second is the
variance, and E is the expectation value. Accordingly the accuracy of the estimate depends on the sum of the variance and
the square bias, thus a dependency exists between variance
and bias. This will be elaborated.
It is known [Sil86] that the expectation value of the kernel
density estimate is
E f (x) =

1
h

K

x−y
f (x)dy.
h

(3)

Together with Equation (2), this tells us that the difference
between the expected value of f and f depends on the size
of the bandwidth. So accordingly decreasing the bandwidth
reduces the bias. Unfortunately, decreasing the bandwidth
will also increases the variance.
The variance of the kernel density estimator can, by substitution and use of the Taylor series, be approximated to
var f (x) ≈

f (x) K(y)2 dy
.
nh

(4)

This is done by Silverman in [Sil86]. This substantiates the
before mentioned statement that decreasing the bandwidth
will increase variance. Another point to be made is that the
variance is also inversely proportional with the number of
samples.
Summarily a kernel density estimate f is a kernel
smoothed version of the true density function, f in addition to random error. Increasing the number of samples will
reduce the variance making the estimate converge to the true
density function convolved with the kernel. If the bandwidth
at the same time goes towards zero, then our estimate will
converge to f . Adjusting the bandwidth controls the trade-off
between bias and variance.

2.3. Adaptive kernel estimators
Adaptive kernel estimators seek to minimize MISE by varying the bandwidth over the estimate. In areas with low density, adaptive kernel estimators reduce noise by using a broad
bandwidth, while they at the same time preserve details in
high density areas by using a small bandwidth.

1
kh(x)d

k

K
i=1

(x − xi )T (x − xi )
h(x)2

(5)

where d is the number of dimensions and h(x) is the distance
from x to the kth nearest sample. This means that the bandwidth varies depending on the local density of the data. In
effect, bias seen in areas with sharp transitions in density is
reduced as the bandwidth changes from being small in high
density areas to being large in low density areas and vice
versa.
The equation for the variable bandwidth kernel estimator
is
f (x) =

1
k

n

i=1

(x − xi )T (x − xi )
1
K
.
h(xi )d
h(xi )2

(6)

Whereas the kth nearest neighbour estimator adapts the local
bandwidth based on a measure of density, the bandwidth
varying kernel estimator uses a different bandwidth for each
observed sample, xi , to weight the estimate. Most often a
pilot estimate of the unknown density is used to vary the
bandwidth [Sim96]. With h(xi ) = hv f˜(xi )−1/2 . Where the
pilot, f˜, is estimated with a fixed-bandwidth kernel estimator.
In computer graphics both Chen et al. [CRMT91] and
Jensen [JC95] use the kth nearest neighbour estimator in order to improve the trade-off between bias and variance. Furthermore, Myszkowsky et al. [Mys97] and Schregle [Sch03]
use extended versions of the kth nearest neighbour estimator
to further improve the trade-off.
Heckbeck [Hec90] used a multivariate histogram with a
variable bin size. He varied the bin size based local density.
Collins [Col94] used the variable bandwidth estimator. For
each particle tracing hit, he spread the particle energy out on
an illumination map using a Gaussian kernel. The bandwidth
of each kernel was adapted according to the local density.

3. Diffusion Filtering
Diffusion filtering was first introduced to image processing
by Perona and Malik [PM90]. Their goal was to contrive a
method, which would preserve edges while smoothing intraregions. To this end, they proposed an image oriented numerical solution to the diffusion equation.
If the diffusion equation is used to express the physical
principal of mass conservation, then it describes the flow
of matter caused by differences in concentration. It can be

c 2008 The Authors
Journal compilation c 2008 The Eurographics Association and Blackwell Publishing Ltd.

L. Schjøth et al. / Diffusion based Photon Mapping

expressed by
∂C
= div(D∇C).
∂t

(7)

It states that given a movement of matter in time caused by
a flux, a change in concentration occurs within a differential
volume. This flux is dependent on the diffusivity, D, and the
concentration gradient, ∇C, where C : Rd × R+ → R, D ∈
Rd×d , and d is the dimensionality.
In their solution, Perona–Malik used a scalar function to
represent diffusivity, such that D := g(x)I, where g : Rd →
R and I ∈ Rd×d is the identity matrix. This function controls
the degree of diffusion in the image locally depending on
the gradient of the image. In practice, their method smooths
an image using a rotational invariant filter, which adapts its
size according to structure. Unfortunately, the method fails
to remove severe noise near edges as the filter size is reduced
in proximity of these.
Weikert [Wei98] suggested another solution to the diffusion equation. Instead of using a scalar function to represent
the diffusivity, he used a matrix called the diffusion tensor,
D ∈ Rd×d . The diffusion tensor should adapt locally as to
describe the structure of the image. Depending on how the
tensor is constructed, this makes the diffusion filtering capable of either edge- or coherence-enhancing smoothing.
In Weickert’s terminology, this form of diffusion filtering is called anisotropic, while diffusion with a scalar diffusivity function, as with Perona–Malik’s diffusion, is called
isotropic. The difference being that anisotropic diffusion occurs parallel to structure using a rotational variant kernel,
while isotropic diffusion uses a rotational invariant kernel,
filtering equally in all directions.
The advantage of anisotropic diffusion is that it, unlike
isotropic diffusion, is capable of smoothing along edges and
structures, thereby avoiding the problem of isotropic diffusion where noise along edges is not removed.

4. Advances in Bias Reduction
As kernel density estimation became relevant to computer
graphics, so did the trade-off problem between variance and
bias. Numerous articles address this issue, some of these go
beyond common kernel density techniques.
Photon mapping usually depends on kth nearest neighbour kernel estimate to improve the trade-off between bias
and variance. However, in [JC95] Jensen proposed an extended method. The method is called differential checking,
and it reduces bias by making sure that the kernel does not
cross boundaries of distinct lighting features. This is done
by expanding the bandwidth ensuring that the estimate does
not increase or decrease drastically, when more photons are
included in the estimate.

2117

Myszkowsky et al. [Mys97] suggested to solve the problem in much the same way as Jensen did with differential
checking. However, they made the method easier to control
and more robust with respect to noise. Myszkowsky et al.
increase the bandwidth iteratively estimating the radiance in
each step. If new estimates differ more from previous than
what can be contributed variance, then the iteration stops, as
the difference is then assumed to be caused by bias. More
recently Schregle [Sch03] followed up their work using the
same strategy, but optimizing speed and usability. Speed is
optimized by using a binary search for the optimal bandwidth. This search starts in a range between a maximum and
a minimum user-defined bandwidth. The range is split up,
and the candidate, whose error is most likely to be caused by
variance and not bias, is searched.
Redner et al. [RLU95] used b-splines to approximate the
illumination function from particle density distributions. The
b-spline function is composed of a number of basis functions
each associated with a control point. The advantage of this
form of representation is that the illumination function is easy
to evaluate and manipulate and that the storage consumption
is negligible. The method is faced with the same dilemma as
the kernel density estimator. The number of basis functions
used in the representation determines the smoothness of the
illumination function.
Shirley et al. [SWH∗ 95] introduced an algorithm for estimating global illumination. Like photon mapping, this algorithm uses density estimation to approximate the illumination
from particles generated during a Monte Carlo-based particle
tracing step. However, unlike photon mapping the algorithm
is view-independent, and for this reason the illumination is
tied to the geometry. They called the algorithm the density estimation framework, and they refined it in a series of
papers.
The first edition of their framework did not try to control
bias. In [WHSG97] they extended the framework to handle
bias near polygonal boundaries. This was done by converting
the density estimation problem into one of regression. In
this way, they could use common regression techniques to
eliminate boundary bias.
Later Walter in his PhD thesis [Wal98] reduced bias by
controlling the bandwidth of the estimate using statistics to
recognize noise from bias. Benefiting from the field of human perception, he used a measure for controlling the bandwidth such that noise in the estimate was imperceptible to the
human eye. Walter recognized that if bias was to be significantly reduced, using his method, then perceptual noise had
to be accepted in the vicinity of prominent edges and other
strong lighting features. This is a common problem, which
also affects differential checking, and both Schregle’s and
Myszkowsky’s methods. Hence, in the proximity of strong
features such as the edges of a caustic the bandwidth stops increasing, and the foundation, on which the estimate is made,
is supported by few photons. This means that when estimates

c 2008 The Authors
Journal compilation c 2008 The Eurographics Association and Blackwell Publishing Ltd.

2118

L. Schjøth et al. / Diffusion based Photon Mapping

are made close to edges, the support is limited and noise may
occur.
The difference between these algorithms mainly lies in
their method of detecting structure and the degree of change
in bandwidth a given proximity of such structure entails.
They use rotation invariant kernels. In the context of diffusion
filtering, these methods are comparable to isotropic diffusion.
In our method, we employ the concept of anisotropic
diffusion. It is a numerical solution to the diffusion equation geared towards particle tracing. Our method uses a
shape adapting rotational variant kernel. In contrast to
Myszkowsky, Schregle, and Walter’s approach, our method
will smooth along edges and structures. Therefore, in the
proximity of edges a radiance estimate performed by our
method will have more support than other methods. We substantiate this assertion in Section 7.
McCool [McC99] use anisotropic diffusion filtering to reduce noise and preserve structure in Monte Carlo rendering.
He processes the rendering in image space using a coherence
map. The coherence map consists partly of world space information about object orientation and depth and partly of
image space information about colour contrast. His filtering of illumination is based on structure derived solely from
colour contrast.
Our algorithm differs from McCool’s as we use anisotropic
filtering only in particle tracing algorithms. We work with
particle distributions in world space and not with pixel contrasts in image space. To our knowledge, anisotropic diffusion has not been employed in connection with the illumination reconstruction of particle tracing algorithms.

5.1. The radiance estimate
In his book [Jen01], Jensen derives an equation which approximates the reflected radiance using the photon map. This
is done by letting the incoming radiance, L i , at a point be
represented by the incoming flux and by letting the incoming
flux at that point be approximated using the point’s k nearest
photons. In this way, the equation for the reflected radiance
becomes
Lr (x, ω) ≈ Lr (x, ω) =

1
π h(x)2

k

fr (x, ωi , ω)

i.

(8)

i=1

The equation sums over the k photons nearest the point x. i
is the flux represented by the ith photon, f r is the bidirectional
reflectance distribution function (BRDF), and h(x) is the
radius of a sphere encompassing the k nearest photons, such
that π h(x)2 is the cross-sectional area of a sphere through
its centre. The radius is dependent on x, because its size is
decided by the photon density in the proximity of x. In the
context of density estimation h(x) is the bandwidth.
The radiance estimate in Equation (8) is simple insofar it
weights each photon in the estimate equally. Jensen refined
the radiance estimate in [Jen96], such that filtering was used
to weigh each photon according to its distance to the point
of estimation.
It is possible to reformulate the radiance estimate to a
general form such that it can be used with different filtering
techniques. We formulate this general radiance estimate as
Lr (x, ω) =

1
h(x)2

k

K
i=1

(x − xi )T (x − xi )
fr (x, ωi , ω)
h(x)2

i,

(9)
5. Density Estimation in Photon Mapping
In photon mapping, indirect illumination is reconstructed
through a series of queries to the photon maps. A photon
map is a collection of photons created during particle tracing
phase, in which photons are reflected around a scene using
Monte Carlo ray tracing. Each query is used to estimate the
reflected radiance at a surface point as the result of a local
photon density estimate. This estimate is called the radiance
estimate.
The accuracy of the radiance estimate is controlled by
two important factors; the resolution of the photon map and
the number of photons used in each radiance estimate. If
few photons are used in the radiance estimate, then noise in
the illumination becomes visible, if many photons are used,
then edges and other sharp illumination features such as those
caused by caustics are blurred. It is impossible to avoid either
of these effects, unless an excessive number of photons are
stored in the photon map. This is the mentioned trade-off
problem between variance versus bias as it manifests itself
in photon mapping.

where x i is the position of the ith photon and K(y) is a
function that weights the photons according to their distance
from x. This function should be symmetric around x, and it
should be normalized such that it integrates to unity within
the distance h(x) to x. In density estimation, K(y) is known
as the kernel function. Usually, the kernel function decreases
monotonically, weighting photons near x higher than those
farther away. In this way, the kernel function reduce bias,
where the change in density is significant.
In his PhD thesis [Jen96], Jensen presents the cone filter.
This filter is used to reduce bias, such that edges and structure
in the illumination are less blurred. As a kernel in the general
radiance estimate, the cone filter has the following form:

K(y) =

⎧
⎨ K(y) =
⎩

0

√

1− k|y|
2 )π
(1− 3k

if

√

|y| < 1,

(10)

otherwise,

where k ≥ 1 is a constant which controls the steepness of the
filter slope.

c 2008 The Authors
Journal compilation c 2008 The Eurographics Association and Blackwell Publishing Ltd.

2119

L. Schjøth et al. / Diffusion based Photon Mapping

Another useful kernel is the Epanechnikov kernel. The
Epanechnikov kernel is known from statistics for its ability
to reduce the MISE of kernel density estimation, but it is furthermore popular, because it is computationally inexpensive
[Sil86]. In computer graphics, Walter has employed it with
good results in [Wal98], and Schregle has in his bias case
study from [Sch03] shown its bias reducing properties to be
competitive. In 2D the Epanechnikov kernel is given by
K(y) =

2
π

(1 − y)

0

if y < 1,
otherwise.

(11)

In this paper, we use the Epanechnikov kernel to examine
our proposed method.

(a)

(b)

Figure 2: (a) Cardioid shaped photon distribution created
by light reflection within a metal ring, (b) gradient field of
the photon distribution in (a).

6. Diffusion Filtering in Photon Mapping
To be able to use anisotropic diffusion filtering in photon
mapping, we have to be able to describe the structure of
the photon map, to get some guidance as how to adapt the
filtering. Furthermore, we need to be able to adapt the kernel
according to the structure description, and it is necessary to
normalize the adapted kernel estimate to preserve energy,
when the kernel changes shape.

6.1. Structure description
The gradient of the illumination function denotes the orientation in which the illumination has maximal intensity change,
and therefore describes the first order structure of the illumination. This information will be used to steer the filtering.
As the illumination function is estimated in the radiance
estimate, the differentiated radiance estimate approximates
the gradient of the photon map.
To differentiate radiance estimate, we combine the generalized radiance estimate from Equation (9), with a suitable
kernel function. Furthermore, it is convenient to simplify the
radiance estimate by assuming that all surfaces hit by photons
are ideal diffuse reflectors. This means that the BRDF, f r , is
constant regardless of the incoming and outgoing direction
of light. In this way, the BRDF need not be differentiated, as
it does not depend on the position, x, which is the variable in
respect to which we differentiate.
This of course is a radical assumption, as photons can be
affected much by the type of surfaces they encounter. However, photons are only stored on diffuse or glossy surfaces,
so the surfaces involved in the radiance estimate are likely
to contain a diffuse element and need therefore not differ
much from an ideal diffuse surface. Using a constant BRDF
to estimate the structure descriptor only affects the diffusion.
In effect, we will have equal diffusion regardless of the incoming directions of the photons. However, the radiance will
still be estimated using the true BRDF.

If we were to differentiate the BRDF, then our algorithm
would not be able to handle arbitrary BRDFs, as we would
have to know the BRDF in order to do so. In effect, we would
not retain the beneficial qualities of photon mapping. Another
solution would be to perform reverse engineering, to numerically estimate the BRDF in question. However, this approach
is both cumbersome and computationally expensive.
Additionally, we have to make a constraint on the generalized radiance estimate. The estimate should use a fixed
bandwidth for h(x), such that the bandwidth is independent
of x, effectively reducing the radiance estimate to a common multivariate kernel estimator rather than the kth nearest
neighbour estimator. This is not a severe constraint. The advantage of the kth nearest neighbour search is its ability to
reduce bias. This ability is important in the radiance estimate, however, when estimating the gradient smoothing is
an advantage, as the gradient is perceptible to noise.
Combining a simplified version of the generalized radiance
estimate with the 2D Epanechnikov kernel we get
Lr (x, ω) =

2fr
π h2

n

1−
i=1

(x − xi )T (x − xi )
h2

i.

(12)

This equation can be differentiated giving us the gradient
function of the estimated illumination function. Differentiating Equation (12) with respect to the jth component of x
gives the partial derivative
4fr
∂ Lr (x, ω)
=
∂xj
π h2

n

−
i=1

xj − xij
h2

i.

(13)

As seen from Figure 2, the gradient of the photon map is a
plausible structure descriptor. Figure 2(a) is a distribution of
photons and Figure 2(b) is a gradient field of the distribution.
The gradient vectors are calculated using the photons nearest
the centre of each quadrant in the grid of the field. The
gradient vectors along the edges of the distribution are those

c 2008 The Authors
Journal compilation c 2008 The Eurographics Association and Blackwell Publishing Ltd.

2120

L. Schjøth et al. / Diffusion based Photon Mapping

with greatest magnitude, and the vectors are as expected
perpendicular to edges and structures.

use the eigenvectors and eigenvalues of the structure tensor
to construct the diffusion tensor.

A more advanced way is to describe the first order structure is with the structure tensor. The structure tensor was
introduced to diffusion filtering by Weickert [Wei95]. The
advantage of the structure tensor is that even though it does
not contain more information than the gradient descriptor, it
is, unlike the gradient, possible to smooth it without losing
important structure information. Being able to smooth the
structure descriptor makes the orientation information less
perceptible to noise.

The orientation of the local edge structure is contained
in the structure tensor. The primary eigenvector, v1 , of the
structure tensor is simply the gradient, which is perpendicular to the local edge orientation. The secondary eigenvector,
v2 , points in the direction parallel to the structure. The corresponding eigenvalues, λ 1 and λ 2 , gives the degree of change
in the directions of the eigenvectors.

We denote the gradient of the photon map as ∇P, where P
is the photon map. The structure tensor is the tensor product
of the gradient. In three dimensions, it is given by
⎞
⎛ 2
Px Py
Px Pz
Px
Py2
Py Pz ⎠ . (14)
S = ∇P ⊗ ∇P = ⎝Px Py
Px Pz
Py Pz
Pz2
In our method, we use the structure tensor to describe the
structure of the photon map.
To improve performance we can reduce the dimensionality
of the problem. This can be done in the density estimate
by projecting local photons and gradient vectors onto the
tangent plane to the surface at the estimation point. If the local
photons and gradient vectors then are transformed into the 2D
tangent space spanned by the tangent and the bi-normal, then
all further estimations can be performed in two dimensions.
In the appendix, it is described how to project photons into
the tangent plane while reducing the bias associated with
high surface curvature.
After projection, the structure tensor can be formulated
as a 2 × 2 matrix. Performance wise this is important as
the eigenvalues and eigenvectors of the structure tensor are
needed to steer the diffusion. The following estimates are
performed in two dimensions. Note, however, that they could
just as well have been done in three dimensions.

6.2. Diffusion tensor
In anisotropic diffusion filtering the filtering is controlled
by a symmetric positive semi-definite matrix called the diffusion tensor [Wei98]. The diffusion tensor can be constructed in variety of ways depending on its purpose. Weickert suggests constructing the tensor as to either promote
edge-enhancing diffusion or coherence-enhancing diffusion.
Coherence-enhancing diffusion is typically useful for completion of interrupted structures, while edge enhancing diffusion steers the diffusion as to enhance edges.
To preserve the finer structures of the illumination during
reconstruction, we employ edge-enhancing diffusion. This is
achieved by constructing the diffusion tensor using information derived from a structure descriptor. Specifically, we can

To achieve edge-enhancing diffusion, the diffusion tensor
should be constructed such that smoothing occurs parallel to
the edges and not across them. The eigenvectors and eigenvalues of the diffusion tensor describe respectively the main
directions of diffusion and the amount of diffusion in the
corresponding direction. Hence, by constructing the diffusion tensor from the eigenvectors of the structure tensor,
diffusion can be steered to enhance the edges.
In this paper, the diffusion tensor is constructed as
D = M diag(μ1 , μ2 ) MT

(15)

where M is [v 2 v 1 ] and diag(·) is the diagonal matrix containing the eigenvalues of D along the diagonal.
It remains to determine the amount of diffusion. That is
the eigenvalues, μ of D:
μ1 = 1,
μ2 =

1
1+

λ1
q

1+α

,

α>0

(16)

where the secondary eigenvalue, μ 2 , is estimated using a
function called the diffusivity function, introduced to diffusion filtering by Perona and Mallik [PM90]. The diffusivity
coefficient, q, decides when the function starts to monotonically decrease and α the steepness of the decline. In practice,
q is the threshold deciding what value of the primary eigenvalue of the structure tensor, λ 1 , is considered an edge and
what is considered noise, and α controls the smoothness of
transition. The primary eigenvalue of the structure tensor
should be normalized such that its range over the photon
map is from zero to one. Section 7 demonstrates how different values of k affect the diffusion.
We have now constructed a diffusion tensor which favours
diffusion parallel to structures while limiting diffusion perpendicular to structures. We will utilize this tensor, such that
it controls the filtering of the photon map.
6.3. The diffusion based radiance estimate
The next step is to use the diffusion tensor to shape the kernel
of the radiance estimate such that it smooths along structures
and edges. To do this, we have to shape our kernel in some
way.

c 2008 The Authors
Journal compilation c 2008 The Eurographics Association and Blackwell Publishing Ltd.

L. Schjøth et al. / Diffusion based Photon Mapping

The multivariate kernel density estimator from Equation
(1) is isotropic insofar the single parameter, h, controls the
filtering. As such smoothing occurs equally in all directions.
Consider a simple 2D normal distribution:
⎛
⎞
2
2
(x
(x
1
1 − μ1 )
2 − μ2 )
⎠
exp⎝− √
− √
f (x) =
2π σ1 σ2
2σ1
2σ2
(17)
where σ1 and σ 2 are the standard deviations with respect to
the axes and μ is the centre of the distribution. Here, we
have a Gaussian kernel whose shape is specified by the two
parameters for the standard deviation. Unfortunately, this
equation only gives control in two directions.
However, generalizing the equation to d dimensions, we
can use an inversed d × d covariance matrix, −1 , to shape
the normal distribution:
f (x) =

1
√

(2π )d/2

det

exp −

(x − μ)T

−1

2

(x − μ)

.
(18)

Using a matrix, we are not limited to control the shape of the
Gaussian kernel in only two directions. If we for example had
shaped our Gaussian kernel to form an ellipse, we could rotate
this kernel by rotating the covariance matrix. The equation
will remain normalized as the determinant of a matrix is
rotational invariant. So the shape of normal distribution in
Equation (18) is controlled by the covariance matrix.
We can use Equation (18) to extend the generalized radiance estimate from Equation (9). To generalize the shape
adapting properties, we use the Mahalanobis distance from
Equation (18) to shape the kernel. The Mahalanobis distance
is a statistical distance. It is given by
(d(x, y))2 = (x − y)T

−1

(x − y).

(19)

As the shape of the kernel should be controlled by the diffusion tensor, we use the tensor in place of the covariance
matrix. We can then reformulate the generalized radiance
estimate as
Lr (x, ω) =

1
√
h2 det D

n

K
i=1

× fr (x, ωi , ω)

i.

−1

(x − xi ) D (x − xi )
·
h2
T

(20)

We now have a general diffusion based radiance estimate,
which filters the photon map adapting the shape of the kernel
according to the diffusion tensor. Or to be even more general,
we have a radiance estimator, which estimates the illumination function taking into consideration the structure of the
photon map, such that edges and structures are preserved.

2121

6.4. Implementation
Implementation of our method can differ depending on which
structure descriptor is used. However, we propose to use the
structure tensor, and for this reason, we need to estimate it,
or have it available during the radiance estimate in order to
construct the diffusion tensor.
We do this using a preprocessing step that approximates
the gradient of the photon map. The preprocessing step occurs between the photon tracing pass and the rendering pass.
To approximate the gradient, we sample it at all photon positions. The advantage of this procedure is that we can store
the local gradient along with the photon, and thus we do
not need a separate gradient map. Additionally, we know the
sampling positions to be located on a surface, as photons are
only stored in connection with a surface. This is useful as the
gradient is only relevant at surface positions.
During the radiance estimate, we calculate the structure
tensors at the photon positions near x. In this way, we can
estimate the local structure tensor as the weighted average
of the surrounding structure tensors. Smoothing the structure tensor reduces noise, and furthermore gives a broader
foundation from which to steer the filtering after.
Weickert operates with two important smoothing parameters, namely integration scale and noise scale. These refer
to the smoothing parameter of the gradient and the structure
tensor respectively. In relation to our method, the noise scale
is the bandwidth used to estimate the gradient in the preprocessing step and the integration scale is the bandwidth used
to smooth the structure tensor. Weickert suggests that the best
results are attained if the noise scale is lower than the integration scale. Through experimentation, we have found this
to be true for diffusion based photon mapping too, although
the amount that they differ seems to have little importance.
Having calculated the local structure tensor, we construct
the diffusion tensor as described in the former section. This
then is used in the general diffusion based radiance estimate
together with a suitable kernel. We use the same bandwidth
for smoothing the structure tensor as for the general diffusion
based radiance estimate.

7. Evaluation and Comparison
To evaluate, we compare our proposed method to regular kth
nearest neighbour photon mapping. Furthermore, we demonstrate that our method avoids a specific drawback common to
many existing bias reducing algorithms, and finally we evaluate the computational performance of our algorithm using
three test scenes of varying complexity. For consistency, the
Epanechnikov kernel is used in all estimations.
To facilitate the evaluation of our method, we have constructed a synthetic photon distribution. The constructed distribution is seen in Figure 3. It is rather simple, yet it contains

c 2008 The Authors
Journal compilation c 2008 The Eurographics Association and Blackwell Publishing Ltd.

2122

L. Schjøth et al. / Diffusion based Photon Mapping

bias, instead we use a fixed bandwidth letting the shape adaption reduce bias.
We first find a suitable bandwidth. This is done using a
large value of the diffusivity coefficient q from Equation
(16). In this way, the kernel will remain rotational invariant,
as it will not adapt according to structure. Estimating the
radiance with a uniform Epanechnikov kernel using different
bandwidths, we then find the bandwidth which reduces noise
to an acceptable level.
Using this bandwidth, we test the diffusion based radiance
estimate by iteratively decreasing the value of the diffusivity coefficient such that the kernel starts to adapt its shape
according to the structure described by the structure tensor.
The result of this procedure is illustrated in the second row
of Figure 4.

Figure 3: A synthetically constructed photon distribution
consisting of 48 000 photons (fewer photons are shown in
the figure for the purpose of visualization).

both edges and ridges and circular and rectangular shapes.
The distribution consists of 48 000 photons.

7.1. The kth nearest neighbour photon mapping
The first row of Figure 4 is a test suite of the constructed distribution created using regular kth nearest neighbour photon
mapping. The suite is created by combining the Epanechnikov kernel from Equation (11), with the general radiance
estimate from Equation (9).
It is seen from the suite that the noise level decreases slowly
with respect to the number of photons per estimate. Bias is
visible as a clearly identifiable blurring of shape edges. In
addition, boundary bias is seen along the boundaries of the
images. It should be clear that the bias increases as the noise
is reduced. This phenomenon is directly related to the bias
versus variance trade-off accounted for earlier. Another thing
to notice is how the thin line losses intensity as the number
of photons per estimate is increased. This happens because
the energy of the line is spread out over a larger area as the
smoothing increases.

7.2. Anisotropic diffusion based photon mapping
We use the diffusion based radiance estimate together with
the Epanechnikov kernel. In contrast to regular photon mapping, we do not use the k nearest neighbour method to reduce

From the results of the diffusion based radiance estimate,
we see that edges are enhanced as the diffusivity coefficient
is decreasing. Comparing the results to those of kth nearest neighbour photon mapping visualized in the first row of
Figure 4, we see that anisotropic diffusion based photon mapping has improved the trade-off between bias and variance
significantly. For instance, comparing Figure 4(d) with Figure 4(h) we see that even though the bias level is comparable
low for the two images, noise is clearly visible in Figure 4(d).
Increasing the bandwidth for kth nearest neighbour photon
mapping as to make the noise level comparable to Figure
4(h) we would at least have to use 600 photons per estimate
which in turn would increase bias well beyond the level seen
Figure 4(h).
Another thing to notice is the thinnest line in the constructed distribution. We know that this line has photon distribution as dense as the two other shapes in the distribution. For this reason, the thin line should be just as intense
as the other shapes. However, as estimates are smoothed
using a larger bandwidth and thus more photons per estimate, the energy is spread out. Comparing the results, it
is seen that the anisotropic diffusion based radiance estimate is most successful in preserving the energy of the
thin line, as it has almost the same intensity as the other
shapes.

7.3. Isotropic diffusion based photon mapping
In order to compare our proposed method to existing bias reducing algorithms, we have developed a method mimicking
these. This method we term isotropic diffusion based photon mapping. Similar to the existing algorithms, isotropic
diffusion based photon mapping reduce the size of the
bandwidth in the proximity of edges. However, it uses the
structure tensor to detect structure and the diffusivity function to determine to what degree bandwidth should be decreased. As we have shown, the structure tensor is a plausible

c 2008 The Authors
Journal compilation c 2008 The Eurographics Association and Blackwell Publishing Ltd.

L. Schjøth et al. / Diffusion based Photon Mapping

2123

Figure 4: Visualizations of a constructed distribution estimated using different photon mapping methods. The first row was
estimated with kth nearest neighbour photon mapping using the (a) 1200, (b) 600, (c) 300 and (d) 150 nearest photons. The
second row was estimated with anisotropic diffusion based photon mapping using a diffusivity coefficient, q, of (e) 0.8, (f) 0.4,
(g) 0.2, and (h) =0.1. The third row was estimated with isotropic diffusion based photon mapping using a diffusivity coefficient,
q, of (i) 0.8, (j) 0.4, (k) 0.2 and (l) 0.1.

structure descriptor, we expect isotropic diffusion based photon mapping to exhibit the same bias reducing qualities as
existing methods and therefore to be a reasonable proxy for
these.

the kernel shape remains rotational invariant. This is done using the result of the diffusivity function as the eigenvalue for
both the primary and secondary eigenvector of the diffusion
tensor.

The approach for isotropic diffusion based photon mapping is quite similar to the one for anisotropic photon mapping. First we find the fixed bandwidth, which reduces the
visible noise to an acceptable level. Then, we iteratively reduce the diffusivity coefficient. However, in contrast to the
anisotropic case, we construct the diffusion tensor such that

The result of this approach is seen in third row of Figure 4.
Comparing the results with those of regular photon mapping,
first row, we see that isotropic diffusion based photon mapping has a superior bias versus variance trade-off. However,
the results also reveal that noise along structure edges becomes apparent as the diffusivity coefficient decreases. The

c 2008 The Authors
Journal compilation c 2008 The Eurographics Association and Blackwell Publishing Ltd.

2124

L. Schjøth et al. / Diffusion based Photon Mapping

Figure 5: Caustic produced by a translucent cylinder posed on a plane: (d) rendered using our method; (a) rendered using
regular photon mapping and the same amount of photons as (d), (b) using approximately the same rendering time as (d) and (c)
with a visual quality comparable to (d).

Figure 6: A cardioid shaped caustic created by a metal ring: (d) rendered using our method; (a) rendered using regular photon
mapping and the same amount of photons as (d), (b) using approximately the same rendering time as (d) and (c) with a visual
quality comparable to (d).

reason for this is that as the diffusivity coefficient is decreasing so is the support area for the estimate. Hence, radiance
estimates made near prominent structure is based on a reduced number of photons, causing noise to appear. This is a
problem inherent to existing bias reducing techniques used
in particle tracing algorithms.
Comparing the results in second row of Figure 4 with
those in the third row, it becomes apparent that anisotropic
diffusion based photon mapping does not suffer the same
degree adverse effects as its isotropic counterpart. Inspecting
the structure edges of Figure 4(h) and Figure 4(l), it is seen
that noise is much less pronounced in the anisotropic case.
The reason for this is that anisotropic diffusion based photon
mapping adapts the filtering according to structure and therefore does not limit the support area near prominent structure
in the same degree as its isotropic counterpart.
We find it reasonable to conclude that anisotropic diffusion
based photon mapping offers an improved trade-off between

bias and variance as compared to existing bias reducing techniques used in particle tracing.

7.4. Performance
In order to test the performance of our proposed algorithm,
we have set up three different test scenes of varying complexity. The image sets in Figures 5, 6 and 7 are renderings of
the three scenes in order of increasing complexity. Each set
contains one image rendered using diffusion based photon
mapping and three images rendered using regular kth nearest
neighbour photon mapping.
The (d) images were created with our method using a
diffusivity coefficient of q = 0.2 and with α equal to one.
The (a), (b) and (c) images were created with regular photon
mapping using (a) the same number of photon as (d), (b)
the approximately same rendering time as (d), and (c) with
a visual quality comparable to (d). For all images created

c 2008 The Authors
Journal compilation c 2008 The Eurographics Association and Blackwell Publishing Ltd.

2125

L. Schjøth et al. / Diffusion based Photon Mapping

Figure 7: Caustics created from water waves: (d) rendered using our method; (a) rendered using regular photon mapping
and the same amount of photons as (d), (b) using approximately the same rendering time as (d) and (c) with a visual quality
comparable to (d).
with regular photon mapping the number of photons per
estimate was regulated for an optimal trade-off between bias
and variance.
Figure 5 is a low complexity scene containing a simple
caustic created by a translucent cylinder. The contours of the
caustics in the Figure 5(a) and 5(b) are clearly blurred as
compared to their counterpart in Figure 5(d). The same is
evident for the image series in Figures 6 and 7. This means
that even with a substantial increase of photons in the photon
map for regular photon mapping, our method still offers a
better trade-off between bias and variance.
Table 1 lists the rendering times for the image series in
Figures 5, 6 and 7. The rendering times for each scene are
relative to a scene rendering using a low resolution photon
map. Consulting Table 1, we see that for all three test scenes,
our method is more than twice as fast as kth nearest neighbour photon mapping, when comparing the rendering times
of the results with similar visual quality. This is because five
to six times as many photons are needed in regular photon
mapping to achieve the same visual quality as with the proposed method. At equal rendering time, it is evident from
the image series that our method produce sharper edges than
regular photon mapping.
Consulting Table 1, we see that for all three test scenes,
regular photon mapping needs five to six times as many
photons to achieve the same visual quality. This means that
rendering times for regular photon mapping are more than
twice those for our method for renderings with comparable
visual quality. Furthermore, the difference in rendering times
increases favourably to our method, concurrent with scene
complexity.
8. Conclusion
In this paper, we have presented a method extending particle
tracing. Our method is a numerical solution to the diffusion

Table 1: Performance results of the images in Figures 5, 6 and
7. The rendering times are relative to a low photon resolution
rendering. For each scene the three first images have been rendered
using kth nearest neighbor photon mapping (KNN) while the last
image has been rendered using diffusion based photon mapping

Scene

Method

Cylinder

KNN

5(a)
5(b)
5(c)

Anisotropic filtering

5(d)

20 000

1.2

KNN

–
6(a)
6(b)
6(c)

20 000
40 000
45 000
160 000

1.0
1.2
1.3
2.7

Anisotropic filtering

6(d)

40 000

1.3

KNN

–
7(a)
7(b)
7(c)
7(d)

50 000
70 000
120 000
520 000
70 000

1.0
1.1
1.7
3.7
1.7

Metal ring

Water

Anisotropic filtering

Figure

Photons in
photon map
5000
20 000
25 000
160 000

Total
time
1.0
1.1
1.2
2.3

equation adapted to photon mapping. The methods enhance
edges and structures of prominent illumination features by
shape adapting the filter kernel according to the structure of
the photon map. In contrast, existing bias reducing methods
only adapts the size of the kernel.
We have evaluated our method using a simple constructed
photon distribution and a number of test scenes. In the evaluation, we demonstrate that our method achieves a superior
trade-off between variance and bias as compared to regular
photon mapping based on the kth nearest neighbour method,
with no substantial increase in computer time. Furthermore,

c 2008 The Authors
Journal compilation c 2008 The Eurographics Association and Blackwell Publishing Ltd.

2126

L. Schjøth et al. / Diffusion based Photon Mapping

Figure 8: Two diagrams illustrating the projection of photons onto the tangent plane of the surface at the estimation point, x.
The photons are projected along their incoming direction.
we substantiate that our method alleviates an edge problem
common to existing popular methods.

Appendix A: Dimensionality Reduction in Photon
Mapping
In photon mapping the surface is presumed to be locally
flat. This is reflected by the fact that the radiance estimate
performs a 2D density estimate on a three-dimensional (3D)
dataset, namely the photon map. The consequence of this
assumption is that when the surface curvature is high and the
photon density is low, the error of the radiance estimate can be
significant. As an example, this error is sometimes evident as
an unnatural increase and decrease in illumination intensity
near corners. In Figure 7(a) and 7(b), the phenomenon is
visible where the caustics are crossing from one wall to the
other. Schregle [Sch03] refers to this error as topological
bias.
One way to increase the accuracy of the radiance estimate
is to ensure that the photons lie in the same plane. This can
be achieved by projecting the photons along their incoming
direction onto the tangent plane to the surface at the estimation point. This calculation can be performed in the radiance
estimate as:
t=

n · (x − xp )
,
n · ωp

Figure 8(a,b) illustrates the projection of photons onto the
a tangent plane to a surface point. At the surface point a
radiance estimate is performed and a circle around the point
illustrates the radius in which photons are collected. In Figure
8(a), the density estimate is performed close to an outward
corner, while the estimate in Figure 8(b) is close to an inward
corner. In Figure 8(a), the photons 1, 2 and 3 are resolved
correctly. However, photon 4 is not part of the k nearest
photons and does not contribute to the radiance estimate
even though it should. Similarly for Figure 8(b), photons 2
and 3 are resolved correctly, while photon 1 is incorrectly
ignored.
The problem with this method is that it can only guarantee that photons within the search radius are resolved correctly. Photon outside the search radius which should have
contributed to radiance estimate are ignored. However, this
method still has an advantage over regular photon mapping
as the defects of topological bias such as those seen in Figure
7(a) and 7(b) are reduced.
The rendering times are relative to a low photon resolution
rendering. For each scene the three first images have been
rendered using kth nearest neighbour photon mapping (KNN)
while the last image has been rendered using diffusion based
photon mapping.

(A1)

References

(A2)

[Arv86] ARVO J.: Backward ray tracing. In SIGGRAPH
’86 Developments in Ray Tracing Course Notes (August
1986), Vol. 12.

where x is the estimation point on a surface, and n is the
surface normal at that point. xp is the position of the photon
and ω p is the photons incoming direction. Then, xproj is the
new projected position of the photon.

[Col94] COLLINS S.: Adaptive splatting for specular to diffuse light transport. In Proceedings of the 5th Eurographics Workshop on Rendering (Darmstadt, Germany, 1994),
Springer.

xproj = xp + ωp t,

c 2008 The Authors
Journal compilation c 2008 The Eurographics Association and Blackwell Publishing Ltd.

L. Schjøth et al. / Diffusion based Photon Mapping

[CRMT91] CHEN S. E., RUSHMEIER H. E., MILLER G.,
TURNER D.: A progressive multi-pass method for global
illumination. In SIGGRAPH ’91: Proceedings of the 18th
annual conference on Computer graphics and interactive
techniques (New York, NY, USA, 1991), ACM Press,
pp. 165–174.
[Hec90] HECKBERT P. S.: Adaptive radiosity textures for
bidirectional ray tracing. In Computer Graphics (August
1990), ACM Siggraph Conference Proceedings, pp. 145–
154.
[JC95] JENSEN H. W., CHRISTENSEN N. J.: Photon maps in
bidirectional monte carlo ray tracing of complex objects.
Computers & Graphics 19, 2 (1995), 215–224.
[Jen96] JENSEN H. W.: The Photon Map in Global Illumination. PhD thesis, Technical University of Denmark,
Lyngby, 1996.
[Jen01] JENSEN H. W.: Realistic Image Synthesis Using
Photon Mapping. A. K. Peters, Ltd., Natick, MA, USA,
2001.
[McC99] MCCOOL M. D.: Anisotropic diffusion for monte
carlo noise reduction. ACM Transactions on Graphics 18,
2 (1999), 171–194.

2127

[RLU95] REDNER R. A., LEE M. E., USELTON S. P.: Smooth
b-spline illumination maps for bidirectional ray tracing.
ACM Transactions on Graphics 14, 4 (1995), 337–362.
[Sch03] SCHREGLE R.: Bias compensation for photon maps.
Computer Graphics Forum 22, 4 (2003), 729–742.
[Sil86] SILVERMAN B.: Density Estimation for Statistics and
Data Analysis. Monographs on Statistics and Applied
Probability, Chapman and Hall, London-New York, 1986.
[Sim96] SIMONOFF J. S.: Smoothing Methods in Statistics.
Springer Series in Statistics, Springer-Verlag, New York,
1996.
[SOS06] SCHJØTH L., OLSEN O. F., SPORRING J.: Diffusion
based photon mapping. In International Conference on
Computer Graphics – Theory and Applications (Set´ubal,
Portugal, February 2006), INSTICC Press, pp. 168–175.
[SWH∗ 95] SHIRLEY P., WADE B., HUBBARD P. M., ZARESKI
D., WALTER B., GREENBERG D. P.: Global illumination
via density-estimation. Rendering Techniques ’95 (1995),
pp. 219–230.
[Wal98] WALTER B.: Density estimation techniques for
global illumination. PhD thesis, Cornell University, 1998.

[Mys97] MYSZKOWSKI K.: Lighting reconstruction using
fast and adaptive density estimation techniques. In Proceedings of the Eurographics Workshop on Rendering
Techniques ’97 (London, UK, 1997), Springer-Verlag,
pp. 251–262.

[Wei95] WEICKERT J.: Multiscale texture enhancement.
Lecture Notes in Computer Science 970 (1995), 230–237.

[PM90] PERONA P., MALIK J.: Scale-space and edge detection using anisotropic diffusion. IEEE Transactions on
Pattern Analysis and Machine Intelligence PAMI-12, 7
(1990), 629–639.

[WHSG97] WALTER B., HUBBARD P. M., SHIRLEY P.,
GREENBERG D. P.: Global illumination using local linear
density estimation. ACM Transactions on Graphgraphics
16, 3 (1997), 217–259.

[Wei98] WEICKERT J.: Anisotropic Diffusion in Image Processing. B. G. Teubner, Stuttgart, Germany, 1998.

c 2008 The Authors
Journal compilation c 2008 The Eurographics Association and Blackwell Publishing Ltd.

