DOI: 10.1111/j.1467-8659.2007.01104.x

COMPUTER GRAPHICS

forum

Volume 27 (2008), number 6 pp. 1557–1566

Statistical optimization of octree searches
Rener Castro, Thomas Lewiner, H´elio Lopes, Geovan Tavares and Alex Bordignon
Matm´ıdia Project, Departamento de Matem´atica, PUC–Rio, Rio de Janeiro, Brazil

Abstract
This work emerged from the following observation: usual search procedures for octrees start from the root to
retrieve the data stored at the leaves. But as the leaves are the farthest nodes to the root, why start from the root?
With usual octree representations, there is no other way to access a leaf. However, hashed octrees allow direct
access to any node, given its position in space and its depth in the octree. Search procedures take the position as
an input, but the depth remains unknown. This work proposes to estimate the depth of an arbitrary node through
a statistical optimization of the average cost of search procedures. As the highest costs of these algorithms are
obtained when starting from the root, this method improves on both the memory footprint by the use of hashed
octrees, and execution time through the proposed optimization.
Keywords: octree, statistical optimization, collision detection, hashing, quadtree, data structures.
ACM CCS: I.3.6 [Computer Graphics]: Graphics data structures and data types E.2 [Data Storage Representations]: Hash-table representations.

1. Introduction
The local geometry of discrete objects is generally based on
groups of nearby elements. Therefore, geometry processing
relies heavily on search procedures such as retrieving objects
at or close to a given position. Some representations of discrete objects, such as grids or meshes, contain explicitly some
of the results of these procedures. In that sense, they provide
one extreme of the execution time/memory space trade off.
Unstructured representations, such as point sets, stay on the
other extreme.
In both situations, independent localization structures usually complement the object proper data structure. Those allow, for example, computing local properties of points sets
such as normals or curvatures; triangulating sampled surfaces
through local algorithms such as moving least-squares techniques, or global algorithms using Delaunay triangulations;
testing collision in animation; representing local physical interaction in simulation and generating multi–resolution representations of discrete objects. Recently, many techniques
use octrees to cluster point sets [SW03, BHGS06] or render
them [BWK02, DVS03].

c 2007 The Authors
Journal compilation c 2007 The Eurographics Association and
Blackwell Publishing Ltd. Published by Blackwell Publishing,
9600 Garsington Road, Oxford OX4 2DQ, UK and 350 Main
Street, Malden, MA 02148, USA.

The classical search data structures are mostly based on
hierarchical representations, because they reduce locations
to a logarithmic complexity. They include octrees, kd–trees,
multigrids, triangulation hierarchies and more general binary
space partitions (BSP). This paper proposes an improvement
of search procedures for octrees based on statistical modelling
of nodes distribution. It works on previously known spaceoptimized representations, and improves the execution time
of these procedures.
1.1. Related works
We will focus here on efficient implementations of search
methods in octrees. [Sam89] provides a general overview
of octrees and their applications. Of particular interest are
memory-efficient representations of octrees. Among those,
[Gar82] introduced linear octrees which use the classical vector representation of fixed valence trees together with efficient
codes for retrieving the position of a node from its index. Her
representation is very compact but represents only full octrees, i.e. octrees with all the leaves at maximal depth. More
recently, [WS93] extended the work of [Gla84] with hashed
octrees which represent an octree as a hash table of nodes,

1557

Submitted August 2006
Revised January 2006
Accepted October 2007

1558

R. Castro et al. / Statistical optimization of octree searches

Figure 1: As the leaves are the farthest nodes to the root, why start from the root to look for the leaves? An optimal initial level
greatly reduces the search costs: (left) an octree refined to separate each vertex of the Stanford bunny; (middle) the histogram
of the number of octree leaves per depth; (right) cost of searching for a leaf starting from different depths.
indexed by their Morton codes [Mor66], as detailed in Section 2. This representation is both compact and allows direct
access of an octree node from its Morton code.
Search procedures can benefit from the direct access facility provided by Morton codes. For full octrees, [Sch92]
provides a simple algorithm to generate the Morton codes
of the adjacent neighbours. [SS95] improved the efficiency
of the code computation using integer dilation. This optimized search has been further extended to other neighbours
in [GDB03, chap. III], starting from the same depth and
computing the Morton codes of the parent or the children
of a given node to complete the traversal. Our work further improves their approach by extending it to direct search
and using a statistical estimation of the neighbours’ depths
(see Figure 1).

1.2. Contributions
We propose improved search procedures for hashed octrees to
benefit from the direct access offered by that representation.
Compared to classical octree representations, it reduces both
execution time and memory consumption. Compared to previous hashed octree operations, it maintains the same memory usage and saves execution time. Although the method
relies on a simple statistical modelling, it improves on previous methods even in the worst case. Moreover, the method
is not specific to dimension 3, and can be directly applied to
quadtrees or higher dimensional 2d -trees.
For the hashed octree introduced in Section 2, the retrieval
of a node by its spatial position and its depth has an average
constant execution time. The main idea for retrieving the leaf
in a given position is to estimate its depth (see Section 3). This
involves a simple statistical modelling (presented in Section
4), which also applies to and improves neighbour retrievals.
The method improves searches by an average factor above
15, as shown by the experiments reported in Section 5.

Figure 2: Quadtree with the node keys, using the following
orientation for the nodes bottom-left, top-left, bottom-right,
and top-right.
2. Octree representations
An octree is a hierarchical data structure based on the recursive decomposition of a 3D region (see Figure 2 for a
2D example). A node of an octree represents a cube in that
region. Each of the eight children of a node represents one
octant of its parent, and the data is usually stored at the leaves.
This hierarchy of subdivisions is commonly represented by a
directed tree where each node is either a leaf or has eight children (this work actually includes octrees where a node can
have less than eight children). We will consider here general
octrees, sometimes called variable resolution octrees because
they have leaves at different depths. This section recalls the

c 2007 The Authors
Journal compilation c 2007 The Eurographics Association and Blackwell Publishing Ltd.

1559

R. Castro et al. / Statistical optimization of octree searches
110

1

101

100

110

111

010

10000

10011

10010

10001

11101

11100

1111001

1111000

111

11110

011

11111

1111011

1111010

(a) Hierarchical representation.

Y
101

001
1

Z
000
101

100

110

100

111

X

10000

10010

10001

10011

1111000

11101

11100

1111001

1111010

11110

11111

Figure 4: Suffixes to append to the parent key to obtain the
child keys.
In addition, some implementations add pointers to the parent to accelerate bottom-up traversals. The second option uses
less memory, but requires more execution time to search for
a given leaf.

1111011

(b) Brother/child representation.
000

001

010

011

100

101

110

111

1111000

1111001

1111010

1111011

11100

11101

11110

11111

10000

10001

10010

10011

100

101

110

111

1

(c) Hashed representation

Figure 3: Three representations for the quadtree of
Figure 2. The hash table uses the three least significant bits
of the key: k mod 23 . The octree case is identical.
basic implementations of octrees and search procedure. The
reader will find a more exhaustive description in [Sam89].
2.1. Classical octree structures
The two most common representations of octrees use pointers
to allow variable resolutions of a tree. The first one relies on
an exhaustive tree representation (see Figure 3(a)): each node
has eight pointers, one for each of its eight children, and a
pointer to the data. The children pointers are null for leaves,
and the data pointer is null for intermediate nodes. The second
one relies on the brother/child tree representation (see Figure 3(b)): some nodes have a pointer to its first child and to
the next child of its parent, and a pointer for the stored data.

2.2. Hashed octrees
Another type of octree representation, more compact, stores
the nodes in a hash table, which allows direct access to
any node while avoiding explicit pointers for the octree
hierarchy (see Figure 3(c)). This representation assigns to
each node a key, which identifies it and serves for computing
its address in the hash table. The key can be computed either from the position of the node inside the octree hierarchy
through a systematic orientation of the octants of a node (see
Figure 4) or from the coordinates of the node in space. In
efficient schemes, the key can be equally computed by both
methods. At the same, this allows time to identify the children
of a node by the octant orientation for traversal algorithms,
and to access a node directly from its position for search
procedures.
2.3. Morton keys
To our knowledge, the most efficient key generation mechanisms use the codes of Morton [Mor66]. The key k(n) of a
node n can be generated recursively from the octree hierarchy: the key of the root is 1, and the key of the child of n is the
concatenation of k(n) with the 3 bits of the child octant (see
Figure 4). With that convention, the depth of n is 13 log2 k(n)
and the key of the parent of n is obtained by truncating the 3
least significant bits of k(n): k(n) 3 (shift right by 3 bits).
The key k(n) can also be generated from the depth l of
n and the position (x, y, z) of its centre: assuming that

c 2007 The Authors
Journal compilation c 2007 The Eurographics Association and Blackwell Publishing Ltd.

1560

R. Castro et al. / Statistical optimization of octree searches

11101
N
101
N

101
C
11100
C

1010010101100010110101110000
1000111

10001
C

1000110

10001
N

1100100

1111000
N

10011
X
110
N

1000011100100110010111100001
10000
N

10010
C

(a) Adjacent neighbors of node 10011

1111001
N

1100101
10011

10011
X
110
C

10000
C

11100
N

(b) Adjacent nodes to 10011 of depth 3

10010
N

(c) Neighbors of node 10011 in radius

1
2

Figure 5: The adjacent neighbours search (a) and inradius neighbours search (c). When searching downward in the adjacency
search (case 2), only the keys of the adjacent children are needed (b).
the root is the unit cube [0, 1]3 , the key k(n) is computed
by interleaving the bits x i , y j , z k , of x, y and z: k(n) =
1xl yl zl xl−1 yl−1 zl−1 . . . x1 y1 z 1 (the codes in the 2D case are
drawn on Figure 2). Interleaving can be accelerated by integer
dilation [SS95].
The hash function assigns to a node n the b least significant
bits of its key: k(n)mod2b . It tends to homogenize the hash
table (see Figure 3(c)), in the sense that its entries are regularly
distributed, especially when the octree is unbalanced. In this
paper, we will assume that the hash table is homogeneous,
and thus the access of a node by its key can be performed in
constant time.

3. Optimized search
This work emerged from the following observation (see Figure 1): as the leaves are the farthest nodes to the root, why
start from the root when looking for a leaf? The answer for
the usual octree representation reduces to: there is no other
way to access a leaf. However, with hashed octrees, a leaf
can be directly accessed by its Morton code, which depends
only on the leaf position and depth. The position is known
when looking for a leaf, but its depth may not. The following
algorithms describe how to retrieve a leaf (or more generally
ˆ The next
a node) from its position and an estimated depth l.
section will describe how to estimate the depth of a leaf.
Algorithm 1 find(point p): find the leaf containing p.

2.4. Classical search procedures
The search for the data associated to a spatial position p in an
octree consists in finding the leaf containing p and retrieving
its data. In pointer octrees, the only way to access a node is
to start from the root and recursively choose the child whose
octant contains p. This procedure has a complexity proportional to the depth of the found leaf. It is usually estimated
as log8 (N), where N is the number of nodes of the octree,
when the tree is balanced, and O(N) in the worst case. This
procedure is widely used for pointerless octrees. Observe that
we can avoid storing the position and size of a node, because
they can be deduced from the traversal.
Some other queries can be performed on an octree: finding
the nodes adjacent to a given node n (see Figure 5(a)), which
will be called adjacent neighbours hereafter, and the nodes
which are within a given radius ρ of n (see Figure 5(c)),
which will be called inradius neighbours hereafter. The usual
algorithm also uses a top-down approach. In the first case, it
recurses on all the children that intersect n, and in the second
case the ones that intersect the ball of radius ρ centred at the
centre of n. These searches are illustrated on Figure 6.

1: compute the key k max of p at maximal depth
2: compute the key k of p at depth lˆ using k max
3: access the node n corresponding to k in the hash table
// Case 2: n is not a leaf
4: while n exists in the hash table do
5:
increase by one the depth of k using k max
6:
access the child of n in the hash table with k
7: end while
8: retrieve the last valid access
// Case 3: n is below the leaf
9: while n does not exist in the hash table do
10:
decrease by one the depth of k
11:
access the parent of n in the hash table with k
12: end while
13: return n
3.1. Direct Search
The direct search procedure of Algorithm 1 is a straightforward application of this idea: In order to find the (unique) leaf
containing a point p, the algorithm generates the key k l ( p)

c 2007 The Authors
Journal compilation c 2007 The Eurographics Association and Blackwell Publishing Ltd.

R. Castro et al. / Statistical optimization of octree searches

1561

Figure 6: Illustration of the search procedures in 3D, on an octree adapted to the 34,834 vertices of the bunny point set.
ˆ Looking for the node n l ( p)
of p at the estimated depth l = l.
corresponding to that key, three situations may occur:
1. The node n l ( p) is a leaf: the algorithm thus returns
n l ( p).
2. The node n l ( p) is not a leaf: it means that the estimated
depth l is too low, and l is incremented until n l ( p) points
to a leaf, which is returned.
3. There is no node corresponding to n l ( p): it means that the
estimated depth l is too high, and l is decremented until
n l ( p) points to a node. The first node is then a leaf, and
the algorithm returns it.
Observe that if the estimated depth is zero, the search starts
from the root and operates with the second case, which corresponds to the usual hierarchical search. Moreover, the key
does not need to be recomputed in the third case, because
the key of n l−1 ( p) can be deduced from the key of n l ( p) by
truncating the 3 least significant bits. Similarly in the second
case, the key at depth l + 1 can be generated from the key at
the maximal depth k max ( p) as above : k l+1 ( p) = k max ( p)
3 · (l max − l − 1), which is faster than generating a new key.

3.2. Adjacent neighbours search
The procedure to find the adjacent neighbours of a node n
(see Figure 5(a)) resembles the direct search, although it must
return a variable number of leaves. We considered two options
to optimize the adjacent node search. First, we generated the
keys of the adjacent neighbours at an optimal depth lˆ and
followed the octree hierarchy towards the leaves. However,
this requires many hash table accesses.
We thus developed a second option for the neighbour
search, presented in Algorithm 2: we generate the keys of
the 26 nodes adjacent to n, with the same depth l(n). Without
statistical optimization, the algorithm would follow the three
cases of the direct search, with the following modification of
the second case, in the spirit of [GDB03].

Algorithm 2 adjacent(n): find the adjacent neighbours of n.
1: put into set s the adjacent neighbours n i at depth l(n)
2: for all nodes n i in s do
3: in the hash table, find the node n i
//Case 1: n i is a leaf
4: if n i exists in the hash table and is a leaf then
5:
add n i to the result set r
6:
7:

//Case 2: n i is not a leaf
else if n i exists in the hash table then
insert into s the children of n i adjacent to n

//Case 3: n i is below the leaf
8: else
ˆ l(n)}
9:
call find (n i ) using depth min{l,
10:
add the found node to the result set r
11: end if
12: end for
13: return the result set r
For the second case, several keys k(n i ) may be generated
at each increment of the depth: there is only one adjacent (l −
1)-neighbour if n i is in the diagonal of n, two if n i shares an
edge with n and four if n i shares a face with n, as illustrated on
Figure 5(b) for the 2D case. The keys of these (l − 1)-nodes
are systematically generated using a small lookup table, and
the algorithm recurses on each of these adjacent neighbours
of depth (l − 1).
As an error of depth estimation in the second case may
result in generating many unused keys, we maintain the above
hierarchical search starting from the 26 adjacent nodes in the
second case. However, the third case can be optimized in a
similar way to the leaf search: if a neighbour of n has a lower
depth than n, we search for it directly at the estimated depth
ˆ if lower than the depth of n. This avoids many intermediate
l,
lookups in the hash table. Moreover, as opposed to our first
option, it benefits from the fact that, if node n is already at
the deepest level of the octree, at least 7 of its adjacent node

c 2007 The Authors
Journal compilation c 2007 The Eurographics Association and Blackwell Publishing Ltd.

1562

R. Castro et al. / Statistical optimization of octree searches

have the same depth. This optimization is actually effective,
as shown in Section 5.

depth:
ˆ =
cost(l)

pl · fl · costlˆ(l).
l

3.3. Inradius neighbours search
The search for nodes within a given radius of n mimics the
adjacent neighbour search. The only difference is again in
the second case, since there are eight neighbours of depth
(l − 1) for each l–neighbour (instead of 1, 2 or 4), which
involves more key generation and hash table access than the
adjacent neighbour search (see Figure 5(c)). Moreover, if the
ˆ
radius is greater than 2−l , some inradius neighbours may not
be adjacent to n and the initial set {ni } of inradius neighbours
must contain more than 26 nodes. We propose here the same
optimization as for the adjacent node, which restricts it to the
third case of the algorithm and gets similar results.

4. Statistical modelling

4.2. Direct search
As mentioned earlier, we will assume that the hash table is
homogeneous, and that accesses to it are made in constant
time. We model the cost of the three cases of the direct search
as follows: if the depth is correctly estimated (case 1), the
node is returned directly with a constant time c. Moreover,
as we use a unique key generation for all the cases, the costs
of computing the key of a parent or a child are equal (cases 2
ˆ generated keys when searching a
and 3). As there are |l − l|
node at depth d, the cost of that search is the sum of a constant
cost c for the key generation plus an overhead proportional
ˆ
to the difference |l − l|:
ˆ =c+
cost(l)

The above algorithms rely on an estimated depth lˆ to look
for the leaf. If we set this depth to zero or l max , the algorithms always start from the root: the direct and the neighbour search behave like the classical octree traversal, and
the adjacent neighbour search enhances classical procedures
only by avoiding geometrical tests. As we mentioned earlier,
as leaves are the farthest nodes from the root, lˆ = 0 corresponds to the worst case (maintaining lˆ below the maximal
depth).
We will now look for a simple statistical model for lˆ in
order to optimize the cost of the search procedures. The computation of lˆ requires a small time overhead during the octree
construction, and can be updated dynamically. Observe that,
as the worst case lˆ = 0 is also the most widely used, even
without any optimization for lˆ our method improves on previous works.

4.1. Cost model
The total cost of the search depends on how many times, on
average, each leaf n will be looked for. We will denote this
number by f (n). For example, if we look for every position in
the domain of the octree, f (n) is proportional to the size of n,
which is a power of its depth: f (n) ∼ 23(lmax −l(n)) . If we look
for some data related to the octree structure, such as internal
collision detection, we may choose f (n) ∼ 1.
Our main assumption is that f (n) depends only on the
depth of n: f (n) = f l . In practice, this means that the octree is used without geometric bias. Observe that this is
the case for the two examples mentioned above. The average cost of the search is then the sum on each leaf n of
ˆ =
the cost of searching that leaf multiplied by f (n): cost(l)
f
(n)
·
cost
(n).
As
the
cost
of
searching
a
leaf
deˆ
l
n∈leaves
pends only on its depth, and denoting by pl the number of
leaves of depth l, we can write it as a sum indexed by the

pl · fl · (lˆ − l) +
l<lˆ

ˆ
pl · fl · (l − l).
l>lˆ

We look for the value of lˆ that minimizes that cost. To do so,
ˆ and look
we construct a differentiable cost function cost(l),
for a zero of its derivative, as detailed in the Appendix:
dcost ˆ
(l) =
dlˆ

lˆ

p(l) f (l) dl
0

−

∞

p(l) f (l) dl.
lˆ

The optimal cost lˆ is thus the median of the depths of the
octree leaves weighted by the number of times they are looked
for: lˆ must satisfy l<lˆ pl · fl = l>lˆ pl · fl . This median
can be dynamically computed during the octree creation by
maintaining a small histogram of the leaves depth. It can also
be approximated by the weighted mean, which reduces the
(already small) preprocessing time.
4.3. Adjacent and inradius neighbors search
The estimation of the depth for the other searches will differ
from the previous one in only one aspect: the statistical model
or f l depends on the node n whose neighbours we are looking
for. Whereas pl n depends only on the depth l n = l(n), the
distribution pl depends on n. The optimum thus depends on
each node n. For extensive use of the octree, this optimum can
be computed for each node, and requires storing one more
integer per node. However, as we use this optimum only in
the third cases of the algorithms, where the neighbour has a
lower depth, we may consider that the distribution of pl n and
pl are independent. Therefore, we approximate the optimal
depth for all nodes by the optimal depth of the direct search.
5. Experiments
We tested our optimization on octrees tracking geometrical
objects in two settings: raw searches inside the octree and
within a collision detection context. The tests were performed
on a 3GHz Pentium IV machine.

c 2007 The Authors
Journal compilation c 2007 The Eurographics Association and Blackwell Publishing Ltd.

1563

R. Castro et al. / Statistical optimization of octree searches

Table 1: Building and preprocessing times on different point sets: varying density (Maracan˜a, David head, Pig, Fighter, Deltao), volumetric
(Volcano, Fighter, Deltao, Cube).
Memory
Point Set
Sphere
Bunny
Maracan˜a
David head
Pig
CSG
Volcano
Fighter
Deltao
David
Rnd sphere
Dragon
Happy
Blade
Chair
Rnd cube
Thai statue

Build

Optimization

Deepest
level

8ptr
(MB)

BCptr
(MB)

Hash
(MB)

8ptr
(msec)

BCptr
(msec)

Hash
(msec)

Time
(msec)

Level

4.4
6
144
9
190
21
395
13
401
11
529
19
551
21
723
14
1 210
20
1 534
21
2 883
18
3 060
21
3 617
21
5 412
16
9 255
18
15 675
12
22 296
20
weighted average

0.2
6.9
9.1
19
19
25
26
35
58
74
138
147
174
260
444
752
1070
632

0.1
3.4
4.6
9.5
10
13
13
17
29
37
69
73
87
130
222
376
535
316

45
50
51
51
51
52
52
54
60
62
82
85
96
134
223
376
535
321

5.6
224
268
726
772
819
1 043
1 584
2 466
3 124
5 756
5 634
7 227
11 641
34 471
45 867
155 803
68 436

5.4
215
257
682
725
768
967
1 509
2 119
2 819
5 100
5 280
6 627
10 079
24 833
39 380
106 509
49 213

11.1
187
230
548
583
642
795
1 211
1 695
2 379
4 053
4 286
5 361
8 384
20 076
31 012
81 446
38 084

7.8
14.2
27.1
32.4
38.2
50.7
50.2
58.6
116
135
268
314
377
518
930
1 202
2 229
354

4
7
21
9
10
8
9
9
12
10
9
10
10
10
11
8
12

# Nodes
(×1000)

Number of searches
Point
Leaf
(×1000)
(×1000)
0.9
35
10
100
100
82
133
257
208
350
500
438
544
883
1 669
4 000
5 000

3.8
126
167
346
351
463
482
632
1 058
1 342
2 523
2 678
3 165
4 735
8 098
13 715
19 509

The building of hashed octree is slightly faster than pointer octrees. The memory consumption is equal for both cases on big point sets. The
preprocessing consists in computing the optimal level and lasts less than 1% of the build time. The averages are weighted by the octree size.
The number of searches are reported for each point set according to the simulated frequency model (the grid search has a constant number of
searches 2097).

5.1. Raw search
We test each of the three proposed search procedures on octrees adapted to a set of points: the nodes are subdivided until
they contain less than one point of the set or if their level is
maximal (21 as we work with 64-bits keys). The octree build
is slightly faster on hashed octrees, and the optimization time
is around 1% of the build time (see Table 1). In our tests, we fix
the hash function to return the 21 least significant bits of the
key. This generate hash tables of sizes similar to the memory
consumption of pointer representation on the big point sets
we used. We compare our results with the classical top-down
search procedures on classical 8-pointers representation and
brother/child representation and hashed representation (see
Table 2). Searches on unoptimized hashed representation are
slower because the access to the child of a node requires
an access to the hash table. Our algorithm performs in average 15 times faster than the pointer representation. For the
other searches, the performance of our method remains several times faster.
Moreover, we compare different optimizations depending
on the a priori access frequency f (n) to a leaf of level n, as
described in Section 3. We experiment with three frequency
model: searching for each point of the set ( f points (n) = \ #
points ∈ n), for each leaf of the octree ( f leaves (n) = 1) and
for each voxel of a regular grid 1273 ( f grid (n) = 23(7−l(n)) ).

This optimization is experimentally validated in Table 3: the
searches return significantly faster when we choose the correct frequency model for the optimization.
5.2. Collision detection
We also tested our optimized search on a real context of
collision detection: we simulated a small ball kicking inside a 3D mesh. Here the octree is adapted to the triangles of the mesh, and each leaf is eventually associated
with one of the mesh triangles intersecting it. At each iteration, the algorithm searches the octree for the leaf containing the ball. If there is a triangle associated with that leaf,
the ball changes direction according to Snell–Descartes reflection. As these operations use direct searches intensively,
our optimized octree outperforms the classical representation
(see Table 4).
6. Conclusions
In this paper, we introduced a statistical optimization for octree searches. The optimization applies to pointerless octrees,
such as hash table representations. In particular, these representations allow a direct access of a node from its key, and replace geometrical tests by bitwise key manipulations. Within
this context, we proposed to search a node directly at its estimated level, instead of starting from the root. The resulting

c 2007 The Authors
Journal compilation c 2007 The Eurographics Association and Blackwell Publishing Ltd.

1564

R. Castro et al. / Statistical optimization of octree searches

Table 2: Execution time (in microseconds) of our optimized searches, compared to classical top-down searches on classical 8-pointers (8ptr )
brother/child (BCptr ) and hash (Unopt) representations.

Direct search

Find adjacent neighbors

Find inradius neighbors

Point Set

8ptr

BCptr

Unopt

Ours

8ptr

BCptr

Unopt

Ours

8ptr

BCptr

Unopt

Ours

Sphere
Bunny
Maracan˜a
David head
Pig
CSG
Volcano
Fighter
Deltao
David
Rnd Sphere
Dragon
Happy
Blade
Chair
Rnd cube
Thai statue

2.17
2.86
6.53
3.29
3.71
3.30
3.28
3.89
4.47
3.58
4.50
3.81
3.80
3.65
3.83
4.18
3.93

7.24
11.28
31.21
12.98
15.40
13.34
13.42
14.82
18.63
15.04
16.42
15.88
16.17
15.25
16.38
14.76
17.38

11.47
18.67
53.47
21.27
25.65
21.98
22.73
24.53
31.64
26.54
27.92
27.43
28.69
27.98
31.41
33.54
37.51

0.58
0.75
0.60
0.64
0.71
0.79
0.71
1.06
1.65
0.87
1.59
1.17
1.21
1.27
2.15
3.79
3.13

23.10
38.34
58.98
43.57
46.46
40.60
43.04
54.70
49.07
46.13
46.51
45.53
46.30
44.05
46.56
51.36
49.99

23.85
35.93
55.79
40.88
43.90
37.75
40.37
50.38
45.56
42.64
42.55
42.80
43.05
40.89
43.43
46.69
47.58

41.55
59.70
95.70
68.69
74.64
63.22
68.74
86.60
77.67
73.64
73.15
74.31
75.37
73.09
80.89
95.21
94.86

7.63
8.70
9.12
9.43
11.73
9.76
8.83
12.88
11.30
10.39
14.45
12.79
13.18
13.11
19.34
27.44
22.43

28.38
36.70
77.75
42.61
53.53
38.79
40.18
51.81
180.30
43.71
42.43
45.88
48.60
43.84
52.92
45.34
79.50

25.39
35.44
76.31
40.93
51.59
37.18
39.43
49.92
169.13
42.17
41.42
44.44
46.39
41.54
50.80
44.04
77.18

41.49
59.26
136.91
70.30
91.88
62.81
69.16
87.79
332.11
74.79
72.71
79.03
83.23
75.27
96.60
84.09
163.46

0.71
0.73
33.72
1.39
10.67
4.57
2.78
2.18
129.28
11.88
9.02
11.67
15.46
11.45
24.48
0.96
53.56

3.81
× 3.8

15.62
× 15.7

27.79
× 26.9

1.33
×1

45.55
× 3.8

42.59
× 3.6

75.12
× 6.2

13.09
×1

56.02
× 14.5

53.72
× 13.8

98.88
× 24.2

19.09
×1

average
gain

Our optimized direct search returns 15 times faster than brother/child searches, and between 10% (random volume) and 1090% faster (maracan˜a)
than classical representations. Each time reported is the average of the searching time for each point of the set. The gain corresponds to the ratio
of the pointer search times over our search times.
Table 3: Average on all the point sets of the execution times (in
microseconds) of the direct search, simulating different frequency
models (lines)

Search all Points
Search all Leaves
Search on a Grid

f points

f leaves

f grid

1.30
0.95
1.70

1.33
0.93
1.66

2.45
1.52
0.89

Optimizing according to the correct frequency model (diagonal
terms) improves the search performance between 2% (points) and
92% (grid). The number of searches in each case is reported on
Table 1.

algorithms combine the memory efficiency of the hashed octree with an execution time performance around 10 times less
than a classical implementation. The proposed strategy works
particularly well on geometric data with multiple level of details (like the Maracan˜a model), but has limited, although
positive gain on data with depth distributions with high variance (like random volume models). Mixed statistical models
may extend this work to more general geometric data.

Table 4: In a collision detection environment where a ball kicks
into a 3D surface, our optimization improves the frame rate (in Hz),
including the whole pipeline from the ball position computation to
the rendering
Frame rate

Surface

# Trigs
(×103 )

# Nodes
(×103 )

8ptr

BCptr

Ours

Sphere
Bunny
David
Dragon
Buddha

2
69
700
871
1 088

4 432
16 671
11 236
23 904
19 525

11.3
7.0
4.6
5.0
3.9

9.0
5.0
3.2
4.1
2.9

60.0
20.4
7.4
7.5
4.1

average

× 2.5

× 3.3

partly supported by the Brazilian Ministry of Science and
Technology (MCT/CNPq Universal 02/2006), and the State
of Rio de Janeiro (FAPERJ Primeiros projetos 2004).

Acknowledgement

References
[BHGS06] BOUBEKEUR T., HEIDRICH W., GRANIER X.,
SCHLICK C.: Volume–Surface Trees. Computer Graphics
Forum 25, 3 (2006), 399–406.

The authors would like to thank Prof. Dr. G¨unther F. Schrack
for providing references on bit interleaving. This work was

[BWK02] BOTSCH M., WIRATANAYA A., KOBBELT L.: Efficient high quality rendering of point sampled geometry.

c 2007 The Authors
Journal compilation c 2007 The Eurographics Association and Blackwell Publishing Ltd.

1565

R. Castro et al. / Statistical optimization of octree searches

In Eurographics Workshop on Rendering (2002), pp. 53–
64.
[DVS03] DACHSBACHER C., VOGELGSANG C., STAMMINGER M.: Sequential point trees. In SIGGRAPH (2003),
pp. 657–662.
[Gar82] GARGANTINI I.: Linear octrees for fast processing
of three-dimensional objects. Computer Graphics and Image Processing 4, 20 (1982), 365–374.
[GDB03] GUMEROV N. A., DURAISWAMI R., BOROVIKO
E. A.: Data Structures, Optimal Choice of Parameters,
and Complexity Results for Generalized Multilevel Fast
Multipole Methods in d Dimensions. Tech. rep., University
of Maryland, 2003.

Figure 7: A probability density p(l) of the number of leaves
pl of depth l of the bunny.

[Gla84] GLASSNER A.: Space subdivision for fast ray tracing. Computer Graphics & Applications 4, 10 (1984), 15–
22.

6

[Mor66] MORTON G. M.: A Computer Oriented Geodetic
Data Base and a New Technique in File Sequencing. IBM,
1966.

5

cost

4

[Sam89] SAMET H.: Applications of Spatial Data Structures. Adison–Wesley, Reading, 1989.
[Sch92] SCHRACK G.: Finding neighbours of equal size in
linear quadtrees and octrees in constant time. Computer
Vision, Graphics and Image Processing 55, 3 (1992), 221–
230.
[SS95] STOCCO L., SCHRACK G.: lnteger dilation and contraction for quadtrees and octrees. In Communications,
Computers and Signal Processing (1995), IEEE, pp. 426–
428.
[SW03] SCHAEFER S., WARREN J.: Adaptive vertex clustering using octrees. Geom. Design and Computing (2003),
491–500.
[WS93] WARREN M. S., SALMON J. K.: A parallel hashed
octtree N-body algorithm. In Supercomputing (1993), 12–
21.

pl · fl · (lˆ − l) +

1

0
1

2

3

ˆ
pl · fl · (l − l)
l>lˆ

To do so, we consider a differentiable function cost interpoˆ = cost(l).
ˆ
lating the discrete cost function: ∀lˆ ∈ N, cost(l)
From the intermediate value theorem, the level lˆm includˆ is at a distance less than 1
ing the lowest cost cost(l)

4

5

6

7

8

9

10

level

ˆ and differentiable
Figure 8: Discrete cost function cost(l)
ˆ for the bunny: the differentiable cost has
cost function cost(l)
a unique minimum, whose integer part is the minimum of the
discrete cost.

to a local minimum cost(l m ) of the differentiable function
cost: |lˆm − lm | < 1. We will now construct the differentiable
function cost in order to have generically only one minimum
l m , and we will round it to optimize the cost function.
ˆ by the following integral :
We define cost(l)
lˆ
0

ˆ deWe aim at minimizing the discrete cost function cost(l)
fined in Section 4 (see Figure 8):

l<lˆ

2

ˆ =c+
cost(l)

Appendix A: Minimization of the cost

ˆ =c+
cost(l)

3

p(l) f (l)(lˆ − l)dl +

∞
lˆ

ˆ
p(l) f (l)(l − l)dl.

Considering p(l) as a probability density for pl and f (l) as
a density for f˙l, the differentiable function cost interpolates
the discrete cost function. As a canonical construction, we
define pl by parts on each integer interval [l, l + 1]. Each
part is a parabola of area p(l) canceling at the interval bounds
(see Figure 7). With a similar construction for f l , the functions to be integrated in the definition of cost are continuous,
and thus cost is a differentiable function (see Figure 8). For
generic distributions pl and f (l), this function has a unique

c 2007 The Authors
Journal compilation c 2007 The Eurographics Association and Blackwell Publishing Ltd.

1566

R. Castro et al. / Statistical optimization of octree searches

local minimum l m , which can be computed by differentiation:
lˆ

d
dcost ˆ
(l) =
c+
dlˆ
dlˆ
+
=

∞
lˆ

d ˆ
l·
dlˆ
lˆ

−
0
∞
lˆ

− lˆ ·

p(l) f (l)(lˆ − l) dl

0

lˆ

=

ˆ f (l))
ˆ − p(l)
ˆ f (l)
ˆ · lˆ
p(l) f (l) dl + lˆ · ( p(l)

ˆ f (l)
ˆ · l)
ˆ
− ( p(l)

lˆ

∞

−

p(l) f (l) dl+

lˆ

0

p(l) f (l) · l dl +

p(l) f (l) dl
lˆ

0

ˆ dl
p(l) f (l)(l − l)

p(l) f (l) · l dl+

∞

lˆ

=
0

ˆ f (l))
ˆ
p(l) f (l) dl − lˆ · (− p(l)

p(l) f (l) dl −

∞

p(l) f (l) dl
lˆ

As this minimum is unique, it must be close to the minimum
of the discrete cost (see Figure 8).

c 2007 The Authors
Journal compilation c 2007 The Eurographics Association and Blackwell Publishing Ltd.

