Eurographics/ IEEE-VGTC Symposium on Visualization 2008
A. Vilanova, A. Telea, G. Scheuermann, and T. Möller
(Guest Editors)

Volume 27 (2008), Number 3

Visual Analysis and Semantic Exploration of Urban LIDAR
Change Detection
Thomas Butkiewicz, Remco Chang, Zachary Wartell, William Ribarsky
Charlotte Visualization Center, UNC Charlotte

Abstract
Many previous approaches to detecting urban change from LIDAR point clouds interpolate the points into rasters,
perform pixel-based image processing to detect changes, and produce 2D images as output. We present a method
of LIDAR change detection that maintains accuracy by only using the raw, irregularly spaced LIDAR points,
and extracts relevant changes as individual 3D models. We then utilize these models, alongside existing GIS data,
within an interactive application that allows the chronological exploration of the changes to an urban environment.
A three-tiered level-of-detail system maintains a scale-appropriate, legible visual representation across the entire
range of view scales, from individual changes such as buildings and trees, to groups of changes such as new
residential developments, deforestation, and construction sites, and finally to larger regions such as neighborhoods
and districts of a city that are emerging or undergoing revitalization. Tools are provided to assist the visual analysis
by urban planners and historians through semantic categorization and filtering of the changes presented.
Categories and Subject Descriptors (according to ACM CCS): I.3.8 [Computer Graphics]: Applications;

1. Introduction
In the mission statement for the USGS Center for LIDAR
Information Coordination and Knowledge (CLICK) it is acknowledged that while "there has been increasing demand
for research utilizing all information generated from LIDAR remote sensing data and not just [the resulting] bare
earth [Digital Elevation Maps (DEM)]," "research on using the entire point cloud of this remote sensing data for
scientific applications has been slowed by a steep learning
curve on research and understanding involving utilizing the
entire point cloud." [USG07] Indeed, when examining previous approaches to the detection of urban change through
LIDAR data, we can see that many researchers choose to
reduce the complexity and detail of the point clouds into
raster based approximations for purposes of speed and ease
of pixel-based calculation of differences and filtering of output. By utilizing the unsimplified point clouds, we retain the
maximum possible data quality and accuracy in our resulting models and calculations, and all vertices in our models
represent actual measurements.
The goal of a change detection algorithm should not be to
c 2008 The Author(s)
Journal compilation c 2008 The Eurographics Association and Blackwell Publishing Ltd.
Published by Blackwell Publishing, 9600 Garsington Road, Oxford OX4 2DQ, UK and
350 Main Street, Malden, MA 02148, USA.

simply calculate the differences between two samplings by
subtracting one surface models from the other. Instead, we
argue, it is more appropriate to determine if measurements
from one set differ from the other due to actual changes
in the physical environment or are the result of a combination of various errors and uncertainties. As such, we start
by requiring data quality measures for our input data. These
values allow us to determine how much deviation between
points in the datasets could be due simply to collection errors and therefore would not represent a change in the actual
physical world being sampled. Individual points are evaluated to determine the likelihood they are legitimate changes,
then clusters of marked change points are aggregated into
change models of buildings, trees, etc.
Our system presents these change models alongside existing Geographic Information System (GIS) data, within an
interactive application that allows the chronological exploration of the changes to an urban environment. The system
has multiple coordinated views including a main 3D view,
a heat map view and a zoomed-in inspection view. For the
main 3D view a three-tiered level-of-detail system maintains

904

Butkiewicz, Chang, Wartell, Ribarsky / Visual Analysis of Urban Change

a scale-appropriate, legible visual representation across the
entire range of view scales, from individual changes such
as a buildings and trees, to groups and regions of changes.
Tools are provided to assist the visual analysis of changes
and their patterns through semantic categorization and filtering of the extracted change models. Heat map signatures capture the relationship between the footprint areas and
heights of change models. Semantic filters can be applied to
suppress or highlight typical classes of physical objects such
as trees, residential houses and road re-gradings.
2. Previous Approaches
A number of researchers have devised methods of detecting
changes in urban environments between LIDAR scans taken
at different times. Vu et al. [VMY04] focus on updating GIS
records and assessing damage from earthquakes; Murakami
et al. [MNH∗ 99] see application in the enforcement of real
estate taxes.
A common strategy these researchers take when attempting detection of changes between LIDAR scans is the transformation of the LIDAR point clouds into a grid using
nearest-neighbor interpolation. As described by Vu et al.
[VMY04] this tactic is chosen because it is effective at decreasing calculation times. A grid resolution is determined
based on the density of the LIDAR samples from the pair
of scans, and the values for each grid location are generally
determined by nearest-neighbor interpolation to preserve the
sharp height changes at building edges.
Murakami et al. subtract the grid values of one scan from
that of the other to produce a grid of values representing
height changes; image processing morphology operations
are used to filter out noise, and the cleaned-up difference
image is merged with an orthoimage for manual interpretation [MNH∗ 99]. Vu et al. [VMY04] determine the statistical
distribution of the intensity values of the difference image
and define those values beyond a certain number of standard deviations from the mean to be possible new construction, and likewise those below a certain number of standard
deviations from the mean to be possible demolition. Morphological opening and reconstruction is again used to filter
out undesirable results. Methods, such as these, that rely on
pixel-based calculations and filtering generally output their
results as raster image masks of the buildings determined to
be newly constructed or demolished/damaged.
Fitting LIDAR points to a regular grid fails to properly
accommodate datasets in which the sampling is uneven or
at multiple resolutions. An commonly encountered example
is data with overlapping swaths, which have at least twice
the resolution in the overlapping areas. The morphological
operations often used to filter the regularly gridded results
also introduces error in the shape/outline of the results. Although in fairness it should be noted that these shortcomings
are not likely to affect the detection of changes as large as
entire buildings.

Certainly the registration and integrated interactive display of terrain data acquired from various sources such as
LIDAR and photogrammetry is not new. Ronnholm et al.
[RHL∗ 07] give an overview of the latest work on methods for integrating laser scanning and providing more accurate modeling, interpretation and classification. However,
this body of work is not focused on interactive and automated change detection and most of the systems combine
static photogrammetry with LIDAR data, not interactively
rendered 3D models.
Vögtle et al. [VS04] develop building segmentation, identification and change detection software that works from
LIDAR data captured at two different dates. Their segmentation algorithm [TV04] utilizes further classification of
raw LIDAR data to differentiate buildings, vegetation and
terrain. Buildings are then classified as either non-altered,
added-on, reduced, new, or demolished. All operations are
on a raster grid. Some LIDAR return statistics are determined of known regions of vegetation, buildings and terrain and are then used in the classification algorithm. Terrasolid [Soi05] uses a variety of geometric heuristics to classify whether LIDAR samples are ground, building, vegetation, etc. But the geometry model isn’t based on a statistical
distribution per-se and it does not appear to be applied to
analyzing changes between different LIDAR timesteps.
Finally, our analysis tools combines two 3D views with
a heat map. Heap maps have been used successfully in visualizations tools in multiple application domains [AH04]
and are included with several commercial tools [Spo05]. In
genomics, heat maps are used for the visualization of massive gene arrays [SS02] and provide a compact overview of
the data as well as a drill-down capability for detailed information. Similar to our system, Chang et al. [CWK∗ 07]
combine an interactive heat map with a 3D visualization. To
our knowledge there has been no interactive visual analysis
of raw LIDAR point cloud data similar to what we present
in this paper.
3. Implementation
The motivation for this work is to visualize the changes
due to construction and development between yearly LIDAR
scans of Mecklenburg County, North Carolina, which contains the city of Charlotte and roughly 370,000 buildings.
The 2002 and 2003 annual scans cover the entire county
and register quite well with each other. However, the density of the sample points is low when compared to the capabilities of modern equipment, with roughly 3-4 meters between points. We found the low-resolution to be a limiting
factor when implementing and evaluating the performance
of the existing techniques previously mentioned. (Smaller
buildings did not have enough pixels to allow pixel-based
morphological opening and reconstruction to effectively filter noise without removing them.) The only data used in
this analysis is the raw LIDAR returns, in the form of x,y,z
c 2008 The Author(s)
Journal compilation c 2008 The Eurographics Association and Blackwell Publishing Ltd.

Butkiewicz, Chang, Wartell, Ribarsky / Visual Analysis of Urban Change

points, without any filtering to remove buildings or trees.
This method is attractive because it does not require the use
or availability of supplementary data such as classification
or intensity values for the LIDAR returns or aerial imagery.
3.1. Pre-Processing
Before processing, values for the horizontal and vertical accuracies of the LIDAR system used for collection are specified in terms of standard deviation. These values allow us to
account for the uncertainty of sample points taken by different hardware systems, as might be encountered when comparing datasets collected across a span of years. By knowing
these characteristics of each dataset, it can be determined
how much deviation between points could be due simply to
collection errors and therefore would not represent a change
in the actual physical world being sampled.
Irregular triangular meshes are generated from the LIDAR points using 2D Delaunay triangulation. The resulting meshes serve two purposes. During change detection,
points are projected into the mesh of the opposing scan
which allows us to quickly determine a collection of surrounding points for comparison purposes. The meshes, as
well as simplified (using QSlim [GH97]) versions of them,
are also stored for use as a reference surface models in the
user interface.
3.2. Change Detection
The goal of the change detection process is to identify and
mark all the points in the new scan that are most likely to be
changes in the actual physical world and not merely changes
in measurement (collection error).
Instead of merely calculating the difference of the surface
models, we iteratively evaluate each point in the new scan in
the following manner: First the point in the new scan is projected in 2D onto the triangulation of the old scan to determine which face it falls within. The distance along that face,
from the projected point to the nearest vertex, minus any positional errors, is calculated. This distance is then used to
calculate a height allowance based on the possible geologic
variation that could be present between the known sample
points. The height of the point above the interpolated face,
minus any vertical measurement errors, is then compared
against the height allowance at that location. If the point exceeds the bounds of what could be accounted for with known
errors and geologic variation, then it is considered to be a legitimate change point and is marked as such.
The error model integrated into our change detection algorithm [BCWR07] combines a stochastic component with
Koppe’s formula [Kop02]. While Koppe’s formula is only an
approximation to more detailed LIDAR error models such
as Baltsavias [Bal99], in principal our error aware approach
could be expanded to include more sophisticated error models. This, of course, could increase computation time for
c 2008 The Author(s)
Journal compilation c 2008 The Eurographics Association and Blackwell Publishing Ltd.

905

change detection, but some of this could be ameliorated
using precomputation and voxel based techniques to track
more arbitrary error volumes.
3.3. Filtering and Model Creation
The resulting set of marked points that have been classified
as significant changes will generally contain many "noisy"
objects caused by collection/data errors, low-resolution scan
returns sporadically striking tall thin objects such as broadcast antennas, street signs, telephone poles, etc.
As mentioned in the related works section, traditionally
changes detected by subtracting raster based digital surface
models are filtered by morphological opening and reconstruction to remove small noisy changes from the results.
These image processing techniques both reduce the accuracy (in shape for example) of the changes reported and are
not applicable to our non-gridded point cloud results. We integrate our noise filtering process within the process of creating models of the detected change points.
We begin by selecting a marked point and examine its
neighboring vertices in the triangulation to determine if any
have also been marked as changed. Here we can implement
the simplest form of noise reduction by disregarding any
marked vertices with no marked neighbors. Discarding these
change points is appropriate in this context, as we expect any
interesting change (e.g. buildings) to contain multiple points.
If the point has marked neighbors we can begin to build a
model for this change. We add the incident faces of the original point and recursively visit the marked neighbors, adding
their incident faces to the current change model until we can
no longer reach any unvisited vertices. We can then store the
extracted model and proceed to select the next marked point
that has yet to be visited and continue this process until no
unvisited marked points remain.
The output of this process is a collection of 3D models
representing the changes between the two scans. We can now
perform yet another type of filtering by computing the sum
of the 2D area of the triangles in each model. To conserve
storage, change models below a specified area threshold can
be discarded at this step. This method is suited for dismissing small legitimate changes, such as trucks on a highway or
individual trees, when the objective is to find more significant developments, such as new construction. Change models also retain a count of the marked change points they contain, allowing for filtering by that criteria as well, which is
advantageous in some cases (such as removing small trees).
4. Presentation and Interaction
Our interactive application allows for a rich visual exploration of the output data as opposed to more traditional output formats (images or digital elevation maps) for this type
of result. We provide the basic behaviors and capabilities

906

Butkiewicz, Chang, Wartell, Ribarsky / Visual Analysis of Urban Change

of common existing GIS / 3D terrain applications (such as
Google Earth or ArcGIS) as well as visualizations that allow the user to analyze the results in a number of different views. These include a main 3D view of the terrain with
highlighted changes, a sub-window showing a zoomed in,
inspection view of any user selected change objects, and a
semantic filtering sub-window utilizing a heat map. In the
heat map, the x and y axis correspond to the changed models’ footprint area and height, and the intensities of the cells
indicate the relative number of changed models matching the
cells’ area and height ranges. In addition to the semantic filtering, manual area and change-point-count thresholds allow
the user to filter out spurious changes.
Existing available GIS data, such as streets, highways,
known building footprints, political boundaries, etc. provide
ease of navigation, meta-data for change models (such as estimated street address) and show the potential for integration
into a larger GIS environment. We draw vector data directly
onto the reference surfaces and models using the technique
presented by Schneider and Klein [SK07].
Changes are presented to the user in the intuitive color
scheme of green representing new construction and growth,
and red representing demolitions, excavations, tree-clearing,
etc. See figure 1 and 2 for example views of interesting urban growth. The user can control the temporal aspect of the
visualization by switching between discrete years, where the
terrain reflects only that year’s scan with only the appropriate
new construction or demolition that has occurred displayed
overtop. A hybrid option is provided that presents data from
multiple years; new constructions are shown overtop of the
terrain from the previous scan in which they did not exist,
and demolitions are shown overtop terrain from the latter
scan in which the result can be seen. In this way, a change
is always presented against its counterpart for reference. See
Figure 3 for an example view of hybrid mode on an dense
urban area.
Due to the large amounts of data and the inherently
broad range of scales at which the dataset can be examined
(from individual houses at street level to county or statewide
views,) it is necessary to implement some form of level-ofdetail. It is here that we can exploit the level-of-detail concept to not only control the amount of data we render, but to
change what it is we are rendering in order to appropriately
abstract the data into a form that makes sense, and is useful
to the user at that zoom-level.

Figure 1: Changes to the university campus between 2002
and 2003. Green models show new construction while red
models show demolition/tree clearing. 2004 building footprints are in black. The selected building (orange) was under
construction, only filling half the future 2004 footprint.

Figure 2: Examining a new residential development under
construction. The selected (orange) volume shown is an area
where the earth has been regraded to allow the level construction of a new road. We can also see build up of earthen
walls (green, lower-right) on either side of the large interstate highway (red), as sonic barriers against traffic noise.

4.1. Levels of Detail/Abstraction

We counteract this problem with the introduction of a second level-of-detail/abstraction. As individual models recede
away from the camera, they gradually begin to glow and
are ultimately replaced by a semi-transparent ’splat’ which
is scaled to maintain near-constant screen-size regardless of
distance. These splats seamlessly fade in and take over while
the individual model detail level fades out.

When the user is zoomed in to a view that is significantly
close to the terrain, the system shows the unaltered change
models at full detail, as this allows for immediate inspection and interpretation of the change detection results. However, as the user zooms out, smaller change models quickly
become little more than a pixel or disappear altogether.

The splats do not simply allow us to see individual
changes/buildings beyond the point at which their models
would disappear. They also provide an amalgamating behavior in which collections of individual changes cooperate
to form larger, more significant glyphs in the visualization.
This is shown in Figure 4 where in a series of increasingly
c 2008 The Author(s)
Journal compilation c 2008 The Eurographics Association and Blackwell Publishing Ltd.

Butkiewicz, Chang, Wartell, Ribarsky / Visual Analysis of Urban Change

907

Figure 4: Shown here is a new residential development at increasingly further camera distances. As the camera moves further
away, individual models gradually begin to glow to emphasize their presence, and are ultimately replaced by semi-transparent
’splats’ which maintain near-constant screen-size regardless of distance. Notice that at the closest view (left) the building models
are individually presented, and once the camera has moved significantly further away, the entire development is represented as
a single entity (right); a seamless transition (middle two images) is presented at distances in between to avoid popping.

ously legible images of the concentration of changes present.
The shading of these regions can be determined by several
criteria, the simplest being the comparative ratios of local to
global change footprint areas, number of change points, or
number of individual changes.
4.2. Heat Map and Semantic Filtering

Figure 3: A view of the downtown area in hybrid mode.
Change models of new construction are rendered in green
and change models of buildings that have been demolished
are rendered in red.

distant views, a new residential housing development seamlessly transforms from a few rows of individual buildings
into a single ’blob’ representing the entire development as a
whole. This blob is visible long after the individual models
would have been too small to render as single pixels, aggregating and preserving the development.
The third and final level of abstraction is displayed when
the user has zoomed out to a distance where depicting individual changes and even amalgamated groups in splat form
no longer makes sense due to issues of overlap and extreme
clutter. At this level, the user is presented instead with urban
legibility regions. These regions are based on the level-ofdetail clusters generated by Chang et al. [CBZ∗ 08] which
delineate sections of the city based on aspects of urban legibility, such as paths, districts, nodes, and other perceptual
qualities. Originating from a LOD solution to city-viewing,
these clusters are naturally useful to display city-wide data
in clustered form at appropriate detail for a wide range of
distances, as Chang et al. demonstrate with census data.
[CWK∗ 07] This ability is clearly shown in Figure 7 where
a significantly wide range of zoom levels result in continuc 2008 The Author(s)
Journal compilation c 2008 The Eurographics Association and Blackwell Publishing Ltd.

To allow a higher-level exploration of the results of the
change detection we provide a semantic filtering interface
utilizing a heat map. The heat map presents the distribution of the physical dimensions of the change models. The
X-axis corresponds to 2D projected area (footprint size),
while the Y-axis corresponds to the maximum height of the
change model above the surrounding terrain. The axes are
divided into bins, forming a matrix of cells. Change models are enumerated into these cells, and the intensity of each
cell indicates the relative number of change models meeting that cell’s size ranges. A logarithmic scale is the default
mapping for intensity, as it allows better observation of the
less populous cells away from the main concentration areas,
however linear and exponential scales are also provided in
case changes follow uncommon distributions, or inspection
deeper into the main concentration is desired.
Different types of physical objects often have a particular signature in the heat map. For instance, individual trees
cut down will produce change models that are relatively tall
with very small footprint areas, while grading of dirt at a
construction site will tend to produce change models that
are relatively flat (low heights), but cover very large areas.
We can define these characteristics with sets of simple conditionals and bounding functions (relating growth in height
to growth in area or vice versa) in order to delineate continuous regions in the heat map. These regions can then be
associated with a particular group of physical changes.
We provide predefined functions that create regions in the
heat map for trees, residential structures, commercial structures, and grading of earth. When the user selects one of
these filter categories, the associated cells in the heat map
are stippled with a unique color to indicate they are actively
filtering the changes presented in the other 3D views. See

908

Butkiewicz, Chang, Wartell, Ribarsky / Visual Analysis of Urban Change

to the more established urban and suburban areas closer to
the city center. We see the wider distribution of changes, especially in the height dimension, for the city center region. A
possible explanation for this is that in the more established
regions, structures tend to be larger and taller, and vegetation is more closely controlled. This tool is generally more
suited for analysis of urban growth in a historical and spatial
comparative sense than for future planning purposes.
5. Evaluation and Applications
We presented our system in October 2007 at the annual
Charlotte Metropolitan GIS User Group Meeting, which is
a one to two day conference for professional GIS users and
developers in commercial, academic, and government sectors. Although we were unable to conduct one-on-one taskbased quantitatively analysis using our system, we were able
to obtain invaluable feedback from the 40 or so attendees regarding the strengths and weaknesses of our system.
Figure 5: Shown here are the regions selected in the heat
map generated by various semantic filters. The "trees" filter
produces the green region, "residential" - orange, "commercial" - yellow, "grading" - brown, and and a user defined
region in black. Notice that the majority of detected changes
fall within the "trees" filter, and that man made changes tend
to be on the outskirts of the distribution; a logarithmic intensity function is used by default to allow these areas to be
better discerned within the heat map.

Figure 5 for an illustration of the shapes these regions take
on in the heat map.
The user can also define their own custom filters by selecting regions of cells in the heat map. This is advantageous
when looking for changes that are not as simply defined as
the provided categories, or to modify existing filters to better
suit a particular dataset. Filters are stackable to permit more
complex filtering.
An example of the usefulness of the custom semantic filtering is shown in Figure 8. Here the user opts to view only
destruction changes, and creates a custom filter on the heat
map to show only changes above a certain area and within a
certain height range. The resulting 3D view allows the user
to easily extract the red change models showing both the deforestation (left and center) due to clear cutting for construction, and the volumes of rock removed at the granite quarry
(upper right).
Because the heat map provides a visual representation of
the statistical distribution of the changes, it can also be used
for a more general understanding of the types of changes
across the entire dataset or in a sub-region. As shown in Figure 6 we can compare the heat map for the edge region of the
city, which is under transformation from rural to suburban,

Most participants indicated that our system added tremendous benefits to understanding the growth and decline of different regions of the city, which is helpful to private developers looking for areas for future investment. City planners
mentioned that our system could help them identify suspicious constructions or destructions for real estate tax enforcement purposes. On the use of the heat map for filtering and analysis, all participants found it useful for looking
for large areas of deforestation, which is important for both
environmental and commercial reasons.
On the other hand, some participants pointed out that our
system doesn’t take advantage of auxiliary LIDAR returns.
Specifically, LIDAR returns often contain not just 3D point
positions, but additional information such as intensities and
color channels that can help classify the returns based on the
reflectance characteristics of their surfaces (concrete, water,
vegetation, etc). By including this extra dimension of data,
our system could better filter based on object types and decrease the degree of ambiguity in understanding the changes
in models.
6. Discussion
While realistic rendering of the terrain is not of concern
in this application, the method used for storage, retrieval,
and display of the reference surface models is still quite
primitive. This manifests itself in the seam artifacts present
(roughly every square mile) between each reference surface
model, a result of triangulations of points on each side of an
arbitrary division line, with no triangles formed across said
line. Clearly there is the need for the integration of a more
advanced terrain engine to elegantly manage the storage and
display of the reference models as a single entity. Hopefully
this issue will be addressed by integration of the successful
aspects of the visualization into an existing 3D terrain or GIS
package.
c 2008 The Author(s)
Journal compilation c 2008 The Eurographics Association and Blackwell Publishing Ltd.

Butkiewicz, Chang, Wartell, Ribarsky / Visual Analysis of Urban Change

909

Figure 6: A is the distribution of changes for a region on the edge of the city, under transition from rural to suburban. B is
the distribution of changes for a region in the center of the city, which is an established urban and suburban area. C is the
difference of the two, showing the wider distribution of changes, especially in the height dimension, in the center city region.

Figure 7: Shown here are the urban legibility regions at increasingly distant camera locations.

There is much potential for the addition of algorithms
such as automated target classification and pattern matching to further the abilities of the semantic filtering functions.
This would be especially helpful in real GIS systems where
the end users may know exactly what changes they want to
ignore or expose, but are incapable of defining the specific
parameters themselves.

7. Conclusions
In line with the mission statement of the USGS CLICK, we
have developed a system that compares LIDAR data from
different times and visualizes the differences in an intuitive
and legible manner. This system, combined with building
footprints from tax records and road information, provides
a powerful tool for visualizing and identifying constructions
and demolitions of buildings, grading of terrain, as well as
increases and decreases in forestation.
c 2008 The Author(s)
Journal compilation c 2008 The Eurographics Association and Blackwell Publishing Ltd.

Instead of reducing point clouds to regularly spaced
rasters, our system maintains accuracy by utilizing LIDAR
point collections of any resolution and consistency. More
importantly, our emphasis on preserving the accuracy in the
LIDAR data is carried throughout the preprocessing and
analysis processes, with all vertices of the final change models representing actual measurements.
The presentation of the resulting LIDAR data uses a threetiered LOD technique that is view dependent. This ensures
that constructions or demolitions of buildings are clearly visible from all view distances and angles and allows the user
to see overviews as well as detailed information at all times.
Lastly, by providing a heat map visualization of the distribution of changes and enabling semantic filtering, we allow
the user to better explore the 3D results, and understand the
patterns contained within, in ways beyond the capabilities of
traditional 2D image results.

910

Butkiewicz, Chang, Wartell, Ribarsky / Visual Analysis of Urban Change

Figure 8: By opting to view only destruction changes, and creating a custom filter on the heat map to show only changes above
a certain area and height range, we can easily see in the 3D view, the red change models showing both the deforestation (left
and center) due to clear cutting for construction, and the volumes of rock removed at a granite quarry (upper right).

References
[AH04] A BELLO J., H AM F. V.: Matrix zoom: A visual
interface to semi-external graphs. Proceedings of IEEE
InfoVis 00 (2004), 183–190.
[Bal99] BALTSAVIAS E.: Airborne laser scanning: basic
relations and formulas. ISPRS Journal of Photogrammetry and Remote Sensing 54 (1999), 199–214.
[BCWR07] B UTKIEWICZ T., C HANG R., WARTELL Z.,
R IBARSKY W.: Analyzing sampled terrain volumetrically
with regard to error and geologic variation. In Visualization and Data Analysis 2007 (2007), vol. 6495, SPIE,
p. 64950.
[CBZ∗ 08] C HANG R., B UTKIEWICZ T., Z IEMKIEWICZ
C., WARTELL Z., P OLLARD N., R IBARSKY W.: Legible
simplification of textured urban models. IEEE Computer
Graphics and Applications (To Appear 2008).
[CWK∗ 07] C HANG R., W ESSEL G., KOSARA R.,
S AUDA E., R IBARSKY W.: Legible cities: Focusdependent multi-resolution visualization of urban relationships. In IEEE Transactions on Visualization and
Computer Graphics (TVCG) InfoVis (2007), pp. 1169–
75.
[GH97] G ARLAND M., H ECKBERT P. S.: Surface simplification using quadric error metrics. In SIGGRAPH
’97: Proceedings of the 24th annual conference on Computer graphics and interactive techniques (1997), ACM
Press/Addison-Wesley Publishing Co., pp. 209–216.
Über die zweeckentsprechende
[Kop02] KOPPÉ C.:
Genauigkeit det Höhendarstellung in topographischer
Plänen und Karten für allgemeine technische Vorarbeiten.
Z. VermessWes, 1902.
H.,
NAKAGAWA
K.,
[MNH∗ 99] M URAKAMI
H ASEGAWA H., S HIBATA T., I WANAMI E.: Change

detection of buildings using an airborne laser scanner.
Journal of Photogrammetry and Remote Sensing 54 (July
1999), 148–152.
[RHL∗ 07] RÖNNHOLM P., H ONKAVAARA E., L ITKEY
P., H YYPPÄ H., H YYPPÄ J.: Integration of laser scanning and photogrammetry. IAPRS Volume XXXVI, Part 3
/ W52 (2007).
[SK07] S CHNEIDER M., K LEIN R.: Efficient and accurate rendering of vector data on virtual landscapes. Journal of WSCG 15, 1-3 (January 2007).
Terrascan user’s guide.
[Soi05] S OININEN A.:
http://www.terrasolid.fi/en/users_guide/, 2005.
[Spo05] S POTFIRE: Decision site for functional genomics.
http://www.spotfire.com/, 2005.
[SS02] S EO J., S HNEIDERMAN B.: Interactively exploring hierarchical clustering results. Computer 35, 7 (Jul
2002), 80–86.
[TV04] T ÓVÁRI D., VÖGTLE T.: Classification methods
for 3d objects in laserscanning data. Geo-Imagery Bridging Continents 20th ISPRS Congress (2004), 12–23.
[USG07] USGS: The United States Geological Survey
Center for LIDAR Information Coordination and Knowledge. http://lidar.cr.usgs.gov/ (2007).
[VMY04] V U T. T., M ATSUOKA M., YAMAZAKI F.:
Lidar-based change detection of buildings in dense urban
areas. In Geoscience and Remote Sensing Symposium,
2004. IGARSS ’04. Proceedings. 2004 IEEE International
(Sept 2004), vol. 5, pp. 3413–3416.
[VS04] VÖGTLE T., S TEINLE E.: Detection and recognition of changes in building geometry derived from multitemporal laserscanning data. The International Archives
of the Photogrammetry, Remote Sensing and Spatial Information Sciences 34 (2004), 428.
c 2008 The Author(s)
Journal compilation c 2008 The Eurographics Association and Blackwell Publishing Ltd.

