Volume 27 (2008), Number 2

EUROGRAPHICS 2008 / G. Drettakis and R. Scopigno
(Guest Editors)

Characterization for High Dynamic Range Imaging
Min H. Kim† and Jan Kautz‡
Department of Computer Science, University College London

Before HDR characterization

After HDR characterization

Difference map (mid-gray = mean) amplified by 10

Abstract
In this paper we present a new practical camera characterization technique to improve color accuracy in high dynamic range (HDR) imaging. Camera characterization refers to the process of mapping device-dependent signals,
such as digital camera RAW images, into a well-defined color space. This is a well-understood process for low
dynamic range (LDR) imaging and is part of most digital cameras — usually mapping from the raw camera signal
to the sRGB or Adobe RGB color space. This paper presents an efficient and accurate characterization method for
high dynamic range imaging that extends previous methods originally designed for LDR imaging. We demonstrate
that our characterization method is very accurate even in unknown illumination conditions, effectively turning a
digital camera into a measurement device that measures physically accurate radiance values — both in terms of
luminance and color — rivaling more expensive measurement instruments.
Categories and Subject Descriptors (according to ACM CCS): I.3.3 [Computer Graphics]: Picture/Image Generation
I.4.1 [Image Processing and Computer Vision]: Digitization and Image Capture

1. Introduction
Recent advances in high dynamic range (HDR) imaging allow us to easily obtain radiance maps with off-the-shelf digital cameras by combining multiple exposures into a single
HDR image [MP95, DM97, MN99, RBS99]. These acquired
radiance maps are commonly used as environment maps for
lighting simulations or for computational photography applications. However, the radiometric accuracy of the acquired
HDR radiance maps — both in terms of luminance and color
— has rarely been discussed or evaluated because traditional
characterization methods for low dynamic range (LDR)
imaging [MVPC00,PAJ01,MJ02,MVPC03,ISO06,NFG07]
were not designed to characterize HDR radiance maps. We
propose a new camera characterization method that works
† e-mail: m.kim@cs.ucl.ac.uk
‡ e-mail: j.kautz@cs.ucl.ac.uk
c 2008 The Author(s)
Journal compilation c 2008 The Eurographics Association and Blackwell Publishing Ltd.
Published by Blackwell Publishing, 9600 Garsington Road, Oxford OX4 2DQ, UK and
350 Main Street, Malden, MA 02148, USA.

well for HDR imaging, is more accurate than many of the
LDR methods and is very efficient in terms of acquisition
time and cost. Our method is based on the insight that common reflective targets have two main drawbacks: 1) they
only offer a low dynamic range, which makes them not a
good choice for HDR imaging and 2) characterization based
on reflective targets requires both the reflectance of the target
and the spectrum of the illuminant to be known. We therefore propose to use a novel back-lit transparent target specifically designed for HDR imaging, offering a higher dynamic
range and wider color gamut. Our method only requires the
emitted radiance to be known, which can be easily measured
once using a spectroradiometer. This enables us to accurately characterize digital cameras used for HDR imaging.
We show the effectiveness of the new method by characterizing three different digital cameras. The achieved accuracy of
the cameras is similar to the accuracy of a spectroradiometer.
As we will demonstrate, radiance maps acquired by different

692

Min H. Kim & Jan Kautz / Characterization for HDR Imaging

cameras are virtually the same when using our characterization method.
2. Background and Related Work
In this section we explain the necessary background and
briefly discuss previous techniques.
2.1. Characterization of Digital Cameras
The sensing area of digital cameras consists of a charge
coupled device (CCD) where incident photons cause charge
to accumulate at each pixel on the sensor. This charge is
transferred into an output digital signal via an analogueto-digital converter [Yam06]. The amount of digitized electronic charge is linear to irradiance on the sensing area —
excluding the noise floor (fixed-pattern noise, sensor dark
current, etc. [Hol98, Jan01]) and blooming (overflowing) of
the sensor response. Typically, a non-linear function is applied to improve the dynamic range of the camera and at the
same time this also takes care of gamma-correction for display.
The sensor is usually mosaiced with an RGB color filter set, which simulates the trichromatic responses (colormatching function) of the human visual system (HVS).
Camera characterization is defined as the transform of
device-dependent signals into device-independent coordinates [Joh02] like CIE XYZ tristimulus values. Ideally, the
same mapping works for all types of illuminations.
The trichromatic response value, R, G, and B, of a specific
pixel on the sensor is given as the integral of the product of
the spectral power distribution of the light source L(λ), the
reflectance (or transmittance) of the imaged object ρ(λ), and
the spectral responsivities of the color filters Dr/g/b (λ) —
assuming that incident light is reflected from object surfaces:
R = L(λ)ρ(λ)Dr (λ)dλ
G = L(λ)ρ(λ)Dg (λ)dλ
B = L(λ)ρ(λ)Db (λ)dλ

(1)

The integration is taken over a suitable wavelength range in
the visible part of the spectrum, for instance, from 380nm to
780nm [ISO06]. The calculation of these response values is
similar to the computation of device-independent tristimulus
values, such CIE XYZ:
¯
X = L(λ)ρ(λ)x(λ)dλ
¯
Y = L(λ)ρ(λ)y(λ)dλ
Z = L(λ)ρ(λ)¯z(λ)dλ

(2)

where x(λ),
¯
y(λ)
¯
and z¯(λ) are the CIE color matching functions (CMF) [CIE86]. The only difference between Equation 1 and 2 is the use of different weighting functions Dr/g/b
and x,
¯ y,
¯ z¯.
Various camera characterization techniques have been
proposed to find a mapping between these color spaces. They
can be categorized into two main classes: models based on

targets with known reflectances [PAJ01,MJ02,Joh02,ISO06]
and models based on the measurement of spectral responsivity using a monochromatic light source [MVPC00, MJ02,
MVPC03, ISO06, NFG07].
The reflectance-based techniques use a color target, such
as the GretagMacbeth ColorChecker, where the tristimulus
values of each color patch are measured first or already
known (e.g., in CIE XYZ). A picture of the color target is
then taken and a direct mapping between the image’s RGBvalues and the measured XYZ values is derived via linear regression (or polynomial regression in case of non-linearized
images). While these techniques are very simple, they are
only valid for the current illumination condition [ISO06],
as L(λ)s in Equation 1 and 2 are not the same with these
methods (L(λ) in Equation 1 is the spectrum of the light
source at scene; L(λ) in Equation 2 is usually CIE D50 illuminant in colorimetry and ICC profiles). As soon as the
lighting changes, a new mapping is required. Therefore this
characterization method is very limited. Nonetheless it is
universally used for ICC input profiles [ICC04] and is part
of the ISO standard [ISO06]. Reflectance-based techniques
have also been extended to HDR imaging by assembling
characterized LDR images into an HDR image by using the
ICC method [GHS01]. However, this extension shares the
same assumption of fixed geometric and spectral illumination characteristics, and also does not allow to characterize
absolute luminance.
The monochromator-based techniques use a white integrating sphere of known reflectance and a monochromatic
light source, whose wavelength can be adjusted. By illuminating the integrating sphere with every single wavelength
within the visible spectrum, the spectral responsivity Dr/g/b
can be measured directly, which then again allows one to
derive a simple linear mapping to CIE XYZ. In this case,
L(λ) is the same for Equation 1 and 2. While this method
is much more universal than reflectance-based techniques,
monochromator-based techniques are very time-consuming,
as each wavelength must be measured individually and a
picture needs to be taken for every wavelength. These techniques can in theory be used for camera characterization in
HDR imaging. However, only color could be characterized
and not luminance, as the employed illumination and target
only offers a low dynamic range.
We propose a new technique, which offers the simplicity
of reflectance-based techniques with the accuracy and the
universal applicability of monochromator-based techniques.
Furthermore, it is well-suited for HDR imaging, and can
characterize both color and luminance. In fact, our experiments show that a digital camera, characterized with our
method, can perform almost identical measurement of the
color and luminance information to a spectroradiometer that
we tested.
c 2008 The Author(s)
Journal compilation c 2008 The Eurographics Association and Blackwell Publishing Ltd.

Min H. Kim & Jan Kautz / Characterization for HDR Imaging

2.2. Acquisition of Radiance Maps
In case of most DSLR cameras, the linear digital signals can
actually be output before non-linear processing as a RAW
image. Within the possible range of camera signals, these
RAW images correspond to the amount of charge of all the
incident photons on the sensor, effectively measuring scene
radiance at each pixel.
Figure 1 demonstrates this; the RAW CCD signals and
the HDR image are indeed proportional to measured luminance. Consequently, a relative HDR radiance map can be
computed by accumulating exposure-scaled linear responses
when using linear RAW images. However, if these are not
available, the non-linear response curve, which comes from
internal camera post-processing such as gamma correction,
must be calibrated in order to convert back to linear signals,
for which various methods exist [MP95, DM97, MN99]. In
this work, we use linear signals avoiding curve fitting and its
potential inaccuracies. The acquired luminance levels that
are stored in the radiance map are only proportional to physical luminance. Absolute luminance levels can be acquired
by re-scaling the luminance values according to a luminance
meter [KGS05, IG04]. In contrast, our method calibrates luminance and color at the same time.

693

well as color appearance modeling is beyond the scope of
this paper. However, we use tone-mapping to display our
characterized images [RSSF02].
3. Camera Characterization for HDR imaging
We will now detail our technique for camera characterization.
3.1. HDR Image Acquisition
Our characterization method can be applied to devices that
directly record HDR images or to standard digital cameras
that require multi-exposure sequences to be fused into one
HDR image. Our HDR imaging setup is based on multiexposure sequences. We fuse 16-bit RAW camera images,
which directly record the linear camera response without
white-balancing, gamma-correction, or any other processing. HDR images are reconstructed from 18 images taken
with varying exposure setting of shutter speed in one f/stop
(1/4000-30s) but fixed aperture size (f/11) and film speed
(ISO 200), using only the HDR assembly part of Debevec
and Malik’s method [DM97]. The result of this procedure is
a single linear HDR image, which is uncalibrated in terms of
absolute luminance and color.

2.3. Tone Reproduction Operators

3.2. HDR Characterization

The dynamic range of HDR radiance maps is usually much
higher than that of typical displays and cannot be displayed
directly. Since simple linear scaling and gamma correction
does not achieve satisfactory results when displaying HDR
images, tone-mapping algorithms have been introduced that
compress the dynamic range in a more suitable manner
among a global, local, or perceptual fashion. Since we only
deal with the input side of HDR imaging, tone-mapping as

As mentioned earlier, previous characterization methods were either limited to known illumination conditions [PAJ01, MJ02, Joh02, ISO06] or required expensive
equipment and prohibitive measurement times [MVPC00,
MJ02,MVPC03,ISO06,NFG07]. Furthermore, these characterization methods were really geared towards low dynamic
range imaging.

Normalized Output Response

Canon 350D camera response
250
200
150
100

RAW Camera Response
Non−linear Camera Response
Ideally Linear Response
HDR Radiance Map

50
0

0

500

1000

1500

2000

Our technique is based on two insights. First, the product
of the spectral power distribution of the light source L(λ)
and the reflectance of the calibration target ρ(λ) can be measured in a single step using a spectroradiometer, allowing
camera characterization rather efficient both in terms of cost
and measurement time. Second, a novel back-lit transparent target specifically optimized for HDR imaging has larger
gamut and higher dynamic range than ordinary reflective
targets, making the characterization perform rather accurate
measurement of luminance and color and is applicable even
in unknown illumination conditions.

2500

Input luminance [cd/sqm]

Figure 1: Characteristic curves of: ordinary non-linear response of Canon 350D, RAW CCD response from the camera, and HDR radiance map on green channel. The Y axis,
which signifies the acquired response, is normalized into
[0,255]. The X axis represents luminance measured by a
spectroradiometer. The square points on the diagonal show
the ideally linear response. As the plot shows, the RAW response and the computed HDR radiance map are proportional to incident light.
c 2008 The Author(s)
Journal compilation c 2008 The Eurographics Association and Blackwell Publishing Ltd.

3.2.1. Setup
We created our own transparent targets by photographically
enlarging the IT8.7/1 [ANS99] color chart onto Kodak Ektachrome professional film (8-by-10 inch) such that each
patch matches the sensing area of the employed spectroradiometer (approx. 8mm in diameter). Two enlarged identical
targets, under one of which we placed three sheets of neutral
density (2×) filters, are placed on a uniform light emitting
table in a darkroom to produce a training set with plenty of
colors (576 patches) and a dynamic range of 4.53 orders of

694

Min H. Kim & Jan Kautz / Characterization for HDR Imaging

magnitude. Using a transparent target not only offers a high
dynamic range, but also provides a very wide color gamut,
see Figure 2.
Two GretagMacbeth ColorChecker targets and two 800W
halogen light sources are used to produce a test set with
48 color patches, producing a different illumination condition (two halogen lights illuminating one target). The
emitted/reflected radiance of each patch in these two experimental sets were measured with the spectroradiometer
(Jeti Specbos 1200) of which luminance accuracy is ±0.05
at 1000cd/m2 and chromaticity repeatability is ±0.0005
(x,y) [MBG04].
Finally, we took HDR images of these two datasets using
three different digital cameras for characterization (Canon
350D, Nikon D100, and Nikon D40), see Figure 3.
3.2.2. Characterization
In traditional colorimetry L(λ) refers to relative spectral
power distributions, which are always normalized (into 100
at 560nm [Hun98]). This discards the intensity scale of the
illumination, which is why previous characterization models have difficulties calibrating absolute scales. Furthermore,
when tristimulus reflectance values are measured by a spectrophotometer (e.g., the GretagMacbeth Spectrolino), a calibrated tungsten light is used, which is then converted into
a CIE D50 illuminant LD50 (λ) (Eq. 2). However, the scene
illuminant L(λ) (Eq. 1) is different from that, effectively
building in this mismatch into the characterization, which
poses problems when different scene illumination is used
after characterization. Hence, our technique uses identical
L(λ) and absolute spectral power distributions to solve both
scale and illumination problems.
Using the above setup, we know the emitted radiance
values for each patch of our transparent target (measured
using the spectroradiometer), corresponding to Equation 2.
Furthermore, the linear camera response for each patch is

known from the HDR image (corresponding to Equation 1).
Since the illumination is identical for both, we can now find
a (least-squares) linear transform between the RGB camera
response and the physical CIE XYZ radiance values that is
applicable to unknown lighting (the L(λ) cancels out):
X = (At A)−1 At M,

where X is a 3 × 3 transform for characterization, A is a
matrix containing the linear RGB camera response for each
patch, and M is a matrix containing the measured radiometric CIE XYZ values for each patch.
This transform X can now be used to map any (high dynamic range) RGB value into a physically meaningful CIE
XYZ value, independent of the illumination. In our particular setup we find three transforms, one for each digital camera.
3.2.3. Display of Radiance Maps
Our mapping transforms HDR input images into physically
meaningful CIE XYZ values. However, in case an image is
not intended for measurement purposes but for display, we
need to take the human visual system into account, which
adapts to a given illumination condition. This is a classical issue and is traditionally called white balancing. There
are a variety of techniques available to simulate this adaption [HHF99, FB93, FHH97]. For our examples, we use the
Bradford chromatic adaptation model used in CIECAM97s;
however, any other method can be used as well.
4. Results
We have tested our HDR characterization methods with
three different cameras (Nikon D100, Canon 350D, and
Test Set
(Reflective 48patches)

Training Set
(Transparent 576patches)

Halogen-lights illuminated

Light-emitting table (D55)

Color
Charts
(Bright)

0.7

(3)

0.6

Color
Charts
(Bright)

Color
Charts
(Dark)

Color
Charts
(Dark)

radiance

0.5

CIE v'

LDR

HDR

0.4

Spectroradiometer

0.3

DSLR
Camera

MultipleExposures
(RAW response)

HDR
radiance map

0.2

0.1

0
0

Radiance
Measurements

Reflective LDR Target
Transparent HDR Target
Spectral Locus
0.1

0.2

0.3

0.4

0.5

0.6

0.7

CIE u'

Figure 2: Comparison of measured gamut boundaries. The
transparent HDR target provides a considerably larger color
gamut than the ordinary reflective target (GretagMacbeth
ColorChecker). Each side of our target (as seen on the right)
is an enlarged IT8.7/1 [ANS99] color chart on Kodak Ektachrome professional film (8-by-10 inch).

Characterization

HDR camera
response

Figure 3: Setup of characterization. A back-lit transparent color target is captured by a digital camera and all
its color patches are measured using a spectroradiometer,
which forms the training set that is used to compute the characterization model. A second test set is acquired for validation purposes. It consists of two GretagMacbeth color charts
illuminated by halogen light.

c 2008 The Author(s)
Journal compilation c 2008 The Eurographics Association and Blackwell Publishing Ltd.

695

Min H. Kim & Jan Kautz / Characterization for HDR Imaging

X
Y
Z

X
Y
Z

Canon 350D / 18-55mm lens
R
G
B
6.8364
1.1685
0.3256
3.0657
4.1205
-1.2861
0.3650
-0.6863
6.3905
Nikon D100 / 35mm lens
R
G
B
10.1001
1.4246
0.5921
4.6565
5.2054
-1.5151
0.4985
-0.7648 10.1364

Nikon D40 / 18-55mm lens
R
G
B
12.9566
1.6246
0.8274
6.0406
6.4671
-1.5985
0.5537
-0.9170 11.5996
Averaged
R
G
B
9.9644
1.4059
0.5817
4.5876
5.2643
-1.4666
0.4724
-0.7894
9.3755

Table 1: Transformation matrices from camera HDR into CIE
XYZ. The transforms were computed from HDR radiance maps of
our transparent target and the corresponding radiance measurements. Averaged refers to the mean matrix of the three different cameras.

4.1. Color Accuracy
We analyze the radiometric accuracy of each of the three
characterization models (one for each camera) by comparing
their results against physical measurements from the spectroradiometer. For each comparison, we compute three different error measures in order to judge the accuracy. First, we
compute CIEDE2000 [CIE01]-values, which are commonly
(a)

(b)

(c)

Training Set
Canon 350D
Nikon D100
Nikon D40

∆E00
1.121
1.311
1.486

Y
0.103
0.096
0.066

u′v′
0.013
0.022
0.026

XYZ
0.116
0.117
0.083

Test Set
Canon 350D
Nikon D100
Nikon D100 (IR filter)
Nikon D40

∆E00
0.480
3.816
1.615
3.104

Y
0.094
1.457
1.193
1.159

u′v′
0.016
0.035
0.048
0.038

XYZ
0.114
1.660
1.439
1.192

Test Set – Other Methods
Canon 350D (LDR Char.)
Canon 350D (HDR ICC)

∆E00
7.028
4.130

Y
0.225
1.085

u′v′
0.039
0.073

XYZ
0.228
0.919

Table 2: Color accuracy of our method: (a) the Training Set
presents the accuracy of our characterization models using the
training data (576 patches under 5571K illumination). (b) the Test
Set shows the accuracy of the same characterization models using a different test data-set (reflective target under 2946K illumination). Accuracy of other methods (c): LDR characterization (only
one target is used [ISO06]) and HDR assembly using ICC profiles
[GHS01]. ∆E00 denotes the median CIEDE2000 over all patches
between measurement and prediction; Y shows the median relative
differences of luminance levels; u′v′ indicates the median relative
differences between measurement and prediction of all patches in
CIE u′v′. XYZ shows the median relative differences of CIE XYZ
channels between measurement and prediction. IR filter means using the infrared blocking filter.
c 2008 The Author(s)
Journal compilation c 2008 The Eurographics Association and Blackwell Publishing Ltd.

We first perform these comparisons within the training set
(the transparent target, see Figure 2), i.e., we validate that
a linear characterization model is sufficient. To this end, we
take the original HDR images (one for each camera), convert
them to CIE XYZ with the characterization matrices from
Table 1 and compute the CIEDE2000 values, Yu′ v′ median
differences, and CIE XYZ median differences for each color
patch in the transparent target. As can be seen in Table 2(a),
the errors are quite low.
Furthermore, we validate how well the characterization
models work with test scenes that were taken under different illumination. Our first test scene consists of two ColMeasurement Test under Tungsten Light Source
10000

Luminance [cd/sqm]

Table 1 presents the matrices of the linear transform from
camera HDR into CIE XYZ coordinates, which were computed as outlined in Section 3.2.2. Note that these matrices
not only transform colorimetric information but also luminances, because we take absolute scales into account such
that the characterized coordinates are identical to the physical radiance measurement. However, the scale of the matrices may be different for other HDR assembly algorithms.

used to compare colors in a perceptual fashion. It is based on
the CIE LAB color space [CIE86], and as such is really only
valid for low dynamic range values. Nonetheless, we include
it for completeness. Second, we compute CIE Yu′ v′ coordinates [CIE86] for the characterized HDR image as well as
the measurements from the spectroradiometer, and compute
(relative) median differences between them. And third, we
compute the (relative) median differences between the characterized CIE XYZ values and the measured CIE XYZ values.

Spectroradiometer
Camera (Canon 350D)
Camera (Nikon D100)
Camera (Nikon D40)

8000
6000
4000
2000
0

F4 E4A3D2F3B2A1D1D4C3E3C1E1B3C2F1 F2C4E2B1A2D3B4A4
Index of ColorChecker Patches (sorted by luminance)
Measurement Test under Tungsten Light Source

0.6
Canon 350D

0.55
CIE v'

Nikon D40). For this we have computed three characterization models, one for each camera, as described in the previous section (using our transparent color target, see Figure 2).

0.5
0.45
Color Difference
Spectroradiometer
Camera (Canon 350D)
Camera (Nikon D100)
Camera (Nikon D40)

0.4
0.35
0.15

0.2

0.25 0.3
CIE u'

0.35

0.4

0.45

Nikon D100

Nikon D40

Figure 4: Test scene consisting of GretagMacbeth charts under halogen light, acquired by three different digital cameras and then characterized using our method. The top
plot presents luminance differences between radiometric
measurement and camera measurements. In particular the
Canon 350D shows very similar performance to the spectroradiometer. Tone-mapped versions of the three characterized
images are shown on the right; differences between them
are difficult to spot. For a quantitative comparison, see Table 2(b). The bottom left plot shows chromaticity differences
of the test patches in a CIE uniform chromaticity diagram.
Differences are minor, only one color shows a big difference,
which is located outside the camera’s R/G/B filter gamut.

696

Min H. Kim & Jan Kautz / Characterization for HDR Imaging

Direct CCD Response (RAW)

Absolute CIE XYZ

Characterization Result

Figure 5: Each step of our characterization method. Direct CCD response RAW is the acquired RAW image without any white
balancing. The greenish appearance is due to the infrared filter in front of the CCD, which will be taken care of by the derived
mapping. Absolute CIE XYZ is the characterized CIE XYZ image (which we render using a 1:1 mapping to RGB for illustration
purposes). Characterization Result is the final image by mapping from characterized and device-independent CIE XYZ to the
display sRGB color space.

Canon 350D

Nikon D100

Nikon D40

Figure 6: An HDR desk scene is characterized with our method for three different digital cameras. Even though they are taken
in slightly different perspective and angles, there are only very minor color differences between the images.
orChecker charts illuminated under halogen light, see Figure 4. As can be seen again in Table 2(b), the errors are
quite low, especially for the Canon 350D. We compare this
result with the previous reflectance-based LDR characterization [ISO06] technique and the HDR assembly method
using ICC profiles [GHS01] (generated by GretagMacbeth
ProfileMaker), see Table 2(c) and Figure 7. As predicted, the
achieved accuracy is lower than with our new method.
In order to confirm repeatability, we acquired the test
set (Canon 350D) a second time under different illumina-

Our second test scene is a desk scene illuminated mainly
by a fluorescent desk lamp, see Figure 5 and 6. Tone-mapped
versions of the characterized HDR images are shown and as
can be seen the colors of all three images are almost identical, even though they were taken with three different cameras.

Characterization Results of Canon 350D
12

LDR Characterization
HDR ICC Profile
HDR Characterization

∆E 00

10
8
6

4.2. Discussion

4
2
0
0

tion (2983K). The median ∆E00 was 0.546 over 48 patches,
which is very close to the ∆E00 of 0.480 for the first test
set. The Nikon cameras have a slightly higher error, which
we could trace back to an inferior infrared filter. Halogen
light emits a large amount of infrared light, which caused
the HDR images acquired with the Nikon cameras to have
a considerable amount of infrared glare. Using an additional
infrared blocking filter (Rosco Thermal Shield) in front of
the lights yielded a median ∆E00 of 1.6 for the Nikon D100,
down from 3.8 (see Table 2(b)).

20

40

60

80

100

Chroma C*
ab

Figure 7: Comparison of color difference (test set, patches
sorted by chromaticity). ∆E00 is computed by using a ColorChecker chart in brightly illuminated area. LDR characterization is calculated using the reflectance-based method
[ISO06]; the HDR ICC method is according to [GHS01].
Our HDR characterization shows considerably low errors.

Our characterization method is applicable to HDR imaging, which is very useful in graphics but also other scientific
fields. Our mathematical method of characterization is rather
simple—a linear transformation between color spaces—and
not different from previous methods. However, our characterization methodology, the combination of a new transparent color target, HDR imaging, and characterization theory,
solves shortcomings of previous characterization methods.
As shown in the results, our characterization performance
is considerably better than previous methods [PAJ01, MJ02,
c 2008 The Author(s)
Journal compilation c 2008 The Eurographics Association and Blackwell Publishing Ltd.

Min H. Kim & Jan Kautz / Characterization for HDR Imaging

Joh02, ISO06, GHS01], yet efficient in terms of cost and acquisition time.
However, there are some limitations of our method. The
performance depends on the optical quality of the digital camera, including lens flare, vignetting, veiling glare,
and the infrared filter. HDR veiling glare can be solved
[TAHL07] but acquisition complexity is greatly increased.
The measurement used in our method returns radiometric
XYZ values, not radiance in each wavelength. In this way,
it still allows potential measurement errors with metameric
colors like other target-based models.
5. Conclusion
We have presented a new technique that can be utilized
to characterize HDR imaging systems, both in terms of
luminance and color. It is more accurate than previous
reflectance-based characterization methods and less timeconsuming than monochromator-based techniques, which
were also really only designed for LDR imaging. We have
validated the method’s accuracy using three different digital
cameras and two test data sets. Even though we have devised
our method with HDR imaging in mind, the same technique
can also be applied to characterize LDR devices.
References
[ANS99] ANSI: Graphic Technology - Color Transmission Target for Input Scanner Calibration. Tech. Rep. ANSI IT8.7/11993 (R1999), ANSI, 1999.
[CIE86] CIE: Colorimetry. Publication CIE 15.2-1986, Commission Internationale de l’Eclairage (CIE), Vienna, 1986.
[CIE01] CIE: Improvement to Industrial Colour Difference Equation. Publication CIE 142, CIE, Vienna, 2001.
[DM97] D EBEVEC P. E., M ALIK J.: Recovering high dynamic
range radiance maps from photographs. In Proc. ACM SIGGRAPH 97 (Aug 1997), pp. 369–378.
[FB93] FAIRCHILD M. D., B URNS R. S.: Image colour appearance colour specification through extension of cielab. Colour
Research Application (1993).

697

[IG04] I NANICI M., G ALVIN J.: Evaluation of High Dynamic
Range Photography as a Luminance Mapping Technique. Paper
LBNL-57545, LBNL, Dec. 2004.
[ISO06] ISO: ISO/17321-1:2006: Graphic technology and photography — Colour characterisation of digital still cameras
(DSCs) — Part 1: Stimuli, metrology and test procedures. 2006.
[Jan01] JANESICK J. R.: Scientific Charge-Coupled Devices,
1st ed. SPIE Publications, Bellingham, 2001.
[Joh02] J OHNSON T.: Methods for characterizing colour scanners
and digital cameras. In Colour Engineering, Green P., MacDonald L., (Eds.). John Wiley, Chichester, 2002, pp. 165–178.
[KGS05] K RAWCZYK G., G OESELE M., S EIDEL H.-P.: Photometric Calibration of High Dynamic Range Cameras. Research Rep. MPI-I-2005-4-005, MPI Informatik, Saarbrücken,
Apr. 2005.
[MBG04] M ORGENSTERN T., B ORNHOEFT G., G OERLICH S.:
Miniaturized Spectroradiometer. Light 2004, JETI Technische
Instrumente GmbH, Brno, Jun. 2004.
[MJ02] M AC D ONALD L., J I W.: Colour characterisation of a
high-resolution digital camera. In Proc. IS&T CGIV (2002),
vol. 1, pp. 433–437.
[MN99] M ITSUNAGA T., NAYAR S. K.: Radiometric self calibration. In Proc. IEEE CVPR (Jun. 1999), pp. 374–380.
[MP95] M ANN S., P ICARD R. W.: On being ‘undigital’ with
digital cameras: Extending Dynamic Range by Combining Differently Exposed Pictures. Tech. rep., Feb. 01 1995.
[MVPC00] M ARTÍNEZ -V ERDÚ F., P UJOL J., C APILLA P.: Calculation of the color-matching functions of digital cameras from
their complete spectral responsitivities. In Proc. CIC (Nov.
2000), pp. 211–216.
[MVPC03] M ARTINEZ -V ERDU F., P UJOL J., C APILLA P.:
Characterization of a digital camera as an absolute tristimulus
colorimeter. J. IS&T 47, 4 (2003), 279–374.
[NFG07] N ORMAND C., F ORNARO P., G SCHWIND R.: Automated digital camera sensor characterization. In SPIE/IS&T EI
(2007), vol. 6502.
[PAJ01] P OINTER M. R., ATTRIDGE G. G., JACOBSON R. E.:
Practical camera characterization for color measurement. In
PICS (2001), pp. 246–251.

[FHH97] F INLAYSON G. D., H UBEL P. M., H ORDLEY S.:
Colour by correlation. In Proc. CIC (1997), IS&T, pp. 6–11.

[RBS99] ROBERTSON M. A., B ORMAN S., S TEVENSON R. L.:
Dynamic range improvement through multiple exposures. In
Proc. IEEE ICIP (1999), vol. 3, pp. 159–163.

[GHS01] G ÖESELE M., H EIDRICH W., S EIDEL H.-P.: Color
calibrated high dynamic range imaging with ICC profiles. In
Proc. CIC (2001), IS&T, pp. 286–290.

[RSSF02] R EINHARD E., S TARK M., S HIRLEY P., F ERWERDA
J.: Photographic tone reproduction for digital images. ACM
Trans. Graph 21, 3 (July 2002), 267–276.

[HHF99] H UBEL P., H OLM J., F INLAYSON G.: Illuminant estimation and colour correction. In Colour Imaging, McDonald L.,
Luo R., (Eds.). John Wiley, Chichester, 1999, pp. 73–95.

[TAHL07] TALVALA E.-V., A DAMS A., H OROWITZ M., L EVOY
M.: Veiling glare in high dynamic range imaging. ACM Trans.
Graph. 26, 3 (2007), 37.

[Hol98] H OLST G. C.: CCD Arrays, Cameras, and Displays,
2nd ed. JCD Publishing, Bellingham, 1998.

[Yam06] YAMADA T.: Ccd image sensors. In Image Sensors and
Signal Processing for Digital Still Cameras, Nakamura J., (Ed.).
CRC Press, Broken Sound Parkway, 2006, pp. 256–276.

[Hun98] H UNT R. W. G.: Measuring Colour, 3rd ed. Fountain
Press, Kingston-upon-Thames, 1998.
[ICC04] International Color Consortium Specification. Tech.
Rep. ICC.1:2004-10, International Color Consortium, 2004.
c 2008 The Author(s)
Journal compilation c 2008 The Eurographics Association and Blackwell Publishing Ltd.

