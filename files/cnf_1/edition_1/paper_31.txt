Evaluation of Large Display Interaction Using Smart Phones
Jens Bauer∗

Sebastian Thelen†

Achim Ebert‡

Computer Graphics & HCI Lab
University of Kaiserslautern

A BSTRACT
Visual analytics, “the science of analytical reasoning facilitated by
visual interactive interfaces” [5], puts high demands on the applications visualization as well as interaction capabilities. Due to their
size large high-resolution screens have become popular display devices, especially when used in collaborative data analysis scenarios. However, traditional interaction methods based on combinations of computer mice and keyboards often do not scale to the
number of users or the size of the display. Modern smart phones
featuring multi-modal input/output and considerable memory offer
a way to address these issues. In the last couple of years they have
become common everyday life gadgets. In this paper we conduct
an extensive user study comparing the experience of test candidates
when using traditional input devices and metaphors with the one
when using new smart phone based techniques, like multi-modal
drag and tilt. Candidates were asked to complete various interaction tasks relevant for most applications on a large, monitor-based,
high-resolution tiled wall system. Our study evaluates both user
performance and satisfaction, identifying strengths and weaknesses
of the researched interaction methods in specific tasks. Results reveal good performance of users in certain tasks when using the new
interaction techniques. Even first-time users were able to complete
a task faster with the smart phone than with traditional devices.
Index Terms: I.3.6 [Computer Graphics]: Methodology and
Techniques—Interaction Techniques; H.5.2 [Information Interfaces
and Representation]: User Interfaces—Interaction styles; H.5.2 [Information Interfaces and Representation]: User Interfaces—Input
devices and strategies
1 I NTRODUCTION
Large displays have become more and more common in the last
few years, especially in the field of data analysis. They provide
more physical space to visualize more contents of large datasets
and are popular for collaboration purposes where a large number
of people need to interact with the screen simultaneously. Due to
space constraints not every user may be provided with a separate
keyboard and/or mouse, in many cases only a single workplace is
available to interact with the large screen, preventing convenient
and efficient collaboration. Small hand-held devices for every user
could solve this problem. Smart phones are small, powerful and
programmable devices owned by more and more people nowadays,
making them a good choice for an ubiquitous input device. This
approach scales well to the number of users and requires no further
per-user-equipment or special environment. Connectivity as offered
by most smart phones today makes integration into a system easy.
The touch displays common on these devices are a veritable in-/
output device on their own, but additionally accelerometers, cameras and other equipment are integral part of smart phones and can
∗ e-mail:

j bauer@cs.uni-kl.de

† e-mail:thelen@cs.uni-kl.de
‡ e-mail:ebert@cs.uni-kl.de

IEEE Symposium on Visual Analytics Science and Technology
October 23 - 28, Providence, RI, USA
978-1-4673-0014-8/11/$26.00 ©2011 IEEE

be exploited in order to enable user interaction via a phone with a
large display application. A lot of interaction metaphors have already been developed for mobile hand-helds, but most of them are
geared towards the solution of a very specific problem. When employing smart phones as a usable interaction device, one has to consider many different cases. In this paper the performance of a handheld device is evaluated for various usage scenarios especially in
terms of user experience. The resulting data is then cross-connected
in order to see the efficiency of using smartphones for common subtasks. By this approach we will show strengths and weaknesses of
smart phones as input devices not only for a single, special problem, but for common tasks occurring in almost any context in any
application, offering developers of large display applications patterns to implement good solutions for the above problems or if a
more individual solution is necessary.
2

R ELATED W ORK

Large display interaction is a topic not new in computer sciences.
More than 10 years ago Swaminathan et al.[4] already came to the
conclusion, that large displays need different interaction techniques
than traditional workstations. When large displays became more
and more affordable, the research interest in this area went up, too.
Robertson et al. [3] focused on various usability issues on large displays. Much other research was conducted on special interactions
for special applications, like Jeon et al. [1] who proposed three special interaction techniques using handheld phones as a replacement
for computer mice, one approach translating the relative movement
of the phone in the air to the movement of the mouse cursor on the
large display screen. The second proposed mechanism selects an
object by pointing on it with the phone (and essentially taking a
picture of an annotated object) and moving it by moving the phone
in the according direction or as in the last method pointing at the
desired cursor position in order to control a cursor manipulating the
selected object. Madhavapeddy et al. [2] used a camera-equipped
mobile phone to interact with a flight-booking application (i.e., a
large world map), but their approach was specialized and cannot
easily be transferred to most other problems.
3

E VALUATION S CENARIOS

For the evaluation four scenarios were chosen, two in a 2D environment and two in 3D. The Stacking Cubes scenario involves
movement of objects in 3D space, the second one, Maze, lets the
user move the viewport into the 3D world. Movement is performed
in both cases by tilting the phone into the intented direction. For
the Stacking Cubes swiping on the touchscreen provides sidewards
movement, giving the user full six-degree-of-freedom. The next
scenario, Map Annotation, asks the user to select a certain spot on
a city map and entering a short comment about that spot. Spot selection is done by entering selection mode (via the smart phone’s
menu) and tapping on the spot. A new textfield opens automatically, letting the test candidate enter the comment. Jigsaw Puzzle is
the last scenario. Participants were asked to complete a puzzle by
using the smart phone’s touch screen to place the puzzle pieces.

265

Figure 1: Stacking Cubes scenario (left), Map Annotation (right)

4 E VALUATION R ESULTS
For each input method (mouse, keyboard (combined or seperate)
and smart phone) in each scenario, we measured the time taken by
each participant in seconds and the candidate then was asked to
rate that method on a scale from 1 (best) to 6 (worst). We tested 17
participants of various ages (20-50 years) and levels of computer
experiences. Each time was converted to a relative time by dividing the actual time of each input method by the total time taken
to complete a scenario with all available input devices, in order to
avoid having the times tainted by individual paces of users. The
significance of all relative times was tested with an ANOVA and a
post hoc Tukey’s HSD test. Since a Levene-Test could not assure
the homogeny of variances in test case 2, additionally a Welchand a Brown-Forsythe-Test were made to assure the outcome of the
ANOVA despite the inhomogeneous input data. The ANOVA-tests
resulted in the F-values of 7.109, 21.733, 43.898 and 67.069 for the
Stacking Cubes, Maze, Map Annotation and Jigsaw Puzzle, respectively. This yields significant differences in measured relative times
in all scenarios not only on the chosen 5% confidence interval, but
even on a 0.2% confidence interval. The robust alternate tests for
case 2 support the rejection of the null hypothesis (No differences in
relative times) on at least a 0.1% confidence interval. Using Tukeys
HSD significant differences in relative times of the smart phone in
contrast to the other input methods can be shown in all cases, but
for smart phone and mouse in scenario 1. This fact has to be kept
in mind for the following evaluation of case 1.
In the first scenario, the keyboard has the best mean time of all
three input methods; mouse is second fastest and the smart phone
took the most time to complete the stacking. Regarding the grades
given by the candidates, the keyboard is rated best (because of its
simple to use interface), mouse is second and the drag-and-tilt control on the smart phone third, but as mentioned above, it is not statistically proven that the times of smart phone and mouse are actually
different with respect of the variance imposed by the various test
users. Most candidates mentioned too little practice with the smart
phone to use it to full extend. Especially since this is a multi-modal
control, practice can improve the times of the smart phone in this
test.
The second 3D-scenario yields results comparable to the first
one. The keyboard-mouse-combination was the fastest input
method available, and with almost the same mean time, the keyboard control was the favorite method of most inexperienced users
since it is easier to learn than the combination method. Accordingly those two methods were given the best grades in this test by
most users. Mouse control was 3rd fastest, leaving the smart phone
control behind in matters of speed. But interestingly the phone was
given the best or second best grade for solving this test scenario by
more than 40% of all test candidates, with many candidates mentioning missing experience with the smart phone.
Map Annotation was the first 2D scenario evaluated. Since most
of this task was done using the native user interface of the smart
phone, people already experienced with the use of mobile phones
had little to no problems solving this tasks. Participants rated the
traditional desktop input higher mostly because of the bigger screen

266

with its higher resolution and because annotating a point of interest
on the smart phone has to be done via a menu on the phone, which
was also the main cause for the phone performing slower in this
task.
The last task evaluated was solving the jigsaw puzzle. The keyboard control was slowest and the worst rated by almost all test
candidates. The smart phone control was slower than the mouse,
mainly for the reason that the smaller screen demanded a much
more exact placement of the two tiles in order to connect them.
Still the phone was rated best by 17% of the test candidates and
was rated worst only by users so content with the desktop controls,
that a grade of 2 or 3 for the phone was the worst grade they gave
in this part of the test. In overall we can say, the smart phone performed very well in this test according to the user experience.
5 D ISCUSSION
Considering the results obtained from the evaluation in categories
shows a good performance of the smart phone in the 2D test applications. Even users who never worked with a smart phone before
had no problems using it to solve the tasks given. A shortcoming of the proposed method is the small screen provided by the device. Another problem especially with the smart phone used in this
test was the low performance of the device with respect to picture
processing, resulting in a low but observable lag when scrolling
the map or dragging jigsaw puzzle pieces around. While the measured time in the 3D scenarios for the phone are not very fast, a
lack of practice with this application of the phone may be the main
problem. Considering that most users had more problems with the
multi-modal control method used in the first scenarios than with
the simple tilting method in the second one, it is feasible that after
some time of practicing with this input method, much better results
are possible. Improved acceleration sensors can also improve user
experience by a large amount, as the jitter of those sensors reduces
the smoothness of the control by a large amount. Studies about
the learning curve are necessary in order to know for sure, if the
times of the smart phone gets on par with those of keyboard and/or
mouse.
Interaction with large high-resolution displays still poses challenges to developers. Especially with the multi-user setting common for these devices, new approaches can improve not only
user experience, but also the performance of the whole (sociotechnological-) system consisting. Our evaluation shows smart
phones really have the ability to become a viable input device, but
cannot be incorporated into a system as easily as more traditional
input devices. Especially selection-tasks can be done on a smart
phone without problems, if the selection items can be fit onto the
small screen of the handheld or if some (simple) means of zooming
is provided. With respect to actual technologies at the time of writing this paper, multi-touch seems to be a feasible solution to this
problem.
R EFERENCES
[1] S. Jeon, J. Hwang, G. J. Kim, and M. Billinghurst. Interaction techniques in large display environments using hand-held devices. In Proceedings of the ACM symposium on Virtual reality software and technology, VRST ’06, pages 100–103, New York, NY, USA, 2006. ACM.
[2] A. Madhavapeddy and R. Sharp. Using Camera-Phones to Enhance
Human – Computer Interaction. 2004.
[3] G. Robertson, M. Czerwinski, P. Baudisch, B. Meyers, D. Robbins,
G. Smith, and D. Tan. The large-display user experience. IEEE Computer Graphics and Applications, 25:44–51, 2005.
[4] K. Swaminathan and S. Sato. Interaction design for large displays.
interactions, 4:15–24, January 1997.
[5] J. J. Thomas and K. A. Cook. Illuminating the Path: The Research and
Development Agenda for Visual Analytics. National Visualization and
Analytics Ctr, 2005.

