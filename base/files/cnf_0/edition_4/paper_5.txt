Getting Along: Composition of Visualization Paradigms
T. Alan Keahey
Visual Insights, Inc.
alan.keahey@visualinsights.com
Abstract
This paper describes how focus+context techniques can
be composed with other high-level visualization paradigms
to mutual advantage. Examples are given showing composition both with a pan&zoom system, and with a treemap
implementation. The examples illustrate how focus+context
can be used as an exploration and navigation tool within
those paradigms.

formation over an entire domain via an area-based derivative computation of a magnification field. These magnification fields can be computed for any given transformation
(independent of the system used to produce the transformation), and their values are well defined over the entire domain (rather than simply at the point of focus, or as simple
distance functions limited to single focus systems).

2.1 Pan&Zoom with Focus+Context

1 Motivation
Nonlinear magnification [10] is a general term used to
describe the properties of a broad collection of techniques
that have gone under the names of fisheye views [4], focus+context [12], continuously variable zoom [3] and others. These techniques have a rich history spanning a large
number of application types, including viewing structured
text[4], graph layout [12, 13], and viewing image/map data
[10]. A feature that is common to most of these systems
is that they have tended to be used as stand-alone tools for
viewing data in isolation, rather than as techniques to complement existing high-level visualization paradigms.
This paper will explore ways in which nonlinear magnification can be used in conjunction with other paradigms,
and show how the composition of focus+context techniques
with other visualization paradigms can allow them to build
on each others’ strengths and reduce their weaknesses, thus
providing a whole that is greater than the sum of the parts.
Our underlying philosophy is that nonlinear magnification
can be used to complement existing paradigms, rather than
compete with them.

2 Composing Visual Paradigms
In this section we will explore the composition of nonlinear magnification techniques with two other popular information visualization paradigms: pan&zoom and treemaps.
The nonlinear magnification routines used here are based
on the nonlinear transformation pipeline first described in
[10]. That work described a 2D nonlinear magnifying transformation Ø as transforming points in a domain , such that
´Ü¼ Ý ¼ µ
Ø´Ü Ý µ. In subsequent work [11], we developed
a method for measuring the effects of any nonliner trans-

Proceedings of the IEEE Symposium on Information Visualization 2001 (INFOVIS’01)
1522-4048/01 $17.00 © 2001 IEEE

The pan&zoom paradigm [1] has been in widespread use
for some time now in different forms. The paradigm offers
advantages of being intuitive to the user and allowing high
levels of distortion free zooming. When combined with filtering techniques [1], such systems offer the potential for
interaction with almost limitless amounts of data in an infinite space. This large data-space can cause navigational
difficulties however, through loss of context when “zoomed
into” the view, and loss of detail when “zoomed out” of the
view. Recent research has made strides towards addressing
these navigational difficulties [5, 7], to which we would add
the current effort.
Pan&Zoom systems provide the ability to manipulate the
global magnification (scale) of a view to a very high degree, whereas focus+context systems provide the ability to
selectively change the local magnification within a view.
Thus the composition of these two systems can be seen as
global+local magnification. This allows the user to use local
magnification to “probe” a given view for regions of interest before committing to a full zoom on that region, thus
preventing the loss of context that the normal zoom operation would entail. This preservation of context is particularly important for navigating in an exploratory environment where the user may be uncertain on which direction to
take within a data-space. By using multiple local magnification lenses (as described in [10] and other works) the user
can also probe multiple regions simultaneously, something
that is not possible with a traditional pan&zoom system.
The spatial characteristics of a pan&zoom system can
be implemented via manipulation of a 4-tuple Î
ÜÑ Ò ÝÑ Ò ÜÑ Ü ÝÑ Ü representing a basic viewport
transformation. A pan&zoom operation Ô (either panning
or zooming) will cause a transformation on this 4-tuple:

Î

Ô´Î µ. To compose this pan&zoom system with our
system for nonlinear magnification [10], we note that the
default domain for our nonlinear transformations is rectangular, and can be described by a 4-tuple in the exact same
way as Î . Thus the systems can be composed simply by
Î so that: ¼ Ô´ µ. Only minor changes to
setting
our nonlinear magnification system are required to scale the
local lens size relative to the global scale.
¼

This composition of global and local magnification has
the nice property that the resolution of the transformation
grid (used for local magnification) remains constant with
respect to the current viewport transformation Î , even as
the global magnification levels change. One of the difficulties encountered by grid-based approximations to nonlinear
transformations [2, 10] is that the maximum level of local
magnification is limited by the resolution of the grid. This
limitation has two aspects: a grid cell at the center of magnification will continue to increase magnification only up until
its defining boundary points get pushed into the context area
and will then cease to increase magnification, and as the cell
grows it inceases the significance of interpolation within
the cell so that the transformation appears chunky rather
than continuous. These difficulties with high levels of local magnification can be partially addressed through the use
of high-resolution grids, however they are more properly
addressed through the use of multiresolution grid methods
(an example of which is described in [8]). This method of
mapping Î onto is a simple resampling mechanism that
provides the effect of a multiresolution grid, thus allowing
local magnification at any scale.
We have implemented a system for global+local magnification, as illustrated in Figure 1. For the local magnification tool, we have chosen a round magnification lens with
a distortion-free region of linear magnification in the middle and a smooth transition between magnified and unmagnified regions. This allows the user to probe down within
regions at local magnification factors of up to 8X or higher
while still preserving a static context area in which to navigate. Additional types of local magnification lenses are possible, and the user has complete control over the size of lens
and degree of magnification. A single click causes the local magnification lens to pop up on the display for use by
the user (a semi-transparent grid overlay is used to show the
user the transformation that has been applied). When the
user finds a region of interest, another single click will cause
the system to pan the center of that region into the center
of the viewport, and will zoom the system in an amount
equal to the local magnification. The local magnification is
smoothed out [10] until all distortion is removed and only
the identity transformation remains. All of these actions after the click are interpolated and animated simultaneously,
so that the user smoothly transitions to the new view. At
this point, the local lens can be deployed again for further

Proceedings of the IEEE Symposium on Information Visualization 2001 (INFOVIS’01)
1522-4048/01 $17.00 © 2001 IEEE

exploration and zooming. Figure 1 shows three stages of
this process: the first image shows the normal view of a
lomap of Portsmouth NH, the middle view shows a
cal lens focused on a peninsular region of Portsmouth in the
upper right, and the final view shows the view panned and
zoomed on the region of interest. The zoom bars on the images allow the user to control the pan and zoom parameters,
and also provide visual feedback to the user for their current
position in the overall dataspace.
This global+local magnification system offers advantages in terms of preservation of context while probing for
regions of interest. In addition, it offers a simple navigation
mechanism for the pan&zoom paradigm. When the user
clicks to zoom in on a region of interest, the relevant panning and zooming operations are collapsed into a single animated operation, thus freeing the user of having to manipulate the panning and zooming operations independently.
This interaction mode is similar to how clicking on discrete
objects in Pad++ [1] works, however it is more generically
based on spatial selection than object selection.
A final issue involving the composition of global and local magnification systems involves the implementation of
filtering. Much of the power of pan&zoom systems comes
from their ability to filter out information that is above or
below the threshold of visibility. Fortunately it is a relatively straightforward matter to continue this type of filtering in the global+local magnification system. Because the
magnification fields described in [11] are well defined over
the entire domain it requires only a simple lookup operation to determine the local magnification Ð for a given point,
this can be multiplied by the global magnification to get
the absolute scale for any point in the domain. This type
of filtering (along with how to position and embed discrete
objects within a nonlinearly transformed space) was demonstrated in the interactive travel atlas described in [9].

2.2 Fisheye Treemaps
Treemaps [6] are another popular paradigm for information visualization that have been widely used in different
variations. Treemaps can be used to lay out entire hierarchies within a fixed amount of display space by subdividing
that space to reflect branches in the hierarchy. As the number of nodes becomes very large however, it may not be possible to display all of them in the desired level of detail, as
they get packed into potentially sub-pixel sized areas [6]. In
order to address this limitation, zooming was introduced in
a later version [16] so that any node could be designated as
the root node of a new hierarchy, which would then be displayed at maximum scale. It is interesting to note that this
zooming mechanism is spatially equivalent to a (possibly
non-uniform) pan&zoom operation that brings the current
viewport parameters into alignment with the bounding box
of the selected node. For both the pan&zoom and treemap

Figure 1. Global+Local Magnification Sequence: initial view, view with local magnification of ROI in
upper right, view panned and zoomed on ROI with local magnification smoothed out.
operations, the zooming operation will necessarily cause a
loss of context.
We can compose nonlinear magnification with treemaps
(fisheye treemaps) to enhance detail in regions of interest
without the loss of context entailed by full zoom methods.
This has been implemented here through the mechanism of
seamless multilevel views [9]. Figure 2 shows two treemap
views of a stock portfolio at different levels of detail 1 (additional levels of detail can be easily added WLOG). We
are using these images as textures representing discrete levels in our multilevel view system. Due to the rectangular
nature of the data, we have chosen an orthogonal nonlinear
step transformation [10] that allows independent magnification along each axis, and preserves horizontal and vertical
lines. The user can control the degree of magnification interactively, and the stepwise nature of the transformation
allows the central region of local magnification to be distortion free. Alternative versions with constrained lenses
and/or multiple regions of magnification are also possible,

Figure 2. Two views of a stock portfolio.
1 These

images were obtained using the TreeMap97 implementation
available at www.cs.umd.edu/hcil, and are used with permission of the
Human-Computer Interaction Lab, University of Maryland

Proceedings of the IEEE Symposium on Information Visualization 2001 (INFOVIS’01)
1522-4048/01 $17.00 © 2001 IEEE

An example of fisheye treemaps is shown in Figure 3.
When the user first looks at the treemap, it has no local
magnification and appears as the lower detailed “black and
white” image on the left of Figure 2. Local magnification is
subsequently applied centering on the leftmost node labeled
“Portfolio 2”, producing Figure 3. This magnification pulls
in more details from the higher detailed “colored” view in a
seamless fashion, including additional sub-hierarchies. For
example, we can now see that the “Portfolio 2” node in
question includes a large portion of computer stocks including Compaq, Cray, DEC, and Unisys. The context of the
surrounding areas are shown at reduced scale, still providing the viewer with a sense of the overall structure of the
hierarchy and the location of their locally magnified region
within it.

Figure 3. Composed fisheye treemap view.
This particular implementation of a fisheye treemap provides interaction with static treemap views, however given

access to the treemap software it could be extended to handle dynamic data with user selection of nodes and properties to display. One approach to doing this would be to
have the treemap software draw it’s images directly to texture memory where the multi-level view data resides(these
texture images could be much larger than available screen
space). User interaction with the resulting view can then be
mapped back into the original treemap coordinates via the
OpenGL picking mechanism, along with information about
the local magnification to determine the view level that is
being acted on. An alternative approach would be to modify
the treemap software to apply the nonlinear transformation
to the node coordinates directly before they are drawn to the
screen, which would allow dynamically adapting the LOD
within hierarchies based upon the local magnification.

3 Discussion
All of the examples in this paper used the nonlinear magnification toolkit described in [10] for producing the localized magnification transformations. It is possible that other
magnification systems could be used as well, although the
complexity of our compositions was simplified greatly by
the simple 2D nature of the toolkit we used. This toolkit is
also capable of more sophisticated methods for indicating
localized scale levels to the user via shading [9], which may
enhance the effectiveness of the composition.
Nonlinear magnification is very generic and spatial in
nature, and is not tied to any specific data type that is being visualized. This lends itself well to being used as an
“overlay operation” that can be composed with other more
specific paradigms. Our applications show how nonlinear
magnification can be used as a complementary tool to existing visualization systems by providing additional support
for navigation and exploration. Related work [15] described
a specific case of integrating a fisheye graph algorithm with
pan&zoom for exploring software structures. In addition to
being used as a lens to navigate and enhance views of existing data, implicit magnification fields [11] are suitable
for use as a “driving mechanism” for LOD, dynamic retrieval, and rollup/drilldown operations. Recent work exploring these issues includes nonlinearly magnified travel
atlases [9], and selective rendering of graph structures based
on their proximity to the center of a hyperbolic space [13].
More generally, nonlinear magnification can be seen as a
continuous version of the Magic Lens [14] paradigm, providing a continuum of values over the view domain rather
than a binary selection.

4 Conclusions
In this paper we have shown how the generic spatial nature of nonlinear magnification is well suited as an “overlay” operation that can be composed with other high-level

Proceedings of the IEEE Symposium on Information Visualization 2001 (INFOVIS’01)
1522-4048/01 $17.00 © 2001 IEEE

visualization paradigms. While much previous work has
emphasized the use of nonlinear magnification as a standalone visualization tool, the examples here demonstrate
how it is also suitable for providing exploration and navigation support within those other paradigms.

References
[1] B. B. Bederson and J. D. Hollan. Pad++: A zoomable graphical interface. In Proceedings of the ACM Conference on
Computer Human Interaction, 1994. Short paper.
[2] M. Carpendale, D. Cowperthwaite, and D. Fracchia. 3D pliable surfaces: For the effective presentation of visual information. In Proceedings of the ACM Symposium on User
Interface Software and Technology, pages 217–226, 1995.
[3] J. Dill, L. Bartram, A. Ho, and F. Henigman. A continuously
variable zoom for navigating large hierarchical networks. In
Conference on Systems, Man and Cybernetics, pages 386–
390, 1994.
[4] G. W. Furnas. Generalized fisheye views. Human Factors
in Computing Systems, CHI ’86, pages 16–23, Apr. 1986.
[5] G. W. Furnas and B. B. Bederson. Space-scale diagrams:
Understanding multiscale interfaces. In Proceedings of the
ACM Conference on Computer Human Interaction, 1995.
[6] B. Johnson and B. Shneiderman. Treemaps: A space-filling
approach to the visualization of hierarchical information
structures. In Proceedings of IEEE Visualization, 1991.
[7] S. Jul and G. W. Furnas. Critical zones in desert fog: Aids
to multiscale navigation. In Proceedings of the ACM Symposium on User Interface Software and Technology, 1998.
[8] T. A. Keahey. Nonlinear Magnification. PhD thesis, Department of Computer Science, Indiana University, Dec. 1997.
[9] T. A. Keahey. The generalized detail-in-context problem. In
Proceedings of the IEEE Symposium on Information Visualization, IEEE Visualization, Oct. 1998.
[10] T. A. Keahey and E. L. Robertson. Techniques for non-linear
magnification transformations. In Proceedings of the IEEE
Symposium on Information Visualization, IEEE Visualization, pages 38–45, Oct. 1996.
[11] T. A. Keahey and E. L. Robertson. Nonlinear magnification
fields. In Proceedings of the IEEE Symposium on Information Visualization, IEEE Visualization, Oct. 1997.
[12] J. Lamping, R. Rao, and P. Pirolli. A focus+context technique based on hyperbolic geometry for visualizing large
hierarchies. In Proceedings of the ACM Conference on Computer Human Interaction, 1995.
[13] T. Munzner. H3: Laying out large directed graphs in 3D
hyperbolic space. In Proceedings of the IEEE Symposium on
Information Visualization, IEEE Visualization, Oct. 1997.
[14] M. C. Stone, K. Fishkin, and E. A. Bier. The movable filter
as a user interface tool. In Proceedings of the ACM Conference on Computer Human Interaction, 1994.
[15] M.-A. D. Storey, K. Wong, F. Fracchia, and H. Muller. On
integrating visualization techniques for effective software
exploration. In Proceedings of the IEEE Symposium on Information Visualization, IEEE Visualization, 1997.
[16] D. Turo and B. Johnson. Improving the visualization of hierarchies with treemaps: Design issues and experimentation.
In Proceedings of IEEE Visualization, 1992.

