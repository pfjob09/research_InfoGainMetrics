Shape-based Transfer Functions for Volume Visualization
¨
Jorg-Stefan
Praßni∗

Timo Ropinski†

¨ Mensmann‡
Jorg

Klaus Hinrichs§

Visualization and Computer Graphics Research Group (VisCG), University of Munster
¨

A BSTRACT
We present a novel classification technique for volume visualization
that takes the shape of volumetric features into account. The presented technique enables the user to distinguish features based on
their 3D shape and to assign individual optical properties to these.
Based on a rough pre-segmentation that can be done by windowing, we exploit the curve-skeleton of each volumetric structure in
order to derive a shape descriptor similar to those used in current
shape recognition algorithms. The shape descriptor distinguishes
three main shape classes: longitudinal, surface-like, and blobby
shapes. In contrast to previous approaches, the classification is not
performed on a per-voxel level but assigns a uniform shape descriptor to each feature and therefore allows a more intuitive user interface for the assignment of optical properties. By using the proposed
technique, it becomes for instance possible to distinguish blobby
heart structures filled with contrast agents from potentially occluding vessels and rib bones. After introducing the basic concepts, we
show how the presented technique performs on real world data, and
we discuss current limitations.
Index Terms: I.3.7 [Computer Graphics]: Three-Dimensional
Graphics and Realism—Color, shading, shadowing, and texture.
1

I NTRODUCTION

Classification is an essential part of the volume visualization
pipeline. By applying transfer functions, the user is able to assign
optical properties to individual parts of a volumetric data set. In
contrast to a segmentation technique, a classification requires that
these individual parts can be distinguished solely based on information present in the data set. The most straightforward classification
can be performed by applying 1D transfer functions [19], which
use the intensity values stored in the data set to assign optical properties, usually given by an emissive color and an opacity value, to
certain subranges within the intensity range. Although 1D transfer
functions are easy to use and do not rely on any pre-computation,
they have the drawback that they do not allow to discriminate features within a data set which have an overlapping intensity range.
To deal with this shortcoming, multidimensional transfer functions
have been proposed [14]. 2D transfer functions based on intensity gradients can be considered as current best practice. They are
more powerful in discriminating certain object types, but do still
suffer from some major drawbacks. For instance, when applying
2D transfer functions to modalities with a rather low signal-to-noise
ratio, it is often difficult to detect boundaries and to discriminate
the desired structures of interest. Furthermore, when dealing with
data sets enhanced by contrast agents, it is often not possible to
distinguish between bone structures and vessels filled with contrast
agent, since both share rather high intensity values and a strong
∗ e-mail:

j-s.prassni@math.uni-muenster.de

† e-mail:ropinski@math.uni-muenster.de
‡ e-mail:mensmann@math.uni-muenster.de
§ e-mail:khh@math.uni-muenster.de

IEEE Pacific Visualisation Symposium 2010
2 - 5 March, Taipei, Taiwan
978-1-4244-6686-3/10/$26.00 ©2010 IEEE

gradient magnitude. Another drawback is the quite complex and
non-intuitive user interface necessary for specifying these intensitygradient transfer functions.
In this paper we propose an addition to the transfer function concept along with a corresponding user interface. By applying methods already used in shape classification, we are able to define a
multidimensional transfer function that takes into account the shape
of a desired feature for assigning optical properties. We perform a
rough, threshold-based pre-segmentation in a prep2rocessing step
and compute the curve-skeletons for each of the resulting volumetric structures. Since curve-skeletons are well known to sufficiently
describe the shape properties of 3D objects [16], we are able to derive some shape metrics for the objects, specifying the degree of
membership in some predefined shape classes. These shape metrics are given by a shape descriptor, i. e., a triple (tubiness, surfaceness, blobbiness). Thus the user is able to distinguish features
that are similar in terms of intensity and gradient magnitude, but do
have different shapes. In order to avoid the need for intensive user
interaction during the preprocessing step, we do not rely on highquality manual or semi-automatic segmentations but focus on those
that can be achieved by simple windowing. As a consequence, a
major challenge in the classification process for real-world data is
to handle imperfections in the pre-segmentation, which may result
in instabilities in the shape-skeletons and thereby disturbing shape
classification. Hence, we use data preprocessing and robust classifiers to handle these issues, which would not be necessary for
voxelized geometry data often used for testing skeletonization algorithms. To make our concept easily accessible, we also propose
a corresponding user interface for specifying shape-based transfer functions, which is based on a continuous triangle-shaped plot
showing the occurrence of the detected shape classes. The user can
directly assign optical properties to these shape classes. Benefits
of the presented approach are that it allows to visually separate objects that previously could only be separated by applying complex
segmentation techniques, therefore requiring much less manual intervention. Furthermore, the notion of shape is very intuitive and
thus the concept can also be applied without profound knowledge
of the underlying algorithms, e. g., for use by domain experts.
2

R ELATED W ORK

Transfer Functions are an essential tool for classifying volumetric data. Since 1D transfer functions cannot be used to distinguish
structures having an overlapping intensity range, multidimensional
transfer function techniques have been proposed. Today, the bestpractice approach considers the gradient length when assigning optical properties. Levoy [15] was the first to propose taking into
account the gradient length in volume rendering. In their seminal paper on semi-automatic transfer function specification, Kindlmann and Durkin [12] show how to exploit also the second order
derivative in order to semi-automatically extract boundaries from
volumetric data. Although this probably forms the basis for most
multidimensional transfer function approaches, the transfer function itself was still 1D and the gradient magnitude was only considered in order to modify the opacity. The method has been extended
by Kniss et al. [14] to support real multidimensional transfer functions, which can be specified by the user through GUI widgets and
dual-domain operations. Sereda et al. [24] also emphasize bound-

9

3

C LASSIFYING S HAPES

IN

VOLUME DATA

The goal of our approach is to construct a fuzzy shapeclassification. In contrast to shape-matching techniques which compare shapes, this classification results in several membership scores
that specify how much the object matches each of the predefined
shape classes. In order to allow the design of an intuitive user interface for shape classification especially for non-visualization experts, we decided to avoid the per-voxel classification performed
by previous approaches [22] [11], since these require the user to
analyze multi-dimensional histograms of similar complexity as the
intensity-gradient transfer function space. Instead, we aimed at pre-

10

Pre-Segmentation
Volume

Skeleton
Computation

Pre-Segmentation

Skeleton
Segments

Volume
Decomposition

Distance Map

aries with a method based on LH histograms. They identify and
display surface representations in histogram space and enable the
user to assign optical properties to these surfaces.
Several advanced data-centric approaches were proposed. Caban and Rheingans [3] use textural properties of volume regions
instead of intensity and gradient values to control optical properties. Hadwiger et al. [8] use a pre-computed feature volume to store
the results of a region growing process over a parameter domain.
This allows visualization of different feature sizes without a costly
re-computation of the segmentation. Correa and Ma [6] describe
size transfer functions that map the relative size of features to color
and opacity by utilizing scale fields for continuous representation
of size. Patel et al. [18] use mean and variance of voxel intensities
for a transfer function specification that is robust to noise.
The results of the transfer function comparison by Pfister et
al. [19] lead to the conclusion that semi-automatic transfer function specification is the most promising approach. Therefore, we
have chosen to follow this paradigm and automatically extract information in a pre-processing, which can be interactively explored
by the user later on.
Our approach is most similar to the one described by Sato et
al. [22]. They also support a volume classification based on shapes.
However, in contrast to our technique they detect shapes, such as
edges lines and blobs, by measuring multi-scale responses to 3D
filters. Thus, their classification is performed on a per-voxel basis, whereas our approach classifies complete volumetric features,
thereby allowing more intuitive user interfaces and a better understanding by domain experts. Zhang et al. [11] use inertia tensors for
the classification of shapes in volumetric data sets. Their approach,
however, is limited to classifying structures of a pre-defined size.
Shape Classification based on skeleton structures has a long history. In 3D, Binford’s generalized cylinders [1] decompose an object into a set of elongated parts defined by sweeping a 2D crosssection through a 3D space curve. The concept of an axial description of shape was proposed even earlier in 2D through Blum’s medial axis transform, or skeleton [2]. Pizer et al. [20] proposed a
framework of stable medial representation for segmentation of objects, registration, and statistical 3D shape analysis.
Cornea et al. [4, 5] examined existing algorithms and introduced
the concept of the hierarchical curve-skeleton as a robust method
to compute increasingly detailed skeletons. Their algorithm uses a
repulsive force field to extract curve-skeletons of general 3D objects
from volumetric data sets, using topological characteristics such as
critical points found in the resulting vector field. As the potential
field is generated by charging the object’s boundary, the algorithm
only requires information about the object’s surface voxels.
Skeletons were previously used for shape-matching, e. g., by Hilaga et al. [10], but also for volume visualization. Takahashi et
al. [25] automate transfer function design by extracting the topological structure of a volume data set using a skeletonization process.
Reniers et al. [21] classify voxel surfaces using a 3D skeletonization
method. Correa and Silver [7] use skeletons to manipulate transfer
functions while they are moving along features. Cornea et al. [5]
list a multitude of further uses for curve-skeletons.

Skeleton
Regions

Ske

Skeleton Region
Merging

leto

n Re

gion

Volu

me

Merged Skeleton
Regions

Transfer Function
Specification

Shape
Classification
Shape
Descriptors

Volume
Rendering
Shape
Transfer Function

Figure 1: Workflow of our approach.

senting a manageable set of shape-classified structures to the user
for the assignment of optical properties. Therefore, we have chosen a statistically motivated approach, based on curve-skeletons,
that classifies structures obtained from a decomposition of the input volume. These curve-skeletons have several benefits for shapeclassification: they are invariant to translation, rotation, and scaling,
and they can cope with moderate amounts of within-class deformation.
From analyzing typical volume data sets and their corresponding
shape-skeletons, we have derived three independent shape classes:
longitudinal/tubular, surface-like, and blobby shapes. The goal of
the classification process is to assign to each voxel in the data set a
score for each shape class, specifying how much the object part corresponding to the voxel matches the shape. No binary decisions are
made, because volume data may contain many ambiguous shapes
and the task of mapping the results of shape classification to optical
properties is better left to the user in an interactive process. The
overall workflow of our approach is a follows (Figure 1):
1. Creation of a pre-segmentation to obtain surface information
about the objects of interest. In order to minimize the amount
of user interaction that is necessary during the preprocessing
step, we focus on segmentations that can be achieved by assigning intensity thresholds (windowing). In case the intensity range of the desired structures is known in advance, e.g.
Hounsfield scale for CT scans, the pre-segmentation can be
obtained automatically.
2. Computation of the curve-skeleton, resulting in several polygonal chains of skeleton points, the curve-skeleton segments.
Additionally, we perform a normalization of the skeleton for
reducing artifacts often caused by imperfect segmentations.
3. Decomposition of the pre-segmentation based on the curveskeleton segments: The volume is further divided into skeleton regions, with each region corresponding to a segment of
the curve-skeleton.
4. Merging of skeleton regions. Neither the computation of
the curve-skeleton nor the skeleton normalization take into
account the membership of structures to the shape classes.
Therefore, the skeleton regions resulting from the ad-hoc decomposition of the pre-segmentation cannot be expected to
have a meaningful shape. We merge skeleton regions based
on certain criteria in order to improve their classifiability.
5. Shape analysis, incorporating both curve-skeleton and volume
data to assign shape scores to the merged skeleton regions,
thereby constructing the shape descriptors.

longitudinal

blobby
surface-like

Figure 2: Typical cases for the three shape classes. The arrows
illustrate the distance of each surface voxel (blue) to the skeleton
segment (red) . For the longitudinal shape a gap in the skeleton is
displayed. The surface shape is shown along with its bounding box.
In the following subsections we first describe the shape classification scheme and then in more detail the individual steps necessary
to generate the shape classification.
3.1 Shape Classification
The goal of the shape classification is to assign to each skeleton
region generated by the previous volume decomposition a degree
of membership in each of the supported shape classes. Only voxels specified in the pre-segmentation are considered, while all other
voxels are considered as background voxels and ignored, setting
their shape descriptor to all zero. Shape class membership is computed independently for each class, therefore further classes can
be added easily. Our system supports three shape classes, namely
tubiness, surfaceness, and blobbiness. In a medical context tubiness would be associated with blood vessels or elongated bones,
blobbiness would be found with organs such as the heart or the
kidneys. Structures with a high surfaceness could include the skullcap or a blade-bone. The three shape classes can also be interpreted as a measure of dimensionality, i. e., a shape with a onedimensional elongation gets a larger tubiness value, whereas a more
three-dimensional shape gets a larger blobbiness value.
3.1.1 Tubiness
We define an elongated region having a circular cross-section of
constant diameter as a perfectly tubular structure. In theory, such
structures feature a curve-skeleton that runs through the center of
each cross-section, and each of the region’s surface points has the
same minimal distance to the curve-skeleton: the radius of the tube.
Therefore, we define the tubiness τ of a volumetric region R as
the inverse of the standard deviation of its surface voxels’ minimal
skeleton distances, i. e.,
1

τ(R) :=
max

1
|∂ R|

2
∑v∈∂ R D(v) − d¯ , 1

∈ [0; 1] ,

(1)

where ∂ R is the set of surface voxels of R, D is the distance map
computed during the skeleton region growing, and d¯ is the mean
skeleton distance of all v ∈ ∂ R. In contrast, both surfaces and
blobby regions usually feature a significantly higher standard deviation, as Figure 2 illustrates. Note that the tubiness classifier is
not restricted to cylindric shapes but yields similar classification results for curved longitudinal shapes such as rib bones.
The reliability of the tubiness classifier depends to some degree on
the quality of the computed curve-skeletons, since especially an incomplete, discontinuous skeleton segment boosts the standard deviation of a tubinal region’s surface-to-skeleton distances. By connecting adjacent skeleton segments during the skeleton normalization we were able to handle this issue in most cases. Only highly
degenerated tubular regions where only a small fraction is represented correctly by the skeleton may be misclassified.

3.1.2 Surfaceness
A surface can be either planar or folded in space. In the first case,
the object’s minimal oriented bounding box has a very small extent in one space direction compared to the extent in the two other
space directions. We compute the minimal oriented bounding box
for each region by applying Har-Peled’s [9] technique. The planarity of a region is then proportional to the ratio of the bounding
box’s second shortest side length bm and its shortest side length
bs . According to our notion of planarity, we define regions with
bm ≥ 10 · bs to be maximal flat and regions with bm ≤ 5 · bs to be
not flat at all and apply a linear transition between these extrema:
plan(R) := clamp

1 bm (R)
− 1, 0, 1 ∈ [0; 1]
5 bs (R)

(2)

In case of a curved surface, the bounding box criterion does not
work. Therefore, we additionally compute the convexity of each
shape by selecting an arbitrary set of pairs of surface points and
determining for each line segment formed by a point pair the fraction that runs inside the shape. The convexity conv(R) is then the
average of these fractions. Since curved surfaces occupy only a
small part of their bounding box’s volume as depicted in Figure 2,
most parts of the line segments between surface points are lying
outside the region. Note that the sum of the planarity measure and
the convexity measure in isolation is not an appropriate surfaceness
classifier, since curved longitudinal shapes might have both planar
bounding boxes as well as a low convexity. Therefore, their sum
has to be weighted by the inverse tubiness score:
sur f (R) := (plan(R) + conv(R)) · (1 − τ(R)) ∈ [0; 2]

(3)

3.1.3 Blobbiness
The goal of the blobbiness classifier is to detect volumetric regions
that humans intuitively regard as “compact”. Though it is hard to
give a precise definition of blobbiness, one can certainly say that
a sphere or a cube are blobby objects, whereas tubes or planar
structures are less so. Furthermore, a suitable blobbiness classifier should classify an ellipse or a cuboid less blobby than a sphere
or a cube. One possibility could be the examination of the ratio of
surface to volume of a given region, since it can be shown that a
sphere has minimum surface for a given volume and that a cube has
a smaller surface than any non-cubic cuboid of the same volume.
But although the surface-to-volume ratio seems to be an appropriate
indicator for the blobbiness of analytical structures, it is less useful
for the classification of volumetric data sets, which often contain
regions with rough, imperfect boundaries. These jagged regions
exhibit a larger surface (i. e., number of surface voxels) than an analytical object of the same global shape, resulting in a misleading
surface-to-volume ratio.
Therefore, we follow a statistically motivated approach focussing on the spatial distribution of a region’s voxels instead of its
surface. We interpret the volumetric region R as a probability distribution and compute its second central moment about the mean,
also called variance, i. e.,
σ 2 (R) :=

∑ |r − m|2

(4)

r∈R

where r are the coordinates of a voxel ∈ R and m is the region’s
center of mass, i. e.,
1
m=
(5)
∑r
|R| r∈R
From an intuitive point of view, the variance measures to what extent a region’s mass is centered around its center of mass, in other
words the variance determines the compactness of an object. More
precisely, a sphere is the shape with minimal variance for a given

11

volume, since no volume element can be moved any closer to the
center of mass in order to reduce the variance. Therefore, we consider the variance of a volumetric region an appropriate measure
of its blobbiness. However, the variance is heavily influenced by
the size of an object, as an object with larger volume needs to occupy a larger region, which increases its variance. In contrast, we
are interested in a size-independent measure of blobbiness, because
we generally consider shape and size as independent concepts. We
achieve this by expressing a region’s variance relatively to the variance of a sphere with the same volume. First, we express a sphere’s
radius r as a function of its volume vol:
4
vol(r) = πr3
3

⇔

r(vol) =

3
vol
4π

1/3

(6)

Second, we calculate the variance σr20 of a sphere with radius r0 ,
which is centered around the origin, by integrating over all spheresurfaces with radius ≤ r0 :
σr20 =

r0
0

4
(4πr2 )r2 dr = πr05
5

(7)

Inserting Eqn. (6) into Eqn. (7) yields the variance of a sphere with
volume vol:
5/3
4
3
2
vol
(8)
σsph
(vol) = π
5
4π
Now, we are able to express a region’s variance in terms of the variance of a sphere of the same size. Hence, we define the blobbiness
of a region R as:
blob(R) :=
3.2

2 (|R|)
σsph

σ 2 (R)

∈ [0; 1]

(9)

Pre-segmentation

As such, volumetric data does not have a notion of shape. Some
semantic information needs to be added to the intensity values associated with the voxels in order to be able to define shapes, mainly
by specifying where object boundaries are located, i. e., which voxels are part of an object’s surface. For typical volumetric data sets,
this decision can be easy, as it is the case with the sharp contrast
between a metallic object and surrounding air in an industrial CT
scan, or more complicated such as for an inner organ surrounded
by tissue of similar intensity in a medical context. Note, however,
that for shape analysis not a full segmentation is required, only surfaces need to be specified. For example, two or more objects which
would be placed in individual segments for a full segmentation can
be placed in the same segment when only their surface is important. Splitting up this pre-segmentation into multiple sub-segments
corresponding to individual objects is left to the subsequent shape
classification. Hence, instead of a full-blown segmentation technique a much simpler method such as windowing can be applied to
acquire a rough approximation of object surfaces inside the volume
data.
3.3

Curve-Skeleton Computation

A major issue with skeleton computation is stability. Even small
changes in the object data, as caused by noise, can have a great influence on the resulting curve-skeleton. This is less of a problem for
our classification scheme, as we are analyzing each skeleton segment by itself, and therefore we incorporate more information with
a statistical approach that is less likely to be influenced by local stability issues. Cornea et al. [4] have evaluated several methods for
computing curve-skeletons, noting that the potential field method
results in the cleanest and smoothest curve-skeletons. We were especially interested in smooth skeletons of low complexity, because

12

Figure 3: Close-up of curve-skeleton in an angiography data set
prior to normalization. Pre-segmentation errors can lead to gaps
in the skeleton, as well as missing skeletons for entire parts of the
volume. The skeleton segments are shown with alternating colors.

heavily branching skeletons would cause problems for the volume
decomposition and merging step. Therefore, we have chosen the
potential field method, although it is the slowest of the examined
techniques, but running time of the preprocessing is not a main issue for our use case.
Our setup uses Cornea’s pfSkel application [5] that computes the
potential-based vector field of the object specified in the input presegmentation to construct the segments of the 3D curve-skeleton.
The algorithm requires a binary volume as input to specify surface
voxels. It outputs the generated curve-skeleton as multiple skeleton segments, each consisting of a polygonal chain of seed points.
Additionally, information about critical points and high divergence
points are given, but these are not used for our technique. To prevent cavities inside the pre-segmentation, caused by noise or other
artifacts, from disturbing computation of the skeletons, we add extra layers of voxels at the surface of objects. While this can have the
effect of smoothing the object and may lead to unwanted merging
of adjacent features, it worked out to remove some noise with the
relatively high resolution data sets we used. The only further relevant parameters are field strength, for which we chose a low value
of 4 to get a minimal complexity skeleton, and percentage of high
divergence points to use, for which we stayed with the default 20%
for all examined data sets.
Though our statistically motivated classification approach is relatively robust towards imperfections of the curve-skeleton, there are
still some computation artifacts and properties inherent to curveskeletons that cause problems during the subsequent steps. Therefore, we perform three basic post-processing steps on the computed
skeleton, which we call skeleton normalization:
1. Thin longitudinal structures such as vessels often exhibit gaps in
the skeleton as depicted in Figure 3. Since these gaps hamper the
applicability of the tubiness classifier, we close them by connecting
each end node of the skeleton graph with its next neighbored skeleton point outside the end node’s skeleton segment, if the connecting
line lies completely within the pre-segmented object.
2. When a blobby shape is passing into a tubular structure, the
skeleton segment running through both is not necessarily split up at
the border region between the two shapes. It would be impossible
to classify the blobby shape in isolation as the skeleton region corresponding to the skeleton segment also contains the respective part
of the tubular structure. Moreover, in case the blobby part of the region is dominated by the tubular one, the region would not even be
recognized as blob. Therefore, we split the curve-skeleton into segments not exceeding a certain length as shown in Figure 4. For the
data sets with sizes of 2563 to 5123 we examined, length thresholds
of five to ten voxels gave good results. Due to the curve-skeleton
decomposition, however, the subsequent region merging step gains
in importance. 3. Degenerated skeleton branches shorter than the
length threshold are discarded (pruning) as these may cause problems during the region merging.

is based on the geometry of the curve-skeleton, the fusion process
also takes into account the shape properties of skeleton regions. The
merging steps are as follows:

(a)

(b)

Figure 4: Comparison of the curve-skeleton of an aneurysm blob
before (a) and after (b) the splitting operation. Without splitting the
left green segment ranges from the blob deep into the left vessel
preventing a proper classification of the blob.

(a)

(b)

(c)

Figure 5: Blob merging demonstrated on one lung of the NCAT
phantom [23]. (a) shows the curve-skeleton after normalization, (b)
the corresponding skeleton regions, (c) the regions after fusion.

3.4

Volume Decomposition

The rough pre-segmentation consisting of a few very large segments is not suitable for any shape classification. Therefore, we
have to further decompose the pre-segmented volume into smaller
segments, which more likely exhibit pronounced shapes, before applying the shape classifiers. This decomposition is based on the
previously computed skeleton. In a curve-skeleton as returned by
the potential field algorithm, however, there is no connection between the skeleton segments and individual voxels in the data set.
Thus, we perform a distance transform in order to compute the distance of each voxel to its nearest skeleton segment and assign the
voxel to this segment. The distance transform is done by simultaneous region growing, where each of the skeleton segments is chosen
as a separate seed. In contrast to the hierarchical mesh decomposition presented by Cornea et al. [5] this includes not only surface
voxels but all voxels associated with a skeleton segment, forming
the skeleton region. The region growing process assigns each voxel
that was initially part of the pre-segmentation to such a skeleton
region. The distance map containing the minimal distance of each
voxel to its next skeleton segment is used in subsequent steps.
3.5

Merging of Skeleton Regions

The volume decomposition outputs a heavily over-segmented data
set, since each segment of the normalized curve-skeleton is assigned a skeleton region. Although the over-segmentation is necessary in order to make sure that no region of the decomposed volume contains structures of different shape classes, it also causes the
skeleton regions to loose their initial shape property. For instance,
the splitting of a vessel causes an originally tubular region to become blobby. Therefore, the fusion of skeleton regions into classifiable units is a crucial step of the classification process. One might
get the impression that volume decomposition and region merging
are inverse operations. However, while the volume decomposition

• First of all, very small regions are merged with the neighbor
region with which they share the largest part of their surface,
since those regions cannot be expected to have any meaningful shape. In order to avoid the necessity to manually specify
a minimal segment size, we define each segment, whose size
deviates down from the mean segment size by more than two
times the standard deviation, as too small.
• Tube merging. In order to allow a reliable classification of
tubes, split tubular structures have to be merged as far as
possible, while preventing erroneous fusions with blobs or
surface-like structures. We have chosen the tubiness score as
merge criterion. More precisely, we fuse all pairs of neighbored regions that both as well as the merge result have a
tubiness score above a certain threshold. Note that the tubiness classifier itself is not affected by the splitting of tubular
structures. Instead, the misclassification is caused by the fact
that the splitting significantly increases the blobbiness score.
Therefore, it is reasonable to base the tube merging on the
tubiness classifier. In addition, the merging stops at skeleton
branches, i.e. two regions are not merged, if the connection
point of their skeleton segments is the origin of a third segment. In our examinations, a tubiness threshold of around 0.8
turned out to be the best choice.
• Blob merging. The curve-skeleton of blobby structures is usually heavily branching, which in combination with the skeleton splitting leads to many thin regions that would not be classified as blobby as illustrated for one lung of the NCAT phantom in Figure 5 (a). Such regions have in common that they
share a much larger border with other regions (inner surface)
than with the background (outer surface). We merge regions
with a high inner-surface-to-outer-surface ratio. As a result,
split up blobby structures are usually not fused into a single region, but the remaining regions have regained a blobby shape
and can thus be classified correctly, as visible in Figure 5 (c).
• Quality-based merging. Since one main objective of the previous fusion steps is not to erroneously merge regions of different shape classes, these steps might fail on imperfect skeleton
segments or object surfaces. For instance, a vessel region with
a rough surface due to artifacts in the pre-segmentation may
have a low tubiness score and might therefore not be merged
with neighbored vessel regions. The last fusion step copes
with these situations by trying to improve the clarity of the
classification: two regions are merged when the classification of the resulting shape is less ambiguous than the input
regions’ classifications. We define the ambiguity of a region
R as the quotient of its lowest and highest classification score:
amb(R) :=

min (τ(R), sur f (R), blob(R))
max (τ(R), sur f (R), blob(R))

(10)

4 U SER I NTERFACE FOR S HAPE T RANSFER F UNCTIONS
To be able to intuitively assign optical properties to certain shape
classes as identified by our approach, a sufficient user interface
is required. In this section, we briefly describe such a user interface concept. It allows us to represent the 4-dimensional transfer
function space, given by the classifiers tubiness, surfaceness and
blobbiness as well as the intensity values, in a comprehensible way.
For simplicity, we consider the shape-based transfer function assignment as a two-stage process, where the user first constrains the
shapes to be visualized before defining the desired intensity range.

13

Figure 6: Shape-selection widget. Each shape is represented by a
marker whose position depicts its degree of membership in the three
shape classes. The user has selected three tubinal shapes (red).
data set
angiography 1 / 2
mouse (cardiac)
mouse (torso)

resolution
2563
225 × 178 × 256
360 × 290 × 400

tskel
210 / 176
512
1930

tclass
13 / 9
7
27

Table 1: Statistics for the data sets presented in the results section.
Given are the data set resolution, the times for computation of the
curve-skeleton and for the classification (in seconds).

The normalization of the shape classifiers makes them comparable and allows the user to intuitively constrain the visualization
to certain shape classes. This normalization gives us the opportunity to use an equilateral triangular shape selection widget based on
barycentric coordinates (see Figure 6), similar to the one proposed
by Kindlmann and Weinstein [13] for DTI data. Each corner of the
triangle represents one of the three shape classes. For each computed shape segment we place a marker inside the triangle in such
a way that the marker’s position indicates the likelihood that the
shape class is best represented by one of the three basic shapes. For
the placement of each marker we use the barycentric coordinates
defined by the three normalized shape classifiers. Then a marker
is placed closer to those corners of the triangle that represent the
shape classes the identified segment is best classified as. Thus, in
the first processing step, the user is able to select an arbitrary number of markers to constrain the shape classes to be visualized. In the
second step, a conventional 1D transfer function is used to assign
optical properties to the selected shape classes. For the examination
of data sets with no planar structures, the surfaceness class can be
omitted collapsing the triangle to a line.
5

R ESULTS

We have integrated shape-based transfer functions into the Voreen
volume rendering engine [17] that implements GPU-accelerated ray
casting using OpenGL fragment shaders and have tested our technique with several synthetic as well as real-world data sets, mostly
from the medical domain. All pre-segmentations of the data sets
presented in this section are a result of windowing. We stayed with
our default merging parameters of 0.8 for the tubiness threshold and
0.1 for the maximum inner-surface-to-outer-surface ratio, while adjusting the maximum skeleton segment length to the sizes of the
data sets. User interaction was only required for the specification
of the intensity range used for the pre-segmentation and for the assignment of transfer functions to the shapes, while the intermediate
classification process runs automatically. Preprocessing times for
the different data sets are given in Table 1. All tests were conducted
on a system equipped with an Intel Core 2 Quad Q9550 CPU and
an NVIDIA GeForce GTX 280 graphics board.
Figure 7 depicts the single steps of the classification process for
an angiography data set. The volume decomposition based on the
normalized curve-skeleton yields a heavily over-segmented volume
(Figure 7(b)). Therefore, the initial skeleton regions mostly lack
pronounced shapes and exhibit rather random shape scores, which

14

are distributed almost uniformly over the whole spectrum. The region merging fuses the more than 200 initial regions to nine final
features with pronounced shapes (Figure 7(c)): The aneurysm is
correctly classified as an isolated blob, while the three large vessel
regions (blue, green, ocher) are represented correctly by the leftmost shape cluster in the user interface. The ambiguity of the five
remaining vessel shapes is caused by imperfect skeleton segments,
which lower the tubiness score of their regions. However, these
regions are still clearly distinguishable from the aneurysm.
Figure 8 shows the classification results of two angiography data
sets. In both cases the blobby aneurysms could be easily isolated
from the tubular vessels. We omitted the surfaceness classifier for
all angiography data sets, since they do not contain such structures.
In Figure 9 we applied our technique to the CT scan of a mouse
heart. Though the shape classification is less clear than for the angiographies, the two shape clusters corresponding to the blobby
heart structures and the vessels, respectively, can be easily identified in the user interface. Furthermore, the vessels are mostly correctly separated from the heart, though a slight misclassification is
visible in the third rendering where parts of the vessels have been
classified as blobby. This is due to the fact that these vessel regions
touch the heart structures and are merged with them.
Figure 10 shows the shape-classification of a CT scan of a mouse
lying on a bed. This case is interesting for several reasons. Since
the heart and vessels are filled with contrast agents, their intensity
range overlaps with the bones’ range and can therefore not be separated by a conventional 1D transfer function, a typical situation in
contrast-enhanced CT scans. Furthermore, the bed as a surface-like
structure also shares this intensity range as visible in 10 (a). The
shape-classification shown in 10 (b) allows a separation of the heart
from the bones and vessels as well as the bed. We consider the classification of the elbows to be correct, since though they are part of
a longitudinal structure the elbows themselves are of blobby shape.
The blobby classification of parts of the shoulder bones, however,
is an error that is caused by gaps in the skeleton in that regions. In
10 (c) the classification has been manually refined through the user
interface by removing the blobby structures outside the heart.
6

C URRENT L IMITATIONS

AND

F UTURE W ORK

A principal limitation of our approach is the dependency on a
proper masking of the volumetric structures that are to be shapeclassified. While such a masking might be tedious in the general
case, creating a sufficiently precise pre-segmentation for volumetric
scans with contrast agents, which are a typical use-case for volume
visualization in the medical domain, is possible with little effort by
windowing.
If an adequate masking is provided, errors or ambiguities in the
shape classification are mainly caused by incomplete merging operations, since small regions are less likely to exhibit a pronounced
shape than larger ones. On the other hand, lowering the merge
barrier increases the risk of erroneously fusing shapes of different
classes. We want to investigate whether a more global merge strategy, which does not focus on the local neighborhood of regions but
rather tries to increase the overall clarity of the classification, can
improve this issue. Furthermore, we currently only use information
from level 0 of the skeleton hierarchy, the “core skeleton”, while incorporating low divergence points and high curvature points added
in levels 1 and 2 might help to refine the region merging.
A further issue is the significant time consumption of the shape
classification and especially the skeleton computation, which do
currently not allow an interactive parameter tuning. While we are
positive that a more efficient implementation can achieve interactive results for the merging and classification steps, it should also
be investigated whether a simpler skeletonization algorithm could
possibly give similar results while having less demanding runtime
requirements compared to the potential field technique.

(a)

(b)

(c)

Figure 7: Classification workflow for the angiography data set shown in Figure 8(b). Subfigure (a) displays the normalized curve-skeleton,
while (b) and (c) present the skeleton regions before and after merging along with the corresponding shape distributions.

7

C ONCLUSION

When exploring volumetric data, the user is rather interested in visually inspecting features than extracting them. We have introduced
shape-based transfer functions in order to blur the border between
simple but limited classification and powerful but costly segmentation techniques. In contrast to previous approaches towards shape
classification in volume data, which perform a voxel level classification, the proposed technique does not require the user to interpret
complex histograms but provides him/her with a manageable set
of shape-classified volumetric features and offers an intuitive interface for the assignment of optical properties. Since we consider
shape, texture and size as independent properties of volumetric features, we believe that a combination of our approach with texturebased [3] and size-based [6] [8] classification schemes might be
worth investigating.

[11]

[12]

[13]

[14]

[15]
[16]

ACKNOWLEDGEMENTS
This work was partly supported by grants from the Deutsche
Forschungsgemeinschaft (DFG), SFB 656 MoBil M¨unster, Germany (project Z1). The presented concepts have been integrated
into the Voreen volume rendering engine (www.voreen.org).
R EFERENCES
[1] T. Binford. Visual perception by computer. In IEEE Conference on
Systems and Control, 1971.
[2] H. Blum. Biological shape and visual science. Theoretical Biology,
38:205–287, 1973.
[3] J. J. Caban and P. Rheingans. Texture-based transfer functions for
direct volume rendering. IEEE TVCG, 14(6):1364–1371, 2008.
[4] N. D. Cornea, D. Silver, and P. Min. Curve-skeleton properties, applications, and algorithms. IEEE TVCG, 13(3):530–548, 2007.
[5] N. D. Cornea, D. Silver, X. Yuan, and R. Balasubramanian. Computing hierarchical curve-skeletons of 3D objects. The Visual Computer,
21(11):945–955, 2005.
[6] C. D. Correa and K.-L. Ma. Size-based transfer functions: A new
volume exploration technique. IEEE TVCG, 14(6):1380–1387, 2008.
[7] C. D. Correa and D. Silver. Dataset traversal with motion-controlled
transfer functions. In IEEE Visualization 2005, pages 359–366, 2005.
[8] M. Hadwiger, F. Laura, C. Rezk-Salama, T. H¨ollt, G. Geier, and T. Pabel. Interactive volume exploration for feature detection and quantification in industrial CT data. IEEE TVCG, 14(6):1507–1514, 2008.
[9] S. Har-Peled. A practical approach for computing the diameter of a
point set. In SCG ’01: Proceedings of the 17th annual symposium on
Computational geometry, pages 177–186. ACM, 2001.
[10] M. Hilaga, Y. Shinagawa, T. Kohmura, and T. L. Kunii. Topology
matching for fully automatic similarity estimation of 3D shapes. In

[17]

[18]

[19]

[20]

[21]

[22]

[23]

[24]

[25]

SIGGRAPH ’01: Proc. of the 28th annual conference on Computer
graphics and interactive techniques, pages 203–212, 2001.
J. Z. Huawei Hou, Jizhou Sun. Moment based transfer function design
for volume rendering. In Grid and Cooperative Computing: Second
International Workshop, pages 215–218, 2003.
G. Kindlmann and J. W. Durkin. Semi-automatic generation of transfer functions for direct volume rendering. In VVS ’98: Proc. of the
1998 IEEE Symposium on Volume Visualization, pages 79–86, 1998.
G. Kindlmann and D. Weinstein. Hue-balls and lit-tensors for direct
volume rendering of diffusion tensor fields. In IEEE Visualization 99
Proceedings, pages 183–189, 1999.
J. Kniss, G. Kindlmann, and C. Hansen. Multidimensional transfer
functions for interactive volume rendering. IEEE Transactions on Visualization and Computer Graphics, 8(3):270–285, 2002.
M. Levoy. Display of surfaces from volume data. IEEE Computer
Graphics and Applications, 8(3):29–37, 1988.
D. Macrini, K. Siddiqi, and S. Dickinson. From skeletons to bone
graphs: Medial abstraction for object recognition. IEEE Computer Society Conf. on Computer Vision and Pattern Recognition, 0:1–8, 2008.
J. Meyer-Spradow, T. Ropinski, J. Mensmann, and K. Hinrichs.
Voreen: A rapid-prototyping environment for ray-casting-based volume visualizations. IEEE Computer Graphics and Applications,
29(6):6–13, 2009.
D. Patel, M. Haidacher, J.-P. Balabanian, and M. E. Gr¨oller. Moment
curves. In Proc. of the IEEE Pacific Visualization Symposium 2009,
pages 201–208, 2009.
H. Pfister, B. Lorensen, C. Bajaj, G. Kindlmann, W. Schroeder, L. S.
Avila, K. Martin, R. Machiraju, and J. Lee. The transfer function
bake-off. IEEE Computer Graphics and Appl., 21(3):16–22, 2001.
S. M. Pizer, G. Gerig, S. C. Joshi, and S. R. Aylward. Multiscale medial shape-based analysis of image objects. Proceedings of the IEEE,
91(10):1670–1679, 2003.
D. Reniers, A. Jalba, and A. Telea. Robust classification and analysis
of anatomical surfaces using 3D skeletons. In Eurographics Workshop
on Visual Computing for Biomedicine, 2008.
Y. Sato, C.-F. Westin, A. Bhalerao, S. Nakajima, N. Shiraga, and
S. Tamura. Tissue classification based on 3D local intensity structures
for volume rendering. IEEE TVCG, 6(2):160–180, 2000.
W. P. Segars. Development and Application of the New Dynamic
NURBS-based Cardiac-Torso (NCAT) Phantom. PhD thesis, University of North Carolina at Chapel Hill, 2001.
P. Sereda, A. Vilanova Bartroli, I. W. O. Serlie, and F. A. Gerritsen. Visualization of boundaries in volumetric data sets using LH histograms. IEEE Transactions on Visualization and Computer Graphics,
12(2):208–218, 2006.
S. Takahashi, Y. Takeshima, and I. Fujishiro. Topological volume
skeletonization and its application to transfer function design. Graphical Models, 66(1):24–49, 2004.

15

(a)

(b)

Figure 8: Shape-classified volume renderings of two angiography data sets, each containing an aneurysm. The thumbnails show renderings
generated with a conventional 1D transfer function, for comparison.

(a)

(b)

(c)

Figure 9: Application of the proposed classification technique to a CT scan of a mouse heart. (b) and (c) show renderings of the classification
result from two perspectives along with the corresponding shape distribution. The red-labeled heart structures correspond to the shapes
selected in the user interface. The rendering in (a) was generated with a conventional 1D transfer function.

Figure 10: Shape-classified CT scan of a mouse lying on a bed. (a) was rendered with a conventional 1D transfer function. In (b) the
bones/vessels are rendered semi-transparently, while the heart and the bed have been colored independently. The blobby structures (red) have
been selected in the user interface. (c) shows a further refined classification where the blobby features outside the heart have been selected in
the user interface in order to assign the same optical properties that have been chosen for the bones/vessels.

16

