Dense Flow Visualization Using Wave Interference
Victor Matvienko∗

†
Jens Kruger
¨

Interactive Visualization and Data Analysis Group (IVDA)

IVDA, DFKI, Intel VCI, and SCI

A

B

C

D

Figure 1: This image shows spiral fields visualized at different frequencies with our method (A & D) and LIC (B & C) for comparison.

A BSTRACT
Dense flow visualization and streamlines are among the most popular methods in numerous applications of scientific visualization.
Because very few works synthesize the benefits of these approaches
into one framework, we propose a hybrid technique. In this work,
we present a novel method of dense flow visualization that produces high contrast images (typical of streamline approaches), with
manageable spatial frequency.
We begin by introducing a notion of a streamline thickness function and thickness wave sources, and then compute the resulting
image as a coherent wave interference pattern. We show that this
problem is equivalent to finding the dominant eigenvector of a sparse
matrix and employ the power iterations numerical scheme to demonstrate an efficient parallel implementation. We conclude by discussing possible quality improvement strategies and extensions of
our method to other domains, including 3D flows.
Index Terms: I.3.0 [Computing Methodologies]: COMPUTER
GRAPHICS—General; I.3.m [Computing Methodologies]: COMPUTER GRAPHICS—Miscellaneous;
1 I NTRODUCTION
Vector field visualization marks one of the cornerstones of scientific visualization and they have demonstrated their practical use in
various scientific and engineering disciplines. Within the realm of
available methods, dense vector field visualization techniques are
known for their ability to give an excellent quick overview of the
entire vector field. Producing a good dense visualization, however,
does require a careful choice of methods and parameters. Considering Cabral and Leedom’s original LIC work [1], there are already
a number of available parameters, such as the number of integration steps, the choice of noise, or the filter kernel. Later extensions
that dealt with improving quality added more methods to choose
from and parameters to set (see Section 2 for details). A different
approach to generating a global overview picture of a vector field
∗ e-mail:

victor.matvienko@dfki.de

† e-mail:jens.krueger@dfki.de

IEEE Pacific Visualization Symposium 2012
28 February - 2 March, Songdo, Korea
978-1-4673-0866-3/12/$31.00 ©2012 IEEE

is the use of automatic streamline placement approaches. Based on
a variety of parameters, such as topological features, line length,
or line distance, integral curves are computed and drawn as lines
of constant width (more details are given in Section 2). With the
proper choice of seed points, these methods can be very effective in
visualizing important features in the flow.
Both texture-based methods and streamline placement approaches
have advantages and disadvantages. In principle, texture-based methods, in particular LIC, are straightforward to implement but relatively
expensive to compute, although parallel implementations are simple.
Nonetheless, they require a number of post-processing operations
to achieve good contrast and feature discrimination. On the other
hand, streamline placement approaches automatically produce highcontrast images and the core operations—the computation of the
integral curves and the rendering of the lines—are both simple and
computationally cheap. However, the computation of the proper
seeding points of the lines can be very complicated and computationally intense. Depending on the method, parallel implementation
may not be as straightforward as for the LIC method. Finally, since
the streamlines are not really dense, improper seed point selection
may result in important flow features being lost in the visualization.
In this work, we propose a novel technique for dense flow visualization that combines the advantages of both texture-based methods
as well as streamline placement approaches, while avoiding most
of their drawbacks. The results of our method are high-contrast
images with controllable spatial frequency (see Figure 1). Relying on a fully automated and well-studied eigenvalue computation
scheme, we managed to create a simple-to-use framework, requiring
only two intuitive parameters: the base streamline line thickness
and thickness variation. The utility of an easy and adaptive control of the spatial frequency (related to line thickness) makes our
method stand out among the LIC-based and streamline techniques.
Unlike most texture-based visualizations, our results are not fuzzy
and can be easily converted to black and white vector graphics for
further post-processing. Depending on the choice of parameters,
imagery between two types of extrema can be achieved: almost
equally spaced streamlines that branch in areas of diverging flows
and non-branching streamlines of varying thickness. In summary,
our novel method has the following properties:
• the method generates dense, high-contrast images

129

• it allows for adaptive spatial frequency control
• it requires few, intuitive parameters
• it is based on a straightforward mathematical framework
• it lends itself to a simple parallel implementation
To the best of our knowledge, this is the first work to use a
distance-based wave interference concept for flow visualization.
While this is not an advantage as such, we hope to pollinate the field
with this new idea to spawn other exciting new ideas.
The remainder of this paper is structured as follows: In the following section we give an overview of the previous work in vector
field visualization with a special focus on texture based methods and
streamline placement. In Section 3, we give a step-by-step explanation of our method. In Section 4, a highly scalable and memory
efficient numerical scheme is presented for obtaining the solution.
In Section 5, we explore the results and consider the influence of the
method’s parameters. Finally, we conclude with a discussion of our
contribution and describe future research directions.
2

P REVIOUS W ORK

According to the state of the art report by Post et al. [10], vector
field visualization methods are generally classified into four categories: direct, texture-based, geometric, and feature-based methods.
Partitions-based techniques can be considered a fifth category, as it
has been recently proposed by Salzbrunn et al. [13]. In this review,
we mainly concentrate on the two classes most relevant for our work:
the dense flow visualization (LIC-like) approaches and the subset
of geometric methods comprised of automatic streamline placement
algorithms. Alternative vector field visualization techniques are not
a major concern of this paper. For a broader overview, we refer the
interested reader to the above mentioned S.T.A.R. or the follow-up
work by Laramee et al. [7].
The texture-based methods have been around since the early
1990’s. Originating from the pioneering work by Van Wijk [19],
and Cabral, and Leedom [1], they proven effective flow analysis in
a wide variety of fields. Numerous improvements have been proposed to the original techniques, focusing on extensions to higher
dimensions (3D LIC [12], LIC on surfaces [4]) efficient computations [16], employment of fast GPU computations [23], and quality
improvements [9].
One of the perceptional challenges introduced with common
dense visualization techniques is the low contrast of the output and
the presence of underlying noise. To improve the image quality
while keeping the computational expenses at bay, Okada and Lane
[9] introduced the concept of double or manifold LIC computations.
This method was then revised and refined by Weiskopf [24] and
Hlawatsch et al. [5]. The basic idea is to apply the LIC algorithm
multiple times, using the filtered output of the previous LIC pass
as input “noise” for the next pass. While this leads to very highquality LIC images, the introduction of multiple passes increases the
importance of careful parameter adjustment, including the choice
of the initial noise texture. To cope with this problem, a thorough
analysis of the influence of various LIC parameters on the signalprocessing level was performed by Stalling and Hege [15], as well
as Stalling in his thesis [16].
The major challenge of streamline visualization inherent to all
sparse methods is a trade-off between visual cluttering and the coverage of the field. Consequently, the problem of optimal streamline
placement has been of great practical interest. Two common solutions to deal with it can be classified as the feature-based and the
density-based approaches. The purpose of the first one, first proposed by Verma et al. [22], is to draw attention to certain regions of
interest, usually critical points. To achieve a good visualization in
those areas, they provide templates for seeding streamlines around

130

different types of critical points, which have to be localized and classified beforehand. Generally, this necessity for the advance segmentation of the field into regions of interest is application-dependent
and might limit the applicability of the feature-based methods as
pointed out by Chen et al. [2].
Density-based approaches seed streamlines by managing the
placement density throughout the whole image. High-quality results are achieved with the method of Turk and Banks [18], who
proposed to use a low-pass filtered image as a measure of density
and a randomized optimization process to achieve on average the predefined density value. Less computationally expensive techniques
include the work of Jobard et al. [6], which separates streamlines
by estimating the placement density as Euclidian distance between
them and Chen et al. [2] who define a streamline similarity distance,
which is related to our thickness function but used to place the lines
rather than generating a distance field. Chen et al. demonstrated
that their method gives better visual quality compared to the work
of Jobard et al., resulting in a smaller angular error of the flow reconstructed from visualization. The most advanced and complex
approaches in the topology-based set of methods can be found in
recent works by Liu et al. [8] and Wu et al. [25].
In our work, we propose a hybrid technique, which merges streamlines and dense visualization. To our best knowledge, there exist
relatively few works that explore the possibilities of such a fusion
approach. One notable exception is the work of Verma et al. [21],
which relates LIC to streamlines. They suggest the idea of a smooth
transition from LIC images to streamline visualization and vice
versa, and show that it can be achieved by mapping a 1D texture on
a line to give a streamline visualization a more LIC-like look, and
on the other hand, to make LIC look like streamlines they utilize a
black image with few white texels as noise input.
Another interesting approach has been proposed by Taponecco
and Alexa [17] on vector field visualization with Markov random
fields. While it is completely different from our method, their results
a similar to our high-contrast images.
3

M ETHOD DESCRIPTION

As our method relies on the notion of the distance between streamlines, or equivalently, the thickness of a streamline, we first need to
find a formal definition for this property. It turns out this notion of
thickness of a streamline is not defined in calculus and is only used
informally when describing visualizations. Consequently, we start
with the introduction of an affinity function between image pixels,
intuitively corresponding to streamline thickness. Then we represent
the intensity of each pixel in the desired visualization image as a sum
of coherent sinusoidal waves propagating from its neighborhood in
the space induced by the constructed function. Finally, we propose
a highly scalable iterative numerical scheme for finding the optimal
image conforming to the derived model.
3.1

Motivation

The result of virtually any dense flow visualization technique is an
image with the image gradient related to the underlying field, since—
as known from image analysis—the most important information
about the image is provided by the edges. In fact, nearly flawless
reconstruction of the entire image is possible given this edge information (see Elder [3] for the details on this topic). Particularly in
flow visualization, the direction of the vector field perceived from
the picture is mainly orthogonal to the gradient of the image, assuming that the contrast of the image (i.e., the gradient magnitude) is
high enough.
The natural idea would be to use this property directly, synthesizing a single scalar field with a gradient orthogonal to the vector
field. However, this scalar field is never computed by any of the
existing methods and indications suggest that it is extremely difficult to compute in the general case. Most known dense vector field

(DVF) visualization techniques only approximate this field, either
through the introduction of some kind of angular error between
the gradient and the vector field or by creating regions with zero
gradient and thus no information about the flow. Commonly used
dense techniques such as LIC distribute this error randomly over the
whole image as a direct result of the noise input, whereas streamline
placement approaches and other sparse techniques can be seen as
introducing zero gradient everywhere except the streamline edges.
We propose a novel way to model the image consisting of cosine
waves orthogonal to the flow, as well as the process to achieve the
approximation of such an image.
3.2

does not necessarily pass through the center of the other pixel (see
Figure 3). Still, as the region bounded by the two streamlines is
small (i.e., the streamlines are close together) the convoluted intensity values are highly correlated if the average width of this region
is smaller than the size of the noise texels.

B

Method Outline

C

The proposed method can be broken down into a pipeline of independent steps, pictured in the Figure 2.

precompute streamline integrals

set up complex affinity matrix

find the dominant eigenvector
of the affinity matrix

apply thresholding and take
the real part of the eigenvector

A

Figure 3: Streamlines traced from pixels A and B, though not the
same, sweep the same region in the texture, while streamline traced
from C sweeps a completely different region.

In our approach, we suggest a function to measure the signed
distance between pixels orthogonal to the flow field, which can be
thought of as a minimum thickness in pixels of a rendered streamline segment that covers the centres of two pixels. We do this in
two computational steps, first tracing a streamline in both directions
of the flow starting at each pixel, similar to the LIC method. The
streamlines are, thus, approximated by polylines. Second, we estimate the line thickness di j (see Figure 4 ) between two pixels Ai
and A j using the signed area Si j of a small polygon, bounded by the
traced streamlines li and l j as in Equation 1,

Figure 2: The main steps of the proposed flow visualization method.

Starting with a vector field and a regular grid, we compute an
affinity function between cells of the image grid, which we call the
relative thickness. This process—discussed in detail in the next
section—involves the computation of the area bounded by streamlines and can be done efficiently by pre-computing certain line
integrals. In essence, the modelling phase of the method exploits the
relative thickness between any two pixels of the image in order to
build a sparse matrix, which describes the propagation and interference of cosine waves, in a network of paths related to the thickness
function. By the nature of this function, such waves result in black
and white flow lines in the image space at least locally close to the
wave source. Next, representing the image as a set of independent
wave sources that are placed in the center of pixels, we search for a
globally consistent image by making their phase coherent. We will
show that the dominant eigenvector of the constructed matrix is the
best approximation of the desired image, and we employ the power
iteration scheme [11] to compute it. Finally, we refine the obtained
result by separating the frequency and the amplitude parts of the
solution.
3.3

Basic Ideas

The formulation of the thickness function is very straightforward
and is inspired by the Line Integral Convolution [1] method. The
essential fact about this DVF visualization technique is that any two
pixels in the resulting image are correlated if they belong to the same
streamline, i.e. two pixels on the same streamline should have the
same color.
In LIC, this is approximated by streamlines traced from the centers of those pixels. It is obvious that for any but trivial fields, the
streamlines starting from different pixels centres do not exactly follow the same paths, because the streamline starting in one pixel

Figure 4: The relative streamline thickness di j for pixel centres Ai and
A j is measured as the average height of the pictured polygon.

di j =

2Si j
|li | + |l j |

(1)

where |li | stands for the length of the streamline li .
While this heuristic only approximates the distance between
streamlines if the change in distance between traced segments is low
compared to the image grid size, it has proven to be sufficient for
our purpose, and can be efficiently computed.
It is worth noting that there exists a number of alternative definitions for the thickness, which might also be used in our framework
(e.g., the averaged signed distances from stream line li to point A j
and from streamline l j to point Ai ). During our tests, however, we
found, that this method does not improve the results that we get with
the definition given in Equation 1, and consequently, we used the
more computationally efficient approach (see details below).
Using Equation 1 and the fact that streamlines li and l j do not
intersect, the considered polygon is simple and its area S can be
computed with the following formula, commonly known from com-

131

In general, this property degenerates to an inequality unless the
distance between streamlines is constant. As we are only interested
in a very small neighborhood (typically with the radius of one pixel),
we can assume a constant distance and use the approximate equality.
With this approximation we define a streamline image u, having
intensity ui in i-th pixel as in Equation 2 (see Figure 5 right)
ui = cos(ϕdki )
where thickness of lines and spacing between them is
ϕ being a user-defined parameter.

(2)
ϕ
π

pixels with

3.4

Figure 5: On the left, the set of all pixels with relative thickness to the
green point less than a pixel size, underlaid by the LIC image of the
same field is shown. The right depicts a distance field computed for
the spiral field from a single green point. Outside a local neighborhood,
the field is increasingly distorted. Please note that the actual method
uses a much smaller neighborhood, with a radius about the size of
one pixel.

putational geometry:
S=

1 n
∑ (xi yi+1 − xi+1 yi )
2 i=0

where (xi , yi ) are the points of the polygon and (x0 , y0 ) =
(xn+1 , yn+1 ).
The advantage of this formulation is that it allows the computation
of the thickness function of any two pixels Ai and A j given the
boundary points for li and l j and the precomputed sums over li and
l j without computing the sum over the whole polygon. Indeed, let
P = {Pk } be the ordered set of points of li , and Q = {Qk } is the
ordered set of points of l j . Also for any two points M = (x, y) and
N = (u, v) we define δ (M, N) = xv − uy. Then,
S=

1
2

n−1

Flow Visualization With Relative Thickness And
Wave Interference
In this section, we propose a model for the flow visualization image
with an image gradient that is orthogonal to the flow field using
Equation 2 as an approximation of a small region (comparable to the
size of a pixel ) of the target image. This equation can be interpreted
as following: the pixel intensities in the neighborhood of k-th pixel
are computed as the amplitude of a cosine wave, emitted at Ak
propagating in the space induced by thickness function d. Figure 6
illustrates a grid of 8x8 independent wave sources producing 64
independent regions, each locally approximating a 64x64 square
segment of the visualization image. Each segment is computed using
the formula in Equation 2 where k denotes the central pixel of the
segment and i all other pixels of the segment. Using a cosine wave,
we create a black and white pattern varying in the same direction as
the described thickness di j .

n−1

∑ δ (Pi , Pi+1 ) + δ (Pn , Qn ) + ∑ δ (Qi+1 , Qi ) + δ (Q0 , P0 )

i=0

i=0

Or, keeping in mind that δ (M, N) = −δ (N, M) and defining S[P] =
∑n−1
i=0 δ (Pi , Pi+1 ):
S=

1
(S[P] + δ (Pn , Qn ) − S[Q] + δ (Q0 , P0 ))
2

Thus, for the computation of the area Si j , the only inputs which are
required are: the integral sums S[P] and S[Q] for the lines li and l j ,
respectively, as well as starting and ending points P0 , Pn , Q0 , Qn .
Let us now explore some useful traits of the constructed function.
Its key benefit is that it can be employed as a simple means to check
if two pixels belong to the same streamline. The relative thickness
di j of such pixels Ai and A j is close to zero, since basically the
area between overlapping streamlines li and l j is measured. It is
important to mention that the closer given points are to each other
compared to the integrated lengths |li | and |l j |, the more accurate
the computation of di j is. As shown in Figure 5 left, choosing |li |
and |l j | too small may cause significant deviation from zero for the
points that are far apart. Nevertheless, the constructed function might
find its applications, for example, in a computationally cheap (not
requiring any vector field integration apart from distance calculation)
algorithm for multiple streamline tracing, that—in a greedy manner—
adds a new pixel to the line with smallest thickness relative to the
pixels on the line.
Another property, which is naturally associated with the line
thickness is that di j = dik + dk j for any three pixels Ai , A j , and Ak .

132

Figure 6: Image of a drain field consisting of 64 wave blocks with
different phases on each block. Again, please note, actual neighborhoods used in our approach are much smaller and this image uses
large regions only for illustration purposes.

To produce a globally consistent image, we need to make these
wave sources coherent. For this reason, we introduce a phase shift
ψk for each k in Equation 3:
ui = cos(ϕdki + ψk )

(3)

And as dii = 0, it immediately follows that:
ui = cos(ψi )

(4)

The problem that we try to solve in the rest of this section is to
find the unknown phase shift ψi or at least to come up with an
approximation to it.
First, let us extend Equation 3 to the complex plane, setting
vk = eıψk and Aki = eıϕdki . The target image u becomes the real part
of the complex image v (i.e., ui = ℜ[vi ]). It is worth noting that using
the imaginary part is also possible and equivalent to employing a
sine function in Equation 3 instead of cosine. Now Equation 3 can
be rewritten as:
vk = Aki vi

(5)

Instead of forcing this requirement to be true for every k and i, we
relax it by requiring the pixel intensity vk to be the weighted sum of
the incoming waves from its neighborhood as in Equation 6:
n

vk =

(6)

∑ wki Aki vi

i=1

with some non-negative weights wi j .
To compensate for the inaccuracy in the distance d computation,
we set the weights wi j = 0 if i ∈
/ N( j) and ∑i∈N( j) wi j = 1 for a
small neighborhood N( j) of j-th pixel. In our experiments, N( j)
is a taken to be a 3x3 square stencil centred in the j-th pixel with
1
w j j = 12 and wi j = 16
for non-zero entries. Further research on the
adaptive computation of weights might be of interest.
The introduction of neighborhood weights makes the intensity of
a pixel consistent with the intensities of its neighbors. Moreover,
this simplification leads to n instead of the original n2 equations (n
being the size of image v).
With a definition of matrix Hi j = wi j Ai j the Equation 6 can be
rewritten in a more compact form as
Hv = v.

(7)

One straightforward interpretation of Equation 7 is that the target
image v is the eigenvector of a complex matrix H, corresponding to
the eigenvalue equal to one. Although there is no guarantee that a
unit eigenvalue of H exists in general case, the largest eigenvalue
and the corresponding eigenvector might be of a great interest for
our visualization purpose. The motivation for it is—as we show
below—that with some technical restrictions on weights w, all the
values of H are real numbers in the range [0, 1] with at least one
value greater or equal to 0.5.
Indeed, since di j = −d ji , then Ai j = A ji (where (.) stands for
complex conjugate), meaning that A is a Hermitian matrix. The
choice of wi j = w ji makes H Hermitian, and consequently, it has
only real eigenvalues. Gershgorin’s circle theorem [20] can be used
to determine their range:
For any matrix B = [bi j ] ∈ Cnxn and any eigenvalue λ of B there
n

exist k such that |λ − bkk | ≤ Rk where Rk =

∑ |bik | − |bkk |.
k=1

Since the weights are normalized such that ∑nj=1 wi j |ai j | = 1
holds for each matrix row i, the choice of wii = 0.5 results in Ri = 0.5.
Thus, eigenvalues of H are real and non-negative, obtaining the
values in the range [0, 1]. Moreover, at least one eigenvalue is greater
or equal than 0.5 since the trace of the matrix is 0.5 · n.
In our method, we suggest using the eigenvector corresponding
to the largest eigenvalue of H as the approximation of the desired
image. The computation can be summarized as follows: we search
for the optimal solution where the interference of the emitted wave
in each pixel with the waves from its neighborhood is constructive
and eigenvalue λ can be thought of as an amplification factor.

4

S CALABLE N UMERICAL S OLVER I MPLEMENTATION

The constructed in the previous section model results in a large
sparse matrix. For instance, given a typical image of 210 x210 pixels
the matrix numbers 240 entries with only 220 x |N| non-zero elements
where |N| is the size of the considered neighborhood. To find the
eigenvector corresponding to the largest eigenvalue, we propose to
use the power iteration method in the following form:
v(k+1) = c(k) Hv(k)
with the normalization factor c(k) = ||Hv1(k) ||
∞
For the sake of completeness, we provide here the brief justification of this method, whereas for the detailed discussion we refer the
reader to the excellent textbook by Quateroni et al. [11]. Since H is
a Hermitian matrix, it has a full system of orthogonal eigenvectors
ei with corresponding real eigenvalues λi , assuming that eigenvalues
are ordered in a decreasing sequence such that λ1 ≥ λi . This means
that for any vector v there exists an expansion v = ∑ni=1 vi ei . Since
ei is an eigenvector and Hei = λi ei for any power k of matrix H it
holds that:
Hkv =

n

n

i=1

i=2

vi λik
e + e1 .
k i
1 λ1

∑ λik vi ei = v1 λ1k ∑ v

Thus, for k → ∞ the method converges to a multiple of e1
Although this method is usually considered if there exists a dominant eigenvalue such that strict inequality |λ1 | > |λi |∀i holds, in our
case this restriction is not necessary. Since all the eigenvalues are
real and non-negative, there cannot be two eigenvalues with opposite
sign and same absolute value, so the method cannot diverge. In fact,
if two maximum eigenvalues are equal the method still converges to
a linear combination of their corresponding eigenvectors, which is
still an eigenvector.
Caution should be exercised in the initialization step of the iterative solver, since the starting vector v(0) must necessarily contain a
e1 component. Therefore, a good choice is a random vector.
The considered scheme exhibits geometric convergence with a
rate equal to the ratio of sub-dominant and dominant eigenvalues
of matrix H. The complexity of each iteration is linear in terms
of the image size. Hence, the overall asymptotic complexity is
the product of the two above. In practice, the iteration time in the
parallel implementation is about (1ms) and mainly bounded by the
amount of available memory.
While further speed improving modifications might be possible, the main advantage of the chosen method is that compared to
more sophisticated techniques for the eigenvector computations, like
QR-decomposition, this scheme is extremely simple and memoryefficient, since it requires storing only the original matrix H and the
latest solution v(k) . Moreover, it involves only one (sparse) matrixvector multiplication which allows a fast parallel implementation
on the modern GPU hardware. Our CUDA-based realization of
the solver on a GeForce GTX 580 video card computes a typical
512x512 image in about 20 seconds, taking roughly 20,000 iterations for convergence. After less than half a second, however, a
meaningful intermediate result is generated (see Figure 7 left). As
the runtime of our algorithm scales linearly with the size of the
image, it can also compute images for larger 2D vector fields in
reasonable time. However, for an application to 3D vector fields
more optimizations such as multi-grid approaches may be necessary.
5
5.1

R ESULTS
Interpretation

After the computation of the complex vector v, the target real-value
image u has to be obtained. To get the desired phase image we

133

Figure 7: The left image shows an intermediate result after about 0,5
seconds while the right image depicts the fully converged solution
after roughly 20 seconds on our target machine. It is evident that the
early version of the image is a close approximation of the final result.

Figure 9: Variation in frequency in the image obtained with a large
1
integration length (1024 pixels) and the base frequency of 20
. The
red line segments show the actual streamlines. Note that discrepancy
between the real streamlines and the image lines around the branching points. Also note, that regions of high frequency are better aligned
with streamlines than low-frequent regions.
Figure 8: On the left, an amplitude image on one of the early iterations
is shown. On the right, another early iteration with the corresponding
amplitude map overlay (6% threshold) is depicted. The image reveals
that streamline branching points as well as boundaries are regions
of low amplitude, which can be interpreted as a relative visualization
certainty.

represent v in the polar form, obtaining the amplitude part r and
phase part ψ such that vi = ri eıψi .
The amplitude part is pictured in Figure 8 left. It can be thought
of as a confidence map of the achieved wave representation, since
it represents the summed amplitudes of the wave emitted in the
pixel and all incoming waves from its neighborhood, allowing to
distinguish between constructive and destructive interference. If the
amplitude is low, the incoming waves and the emitted wave are not
phase-coherent and thus cancel each other. It means that the wave
representation in this point is not consistent with the neighbourhood
and thus is not usable for flow visualization. On the other hand, if the
amplitude is high at a given point, one can argue that the accuracy
of visualization is high, because the phases of the waves from the
neighbourhood agree in this pixel.
For example, Figure 8 right illustrates that the amplitude stays
low close to the image boundary as well as at the points where
streamlines split. This indicates the regions where the flow field
normal disagrees with the image gradient.
For our final visualization images we first threshold the amplitude
factor, setting ri = ri , and then taking the real part of the image.
Since v is normalized with ||.||∞ norm, the resulting image has
amplitudes of zero and one. Choosing the imaginary part of the
image is of course possible and will result in the simple global phase
shift of the result by π2 .

134

Figure 10: The top vortex from the previous figure represented with
higher frequency (ϕ = 17 , L = 1400). Note a better representation of the
swirling behavior. The red line segments show the actual streamlines.

5.2

Parameters and the Pattern Frequency Control

The considered method allows the user to control two parameters:
the length L of the traced line segments li and the base frequency ϕ.
While the short integration length allows the frequency to be kept
slightly varying around the base frequency at the cost of introducing
black and white line branching, increasing the length causes significant deviations from the base frequency, while taking into account
long-term flow behavior as in Figure 9.
The choice of parameters L and ϕ can be adapted on a per-pixels
basis (e.g., according to the topological information about the field).
Introducing a position-dependent ϕi j might be useful for employing
lower frequency in simple laminar regions, whereas the turbulent

regions would have higher spatial frequency and thus more details.
For an example of the advantage of the high-frequent representation,
compare the vortex representation in Figure 10 to the top vortex in
Figure 9. Clearly due to the high contrast of the results, using high
frequencies might lead to more prominent aliasing artefacts while
downsampling (compared to e.g., LIC images).
Also, although the idea to use ϕi j as a means to visualize an
additional scalar function is tempting, we would recommend to use
color instead, since the frequency in the given point can be altered
in the optimization process, due to influence of parameter L.
Using an adaptive L might increase the accuracy of representation,
since different lengths seem to be appropriate for different flow types.
As mentioned, smaller integration lengths create less variation in
frequency for strongly diverging regions at the cost of introduction
of streamline branches in the divergent regions. Since the vector
field representation is distorted in the vicinity of these branches, it is
probably desirable to have a frequency variation as opposed to many
streamline branches. On the other hand, in the turbulent regions,
consistent high frequency pattern is necessary because the size of
represented flow features is small. For simple laminar flows with
low divergence, the effect of L is much less visible. In other words,
since the choice of L determines the time interval on which the flow
is integrated, one should decide (possibly locally for every pixel),
whether his is interested in the long-term or short-term flow behavior.
Figure 11 illustrates the how (constant) short integration length can
be used to picture the turbulent region. For comparison, we provide
two LIC images of the same field with short and long kernels, for
visualizations of turbulent and laminar regions, correspondingly.
In order to limit the displayed frequency variation for large L and
avoid aliasing in the resulting image, we rescale ϕ in Equation 3,
applying adaptive smooth thresholding F( f ) such that F(ϕdi j ) < fN
where fN is Nyquist frequency. We define the threshold through a
2
sigmoid function, F( f ) = e−8 ln(3)
f +1 − 1, assuming that f is normalized such that FN = 1.
In our visualization system, we implemented two sliders to control the two parameters L and ϕ described above for the user to
interactively explore the parameter space. While it does take several
seconds for the method to converge, we display the intermediate of
the solver, resulting in instant feedback to the user.
We have not noticed any significant effect of parameter values
L and ϕ on the run time of the numerical optimization process.
The duration of the pre-computation stage, however, is linearly
dependent on the L. We trace all the streamlines in parallel in this
stage, and thus, their length is the major performance factor. The
time of the pre-computation stage is negligible compared to the time
of convergence of the power iteration scheme.
6

D ISCUSSION

In this section we will discuss the drawbacks of our method and
propose means to mitigate them.
One downside of the method is that the choice of the base frequency dictates the size of the details that can be represented by
the visualization. That may be a desirable effect, when it is known
from certain a priori information about the dataset that everything
above certain frequency is noise. Otherwise, the image resolution
and frequency ϕ should be chosen high enough to capture small flow
details, which in turn may lead to very high-frequent high-contrast
images that are disturbing to a human eye.
The second downside of the method is that the field is distorted
in the immediate proximity of the streamline branching points, especially for small integration lengths. The fact that the presented
algorithm doesn’t make any difference between black and white
line branching may be unusual and even disturbing for experts who
are used to streamline visualization. Such splitting streamlines
distinguish our visualization image from the results of analogous
techniques. This effect can be largely attenuated with smoothing

Figure 12: Post-processed versions of images generated with our
method. On the left, the output was converted to vector graphics, and
on the right, it was smoothed by a LIC.

at one of the following post-processing steps and increasing the
integration length.
To improve the images for print, a threshold can be applied to the
output to achieve black and white images, which can then be easily
converted to the vector graphics form. Figures 12 left and 1A illustrate how off-the-shelf, general-purpose bitmap tracing algorithms
can be used for this purpose. We used the open source ”Potrace”
[14] utility to turn our results into a sparse visualization, somewhat
similar to streamline image, though not exactly the same. It can be
further analysed and enhanced with geometry processing algorithms
or just used as a scalable visualization free from the limitations of a
raster picture. The advantages of this picture are especially obvious
when printed on paper.
An alternative approach to create high-quality images is to apply
our method following a LIC processing, which adds smoothness in
the direction of the flow. This scheme results in a much better visual
quality than any other LIC application based on a noise texture, as
can be seen in Figure 12 right.
7

F UTURE W ORK

It is clear that some parts of our method pipeline are only approximations, as is true for many other visualization techniques. While
so far we have not developed a formal theory to precisely predict
errors in the resulting images, still, our experiments show, that the
resulting visualizations are close in quality to existing techniques,
and in some cases, arguably better. We believe that this fresh new
look on the texture-based flow visualization will be of interest for
concerned researchers who might contribute to the evaluation and
improvement of the method. In the future, we also plan to team up
with experts in the field to compare established methods with our
novel technique in a formal user study.
We also realize that the vast majority of flow visualization applications requires processing of 3D and time-dependent flows. There are
three obvious extensions to our technique that might be considered
in this regard: isosurfaces visualization, stream surface visualization, and streamlines visualization in space. These problems are
enumerated above in order of increasing complexity. The isosurface visualization, though not related to flow visualization, seems
to be the most straightforward development of our technique in 3D.
Likewise, image isolines can be pictured with our method applied
to a flow orthogonal to the gradient of the image, the isosurfaces
visualization arises naturally when the area integral is replaced by
a volume integral in our method. The stream surface visualization
requires a more elaborate application of our wave model, since a
globally consistent orientation (affecting the sign of thickness in
2D) of the surfaces is not intuitively defined, as opposed to isosurfaces. Finally, visualizing streamlines in 3D seems to be the most
challenging topic, since we have strong evidence that an additional

135

Figure 11: A flow around a cylinder, visualized with our technique using L = 30 and ϕ =
short kernel (middle) and a long kernel (right).

dimension along with thickness is required to model a wave solution
for this problem.
We are also considering extensions of our method to timedependent flows and using topological features as a means of adaptive frequency control in order to improve the quality of the results.
ACKNOWLEDGEMENTS
The work presented in this paper was made possible in part by the
NIH/NCRR Center for Integrative Biomedical Computing, P41RR12553-10 and by Award Number R01EB007688 from the National Institute of Biomedical Imaging and Engineering, as well as
the Intel Visual Computing Institute and the Cluster of Excellence
“Multimodal Computing and Interaction” at the Saarland University. The content is under sole responsibility of the authors. Special
thanks to Tino Weinkauf for fruitful discussions and software support.
R EFERENCES
[1] B. Cabral and L. C. Leedom. Imaging vector fields using line integral
convolution. In Proceedings of the 20th Annual Conference on Computer Graphics and Interactive Techniques, SIGGRAPH ’93, pages
263–270, New York, NY, USA, 1993. ACM.
[2] Y. Chen, J. Cohen, and J. Krolik. Similarity-guided streamline placement with error evaluation. IEEE Transactions on Visualization and
Computer Graphics, 13:1448–1455, November 2007.
[3] J. H. Elder. Are edges incomplete? International Journal of Computer
Vision, 34(2-3):97–122, 1999.
[4] L. K. Forssell. Visualizing flow over curvilinear grid surfaces using line
integral convolution. In Proceedings of the conference on Visualization
’94, VIS ’94, pages 240–247, Los Alamitos, CA, USA, 1994. IEEE
Computer Society Press.
[5] M. Hlawatsch, F. Sadlo, and D. Weiskopf. Hierarchical line integration.
IEEE Transactions on Visualization and Computer Graphics, 99, 2010.
[6] B. Jobard and W. Lefer. Creating evenly-spaced streamlines of arbitrary density. In Visualization in Scientific Computing ’97, Proc. Eurographics Workshop, Boulogne-sur-Mer, France, April 28–30, 1997,
Eurographics, pages 43–56. Springer-Verlag Wien New York, 1997.
[7] R. S. Laramee, H. Hauser, H. Doleisch, B. Vrolijk, F. H. Post, and
D. Weiskopf. The state of the art in flow visualization: Dense and
texture-based techniques. Computer Graphics Forum, 23:203–221,
2004.
[8] Z. Liu, R. Moorhead, and J. Groner. An advanced evenly-spaced
streamline placement algorithm. IEEE Transactions on Visualization
and Computer Graphics, 12:965–972, September 2006.
[9] A. Okada and D. Lane. Enhanced line integral convolution with flow
feature detection. In SPIE Vol. 3017 Visual Data Exploration and
Analysis IV, pages 206–217, 1997.
[10] F. H. Post, B. Vrolijk, H. Hauser, R. S. Laramee, and H. Doleisch. The
state of the art in flow visualisation: Feature extraction and tracking.
Computer Graphics Forum, 22(4):775–792, 2003.
[11] A. Quarteroni, R. Sacco, and F. Saleri. Numerical Mathematics. Texts
in Applied Mathematics. Springer, Berlin, Heidelberg, second edition,
2007.

136

1
3

(left) compared to the enhanced two-fold LIC with a

[12] C. Rezk-Salama, P. Hastreiter, C. Teitzel, and T. Ertl. Interactive exploration of volume line integral convolution based on 3d-texture mapping.
In Proceedings of the conference on Visualization ’99: celebrating ten
years, VIS ’99, pages 233–240, Los Alamitos, CA, USA, 1999. IEEE
Computer Society Press.
[13] T. Salzbrunn, H. J¨anicke, T. Wischgoll, and G. Scheuermann. The state
of the art in flow visualization: Partition-based techniques. In SimVis,
pages 75–92, 2008.
[14] P. Selinger. Potrace: a polygon-based tracing algorithm, 2003.
[15] D. Stalling. Fast Texture-Based Algorithms for Vector Field Visualization. PhD thesis, Zuse Institute Berlin, 1998.
[16] D. Stalling and H.-C. Hege. Fast and resolution independent line
integral convolution. In Proceedings of the 22nd Annual Conference
on Computer Graphics and Interactive Techniques, SIGGRAPH ’95,
pages 249–256, New York, NY, USA, 1995. ACM.
[17] F. Taponecco and M. Alexa. Vector field visualization using markov
random field texture synthesis. In Proceedings of the symposium on
Data visualisation 2003, VISSYM ’03, pages 195–202, Aire-la-Ville,
Switzerland, Switzerland, 2003. Eurographics Association.
[18] G. Turk and D. Banks. Image-guided streamline placement. In Proceedings of the 23rd annual conference on Computer graphics and
interactive techniques, SIGGRAPH ’96, pages 453–460, New York,
NY, USA, 1996. ACM.
[19] J. J. van Wijk. Spot noise texture synthesis for data visualization.
SIGGRAPH Comput. Graph., 25:309–318, July 1991.
[20] R. S. Varga. Gershgorin and His Circles. Springer, first edition, 2004.
[21] V. Verma, D. Kao, and A. Pang. PLIC: Bridging the gap between
streamlines and LIC. In In Proceedings of Visualization 1999, pages
341–348, Los Alamitos, CA, USA, 1999. IEEE Computer Society
Press.
[22] V. Verma, D. Kao, and A. Pang. A flow-guided streamline seeding
strategy. In Proceedings of the conference on Visualization ’00, VIS
’00, pages 163–170, Los Alamitos, CA, USA, 2000. IEEE Computer
Society Press.
[23] D. Weiskopf. GPU-Based Interactive Visualization Techniques (Mathematics and Visualization). Springer-Verlag New York, Inc., Secaucus,
NJ, USA, 2006.
[24] D. Weiskopf. Iterative twofold line integral convolution for texturebased vector field visualization. In Mathematical Foundations of Scientific Visualization, Computer Graphics, and Massive Data Exploration,
Mathematics and Visualization, pages 191–211. Springer Berlin Heidelberg, 2009.
[25] K. Wu, Z. Liu, S. Zhang, and R. J. Moorhead II. Topology-aware evenly
spaced streamline placement. IEEE Transactions on Visualization and
Computer Graphics, 16:791–801, September 2010.

