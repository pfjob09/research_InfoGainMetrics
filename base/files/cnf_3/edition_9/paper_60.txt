Rendering recognizably unique textures
Janne V. Kujala and Tuomas J. Lukka
Hyperstructure Group
Agora Center, P.O. Box 35
FIN-40014 University of Jyv¨askyl¨a
Finland
jvk@iki.ﬁ, lukka@iki.ﬁ
Abstract
We present a perceptually designed hardwareaccelerated algorithm for generating unique background
textures for distinguishing documents. To be recognizable, the texture should produce a random feature vector
in the brain after visual feature extraction.
Our motivating example is a hypertext user interface which shows a fragment of a link’s target in the
margin. Upon traversing the link, the fragment expands
to ﬁll the screen. Our goal is to avoid user disorientation by texturing each document with a unique background so that a document can easily be recognized from
a fragment. The user should be able to learn the textures of the most often visited documents, as per Zipf ’s
law.
The results of an initial experiment show that the
generated textures are indeed recognizable. We discuss
a method for enhancing text readability by both providing fast, interactive zooming and unnoticeably bleaching
the background around text.

1. Introduction
In this article, we introduce the use of procedurally
generated unique backgrounds as a visualization of document identity. In our approach, each document has
a diﬀerent, easily distinguishable background texture.
The user can thus identify an item at a glance, even if
only a fragment of the item is shown, without reading
the title (which the fragment may not even show).
In the following sections, we ﬁrst review related
work on texturing. Next, we discuss an example user
interface to a hypertext structure. Then, we formulate general principles for designing recognizable backgrounds and present our hardware-accelerated implementation. Following this, we discuss enhancing text
readability on such backgrounds and practical experiences and conclude.

2. Related work
The texture of a surface, taken literally, is its
translation-invariant statistical microstructure.
In
computer graphics, the word texturing is used in a

somewhat looser sense[6, 16]: it refers to mapping 2D
arrays of numerical values onto graphics primitives such
as polygons or Bezi´er patches, modifying their rendered
appearance in some way (coloring[6], bump mapping[3],
etc.). Textures have been synthesized in several ways:
procedurally[8, 22, 26, 27, 29], using other textures as a
starting point[17], perceptually, for visualizing surface
orientation[19, 34, 35] and scalar or vector ﬁelds[37],
and statistically, as samples from a probability distribution on a random ﬁeld[9, 12, 36]. As a particular
example, the Starﬁsh[32] program uses procedural texturing for generating random wallpaper textures.
Psychophysical studies on texture perception have
mostly concentrated on pre-attentive visual texture
discrimination[1, 20], the ability of human observers
to eﬀortlessly discriminate pairs of certain textures.
Julesz[21] proposed that texture discrimination could
be explained by the densities of textons, fundamental
texture elements, such as elongated blobs, line terminators, and line crossings. However, the textons are
hard to deﬁne formally.
Simpler, ﬁltering-based models can explain texture
discrimination equally well[2]. There is also physiological evidence of the ﬁltering processes: in the visual
cortex, there are cells sensitive to diﬀerent frequencies,
orientations, and locations in the visual ﬁeld[5].
On a higher level, the correlations between local
features are combined by forming contours and possibly other higher-level constructions[31]. These higher
levels are not yet thoroughly understood; some theories[18] assume certain primitive shapes whose structure facilitates recognition.
There have also been studies on mapping texture
appearance to an Euclidian texture space[14]: in these
experiments, three dimensions have been suﬃcient to
explain most of the perceived diﬀerences for artiﬁcial
textures. However, the texture stimuli have been somewhat simple (no color, lack of frequency-band interaction, etc.). For some natural texture sets, three dimensions have also been suﬃcient[28], but semantic connections can make it hard to assess the dimensionality.

Proceedings of the Seventh International Conference on Information Visualization (IV’03)
1093-9547/03 $17.00 © 2003 IEEE

a)

2

1

Lorem
ipsum dolor sit
amet, consectetur
adipisicing
elit, sed do eiusmod tempor incididunt ut labore
et dolore magna
aliqua. Ut enim
ad minim veniam, quis nostrud exercitation
ullamco laboris
nisi ut aliquip
ex ea commodo
consequat.
Duis
aute
irure dolor in
reprehenderit
in voluptate velit
esse cillum dolore eu fugiat
nulla pariatur.
Excepteur
sint
occaecat

cupidatat
non
proident, sunt in
culpa qui ofﬁcia
deserunt mollit
anim id est laborum.
Lorem
ipsum dolor sit
amet, consectetur
adipisicing
elit, sed do eiusmod tempor incididunt ut labore
et dolore magna
aliqua. Ut enim
ad minim veniam, quis nostrud exercitation
ullamco laboris
nisi ut aliquip
ex ea commodo
consequat.
Duis
aute
irure dolor in
reprehenderit

in voluptate velit
esse cillum dolore eu fugiat
nulla pariatur.

consequat.
Duis
aute
irure dolor in
reprehenderit
in voluptate velit
esse cillum dolore eu fugiat
nulla pariatur.

Excepteur
sint
occaecat
cupidatat
non
proident, sunt in
culpa qui ofﬁcia
deserunt
mollit anim id est
laborum. Lorem
ipsum dolor sit
amet, consectetur
adipisicing
elit, sed do eiusmod tempor incididunt ut labore
et dolore magna
aliqua. Ut enim
ad minim veniam, quis nostrud exercitation
ullamco laboris
nisi ut aliquip
ex ea commodo

Excepteur
sint
occaecat
cupidatat
non
proident, sunt in
culpa qui ofﬁcia
deserunt mollit
anim id est laborum.
Lorem
ipsum dolor sit
amet, consectetur
adipisicing
elit, sed do eiusmod tempor incididunt ut labore

et dolore magna
aliqua. Ut enim
ad minim veniam, quis nostrud exercitation
ullamco laboris
nisi ut aliquip
ex ea commodo
consequat.
Duis
aute
irure dolor in
reprehenderit
in voluptate velit
esse cillum dolore eu fugiat
nulla pariatur.
Excepteur
sint
occaecat
cupidatat
non
proident, sunt in
culpa qui ofﬁcia
deserunt mollit
anim id est laborum.

Lorem ipsum dolor sit
amet, consectetur adipisicing
elit, sed do eiusmod tempor
incididunt ut labore et dolore
magna aliqua. Ut enim ad
minim veniam, quis nostrud
exercitation ullamco laboris
nisi ut aliquip ex ea commodo
consequat.

3

Duis aute irure dolor in
reprehenderit in voluptate
velit esse cillum dolore eu fugiat nulla pariatur.

ÄÓÖ Ñ Ô×ÙÑ ÓÐÓÖ × Ø Ñ Ø¸
ÓÒ× Ø ØÙÖ
Ô× Ò
Ð Ø¸ ×
Ó
Ù×ÑÓ Ø ÑÔÓÖ Ò
ÙÒØ ÙØ Ð ÓÖ
Ø ÓÐÓÖ Ñ Ò Ð ÕÙ º ÍØ Ò Ñ
Ñ Ò Ñ Ú Ò Ñ¸ ÕÙ × ÒÓ­ÖÙ Ü Ö ¹
Ø Ø ÓÒ ÙÐÐ Ñ Ó Ð ÓÖ × Ò × ÙØ Ð ÕÙ Ô
Ü
ÓÑÑÓ Ó ÓÒ× ÕÙ Øº

Excepteur sint occaecat
cupidatat non proident, sunt
in culpa qui oﬃcia deserunt
mollit anim id est laborum.
Lorem ipsum dolor sit amet,
consectetur adipisicing elit,
sed do eiusmod tempor incididunt ut labore et dolore
magna aliqua. Ut enim ad
minim veniam, quis nostrud
exercitation ullamco laboris
nisi ut aliquip ex ea commodo
consequat.

Ù × ÙØ ÖÙÖ ÓÐÓÖ Ò Ö ÔÖ ¹
Ò Ö Ø Ò ÚÓÐÙÔØ Ø Ú Ð Ø ¬ ÐÐÙÑ
ÓÐÓÖ Ù Ù Ø ÒÙÐÐ Ô Ö ØÙÖº
Ü ÔØ ÙÖ × ÒØ Ó
Ø ÙÔ Ø Ø
ÒÓÒ ÔÖÓ ÒØ¸ ×ÙÒØ Ò ÙÐÔ ÕÙ Ó« ¹
× ÖÙÒØ ÑÓÐÐ Ø Ò Ñ
­ Ð Ó¹
ÖÙÑº

Duis aute irure dolor in
reprehenderit in voluptate
velit esse cillum dolore eu fugiat nulla pariatur.

ÄÓÖ Ñ Ô×ÙÑ ÓÐÓÖ × Ø Ñ Ø¸
ÓÒ× Ø ØÙÖ
Ô× Ò
Ð Ø¸ ×
Ó
Ù×ÑÓ Ø ÑÔÓÖ Ò
ÙÒØ ÙØ Ð ÓÖ
Ø ÓÐÓÖ Ñ Ò Ð ÕÙ º ÍØ Ò Ñ
Ñ Ò Ñ Ú Ò Ñ¸ ÕÙ × ÒÓ­ÖÙ Ü Ö ¹

Excepteur sint occaecat
cupidatat non proident, sunt
in culpa qui oﬃcia deserunt
mollit anim id est laborum.

Ø Ø ÓÒ ÙÐÐ Ñ Ó Ð ÓÖ × Ò × ÙØ Ð ÕÙ Ô
Ü
ÓÑÑÓ Ó ÓÒ× ÕÙ Øº
Ù × ÙØ ÖÙÖ ÓÐÓÖ Ò Ö ÔÖ ¹
Ò Ö Ø Ò ÚÓÐÙÔØ Ø Ú Ð Ø ¬ ÐÐÙÑ
ÓÐÓÖ Ù Ù Ø ÒÙÐÐ Ô Ö ØÙÖº
Ü ÔØ ÙÖ × ÒØ Ó
Ø ÙÔ Ø Ø
ÒÓÒ ÔÖÓ ÒØ¸ ×ÙÒØ Ò ÙÐÔ ÕÙ Ó« ¹
× ÖÙÒØ ÑÓÐÐ Ø Ò Ñ
­ Ð Ó¹
ÖÙÑº ÄÓÖ Ñ Ô×ÙÑ ÓÐÓÖ × Ø Ñ Ø¸
ÓÒ× Ø ØÙÖ
Ô× Ò
Ð Ø¸ ×
Ó
Ù×ÑÓ Ø ÑÔÓÖ Ò
ÙÒØ ÙØ Ð ÓÖ
Ø ÓÐÓÖ Ñ Ò Ð ÕÙ º ÍØ Ò Ñ
Ñ Ò Ñ Ú Ò Ñ¸ ÕÙ × ÒÓ­ÖÙ Ü Ö ¹
Ø Ø ÓÒ ÙÐÐ Ñ Ó Ð ÓÖ × Ò × ÙØ Ð ÕÙ Ô
Ü
ÓÑÑÓ Ó ÓÒ× ÕÙ Øº
Ù × ÙØ ÖÙÖ ÓÐÓÖ Ò Ö ÔÖ ¹
Ò Ö Ø Ò ÚÓÐÙÔØ Ø Ú Ð Ø ¬ ÐÐÙÑ
ÓÐÓÖ Ù Ù Ø ÒÙÐÐ Ô Ö ØÙÖº

Ü ÔØ ÙÖ × ÒØ Ó
Ø ÙÔ Ø Ø
ÒÓÒ ÔÖÓ ÒØ¸ ×ÙÒØ Ò ÙÐÔ ÕÙ Ó« ¹
× ÖÙÒØ ÑÓÐÐ Ø Ò Ñ
­ Ð Ó¹
ÖÙÑº
ÄÓÖ Ñ Ô×ÙÑ ÓÐÓÖ × Ø Ñ Ø¸
ÓÒ× Ø ØÙÖ
Ô× Ò
Ð Ø¸ ×
Ó
Ù×ÑÓ Ø ÑÔÓÖ Ò
ÙÒØ ÙØ Ð ÓÖ
Ø ÓÐÓÖ Ñ Ò Ð ÕÙ º ÍØ Ò Ñ
Ñ Ò Ñ Ú Ò Ñ¸ ÕÙ × ÒÓ­ÖÙ Ü Ö ¹
Ø Ø ÓÒ ÙÐÐ Ñ Ó Ð ÓÖ × Ò × ÙØ Ð ÕÙ Ô
Ü
ÓÑÑÓ Ó ÓÒ× ÕÙ Øº
Ù × ÙØ ÖÙÖ ÓÐÓÖ Ò Ö ÔÖ ¹
Ò Ö Ø Ò ÚÓÐÙÔØ Ø Ú Ð Ø ¬ ÐÐÙÑ
ÓÐÓÖ Ù Ù Ø ÒÙÐÐ Ô Ö ØÙÖº
Ü ÔØ ÙÖ × ÒØ Ó
Ø ÙÔ Ø Ø
ÒÓÒ ÔÖÓ ÒØ¸ ×ÙÒØ Ò ÙÐÔ ÕÙ Ó« ¹
× ÖÙÒØ ÑÓÐÐ Ø Ò Ñ
­ Ð Ó¹
ÖÙÑº

лОРЕМ ИПСУМ ДОЛОР СИТ АМЕТ ЦОНСЕЦТЕТУР
АДИПИСИЦИНГ ЕЛИТ СЕД ДО ЕИУСМОД ТЕМПОР
ИНЦИДИДУНТ УТ ЛАБОРЕ ЕТ ДОЛОРЕ МАГНА АЛИ
ЯУА уТ ЕНИМ АД МИНИМ ЖЕНИАМ ЯУИС НОС
ТРУД ЕЬЕРЦИТАТИОН УЛЛАМЦО ЛАБОРИС НИСИ УТ
АЛИЯУИП ЕЬ ЕА ЦОММОДО ЦОНСЕЯУАТ

4

дУИС АУТЕ ИРУРЕ ДОЛОР ИН РЕПРЕХЕНДЕРИТ
ИН ЖОЛУПТАТЕ ЖЕЛИТ ЕССЕ ЦИЛЛУМ ДОЛОРЕ ЕУ
ФУГИАТ НУЛЛА ПАРИАТУР
еЬЦЕПТЕУР СИНТ ОЦЦАЕЦАТ ЦУПИДАТАТ НОН
ПРОИДЕНТ СУНТ ИН ЦУЛПА ЯУИ ОФФИЦИА ДЕ
СЕРУНТ МОЛЛИТ АНИМ ИД ЕСТ ЛАБОРУМ лОРЕМ
ИПСУМ ДОЛОР СИТ АМЕТ ЦОНСЕЦТЕТУР АДИП
ИСИЦИНГ ЕЛИТ СЕД ДО ЕИУСМОД ТЕМПОР ИНЦИ
ДИДУНТ УТ ЛАБОРЕ ЕТ ДОЛОРЕ МАГНА АЛИЯУА уТ
ЕНИМ АД МИНИМ ЖЕНИАМ ЯУИС НОСТРУД ЕЬЕРЦИ
ТАТИОН УЛЛАМЦО ЛАБОРИС НИСИ УТ АЛИЯУИП ЕЬ
ЕА ЦОММОДО ЦОНСЕЯУАТ
дУИС АУТЕ ИРУРЕ ДОЛОР ИН РЕПРЕХЕНДЕРИТ
ИН ЖОЛУПТАТЕ ЖЕЛИТ ЕССЕ ЦИЛЛУМ ДОЛОРЕ ЕУ
ФУГИАТ НУЛЛА ПАРИАТУР
еЬЦЕПТЕУР СИНТ ОЦЦАЕЦАТ ЦУПИДАТАТ НОН
ПРОИДЕНТ СУНТ ИН ЦУЛПА ЯУИ ОФФИЦИА ДЕ
СЕРУНТ МОЛЛИТ АНИМ ИД ЕСТ ЛАБОРУМ

5

Lorem ipsum
dolor sit amet,
consectetur
adipisicing elit,
sed do eiusmod
tempor
incididunt ut
labore et
dolore magna
aliqua. Ut enim
ad minim veniam,
quis nostrud
exercitation
ullamco laboris
nisi ut aliquip ex
ea commodo
consequat.
Duis aute irure
dolor in
reprehenderit in
voluptate velit
esse cillum

dolore eu fugiat
nulla pariatur.
Excepteur sint
occaecat
cupidatat non
proident, sunt in
culpa qui officia
deserunt mollit
anim id est
laborum. Lorem
ipsum dolor sit
amet,
consectetur
adipisicing elit,
sed do eiusmod
tempor
incididunt ut
labore et
dolore magna
aliqua. Ut enim
ad minim veniam,
quis nostrud

exercitation
ullamco laboris
nisi ut aliquip ex
ea commodo
consequat.
Duis aute irure
dolor in
reprehenderit in
voluptate velit
esse cillum
dolore eu fugiat
nulla pariatur.
Excepteur sint
occaecat
cupidatat non
proident, sunt in
culpa qui officia
deserunt mollit
anim id est
laborum.

b)
nisi ut aliquip
ex ea commodo
consequat.
Duis
aute
irure dolor in
reprehenderit
in voluptate velit
esse cillum dolore eu fugiat
nulla pariatur.

didunt ut labore ip
et dolore magna a
aliqua. Ut enim tu
ad a minim ve- ruree
qui officia
dolor
in
niam,
quisrepreh
nosm
runt mollit
enderit in
id est
voluptate velit d
trud
exercitation
rum. Lorem
esse cillum
m dolor sit
ullamco
laboris
dolore eu fugiatet
nulla pariat
ecteturut
nisi
aliquip ur. a
elit,
Except
exoicing
ea
commodo
eur
eiusmod
sint ad
consequat.
n
tr
Duis
aute u
irure dolor in n
ex
reprehenderit
ÑÓ

Excepteur
sint
occaecat

Ù ×

Ò

Ö Ø

ÓÐÓ

Ö

Ü
ÒÓ
Ò

ÔÖ
Ó

ÙØ

Ò

Ù

ÔØ

ÒØ¸

ÓÒ

× Ò
×

× ÕÙ

ÖÙ
Ö

ÐÙÔ

Ø

Ø

Ø ÒÙ

× ÒØ

×ÙÒ

× ÖÙ

Ä
Ó
Ð Ø¸ ×
Ô× Ò
ÓÒ× Ø ØÙÖ
ÙÒØ ÙØ Ð ÓÖ
Ù×ÑÓ Ø ÑÔÓÖ Ò
Ð ÕÙ º ÍØ Ò Ñ
Ø ÓÐÓÖ Ñ Ò
Ö ¹
ÕÙ × ÒÓ­ÖÙ Ü
Ñ¸
Ò
Ú
Ñ
Ò
Ñ
Ô
ÓÖ × Ò × ÙØ Ð ÕÙ
Ø Ø ÓÒ ÙÐÐ Ñ Ó Ð
Øº
ÓÑÑÓ Ó ÓÒ× ÕÙ
Ü

ÚÓ

Ù

ÙÖ

Ó

Ø

ÓÐÓ
Ö
Ú

ÐÐ

Ð Ø
Ô

Ö

ÙØ

Øº

Ò

Ö Ô

¬

ÐÐÙ

ØÙÖ
º

Ó
Ø
Ò

ÙÔ
Ø

Ü

ÖÙÑ
Ò Ö ÔÖ ¹
Ù × ÙØ ÖÙÖ ÓÐÓÖ
Ø Ú Ð Ø ¬ ÐÐÙÑ
Ò Ö Ø Ò ÚÓÐÙÔØ
ÒÙÐÐ Ô Ö ØÙÖº
ÓÐÓÖ Ù Ù Ø
Ó
Ù
Ø ÙÔ Ø Ø
ÔØ ÙÖ × ÒØ Ó , qu
Ø
Ü xer
citation Ò ÙÐÔ isÕÙnoÓ«
str¹ud Ñ
ÒØ¸ ×ÙÒØ ullamco
nisi ut
Ò Ö ÔÖ ¹ ÒÓÒ ÔÖÓ
Ó¹
Ð ori
aliquØip Ò Ñ
­lab
Ù × ÙØ ÖÙÖ ÓÐÓÖ
ÑÓÐÐ ex ea
s
con
ÖÙÒØ
×
ÐÐÙÑ
seq
com
Ø¸ Ø
uat.
Ñ do
Ø Ú ÐØ ¬
× Ø mo
Ò Ö Ø Ò ÚÓÐÙÔØ
ÄÓÖ Ñ Ô×ÙÑ ÓÐÓÖ
ÖÙÑº
ØÙÖº
Ö
Ó
Ô
ÒÙÐÐ
Ð Ø¸ ×
Ô× Ò
ÓÐÓÖ Ù Ù Ø
ØÙÖ
ÓÒ× Ø Du
is auteÒ
ÙÒØ ÙØ Ð ÓÖ
reprehØ ÑÔÓÖ
re do
Ù×ÑÓ
enderit iru
Ø ÙÔ Ø Ø
ÕÙ º ÍØlorÒ Ñin
Ü ÔØ ÙÖ × ÒØ Ó
it essÑ Ò Ð in
ØvelÓÐÓÖ
voluptat
Ü eÖ ¹
lum
Ò ÙÐÔ ÕÙ Ó« ¹ giat Ú Òe cil
× ÒÓ­ÖÙ
ÕÙdo
Ñ¸
lore eu Ð ÕÙ
ÒÓÒ ÔÖÓ ÒØ¸ ×ÙÒØ
­ Ð Ó¹ Ñ Ò Ñnulla pariatur
ÙØ fu- Ô
Ñ
Ò
Ò
×
Ø
ÓÖ
Ð
ÑÓÐÐ
Ó
. ×
× ÖÙÒØ
Ø Ø ÓÒ ÙÐÐ Ñ
Øº
ÓÑÑÓ Ó ÓÒ× ÕÙ
ÖÙÑº
Ü Excep
cupidata teur sint occ
t non
aecÒ Ö ÔÖ ¹
pro
ÓÐÓÖ × Ø Ñ Ø¸in culpa × ÙØ
ide ÓÐÓÖ at
ÖÙÖ
ÄÓÖ Ñ Ô×ÙÑ
Ómollit Ùqui oﬃcia nt,Ð sun
t ÐÐÙÑ
Ð Ø¸ ×
Ô× Ò
ÚÓÐÙÔØ ØdeÚserØun¬t
Ø Ò id
Ö im
ÓÒ× Ø ØÙÖ
Ò an
est ÒÙÐÐ
ÙÒØ ÙØ Ð ÓÖLore
l b Ô Ö ØÙÖº
Ù×ÑÓ Ø ÑÔÓÖ Ò
ÓÐÓÖ Ù Ù Ø
Ð ÕÙ º ÍØ Ò Ñ
Ø ÓÐÓÖ Ñ Ò
¹
Ö
Ü
ÕÙ × ÒÓ­ÖÙ

a
nos- mod temp
ut l
aute niam, quis
Duis
citation didunt
in trud exer laboris et dolore m
irure dolor
ullamco
erit
ip aliqua. Ut
hend
aliqu
repre
nisi ut
minim
ÔÓÖo Ò ad ¸ ×
mod
in voluptate velit ex ea Øcom
Ó
ÓÐÓÖ Ñ
Ü
ÙÒØ ÙØ , quis
Ð ÓÖ
Ò Ð ÕÙ niam
Ñ Ò Ñ t.
esse cillum do-t consequa
º ÍØ
Ú Ò Ñ¸
exerc
ÒÑ
trud
ÕÙ × ÒÓ­
Ø Ø ÓÒ
lore eu fugia
ÙÐÐ Ñ
ÖÙ Ü co
Ó Ð ÓÖ
Ö ¹
Ü
× Ò ullam
nulla pariatur.
× ÙØ
Ð
Ó ÓÒ×
Duis ÓÑÑÓaute
ÕÙ
ut
nisi Ô ÓÐÓÒ
dolor in ÕÙ Øºex ea com
irure
Ù × erit
Excepteur
ÙØ ÖÙÖ
hend
occaecat repreÒ Ö Ø Ò ÚÓÐÙÔØ ÓÐÓÖ Ò Ö ÔÖ
sint

ÄÓÖ Ñ Ô×ÙÑ
ÓÐÓÖ × Ø Ñ
Ø¸ Ø Ø ÓÒ ÙÐÐ
ÓÒ× Ø ØÙÖ
ÑÓ
Ô× Ò
Ð Ø¸ ×
Ó Ü
Ù×ÑÓ Ø ÑÔÓÖ
ÓÑÑÓ
do
ulla
aliquip Ò ÙÒØ ÙØ Ð ÓÖ
irure enderit
i utØ ÓÐÓÖ
Ñ
odoÒ Ð ÕÙ º ÍØ Ò
nis
reh
mm
lit
co
rep
tate ve
ex eaÑ ÒuaÑt.Ú Ò Ñ¸ ÕÙ × ÒÓ­ÖÙ Ñ
Ù × ÙØ
in volup lum do- conseq
Ü
Ö ¹
Ø Ø ÓÒ ÙÐÐ Ñ Ó
Ò Ö Ø Ò ÚÓÐÙ
Ð ÓÖ × Ò × ÙØ
esse cil
fugiat
Ð ÕÙ Ô
Ü
ÓÑÑÓ
ÓÐÓÖ Ù Ù
auÓte ÓÒ× ÕÙ Øº
lore eu
.

nulla pa

riatur

ur
Exceptecaecat
oc
sint

¹
Ø Ú Ð
Ø ¬
ÒÓÒ Ô
Ù Ù
ÐÐÙÑ
Ø ÒÙÐÐ
Ô Ö ØÙÖ
×
º
ÖÙÑº
Ü ÔØ
ÙÖ × ÒØ
Ó
ÓÒ× Ø
Ø ÙÔ
ÒØ¸ ×ÙÒ
Ø
Ø Ø
Ø
Ò
ÙÐÔ ÕÙ
× ÖÙÒØ
Ù×ÑÓ
ÑÓÐÐ Ø
Ó« ¹
ÖÙÑº
ÒÑ
Ø ÓÐÓÖ
­ Ð Ó¹
ÑÒÑ
Ú
Ø Ø ÓÒ
ÄÓÖ Ñ
Ù ÐÐ
Ô×Ù
ÓÐÓÖ

ÒÓÒ Ô

ÖÓ

Ü ÔØ ÙÖ ×
ÒÓÒ ÔÖÓ ÒØ¸
×Ù
× ÖÙÒØ ÑÓÐ
ÖÙÑº ÄÓÖ Ñ
Ô×
ÓÒ× Ø ØÙÖ
Ü ÔØ ÙÖ × ÒØ Ó
Ô
Ø ÙÔ Ø Ø
ÒÓÒ ÔÖÓ ÒØ¸
Ù×ÑÓ Ø ÑÔÓÖ
×ÙÒØ Ò ÙÐÔ
ÕÙ Ó« ¹ Ø
× ÖÙÒØ ÑÓÐÐ Ø
ÓÐÓÖ Ñ Ò
ÒÑ
­ Ð Ó¹ Ñ Ò
ÖÙÑº
Ñ Ú Ò Ñ¸ Õ
Ø Ø ÓÒ ÙÐÐ Ñ Ó
Ð
Ü
ÄÓÖ Ñ Ô×ÙÑ
ÓÑÑÓ Ó Ó
ÓÐÓÖ × Ø Ñ
Ø¸
ÓÒ× Ø ØÙÖ
Ô× Ò
Ð Ø¸ ×
Ó
Ù×ÑÓ Ø ÑÔÓÖ
Ù × ÙØ ÖÙ
Ò
ÓÐÓÖ

ÓÐÓÖ Ò Ö ÔÖ ¹
Ö Ø Ò ÚÓÐÙÔØ Ø
Ú Ð Ø ¬ ÐÐÙÑ
Ù Ù Ø ÒÙÐÐ
Ô Ö ØÙÖº

Ø Ø ÓÒ ÙÐÐ Ñ Ó Ð ÓÖ × Ò ×
Ü
ÓÑÑÓ Ó ÓÒ× ÕÙ
Ù × ÙØ ÖÙÖ ÓÐÓ
Ò Ö Ø Ò ÚÓÐÙÔØ Ø Ú Ð
ÓÐÓÖ Ù Ù Ø ÒÙÐÐ Ô

Ü ÔØ ÙÖ × ÒØ Ó
ÒÓÒ ÔÖÓ ÒØ¸ ×ÙÒØ Ò ÙÐ
× ÖÙÒØ ÑÓÐÐ Ø Ò Ñ
ÖÙÑº ÄÓÖ Ñ Ô×ÙÑ ÓÐÓ
ÓÒ× Ø ØÙÖ
Ô× Ò
DuiØs ÑÔÓÖ Ò
Ü ÔØ ÙÖ × ÒØ Ó
Ø ÙÔ Ø Ø
Ù×ÑÓ
ÙÒ
aute
repreh
de Ò iruÐ re
ÒÓÒ ÔÖÓ ÒØ¸ ×ÙÒØ Ò ÙÐÔ ÕÙ Ó« ¹ ve
Ø litÓÐÓÖenÑ
ÕÙ do
ºl
esse rit in
lup
× ÖÙÒØ ÑÓÐÐ Ø Ò Ñ
­ Ð Ó¹ gi
ÑatÒ nu
Ñ lla
Ú ÒcilluÑ¸
ÕÙ ×voÒÓ­
m do
lo
ÖÙÑº
Ø Ø ÓÒ ÙÐÐ pa
Ñria
Ó tu
Ð r. ÓÖre× Òeu×
ÜExceptÓÑÑÓ Ó ÓÒ× ÕÙ
cu
ÄÓÖ Ñ Ô×ÙÑ ÓÐÓÖ × Ø Ñ Ø¸
ÓÒ× Ø ØÙÖ
Ô× Ò
Ð Ø¸ ×
Ó
Ù×ÑÓ Ø ÑÔÓÖ Ò
ÙÒØ ÙØ Ð ÓÖ

pid

eur

i

Ù × ÙØ ÖÙÖ ÓÐÓ
Ò Ö Ø Ò ÚÓÐÙÔØ Ø Ú Ð

incididunt ut labore et dolore
magna aliqua. Ut enim ad
minim veniam, quis nostrud
exercitation ullamco laboris
nisi ut aliquip ex ea commodo
consequat.

do eiusmod
temp or
incididunt ut
labore et dolor
e
magna aliqu
a. Ut enim
ad
minim venia
m, quis nostr
ud
exercitation
ullam
Ø ÙÔ co ¹ laboris
Ó
ÒØ
nisi
×
Ó«
ÔØ ÙÖut aliqu
Ü cons
ÙÐÔexÕÙeaÐ comm
Ò ip
Ø
odo
Ó¹
×ÙÒ
equa
ÒØ¸
­
ÒÓÒ ÔÖ Ó
Øt. Ò Ñ

Ñ Ò Ñ Ú Ò Ñ Ó Ð ÓÖ × Ò × ÙØ
Ø Ø ÓÒ ÙÐÐ ÑÓ Ó ÓÒ× ÕÙ Øº
Ü ÓÑ
Ø¸
ÐÐ
Ò Ö ÔÖ ¹
× ÖÙÒØ ÑÓÔ×Ù
ÓÐÓÖ × Ø Ñ
ÖÙÖ ÓÐÓÖ
ÐÐÙÑ
Ñ Ñ Ò Ð Ø¸ ×
Ù × ÙØ ÙÔØ
Ø Ú ÐØ ¬ º
ÖÙÑº ÄÓÖDuisÔ ×aute
ÓÖ in
irure
ÙØ Ð dolor
Ø ØÙÖ hend
Ò Ö Ø Ò ÚÓÐ Ø ÒÙÐÐ Ô Ö ØÙÖ
ÓÒ× repre
Ò ÙÒØ
ÓÖ erit
inÍØ Òvolup
Ñ tate
Ó Ø ÑÔ
ÓÐÓÖ Ù Ù
Ù×Ñvelit
ÕÙ º dolor
Ð
esseÒ cillum
Ø
Ø
Ü
Ñ
ÖÙ e Öeu fuØ ÙÔ ¹ Ø giat
ÓÐÓÖ nullaÑ¸paria
ÕÙ × ÒÓ­
ÒØ Ó
Ó«
tur.
ÚÒ
× ÙØ Ð Õ
Ü ÔØ ÙÖ× ×ÙÒ
Ø Ò ÙÐÔ ÕÙ­ Ð Ó¹ Ñ Ò Ñ ÙÐÐ
ÓÐ ÓÖ × Ò
Ø Ø ÓÒExceÑÑÓ Ó ÓÒ× ÕÙ Øº
ÒÓÒ ÔÖ Ó ÒØ¸
Ø ÒÑ
ÓÑ pteur sint occa
× ÖÙÒØ ÑÓÐÐ
Ü
ecat
cupidatat non
Ö Ò Ö sunt
ÓÐÓent,
proid
ÖÙÑº
ÙØ ÖÙÖ
¬
Ø Ñ Ø¸ in culpa
Ù × qui
oﬃci
Ø ÚaÐ Ødeser
Ó
Ñ ÓÐÓÖ ×
Ø Ò ÚÓÐÙÔØ
Ô Ö ØÙunt
ÄÓÖ Ñ Ô×ÙÔ × Ò Ð Ø¸ × Ð ÓÖ mollÒitÖ anim
idØ ÒÙÐ
estÐ labo
Ù
rum.
Ù
Lore
ÙØ
ØÙÖ
m
Ö
Ø
ÙÒØ
ipsum
ÓÐÓ
ÓÒ×
dolor sit amet
Ò
Ñ
Ù×ÑÓ Ø Ñ ÔÓÖÒ Ð ÕÙ º ÍØ Ò Ü Ö cons
¹ ectetur adipisicing elit,,
sed do eiusm
Ø ÓÐÓÖ Ñ Ñ¸ ÕÙ × ÒÓ­ÖÙ
od temp or incididunt
ÑÒÑ Ú Ò

Duis lor in
do
irure en
rit ÖÙÖ
Ù de
× ÙØ
repreh
Ò

ÄÓÖ Ñ Ô×ÙÑ ÓÐÓÖ × Ø Ñ Ø¸
ÓÒ× Ø ØÙÖ
Ô× Ò
Ð Ø¸ ×
Ó
Ù×ÑÓ Ø ÑÔÓÖ Ò
ÙÒØ ÙØ Ð ÓÖ
Ø ÓÐÓÖ Ñ Ò Ð ÕÙ º ÍØ Ò Ñ
Ñ Ò Ñ Ú Ò Ñ¸ ÕÙ × ÒÓ­ÖÙ Ü Ö ¹
ep luptate do- e nsØeqØ uÓÒ ÙÐÐ Ñ Ó Ð ÓÖ × Ò × ÙØ Ð ÕÙ Ô
ÓÑÑÓ Ó ÓÒ× ÕÙ Øº
n vo cillum giat co Ü
esse eu fu
Duis do
lore pariatur.
irure enÙ × ÙØ ÖÙÖ ÓÐÓÖ Ò Ö ÔÖ ¹
nulla
eh
teur at reprÒ Ö Ø Ò ÚÓÐÙÔØ Ø Ú Ð Ø ¬ ÐÐÙÑ
ep
Exc occaec
ÓÐÓÖ Ù Ù Ø ÒÙÐÐ Ô Ö ØÙÖº
sint

×
Ò ÚÓ

Ø
ÐÙÔ

Ù

Ù

Ø

ÐÐ
Ø ÒÙ

Ô

ØÙÖ

Ö

Ø

× ÒØ

ÙÖ

×ÙÒ

ÒØ¸

Ó

ÑÓ

ÒØ
× ÖÙ

Ó
Ø

­

¹
Ó¹

Ð

×

Ñº

ÓÐ

Ø
Ñ
Ø

Ò
Ø
Ü

Ñ

× Ø

Ö
ÓÐÓ

Ñ

Ø

Ó
Ù×Ñ

Ò Ñ

ÐÐ Ø

Ô×Ù

Ó«

ÕÙ
ÙÐÔ

Ò

Ø

ÙÔ

Ø

ÔØ

Ü
ÔÖ

ÓÒ

Ó

×

Ð Ø

Ø¸

Duis aute irure dolor in
reprehenderit in voluptate
velit esse cillum dolore eu fulit co
giat nulla pariatur.
illum
nseq
u fu douat.
iatur. giat
Excepteur sint occaecat
D
irure uis
cupidatat non proident, sunt
eur
repreh dolor aut
in culpa qui oﬃcia deserunt
en
in
caec
in
mollit anim id est laborum. at es volupt derit
ate
no
se
Lorem ipsum dolor sit amet,
unt inn lore cillum velit
euБО ЯУdo
consectetur adipisicing fﬁ
elit,
ЛА
nuЦО
ИС llaНСpЕЯ
cia ДО
РИfu
gi
С
НИС
УАТ
sed do eiusmod tempor in-С АУТЕ
ЛУПТ ИРУР
cididunt ut labore et dolore
Т НУ АТЕ Ж Е ДОЛО
ЛЛА
ЕЛ
Р ИН
ПАРИ ИТ ЕССЕ
magna aliqua. Ut enim ad
Р
АТУР
ЦИЛЛ
ТЕ
minim veniam quis nostrud УР С

c)
nisi ut aliquip
ex ea commodo
consequat.
Duis
aute
irure dolor in
reprehenderit
in voluptate velit
esse cillum dolore eu fugiat
nulla pariatur.

didunt ut labore ip
et dolore magna a
aliqua. Ut enim tu
ad a minim ve- ruree
qui officia
dolor
in
niam,
quisrepreh
nosm
runt mollit
enderit in
id est
voluptate velit d
trud
exercitation
rum. Lorem
esse cillum
m dolor sit
ullamco
laboris
dolore eu fugiatet
nulla pariat
ecteturut
nisi
aliquip ur. a
icing elit,
Excepteur
exo eiusmo
ea dcommodo
sint ad
consequat.
n
tr
Duis
aute u
irure dolor in n
ex
reprehenderit
ÑÓ

Excepteur
sint
occaecat

Ù ×

Ò

ÓÐÓ
Ö

Ü
ÒÓ
Ò

ÔÖ

Ó

× ÖÙ

Ä
Ó
Ð Ø¸ ×
Ô× Ò
ÓÒ× Ø ØÙÖ
ÙÒØ ÙØ Ð ÓÖ
Ù×ÑÓ Ø ÑÔÓÖ Ò
Ð ÕÙ º ÍØ Ò Ñ
Ø ÓÐÓÖ Ñ Ò
ÜÖ ¹
ÒÓ­ÖÙ
×
ÕÙ
Ñ Ò Ñ Ú Ò Ñ¸
Ô
ÓÖ × Ò × ÙØ Ð ÕÙ
Ø Ø ÓÒ ÙÐÐ Ñ Ó Ð
Øº
ÓÑÑÓ Ó ÓÒ× ÕÙ
Ü

Ö Ø

ÙØ

Ò

Ù

ÔØ

ÓÒ

Ø

Ø ÒÙ

× ÒØ

×ÙÒ

× Ò
×

× ÕÙ

ÖÙ
Ö

ÚÓ
ÐÙÔ
Ø

Ù

ÙÖ

ÒØ¸

Ó

Ø

ÐÐ

Øº

ÓÐÓ
Ö
Ú

Ð Ø
Ô

Ö

ÙØ

Ò

Ö Ô

¬

ÐÐÙ

ØÙÖ
º

Ó
Ø
Ò

ÙÔ
Ø

Ü

ÖÙÑ
Ò Ö ÔÖ ¹
Ù × ÙØ ÖÙÖ ÓÐÓÖ
Ø Ú Ð Ø ¬ ÐÐÙÑ
Ò Ö Ø Ò ÚÓÐÙÔØ
ÒÙÐÐ Ô Ö ØÙÖº
ÓÐÓÖ Ù Ù Ø
Ó
Ù
Ø ÙÔ Ø Ø
ÔØ ÙÖ × ÒØ Ó , qu
Ü xer
«¹ Ø
citation Ò ÙÐÔ isÕÙnoÓstr
ud
ÒØ¸ ×ÙÒØ ullamco
nisi ut
Ò Ö ÔÖ ¹ ÒÓÒ ÔÖÓ
Ó¹ Ñ
Ð ori
aliquØip Ò Ñ
­lab
Ù × ÙØ ÖÙÖ ÓÐÓÖ
ÑÓÐÐ ex ea
s
con
× ÖÙÒØ
sequa
Ø¸ Ø
Ñ do
Ø Ú Ð Ø ¬ ÐÐÙÑ
× Ø mo
t.Ô×ÙÑ ÓÐÓÖ com
Ò Ö Ø Ò ÚÓÐÙÔØ
Ñ
ÖÙÑº ÄÓÖ
Ó
ÒÙÐÐ Ô Ö ØÙÖº
Ð Ø¸ ×
Ô× Ò
ÓÐÓÖ Ù Ù Ø
ØÙÖ
ÓÒ× Ø Du
is auteÒ
ÙÒØ ÙØ Ð ÓÖ
reprehØ ÑÔÓÖ
re do
Ù×ÑÓ
enderit iru
Ø ÙÔ Ø Ø
ÕÙ º ÍØlorÒ Ñin
Ü ÔØ ÙÖ × ÒØ Ó
it essÑ Ò Ð in
ØvelÓÐÓÖ
voluptat
Ü eÖ ¹
lum
Ò ÙÐÔ ÕÙ Ó« ¹ giat Ú Òe cil
× ÒÓ­ÖÙ
ÕÙdo
Ñ¸
lore eu Ð ÕÙ
ÒÓÒ ÔÖÓ ÒØ¸ ×ÙÒØ
Ñ Ò Ñnulla pa
Ó¹
Ô
Ð
­
Ñ
riatur
ÓÖ.× Ò × ÙØ fu× ÖÙÒØ ÑÓÐÐ Ø Ò
Ø Ø ÓÒ ÙÐÐ Ñ Ó Ð
Øº
ÓÑÑÓ Ó ÓÒ× ÕÙ
ÖÙÑº
Ü Excep
cupidata teur sint occ
t non
aecat
¹
Ñ Ø¸in cu
ÔÖ
Ø
Ö
×
Ò
pro
ÓÐÓÖ
ÓÐÓÖ
ide
lpa × ÙØ ÖÙÖ
ÄÓÖ Ñ Ô×ÙÑ
i oﬃcia nt,Ð sun
Ómollit Ùqu
t ÐÐÙÑ
Ð Ø¸ ×
Ô× Ò
ÚÓÐÙÔØ ØdeÚserØun¬t
Ø Ò id
Ö im
ÓÒ× Ø ØÙÖ
Ò an
est ÒÙÐÐ
ÙÒØ ÙØ Ð ÓÖLore
l b Ô Ö ØÙÖº
Ù×ÑÓ Ø ÑÔÓÖ Ò
ÓÐÓÖ Ù Ù Ø
Ð ÕÙ º ÍØ Ò Ñ
Ò
Ñ
ÓÐÓÖ
Ø
Ö ¹
ÕÙ × ÒÓ­ÖÙ Ü

a
nos- mod temp
ut l
aute niam, quis
Duis
citation didunt
in trud exer laboris et dolore m
irure dolor
ullamco
a. Ut
reprehenderit
ut aliquip aliqu minim
nisi
velit
ad
¸
ÔÓÖo Ò
×
in voluptate
Ó
ÓÐÓÖ mod
Ü
ÙÒØ ÙØ , quis
ex ea Øcom
Ñ Ò
niam
Ð ÓÖ
Ñ Ò Ñ t.
Ð ÕÙ º
esse cillum do-t consequa
Ú Ò Ñ¸
ÍØ Ò exerc
Ñ
trud
ÕÙ × ÒÓ­
Ø Ø ÓÒ
lore eu fugia
ÙÐÐ Ñ
ÖÙ Ü co
Ó Ð ÓÖ
Ö ¹
Ü
× Ò ullam
nulla pariatur.
× ÙØ
Ò
Ð ÕÙut
Ó ÓÒ×
Duis ÓÑÑÓaute
Ô
ÕÙ nisi
Øº
in
ÓÐÓ
r
irure dolo
ex ea com
Ù × erit
Excepteur
ÙØ ÖÙÖ
Ò hend
ÓÐÓÖ Ò
ÖØ Ò
occaecat repre
ÚÓÐÙÔØ
Ö ÔÖ ¹
sint
ÓÐÓÖ
Ø Ú Ð

ÄÓÖ Ñ Ô×ÙÑ
ÓÐÓÖ × Ø Ñ
Ø¸ Ø Ø ÓÒ ÙÐÐ
ÓÒ× Ø ØÙÖ
ÑÓ
Ô× Ò
Ð Ø¸ ×
Ó Ü
Ù×ÑÓ Ø ÑÔÓÖ
ÓÑÑÓ
do
ulla
aliquip Ò ÙÒØ ÙØ Ð ÓÖ
irure enderit
i utØ ÓÐÓÖ
mmÑodoÒ Ð ÕÙ º ÍØ Ò Ñ
repreh tate velit nis
Ò Ñ Ú Ò Ñ¸
eaÑ co
ex
lup
Ù × ÙØ
ÕÙ
× ÒÓ­ÖÙ Ü Ö
t.
in vo
¹
Ø Ø ua
nseq
ÓÒ ÙÐÐ Ñ ÓÐ Ó
lum do
co
cil
Ò
Ö
Ø
Ö
se
Ò
×
iat
ÚÓ
Ò
ÐÙ
× ÙØ Ð ÕÙ Ô
es
fug
Ü
ÓÑÑÓ
ÓÐÓÖ Ù Ù
auÓte ÓÒ× ÕÙ Øº
lore euriatur.
Duis
in
lla pa

nu

ur
Exceptecaecat
oc
sint

Ø ¬
ÒÓÒ Ô
Ù Ù
ÐÐÙÑ
Ø ÒÙÐÐ
Ô Ö ØÙÖ
×
º
ÖÙÑº
Ü ÔØ
ÙÖ × ÒØ
ÒÓÒ ÔÖÓ
Ó
ÓÒ× Ø
Ø ÙÔ
ÒØ¸ ×ÙÒ
Ø
Ø Ø
Ø Ò ÙÐÔ
× ÖÙÒØ
Ù×ÑÓ
ÕÙ Ó«
ÑÓÐÐ Ø
¹
ÒÑ
Ø ÓÐÓÖ
­ Ð Ó¹
ÑÒÑ
Ú
Ø Ø ÓÒ
ÄÓÖ Ñ
ÙÐÐ
Ô×Ù

ÖÙÑº

Ü ÔØ ÙÖ ×
ÒÓÒ ÔÖÓ ÒØ¸
×Ù
× ÖÙÒØ ÑÓÐ
ÖÙÑº ÄÓÖ Ñ
Ô×
ÓÒ×
Ü ÔØ ÙÖ × ÒØ Ó
Ø ØÙÖ
Ô
Ø ÙÔ Ø Ø
ÒÓÒ ÔÖÓ ÒØ¸
Ù×ÑÓ
Ø ÑÔÓÖ
×ÙÒØ Ò ÙÐÔ
ÕÙ Ó« ¹ Ø
× ÖÙÒØ ÑÓÐÐ Ø
ÓÐÓÖ Ñ Ò
ÒÑ
­ Ð Ó¹ Ñ Ò
ÖÙÑº
Ñ Ú Ò Ñ¸ Õ
Ø Ø ÓÒ ÙÐÐ Ñ ÓÐ
Ü
ÄÓÖ Ñ Ô×ÙÑ
ÓÑÑÓ Ó Ó
ÓÐÓÖ × Ø Ñ Ø¸
ÓÒ× Ø ØÙÖ
Ô× Ò
Ð Ø¸ ×
Ó
Ù×ÑÓ Ø ÑÔÓÖ
Ù × ÙØ ÖÙ
Ò
ÓÐÓÖ

ÓÐÓÖ Ò Ö ÔÖ ¹
ÚÓÐÙÔØ Ø Ú Ð Ø
¬ ÐÐÙÑ
Ù Ù Ø ÒÙÐÐ
Ô Ö ØÙÖº

Ø Ø ÓÒ ÙÐÐ Ñ Ó Ð ÓÖ × Ò ×
Ü
ÓÑÑÓ Ó ÓÒ× ÕÙ
Ù × ÙØ ÖÙÖ ÓÐÓ
Ò Ö Ø Ò ÚÓÐÙÔØ Ø Ú Ð
ÓÐÓÖ Ù Ù Ø ÒÙÐÐ Ô

Ü ÔØ ÙÖ × ÒØ Ó
ÒÓÒ ÔÖÓ ÒØ¸ ×ÙÒØ Ò ÙÐ
× ÖÙÒØ ÑÓÐÐ Ø Ò Ñ
ÖÙÑº ÄÓÖ Ñ Ô×ÙÑ ÓÐÓ
ÓÒ× Ø ØÙÖ
Ô× Ò
DuiØs ÑÔÓÖ Ò
Ü ÔØ ÙÖ × ÒØ Ó
Ø ÙÔ Ø Ø
Ù×ÑÓ
ÙÒ
aute
re
preh
de Ò iruÐ re
ÒÓÒ ÔÖÓ ÒØ¸ ×ÙÒØ Ò ÙÐÔ ÕÙ Ó« ¹ ve
Ø litÓÐÓÖenÑ
ÕÙ do
ºl
esse rit in
lup
× ÖÙÒØ ÑÓÐÐ Ø Ò Ñ
­ Ð Ó¹ gi
ÑatÒ nu
Ñ lla
Ú ÒcilluÑ¸
m ÕÙ ×voÒÓ­
paria dolore eu
ÖÙÑº
Ø Ø ÓÒ ÙÐÐ Ñ Ó tu
Ð r. ÓÖ × Ò ×
Ex
Ü ceptÓÑÑÓ Ó ÓÒ× ÕÙ
cu
ÄÓÖ Ñ Ô×ÙÑ ÓÐÓÖ × Ø Ñ Ø¸
ÓÒ× Ø ØÙÖ
Ô× Ò
Ð Ø¸ ×
Ó
Ù×ÑÓ Ø ÑÔÓÖ Ò
ÙÒØ ÙØ Ð ÓÖ

pid

eur

i

Ù × ÙØ ÖÙÖ ÓÐÓ
Ò Ö Ø Ò ÚÓÐÙÔØ Ø Ú Ð

incididunt ut labore et dolore
magna aliqua. Ut enim ad
minim veniam, quis nostrud
exercitation ullamco laboris
nisi ut aliquip ex ea commodo
consequat.

do eiusmod
temp or
incididunt ut
labore et dolor
e
magna aliqu
a. Ut enim
ad
minim venia
m, quis nostr
ud
exercitation
ÙÔ
ullam
Ø
co
Ó
¹ laboris
nisi
ÔØ ÙÖut× ÒØaliqu
ip
exÕÙea Ó«
Ü cons
ÙÐÔ
comm
Ò
Ø
×ÙÒ
Ð Ó¹ odo
ÒÓÒ ÔÖÓ ÒØ¸equat. Ò Ñ ­

Ñ Ò Ñ Ú Ò Ñ Ó Ð ÓÖ × Ò × ÙØ
Ø Ø ÓÒ ÙÐÐ ÑÓ Ó ÓÒ× ÕÙ Øº
Ü ÓÑ
Ø¸
ÐÐ Ø
Ò Ö ÔÖ ¹
× ÖÙÒØ ÑÓÔ×Ù
ÓÐÓÖ × Ø Ñ
ÖÙÖ ÓÐÓÐ ÖØ ¬ ÐÐÙÑ
Ñ Ñ Ò Ð Ø¸ ×
Ù × ÙØ ÙÔØ
Ø Ú
ÖÙÑº ÄÓÖDuisÔ ×aute
º
ÓÖ in
irure
ÙØ Ð dolor
Ø ØÙÖ hend
Ò Ö Ø Ò ÚÓÐ Ø ÒÙÐÐ Ô Ö ØÙÖ
ÓÒ× repre
Ò ÙÒØ
ÓÖ erit
inÍØ volup
Ò Ñ tate
Ø ÑÔ
Ó
º
ÓÐÓÖ Ù Ù
velit
Ù×Ñ
ÕÙ
Ð
esse
dolor
Ñ Ò cillum
ÖÙ eÜ Öeu fuØ ÙÔ Ø Ø¹ Ø giat
ÓÐÓÖ nulla
ÕÙ × ÒÓ­
ÒØ Ó
Ó«
tur.
Ú Ò Ñ¸paria
× ÙØ Ð Õ
Ü ÔØ ÙÖ ××ÙÒ
Ø Ò ÙÐÔ ÕÙ­ Ð Ó¹ Ñ Ò Ñ ÙÐÐ
Ó Ð ÓÖ × Ò
Ø Ø ÓÒExceÑÑÓ Ó ÓÒ× ÕÙ Øº
ÒÓÒ ÔÖÓ ÒØ¸
Ø ÒÑ
× ÖÙÒØ ÑÓÐÐ
Ü ÓÑ pteur sint occaecat
cupidatat non
Ö Ò Ösunt
ÓÐÓ
proid
ÖÙÑº
ent,
ÙØ ÖÙÖ
¬
Ø Ñ Ø¸ in culpa
Ù × qui
oﬃci
Ø ÚaÐ Ødeser
Ó
Ñ ÓÐÓÖ ×
Ø Ò ÚÓÐÙÔØ
Ô Ö ØÙunt
ÄÓÖ Ñ Ô×ÙÔ × Ò Ð Ø¸ × ÓÖ mollÒitÖ anim
idØ ÒÙÐ
estÐ labo
rum.
Ù Ù dolor
ÓÒ× Ø ØÙÖ ÑÔÓÖ Ò ÙÒØ ÙØ ÒÐ Ñ LoreÓÐÓmÖ ipsum
sit
Ø
cons
º ÍØ Ü Ö ¹ ectetur adipisicin amet,
Ù×ÑÓ
Ò Ð ÕÙ ÒÓ­
g elit,
Ñ
ÖÙ
Ö
sed
ÓÐÓ
do
Ø
eiusmod temp
Ñ¸ ÕÙ ×
or incididunt
ÑÒÑ Ú Ò

dolor
irure en
rit ÖÙÖ
Ù de
× ÙØ
repreh
Ò ÖØ Ò

ÄÓÖ Ñ Ô×ÙÑ ÓÐÓÖ × Ø Ñ Ø¸
ÓÒ× Ø ØÙÖ
Ô× Ò
Ð Ø¸ ×
Ó
Ù×ÑÓ Ø ÑÔÓÖ Ò
ÙÒØ ÙØ Ð ÓÖ
Ø ÓÐÓÖ Ñ Ò Ð ÕÙ º ÍØ Ò Ñ
Ñ Ò Ñ Ú Ò Ñ¸ ÕÙ × ÒÓ­ÖÙ Ü Ö ¹
ep luptate do- e nsØeqØ uÓÒ ÙÐÐ Ñ Ó Ð ÓÖ × Ò × ÙØ Ð ÕÙ Ô
ÓÑÑÓ Ó ÓÒ× ÕÙ Øº
n vo cillum giat co Ü
esse eu fu
Duis do
lore pariatur.
irure enÙ × ÙØ ÖÙÖ ÓÐÓÖ Ò Ö ÔÖ ¹
nulla
r
repreh
pteu
Ò Ö Ø Ò ÚÓÐÙÔØ Ø Ú Ð Ø ¬ ÐÐÙÑ
Exce occaecat
ÓÐÓÖ Ù Ù Ø ÒÙÐÐ Ô Ö ØÙÖº
sint

×
Ò

Ø
ÐÙÔ
ÚÓ

Ø

ÐÐ
Ø ÒÙ

Ù

Ù

Ô

ØÙÖ

Ö

Ø

ÔØ

Ü

Ó
ÔÖ

×
ÓÒ

Ø

× ÒØ

ÙÖ
ÒØ¸

ÒØ
× ÖÙ

Ó

Ø
×ÙÒ

ÑÓ

Ò

ÐÐ Ø

Ó«

ÕÙ

ÙÐÔ

­

ÓÐÓ

¹
Ó¹

Ð

Ø

Ó
Ù×Ñ
ÓÐ

Ø
Ñ
Ø

Ò Ñ

Ñº
Ñ
Ô×Ù

Ø

ÙÔ

Ò
Ø
Ü

Ö

Ñ

× Ø
Ð Ø

×

Ø¸
Ó

Duis aute irure dolor in
reprehenderit in voluptate
velit esse cillum dolore eu fulit co
giat nulla pariatur.
illum
nseq
u fu douat.
iatur. giat
Excepteur sint occaecat
D
irure uis
cupidatat non proident, sunt
eur
repreh dolor aut
in culpa qui oﬃcia deserunt
en
in
caec
at in volupt derit
mollit anim id est laborum.
esse
ate
no
Lorem ipsum dolor sit amet,
unt inn lore cillum velit
euБО ЯУdo
consectetur adipisicing fﬁ
elit,
ЛА
nuЦО
llaНСpЕЯ
cia ДО
РИfu ИС
НИС
УА С gi
sed do eiusmod tempor in-С
АУ
ЛУ ТЕ ИР

Т

ПТ
УР
cididunt ut labore et dolore
Т НУ АТЕ Ж Е ДОЛО
ЛЛА
ЕЛ
Р ИН
ПАРИ ИТ ЕССЕ
magna aliqua. Ut enim ad
Р
АТУР
ЦИЛЛ
ТЕ
minim veniam quis nostrud УР С

Figure 1. The motivating example for unique backgrounds: the BuoyOING focus+context interface for
browsing bidirectionally hyperlinked documents. The interface shows the relevant fragments of the other ends
of the links and animates them ﬂuidly to the focus upon traversing the link. a) shows a small document
network. b) and c) show what a user sees while browsing the network, b) without and c) with background
texture. There are three keyframes where the animation stops. Two frames of each animation between the
keyframes are shown. The unique backgrounds help the user notice that the upper right buoy in the last
keyframe is actually a part of the same document (1) which was in the focus in the ﬁrst keyframe. Our (as
yet untested) hypothesis is that this will aid user orientation.

Proceedings of the Seventh International Conference on Information Visualization (IV’03)
1093-9547/03 $17.00 © 2003 IEEE

3. The motivation for Unique Backgrounds: the BuoyOING user interface
Focus+Context, or, ﬁsheye views[10] are a
paradigm for viewing large, structured information sets
by showing the current area of interest (focus) magniﬁed and the structurally connected but further-away
elements peripherally, with less magniﬁcation. Much
of the work on focus+context views has concentrated
on tree structures or ﬂat 2D images or maps.
The motivating example for unique backgrounds is
the BuoyOING (Buoy-Oriented Interface, Next Generation) user interface, a focus+context interface for
navigating hypertext. BuoyOING is a logical step from
the earlier work on Fluid Links[39], hypercept animations[23], and transpointing windows[24]. BuoyOING
has been designed from the ground up around the following three principles:
1. the user should always see all link targets (”you
should see where you can go”)
2. the link transition should be ﬂuidly animated (”you
should see where you do go”)
3. the link transition and resulting view should make
it obvious to the user how to go back, without an explicit back button (”once you get there, you should
see how you can get back”). This implies bidirectional
links.
The links are between speciﬁc areas of the 2D documents, and the relevant fragments of the target document is shown ﬂoating in the margin when the link
anchor is close to the focus. Figure 1 shows a sample
document structure and a traversal, with and without
unique backgrounds.

4. Generating Unique Background Textures
In this section, we discuss the general principles we
have used to derive our algorithm to generate unique
background textures. The goals are that the unique
backgrounds should be easily distinguishable and recognizable, and that they should not signiﬁcantly impair
the reading of black text drawn on top.
Our approach is an extension of the type of inversion approach that has been used by Ware and
Knight[37] for inverting the earliest stage of the visual
system in order to place a particular vector or scalar
ﬁeld of data in the texture “channel”.
The ability to distinguish a particular texture from
a large set depends on the distribution of textures in
the set. For instance, it is intuitively clear that textures
with independently random texel values would be a
very bad choice: all such textures would look alike,
being just noise. In order to design a distinguishable

Feature extraction

Feature generation

Feature vector
Matching

Seed value
Memorized vectors
Objects w/ identity

Figure 2. The qualitative model of visual perception
used to create the algorithm. The visual input is
transformed into a feature vector, which contains
numbers (activation levels) corresponding to, e.g.,
colors, edges, curves and small patterns. The feature
vector is matched against the memorized textures.
In order to generate recognizable textures, random
seed values should produce a distribution of feature
vectors with maximum entropy.

distribution of textures, we have to take into account
the properties of the human visual system.
The simple model of texture perception we use assumes that at some point, the results from the diﬀerent
pre-attentive feature detectors, such as diﬀerent shapes
and colors, are combined to form an abstract feature
vector (see Fig. 2). As seen for example in [25], only
a limited number of diﬀerent features detected can be
grouped into objects, indicating that the spatial resolution of the feature vector is quite low — as a well-known
example, conjunction coding is not preattentive — red
squares are hard to ﬁnd among green squares and red
and green circles.
The feature vector is then used to compute which
concept the particular input corresponds to by comparing it to memorized models in a simple perceptron-like
fashion[30, 38]. This conﬁguration is commonly used
in neural computation.
This rough, qualitative model is able to explain
why uniformly random texels do not make easily
distinguishable background textures: after the “preprocessing”, diﬀerent instances of noise would all yield
almost exactly the same feature vector in the brain.
Noise has no shape because there is no correlation between the pixels.
From the model we can see that to be distinguishable, a feature vector for a given texture should always
be the same. Fragments of a non-repeating texture will
be slightly diﬀerent, resulting in slightly diﬀerent vectors even if the local structure is the same. A repeating
texture should thus be easier to recognize. Our anecdotal observations conﬁrm this.
Additionally, the entropy of the feature vectors

Proceedings of the Seventh International Conference on Information Visualization (IV’03)
1093-9547/03 $17.00 © 2003 IEEE

over the distribution of textures should be maximized.
The distribution should contain occurrences of as many
diﬀerent features as possible, and the features should be
distributed independently from each other. However,
the results cited above[25] also indicate that in any single texture, only a limited range of features should be
used.
In a sense, the model of perception should be inverted in order to produce a unique background from a
random vector. Features that are orthogonal for human
perception (e.g., color and the direction of the fastest
luminance change) should be independently random,
and features not orthogonal (e.g., colors of neighbouring pixels) should be correlated so as to maximize the
entropy.
An important point in generating the backgrounds
is that the texture appearance should have no correlation with any attribute or content of the document
so that the textures of any hyperlinked documents are
similar only by chance.

5. Hardware-accelerated implementation
In this section, we discuss our hardwareaccelerated implementation (libpaper) of unique backgrounds (papers).

A. Parameter hierarchy
We have found that setting the parameters hierarchically produces the best results: the parameters
for diﬀerent passes should depend on hyperparameters
randomly selected for the entire paper. This is in accordance with the discussion about [25] above: the hyperparameters limit the number of diﬀerent features that
are rendered onto one texture.
Our current parameter hierarchy is shown in Fig. 3.
The individual parameters are explained in the subsections below.

B. Rationale for a Fragment-based implementation
One major goal for the implementation is to support complicated mappings between paper and screen
coordinates, such as ﬁsheye distortion. To make this
simple, all processing when rendering the background
texture must be done on the fragment level after the
texture accesses, i.e., we cannot use procedural geometry except if pre-rendering the background into a texture.
However, pre-rendering each texture is likely to be
too time- and memory-consuming if there are dozens
of diﬀerent documents visible at the same time, so we
shall limit ourselves to pure fragment-based rendering
in this article. However, if a single background covers

CIELAB

Basis textures

Colors

Basis texture
probabilities
.81

Combiner
programs

Global

Repeat unit

.11
Per-paper

Combiner
parameters

Combiner
program

Per-pass

TexGen

Basis Texture

Per-texunit

Figure 3. The parameter hierarchy for unique textures in our implementation. At the highest level,
global hyperparameters deﬁne the distribution of the
textures. For reasons explained in text, the parameters used by diﬀerent rendering passes of the same
background texture need to be correlated; this is
achieved by having them depend on hyperparameters
selected for each paper from the global distribution.

large areas of the screen, pre-rendering may increase
performance considerably, and therefore our implementation does support two rendering modes with diﬀerent tradeoﬀs. In the direct mode, small, static basis
textures are used, which requires 2-3 passes with all
texture units enabled. In the pre-rendered mode, rendering requires 1 pass with only one texture unit, but
the repeating unit of the texture has to be pre-rendered
into a texture of its own. To achieve a satisfactory
image quality in zooming with pre-rendering, a relatively large texture has to be used for each background;
512x512 is not really suﬃcient.
Plain OpenGL 1.3 does not by itself provide
enough ﬂexibility in the fragment pipeline to allow for
generating features nonlinearly from the basis textures.
Because of this, and the availability of stable Linux
drivers, our main platforms are NV10, i.e., OpenGL
1.3 + GL NV register combiners, and NV25, i.e., NV10
+ GL NV texture shader3. We are working on an implementation based on GL ARB fragment program once
suitable hardware and Linux drivers emerge.

C. Colors
Color is the most dominant visual attribute of a
texture. Therefore, it is essential that the overall colors of the backgrounds are maximally diverse with respect to color perception. However, we come again
to the number-of-diﬀerent-features arguments of Section 4: too many diﬀerent colors in a single background
are perceived just as a mix of many colors, making all

Proceedings of the Seventh International Conference on Information Visualization (IV’03)
1093-9547/03 $17.00 © 2003 IEEE

Figure 4. The complete set of 2D basis textures
used by our implementation. All textures shown in
this article are built from these textures and the corresponding HILO textures for oﬀsetting.
such backgrounds look the same.
To maintain recognizability, we use a small palette
of colors for each paper, selected randomly from a
heuristic distribution. The ﬁnal image contains convex combinations of the palette colors.
Even though the CIE L∗ a∗ b∗ [7] color space is fairly
perceptually uniform, it is not good for selecting random colors (cf. [15]): using a uniformly chosen hue
angle produces too much blue and too little yellow for
high L∗ (luminance). Because of this, we use a different color circle with seven evenly spaced “primary”
hues (RGB, CMY and orange).
Hues are chosen from a distribution which usually
clusters them fairly close together around a uniformly
chosen mean but also allows far-away hues in the same
palette occasionally. Because the shape of the RGB
color gamut irregularly limits the saturations of light
colors and linear interpolation can further reduce the
saturation, the saturations of the palette colors are chosen from a distribution emphasizing saturated colors:
unsaturated colors can easily cause a too multicolored
palette because the adaptive eﬀects of the eye shift
them towards the complementary colors of the more
saturated colors in the palette.
For readability, we only use colors with the CIE L∗
value over 80. Note that the display gamma interacts
with the lightness computation: we have adjusted the
computations for a display gamma of 2.2, which is typically the default in PC systems. For each background,
we use colors from both the dark and light end of the
80–100 range in order to create some contrast. This
makes the shapes in the texture apparent, and avoids
the unpleasant, blurry appearance of images with only
chroma changes in colors.

D. Basis textures
The shapes of the ﬁnal background texture are generated entirely from a small set of static basis textures.

Even though the basis textures are RGB textures, they
contain no color information: they are simply treated
as 3- or 4-vectors to be used in various ways to create
shapes, and color is added by the register combiners
using the palette selected as described above.
We have obtained good results with the basis textures in Fig. 4: a mix of small textures with uniformly
random texels, larger textures with noise or turbulence[27], and simple geometric images (e.g., checkerboard).
As for the selection of basis textures for each paper, the principle of limiting the number of diﬀerent
features in each texture applies here as well: we use
hyperparameters for each background texture to control the probabilities of selecting diﬀerent basis textures
so that each paper will mostly have only basis textures
two or three types.

E. Texture coordinates
The choice of the geometry of the repeating unit
(a parallelogram) ﬁxes an absolute scale for the paper.
The repeating unit should be fairly isotropic to avoid
the degeneration of textures to diagonal lines, and the
units for diﬀerent textures should be relatively similar
in size. The repeating unit is chosen from a heuristic
distribution satisfying these criteria.
After a repeating unit is ﬁxed, there is still freedom
in choosing texture coordinates for each basis texture:
any mapping of the texture is ﬁne, as long as it repeats with the selected repeating unit. For example, a
texture can repeat multiple times inside the repeating
unit, or can be skewed with respect to the repeating
unit. Again, a heuristic distribution is used which does
not skew or scale the basis texture too much too often.

F. Texture shading
On the NV25 architecture, the texture accesses can
be customized further by the use of texture shading:
the texture coordinates used by a texture unit can be
made to depend on the result of a previous texture unit.
This can be used to create a large variety of shapes[27].
So far, we have only used oﬀset textures with random
oﬀset matrices, but even they do improve the quality
of the output.

G. Register combiners
The NVIDIA register combiners extension is used
to combine the the 3- and 4-vectors obtained from the
basis textures and the palette colors into the ﬁnal fragment color. Our need for the combiners is rather unconventional: we want to lose most of the original shapes
of the basis textures in order to create new, diﬀerent
shapes from the interaction of the basis texture values

Proceedings of the Seventh International Conference on Information Visualization (IV’03)
1093-9547/03 $17.00 © 2003 IEEE

ground look similar at diﬀerent scales, but this would
remove the use of the texture as a cue of scale.
Our nonlinear use of the register combiners does
have some ill eﬀects when zooming the texture out to a
very small scale: mipmapping will not give the correct
average color value. It may be possible to alleviate this
by modeling the texture mathematically and calculating the correct average and placing corrective terms to
the equations. However, in the intended zooming range
the current system is quite satisfactory.

B. Text readability
Figure 5. How the limited register combiners of the
NV10 architecture can be used to generate shapes.
Top: the two basis textures. Bottom left: dot product of the basis textures: 2(2a − 1) · (2b − 1) + 1/2,
where a and b are the texture RGB values. Bottom right: dot product of the basis textures squared:
2
32 ((2a − 1) · (2b − 1)) . This term can then be used
to modulate between two colors.
and combiner parameters chosen randomly from the
seed number. For this, we use dot products of texture
values with each other and with random constant vectors, and scale up with the register combiner output
mappings to sharpen the result (see Fig. 5). The resulting values are used for interpolating between the
palette colors. Because some basis textures have blurrier edges than others, the output scalings need to be
adjusted depending on the basis textures selected.

6. Experiences, evaluation
A. Overall appearance of the resulting textures
As seen in Fig. 7, the overall appearance of the
textures is somewhat natural and the textures clearly
do have unique distinguishing features.
They can be zoomed quite well, even though we
have not tried to attain inﬁnite zoomability[11] with
the current implementation, but only the more modest
goal of zooming within a range that would be reasonable for a single PDF document, i.e., approximately 20fold diﬀerence between minimum and maximum zoom.
Although texture perception is scale-independent
to some extent, the display resolution and certain spatial interactions in color perception limit the scale at
which diﬀerent features can be pre-attentively perceived. Therefore, we have chosen the texture coordinate mappings for diﬀerent texture units so that the
resulting textures have separate distinguishing features
on both small and large scales.
It could be possible[11] to make the unique back-

The most common criticism against this work concerns text readability. Indeed, one of the most diﬃcult
aspects of this work was tuning the random color selection to produce acceptable results. However, in the
current version, even relatively small text is quite legible on the backgrounds.
Experiments in [33] indicate that a background
texture only aﬀects readability when the text contrast
is low. Also, as discussed there, subjective assessments
of readability often have low correlation with objective
measurements.
Additionally, text readability on the generated
backgrounds depends strongly on the text scale; making it easy for the user to zoom ﬂuidly in and out helps.
It is also possible to enhance the text readability
explicitly, by lightening (“bleaching”) the background
slightly around the area where the text is drawn. The
bleaching can be made almost unnoticeable on a computer screen and works well because we start from a
fairly light background.

C. An Initial Recognizability Experiment
Experiments on black-and-white ink blots and
snow crystals [13] have shown that complex, unfamiliar
pictures can be remembered and recognized and that
recognition performance decreases very little over time.
In order to evaluate the recognizability of our procedurally generated textures, we need to have an appropriate comparison point. Pictures of natural objects
would not be appropriate, because they cannot be generated in inﬁnite amounts from seed numbers and they
would easily yield undesirable semantic associations.
Lacking a better example, we shall use plain solid color
backgrounds as a baseline even though the colors of
even a small set of randomly chosen colors would most
likely not be discriminable.
Another question is how many textures would the
user have to remember for it to be useful. Studies of
web cache statistics (see, e.g., [4]) have shown that ﬁle
popularity approximately follows Zipf’s law so that a
small number of documents accounts for most of the

Proceedings of the Seventh International Conference on Information Visualization (IV’03)
1093-9547/03 $17.00 © 2003 IEEE

Figure 6. Two diﬀerent screenshots of a structure of PDF documents viewed in a focus+context view. The
user interface shows relationships between speciﬁc points in the documents. Each document has an unique
background, which makes it easy to see that the fragment of a document on the right side of the bottom
view is the document fully seen in the top view; without unique backgrounds, this would be relatively diﬃcult
and would require traversing the link.

Proceedings of the Seventh International Conference on Information Visualization (IV’03)
1093-9547/03 $17.00 © 2003 IEEE

Figure 7. A number of unique backgrounds generated by our system. This view can be rendered, without
pre-rendering the textures, in 20ms on a GeForce4 Ti 4200 in a 1024x768 window (ﬁll-rate/bandwidth limited).
use, see Fig. 9.
Thus, we chose to measure the recognition of only
15 target textures or colors in the experiment. Our
hypothesis is that the texture backgrounds are more
recognizable than the solid colors.
C.1 Method
Participants. Five participants na¨ıve to the hypothesis and our texturing work performed the experiment in both conditions.
Stimuli. 15 target backgrounds and 15 distractor
backgrounds were randomly chosen for both the texture and solid color conditions. The distribution of
the solid colors was the same that is used for the texture colors except that the highest lightness tail was
de-emphasized to increase the otherwise low discriminability of very light, unsaturated colors.
Procedure. Each participant performed the test individually in both conditions in a random order. First,
the 15 target backgrounds were shown sequentially, in
a random order, 5 seconds each. Then, recognition was
tested by showing the 15 target backgrounds and the 15
distractor backgrounds in a random order and having
the participant answer “seen” or “not seen” for each
one. The time for answers was not limited.

Table 1. Results of a recognition experiment with
15 previously seen textures and light colors to be
picked out from 15 not previously seen instances.
The numbers give the percentage of trials and the
average reaction time in seconds for the ﬁve subjects.
This shows that the textures are quite recognizable
even after just one previous viewing.
textures
colors
correct incorrect
correct incorrect
seen
72 (2.6s) 28 (5.5s) 71 (2.8s) 29 (4.1s)
not seen 84 (3.0s) 16 (5.6s) 43 (3.4s) 57 (4.0s)
total
78 (2.8s) 22 (5.5s) 57 (3.1s) 43 (4.1s)
C.2 Results
The results are summarized in Table 1. An analysis of variance indicates that the average recognition
performance is signiﬁcantly better for the textures than
for the solid colors [F(1,4) = 19.0, p = .012]. The large
number of false positives shows that solid colors do not
have enough variation for unambiguous recognition.
Of course, solid colors could facilitate recognition
in the presence of other cues, such as the text of the
document. However, the recognition of similar-looking
fragments of documents would still depend on conscious eﬀort on the user’s part — exactly what the
unique background textures were designed to avoid.

Proceedings of the Seventh International Conference on Information Visualization (IV’03)
1093-9547/03 $17.00 © 2003 IEEE

a)

b)

c)

d)

Figure 8.
Enhancing text readability on colored
backgrounds: a) Original, b) Zooming, c) Bleaching, d) The bleached version without drawing the
black text, showing the blurred lightening.

7. Conclusions
We have presented a perceptually designed
hardware-accelerated algorithm for generating recognizably unique backgrounds. The motivating example,
the BuoyOING user interface demonstrates that the
method is at its most useful when the same document
can be reached through several ways and fragments of
documents are seen.
Of course, we cannot hope to match in quality
a unique graphical appearance designed by a human
designer; magazines and web sites have long used
skillfully designed graphical elements to make themselves recognizable. However, our algorithm is able to
generate an unlimited amount of unique backgrounds
cheaply, making it possible, e.g., for all academic articles with similar typography to have their own background.
So far, we have concentrated mostly on low-end
hardware, and have not even tapped the full potential

Figure 9. Zipf’s law concretized: why distinguishing 15 textures from a large number of others helps.
In real life, some documents get accessed far more
often than most. The diagram shows 2000 documents weighted with Zipf’s law with exponent 1.1.
Each square represents a document, and the area of
each square is scaled to its rate of accesses. Under
these conditions, the 15 most important documents
account for approximately half of the accesses. Of
course, it is impossible to know which documents will
be important and that will also change with time so
all documents should be textured stably from the
ﬁrst viewing onwards.
of the NV25 architecture.
We have conducted an initial recognition experiment showing that the textures generated by our algorithm are indeed recognizable. Carrying out more
usability tests is necessary, both to measure how well
textures can be remembered and to make the ad hoc
distributions more experimentally based.
It can of course be argued that the backgrounds
clutter the display visually, making the user interface
more confusing, and may not even be helpful. Indeed,
many aspects of the system are a compromise between
recognizability and other goals such as readability, rendering performance, or user comfortability.
Overall, however, we feel that the backgrounds can
greatly improve user orientation, enabling more eﬃcient views to hyperstructured content, and therefore
that the beneﬁts can be made to outweigh the costs.

8. Acknowledgments
The authors would like to thank Marketta
Niemel¨a for help with ANOVA, and John Canny, Benja
Fallenstein, Marketta Niemel¨a and Pertti Saariluoma
for discussions. Benja Fallenstein, Matti Katila, and
Asko Soukka have contributed to the development of
the BuoyOING interface in aspects not related to the
unique background textures.

References
[1]

J. R. Bergen. Theories of visual texture perception.
In D. Regan, editor, Vision and Visual Dysfunction,

Proceedings of the Seventh International Conference on Information Visualization (IV’03)
1093-9547/03 $17.00 © 2003 IEEE

[2]
[3]
[4]

[5]

[6]

[7]
[8]

[9]

[10]
[11]

[12]

[13]

[14]
[15]

[16]

[17]

[18]

[19]

[20]
[21]

volume 10B, pages 114–134. Macmillian, New York,
1991.
J. R. Bergen and E. H. Adelson. Early vision and
texture perception. Nature, pages 363–364, May 1988.
J. F. Blinn. Simulation of wrinkled surfaces. In Proc.
SIGGRAPH’78, pages 286–292. ACM Press, 1978.
L. Breslau, P. Cao, L. Fan, G. Phillips, and S. Shenker.
Web caching and zipf-like distributions: Evidence and
implications. In Infocom’99 proceedings, pages 126–
134, 1999.
V. Bruce, P. R. Green, and M. A. Georgeson. Visual
Perception: Physiology, Psychology, and Ecology, 3rd
edition. Psychology Press, 1996.
E. E. Catmull. A Subdivision Algorithm for Computer
Display of Curved Surfaces. PhD thesis, Dept. of CS,
U. of Utah, Dec. 1974.
Colorimetry. CIE Publication No. 15.2, 2nd Edition,
1986.
R. L. Cook. Shade trees. In Proceedings of the 11th annual conference on Computer graphics and interactive
techniques, pages 223–231, 1984.
G. C. Cross and A. K. Jain. Markov random ﬁeld texture models. IEEE Transactions on Pattern Analysis
and Machine Intelligence, 5(1):25–39, 1983.
G. W. Furnas. Generalized ﬁsheye views. In Proceedings of CHI ’86, pages 16–23. ACM Press, 1986.
G. W. Furnas and X. Zhang. Illusions of inﬁnity: feedback for inﬁnite worlds. In Proc. UIST’00, pages 237–
238. ACM Press, 2000.
S. Geman and D. Geman. Stochastic relaxation, Gibbs
distributions, and the Bayesian restoration of images.
IEEE Transactions on Pattern Analysis and Machine
Intelligence, 6:721–742, 1984.
A. G. Goldstein and J. E. Chance. Visual recognition
memory for complex conﬁgurations. Perception and
Psychophysics, 9(2B):237–241, 71.
R. Gurnsey and D. J. Fleet. Texture space. Vision
Research, 41:745–757, 2001.
C. G. Healey. Choosing eﬀective colours for data visualization. In Proc. IEEE Visualization ’96, pages
263–270, 1996.
P. S. Heckbert. Survey of texture mapping. In
M. Green, editor, Proceedings of Graphics Interface
’86, pages 207–212, 1986.
D. J. Heeger and J. R. Bergen. Pyramid-based texture
analysis/synthesis. In Proc. SIGGRAPH’95, pages
229–238. ACM Press, 1995.
B. I. Recognition–by–components: A theory of human image understanding.
Psychological Review,
94(2):115–147, 1987.
V. Interrante. Illustrating surface shape in volume data
via principal direction-driven 3d line integral convolution. In Computer Graphics (SIGGRAPH ’97 Proceedings), pages 109–116, 1997.
B. Julesz. Visual pattern discrimination. IRE Transactions on Information Theory, 8(2):84–92, 1962.
B. Julesz. Textons, the elements of texture perception,
and their interactions. Nature, 290:91–97, Mar 1981.

[22] E. M. H. Ken Perlin. Hypertexture. Computer Graphics, 23(3):253–262, 1989.
[23] D. Milgram and W. B. Cowan. Hypercept: behavioural linkage in hypertext environments. In Proc.
NPIVM’99, pages 49–55. ACM Press, 1999.
[24] T. H. Nelson. Xanalogical structure, needed now more
than ever: parallel documents, deep links to content,
deep versioning, and deep re-use. ACM Computing
Surveys, 31(4es), 1999.
[25] I. R. Olson and Y. Jiang. Is visual short-term memory
object based? rejection of the “strong-object” hypothesis. Perception & Psychophysics, 64(7):1055–1067,
2002.
[26] D. R. Peachey. Solid texturing of complex surfaces.
In Proceedings of the 12th annual conference on Computer graphics and interactive techniques, pages 279–
286. ACM Press, 1985.
[27] K. Perlin. An image synthesizer. Computer Graphics
(SIGGRAPH ’85 Proceedings), 19(3):287–296, 1985.
[28] A. R. Rao and G. L. Lohse. Towards a texture naming system: Identifying relevant dimensions of texture.
Vision Research, 36:1649–1669, Jun 1996.
[29] J. Rhoades, G. Turk, A. Bell, A. State, U. Neumann,
and A. Varshney. Real-time procedural textures. In
Proceedings of the 1992 symposium on Interactive 3D
graphics, pages 95–100. ACM Press, 1992.
[30] F. Rosenblatt. Principles of Neurodynamics: Perceptrons and the Theory of Brain Mechanics. Washington,
DC: Spartan, 1962.
[31] J. Saarinen, D. M. Levi, and B. Shen. Integration of
local pattern elements into a global shape in human vision. Proceedings of the National Academy of Sciences
U.S.A., 94:8267–8271, Jul 1997.
[32] M.
Saxman.
The
Starﬁsh
program.
http://www.redplanetsw.com/starﬁsh/.
[33] L. F. V. Scharﬀ, A. L. Hill, and A. J. Ahumada, Jr.
Discriminability measures for predicting readability of
text on textured backgrounds. Optics Express, 6(4):81–
91, 2000.
[34] D. Schweitzer. Artiﬁcial texturing: An aid to surface
visualization. In Proc. SIGGRAPH’83, pages 23–29,
1983.
[35] D. Stalling. LIC on surfaces. In Texture Synthesis with
Line Integral Convolution, pages 51–64, 1997.
[36] G. Turk. Generating textures on arbitrary surfaces using reaction-diﬀusion. In Proc. SIGGRAPH’91, pages
289–298. ACM Press, 1991.
[37] C. Ware and W. Knight. Using visual texture for
information display. ACM Transactions on Graphics
(TOG), 14(1):3–20, 1995.
[38] B. Widrow and M. E. Hoﬀ. Adaptive switching circuits. In IRE WESCON Convention Record, volume 4,
pages 96–104, 1960.
[39] P. T. Zellweger, B.-W. Chang, and J. D. Mackinlay.
Fluid links for informed and incremental link transitions. In Proc. HyperText’98, pages 50–57. ACM Press,
1998.

Proceedings of the Seventh International Conference on Information Visualization (IV’03)
1093-9547/03 $17.00 © 2003 IEEE

