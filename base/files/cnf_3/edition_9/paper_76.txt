A Model of Real - Virtual Object Interactions
in Stereoscopic Augmented Reality Environments
Ming Hou
Defence Research & Development Canada
Ming.Hou@drdc-rddc.gc.ca

Abstract
The objective of this study is to find a practical
solution to improve remote 3D measurement accuracy by
investigating surface effects on a real-virtual object
alignment task in a stereoscopic augmented reality
environment. A psychophysical method of adjustment
was used for aligning a computer-generated graphic
virtual pointer with the designated targets on the image
of a real hemisphere surface. The known conflict
between binocular fusion and object occlusion cues was
confirmed to play a major role as an extra depth cue.
Surface texture density had significant impact on realvirtual object alignment task. A model was proposed for
the process of detecting the interactions of real-virtual
objects and guidelines were also given for augmented
reality interface design accordingly.

1. Introduction
Augmented Reality (AR) offers an exciting potential
for numerous applications in not only information
visualization but also remote manipulation [1][2].
Stereoscopic video based AR provide means for remote
3D measurement at low cost. A typical example is a
virtual tape measure (VTM) that can assist micro-surgery
as an accurate and precise measurement device within
remote 3D video images for high contrast corners and
edges [3]. Other types of VTM have also been used to
facilitate the inspection of underground sewer pipes [4]
and 3D geometric modelling for maintenance in nuclear
plants [5].
Although stereoscopic displays provide the general
advantage of enhanced relative depth perception, it has
been found with stereoscopic AR that observers can lose
the fusion of both real and virtual images when trying to
place virtual objects at points behind images of opaque
real objects and that the perceived locations of virtual
objects depends on their actual locations relative to

adjacent real objects in AR displays [3][6][7]. Thus the
perceptual ambiguities about the exact locations of real
and virtual objects make accurate 3D measurements often
difficult to achieve. In order to solve this problem and
provide guidance on 3D AR interface design, two
experiments have already been conducted [8][9][10].
Both involved interactive manipulation of a stereoscopic
graphic virtual pointer (VP) relative to designated targets
on a cylindrical real object surface viewed via a dual
camera stereoscopic video system.
In those earlier studies, it was found that, whenever
the VP went behind the surface of a real object, it
remained visible, due to the fact that the display software
had no knowledge of the presence of any of the
(unmodelled) real objects, which should otherwise
occlude the VP. In conflict with this phenomenon is the
mechanism of binocular fusion, which is necessary for
the observer's perception of a single fused image in depth.
The result of failure to occlude when the VP are placed
behind real objects has two consequences. One of the
results is a double image, due to the perceptual conflict
between consistent binocular disparity information and
inconsistent occlusion information. The double image
occurs because the brain is no longer able to reconcile the
(absence of) occlusion information while at the same time
fuse the left and right images for both the real object
(video) and the virtual object (graphic). The opposite
result occurs when the conflict is apparently not too large.
In other words, the brain continues to fuse both the real
and virtual object images while at the same time
accepting the presence of the unoccluded VP behind the
real object surface. Therefore, the real object appears
transparent.
The results from those studies also suggested that the
“pseudo-transparency” and converse fusion breakdown
phenomena might be used in combination as an extra
depth cue for detecting the interaction between real and
virtual objects under such circumstances. Especially
when a VP is placed behind a highly textured surface,
observers are less able to resist the tendency to fuse the
surface texture features stereoscopically.
In such
situation it is more difficult to perceive transparency, that

Proceedings of the Seventh International Conference on Information Visualization (IV’03)
1093-9547/03 $17.00 © 2003 IEEE

is, to reconcile the fact that the fused VP is behind the
fused real surface yet still visible – a “perceptual
impossibility”, resulting in the breakdown of either the
VP or the object surface into a double image. Although
this conflict between occlusion and binocular disparity
can bring some discomfort to perception of such AR
environments, observers can in fact exploit this
breakdown phenomenon to their advantage when judging
proximity interactions between virtual (graphic) and real
(video) surface images. Thus, this process can assist the
real-virtual alignment task. However, the question
remains as to whether this result can be maintained for all
other kinds of curved surfaces in the natural environment
rather than a cylinder surface, especially for other real
object surfaces (e.g., a rock or an aneurysm surface) with
which the VP has to be rotated in order to align with the
direction of the normal to the curved surfaces?
The above fusion breakdown phenomenon explains
why texture density played a major role for localizing real
object surfaces in these earlier experiments. However,
one question that remains to be addressed is: how
sensitive will observers be to different texture settings for
performing accurate alignment tasks? In other words, is
there any optimal density value for a certain type of
texture (random dot pattern in the current study) to
generate better performance?
In order to answer these questions, the object of the
study reported here was to further refine our
understanding of observers’ sensitivity with respect to
texture density and surface curvature, and confirm the use
of fusion breakdown as an extra cue to facilitate the
detection of real-virtual object interactions in AR
interfaces. Ultimately, a practical engineering solution
was expected to be developed for improving the realvirtual object alignment in real world operational
environments for arbitrarily oriented and arbitrarily
textured 3D curved surfaces, rather than limiting our
viable measurement situations always to high contrast
corners and edges.

2. Research Methodology
A 5x5 factorial design was carried out, comprising a
combination of five texture densities and five target
positions. Surface textures for all stimuli had the same
type of random dot pattern, which consisted of white dots
randomly dispersed on a black background (generated
using a software package: StereogramTM). Five levels of
texture density were used {0, 10, 20, 30, 40}, where the
numbers corresponded respectively to percent of the area
on the grid containing white dot elements. The remaining
area was all black on the surface background. Therefore,
0 means that the target area was all black, as there were
0% of white dots on the background. This provided a
control condition for no texture at all as a staring point of

the texture density continuum. (No density levels of > 50
were used, as this would have introduced too much glare
for the video cameras if more than half of the grid had
contained white dot elements).

2.1 Stereoscopic AR System
A 60 cm diameter hemisphere was chosen as the real
world stimulus, with five targets distributed across its
surface, as illustrated in Figure 1. Alternating field
stereoscopic images of the hemisphere were pre-recorded,
using a calibrated pair of JVC cameras located 158 cm
from the front surface of the hemisphere. The stereo
images were displayed on a Silicon Graphics Indy
workstation and were viewed through synchronized
IAMX liquid crystal shutter glasses. The observers’
viewing distance was 48 cm from the screen.
Stereo Camera
Stereoscopic AR Display
Virtual
Pointer

Hemisphere
Stimulus

Spaceball
Observer

Barrier

Figure 1. Experimental set-up (The centres of 5
circles in the stimulus image designate
target positions for different textured
sessions)
Considering the special geometry of the hemisphere
and camera-viewing angle, all targets were placed within
horizontally distributed circles at 50o elevation to provide
observers an adequate view of all the targets on the
hemisphere. One target was placed at the central
meridian of the hemisphere surface along the line of sight
(facing the observer). The other targets were distributed
on both the left and right sides (relative to the observer) at
spacing 30o from the central meridian.

2.2 Procedure
A psychophysical method of adjustment was used for
the alignment task of the VP with designated targets on
the surface of real hemisphere image. Participants used
the Spaceball to move the VP with six degree of freedom
(three translations and three rotations) until the VP
appeared to them to touch the surface of the sphere

Proceedings of the Seventh International Conference on Information Visualization (IV’03)
1093-9547/03 $17.00 © 2003 IEEE

exactly at the target position, in the mean time, align it
with the estimated surface normal at designated target
position. Each experiment consisted of 6 randomized
replications for each condition, for a total of 150 (6x5x5)
judgements. The experiment, including practice, took
place over a span of two days, with each session lasting
approximately two hours per day. Eleven university
students participated in the experiment, and none of them
knew about the design and the goals of the experiment.
Some of them wore optical correction.
Figure 2
illustrates how task completion might have appeared from
the observer’s point of view. (It is important to recall that
observers viewed the images stereoscopically, which is
not possible to reproduce here.)

It is noted that attention was paid only to radial error,
since differences between the actual and perceived
centres of the target circles on the hemisphere surface
were not of interest. A negative mean error means that
the position detected by participants is outside the sphere
surface (r-d < 0), and a positive mean error means that the
detected position is inside the real target surface along the
surface normal (r-d > 0).

3. Results and Discussion
An analysis of variance performed on the results
revealed that surface texture had significant effects on
alignment accuracy, as summarised in Figure 4.

Figure 2. Example of placement task using a 3D
pyramidal virtual pointer (VP), shown
being aligned with a 10% density target,
situated at 30o from central meridian.

2.3 Measurement
The placement errors between the target positions
estimated and the corresponding real surface positions
were computed along the direction of the normal vector at
the perceived target position. This corresponded to the
difference between the sphere radius (r) and the distance
from the perceived target position to the origin (d), as
illustrated in Figure 3.
Positive Error (r-d>0)
Surface normal

r
Real target
on surface

d
O

Estimated target
(inside surface)

Figure 3. Measurement of placement error.
(Positive error shows the perceived
target is inside the sphere along
surface normal)

Mean Alignment Error
(cm)

Alignment Error vs Texture Density
(Error Bar=95% CI, F(4,40)=41.34, P<0.001)
1.6
1.2
0.8
0.4
0
0

10

20

30

40

Texture Density (%)

Figure 4. Effect of surface texture (positive values
indicate estimated position inside
sphere surface)

3.1 Optimal Texture Density Value
It is important to note that the positive errors found
here are consistent with results from the previous studies,
where it was found that highly textured surface generated
smaller placement error than sparsely textured surfaces.
In those experiments, however, only two values of texture
density were used: high =33% and low = 11% [8][9].
The positive error shown in Figure 4 indicates that
the perceived targets at all texture density levels were
inside the sphere. This indication supports our contention
that the fusion breakdown caused by the cue conflict
between binocular disparity and occlusion was being used
as an extra cue to detect the sphere surface. In other
words, the fact that participants consistently placed the
cursor behind the target surface suggests that there was
some special cue associated with the target surface itself,
since there is no reason to predict such a bias based on
binocular disparity matching alone.
It should be also noted that there appears to be a limit
for the higher texture density advantage, somewhere

Proceedings of the Seventh International Conference on Information Visualization (IV’03)
1093-9547/03 $17.00 © 2003 IEEE

around 30%. Since the 40% texture density error appears
to be on the right hand side of a U-shaped function (see
Figure 4), this suggests that there is an optimal value for
certain textures (in this study randomly distributed square
dots).
In other words, when the texture density
approached this optimal value, it facilitated alignment,
but when the texture density exceeded this optimal value,
it started to generate more alignment errors, possibly
because there were too many surface features to be fused
(just like a field of grass with too many small element to
identify), or perhaps due to too much glare caused by the
increasing proportion of white versus black element.

3.2 Real-Virtual Object Interaction Model
The most important finding in this research is the
confirmation that the fusion breakdown phenomenon can
be used as an extra depth cue for detecting the interaction
between the virtual and real objects and thus determining

the real object position.
Based on the above
investigations, a model can be proposed that involves two
phases to describe interactions between virtual and real
objects in stereoscopic AR environments, as illustrated in
Figure 5. For the perceptual processes at the left,
observers perceive both the VP and the target surface
with either clear fusion or fusion difficulty. If the VP is
converged in front of or at the surface, simple stereo
matching cues provide an unequivocal percept of the VP
being in front of the real object surface, and there were no
fusion difficulties occur. At this stage, observers have no
decisions to make, and they must continue to adjust the
VP towards the target surface. However, whenever the
VP is at or behind the surface, stereo matching cues are
equivocal, and concurrent fusion difficulties may or may
not occur. Observers then have to decide where the VP is
relative to surface, which is modelled on the right hand
side of Figure 5.

Perception

Cognition / Decision Making
(Stereo Matching + Cue Conflict Resolution)

(Stereo Matching)

behind

(Breakdown/Conflict)

Fusion
difficulty

VP behind,
or at, real
surface?
at
at

Fused
Image?

No fusion
difficulty

(Transparency)
No

Localisation
Achieved

VP behind,
or at, real
surface?

Stereo
Matching :
VP in front of
real surface?

behind

(Backward to surface)
Adjustment

Yes

(Forward to surface)
User
External World

Display of virtual pointer (VP)

AR Display

VP Controller

superimposed upon real object surface
Figure 5.

Model of real-virtual object interactions

Proceedings of the Seventh International Conference on Information Visualization (IV’03)
1093-9547/03 $17.00 © 2003 IEEE

The cognition/decision making processes involve
deciding how to reconcile ambiguous and/or conflicting
stereo matching and occlusion cues. In other words,
observers have to decide either to continue adjusting the
VP or that surface has been reached (in which case the
localization goal has been achieved). If the VP is
perceived near the surface and fusion difficulties
encountered, observers have to decide if the VP is at the
surface (goal achieved) or still behind the surface (in
which case the VP adjustment must continue). If the VP
is not perceived in front, but no fusion difficulties are
encountered, then possible perception of transparency of
the real object surface is experienced. In that case,
observers still need to decide if the VP is at or behind the
surface.
Figure 6 is a typical example of alignment
trajectories, in which the frequent oscillations back and
forth explicitly illustrates the alignment process.
Wherever the VP is judged relative to the target surface,
the observer can adjust it to collect more information, by
performing the perception and cognition processes back
and forth until reaching the decision that satisfactory
alignment has been achieved. In other words, it is not
necessary to make a “damped response” in approaching
the surface. Observers can exploit the interactions
between the real and virtual objects first, and afterwards
make a judgement to decide on their relative locations.
This model can therefore serve as a guideline for
investigating the interesting perceptual conflicts uniquely
characteristic of stereoscopic AR environments.

3.3 Implication for 3D AR Interface Design

The present study demonstrates that the fusion
breakdown can be used as an extra cue, over and above
binocular disparity matching. The optimal level of 30%
texture density was also identified to offer the
opportunity to apply a certain type of texture (randomly
distributed square dot) as a means to explore the fusion
breakdown easily and effectively. Thus, these results
should make it feasible to better detect the real object
position and to make more accurate 3D measurements,
even for the complex visual features of the aneurysm
surfaces in the surgical fields, where the surfaces were
rounded, shading was uneven, and textured cues were
ambiguous [3]. A method for making more accurate 3D
measurements can be artificially projecting an
appropriate surface texture like random dot onto real
object surfaces to facilitate real-virtual object alignment
in stereoscopic AR environments. This innovative
technique is being tested in an experimental mine site to
explore the feasibility of using incident light to create
texture patterns on curved surfaces. The rationale behind
this idea is that, in an environment in which natural
textures are inadequate for accurate alignment – such as
aligning up a virtual robot with a rock face inside a mine
[9], one could simply add the required texture artificially
through incident light projection with more depth and
curvature information provided naturally by the distortion
on the curved rock surfaces, as illustrated in Figure 7.

4. Conclusions
This research has endeavoured to illustrated a
number of perceptual issues related to stereoscopic AR

One specific goal for this research is to develop an
engineering solution for improving 3D measurement
accuracy in stereoscopic AR environments.

Placement Error
(cm)

Placement Error vs Time
(Highly Textured Surface)
2
1
0
-1
-2
-3
-4
-5
-6
0

50

100

150

Time (sec.)

Figure 6. Example of an alignment trajectory.
(Oscillation back and forth around the
cylinder surface – 0 placement error)

Figure 7. A virtual pointer overlaid on a rock
surface with projected random dot
texture. (In addition to the advantages
of surface texture for stereo AR
alignment, it can be seen that natural
indentations on the rock surfaces are
enhanced by the projected texture)

Proceedings of the Seventh International Conference on Information Visualization (IV’03)
1093-9547/03 $17.00 © 2003 IEEE

interface design by a detailed investigation of texture
density effect on VP alignment relative to a hemisphere
surface. A psychological method of adjustment was used
to measure the placement errors between the observers’
perceived surfaces and the surface positions in the real
scene. The alignment errors were recorded and analysed.
The experimental results were consistent with the results
in previous studies, but also added some new insights.
Due to the interaction between real and virtual object
images, perceptual conflicts between object occlusion and
binocular disparity cues cause spatial ambiguity to occur.
Generally, this ambiguity can make accurate 3D
measurements difficult in stereoscopic AR environments,
one would assume that such conflicts would be
considered as a bad thing. However, it has been shown
that in the particular system reported here the fusion
breakdown caused by these conflicts can be regarded as
an effective cue for detecting interaction between real and
virtual objects, and thus for accurately localizing the
position of real objects. From a practical point of view,
this is a positive feature of such interfaces. Therefore, the
followings are the main findings and contributions:
1.

2.

The fusion breakdown caused by the conflict
between occlusion and binocular disparity can be
used as an extra cue to detect the interaction of
virtual and real objects, and thus can facilitate the
estimation of real surface locations in AR
environments. This is evident by the slightly
overestimated surface locations along surface normal
direction in this study.
A model has been proposed to describe the process
of detecting the interactions between virtual graphic
objects and real object images when they occur. It
involves two phases: the perceptual process of
perceiving fusion difficulties and the cognitive
process of weighting the fusion conflict cue off
against judgment of relative binocular disparity.

References
[1] Milgram, P., Drascic, D., and Grodski, J. “Enhancement
of 3D video displays by means of superimposed
stereographics”. Proc. of HFES 35th Annual Meeting,
1991, pp. 1457-1461.

[2] Cannon D. & Thomas G. “Virtual tools for supervisory and
collaborative control of robots”. Presence: Teleoperator
and Virtual Environments, Vol. 6, No. 1, 1997, pp. 1-28.

[3] Kim, M. Y., Drake, J. M. and Milgram, P. “Virtual tape
measure for the operating microscope: System
specifications and performance evaluation”. Computer
Aided Surgery, No. 5, 2000, pp. 148-155.

[4] Lawson S. W., Pretlove J. R.G., Wheeler A. C., and Parker
G. A. “Augmented reality as a tool to aid the telerobotic
exploration and characterization of remote environments”.
Presence: Teleoperator and Virtual Environments, Vol.
11, No. 4, 2002, pp. 352-367.

[5]

Fuchs P., Nashashibi F., and Maman D. “Assistance for
telepresence by stereovision-based augmented reality and
interactivity in 3D space”. Presence: Teleoperator and
Virtual Environments, Vol. 11, No. 5, 2002, pp. 525-535.

[6] Ellis S. R. & Menges B. M. “Localization of virtual objects
in the near visual field”. Human Factors, Vol. 40, No. 3,
1998, pp. 415-431.

[7] Hou M. “Perceptual localization of surface normal”. Proc.
of ACM Conference on Human Factors in Computer
Systems CHI'99 (Extended Abstract), 1999, pp. 57-58.

[8] Hou M. & Milgram P. “Effect of surface characteristics
on alignment of graphic and real objects in a stereoscopic
augmented reality environment”. Proc. of IEA200 /
HFES2000 Congress, San Diego, CA. Vol. 3, 2000, pp.
476-479.

[9] Hou, M. and Milgram, P. “Investigation of surface effects
3.

Visible texture density of target surfaces significantly
affected alignment performance. In general, highly
textured surfaces facilitate target placement, but only
up to a certain texture density, after which
performance deteriorates.
In other words, the
existence of an optimal level of texture density has
been demonstrated.

on alignment of real and graphic objects in stereoscopic
augmented reality environments”. Proc. of HFES 45th
Annual Meeting, Minneapolis, MN, 2001, pp. 1877-1881.

[10] Hou, M. “Effect of surface characteristics on alignment of

It can be seen that above findings can not only
provide guidelines to 3D AR interface design, but also
provide a practical engineering solution for improving 3D
measurement accuracy in AR environments by projecting
light pattern on the real object surfaces.

Proceedings of the Seventh International Conference on Information Visualization (IV’03)
1093-9547/03 $17.00 © 2003 IEEE

real and graphic objects in stereoscopic augmented reality
environments”.
Unpublished
Ph.D.
dissertation.
University of Toronto, 2003.

