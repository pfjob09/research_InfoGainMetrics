CAEVA: Cognitive Architecture to Evaluate Visualization Applications

Octavio Juarez-Espinosa (oj22@andrew.cmu.edu)
Department of Social and Decision Sciences, Carnegie Mellon University, Porter Hall 208-C
5000 Forbes Av
Pittsburgh, PA 15213 USA

Abstract
This paper describes a cognitive architecture to
evaluate visualization applications (CAEVA).
This architecture requires gathering domain
knowledge to adapt existing evaluation models to
new domains and applications. This architecture
has two main components: one for interoperability
and one for cognitive models. The interoperability
component uses client-server protocols. The
cognitive component includes three subcomponents: knowledge about visualization,
knowledge about the data domain, and knowledge
about data analysis strategies.
CAEVA was used to evaluate the visualizations
generated to compare environmental products.
The cognitive model is written in ACT-R and
simulates how human beings use visualizations to
perform data analysis tasks.
The data produced by the simulation model is
validated with empirical data obtained from
human subjects performing the same task. The
simulation model produces traces that allow
researchers to analyze the strategies followed by
the users in the task. The data produced by the
model allowed us to study the learning process of
visualization users.

1. Introduction
This study is an ongoing project that uses
cognitive models to evaluate visualizations and to
explain user strategies when they solve problems using
visualizations. Evaluation of visualizations has been
performed basically via empirical studies, which used
few users. Some of the parameters evaluated in
visualizations include performing time and quality of
the solution. However, quality of solution is a domain
dependent parameter and it is not evaluated in each

study. Empirical studies are expensive and time
consuming. The combination of empirical studies and
cognitive models will help to evaluate better the use of
visualizations and allow keeping the evaluation costs
low.
In this paper, the usage of cognitive models to
evaluate and design visualizations is proposed. One
advantage of using cognitive models to evaluate
visualizations is that they allow researchers to
understand the user actions better than empirical
studies that produce only a set of response times. Some
of the issues that can be better understood with
cognitive modeling include attention control, solution
strategies, memory failures, memory limitations, and
learning.
There is a gap in the methodology to combine
empirical studies and cognitive modeling in the
evaluation process. The combination of those
techniques in this architecture is based on the user
goals, the tasks, and the environment. CAEVA is
adapted to new domains based on domain knowledge
and it is not attached to any cognition theory.
However, in our example we based the analysis in
ACT-R, a symbolic architecture.

2. Related Research
Empirical evaluation of visualizations has been
performed in many studies. These studies analyze user
performing a task with the application evaluated [1].
This research investigated the performance time and
the quality of the task performance. Additionally, it
suggested that users make decisions based on few data
sets instead of considering the complete set of data.
Most of the previous research on visualization
evaluations involves experiments with users to study
the effect of visualization in their task [2, 3]. While
empirical evaluations performed in existing studies
have some limitations to understand the process of

Proceedings of the Seventh International Conference on Information Visualization (IV’03)
1093-9547/03 $17.00 © 2003 IEEE

using visual displays, the cognitive analysis of
visualizations may help to understand how people
process and use complex visualizations or how people
learn to use complex visualizations and why
visualizations are hard or easy to use [4].
In this work, we propose cognitive models to
evaluate applications. There were not references to
previous research studies that used cognitive models to
evaluate computer applications.

The cognitive model simulates a human
interacting with the system and the visualization
application represents the external world that provides
information to the cognitive model, as can be seen in
Figure-1. CAEVA has three components: the
interoperability model, the cognitive model to simulate
human beings performing tasks, and a command server
that processes the XML messages embedded in the
visualization application.

3. Cognitive Modeling

4.1. Interoperability Model

Cognition architectures have been evolving and
they have been used in different real-life domains,
such as flight control and firefighting. ACT-R and
SOAR are two examples of those architectures used to
model cognition in different domains [5].
A cognitive model has two components:
declarative knowledge and procedural knowledge. The
declarative component represents chunks in memory
and the procedural knowledge consists of production
rules. The declarative component simulates
information stored in the memory while procedural
rules simulate using the information stored in memory
to solve a problem. The cognition architecture
manipulates an activation coefficient that controls the
rules and memory chunks which are retrieved in a
particular simulation state.
The cognitive modelers write a cognitive model
and collect data from their simulations about response
times and sequences of productions used. With this
information, cognitive modelers compare the data
obtained in the model with the data obtained from
human beings in empirical studies. These comparisons
verify how well the simulation predicts human
behavior.
Also, the cognitive architecture simulates learning
of skills and problems with memory. Although, the
cognitive architectures use symbolic data for the
models, some existing architectures incorporate
models of perception and motor skills [6].

The model used to make easier the communication
between the cognitive models with visualization
applications is shown in Figure-1.

4. CAEVA
CAEVA is a software architecture that defines
software components of a system designed to evaluate
users interacting with information-visualization
applications. Those components are the combination of
domain-dependent and domain-independent modules.
CAEVA was designed to make easier the process of
designing and writing cognitive models to evaluate
applications that use visualizations. The idea is to
reuse domain-independent components in different
evaluations and to adapt or rewrite domain-dependent
components to save evaluation time.

Figure-1: Cognitive Evaluation Architecture

The cognitive model communicates with the
visual application using XML messages. The visual
application sends the state of the world encoded in a
XML message. The cognitive model updates the state
in the cognitive model and executes the production
system to study when it must perform actions in the
visual application. Those actions sent by the cognitive
model are called “commands.” These commands are
equivalent to the actions that a user performs using the
mouse and the keyboard while interacting with the
system. This component is domain-independent and it
can be re-used in every cognitive evaluation without
changes.

4.2. Command Server
The visualization application needs to implement
a server that processes the commands sent by the
cognitive model. This server processes actions
executed by the model simulating human beings
interacting with the graphic user interface (GUI)
interaction. For specific domains, the modeler must
define the commands for the application and the XML
messages that will be used in the interaction. Those

Proceedings of the Seventh International Conference on Information Visualization (IV’03)
1093-9547/03 $17.00 © 2003 IEEE

messages are implemented after observing users
interacting with the visualization application or
studying the user manuals for the application.

4.3. Cognitive Model
The cognitive model is the component that
simulates a human interacting with the software
system. This model has two components: one domaindependent and one domain-independent, as can be seen
in Figure-2.

5. Environmental Visualization: A Case
Study
The task used to illustrate CAEVA is the
comparison of two alternative designs of a product
based on environmental data. To compare two
alternative designs, a user needs to perform a life-cycle
assessment (LCA) evaluation for each product being
compared. LCA computes the toxic emissions of a
product from the raw materials acquisition and
production, to product disposal. This experiment was
previously reported [1].
How well the products are compared depends on
user knowledge, user experience, user cognitive
strategies, computer user interface, and the data set
quality. Also, the problem solution is affected by the
size and type of the task used.
This experiment was designed to explore the
effects of adding information visualization components
to the economic input-output life-cycle assessment
(EIO-LCA) software in order to influence problem
solution. It is likely that users with graphic tools
improve the process of results analysis. Figure-3 shows
a simple 2D display used with the LCA software.

Figure-2: Cognitive Model Components

The domain independent knowledge contains rules
about visualizations design. This component includes
heuristics followed by users to design visualizations.
For example, the criteria used to select a graphic type
to represent specific types of information may be
represented as a set of production rules that model how
human beings design new visualizations of data sets.
The domain independent knowledge also contains
rules to simulate how users analyze data sets, e.g. the
selection of the aggregation level to perform the
analysis. The strategies used to analyze data can be
transferred from one domain to another without any
change.
The domain dependent knowledge contains rules
to simulate how human beings use the domain
knowledge to perform the analysis. For example, to
find out which data subsets are more important to
answer a research question requires some rules that
depend on the domain. This component of the model
needs to be rewritten for each new application to be
evaluated.

Figure-3: Graphical Comparison of Two Products
Based on Life-Cycle Assessment Data

The selection of the most environmentallyfriendly product may be affected by the data set
selected to inform the decision. Differences may be
produced in the data sets used to inform the same
decision, because users have different criteria
regarding the data sets used. The level of detail used to
inform their decisions may be affected by how
confident a user is about the data sets and how well
he/she understands the model.
Figure-4 shows different views of the LCA data
sets. To select the best environmental friendly product
a user selects specific data sets, levels of aggregation,
and types of graphics. Different users will select

Proceedings of the Seventh International Conference on Information Visualization (IV’03)
1093-9547/03 $17.00 © 2003 IEEE

different graphics and different data sets based on their
experience in the domain.

5.1. Cognitive Model
The cognitive model consists of several
declarative and procedural components. The
production rules and the declarative knowledge are
divided in domain-independent and domain dependent
set of rules.

Figure-4: Multiple view of LCA data

Juarez (2000) asked the subjects to provide the
following information:
- which product was selected based on the
environmental effects,
- why the product model was selected, and
- which numerical data were considered to
support the decisions.
The results were analyzed using simple
descriptive
statistics.
However,
they
were
complemented with a qualitative analysis, which
provided more information about the solution process.
The population examined consisted of 10 students
using a software version with visualizations and a
software version without visualizations. The analysis
was separated into time analysis and qualitative
analysis for each problem component. The groups
using the software with visualizations spent less time
on the tasks. Yet, both groups improved their
performance when they used the software tool in the
second session. The time reduction might have been
caused by the users’ learning. However, the group of
users with lower performance time and less variation
was the group that used the software with
visualizations.
The variation of the solution quality variable is too
low for the users using the software with graphics.
Other information that was obtained from this analysis
includes the following:
- Users made their decisions based on a subset
of the data sets. They did not use the complete
set of 75 vectors. Most of the users only
needed to review 3 or 4 data sets to support
their decisions.
- Users preferred to work in the level of
summaries. Only a few of them focused their
attention on the data sets’ details.

5.1.1. Domain-Independent Declarative Knowledge
about Visualization Design. This part of the model
contains memory chunks with knowledge that includes
the definition of visualization types and their
constraints to be used. For example, to use a bar chart,
a chunk may specify that two data sets, one with
quantitative data and another with nominal data, are
required. Tree maps and other techniques, such as time
lines or multi-axis coordination, have different usage
constraints and they will be represented in the model
as a set of memory chunks. This component can be
reused without changes in different data domains.
5.1.2. Domain-Independent Procedural Knowledge.
The domain-independent rules are used to simulate
how human beings design visualization for one task.
Some of the heuristics encoded in this module include
knowledge gathered by the visualization community in
previous research [7]. The heuristics collected by
Mackinlay are based on the criteria of expressiveness
and effectiveness.
The current prototype includes effectiveness
criteria. For example, the following list of graphical
languages is sorted based on accuracy from more
accurate to less accurate to represent information:
position, length, angle, slope, area, volume, color, and
density. This rank means that position in a line is more
accurate to represent a quantitative data than
representing the same data using area or color. For
example, representing two numbers with almost the
same value are hard to compare when you represent
them using area. However, they are easy to compare
when they are represented as a position in a line. The
effectiveness of a graphic technique is determined by
the perceiver capabilities.
Based on the type of data, the expressiveness of
one technique or graphical language varies. For
example, quantitative data are better presented using
position, length, angle, slope, and area. The ordinal
data, which are data that can be sorted, are better
represented using position, density, angle, and slope.
Finally, the nominal data, which include a set of
names, are better represented using position, color,
texture, and connection [7].
To encode our procedural knowledge we used
production rules which have two components: left-side
and right-side. The left-side is a list of pre-conditions

Proceedings of the Seventh International Conference on Information Visualization (IV’03)
1093-9547/03 $17.00 © 2003 IEEE

to fire the rule. The right-side represents actions
performed by the production in the system state.
The system has rules to select the graphical
languages that are more effective to display the type of
information used. There are rules for every graphical
language known by the current user and the model can
be enriched with new techniques when they are
available. These rules can be reused without changes
among domains.
5.1.3. Domain-Independent Procedural Knowledge
about Data Analysis. This component includes
knowledge about data analysis processes. Mainly, it
includes heuristics used by users while they solve
problems. Some of the heuristics include the level of
aggregation used, the data sub-sets used, and the type
of graphics selected. For example, a user may start to
compare two products in a high aggregation level and
at the end he/she may analyze detailed data sets.
Following this rule, the first graphics are generated to
present global information and the final graphics help
to understand information details.
5.1.4. Domain-Dependent Procedural Knowledge.
Finally, there is a set of rules that encodes information
specific to the environmental domain. For example, in
the environmental domain, the cognitive modeler
writes productions about the specific data groups and
the sub-total measure vectors. In the environmental
example of our case study, a user must visualize 75
vectors grouped in 11 sub-groups.
A user must decide whether he/she wants to have
the global summary or the summaries of one of the 11
data subsets. It may be the case that, based on their
experience, different users have different preferences
regarding the number of data sets to summarize. The
model should account for those individual differences.
However, users sometimes follow heuristics based on
current environmental regulations, such as global
warming indicator and the green house gases.

6. Summary and Future Research
This paper described the progress of an ongoing
project to design CAEVA, which is an architecture to
evaluate visualizations. CAEVA is used in the process
of applying cognitive models to complement the
evaluation of software applications that include
visualizations. The existing technologies for cognitive
modeling can improve the evaluation process of
visualization applications.
In the near future, the environmental data case
study will be finished to compare the data produced by
our system and the data empirical data obtained in
previous research. Future work includes writing of
cognitive models and the collection of data from
empirical studies of visualization in different domains.
Another task will be the collection of knowledge used
to design visualizations and knowledge about
heuristics to perform data analysis in order to have
generic and reusable modules that save time in the
implementation of cognitive models to evaluate
systems. Finally, we will study methods to make easier
the process of collecting domain knowledge in the
process of data analysis.

7. References
1.

2.

3.
5.1.5. Learning, Individual Differences, and
Memory Overload. The process of learning strategies
in the domain independent and domain dependent
knowledge about data analysis and visualizations can
be simulated in the cognitive architecture. This
component is under development in CAEVA.
Individual differences regarding data preferences
and knowledge about the domain can be simulated
using cognitive architectures. Finally, the memory
failures and overload can be simulated with the
manipulation of ACT-R parameters.

4.

5.

Proceedings of the Seventh International Conference on Information Visualization (IV’03)
1093-9547/03 $17.00 © 2003 IEEE

Juarez, O.H., C. Garrett, J.H., Jr. Evaluating
visualizations based on the performed task. in
IV 2000. 2000. London, England.
Dillenseger, J.L., et al., Evaluation of the 3D
visualization of quantitative
stereoelectroencephalographic information,
in Proceedings of the 22nd Annual
International Conference of the IEEE
Engineering in Medicine and Biology Society
(Cat. No.00CH37143), J.D. Enderle, Editor.
2000, IEEE: Piscataway, NJ. p. 2751-4 vol.4.
Sousa Santos, B., J.L. Dillenseger, and C.
Ferreira, Experimental methodology for the
evaluation of the 3D visualization of
quantitative information: A case study
concerning SEEG information. Journal of
Computing and Information Technology CIT 10, 2002(2): p. 103-13.
Trafton, J.G., Shah, P., Kirschenbaum, S.,
Cheng, P. Proceedings of the Twenty-Fourth
Annual Conference of the Cognitive Science
Society. in CogSci 2002. 2002. FairFax,
Virginia.
Anderson, J.R. and C.D. Schunn, Implications
of the ACT-R learning theory: No magic
bullets Advances in instructional psychology:
Educational design and cognitive science, R.

6.

7.

Glaser, Editor. p. 1-33; Mahwah, NJ, US
Lawrence Erlbaum Associates, Publishers,
2000 xvi, 404.
Anderson, J.R., M. Matessa, and C. Lebiere,
ACT-R: A theory of higher level cognition
and its relation to visual attention. HumanComputer Interaction Special Issue: Cognitive
Architectures and Human-Computer
Interaction, 1997. 12(4): p. 439-462.
Mackinlay, J.D., Automatic design of
graphical presentations, in Computer
Science. 1987, Stanford University.

Proceedings of the Seventh International Conference on Information Visualization (IV’03)
1093-9547/03 $17.00 © 2003 IEEE

