Real-Time Network Virtual Military Simulation System
Yi-Haur Shiau1, Shin-Jye Liang2
National Center for High-Performance Computing, Taiwan
2
Department of Marine Environmental Informatics, National Taiwan Ocean University, Taiwan
{c00shh00@nchc.org.tw, sjliang@mail.notu.edu.tw}
1

Abstract
Network virtual reality is an advanced, distributed
interactive and collaborative computer graphics
technology for presenting information and exploring
data in the 3D virtual environment. In this paper, a
real-time network virtual military simulation system is
developed. The Digital Terrain Model and SPOT
images of the Geographic Information System are
integrated with the weather simulation of the particle
system to construct a 3D virtual environment. The
main features of the system include (1) ROAMing is
used to construct and visualize the 3D virtual
environment, (2) particle system is employed to
simulate the weather conditions, (3) physical, gravity
and collision detection are adopted to fulfill the
realistic interactions, and (4) network communications
is supported for distributed multi-users.
Several computer graphics accelerating schemes,
such as real-time optimally adapting meshes, view
frustum culling, level-of-detail, are used to speedup the
rendering, and dead reckoning to reduce the flow rate
of network to make the distributed real-time VR
feasible.

1. Introduction
Owing to the recent development and advancement
of computer software and hardware, the visualization
technology has become a new trend to observe and
present massive data and simulation results in the 3D
scenes [1]. Moreover with the help of network
communications, distributed visualization opens up a
new way of collaboration and interaction via network
[2, 3, 4]. The distributed and collaborative system has
become an active research subject.
Even though CPU and 3D display cards have
advanced remarkably, the demanding of processing
massive data is still high, especially the data of the
Geographic Information System (GIS). It is
challenging to perform the real-time visualization for

11th International Conference Information Visualization (IV'07)
0-7695-2900-3/07 $20.00 © 2007

processing the massive data and information. This can
be improved by accelerating the rendering process
scheme, such as real-time optimally adapting meshes
(ROAMing), level-of-detail (LOD), view frustum
culling (VFC), image-based rendering (IBR), etc [5, 6,
7, 8]. Moreover, the real-time communication and
interaction between the multi-users is also important
for the amount of network flow traffic [9]. The method
of reducing the transfer of data among users, such as
the dead reckoning and routing table, employed.
In this paper, a real-time network virtual military
simulation environment is developed. It is constructed
with the digital terrain model (DTM) and SPOT image,
the weather simulation by using particle system, and a
lot of tanks and tree. It is built up with a large number
of polygons and an amount of textures. This served as
the data and scene to test the visualization and
communication methods mentioned above, and
measure their performance for a distributed real-time
visualization.
The rest of the paper is organized as following:
Section 2 introduces the 3D visualization system
architecture and implementation techniques; Section 3
presents the network system architecture; Section 4
shows the simulation results; and Conclusions and
discussion are made in Section 5.

2. 3D visualization system architecture
The real-time network virtual military simulation
system includes two system architectures: One is the
3D visualization system architecture, the other is
network system architecture.
The workflow of the 3D visualization system
architecture includes preprocessing stage and run-time
stage. In the preprocessing stage, the binary tree of the
real-time optimally adapting terrain mesh is
constructed by terrain data preprocessing; the particle
system parameter is setup by using weather data. In the
run-time stage, there are four components: (1) Users
input and interaction in the main system, and the main

system updates viewpoint, and the ROAMing engine
dynamic adjusts the binary tree architecture. (2) The
main system and dynamic object control adjust the
parameters of the particle system engine, and model
the collision response. (3) Multi culling and
acceleration schemes, such as view frustum culling
(VFC), back face culling (BFC), occlusion culling
(OC), and level-of-detail (LOD) are adopted. (4) The
rendering data is sent to hardware rendering pipeline.
Figure 1 shows the workflow of the 3D visualization
system architecture.

terrain is rendered when it is farther away from the
camera or it has smooth gradients. The optimal
rendering speed can be reached with high quality
visualization.
ROAMing is the dynamic mesh representation
based on the triangle bintrees. Figure 2 shows 0-3 level
of a representative triangle bintree: Level 0 is the
coarsest level, and the rest levels of the triangle bintree
are defined by recursively repeating the splitting
process.

Figure 2. Illustration of the levels 0-3 of a
triangle bintree

Figure 1. Illustration of the workflow of the 3D
visualization system architecture
The 3D visualization system architecture consists of
five subsystems: ROAMing terrain system, particle
system, collision detection system, physical and
gravity system, and culling and acceleration system.
The function of each subsystem is briefly introduced as
follow.

Figure 3 shows the data structure of each triangle.
Each triangle has three neighbors are right neighbor,
left neighbor, and base neighbor. They define their
neighbor relationship. The right child and left child are
the two child triangles of the next level of the triangle.
Four nodes are apex vertex, right vertex, left vertex and
center vertex. Because the terrain data of height map
doesn’t dynamically change, the variance of each
triangle bintree can be computed beforehand. The
variance
is
computed
by
abs(centerZ((leftZ+rightZ)/2)). The variance of the level is stored
at the variance tree to reduce the run-time computing
time. Figure 4 shows the variance tree. In the run-time
stage, ROAMing dynamically chooses an adaptive
level of the triangle bintree to represent the complex
terrain that depends on the defined variance and the
camera position.

2.1. ROAMing terrain system
In order to display the complex of the real terrain, a
high-resolution height field is used. However, the large
data wastes the rendering resource. ROAMing [10] is
adopted to balance the visual quality and rendering
effect. Depending on the camera position, ROAMing
can dynamically adjust the number of polygons and
different resolution of the terrain model. Higher
resolution terrain is rendered when it is closer to the
camera or it has sharp gradients, and lower resolution

11th International Conference Information Visualization (IV'07)
0-7695-2900-3/07 $20.00 © 2007

Figure 3. Illustration of the data structure

color of clouds is determined by the scattering and
transparency of the particle. The color information of
every particle is replaced by a similar texture, and
billboard technology [15] is used to speed up the
rendering in the run-time stage.

2.3. Collision detection
Figure 4. Illustration of the variance tree
It should be noted when the level of the patching
triangles is different, it might cause the cracks as
shown in Figure 5. ROAMing uses a recursively forcesplit method to constrain the level of the adjacent
patches to the same level to avoid the cracks. Figure 6
illustrates the forced split method.

Figure 5. Illustration the cracks

The collision detection [16] scheme was employed
to avoid the collision and penetration of the observers
and objects during navigation. A simple geometry,
named a bounding volume, is used to package every
object. We only need to detect the collisions between
the bounding volumes and decide the motion of the
collided objects thereafter. It simplifies the complex of
the collision detection, and enhances the performance
while navigating. In this paper, two different kinds of
collision detection are used: One is the collision
detection between two moving objects and the other is
the collision detection between one moving object and
one static object. In the first situation, if the sum of the
radios of the two bounding spheres is larger than
distance of these two moving objects, it denotes the
collision occurs. In the second situation, the collision
occurs if the surface of the moving object enters the
region of the static object.

2.4. Physical and gravity system

Figure 6. Illustration of the force-split method

2.2. Particle system
Particle system [11] is a way of modeling fuzzy
objects, such as fire, clouds, smoke, water, etc. In this
paper, in order to visualize more realistic scene, the
weather variation is embedded into the virtual military
environment, such as clouds, rain, lightning, etc. We
adopt the cellular automation [12] that uses the state
transformation of the multiple particles to simulate the
variation of the clouds. After the clouds simulation, the
clouds model is then constructed for visualization.
However, the clouds are non-rigid objects and cannot
be constructed with polygons. Particle system is used
to visualize the clouds [13, 14]. For the conventional
particle system, more particles are used for more
details of the model, and cause more CPU time and
computing resources needed. In order to overcome the
defect, textures and billboard scheme are used. The

11th International Conference Information Visualization (IV'07)
0-7695-2900-3/07 $20.00 © 2007

After the collision is detected between the two
moving objects, the corresponding physical collision
response of the moving objects is implemented, such
as stop, directional changes, etc. The interactive
response after the collision of the moving object and
static object is also implemented. Due to the rise and
fall of the landform, the system detects the height
information of the later time instance of the object, and
compares with the current position to decide if the
motion is ascent or descent. Moreover, the gravity
system is implemented to adjust the speed of the
object.

2.5. Culling and acceleration system
In order to support high resolution, realistic scene,
and real-time rendering, several computer graphics
accelerating schemes are employed to pre-process the
data before the data is delivered to CPU for rendering.
These accelerating schemes, include VFC, back face
culling, billboard, and LOD used in the paper are
briefly introduced as following.
2.5.1. View frustum culling. Due to the complex
scene and the large amount of data, it is extremely

challenging to render the whole scene in real-time.
VFC is a scheme that only the objects in sight are
rendered and other objects out of sight are not
rendered. This significantly reduces the amount of data
for processing, and therefore the performance of
rendering is enhanced.
2.5.2. Back face culling. About half the polygons of a
non-transparent (blocked by the front faces) object
won’t be seen at a time, and these polygons are called
back face. Back face culling (BFC) is a way to detect
the back face and not to render those polygons.
Consider the polygon’s position (p), viewpoint (v), and
polygon’s normal (n), and the back face is can be
checked if (p-v)n>0. By using the BFC, we can
substantially reduce the rendering data.
2.5.3. Billboard. While rendering relatively complex
3D objects, such as tree meshes, it might take a large
amount of data and raises the loading while rendering
in real-time stage. The scheme of the IBR is applied. It
takes an image to display the 3D objects so that it
might lighten the loading of rendering. However,
single image doesn’t have 3D effect, and the billboard
scheme is address to resolve this problem. It rotates the
image while viewpoint of user changes, and let the
image always face user. In this paper, we use two cross
images to replace a single image to enhance the
realistic and 3D effect.
2.5.4. Level-of-Detail. There are many objects in the
scene, some are near the viewpoint, and others are far
away the viewpoint. It wastes the rendering resource
when these objects are represented in the same
resolution. The approach of LOD is to present the
objects in different level of details depending on the
distance between the viewpoint and observed objects
in navigation. The closer of the distance, the more
details of the object are needed to be presented, and
vice versa. This is a popular approach to simplify 3D
objects.

3. Network architecture
The single-server multiple-clients architecture is
adopted for the distributed communications. The
communication protocol between client and server is
TCP/IP. To realize the real-time interaction in the
network virtual scene, each client must keep a list of
all clients and send the update packet to others the
latest states of the system, such as position changes,
speed changes, etc. The blind broadcast is one of the
easiest ways to send the updated packet every unit time
for each client. But it may cause a serious delay on the

11th International Conference Information Visualization (IV'07)
0-7695-2900-3/07 $20.00 © 2007

limited bandwidth network for a large amount of data
to transfer. In this paper, we utilized the dead
reckoning to overcome this hurdle. It can effectively
reduce the network flow. Its performance is examined
and compared with the blind broadcast.
Dead reckoning employs the concept of predicting
the states of others by the extra information provided
in the update packets. The extra information (including
speed, moving direction, and rotate speed) of the
updated packet is used to predict the position of others
at the later time. A new updated packet of the predicted
client is sent to others only when it regards that the
further states of others can not be predicted due to their
change of moving direction, speed, etc. By doing this,
communication rate among clients is substantially
reduced. Furthermore, the states of the updated packets
may not be the same as what is predicted. When this
happens, it is necessary to converge the wrong states
predicted to the correct ones in the updated packets and
keep the states of change smooth. Figure 7 illustrates
the state prediction and updating of dead reckoning.

Figure 7. Illustration of the state detection and
updating of an object
The routing table is implemented to further reduce
the distributed communications. It is a 2D array R(A,
B) table which indicates the visibility of clients A and
B. If there is a interactive region for clients A and B,
then R(A, B) = TRUE and R(B, A) = TRUE. It means
they are visible to each other. The server keeps and
updates the record of the routing table. It is used for
checking, updating and communicating among them.
This approach substantially reduces the network flow
among visible clients, and the computation time of the
clients to predict the state of others. Figure 8 illustrates
the view frustum of objects and the corresponding
routing table.

Figure 8. Illustration of the view frustum of
objects and the associated routing table

The terrain model constitutes most of the data of the
virtual system. In this study, the terrain model is
composed of 1,048,576 polygons. This is considered to
be a relative large amount of data for rendering.
Computer graphics accelerating schemes and network
communication methods mentioned in previous section
are employed to realize the real-time rendering and
interactions. Figure 11 illustrates the performance of
using ROAMing for the terrain model. With
ROAMing, we can use the low-resolution (coarse)
terrain model to approximate the high-resolution (fine)
model, save about 95% of the memory and cpu time.

4. Implemented results
A virtual military simulation system is implemented
on a personal computer (Pentium4 2.4G, 1GB RAM,
Window 2000) with MS Visual C++. The 3D virtual
military environment is constructed by integrating the
GIS (including DTM and SPOT images) and the
weather condition by the particle system. Figure 9
shows the architecture of the virtual military
simulation system. Some artificial structures and trees
are added to make the virtual scene more real. Figure
10 depicts different weather condition of the virtual
military environment.

Figure 11. Illustration the performance of
ROAMing for terrain modeling: (a) fineresolution, (b) medium-resolution, and (c)
coarse-resolution, respectively

Figure 9. Construction of the virtual military
scene

Table 1 summarizes the performance of the
computer graphic accelerating schemes measured in
terms of the number of polygons and frames per
second (fps). It is clearly demonstrated that with the
ROAMing with/without VFC schemes, we can
substantially speed up the rendering.
Table 1: Comparison of number of polygons and
frames per second with/without using computer
graphic accelerating schemes.

(a) Cloudy weather

Without
ROAMing

(b) rainy weather

Figure 10. Weather simulation by particle
system: (a) cloudy weather and (b) rainy
weather, respectively

11th International Conference Information Visualization (IV'07)
0-7695-2900-3/07 $20.00 © 2007

Without
VFC
With
VFC

1,048,576
(~0 FPS)
786,432
(~1 FPS)

With
With
With
ROAMing ROAMing ROAMing
Level 3
Level 2
Level 1
32,084
17.266
7,324
(18 FPS)
(28 FPS)
(61 FPS)
9,606
6,144
4,672
(54 FPS)
(77 FPS)
(96 FPS)

Table 1 summarizes the performance of the
computer graphic accelerating schemes measured in
terms of the number of polygons and frames per
second (fps). It is clearly demonstrated that with the
ROAMing with/without VFC schemes, we can
substantially speed up the rendering. The dead
reckoning is also implemented to reduce the network
flow rate of distributed communications. Table 2
shows the comparison of communication rate of the
blind broadcast and dead reckoning. It is noted that
dead reckoning outperformed blind broadcast
significantly. The transfer packet rate of dead
reckoning is almost two orders less than that of blind
broadcast. This makes the real-time distributed
interactive virtual reality for multi-users via network
feasible.
Table 2: Comparison of communication rate of the
blind broadcast and dead reckoning.
Packet numbers Packet scales per
per minute
minute
Blind broadcast
1,464
4,392 floats
Dead reckoning
16
96 floats

5. Conclusions
A real-time network virtual military simulation
system we develop is a distributed, multi-users
interactive, realistic military visualization scene. The
virtual military environment is constructed by the
DTM and SPOT images. Particle system is employed
to simulate the weather conditions. Users can remotely
login, immerse, navigate and interact with other users
in the 3D virtual military environment. To realize the
real-time rendering and communications, various
computer graphics accelerating schemes (ROAMing,
VFC, LOD, and billboard) and distributed
communication methods (blind broadcast and dead
reckoning) are implemented. Performance of the
integration of these rendering and communication
methods is studied and found satisfactory.
Based on the real-time network virtual military
simulation system, we plan to integrate distributed
computing to visualize more realistic scene for the
future study. It can be applied to many areas, such as
distance learning, video conferencing, tele-medicine,
and online game, and etc.

6. References
[1] J.R. Brown, R. Earnshaw, M. Jern, and J. Vince,
“Visualization: Using Computer Graphics to Explore Data
and Present Information”, John Wiley & Sons, 1995.

11th International Conference Information Visualization (IV'07)
0-7695-2900-3/07 $20.00 © 2007

[2] Y.H. Shiau, T.C. Ho, J.B. Yu, B.Y. Huang, and S.J. Liang,
“Networked Virtual Ocean World”, In Proc. of the 5th
International Conference on Hydroinformatics, 2002, pp.
1513-1520.
[3] S.J. Liang, J.H. Lee, S.H. Chen, and J.H. Shiau.
Networked Collaborative Environment for HydroEngineering. The International Journal of Computational
Engineering Science, 2, 2001, pp. 557-567.
[4] B.F. Naylor, “The Interactive Playing with Large
Synthetic Environments. Interactive 3D Graphics”, 1995, pp.
107-108.
[5] H. Hoppe, “Smooth view-dependent level-of-detail
control and its application to terrain rendering”, In Proc.
IEEE Visualization ’98, 1998, pp. 35-42.
[6] H. Hoppe, “View-dependent refinement of progressive
meshes”, In Proc. SIGGRAPH ’97, 1997, pp. 189-198.
[7] T. Moller, and E. Haines, “Real-Time Rendering”, A. K.
Peters Ltd. 1999.
[8] A. Ufl, and T. Moller, “Optimized View Frustum Culling
Algorithms”, Technical Report 99-3, Department of
Computer Engineering, Chalmers University of Technology.
1999.
[9] S. Singhal, and M. Zyda, “Networked Virtual
Environments. Design and Implementation”, AddisonWesley. 1999.
[10] M. Duchanineau, M. Wolinsky, D. Sigeti, M. Miller, C.
Aldrich, and M. Mineev-Weinstein, “ROAMing Terrain:
Real-time Opeimally Adapting Meshes”, In Proc. IEEE
Visualization ’97, 1997, pp. 81-88.
[11] W.T. Reeves, “Particle Systems – A Technique for
Modeling a Class of Fuzzy Objects”, Computer Graphics,
1983, pp. 359-376.
[12] S. Wolfram, “Theory and Application of Cellular
Automata”, Reading, MA: Addison-Wesley. 1986.
[13] Y. Dobashi, “A simple, efficient method for realistic
animation of clouds”, In Proc. SIGGRAPH ’00, 2000, pp.
19-28.
[14] Y. Geoffrey, “Gardner Visual Simulation of Clouds”, In
Proc. SIGGRAPH ’85, 1985, pp. 297-304.
[15] D. Xavier, D. Fredo, S. Francois, and D. Julie,
“Billboard clouds for extreme model simplification”, ACM
TOG 22, 3, July 2003, pp. 689-696.
[16] S. Gottschalk, “Collision Detection For Interactive
Graphics Application”, Ph. D Thesis, Department of
Computer Science, University of North Carolina, Chapel Hill.
2000.

