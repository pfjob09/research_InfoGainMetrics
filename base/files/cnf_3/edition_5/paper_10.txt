Focus Group Methodology for Evaluating Information
Visualization Techniques and Tools
Riccardo Mazza, Alessandra Berrè
{mazzar@lu.unisi.ch, alessandra.berre@lu.unisi.ch}
Abstract
This paper proposes a structured methodology that
uses focus group interviews to evaluate Information
Visualization techniques and tools. Focus groups are
particularly suitable for the collection of qualitative data
from users, and allow researchers to uncover unexpected
problems that cannot be identified through analytical
evaluations or controlled experiments. The approach
relies on open-ended questions to explore user attitudes,
feelings, and beliefs, but also indicates a number of
questions designed to explore specific cognitive tasks
related to Information Visualization systems. We argue
that focusing the discussion on cognitive tasks allows for
the generation of user comments that are more effective
than informal and unstructured interviews.
Keywords: empirical evaluations, focus group.

1. Introduction
Over the last decade, researchers have proposed
numerous techniques and tools in the area of Information
Visualization (InfoVis). A number of solutions (such as
Spotfire and Inxight) have moved out of the research
laboratories to become commercial products. However,
the number of prototypes that had a follow-up into a real
application, when compared with other disciplines, is
extremely low. The reason for this difficulty in
transferring an InfoVis solution to a commercial product
could be related to the difficulty in conducting
evaluations and judging the utility of visualization
systems.
The evaluation of an InfoVis technique or tool is a
challenging task. This is because it is often difficult to
construct experiments or observations that give definitive
quantitative answers regarding a particular visualization.
Each newly proposed technique and tool should be
evaluated with its intended users in mind. In assessing a
system, we must determine what aspects of a
visualization system provide a value, as well as how and
why [12]. In fact, less than 20% of the authors of InfoVis
systems report user evaluations [4], reflecting the level of
difficulty for researchers in terms of conducting
evaluations for this type of application.
The lack of a systematic approach to the evaluation
of an InfoVis application was reported during the panel

11th International Conference Information Visualization (IV'07)
0-7695-2900-3/07 $20.00 © 2007

session of the IV04 Conference and also by a number of
prominent researchers [2][11]. Recently, a workshop was
dedicated to this thematic (BELIV’06, held in Venice on
23 May 2006 [1]), showing that, finally, researchers in
the InfoVis domain acknowledged the need for standard,
accepted evaluation techniques appropriate for this sort
of application.
In this paper, we briefly present the most common
evaluation methods undertaken with an InfoVis
application and propose a systematic approach for
evaluating the InfoVis tools’ utility through the use of
focus groups with some representative users.

2. Evaluation Methods
Current evaluation practices regarding InfoVis
techniques and tools are based on methodologies
established in Human Computer Interaction (HCI). They
fall into two categories: analytic evaluations and
empirical evaluations.
Analytic
evaluation
methods
come
from
psychological models of human information processing
and are based on studies of human cognition and
behaviour. They are performed with expert-based
methods such as heuristics evaluations (where an expert
evaluates an interface and judges its compliance with
recognized usability principles called “heuristics”), or
cognitive walkthroughs (where an expert walks through a
specific task using a prototype system, thinking carefully
about potential problems that could occur at each step)
[13]. They are also used to evaluate usability and
accessibility issues. Analytic evaluations usually occur
during the system's design and are oriented to identify
problems and guide modifications during the
development of a system.
Empirical evaluation methods (also known as user
studies) involve real users in the study and allow
designers to obtain qualitative and quantitative data.
Usually they are performed with systems already
implemented (in the form of prototypes or
demonstrators), as they are suitable for making formal
claims. Empirical evaluations can be further
distinguished between quantitative studies and
qualitative studies.
Quantitative studies consist of an analysis of
determinate hypotheses
tested
through
direct
measurements [3]. Examples of such hypotheses can be
the user's performance in relation to a specific task, or

the number of trials required in order to accomplish a
specific task. This requires the definition of one or more
variables related to the hypotheses examined and a
metric associated with each of them. The evaluation is
carried out usually by means of controlled experiments
(also known as experimental studies) [7]. They consist of
asking the user testers to run a task, performing some
measurements using observation methods, and
completing the study with questionnaires or interviews.
Qualitative studies can also be quite useful for the
empirical evaluation of user-centred systems. Qualitative
research involves the analysis of qualitative data, which
may be obtained through questionnaires, interviews, and
observations of users using the system, in order to
understand and explain social phenomena. They are
complementary to quantitative methods used in
experimental studies for their ability to analyse
phenomena from the point of view of the participants,
which it is largely lost when textual or analytical data are
quantified [8]. Interviews are a form of qualitative
research that can be conducted with users, asking
specific questions to elicit information about users’
impressions and general comments. Focus groups
[9][6][10] are another form of qualitative research that
involve group interviews of individuals selected and
assembled by researchers; they discuss and comment on,
based on personal experience, the topic that is the subject
of the research [5]. In InfoVis, both focus groups and
interviews can be appropriate for detecting the users’
opinions about the usefulness of the proposed graphical
representations. These are less formal than in a
controlled experimental study, but have the advantage of
getting the user's viewpoint directly and "may reveal
issues which have not been considered by the designer"
[5](p. 431).

3. Focus Groups
A focus group is a powerful social interviewing
technique that allows researchers to elicit several
viewpoints from users at the same time. Users’
comments can be obtained very quickly, and the social
discussion allows participants to use, reflect on, and
comment on the ideas of others. A focus group is
conducted by bringing together representative users to
discuss their issues and concerns about the features of the
system being evaluated. The discussion is led by a
moderator whose role is to facilitate the interaction
between group participants and to keep them focused on
the topic of investigation.

3.1 Why use focus groups?
This investigation technique is useful because
“attitudes, feelings, and beliefs ... are more likely to be
revealed via the social gathering and the interaction
which being in a focus group entails” [5]. Compared to
other investigation methods, such as observation,
interviews, or surveys, focus groups are particularly
suitable for the challenges specific to InfoVis, such as

11th International Conference Information Visualization (IV'07)
0-7695-2900-3/07 $20.00 © 2007

“formulat[ing] and answer[ing] questions [users] didn’t
anticipate having before looking at the visualization”
[11] (p.111). With focus groups, evaluators have the
opportunity to collect qualitative information that can be
used to identify what worked and what did not, and more
importantly, why.

3.2 Advantages, limitations, and issues of focus
groups
Focus groups were first used in the world of
marketing to evaluate potential customer response to new
products. Now they are being adopted in other domains
to identify user needs and feelings that might be missed
through other methods of assessment. The main
advantages of focus group are as follows:
• Focus groups provide qualitative data more
quickly, and they are more cost-effective than
other methods;
• Researchers may interact directly with
participants and obtain rich data in the
participants’ own words. This also gives them
the opportunity to clarify the responses, followup questions, and receive contingent answers to
questions; and
• Focus groups allow respondents to react to other
group members, and to generate new ideas that
might have not been uncovered in individual
interviews.
Although focus groups offer interesting advantages,
they have some limitations as well:
• Responses from group members are not
independent of one other. Also, the small
number of participants may limit the
generalisation of the research;
• A dominant member of the group may bias the
result, and more reserved members may be
hesitant to talk;
• The open-ended nature of the responses make
the analysis of the result difficult; and
• A skilled and experienced moderator is needed
for an effective research study.

4. Designing a focus group for evaluating
InfoVis tools
In a focus group, a number of open-ended questions
are asked in such a way to trigger discussion among the
participants.
To help the researcher in adopting this technique and
obtaining useful comments and feedback from users, we
propose a structured process that will be described in the
following sections.

4.1 Preparing for the interview
Like other evaluation techniques, an effective focus
group requires thorough preparation. In particular, it
includes the following steps:

•
•
•
•

Establish the research objectives.
Identify and recruit participants.
Design the questions to be used in the study.
Plan the sessions.

Research Objectives
The first step of the process is to define the research
objectives. As the focus group is powerful in obtaining
qualitative information on the attitudes, feelings, and
beliefs of the users, some possible research objectives
could include the evaluation of the functionality and the
usefulness of an InfoVis application. A good evaluation
elicits both open-ended, unstructured user comments and
user opinions on questions distilled by the moderator.
Also, InfoVis applications have some specific tasks that
might be worth exploring. For this reason, we suggest
structuring a focus group into two parts. The first part
will be dedicated to exploring more open-ended, generic
questions on the usefulness of the system, and the other
part will be more oriented towards exploring the
cognitive tasks of InfoVis applications. Details on the
two parts are specified in the following sections.
Participants
Each interview should involve a number of
representative users of the system. In the literature, there
is no universal indication about the recommended
number of people per group. Even though some authors
give precise suggestions about group size (Krueger [9]
recommends 7 to 10 participants, and Morgan [10]
suggests a range of 4 to 12 participants), we have to
acknowledge that a small number of participants per
group might lead to a partial analysis, so we suggest
having at least 6 participants per group. Each session
should last between 1 and 2 hours, and should cover a
range of 6 to 10 different key topics.
As a group with highly different characteristics
might lower the quality of the data, we suggest
conducting multiple interview sessions to get a crosssection of views from participants with different
backgrounds and skills.
For instance, one session with the focus group may
involve a discussion with the experts of the field in
which our visualization will be used. It is important to
involve experts who have extensive experience with the
use of InfoVis. The second session may invite people
with strong knowledge of the field of interest, but who
are familiar with the use of graphical interfaces. It is
useful to have a complete overview of the problems with
the graphical representations and of any particular need
the users may have.
Questions
To maximize the effectiveness of the evaluation,
researchers need to focus the questions on the research
objectives.
It is advisable to divide the interview into two parts.
In the first part, the moderator will ask some questions
regarding the participants’ general impressions. He/She
will ask a question about the benefits they may have

11th International Conference Information Visualization (IV'07)
0-7695-2900-3/07 $20.00 © 2007

when using the representations, and about the usability
problems they might encounter when using them. The
second part of the discussion will focus the discussion on
a series of questions that concern specific cognitive tasks
that are involved in InfoVis tools.

4.1 Part one: Introducing the focus group
The first few moments in a focus group discussion
are critical. In a short time, the moderator has to create a
thoughtful, permissive atmosphere. After an introductory
explanation about the aim of the interview and about the
purpose of the study and its role, it is very important to
formulate some open questions to encourage debate. To
this aim, the moderator will show the visualizations on a
large screen and the participants will be asked to discuss
that representation.
At this stage, the moderator may ask some questions
about the possible use of the visualization (useful to
better understand the needs of the users), or questions
about the possible usability problems users may
encounter when using that system.
The questions could include the following:
•
•

•
•

What kinds of activities would you use this
representation for?
Do you find this representation useful? If so,
why? Would you be interested in having this
information displayed for some of your
activities?
What kind of information can you gather from
these images?
Do you think it should be presented differently?
If so, how?

To help the researcher with the analysis of the
discussions, it is advisable to record the sessions on
videotape. This will provide a complete record of the
session, and it will also capture all the verbal and
nonverbal behaviours.

4.2 Part two
The second part the research aims to explore the
cognitive tasks the user performs with InfoVis
applications. Such tasks are well known, but only a few
authors explicitly explore them in the evaluation of
InfoVis applications. Weherend and Lewis [14] defined a
number of domain-independent operations that a user
might need to execute to analyse data. These operations
will be used to keep the interview focused on specific
cognitive aspects of InfoVis application. These are:
•
•
•
•
•
•
•

Locate
Identify
Distinguish
Categorize
Cluster
Distribution
Rank

•
•
•

Compare
Associate
Correlate

Each of these tasks will be presented with a description
and sample questions that the moderator can ask the
subjects during the discussion.
1. Locate
Description: the user is able to find something that
he/she knows already and indicates it by pointing at it or
describing it.
Examples:
− Can you identify a particular object that you
knew before looking at this representation?
− What do you suggest to improve the
identification of items in this representation?
2. Identify
Description: similar to locate, but the user is able
to locate an item without previous knowledge of it.
Examples:
− Can you identify a particular object in this
visualization that you didn’t know before?
− Which graphical propriety helped you in
identifying this object? Do you think this should
be represented differently?
3. Distinguish
Description: the user is able to distinguish among
the different items in the datasets.
Examples:
− Can you distinguish among the different objects
in the dataset?
− What visual items are not clear in this
representation?
− Is there any object that is not captured in this
representation?
4. Categorize
Description: the user is able to identify divisions of
item categories using visual objects.
Examples:
− Can you describe the object categories?
− What are the problems that you encountered in
the categorization of the data?
− Do you think that this representation helped you
to classify the data?
− What do you suggest to improve the
categorization of data in this representation?

11th International Conference Information Visualization (IV'07)
0-7695-2900-3/07 $20.00 © 2007

5. Cluster
Description: the user is able to find a cluster of
items (if any). They can be identified by items that are
linked or grouped together.
Examples:
− Are you able to identify any groups/clusters of
data in this representation?
− What sort of problem do you think you will
encounter in finding clusters with this graphical
representation?
− What do you suggest to improve the
understanding of clusters in this representation?
6. Distribution
Description: the user is able to characterize the
distribution of an attribute’s values over the set of data
cases.
Examples:
− Do you think that this representation gives you
a clear picture of the distribution of the objects
and their values over the whole set?
− What are some of the problems that you might
encounter when characterizing the distribution
of the objects in this representation?
7. Rank
Description: the user is able to indicate the order of
the items displayed according to some metric.
Examples:
− Can you see an ordering of the objects
represented?
− Do you understand the metric according to
which the objects are ranked?
− Would you like to have other instruments to
rank the objects?
− Would you want to order the objects with a
different criterion?
8. Compare
Description: the user is able to compare similar
entities or different sets of items.
Examples:
− Do you feel that this representation gives you
the opportunity to make comparisons between
similar objects?
− Do you feel that this representation gives you
the opportunity to make comparisons between
different sets of objects?

−
−
−

Do you feel that this representation allows you
to have a clear picture of the relations between
objects?
Do you feel that this representation underlines
the most important relationships?
Do you have some suggestions to improve the
comparison of objects in this graphical
representation?

9. Associate
Description: the user is able to form relationships
between the items displayed.
Examples:
− Can you identify the relations between the
objects represented?
− Do you feel that this representation gives you
the opportunity to better establish relationships
between objects?
− What do you suggest to improve the
understanding of relationships in this
representation?
10. Correlate
Description: given two attributes of the dataset, the
user is able to determine whether there is a relationship
between the values of those attributes.
Examples:
− Is there any correlation between the values of
these objects?
− Is there any relationship that can be gathered
but is not captured very well in this
representation?
− Do you feel that this representation gives you
the opportunity to identify new relationships?

improvements that would not have been revealed with
other analytic and empirical evaluation techniques.

References
[1]

[2]
[3]
[4]

[5]
[6]
[7]
[8]

[9]
[10]
[11]

Conclusions
In this paper, we introduced a systematic approach
to evaluating InfoVis applications using the qualitative
data collected from focus groups. This interview
technique is used successfully in marketing and social
sciences, and can be adopted to evaluate some aspects of
InfoVis applications.
The evaluation of an InfoVis technique or tool may
address different criteria, namely: functionality,
effectiveness, efficiency, usability, and utility. The most
commonly used techniques (e.g., controlled experiments,
heuristics, and cognitive walkthroughs) aim to evaluate
the effectiveness, efficiency, and usability of the
proposed representations. However, the users will have a
real advantage over the graphical representations only if
the information provided is useful to them. The focus
group, and, to some extent, the individual user interviews
may be appropriate to investigate this aspect. Focus
groups may uncover potential problems and suggest

11th International Conference Information Visualization (IV'07)
0-7695-2900-3/07 $20.00 © 2007

[12]

[13]
[14]

Proceedings of the 2006 AVI workshop on BEyond time
and errors: novel evaluation methods for information
visualization 2006, Venice, Italy May 23 - 23, 2006
http://portal.acm.org/toc.cfm?id=1168149.
Chen C. Top 10 Unsolved Information Visualization
Problems. IEEE Computer Graphics and Applications.
25 (4). pp.12-16. 2005.
Dix, A., Finlay, J., Abowd, G., and Beale, R. HumanComputer Interaction. Prentice Hall, second edition.
1998.
Ellis Geoffrey, Dix Alan. An explorative analysis of user
evaluation studies in information visualisation.
Proceedings of the 2006 AVI workshop on BEyond time
and errors: novel evaluation methods for information
visualization 2006, Venice, Italy May 23 - 23, 2006.
Gibbs, A. Focus groups. Social Research Update,
University
of
Surrey,
UK.
Num.
19.
http://www.soc.surrey.ac.uk/sru/SRU19.html. 1997.
Greenbaum, T. L. The Handbook for Focus Group
Research. SAGE publications, CA, USA. 1998
Johnson, P. Human-computer interaction: psychology,
task analysis and software engineering. McGraw-Hill,
London. 1992.
Kaplan, B. and Maxwell, J. A. Qualitative research
methods for evaluating computer information systems. In
Anderson, J. G., Aydin, C., and Jay, S. J., editors,
Valuating Health Care Information Systems: Methods
and Applications, pages 45–68. Sage, Thousand Oaks,
CA, 1994.
Krueger, R. A. Focus Groups: A Practical Guide for
Applied Research. Third Edition. Sage Publishing,
Newbury Park, CA. 2000.
Morgan, D. L. Focus group as qualitative research. Sage,
London. 1988.
Plaisant, C. The challenge of information visualization
evaluation. Proceedings of the working conference on
Advanced visual interfaces (AVI04). pp. 109 – 116.
2004.
Stasko John. Evaluating Information Visualizations:
Issues and Opportunities (position statement).
Proceedings of the 2006 AVI workshop on BEyond time
and errors: novel evaluation methods for information
visualization 2006, Venice, Italy May 23 - 23, 2006.
Tory M. and Möller T. Human Factors in Visualization
Research. IEEE Transaction of Visualization and
Computer Graphics. Vol. 10 N. 1. 2004
Wehrend, S. C., and Lewis, C. A problem-oriented
classification of visualization techniques. In Proceedings
of the First IEEE Conference on Visualization, ed. A. E.
Kaufman, et al., 139-143. San Francisco, CA, October 23
- 26 1990. Los Alamitos, CA: IEEE Computer Soc.
Press. 1990.

