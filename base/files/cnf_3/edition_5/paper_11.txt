A Comparative Study of Four Hierarchy Browsers using the Hierarchical
Visualisation Testing Environment (HVTE)
Keith Andrews and Janka Kasanicka
IICM, Graz University of Technology, Austria
kandrews@iicm.edu

Abstract
Four hierarchy browsers were compared in a counterbalanced repeated measures study with 32 test users. The
four browsers tested were in-house implementations of 1) a
windows explorer style tree view, 2) an information pyramids browser, 3) a treemap browser, and 4 ) a hyperbolic browser. Each user performed eight tasks with each
browser. Task completion time, subjective ratings, and overall preference data were collected. Almost no significant
differences in performance were found, but users significantly preferred the tree view browser.
The four browsers are implemented as part of the Hierarchical Visualisation System (HVS), a Java framework
for visualising hierarchies. The Hierarchical Visualisation
Testing Environment (HVTE) is a semi-automated testing
environment built on top of HVS, which presents a sequence
of tasks from a test case database to the user, together with
an associated browser and test hierarchy, and automates
the collection of timing data.
Keywords: information visualisation, trees, hierarchy
browsers, Java, semi-automated test environment, comparative study.

1. Introduction

Information visualisation seeks to visualise abstract information structures and spaces to make them more easily accessible and manageable. Information is often organised into hierarchies of one kind or another and various
techniques have been developed to visualise hierarchically
structured information. However, there has been relatively
little formal evaluation of hierarchical information visualisation techniques.

11th International Conference Information Visualization (IV'07)
0-7695-2900-3/07 $20.00 © 2007

Figure 1: The Hierarchical Visualisation Testing Environment (HVTE). The user has been randomly assigned test case 2 and is working with the hyperbolic browser on task 25, to find the deepest subdirectory in directory ndl.

2. The Hierarchical Visualisation Testing Environment (HVTE)
The Hierarchical Visualisation Testing Environment
(HVTE) is a testing environment for running comparative
studies of hierarchy browsers. HVTE utilises the browser
infrastructure provided by the Hierarchical Visualisation
System (HVS), which is described in the companion paper
[2]. Figure 1 shows part of a typical test session in HVTE.
The user is usually assigned a test case at random, for
example by drawing a number from a hat. HVTE then
presents the user with a sequence of tasks from the test
case database, each task with an associated test hierarchy
and one (or multiple) browsers. HVTE uses the HSQLDB
database to retrieve test cases and configurations and automates the collection of timing data from the user’s session.
Figure 2 shows the initial screen of HVTE. The user
begins by clicking on their randomly assigned test case.

Figure 2: The initial screen of the Hierarchical Visualisation Testing Environment (HVTE). The user
clicks on their randomly assigned test case and the
corresponding sequence of task, browser, and hierarchy is started up automatically.

HVTE then systematically starts one or more HVS browsers
in sequence, with a particular hierarchy and a series of tasks,
depending on the assigned test case for that user.
For each browser a series of tasks is usually performed.
The first task of such a series is shown in Figure 3. The
task is displayed in the top middle window. The hierarchy
browser to be used for the next series of tasks is illustrated
in the middle of the screen. The user first acknowledges the
browser to be used by clicking the OK button, then reads the
task and presses the Continue (Weiter) button to proceed.
The task is usually presented in the native language of
the test user, in this case German. It translates as “Find
the deepest subdirectory inside the directory jazz. Write
the name of this directory into the answer field to the right
and then press Continue.” HVTE presents the appropriate
browser with the appropriate test hierarchy. The user now
uses the browser to find the answer to the question and enters their answer into the answer field as the top right. In this
case, the correct answer is the directory learn/papers/
chi-97-kidpad/images. Figure 4 shows the user having entered their answer just before pressing the Continue
button. To simplify the collection of accuracy and timing
data, HVTE automatically logs user answers and task completion times.

3. Hierarchy Browser Comparative Study
The four hierarchy browsers with the most mature and
stable implementations in HVS were chosen for comparison
in the first HVTE comparative study:
1. TV: tree view browser (Figure 4).

11th International Conference Information Visualization (IV'07)
0-7695-2900-3/07 $20.00 © 2007

Figure 3: The first task for this user is displayed in
the top middle window. The browser to be used for
the next series of tasks is illustrated in the middle
of the screen, in this case the Tree View Browser.
The task here is to find the deepest subdirectory
inside the directory jazz.

2. Pyr: information pyramids (Figure 5).
3. TM: treemap browser (Figure 6).
4. Hyp: hyperbolic browser (Figure 7).
To delimit the scope of the study, it was decided to concentrate on tasks related to the structure and topology of the
hierarchy. Tasks related to individual attributes of the nodes
were not tested. We hypothesised that users’ previous experience with tree view browsers would give that browser an
advantage in most of the tasks. A counterbalanced, repeated
measures study with 32 test users was designed to test this.
The test hierarchy used was the reduced version of
the logs_A hierarchy from the InfoVis 2003 contest [5].
The original logs_A hierarchy contains about 70,000 leaf
nodes. The reduced hierarchy is the hcil subtree (everything under /projects/hcil) containing 3,239 leaf
nodes. The hierarchy represents part of the file system of
the University of Maryland Computer Science Department
web site.
Each user performed eight tasks with each browser. The
eight tasks were divided into two overview tasks, two search
tasks, two count tasks, and two compare tasks. Four sets of
equivalent tasks were designed (8 tasks in each set). The
tasks were formulated in the native language of the test
users (German). Table 1 shows the tasks in task set A in
English translation. Task sets B, C, and D each contained 8
equivalent and analogous tasks, chosen to be approximately
equally difficult.
To counterbalance the presentation order of browsers and
tasks, two interleaved 4×4 latin squares were used, pro-

A1

Overview

Deepest Subdirectory

A2

Overview

Most Subdirectories

A3

Search

Find Directory

A4

Search

Find File

A5

Count

Count Subdirectories

A6

Count

Count Files

A7

Compare

Compare Subdirectories

A8

Compare

Compare Files

Find the deepest subdirectory inside the directory “pad++” (/hcil/pad++). Write the name of this directory into the answer field to the right and then press “Continue. . . ”.
Find the directory inside “ndl” (/hcil/ndl) with the most direct subdirectories. Write the name of this
directory into the answer field to the right and then press “Continue. . . ”.
Find the directory “yidemo” (/hcil/lifelines/yidemo). When you have found the directory, write “OK”
or “found” into the answer field to the right and then press “Continue. . . ”.
Find the file /hcil/treemaps/treemap2000/images/banner-logo-large.gif. When you have found the file,
write “OK” or “found” into the answer field to the right and then press “Continue. . . ”.
Count the number of subdirectories directly inside the directory “/hcil/pubs”. Write the answer into the
answer field to the right and then press “Continue. . . ”.
Count the number of files directly inside the directory “/hcil/qp”. Write the answer into the answer field
to the right and then press “Continue. . . ”.
Which directory has more direct subdirectories: “/hcil/about” or “/hcil/eosdis” ? Write the answer into
the answer field to the right and then press “Continue. . . ”.
Which directory has more files directly inside: “/hcil/spotfire” or “/hcil/spacetree” ? Write the answer
into the answer field to the right and then press “Continue. . . ”.

Table 1: The eight tasks of task set A. Task sets B, C, and D contain equivalent tasks designed to be equally
difficult.

Figure 4: The user has found the deepest subdirectory inside jazz, called papers, and has entered
papers into the answer field.

ducing the 16 test cases shown in Table 2. TV, Pyr, TM,
and Hyp represent the tree view, information pyramids,
treemap, and hyperbolic browsers, respectively. A, B, C,
and D represent the four sets of equivalent tasks. Two users
were randomly assigned to each test case.
The 32 test users ranged in age from 19 to 68 (median 29)
and were mostly students in Graz. All had many years of
experience using a computer (7 to 20 years, median 12), 29
mainly used Microsoft Windows and 3 mainly used Linux.
Each user was given about 5 minutes of training on each of
the four browsers, before commencing with the actual tasks.
Timings were taken automatically by HVTE, but the tests
were also recorded on DVD in case any post-test analysis
was needed. Task success was recorded in terms of whether
or not the correct answer was given.
For the subjective ratings, each test user was asked to rate
each browser using a 7-point Likert scale for each of nine

11th International Conference Information Visualization (IV'07)
0-7695-2900-3/07 $20.00 © 2007

Figure 5: The HVTE information pyramids browser
at the start of the first task for test case 2.

factors, as shown in Table 3. Finally, each user was asked to
state an overall preference for one of the four browsers for
each of the nine factors. Figure 8 shows the room environment used for the study.

4. Results
The average task completion times and standard deviations for each browser and task are shown in Table 4. The
average times are quite similar for most of the tasks. The
K-S test is a test of normality, significance indicates nonnormally distributed data, non-significance (bold values) indicates normally distributed data. Task T7 was the only
task where all timings were normally distributed and paired
samples t tests could be used. For all other tasks, the timings were not normally distributed and pairwise Wilcoxon
signed ranks tests were used.

Test Case
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16

Figure 6: The HVTE treemap browser at the start of
the first task for test case 2.

Sequence
TV-A
TV-B
TV-D
TV-C
Pyr-A
Pyr-B
Pyr-D
Pyr-C
Hyp-A
Hyp-B
Hyp-D
Hyp-C
TM-A
TM-B
TM-D
TM-C

Pyr-B
Pyr-D
Pyr-C
Pyr-A
Hyp-B
Hyp-D
Hyp-C
Hyp-A
TM-B
TM-D
TM-C
TM-A
TV-B
TV-D
TV-C
TV-A

TM-C
TM-A
TM-B
TM-D
TV-C
TV-A
TV-B
TV-D
Pyr-C
Pyr-A
Pyr-B
Pyr-D
Hyp-C
Hyp-A
Hyp-B
Hyp-D

Hyp-D
Hyp-C
Hyp-A
Hyp-B
TM-D
TM-C
TM-A
TM-B
TV-D
TV-C
TV-A
TV-B
Pyr-D
Pyr-C
Pyr-A
Pyr-B

Table 2: The 16 test cases in a 4×4 counterbalanced design. TV, Pyr, TM, and Hyp represent the
tree view, information pyramids, treemap, and hyperbolic browsers, respectively. A, B, C, and D represent the four sets of equivalent tasks. Two users
were randomly assigned to each test case.
Q1
Q2
Q3
Q4
Q5
Q6
Q7
Q8
Q9

Bad overview
Bad operability
Not intuitive
Not usable
Not understandable
Not logical
Not useful
Bad orientation
Bad navigation

3210123
3210123
3210123
3210123
3210123
3210123
3210123
3210123
3210123

Good overview
Good operability
Very intuitive
Very usable
Very understandable
Very logical
Very useful
Good orientation
Good navigation

Table 3: User ratings were recorded on a 7-point
Likert scale for each of 9 factors. The marks were
converted into scores of 0 (worst) to 6 (best) for
analysis.
Figure 7: The HVTE hyperbolic browser at the start
of the first task for test case 2.

As can be seen in Table 5, the task completion data reveal no statistically significant differences between the four
browsers, except in one case: the tree map browser was significantly faster than the hyperbolic browser for task T6 involving the counting of files in a subdirectory.
The subjective rating data is summarised in Table 6. In
the subjective ratings, test users consistently rated the tree
view browser significantly higher than the other browsers in
a variety of factors. The treemap browser was consistently
rated significantly lower than the other browsers in a variety
of factors. The significant differences in ratings are shown
in Table 7.
In terms of preference, the number of votes for each
browser is shown in Table 8. For each of the factors, a
one-way chi-square test reveals that the voting patterns are
significantly different to chance (for Q6, Q7, and Q8, the
chi-square analysis was calcualted by hand, since SPSS and

11th International Conference Information Visualization (IV'07)
0-7695-2900-3/07 $20.00 © 2007

Excel break down when cells contain 0 votes). In broad
terms, the traditional tree view browser is most preferred
and the treemap browser is least preferred.

5. Related Work
The authors are not aware of any previous work in building a semi-automated testing environment for information
visualisations. There have been some previous comparative
studies of hierarchy browsers.
[7] compared six hierarchy browsers in their original
implementations, as obtained from the developers. The
browsers were Treemap 3.2, Sequoia View 1.3, BeamTrees,
Star Tree Studio 3.0 (hyperbolic browser), Tree Viewer
(botanic browser), and Windows Explorer. 48 students
participated, randomly assigned to 6 groups in a betweengroups experiment, each student completing 15 tasks with
only one browser. Students were asked to time themselves,
so the task completion data may not be very accurate. That
said, the self-timings showed Windows Explorer to be sig-

Figure 8: The test room used for the comparative
study.

nificantly faster than most other browsers. Windows Explorer was also preferred to most other browsers, as found
in our own study.
[9] compared the SunBurst hierarchy browser to an inhouse implementation of a treemap browser with 32 students in a repeated measures experiment. Users preferred
the SunBurst browser, but the quantitative results of the
study were inconclusive.
[4] compared a hyperbolic browser to a tree view
browser with 17 test users. There was no significant difference in performance, but users somewhat preferred the
tree view browser. This supports the results from our study,
where users significantly preferred the tree view browser.
[8] compared their SpaceTree to a tree view browser
(Windows Explorer) and a hyperbolic browser. The experiment involved 18 computer science students completing 7
tasks in a repeated measures design. There were some significiant differences on individual tasks, but no general pattern emerged.
[3] compared four hierarchy browsers for decision trees.
They found the treemap to both perform worst and be uniformly disliked, which backs up the results in this study.
Previous research at Graz University of Technology
[1, 6] compared a tree view browser to the InfoSky galaxy
view, based on recursive voronoi tesselations representing
directories and subdirectories. The first study found the tree
view browser to be significantly faster than the galaxy view,
the second study used an improved version of the galaxy
view and found no significant differences.

6. Concluding Remarks
The Hierarchical Visualisation System (HVS) provides a
good platform for hierarchical visualisation. The Hierarchical Visualisation Testing Environment (HVTE) is a semi-

11th International Conference Information Visualization (IV'07)
0-7695-2900-3/07 $20.00 © 2007

T1 Deepest Subdir
Mean
Std Dev
K-S
T2 Most Subdirs
Mean
Std Dev
K-S
T3 Find Dir
Mean
Std Dev
K-S
T4 Find File
Mean
Std Dev
K-S
T5 Count Subdirs
Mean
Std Dev
K-S
T6 Count Files
Mean
Std Dev
K-S
T7 Compare Subdirs
Mean
Std Dev
K-S
T8 Compare Files
Mean
Std Dev
K-S

TV
102.2
108.9
0.000
TV
61.1
31.3
0.200
TV
36.5
30.4
0.000
TV
47.2
42.8
0.000
TV
26.5
15.7
0.000
TV
26.6
18.8
0.002
TV
44.4
17.4
0.200
TV
50.8
34.6
0.012

Pyr
110.8
86.8
0.007
Pyr
57.9
30.4
0.095
Pyr
47.3
61.8
0.000
Pyr
51.5
42.1
0.001
Pyr
2 3.4
11.0
0.014
Pyr
26.9
26.3
0.000
Pyr
46.0
25.5
0.134
Pyr
46.7
23.3
0.200

TM
92.8
86.4
0.000
TM
52.9
26.1
0.200
TM
36.0
37.7
0.000
TM
46.7
36.1
0.000
TM
27.1
18.1
0.002
TM
20.0
13.5
0.000
TM
45.6
25.1
0.050
TM
46.5
24.4
0.043

Hyp
87.6
85.1
0.000
Hyp
58.5
33.6
0.000
Hyp
45.8
44.5
0.000
Hyp
47.9
34.9
0.000
Hyp
32.0
24.9
0.001
Hyp
33.3
19.9
0.140
Hyp
44.5
21.5
0.200
Hyp
53.1
46.2
0.000

Table 4: Mean task completion times and standard
deviations for each browser and task. The K-S test
is a test of normality, significance indicates nonnormally distributed data, non-significance (bold
values) indicates normally distributed data.

automated testing environment built on top of HVS, which
largely automates the task of running comparative studies
of hierarchy browsers.
In the current study with 32 test users, no significant differences in performance were found between the four hierarchy browsers (tree view, pyramids, treemap, and hyperbolic) tested, with one exception for one task.
In terms of subjective ratings, test users consistently
rated the tree view browser significantly higher than the
other browsers in a variety of factors. The treemap browser
was consistently rated significantly lower than the other
browsers in a variety of factors. The tree view browser was
also significantly preferred over the other browsers in most
factors.
In summary, it would appear that users have many, many
hours of experience with tree view style browsers like Windows Explorer. They have developed an affinity to that style
of hierarchy browser which is hard to shake off, even though
other kinds of hierarchy browser sometimes outperform tree
view browsers for certain kinds of task.

T1
T2
T3
T4
T5
T6
T7
T8

Pyr-TV TM-TV Hyp-TV TM-Pyr Hyp-Pyr Hyp-TM
0.400 0.550
0.246
0.130
0.130
0.390
0.411 0.416
0.525
0.575
0.852
0.601
0.262 0.751
0.550
0.411
0.765
0.270
0.765 0.822
0.627
0.822
1.000
0.926
0.654 0.765
0.513
0.537
0.286
0.400
0.896 0.121
0.191
0.466
0.104
0.002
0.755 0.825
0.976
0.935
0.797
0.865
0.808 0.793
0.940
0.896
0.575
0.765

Table 5: Pairwise significance tests for the task
completion times for each browser pairing. T7 was
the only task where all timings were normally distributed and paired samples t tests could be used.
For all other tasks, the timings were not normally
distributed and pairwise Wilcoxon signed ranks
tests were used. The bold value indicates the only
statistically significant difference at p < 0.05.

References
[1] K. Andrews, W. Kienreich, V. Sabol, J. Becker, G. Droschl,
F. Kappe, M. Granitzer, P. Auer, and K. Tochtermann. The
infosky visual explorer: Exploiting hierarchical structure and
document similarities. Information Visualization, 1(3/4):166–
181, Dec. 2002.
[2] K. Andrews, W. Putz, and A. Nussbaumer. The hierarchical visualisation system (HVS). In Proc. 11th International
Conference on Information Visualisation (IV’07), Zurich,
Switzerland, July 2007. IEEE Computer Society Press.
[3] T. Barlow and P. Neville. A comparison of 2-d visualizations
of hierarchies. In Proc. IEEE Symposium on Information Visualization (InfoVis 2001), pages 131–138, San Diego, California, USA, Oct. 2001. IEEE Computer Society.
[4] M. Czerwinski and K. Larson. The new web browsers:
They’re cool but are they useful? Presentation at HCI’97,
Aug. 1997.
[5] J.-D. Fekete and C. Plaisant. Information visualization benchmarks repository, 2003.
[6] M. Granitzer, W. Kienreich, V. Sabol, K. Andrews, and
W. Klieber. Evaluating a system for interactive exploration
of large, hierarchically structured document repositories. In
Proc. IEEE Symposium on Information Visualization (InfoVis
2004), pages 127–134, Austin, Texas, USA, Oct. 2004.
[7] A. Kobsa. User experiments with tree visualization systems.
In Proc. IEEE Symposium on Information Visualization (InfoVis 2004), pages 9–16, Austin, Texas, USA, Oct. 2004.
[8] C. Plaisant, J. Grosjean, and B. B. Bederson. Spacetree: Supporting exploration in large node link tree, design evolution
and empirical evaluation. In Proc. IEEE Symposium on Information Visualization (InfoVis 2002), pages 57–66, Boston,
Massachusetts, USA, Oct. 2002. IEEE Computer Society.
[9] J. T. Stasko, R. Catrambone, M. Guzdial, and K. McDonald. An evaluation of space-filling information visualizations
for depicting hierarchical structures. International Journal of
Human-Computer Studies, 53(5):663–694, Nov. 2000.

11th International Conference Information Visualization (IV'07)
0-7695-2900-3/07 $20.00 © 2007

Q1 Overview
Mean
Std Dev
Q2 Operability
Mean
Std Dev
Q3 Intuitive
Mean
Std Dev
Q4 Usable
Mean
Std Dev
Q5 Understandable
Mean
Std Dev
Q6 Logical
Mean
Std Dev
Q7 Useful
Mean
Std Dev
Q8 Orientation
Mean
Std Dev
Q9 Navigation
Mean
Std Dev

TV
4.78
1.60
TV
5.03
1.15
TV
4.38
1.86
TV
5.09
0.89
TV
5.75
0.51
TV
5.53
1.14
TV
5.09
1.25
TV
5.13
1.16
TV
5.16
1.22

Pyr
4.13
1.68
Pyr
4.16
1.55
Pyr
4.28
1.51
Pyr
3.84
1.32
Pyr
4.97
1.00
Pyr
5.16
0.95
Pyr
3.88
1.43
Pyr
3.13
1.95
Pyr
3.63
1.81

TM
1.25
1.50
TM
3.44
1.81
TM
2.97
1.53
TM
1.72
1.67
TM
4.19
1.89
TM
3.84
2.05
TM
2.75
1.87
TM
1.28
1.53
TM
3.31
1.86

Hyp
3.38
1.43
Hyp
2.97
1.79
Hyp
4.03
1.47
Hyp
2.81
1.71
Hyp
4.84
1.05
Hyp
5.00
1.05
Hyp
3.91
1.57
Hyp
3.06
1.74
Hyp
2.75
1.74

Table 6: User rating data for nine factors about
each browser. The ratings were given on a 7-point
Likert scale and converted to scores between 0
(worst) and 6 (best).

Q1 Overview
Q2 Operability
Q3 Intuitive
Q4 Usable
Q5 Understandable
Q6 Logical
Q7 Useful
Q8 Orientation
Q9 Navigation

Pyr-TV TM-TV Hyp-TV TM-Pyr Hyp-Pyr Hyp-TM
0.086 0.000 0.000 0.000
0.117
0.000
0.015 0.002 0.000 0.062
0.026
0.259
0.768 0.003 0.195 0.001
0.590
0.016
0.001 0.000 0.000 0.000
0.020
0.011
0.000 0.000 0.000 0.038
0.607
0.069
0.038 0.002 0.012 0.001
0.509
0.013
0.001 0.000 0.004 0.010
0.980
0.011
0.000 0.000 0.000 0.000
0.817
0.000
0.002 0.000 0.000 0.542
0.100
0.181

Table 7: Pairwise significance tests for user ratings. None of the data were normally distributed,
so pairwise Wilcoxon signed ranks tests were used
throughout. Bold values indicate statistically significant differences at p < 0.05.

Q1 Overview
Q2 Operability
Q3 Intuitive
Q4 Usable
Q5 Understandable
Q6 Logical
Q7 Useful
Q8 Orientation
Q9 Navigation

TV
18
23
11
24
20
15
23
19
16

Pyr
6
5
10
3
5
6
3
6
7

TM
2
2
1
2
1
0
0
0
2

Hyp
6
2
10
3
6
11
6
7
7

Table 8: The stated browser preference for each
factor. The table entries indicate the number of
votes for each browser.

