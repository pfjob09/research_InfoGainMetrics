2009 13th International Conference Information Visualisation

Navigating VR Panoramas on Mobile Devices

1

Wolfgang Hürst1, Steffen Wittmer2
Utrecht University, Department of Information & Computing Sciences, Utrecht, The Netherlands
2
Albert-Ludwigs-University, Department for Computer Science, Freiburg, Germany
huerst@cs.uu.nl, steffen.wittmer@web.de
panoramas. QuickTime VR (QTVR) [1,2] is maybe the
most popular file format for VR panoramas. It is
supported by Apple’s QuickTime and normally included
as a plug-in in the standalone QuickTime Player as well
as the QuickTime Web browser plug-in for Windows
and Apple OS.

Abstract
Given small screen sizes, navigation in large data
on mobile devices often becomes a problem. In this
paper, we present different interfaces for pen-based
navigation in VR (Virtual Reality) panoramic images on
cell phones with touch-sensitive displays. Four different
solutions have been implemented and evaluated in an
initial user study. Our designs offer users advanced
navigation functionality thus increasing usability and
making VR panoramas on mobile devices more useful.
Keywords: VR panoramas, QTVR, mobile interfaces,
interaction, browsing

With normal photography (top), a
scene is projected onto a 2D image.
When looking at
different display
details of such
an image (right),
perfect perspective
is only provided if the
viewer matches the
camera’s position during
the time of picture
taking. At any other
position, perspective
appears to be unnatural
thus creating the
impression of
a flat, unrealistic
environment.

1. Introduction
Recent increases in storage and processing power
enable us to experience all kind of media on mobile
phones. With today’s devices it has already become
natural to replay audio files, watch videos, and look at
photos on your mobile. However, despite increases in
performance, screen size and restricted input capabilities
remain a natural limit for cell phones. This becomes
particularly apparent when browsing large documents,
for example, scrolling a large list of text, browsing
through a long video, or looking at display details of a
high resolution image.
In this paper, we take a closer look at browsing and
navigating VR (virtual reality) panoramas on mobile
phones. In contrast to a normal, flat panoramic image,
VR panoramas create the illusion for the viewer to be
surrounded by the image. Thus, changing the viewpoint
(e.g. by scrolling to the left or right), not only changes
the display window of the image, but also the perspective
of the objects within the image. Normally, two steps are
involved in creating VR panoramas (cf. Figure 1). First,
a fisheye-like image is taken by using, for example, a
special panoramic camera or by stitching together a
sequence of following photos. Then, this image is
mapped onto a cube or sphere surrounding the observer.
VR panoramas which cover a whole horizontal 360
degree and vertical 180 degree view are also called cubic

978-0-7695-3733-7/09 $25.00 © 2009 IEEE
DOI 10.1109/IV.2009.26

For creating a VR panorama,
usually a fisheye-like photo is
taken by using a panoramic
camera or stitching several
photos together (top).

This photo
is mapped onto
a cube or sphere.
The viewer is placed
inside of this cube or sphere
When browsing through different display details of this VR
image, viewers now always take the same perspective as a
virtual camera which is pointing in the same direction, thus
creating the illusion of a virtual environment.

Figure 1 VR panoramas illustrated
Obviously, browsing full 360 degree VR panoramas
requires much more processing power than scrolling
through display details of a regular photo because
intensive image transformations are needed in order to
constantly adapt to changes in perspective. However,
recent performance improvements enable us to view VR
panoramas on common, state-of-the-art mobile phones
[3]. Unfortunately, the small size of such devices and the

203

order to deal with this problem, we started experimenting
with different kinds of interactions based on the concept
of elastic interfaces [4]. In our approach, called elastic
panning, scrolling speed is not set based on the distance
between the current mouse pointer position and a fixed
reference point but instead, it is adapted dynamically.
Clicking anywhere on the screen again creates a
reference point. However, this is not a fixed reference
point as with the standard interface but an “elastic” one
which (after a short delay) follows the mouse pointer’s
movements. The idea can be illustrated by imagining a
virtual rubber band which is spanned between the
flexible reference point and the mouse pointer (cf. Figure
3). The pointer pulls on the rubber band making the
reference point follow its movements. The speed at
which the reference point follows the mouse pointer
depends on the length of the rubber band: if the length
(i.e. the tension on the rubber band) increases, the
reference point moves faster. If it gets shorter (i.e. the
tension on the rubber band decreases), movement slows
down. The resulting scrolling speed and direction of the
reference point are then mapped directly to movements
of the VR panorama, i.e., the image moves behind the
visible area at the same speed and in opposite direction
as the elastic reference point. Once the pen is lifted from
the screen, scrolling stops immediately. The main
advantage of this approach is that the rubber band effect
compensates small irregularities in the input, thus avoids
the problem of getting lost due to small mouse pointer
changes at a high scrolling velocity. This comes at the
price that it is much harder to keep scrolling at a constant
speed because of the continuous adaptation of the
dynamically moving reference point. However, our first
experiments with an implementation on a desktop PC
environment indicated that the latter issue does not seem
to be a critical problem given the large screen size.
Further evaluations of this approach in desktop PC
environments are ongoing work and beyond the scope of
this paper. For this paper, we implemented and evaluated
a version of the elastic panning approach on a mobile
phone (cf. next section).

resulting difficulties for interaction remain a major
burden for the usability and usefulness of such data on
cell phones.
In the following, we start by describing general user
interface issues for VR panoramas on desktop PCs and
discussing their representation on mobile devices
(Section 2). We introduce four different interface designs
for better navigation in such data on a cell phone with a
touch sensitive display and pen interaction (Section 3). A
first user study (Section 4) evaluates the designs,
compares the different approaches, and highlights issues
for future research (Section 5).

2. VR Panoramas on Desktop PCs and
Mobile Phones
VR panoramas have become very popular on the
web. Examples for such images can be found at
http://www.panoramas.dk/. In the standard interface for
navigation within such images (cf. Figure 2), users create
a reference point by clicking anywhere on the image.
Moving away from that position starts scrolling of the
image in the opposite direction of the mouse pointer’s
movements. This kind of interaction is often called
panning because the resulting effect resembles looking
through the view finder while panning a camera over a
scene. Scrolling speed is set proportional to the distance
between the reference point and the current mouse
pointer position. Hence, users can increase or decrease
scrolling velocity by moving further away and closer to
the reference point, respectively. Scrolling stops
immediately if the pressed mouse button is released or if
the mouse pointer reaches the original reference point
again.

Scrolling direction: Scrolling is
done exactly in the opposite
direction of the mouse pointer’s
movements, thus creating the
effect of a camera panning over a
scene.

WINDOW
WITH
DISPLAY
DETAIL

ELASTIC RUBBER
BAND

Scrolling speed is set proportional to the
distance between the reference point and
the current pointer position.
As a consequence, all positions on the
dotted circle in the illustration result in the
same scrolling speed (but different
directions)

REFERENCE
POINT

FLEXIBLE
REFERENCE
POINT
CURRENT POINTER
POSITION

CURRENT POINTER
POSITION

Elastic panning. Scrolling speed
is set proportional to the length of
the elastic rubber band (longer
band → stronger tension → faster
movement). Scrolling direction is
done in opposite direction of the
pointer’s movements.
SCROLLING DIRECTION
OF THE FILE

Figure 2 Standard interface for browsing VR
panoramas

Figure 3 Elastic interface for browsing VR
panoramas

Although this kind of navigation seems very simple
and intuitive, problems can be observed during
operation. Especially when scrolling at higher velocities
and large zoom levels, people often tend to get lost in the
image because small changes in scrolling direction can
result in large changes of position within the image. In

For our implementation of alternative interface
designs for VR panoramas on mobile devices we used
the PTViewerME by Helmut Dersch from Furtwangen
University, Germany [3,5] which is licensed under the
GNU GPL. This viewer for VR panoramas is
implemented in Java and thus requires a cell phone

204

Standard interface and elastic panning. When
making the PTViewerME run on our Sony Ericsson
W950i, we first changed visualization from the portrait
mode used in the original implementation to landscape
mode. Thus, VR panoramas can now be viewed at a
resolution of 320x240 pixels by holding the device
sideways.
By adding touch screen functionality to the viewer,
we were able to implement a standard navigation
function similar to the one commonly used for desktop
applications and described at the beginning of Section 2
(cf. Fig. 2). An image of the actual implementation can
be found in Figure 4. A small dot marks the fixed
reference point. A triangle next to the pen’s tip illustrates
scrolling direction.

running Java Micro Edition (J2ME) as well as several
Java add-ons (e.g. JSR 184 for 3D graphics support; for
further details see [5]). In the original implementation of
the PTViewerME, navigation is done, for example, using
the joystick like button provided by many cell phones.
Additional buttons from the phone’s keypad can be used
for zooming. Scrolling speed is therefore limited to fixed
velocity values. This restriction obviously reduces
usability of VR panoramas on mobile devices. Providing
only fixed scrolling speeds prevents users, for example,
from getting a quick overview (by scrolling very fast) or
doing an exact positioning (by scrolling very slowly).
Using additional buttons to offer a larger range of
scrolling speeds might reduce this problem to some
degree but at the same time increases complexity and
manageability of the interface.
The current trend of equipping cell phones with a
touch sensitive display that can be operated by pen or
finger input gives us new opportunities to deal with this.
For example, it enables us to implement the two desktop
interfaces described above. In our experiments, we used
a Sony Ericsson W950i cell phone. It features a touch
screen which is operated by a small pen. In addition, it
has a larger screen resolution (240x320 pixels) than the
device used by the author of PTViewerME, and it
provides a bigger Java Heap (approx. 4MB compared to
2MB on the device used by Dersch [3, 5]). However, due
to memory restrictions, the viewer still down-samples the
panorama images to a rather low resolution. In our
experiments, we used a size of 512x512 pixels for each
square of the cube representing the VR panorama (cf.
Figure 1). The internal resolution of the viewer is
actually even lower, i.e. 256x256 pixels, but since it uses
a very good interpolation algorithm, we figured out that
the image size used by us yields to a better image quality
on the mobile phone.
All of the interfaces developed and evaluated as part
of this paper assume pen-based input. Finger-based
interaction – although possible – does not seem useful
for us here due to the small screen size. Evaluating if the
results presented in this paper are also valid for devices
with larger screens and investigating finger input is part
of our future work (cf. Section 5). When we started
working on this project, the ability to program on the
Apple iPhone was still limited thus forcing us to restrict
our work to devices with the characteristics specified
above. This situation has changed now since better
development tools and a more open API are meanwhile
available for the iPhone and in addition, more and more
phone manufactures offer devices with a similar large
screen and touch functionality.

Figure 4 Implementation of the standard
interface
Similarly to the standard interface, we also
implemented a mobile version of the elastic panning
approach that is described at the end of Section 2 (cf.
Figure 3). On the touch screen, it is visualized by two
small icons, a black and a white circle representing the
current position and the elastic reference point,
respectively. The virtual rubber band spanned between
these two objects is illustrated by a thin dotted black line,
as shown in Figure 5.

Figure 5 The elastic panning interface
2D-PVslider. The 2D-PVslider approach was
inspired by the PVslider interface used in [6] for 1dimensional video browsing along the timeline. In our
implementation on the mobile device, we extended this
concept to a 2-dimensional navigation, enabling us to use
it for scrolling through VR panoramas. Our approach is
motivated by the observation that it is usually quite hard
to do an exact positioning (e.g. placing a particular object
in the VR panorama directly in the middle of the screen)
by modifying scrolling speed – even if very slow

3. New Interfaces for Mobiles
In all four interfaces presented below, scrolling
speed and direction for navigation within the VR
panorama are set depending on the position and
movement of the pen on the touch sensitive screen (cf.
Figures 4-6). Zooming in and out is done by using two
buttons on the phone’s keypad.

205

both parts with a lower weight (0.5 vs. 1.0 in our
implementation) for the vertical part. The approach is
illustrated in Figure 7. For this interface, no additional
visual feedback is needed in the actual implementation.

velocities are supported. For such a task, grabbing the
image and moving it directly seems to be much easier
and more convenient. Therefore, the 2D-PVslider is split
into two areas (see Figure 6): An inner circle, the
position region, and an outer circle, the velocity region.
Clicking on the screen makes the circle appear centered
around the pen. Moving the pen within the visualized
circle makes the image follow the pen’s movements thus
allowing the user to navigate within a small range of the
image. Once the inner part of the circle is left, the viewer
switches to velocity mode which is similar to the
standard interface illustrated in Figure 2. The only
difference in the implementation is that the distance
between the pen’s position and the reference point (i.e.
the center of the circle) is reduced by the radius of the
circle before calculating the related scrolling speed. The
interface is visualized by a dot indicating the reference
point, the circle around it, and an arrow indicating
scrolling direction if the pen is outside of the circle, i.e.
in velocity mode (cf. Fig. 6).

LENGTH AND DIRECTION
OF THE PEN’S FLICK
VERTICAL
FRACTION
dVERT OF THE
PEN’S FLICK
SCROLLING
DIRECTION d

Scrolling direction is set as a
weighted sum of the vertical
and horizontal fraction of the
pen’s flick:
d = - (0.5*dVERT + 1.0 * dHORIZ)
Scrolling speed is set
proportional to the length of the
pen’s flick.

HORIZONTAL FRACTION dHORIZ
OF THE PEN’S FLICK

Figure 7 Illustration of 2D flicking

4. Evaluation
The original interface of the PTviewerME offers
only fixed speed values for browsing. In addition,
interaction via the small keypad can be quite difficult,
especially for exact positioning tasks. In contrast to this,
our interfaces presented in the previous section enable
users to browse VR panoramas at different speeds. The
2D-PVslider and 2D-flicking also offer two different
interaction modes: standard navigation by modification
of scrolling speed as well as direct movement of the file
for exact positioning. However, providing more
functionality can also increase complexity of an
interface. In addition, it is not clear if people are
comfortable with such a pen-based operation on a small
display, especially since for the normal phone interface,
the pen is generally only used to select menu entries and
push buttons, i.e. simple click operations instead of
continuous pen movements over the screen. In order to
evaluate the usability and verify manageability of our
interfaces, we therefore set up an initial user study.
Another aim of this experiment was to identify the
advantages and disadvantages of the four different
designs compared to each other.
Setup. 15 subjects (twelve male, three female, ages
20-30) participated in the evaluation. Four of them had
experience with pen-operated mobile devices (mostly
PDAs), seven mentioned to have a little experience
(including people who just have tried it out a few times),
and four had no experience with this kind of interaction
at all. None of them had used VR panoramas on a cell
phone before. In the evaluation, we did not observe any
differences between these groups of users with different
experience levels.
For the experiment, we used a within groups design,
i.e. each participant evaluated all four interfaces
described in the previous section. We selected three 360
degree VR panoramas (two landscapes and one showing
the inside of a church) for the tests. Since all of them
showed popular scenes, we assumed that some of the
users might be familiar with some of the contents
presented in the photos. For this reason, we decided to
show only one of the three images to each of the

Figure 6 The 2D-PVslider approach
iPhone-style 2D-flicking. Our final approach also
enables users to move the image directly and to navigate
by manipulation of scrolling speed. It is inspired by the
way in which long lists are skimmed on the iPhone.
There, you can move a list up or down by resting your
finger on the screen and moving it in the respective
direction. By flicking your finger quickly over the
screen, the list starts scrolling at a certain velocity which
continuously decreases. Initial scrolling speed depends
on the momentum of the finger’s flick, i.e. the faster you
flick, the faster you are scrolling in the list. Extending
the direct manipulation part to a 2-dimensional case is
straight forward and similar to the interaction in the
position region of the 2D-PVslider. However, when
implementing a 2-dimensional flicking functionality, we
immediately realized that it was hard to operate. The
reason for this is that people generally are not able to
draw a perfect straight line and thus end up going in an
unwanted direction. For example, assume you want to
scroll strictly horizontally and flick the file, for example,
very strongly to the right. Given the high scrolling speed,
even very small variations from a perfect horizontal line
will result in an unwanted upwards or downwards
movement which can be very irritating and frustrating.
However, a simple modification can solve this problem:
Each input (i.e. movement of the pen on the screen) is
split into its horizontal and vertical part. Then the
scrolling direction of the file is set as a weighted sum of

206

because they contradicted with our experience in
navigating VR panoramas on desktop PCs.
Standard interface. To our surprise, the standard
interface achieved the best average grade in the final,
overall rating of the interfaces (cf. Table 1.4, last
column). Most users commented that they particularly
liked this interface’s simplicity in both functionality and
visualization. Generally, all participants were able to
handle it very well. This result was unexpected given the
problems we saw with this kind of interaction for VR
panorama browsing on desktop PCs (cf. Section 2).
However, the reason for this turned out not to be
grounded in the interface, but was caused by the low
resolution of the VR panoramas (cf. Section 2, last
paragraph) and the small form factor of the device.
Having only one, rather coarse zoom level and a
relatively small screen area to move the pen avoided
most of the problems typically observed in desktop
environments, such as getting lost or ending up in a
wrong part of the image due to a small change in
scrolling direction at high velocities.
Elastic panning. Given the positive initial
experience we had with elastic panning on the desktop
PC, we were also quite surprised about the negative
feedback for this approach which got the lowest average
grade in the final, overall rating (Table 1.4, last column).
However, this observation can again be explained by the
different conditions we have on a mobile device
compared to desktop environments. First, the advantages
of elastic panning which have been mentioned in Section
2 were not apparent to most users since the related
problems with the standard slider did not appear on the
mobile phone. Second, the lack of a constant scrolling
mode and the resulting need to continuously being forced
to reposition the pen when scrolling longer distances
(such as full 360 degree turns) was considered very
annoying. Indeed, this was the main reason mentioned by
many users for their rather low ratings. On desktop PCs,
this problem is less critical because repositioning of the
pen is not required that often due to the larger screen
size. However, on the plus side, some users noted that
this approach is better than 2D-flicking (cf. below)
because scrolling stops immediately when the pen is
released, its easier to control, and better for fine
adjustments.
2D-flicking. Considering the other two approaches,
no clear trend could be observed. For 2D-flicking, users
noted positively its handy operability and the (missing)
visualization. However, few participants noted that the
complete lack of any visual feedback sometimes caused
orientation problems. We actually observed somehow
similar problems in recent experiments with onedimensional flicking for timeline-based video browsing
which we were able to solve by providing additional
visual feedback [7]. Negative comments were mostly
related to the last task where users were asked to head for
particular objects and do an exact positioning. Some
users considered 2D-flicking to be less accurate for tasks
requiring fine adjustments of the display detail. Although
one also needs to continuously re-position the pen when

participants and give them some time to familiarize
themselves with its content before the actual evaluation.
The goal of this was to avoid any irregularities in the
feedback which could have resulted from different
previous knowledge of the used data. Hence, our
experiments simulate browsing tasks in known material.
Evaluation of navigation in unfamiliar data is part of our
plans for future work (cf. Section 5).
Groups of five users were assigned to one of the
three photos. For each group, the order in which they
tested the interfaces was unique to avoid any influences
on the evaluation. We were not able to identify any
differences among the three groups. Therefore, we
assume that the actual content had no influence on the
usability of the interfaces. All photos were set to an
intermediate zoom level and users were not asked to do
any zooming during the evaluation.
Procedure. As noted above, the photo was shown to
each participant at the beginning. Then, the device was
handed over to them and they were asked to figure out
how the first interface works by experimenting with it.
They only knew that they can navigate through the image
by moving the pen somehow over the screen. After they
understood its functionality and took some time to
practice and experience it, they were asked to solve two
tasks: First, they were supposed to get an overview of the
whole scene (landscape or church) by making a full 360
degree turn. Then, they had to do a task including exact
positioning, for example, finding a church tower that was
visible in one of the landscapes and placing it directly in
the center of the screen. After everything was done, the
same procedure was repeated for each of the remaining
three interfaces.
Feedback was captured in terms of some ratings for
each interface where the participants had to give grades
on how intuitive each interface is, how well it can be
operated, what functionality it provides, and a
summarizing overall assessment. Grades were given
from 1 to 5 (with 1 being the best possible one, similar to
the German high school rating system). Since
intermediate ratings are common in German school
systems, it was allowed to also specify a first decimal
place. Ratings were given immediately after each
interface was evaluated, but it was allowed to do a final
modification at the end in order to give a comparative
judgment. In addition to the ratings, the common think
aloud technique was used during the experiments, i.e.
users were asked to describe what they are doing and
were encouraged to give comments and feedback during
the tests. A neutral observer noted any comments and
observations. After performing the tasks, users were also
interviewed and questioned, for example about their
ratings, etc.
Results. General feedback from the participants
about the use of VR panoramas on mobile devices was
very positive, confirming our initial impression that
presenting such data on mobile phones is promising and
useful. When looking at the actual interfaces, we made
some observations which were a little surprising to us

207

User

9

12

Standard

1

1

2

4

11

1

13

14

15

3

6

8

5

7

1 1.5

1

1

1

2

2

2

2

3

2

2 1.5

10 A verage
1.60
2.08

Elastic 1.5 2.5

3 2.5

2

1

1

1

1

2 1.7

4

3

3

Flicking 1.5 3.5

2 2.5

2

1

1

1

1 1.7 1.5

1

1

2 1.5

1.61

1 1.5

1

1

1

2

2

2 1.5

1

1

1.50

PV slider

2 1.5

3

2
1

How w ould you r ate the pr ovide d functionality?
User
Standard

3

4

9

8

15

2

7

10

12

Table 1.1
1

13

14

5

6

11 A verage

2 1.7

1 1.5 1.5

1

1

1

1 1.5

1

1

1

1

2

Elastic

2 3.5

2

2

2

3

2

2

3

2

2

1

3 1.7

1

Flicking

2 2.2

2

1

1

4

2 2.5

3

1

1

1

1 1.5

1

1.75

2

3

3

2

1

1 1.5

1

1

1

1 2.5

2

1.73

PV slider

2

2

How w e ll can this inte r face be ope r ate d (m anage ability)?

1.28
2.15

Table 1.2

User

3

10

14

15

1

7

12

9

4

13

2

8

11

5

6 A verage

Standard

1

1

1

1

1

1

1

1

1

1

1

1

1

2

2

1.13

2 2.5

2

2

2

2

2

1 2.7

2

1

1

1

2 1.7

1.79

Elastic
Flicking

2

3

2

2

3

2 2.5

1

1

1

3 1.5

2

1 1.5

1.90

PV slider

3

2

2

2

1

1

2

1

1

1

1

2

1.53

1

1

2

How intuitive is this inte r face ?
User
Standard
Elastic

2

4

9

11

1 1.2 1.3 1.3
3

12

Grades are from 1 (=
best) till 5 (= worst)
with 0.1 steps.
The best rating given
by each user is
indicated using bold
face. The ordering of
the columns is done
based on these best
ratings, i.e. similar top
ratings are grouped
together.

Table 1.3
15

10

1 1.2 1.5

3 1.7 1.4 2.5 1.5 1.7

Flicking 2.5 2.2 1.5 1.7 2.7 1.3
PV slider 1.5 1.5 2.3 1.5 1.5

Tables 1.1-1.4.
Comparative ratings
given by the
participants.

1

3

5

6

8

1 2.5

2

2

2

2

2 2.7 1.7

14

7

13 A verage

2 1.5 1.5

1.53

3 1.7 2.5 1.7

2.14
1.70

2

1 1.7

1 1.5 1.5 1.5

2 1.4

2 1.5

1 2.7

2 2.3 2.5

1 1.3

Ge ne r al im pr e s s ion and ove r all r ating

2

1.77
Table 1.4

functionality is very useful for fine adjustments. The
initially surprising observation that some users still rated
the standard interface’s functionality higher than the 2DPVslider’s might be explained by a decrease in the
maximum scrolling speed: Because the inner circle uses
up a lot of screen space, users are not able to make
similarly large radiuses (and thus, achieve similarly high
velocities) than with the standard interface. One
participant actually proposed to use a quadratic radius-tospeed mapping in order to deal with this problem.
Comparative ratings. Comparing the ratings given
for the functionality of each interface (Table 1.1), no
clear trend can be identified and some inconsistencies are
observed. As said in the previous paragraph, users did
not necessarily appreciate the additional functionality
added by the 2D-PVslider, either because it was
accompanied by a decrease of the maximum scrolling
speed compared to the standard interface or because they
just did not see any need for this kind of interaction.
Personal preferences were also the main reason for
different ratings of the functionality for 2D-flicking
compared to elastic panning: Users who saw tasks
involving fine adjustments (e.g. direct positioning of an
object) as more important than fast, continuous browsing
tasks (e.g. getting a quick 360 degree overview)
generally gave elastic panning a higher rating than 2Dflicking, and vice versa. Two users gave all interfaces the

making a 360 degree turn in the data, this issue was not
considered to be critical (in contrast to elastic panning,
cf. above). Most likely, this is due to the fact that you do
not have to keep the pen constantly on the screen during
scrolling but lift it after making one flick anyhow, which
apparently makes repositioning of the pen much more
natural and seemingly more integrated into the overall
interaction style. On the other hand, some users
considered this to be a disadvantage because as a
consequence an additional click on the screen is required
to abruptly stop scrolling whereas with elastic panning,
this is achieved by simply lifting the pen.
2D-PVslider. The major reason for lower ratings of
the 2D-PVslider approach was its visualization.
Although being rather small and not covering much of
the photo’s content, it was considered disturbing and
distracting by most users especially given the small
screen size. In terms of functionality, this approach is
more powerful than the standard slider because it
features the very same functionality in the outer circle
but adds the possibility to move the image directly in the
inner circle. Therefore, we were quite surprised that
many participants even noted the circle as being
redundant at their first glance at the interface. However,
after experiencing it for a while, some users changed
their mind and said that it is an improvement over the
standard slider. Some explicitly noted that the additional

208

resolution. It will be very interesting to verify if the
above mentioned statement about complexity vs.
functionality still holds for this data. In addition,
scrolling at a higher zoom level might result in similar
problems with the standard interface like we observed
them on desktop PCs. Further areas worth exploration
are devices with larger screens and finger-based
interaction instead of using a pen (cf. comments at the
end of Section 2).
As already mentioned earlier, we are also planning
to investigate more complex browsing tasks such as
finding an object in an unknown scene. Finally, we want
to experiment with different input devices besides penbased operation. For example, in [8], Rohs and Essl
investigated information navigation methods using
different sensor technologies for spatial tracking in an
abstract map navigation task. Some of these approaches
might be useful for browsing VR panoramas as well.

highest possible rating, indicating that even if there are
differences between the functionality provided by each
one, these are not relevant in practice.
Considering the manageability of the interfaces (cf.
Table 1.2), all but three participants gave the standard
interface the highest rating. However, nine of them said
that 2D-flicking, the 2D-PVslider, or both approaches
can be handled equally well. Generally, the elastic
panning approach was considered to be the most
complex one and got the highest rating for manageability
only in two cases. The ratings for manageability are
closely related to the users’ opinions on how intuitive the
interfaces are (cf. Table 1.3). Again, the standard slider
got the best grade in almost all cases. Only two users
rated 2D-flicking as being more intuitive (unfortunately,
we do not have any information if they have been
familiar with 1D-flicking as it is, for example, used in
Apple’s iPhone). However, all approaches have been
considered quite intuitive by the participants. Even
elastic panning got remarkable good ratings and on
average was even graded slightly higher than 2Dflicking.

Acknowledgements
The authors like to thank Helmut Dersch,
Furtwangen University, Germany, who developed the
PTViewerME and provided valuable input and support
for using it in our project.

5. Discussion and Future Work
The most important result from our evaluation is the
fact that all interfaces got a relatively high rating and
were perceived very positively by all participants. Even
elastic panning, which got the lowest rating in all but one
category, was generally graded relatively high. In fact,
some participants of the study said that all interfaces
were quite good and useful and that there are only
marginal differences. In addition, looking at VR
panoramas on such a mobile devices was considered to
be interesting, fun, and entertaining. We interpret this as
a confirmation of our initial statement that viewing VR
panoramas on mobile devices is indeed useful. Offering
advanced interfaces and interaction elements, such as the
ones introduced in this paper, can increase their usability
even further and open a whole range of new and
interesting applications.
From the results of the evaluation, no single best
solution could be identified for the interface design.
Nevertheless, some general trends and guidelines can be
observed. Extensive and large widgets are often
considered disturbing and distracting because of the
small screen size. Hence, visualization of the interface
should be kept to a minimum. However, some feedback
is generally appreciated in order to support orientation
during browsing. In addition, users prefer clear control
over the interface and do not appreciate unpredictable or
hardly controllable behavior. While these are general
observations which most likely hold true for all kinds of
interfaces on small devices, the observation that easy
operation and low complexity is preferred even when it
comes at the price of a reduced functionality is
interesting and worth further investigation. Performance
of mobile devices keeps constantly increasing. The latest
generation of high end cell phones already allows us, for
example, to process VR panoramas at a much higher

References
[1] Apple – QuickTime – Technologies – QuickTime VR, see
http://www.apple.com/quicktime/technologies/qtvr/ [last
access: April 2009]
[2] Shenchang Eric Chen (1995) QuickTime VR: an imagebased approach to virtual environment navigation.
Proceedings of the 22nd Annual Conference on Computer
Graphics and Interactive Techniques (SIGGRAPH 1995)
[3] Helmut Dersch (2007) PTViewerME – HowTo.
(conference slides), PanoTools Meeting, Luzern 2007, see
http://webuser.hs-furtwangen.de/~dersch/PTViewerME/
Luzern.pdf [last access: April 2009]
[4] T. Masui, K. Kashiwagi, G.R. Borden IV (1995) Elastic
graphical interfaces to precise data manipulation.
Conference companion on ACM CHI 1995.
[5] Homepage, Helmut Dersch, see http://webuser.hsfurtwangen.de/~dersch/ / [last access: April 2009]
[6] G. Ramos, R. Balakrishnan (2003) Fluid interaction
techniques for the control and annotation of digital video.
Proceedings of ACM UIST 2003, Vancouver, BC, Canada,
Nov. 2003.
[7] W. Hürst, Konrad Meier (2008) Interfaces for Timelinebased Mobile Video Browsing. Proceedings of ACM
Multimedia 2008, Vancouver, BC, Canada, October 2008
[8] M. Rohs, G. Essl (2007) Sensing-based Interaction for
Information Navigation on Handheld Displays.
Proceedings of the 9th International Conference on
Human Computer Interaction with Mobile Devices and
Services (MobileHCI), Singapore, September 9-12, 2007.

209

