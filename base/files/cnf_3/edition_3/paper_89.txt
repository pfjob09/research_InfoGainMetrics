2009 13th International Conference Information Visualisation

New Techniques for Visualising Web Navigational Data
V. Pascual-Cid1,2 , R. Baeza-Yates2,3 , J.C. D¨ursteler2 , S. Minguez1 and C. Middleton1
1
Fundaci´o Barcelona Media, Barcelona, Spain
2
Universitat Pompeu Fabra, Barcelona, Spain
3
Yahoo! Research, Barcelona, Spain

Abstract

do during their visit.
To ground our understanding of the problem, we interviewed four experienced Web analysts, each of them with
more than four years of experience on the Web Analytics
field. The aim of these interviews was to understand the
major problems that Web experts suffer in their day-to-day
work, and the properties of the tools that they are currently
using in order to get feedback on how to improve the functionalities of the Website Exploration Tool (WET), already
introduced in [12]. The interviews were semi-structured,
and basically guided by the answers. Although analysts’
main goals were different, all of them agreed that the tools
they are currently using do not provide all the insight they
believe can be extracted from usage data. Moreover, all of
them acknowledged that there is too much data to be easily
understood, and stated that current website analysis tools
have a lack of more explorative visualisations for drilling
down on the available data.
According to our preliminary poster [13] and the feedback provided by the Web analysts, the main contribution
of this paper is the presentation of a set of techniques that
enable the representation of Web Navigational Data, providing combined visual abstractions that can be customised
by the user, as well as recomputed by changing the focus of
interest. Contrary to most of the current visualisation systems which usually use only one visualisation for solving a
specific problem, our highly interactive system allows the
mapping of several Web metrics at the same time within a
context, such as visual abstractions from website structure,
user sessions from a focus of interest and a new approach
for representing web usage as a hierarchy.

Understanding Web Navigational Data is a crucial task
for Web analysts as it may influence the website improvement process. However, major Web analytics tools do not
provide enough insight, taking into account the vast amount
of data available in Web servers’ log files. Moreover, some
analysts argue that those tools have a lack of rich visualisations that enable the exploration of such data. In this paper
we introduce new techniques applied to a highly interactive
and exploratory tool, to allow drilling down through Web
usage data. The system uses a set of coordinated visual abstractions from website structure and users’ navigation to
provide different perspectives and hence, to assist the conversion of data into knowledge.

1

Introduction

One of the most important key performance indicators
for Web analysts is the Conversion Rate (CR), which measures how many users that have reached a website have
also accomplished one of its goals (e.g. subscribing to the
newsletter service, buying a product or downloading a software). While this value is present in most of the commercial
Web analytics tools, it is not easy to comprehend the reason
why the CR of a website is high or low. For instance, a low
CR could mean that the website’s hyperlink structure is not
easy to navigate, so users leave it before completing a goal.
To achieve the insight required to understand users’ behaviour, Web analysts make extensive use of Web metrics derived from the field of Web Usage Mining (WUM).
Nevertheless, the vast amount of information available to
be analysed and understood emphasises the need of exploratory tools to help analysts in their website improvements process.
There are many factors that may influence users’ behaviour. For instance, discovering the entry and exit points
of the site may provide useful information on how the users
arrive to a site, where do they abandon it, and what did they
978-0-7695-3733-7/09 $25.00 © 2009 IEEE
DOI 10.1109/IV.2009.53

2

Related Work

Realising the importance of understanding Web Navigational Data, researchers have focused on developing visual and exploratory systems for its analysis. In that sense,
one of the main trends has been the visualisation of users’
paths with node-link diagrams [14, 7, 10]. While these systems provide visualisations of users’ routes, another com627
621

mon approach has been the visualisation of users’ behaviour
along with the website structure, used as a context where
to interpret such data. Furthermore, as the visualisation of
the whole webgraph usually generates cluttered visualisations, the most used approach to overcome this problem has
been the extraction of hierarchies out of it, usually using a
Breadth First Search algorithm [6, 3, 7]. With this approach,
Chi et al introduced a system based on the visualisation of
website structure using the radial Tree visual metaphor [5].
The edge thickness was used to map the amount of traffic
occurred on a link while colour was used for mapping the
type of content of the target node. The same authors also
presented Time Tube [6], which consists of a set of snapshots that represent the evolution of the website with time;
and the Dome Tree [4], which is a modification of the Radial Tree that uses a third dimension where users’ paths are
displayed.
Following the same approach, Chen et al [3] proposed
a visual data mining system with the ability to visualise
what they call multi-layer webgraphs. Their approximation
is based on the combination of layers that contain information from web usage, with the structure of the website
represented as a Radial Tree. The authors also proposed
another visual metaphor called Polygon Graphs [2]. This
technique extends the concept of the Radial Tree metaphor
by generating polygons that appear from the connection of
parent nodes in the hierarchy with representative points in
the edges calculated according any usage data of its children node. Hence, visual artefacts are produced within the
hierarchy, generating outliers that assist the detection of patterns.
Another approach for visualising Web Navigational Data
is the proposed in VISVIP [7]. This system uses a simplified representation of a webgraph laid out using a force
directed algorithm where nodes are colour-coded to denote
page type. Users’ paths are then represented using smooth
curves upon the graph. The time that subject has spent at
each page is also depicted using dotted vertical lines which
height is proportional to the amount of time spent in that
node.
Keahey and Eick decomposed the general path analysis problem into a set of visualisations that focus on representing the paths between predefined pages [11]. For instance, they present Funnel Charts as a solution for visualising dropout rates along a designated sequence of pages.
This approach has been widely adopted by the Web Analytics community, and is available in most of the current analisys tools. Source/Target Charts and Leaky Pipe Chart were
also presented for depicting the traffic between some entry
and exit pages in the site. These visualisations resemble a
vertical tree layout where a small number of entry pages are
located in the top of the image, and ending points in the bottom side. They also emphasise the usage of edge thickness

for mapping the amount of traffic held by every link.
Finally, Eick [9] proposed a visualisation to depict users’
behaviour based on the usage of three columns. The left
column contain nodes that represent the most frequent referrer pages used to reach a desired page, located in the
middle column. The destination pages after the focus node
are placed in the right column. Hence, it is quite intuitive to
identify the users’ flow around a single node.
Next section will show how our system uses some of
the techniques presented above, and which new approaches
have been followed to enhance the understanding of Web
Navigational Data.

3

Visualising Users’ Behaviour

The website Exploration Tool (WET) is a visual tool to
support Web Mining. Its main characteristic is its ability to
overlay the visualisation of web metrics and web usage on
top of meaningful representations of a website. The main
goal of WET is to assist in the conversion of web data into
information by providing an already known context where
web analysts may interpret the data.
As we have already seen, a typical approach for representing the webgraph of a site avoiding the generation
of cluttered visualisation is to use hierarchical representations. In that sense, WET generates representative hierarchies from the website structure or the aggregation of users’
navigation.

3.1

The Graph’s Logic System

While the extraction of hierarchies from a website’s
graph is a common technique for representing it, visualising very large trees with thousands of nodes still generate visualisations with too many items. To overcome this
problem we have developed a system called Graph’s Logic

Figure 1. The GLS selects relevant nodes
(contoured area), and non-relevant ones
needed for the generation of the website
structure

622
628

System (GLS), which aims at avoiding visualisation as well
as computational overloads caused by the representation of
very large websites. Thus, this system is able to calculate
representative and complete subgraphs from the whole webgraph containing valuable data to solve a specific problem.
For instance, knowing that usually the pages with highest
traffic are a small subset of pages in a site, the GLS is capable of extracting the complete subgraph that contains them.
To obtain this subgraph, the GLS calculates the minimum
path from the home page to each of relevant node. The nonrelevant ones that appear in this process are then part of the
selected subgraph and hence, collected to maintain the notion of website structure. An example of the GLS may be
found in Figure 1, where the contoured area represents the
nodes of the subgraph extracted by the GLS, which contains
relevant nodes (bigger nodes in the image) and non-relevant
ones that are part of the same subgraph.

3.2

the concept of Local Maximum Link (LML) as a link that
provides the highest amount of traffic to a node in the Webgraph. Hence, each node in the Webgraph, except the root,
will have one LML. Our objective was to generate a hierarchy containing the maximum number of LMLs, in order
to get a visualisation based on the users’ behaviour, rather
than on its theoretical structure. Our approach is based on
a Maximum Branching algorithm, which collects the LML
of every node in the site, and resolves the cycles that this
process may produce [8]. This visual abstraction generates
hierarchies that enable the direct visualisation of the most
used link per page in the site.
To prove the usefulness of this approach, we compared
the three hierarchical approaches for representing a website:
a typical Breadth First Search algorithm (BFS), a WeightedBreadth First Search (W-BFS) algorithm as presented in the
previous section, and the Maximum Branching (MB) approach. Figure 2 illustrates an example of the output of
those algorithms. The experiment was based on counting
the number of LMLs selected by the three algorithms on
five different websites, each one rooted randomly at a hundred different nodes. From the records generated by each
algorithm, we deleted those executions that were unable to
generate a tree because the selected root didn’t have any out
link. The selected sites had different sizes and were selected
according to its different structures, going from a personal
website with a few hundred pages and links, to a highly
connected blog with about three thousand pages and fifty
thousand links.
Table 1 shows the average percentage of LMLs found by
each algorithm on each website as well as the standard deviation of the measures. These values have been calculated
according to the Total LML value, which represents the desired number of LMLs (ideally (n − 1)) minus the number
of non-relevant LMLs. We define a non-relevant LML as
a link that points to a page that has never been navigated.
These edges are considered irrelevant, as none of them report traffic to its target node.
While it can be seen that the results changed according
to the connectivity of the websites, it is clear that the MB
algorithm always shows more LML than the Breadth First
Search approaches, improving the results in an average of a
20%.
From this experiment we can conclude that the MB algorithm produces hierarchical visualisations that improve the
accuracy of BFS and W-BFS in terms of visualising LMLs.
Hence, this approach helps on showing the most used links
within the site.

Structure Tree

Representing a website as a hierarchy means that, from
all the existing links (up to n(n − 1) since webgraphs are
directed), n − 1 must be selected with the condition that every node must end up having only one incoming edge (except the root). One approach to deal with this problem is
to extract the website structure as proposed by Botafogo
et al. in [1]. The authors proved the usefulness of a
Breadth First Search algorithm (BFS), which selects the first
non-expanded incoming edge per node that appears in the
data traversal to resemble the theoretical website structure.
However, due to the nature of this algorithm, other parents
of a node that coexist in the same level might not be considered. To get over this problem, we used the approach proposed in [3], which is based on a Weighted-BFS algorithm.
Thus, the edges’ weight are based on the link’s frequency,
which we define as the number of times that a link has been
used in a period of time. Hence, the frequency of every
link is used to select the node that provides more traffic to a
node from all the possible parent nodes in the same level of
the data traversal. This hierarchy provides an overview of
the whole webgraph, locating every page at the minimum
distance of the root node which is, by default, the home
page of the site. Moreover, the width and transparency of
links have been set according to its frequency. This visual
mapping allows to easily identify unused links and helps on
emphasising most used ones.

3.3

Usage Tree

3.4

In previous sections we have defined how structural hierarchies may be extracted from a webgraph. Hereafter we
introduce a new approach for generating hierarchical structures from websites called “Usage Tree”. We first define

Sessions graph

Up to now, we have presented ways of visualising a webgraph by representing hierarchical abstractions based on the

623
629

(a) A graph representing a website

(b) Hierarchical tree from the BFS algorithm

(c) Hierarchical tree from the W-BFS algorithm

(d) Hierarchical tree from the BM algorithm

Figure 2. An example of the visual abstractions generated by the different hierarchical approaches
from a Webgraph

website
A
B
C
D
E

#nodes
143
366
374
957
2812

#links
565
21865
11767
4898
51807

Total LML
140
91
291
287
2017

BFS
X
σ
86% 10%
57% 5%
42% 3%
61% 1%
48% 1%

W-BFS
X
σ
90% 12%
60% 5%
42% 3%
65% 1%
68% 3%

MB
X
σ
98% 0%
97% .4%
68% .2%
87% .1%
86% .1%

Table 1. Average percentage of maximum links found by each algorithm
website structure and links usage. However, users’ navigational patterns are more complicated than just a tree. Therefore, we have developed a visualisation dedicated to the representation of detailed sessions based on the focus of interest of the Web analyst. That is, WET allows the analyst to
fix any node as root of any of the available hierarchies, modifying the focus of interest of the visualisations. After this
action is performed, the system queries a database where

users sessions have been previously stored, collecting all
the sessions that have started in that node. Such sessions are
depicted using a Force Directed Layout that can be seen in
the bottom right image of Figure 3. In this case, edge width
and transparency have been used for representing the sessions frequency, which corresponds to the number of users
that started navigating at the focus node, and passed through
every node in the visualisation.

624
630

esting links that may be hidden by default. To overcome
this problem, WET enables the analysts to toggle between
showing just the links on the hierarchy, or visualising them
all. As this approach may produce highly cluttered visualisations, a dynamic filtering system allows the analyst to
select the usage thresholds that will filter non-desired links.
Figure 4 shows how the visualisation helps on finding interesting links, by first depicting all the links within the site
(Figure 4(a)), and then filtering system which them according to predefined usage thresholds (Figure 4(b)).
Moreover, the system enables the visualisation of existing broken links (HTTP error 404) in the site. While discovering such links is a common feature of many website analysis tools, none of them reports these links in a visual way.
Our approach allows analysts to be conscious of their existence by making all of them visible in the website structure,
enabling the discovery of where are they located as well as
understanding how many users have used them.
WET has also been provided with a highlighting system that enables the highlighting across the different visual
metaphors. Hence, any interaction with a metaphor may
also be reflected in any of the available visualisations.

Figure 3. WET user interface example that
highlights the same subgraph across visualisations. Glyph’s colour shows similar content pages and glyphs’ size represents visits
per page.

4

Personalising the Visualisations

Once we have already introduced the visualisations
available in our system, we introduce now its exploratory
capabilities, which enable the interaction with the representations in order to assist analysts in the acquisition of knowledge.
One of these exploratory techniques is the usage of the
visualisations as a background context where to map information regarding Web metrics, such as number of visits
per page, page rank or entry points. Accordingly, the system enables the analyst to dynamically decide which visual
attribute should be used for representing a desired metric.
Hence, the system smoothly changes all the available visualisations corresponding to user’s selection. Due to this
interaction, analysts may explore several metrics within a
context that might help them to get a better understanding
of the data.
On the other hand, the usage of bookmarks and search
engines has decentralised the entry points of a website. In
that sense, understanding where do the users enter to a website is a crucial information. While WET allows the discovery of these pages by using its built-in mapping system, it
also allows the analyst to change the focus of interest by
placing any node to the centre of the visualisation. By performing this action, the system recalculates all the visualisations, creating new perspectives on how the site is structured
around the new root (ideally, a landing page), and how the
users navigate from it. To accomplish that and to help on
preserving the analysts’ mental map, we used an animation
that shows the change of the layout [15].
Although the provided visualisations generate different
perspectives of a website, there are still potentially inter-

(a) All the links of a website

(b) Radial Tree with most relevant links after applying a filter

Figure 4. The filtering system allows to identify the most used links (right) from the cluttered visualisation of the whole Webgraph

625
631

5

Conclusions

References
[1] R. A. Botafogo, E. Rivlin, and B. Shneiderman. Structural
analysis of hypertexts: identifying hierarchies and useful
metrics. ACM Trans. Inf. Syst., 10(2):142–180, 1992.
[2] J. Chen, T. Zheng, W. Thorne, D. Huntley, O. R. Zayane,
and R. Goebel. Visualizing web navigation data with polygon graphs. In IV ’07: Proceedings of the 11th International Conference Information Visualization, pages 232–
237. IEEE Computer Society, 2007.
[3] J. Chen, T. Zheng, W. Thorne, O. R. Zaiane, and R. Goebel.
Visual data mining of web navigational data. In IV ’07:
Proceedings of the 11th International Conference Information Visualization, pages 649–656. IEEE Computer Society,
2007.
[4] E. Chi, P. Pirolli, and J. Pitkow. The scent of a site: a system for analyzing and predicting information scent, usage,
and usability of a web site. In CHI ’00: Proceedings of
the SIGCHI conference on Human factors in computing systems, pages 161–168. ACM, 2000.
[5] E. H. Chi. Improving web usability through visualization.
IEEE Internet Computing, 6(2):64–71, 2002.
[6] E. H. Chi, J. Pitkow, J. Mackinlay, P. Pirolli, R. Gossweiler,
and S. K. Card. Visualizing the evolution of web ecologies. In CHI ’98: Proceedings of the SIGCHI conference on
Human factors in computing systems, pages 400–407. ACM
Press/Addison-Wesley Publishing Co., 1998.
[7] J. Cugini and J. Scholtz. Visvip: 3d visualization of paths
through web sites. In DEXA ’99: Proceedings of the 10th
International Workshop on Database & Expert Systems Applications, page 259. IEEE Computer Society, 1999.
[8] J. Edmonds. Optimum Branchings. J. Res. Nat. Bur. Standards, 1967.
[9] S. G. Eick. Visualizing online activity. Communications.
ACM, 44(8):45–50, 2001.
[10] J. I. Hong and J. A. Landay. Webquilt: a framework for
capturing and visualizing the web experience. In WWW ’01:
Proceedings of the 10th international conference on World
Wide Web, pages 717–724. ACM, 2001.
[11] T. A. Keahey and S. G. Eick. Visual path analysis. In Proceedings of the IEEE Symposium on Information Visualization (InfoVis’02), page 165. IEEE Computer Society, 2002.
[12] V. Pascual and J. C. Dursteler. Wet: a prototype of an exploratory search system for web mining to assess usability.
In IV ’07: Proceedings of the 11th International Conference
Information Visualization, pages 211–215. IEEE Computer
Society, 2007.
[13] V. Pascual-Cid. An information visualisation system for the
understanding of web data. In IEEE Symposium on Visual
Analytics Science and Technology, 2008. VAST ’08, pages
183–184, Oct. 2008.
[14] J. E. Pitkow and K. A. Bharat. Webviz: A tool for worldwide web access log analysis. In Proceedings of the 1st International WWW Conference, pages 271–277, 1994.
[15] K. Yee, D. Fisher, R. Dhamija, and M. Hearst. Animated exploration of dynamic graphs with radial layout. In Proceedings of the IEEE Symposium on Information Visualization
2001 (Infovis’01), page 43. IEEE Computer Society, 2001.

The huge amount of data that Web analysts have to
deal with, floods them to the point that they are currently
demanding more visual and explorative systems to get a
deeper insight on their data. To understand better the situation, we interviewed a set of experienced Web analysts
that exposed how do they handle one of the big problems on
the Web Analytics community: the understanding of users’
behaviour on a website. While the visualisation of predefined users’ path seems to be already solved with the usage
of visualisations such as Funnel charts, it is still fairly complicated to get an overall flavour on how the users behave
within a website. This could be one of the reasons why experienced Web analysts still feel that they are not able to get
most out of their website data.
In this paper we introduce a set of techniques integrated
in a highly interactive and exploratory tool that allows
drilling down through Web data. The tool, an improved
version of WET, provides a set of combined visual abstractions that can be visually customised as well as recomputed
by changing the focus of interest. WET also provides two
Radial Trees laid out according to different algorithms that
extract meaningful hierarchies from the whole Webgraph.
While the approach of using a Breadth First Search algorithm has been already used for extracting an approximation
of the website structure, we present a novel approach based
on the usage of a maximum branching algorithm which generates a hierarchy based on the users’ behaviour. An experiment based on five websites rooted randomly at a hundred of different nodes showed that this algorithm generates
hierarchies that presents a higher amount of relevant links
than the Breadth First Search approximations, which represent the current state of the art. Furthermore, the system
also contemplates the visualisation of users’ sessions using
a Force Directed Graph.
Our work can be extended to consider different states in
the Web site by defining a set of pages that logically are the
same state, for example browsing a catalog, buying an item
or contacting the company. This allows to make the interpretation easier and diminishes the number of links. Future
work must consider the extensive evaluation of the tool to
validate our approach. Moreover, WET has a built-in logging system that stores information regarding analysts actions. The further investigation of such data may provide
valuable information on how the analysts behave while using our system.

Acknowledgements
This work is partially supported by the Grant TIN200615536-C02-01 of the Ministry of Science and Innovation of
Spain

626
632

