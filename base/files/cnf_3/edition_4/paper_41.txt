12th International Conference Information Visualisation

Visual Analytics for the Detection of Anomalous Maritime Behavior
Maria Riveiro, G¨oran Falkman, Tom Ziemke
School of Humanities and Informatics, University of Sk¨ovde, Sweden
{maria.riveiro, goran.falkman, tom.ziemke}@his.se
Abstract

sual analytics is defined as analytical reasoning supported
by highly interactive visual interfaces [22]. Contributions
in this area integrate information visualization, interaction
and computational analysis in order to transform massive
data into knowledge. Several tools/applications that offer a
diverse number of data mining and visualization functionalities have been developed to support the various steps or
the entire knowledge discovery process. An example of the
latter is VidaMine [14], an overall framework that supports
planning, data preprocessing, data integration, evaluation
and presentation.

The surveillance of large sea areas often generates huge
amounts of multidimensional data. Exploring, analyzing
and finding anomalous behavior within this data is a complex task. Confident decisions upon the abnormality of a
particular vessel behavior require a certain level of situation awareness that may be difficult to achieve when the operator is overloaded by the available information. Based
on a visual analytics process model, we present a novel
system that supports the acquisition of situation awareness
and the involvement of the user in the anomaly detection
process using two layers of interactive visualizations. The
system uses an interactive data mining module that supports the insertion of the user’s knowledge and experience
in the creation, validation and continuous update of the
normal model of the environment.

Human informed decision-making can be seen as a
complex information processing task. According to Endsley [6], certain level of situation awareness (SA) must be
reached in order to make a complex decision. Endsley defines SA as the perception of the elements in the environment within a volume of time and space, the comprehension
of their meaning and the projection of their status in the
near future. First, attributes and dynamics of the elements
in the environment are perceived, then multiple pieces of
information are integrated and their relevance to the decision maker’s goals is determined and at the projection
level, future events are predicted. When a decision-maker
faces a complex problem a mental model of the environment is built. In this process, humans seek for information
that can help them to understand the situation. Key elements in the construction of the operator’s environmental
mental model are the adequate presentation of the data and
the availability of methods that allow interaction with the
information. Past research has investigated the role of information presentation on decision-making. Cognitive fit
theory [23] can be used as a theoretical framework for analyzing how the presentation of information affects decision making. Cognitive fit theory states that decision making is improved when the representation of the information
matches the problem solving task, since decision makers
develop a more accurate mental model of the problem.

Keywords— anomaly detection, interaction, visualization,
visual analytics, situation awareness, surveillance.

1

Introduction

Vigilance and surveillance systems are commonly complex in function and structure since they process huge
quantities of heterogeneous data from multiple sources,
such as radars, cameras, automatic identification systems,
etc. Monitoring this kind of systems is a challenging activity for humans. The reasons are diverse: the amount of information, the high number of variables involved as well as
the opacity and complexity of the data mining techniques
used in the detection process. Other important factors to
consider are, for example, time pressure during the decision making process, high stress, inconsistencies and the
imperfect and uncertain nature of the information handled.
Data mining techniques can filter and extract valuable
patterns among this data. Information visualization methods can be of great value as well, when large data sets must
be analyzed by humans. The integration of data mining and
information visualization techniques has received a lot of
attention in recent years. Nevertheless, visualization has
been mainly used to provide better understanding of the final results. The need to tightly include the human in the
exploration process is now recognized by several authors
(e.g. [3, 12, 20]). As a new emergent research area, vi-

1550-6037/08 $25.00 © 2008 IEEE
DOI 10.1109/IV.2008.25

The main contribution of this paper is a novel system
that supports the user in the detection of anomalous behavior in maritime traffic. Based on the visual analytics
process model [13], we have designed a prototype system
that interactively integrates data preprocessing, data min-

273

ing and visualization techniques in order to support the acquisition of SA that guides the decision making process.
The interactive data mining module filters out anomalous
vessels by building a model of normal behavior. Events
that are classified as anomalies can be flagged as alerts
for a human operator who continuously validates, updates
and refines the normal model by interacting with the visual
representations of partial results of the detection process.
Thus, the detection procedure becomes transparent to the
users, which may increase their confidence and trust in the
system.

2

where a final representation of the normal/abnormal space
is presented using SOM (however, this approach does not
include any interaction).

3

Visual analytics process model

Figure 1 illustrates a formalization of the visual analytics process by Keim et al. [13] and its correspondence
with the architecture of the system suggested here. The
“data pre-processing ” step includes cleaning, transformation and integration of data functions (DW ). After the
pre-processing step, visualization methods and automated
analysis methods are applied to the data. The “hypothesis
generation” step creates a model of the normal behavior
from observations recorded during a period of time (training data). Once the model is complete, real time observations (test data) are processed in order to detect abnormal
behavior. For that, the cumulated probability value of the
observed data is calculated and compared to the threshold
level. If the probability value is higher than the threshold,
the operator is notified (hypothesis: anomalous behavior).
The user now has to acknowledge the anomaly, modify the
model if it is a false alarm or look for more information if
he/she cannot make a confident decision.

Related work

Few descriptions of maritime anomaly detection systems can be found in the literature. The majority of them
present a fully automatic approach to anomaly detection
problem, where the user is mainly considered as a consumer of information (e.g., the work presented in [16] and
[2]). Examples of methodologies for anomaly detection
that include human expert knowledge to any extent are
rare. An exception is the work presented in [11], where
a solution based on Bayesian networks incorporates input
from the user to build the normal model in the training
phase. However, despite the initial phase, no further input from the user is proposed for updating or validating the
results.

Data visualizations

UV

2.1 Anomaly detection algorithms
Anomalies are defined as deviations from normality.
Detecting these deviations can be seen as a classification
problem [9]: given a set of observations, they must be
classified as normal or abnormal. Nevertheless, conventional classification algorithms cannot be used in real world
problems. The main reason is that commonly, only normal
samples are available in the training phase, and both normal and abnormal samples are required when conventional
classifiers are used. Moreover, the set of anomalies can be
infinite since we can encounter unknown anomalies. There
are many approaches to anomaly detection in the literature
(most of them in the network security area). The majority
of them build a model of the normal behavior in an unsupervised manner (e.g. [5]). Solutions based on artificial
immune systems have been also applied in intrusion detection in network systems. An example of the latter is
the methodology presented in [9] where fuzzy characterizations of normal/abnormal spaces are used in the detection process.

VS

DW

UCV

V

Support for situation
awareness and
decision-making

Sensor data

Input

S
Data preprocessing

UInput

HV
HS

VH
H

I

UCH
UH

Hypothesis generation

Figure 1: Visual analytics process (adapted from [13] with
minor changes). The source S represents the dataset and I
accounts for the goal of the process, insight. Insight is obtained from the set of created visualizations V or through
confirmation of the hypothesis H. DW includes data preprocessing functions (W ∈ (T transformation, C cleaning,
SL selection, I integration)), U represents user interactions (UCV , UCH : insight concluded by visualization or
hypothesis) and V symbolizes the visualization functions.
We have added Uinput that depicts interaction over the data
gathering process (e.g. selection of sources).

2.2 Anomaly visualization
Most of the published work regarding anomaly visualization is restricted to the computer security area. Examples of this kind are [17], using 3D displays, [19] regarding network traffic visualization or techniques for visualizing security log-files [21]. Another approach, using Self
Organizing Maps (SOM), is the work introduced in [8],

We use two layers of visual representations in the
anomaly detection process: (1) general views, V , VS and

274

UV (list of alerts, geographical map, configurable views–
different attributes vs time or space, detailed information,
etc.) and (2) interactive displays that allow direct manipulation with the data mining module that generates the hypothesis over the data, H, HS and UH . The set of interactive visual representations support the user in the knowledge discovery process and in the insertion of the user’s
experience and knowledge in the system.
The purpose of the suggested methodology is to support the acquisition of SA through interactive visualization, from the extraction of the environmental information
and its integration with previous knowledge to create a coherent mental picture, to the prediction or anticipation of
future events. Furthermore, the interaction capabilities engage the user in the detection process, turning it into a more
transparent process that may increase the user’s trust in the
system. In the following sections we describe in detail the
“data pre-processing”, “data visualizations” and “hypothesis generation” steps of the analytical model.

adding an interactive module that allows continuous refinement of the calculated model and development of a “special event” model by the user. This method was selected
over other approaches since it generates a visual representation of the normal space that can be used as an interactive
basis for refining the model. The graphical representation
of the model of the environment facilitates the understanding of the model itself, since peaks and valleys are quickly
identified as normal and abnormal behavior (see figure 3).
Essentially, the detector builds a normal behavioral
model using a clustering algorithm, the SOM, over the
training data set. The SOM learns what is normal via iteration over the training data. In order to quantify probabilities of normal and anomalous behaviors, the detector uses
a GMM coupled with the use of Bayes’ theorem. Once the
model of the normal behavior is established, the detector
can be used on the test data (which represent real world
observations – sensor readings of vessel movement). For
each new observation, P (observationvesselID ) is calculated. A sliding window over the m most recent observations is used to calculate an average probability value. If
the probability value is higher than a given threshold, the
detector will flag the vessel as anomalous (hypothesis).

3.1 Data pre-processing (S, DW )
The data has been provided by Saab Microwave Systems and it has been generated using the ground target
simulator GTSIM described in [24] (a doppler radar over
a large coverage area is simulated to obtained the sensor
readings). The training data does not include any anomalies since we need to create a normal model of the environment. Our method and application will be tested over the
test data, that has hidden anomalies.
The original data consists of sensor readings of approx. 500 vessels. Each reading contains six attributes:
time stamp, object-ID (object identification number), object type (fishing boat, cargo, etc.) and position (given by
x-, y- and z-coordinates using the Swedish grid, RT90).
The number of readings per vessel varies from 2000 to
4000. There are some measurement errors associated with
the vessels positions. The training data set has been preprocessed by calculating two additional attributes (speed
and heading) and by cutting out a region of interest, in
this case a region south of Sweden. The final attributes
are: time stamp, vessel type, x-coordinate, y-coordinate, zcoordinate, speed and heading (the z-coordinate is not used
in the anomaly detection process, but it is used to adjust the
height in the representations). There are three types of vessels: F (‘Fartyg’, vessel), FF (‘Fiskefartyg’, fishing boat)
and HF (‘Handelsfartyg’, cargo ship).

3.2.1

SOM, GMM and the Bayes’ theorem

A SOM can be seen as a clustering algorithm based on a
neural network [15]. It takes a set of n-dimensional training data as input and clusters it into a smaller set of ndimensional nodes, also known as model vectors. These
model vectors tend to move towards regions with a high
training data density, and the final nodes are found by minimizing the distance of the training data from the model
vectors. The SOM creates a 2D map from n-dimensional
input data. In the map, it is usually possible to identify borders that define different clusters. These clusters consist of
input data with similar characteristics, in our case, vessels
with similar behavior. The output from the SOM is useful
for classification, and can be used for portraying a compressed representation of a “normal picture” (see an example in figure 2). However, it does not provide a complete
solution to the anomaly detection problem since there are
many events that do not clearly fall into these well-defined
clusters. Therefore, a GMM has been used on top of the
SOM.
A GMM is a statistical model in which the overall probability distribution, P (x1 , ..., xn ), is synthesized from a weighted sum of individual Gaussian distributions (where the sum always is vaguer than the
individual distributions themselves): P (x1 , ..., xn ) =
D
D
i=1
j=1 pij Pij (x1 , ..., xn ). The individual distributions, Pij , in this case correspond to the model vectors that
were the output from the SOM. Each model vector is char-

3.2 Hypothesis generation (H)
One of the main challenges we have faced is the selection of a data mining technique/s that support interaction.
The approach selected to build the normal/special behavior
model is based on the work presented in [16] (a Gaussian
Mixture Model (GMM) over a SOM of the training data
is used for that). We have extended here their proposal,

275

U-matrix

Heading

Speed
1.0

10

266

0.5

6.37

176

0

2.72

85.6

vation /5 s). If the probability value is higher than a given
threshold, the detector will flag the vessel as anomalous
and alert the operator. If the user considers that it constitutes a real threat and it is representative of abnormal
behavior, the observed data will be part of the “special
events” database. The “special events” database contains
any behavior that the user would like to be alerted of in
the future (that includes not only abnormal behavior but
also any rare, suspicious or unknown events). However, if
the user considers that the flagged vessel exhibits a normal
behavior, the normal model must be updated in order to
prevent that this false alarm occurs in the future. The user
then interacts with the graphical representation of the mixing proportions of the SOM (see figure 3) or introduce the
probability values of the event (from very probable to not
probable at all). In the latter, the observations are added to
the training data and its weight values are updated regarding the probability value that the operator has introduced.
Thereby, the model of normal behavior is built and updated
by the user.

Figure 2: SOM for the HF (cargo ship) vessels. The maps
have rectangular structure and the dimensions of the grid
are 60 by 60 (D). The first map corresponds to the unified
distance matrix (U-matrix) and then the component planes
for the features speed and heading. The U-matrix visualizes distances between neighboring map units, and thus
shows the cluster structure of the map: high values of the
U-matrix indicate a cluster border, uniform areas of low
values (blue) indicate the clusters themselves. The component planes show clusters of data with similar values (a
color identifies a cluster).
acterized by a n-dimensional Gaussian probability density
function. The mean of each individual probability density
function is given by the final weights for the model vector,
while the variance is given by the dispersion of training
data around the model vector.
When new observations arrive, the GMM can be
used to quantify the likelihood P (d|H = normal) for
obtaining the observation d given the learned model of
what is to be considered as a normal event (H is the
hypothesis). However, the quantity we want to calculate is
the probability of an anomalous event, given the observed
data, P (H = anomalous|d) (in order to do that we
can just take the complement 1 − P (H = normal|d)).
To calculate P (H = normal|d) from the likelihood
we have to use Bayes’ theorem: P (H = normal|d) =
P (d|H = normal)P (H = normal)/ h∈H P (d|h)P (h)
where h refers to the hypothesis: being normal or not. The
prior probability, P (H = normal) adjusts the detection
threshold and can be fine-tuned by the human operator
in order to get an acceptable ratio between the detection
rate and the false positive rate. Otherwise, it reflects
the expected relative frequency between the number of
normal observations and the total number of observations.
h∈H P (d|h)P (h) can be seen as a normalization
constant. In order to calculate this normalization constant
we need to know the quantity P (d|H = anomalous),
which is not known since we have not built such a model.
Hence, we conclude: P (H = normal|d) ∝ P (d|H =
normal)P (H = normal).
3.2.2

Mixing proportions pij

0.04

Probability, pij

0.03

0.02
0.026519

0.01

6
5

0
6

4
5

3

4
3

2
2

Neuron coordinate y

1

1

Neuron coordinate x

Figure 3: Mixing proportions pij . Peaks and valleys are
quickly identified as normal/abnormal behavior. Users can
drag/modify the probability values if they consider them
unrealistic. If one probability value is modified, the others are recalculated. This graphical representation provides
support for interaction and continuous refinement of the
normal model.

4

Data visualizations (V, VS , UV )

Data visualization functions include representations of
the pre-processed data, like vessel tracks over the geographical map, individual vessel information regarding different attributes or combinations of them (e.g.
speed/heading vs. time/position). Parallel coordinates
views and views of the continual evolution of the model
vectors for a given vessel are also available.

Interacting with the normal model (UH )

An average probability value is calculated continuously
over the m most recent observations (data rate: 1 obser-

276

Figure 4: System design: geographical map, vessels and alarms list (top left); controls for the main map, the different
views panel and the detector module (top right); different data visualizations display (bottom left); SOM data clusters and
interactive normal model display (bottom right).

5

System design and description

of the alert, etc. is shown) and system SA (the operator
can control the underlying data mining algorithm used to
determine the possible anomalies).
The graphical interface has been divided into four main
panes or modules: geographical map (top left), controls
(top right side: filter module, vessel module and detection
module ), alarms list and detailed information display (bottom left) and normal model display (bottom right).
There is a basic task that the operator constantly carries out: establishing and update the normal picture or situation of the supervised zone. Thus, the vessels are displayed over a background map of the area. Over the normal
situation, abnormal behavior must be identified. Therefore, both background awareness (keeping the “big picture”) and foreground awareness (particular details) must
be supported. Filtering options are grouped under the filter
pane. The operator can filter the displayed vessels regarding multiple features. When a vessel is flagged as anomalous, a card with its information appears in the alert list
(detailed information of the vessel can be obtained pressing its button). References to time are very important for
the operators [18]. Therefore, we include reference points,
such as how long a vessel has been in a certain area, history
of the vessel, how old a certain alarm is and when it was
reported, etc.

The system’s design (see figure 4) has been conceived to
provide an effective visualization of time dependent maritime traffic data and to support the identification of anomalous vessel behavior. The graphical user interface is designed to suit analytical requirements and to allow an intuitive control of the data mining module that creates the
normal model of the environment. The current system design is based on the requirements specified by experts from
Saab Microwave Systems (Gothenburg, Sweden), a literature study on the implications of SA on system design (see
[4], [10], [6], [7], [1]) and user field studies conducted recently in a marine surveillance control center in Malm¨o,
Sweden, by members of our research group (part of the
study can be read in [18]). Endsley’s studies on SA (e.g.
[6]) conclude that different elements must be supported:
geographical SA, temporal SA, system SA, environmental SA and tactical SA. The first three elements rely highly
on the capabilities and functionality of the system used to
perform certain tasks. Therefore, the system presented in
this paper has been developed to support the acquisition
of: geographical SA (geographical information, vessels,
tracks and possible anomalous vessels are presented), temporal SA (information regarding history of the vessel, age

277

insertion of the user’s knowledge and experience in the
creation, validation and continuous update of the environment’s normal model. Although the application has been
designed for maritime anomaly detection in particular, it
has much wider application in general (e.g network intrusion detection).
Possible improvements to the current version of the system involve the incorporation of relational information (relations with other vessels or other objects in the environment) and the control of the false alarm rate that may lead
to a reduced usage of the tool.
The usability of the system has been demonstrated, to
some degree, on synthetic maritime data. User studies will
be undertaken in the future and their results will probably
adjust the system design and functionality. The literature
offers a variety of visualization evaluation methods, such
as controlled experiments, longitudinal studies, usability
tests or analytical methods, like cognitive walk troughs.
From our point of view, the evaluation of visual analytical tools is a complex problem, engaging many challenges
that should not be underestimated. The ultimate purpose of
the system presented in this paper is supporting the acquisition of SA that will allow more effective identification of
anomalous vessel behavior. Therefore, one important aspect we need to evaluate is to which extent the acquisition
of SA is supported (methods like SAGAT, Situation Awareness Global Assessment Technique, can be used here) and
how it influences the decision-making process.

The control of the data mining module is done in the
detection process pane. The period of time of the training data can be also chosen. The operator can select the
type of vessel, the features involved in the detection process, the values of the learning rate (SOM), sliding window
number of samples (m) and threshold value. Under this
tab, the operator can control the construction of the environment’s normal model, manipulating the mixing proportions display (figure 3). Cumulative probability values and
the threshold value are displayed over time (the operator
can adjust the threshold value in real time, thus controlling
the false alarm rate).

6

Preliminary results

For testing our approach, anomalies were hidden in the
synthetic test data by Saab Microwave Systems. Three different types of anomalies were found using our application: (1) one of the vessels had abnormal speed values,
compared to the training data (2) an HF vessel had a behavior typical of a fishing boat and (3) an HF vessel approached the coast (this behavior has not been seen before
in the analyzed area, here, the heading values were not considered normal). Nevertheless, in order to detect the vessel
approaching the coast line, the threshold value must be reduced considerably, which generates high number of false
positives.
In conclusion, preliminary results show that the system produces satisfactory outcomes, since single attribute
anomalies can be detected. However, the experiments carried out evaluate the performance of the system regarding
the detection of anomalies, but no user tests have been performed so far with domain experts. User evaluations will
be carried out in the future.

7

Acknowledgements
This work was supported by the Information Fusion Research Program (University of Sk¨ovde, Sweden) in partnership with the Swedish Knowledge Foundation and carried out in collaboration with Saab Microwave Systems
(Gothenburg, Sweden). We would like to thank Thomas
Kronhamn, Martin Smedberg and H˚akan Warston for providing the data and for their valuable feedback.

Final remarks and future work

Security and surveillance systems monitoring large sea
areas process and integrate vast amounts of sensor readings
from a large number of objects with different characteristics and behaviors. Analyzing and finding relevant patterns
and special events in them is normally a difficult task, that
can rarely be solved in a fully automatic manner. Data mining methods that support user interaction are of great value
in these cases, since they integrate human knowledge and
automatic processing. Visual representations of the data reduce the cognitive work required to carry on certain tasks.
Thus, the integration of visualization, data mining and interaction methods offers new possibilities and capabilities.
Applying these basic ideas, this paper has presented a
system for the analysis of maritime traffic based on the visual analytics process model [13] (to the best of our knowledge, visual analytical tools have not been used in this domain). The system includes a set of interactive visual representations that support the analysis of the data and the

References
[1] M. J. Barnes. The human dimension of battlespace
visualization: Research and design issues. Technical Report ARL-TR-2885, Army Research Laboratory, February 2003.
[2] N. Bomberger, B. Rhodes, M. Seibert, and A. Waxman. Associative learning of vessel motion patterns
for maritime situation awareness. In Proceedings of
the 9th International Conference on Information Fusion, July 2006.
[3] R. A. Burkhard, G. Andrienko, N. Andrienko,
J. Dykes, A. Koutamanis, W. Kienreich, R. Phaal,
A. Blackwell, M. Eppler, J. Huang, M. Meagher,
A. Gr¨un, S. Lang, D. Perrin, W. Weber, A.V. Moere,

278

[14] S. Kimani, S. Lodi, T. Catarci, G. Santucci, and
C. Sartori. VidaMine: a visual data mining environment. Journal of Visual Languages & Computing,
15(1):37–67, 2004.

B. Herr, K. B¨orner, J. D. Fekete, and D. Brodbeck.
Visualization summit 2007: ten research goals for
2010. Information Visualization, 6:169–188, 2007.
[4] M. Davenport and C. Risley. Information visualization: the state of the art for maritime domain awareness. Technical Report DRDC Atlantic CR 2006-122,
Defence R&D Canada - Atlantic, Dartmouth, Nova
Scotia, 2006.

[15] T. Kohonen. The Self-Organizing Map. Proceedings
of the IEEE, 78(9):1464–1480, 1990.
[16] J.B. Kraiman, S.L. Arouh, and M. L. Webb. Automated anomaly detection processor. In A. F. Sisti and
D. A. Trevisani, editors, Proceedings of SPIE: Enabling Technologies for Simulation Science VI, pages
128–137, Jul 2002.

[5] D. E. Denning. An intrusion-detection model. IEEE
Transactions on Software Engineering, 13(2):222–
232, 1987.
[6] M. R. Endsley. Toward a theory of situation awareness in dynamic systems. Human Factors Journal,
37(1):32–64, 1995.

[17] S. Musa and D. J. Parish. Visualising communication
network security attacks. In IV ’07: Proceedings of
the 11th International Conference Information Visualization, pages 17–22, Washington, DC, USA, 2007.
IEEE Computer Society.

[7] J. T. Freeman and M. S. Cohen. A critical decision
analysis of aspects of naval anti-air warfare. Technical Report 98-2, Cognitive Technologies, Inc., 9 June
1998.

[18] M. Nilsson, J. van Laere, T. Ziemke, and J. Edlund.
Extracting rules from expert operators to support situation awareness in maritime surveillance. To be published in 11th International Conference on Information Fusion, 2008.

[8] F. A. Gonz´alez, J. C. Galeano, D. A. Rojas,
and A. Veloza-Suan. Discriminating and visualizing anomalies using negative selection and selforganizing maps. In GECCO ’05: Proceedings of the
2005 conference on Genetic and evolutionary computation, pages 297–304, New York, NY, USA, 2005.
ACM.

[19] I. V. Onut and A. A. Ghorbani. A novel visualization
technique for network anomaly detection. In Proceedings of the Second Annual Conference on Privacy, Security and Trust, 2004.

[9] F. Gonz´alez, D. Dasgupta, and R. Kozma. Combining negative selection and classification techniques
for anomaly detection. In Congress on Evolutionary
Computation, pages 705–710. IEEE, 2002.

[20] B. Shneiderman. Inventing discovery tools: combining information visualization with data mining. Information Visualization, 1(1):5–12, 2002.
[21] S. T. Teoh, K. L. Ma, S. F. Wu, and T. J. JankunKelly. Detecting flaws and intruders with visual data
analysis. IEEE Computer Graphics and Applications,
24(5):27–35, 2004.

[10] D. Gouin, P. Evdokiou, and R. Vernik. A showcase of
visualization approaches for military decision makers. In RTO IST Workshop on Massive Military Data
Fusion and Visualisation: Users Talk with Developers, RTO-MP-105, Halden, Norway, 2002.

[22] J. J. Thomas and K. A. Cook, editors. Illuminating
the Path: The Research and Development Agenda
for Visual Analytics. IEEE Computer Society, Los
Alametos, CA, 2005.

[11] F. Johansson and G. Falkman. Detection of vessel
anomlies - a Bayesian network approach. In Proceedings of the 3rd International Conference on Intelligent Sensors, Sensor Networks and Information
Processing, 2007.

[23] I. Vessey. Cognitive fit: a theory-based analysis of
the graphs versus tables literature. Decision Sciences,
22:219–240, 1991.

[12] D. A. Keim. Information visualization and visual
data mining. IEEE Transactions on Visualization and
Computer Graphics, 7(1):1–8, 2002.

[24] H. Warston and H. Persson. Ground surveillance and
fusion of ground target sensor data in a network based
defense. In Proceedings of the 7th International Conference on Information Fusion, pages 1195–1201,
2004.

[13] D. A. Keim, F. Mansmann, J. Schneidewind,
J. Thomas, and H. Ziegler. Visual analytics: Scope
and challenges. Visual Data Mining: Theory, Techniques and Tools for Visual Analytics, Springer, 2008,
Lecture Notes In Computer Science (lncs), 2008.

279

