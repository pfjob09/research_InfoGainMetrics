12th International Conference Information Visualisation

Visually Summarising Software Change
Tom Arbuckle
University of Limerick
Limerick, Ireland
tom.arbuckle@ieee.org

Abstract

summaries. Our interest is in first impressions and in providing big pictures of changes meaningful to developers, researchers and managers. How can summarised changes in
structure, in behaviour or in the artefacts of the software
itself be compared and presented in a graphically useful
‘quick look’ way?
This paper, which provides an answer to that question, is
structured as follows. Sections providing a motivational example and an overview of alternative solutions are followed
by a section in which we describe a series of experiments
performed on an open-source application. For each experiment, we provide a summary illustration and provide an
analysis of the meaning of its results. Thereafter, we sketch
the information-theoretic basis for the illustrations and explain the procedure by which they were obtained. After a
brief section exploring the implications of these findings,
we outline future work and conclude.

Many authors have noted the problem of excessive information when attempting to create useful visualisations
of software. The problem of visualising change over multiple versions of software is more complex still. We present
a means of visualising changes in software, founded on
information-theoretic arguments, that easily and automatically summarises difference between software versions with
respect to their code, their structure or their behaviour.
Further, we show, by creating visualisations in experiments
on real-world data, that the method is of utility to practitioners and has implications beyond the field of software
visualisation.
Keywords: software evolution, visualisation of change,
Kolmogorov complexity, similarity metric, CompLearn.

2 Motivation: Example Scenario
1 Introduction
Suppose an engineer has been set the task of evaluating
a series of releases of software with which he or she is completely unfamiliar with a view to beginning maintenance activities. If a complete set of documentation exists, the engineer will be very lucky but will still have to pick through
the documentation to find the changes. If, as is often the
case, the documentation is patchy or non-existent, the only
course of action is some form of reverse engineering activity. The engineer needs to find out about both the general
structure of the code and its detailed design; to discover as
many flaws or defects as possible in preliminary testing or
review; to locate where major changes were introduced; and
to record these findings before creating suites of regression
tests (if none yet exist) or introducing changes. What can
the engineer do to expedite progress?
In the case of single versions of the code, reverse engineering and re-engineering patterns such as “Read all the
code in one hour” [10] can certainly contribute. Moreover,
there is a plethora of tools that allow the interactive exploration of source code [39, 38, 27, 21]. In the case of multiple

Software is difficult to visualise: it is both complex and
detailed, has multiple levels of structure and both static and
dynamic aspects need to be examined for a detailed understanding of its operation. When we come to consider software evolution, or, alternatively, the comparison of different
versions or releases of software, the problems are further
compounded by the chronological nature of the evolution
— or simply by the quantities of data for comparison.
Successful approaches to visualising software have accounted for software’s inherent properties by mirroring
them. Means of presenting data only when needed and in
the right quantities have been formulated and several implementations of useful tools for the exploration of software
structure have been documented in the literature.
The approach taken in this paper, however, is one of (theoretically based) summarization and of the comparison of
Diagrams in this paper employ colour: obtaining an electronic or
colour-printed version will aid comprehension.

1550-6037/08 $25.00 © 2008 IEEE
DOI 10.1109/IV.2008.58

559

"plot_bins_blocksort.data" matrix
1
0.8
0.6
0.4
0.2
0

1

3.1

2.6

0.8
2.4

0.6

2.2
3.1

2.0

0.4

2.6
2.4

1.5

0.2

2.2
2.0

1.3

1.5
1.3
1.1
1.1

1.3

1.5

2.0

2.2

2.4

2.6

3.1

0

1.1

1.1

1.3

1.5

2.0

2.2

2.4

2.6

3.1

Figure 1. Comparison of 16 binary versions of slocate

releases of the same software, there are some research tools
such as Seesoft [12], Gase [16] and EvoTrace [14] that allow visualisations of software versions in terms of change
log visualisations, comparisons of change history, semantic
similarities or clustering of similar entities. However, they
offer quite a lot of information in terms of disparate views
of the software.
What happens if the engineer just wants a quick summary of several different aspects of the software artefacts
in order to allow them to know where to most productively
start work? How can they obtain, programmatically, a visualisation of summarised software change?
Would a diagram like figure 1 help? This diagram shows
(in both 3D and 2D) plots of a distance matrix in which
each of sixteen releases of (in this case, the executables for)
a software package are compared with each other. The pairwise degree of similarity between versions is found quickly,
automatically, and in a parameter free way. The distance
matrix plots are symmetric, a central ridge, value 1.0 denoting identicality. The similarity between the first and the
last versions is shown to be least (graphed numeric result
tending towards 0.0).
It is most convenient to think of the plots either in terms
of columns or rows. Reading from a point on this ridge
either up (a column) or (along a row) to the right corresponds to a comparison of that (reference) release with later
releases. A flat area (in a row or a column) shows that the
elements at that point are equally dissimilar to the reference,

not that they are necessarily similar to each other. Descriptions of how the experimental data are derived, common
analysis of multiple experiments, and the theoretical background are given in sections 4, 6 and 5 respectively.

3 Visualisation of Software Change
What are the problems associated with the visualisation
of software change and what can be done to ameliorate
them? The main problem is that there is a surfeit of information and that a means needs to be found of reducing the
cognitive load to make it easier (or possible) for the viewers to extract understanding from pictorial representations
of the change data. We survey the literature.

3.1

Why and how to visualise

Sillito et al. [36] describe the tasks that a programmer
must perform when making changes to software. Developers need to explore the code base to build an understanding
of the software to be modified: gaining a sufficiently broad
understanding is difficult. Apart from the cognitive overload, there is the problem of finding focus points, or landmarks by which to navigate, during the building of the modification. Effective visualisations provide one tool in alleviating these problems. What makes a good visualisation is
discussed by Amar and Stasko [2] who introduce the notion

560

of analytic gaps, “obstacles faced by visualisations in facilitating higher level tasks”. Erbacher [13] outlines an iterative
process by which effective visualisations can be designed
and Hungerford et al. [17] discuss how visualisations can
be critically reviewed. Kienle and M¨uller [19], on the other
hand, study the requirements for visualisation tools. They
identify seven quality attributes that they recommend for effective visualisation systems. Finally, Reiss [32] points out
that, despite decades of research and the intuitive utility of
visualisation to the problems at hand, very few visualisations have had much impact in commonly available development environments.

3.2

academic approaches to exploiting visualisation for a
wide variety of purposes.
• Despite general agreement concerning its utility, there
seems to be limited use of visualisation techniques in
the professional development arena.
• Several approaches exist to pairwise compare software
releases. In particular, several diff -like tools exist such
as JDiff, UMLDiff, SiDiff and DiffArchVis which will
provide details concerning the difference between versions.
• There does not seem to be a generic context-free way
to compare software artefacts quickly to get a single
measure of their degree of similarity.

Software Visualisation

In section 2, we mentioned Rigi [39], SHriMP/Creole
[38, 27] and CodeCrawler [21] as tools providing visualisations of software systems. Many others can be found in
the literature. For example, Li et al. [24] discuss how to display software architectures with constant visual complexity.
Ducasse et al. [11] employ polymetric views for looking at
the large quantities of run-time information. Reiss et al.
[33] review visualisations of run-time information.
We focus on tools and projects that are particularly concerned with visualising or measuring software evolution.
McNair et al. [28], Ratzinger et al. [31] and Voinea and
Telea [41] all discuss this topic. Sawant and Bali [35] describe a tool for the visualisation of differences in software
architecture whereas van Rysselberghe and Demeyer [34]
are concerned with software understanding via the visualisation of change history. Vasa et al. [40] study which elements of software projects change between releases with
the aid of the Bhattacharyya metric. Licata et al. [25] investigate how the signatures of program features change with
time by comparing pairs of versons of code taken from a
code versioning system. While Wu et al. [43] are interested in looking at how the rate of change varies to highlight conspicuous changes, Xie and Notkin [45] investigate
the change in value spectra with a view to employing this
information in regression testing. Xing and Stroulia [46]
employ the UMLDiff tool [47] for examining the evolution
of software design. Similar work has been carried out by
Wenzel et al. [42]. The paper by Apiwattanapong et al. [3]
is well known for its discussion of semantic differencing
and the JDiff tool. Fluri and Gall [15] investigate how a
classification of the types of changes being made can help
in discovering coupling between the items changed.

3.3

4 Experiments
In several experiments, we apply the same method to
gauge and visualise the similarity of a variety of software
artefacts. In each case, we also provide an analysis of the
results. The common method and procedure by which these
visualisations are obtained from the different forms of experimental data is explained in section 6.
All experiments are performed on the open-source software slocate [26], which is designed to catalogue and index
all files present in a specified area of a filesystem. slocate
has a long history with many publicly available releases. Its
code, which is short but performs fairly complex operations,
has also been redesigned on at least one occasion. This
makes the package an interesting candidate for our experiments. Source lengths in kilobytes for the slocate releases
we studied are shown in table 1.
Table 1. slocate releases and sizes (kilobytes)
Release. 1.0 1.1 1.2 1.3 1.4 1.5 1.6 2.0
Size
26.6 26.7 24.0 23.9 29.7 31.3 32.2 70.3
Release
2.1 2.2 2.3 2.4 2.5 2.6 2.7 3.1
Size
72.3 72.7 70.7 73.6 82.6 91.3 92.0 67.4

4.1

slocate : Sources, Binaries

In our initial trials of the method [4], we made a direct
examination of the source code as well as looking at indexing and search traces on a known set of data. These results
are recreated and revisualised in this section for comparison
with the new results.

Visualisation: Summary

The literature surveyed can be summarised as follows.

4.1.1 Experiments

• There is a broad literature on the visualisation of software engineering artefacts with many sophisticated

As a first step in our investigation of slocate, we see how
much information we can learn from the packages directly.

561

"plot_sources_blocksort.data" matrix
1
0.8
0.6
0.4
0.2
0

"plot_tars_blocksort.data" matrix
1
0.8
0.6
0.4
0.2
0

1

3.1

2.6

0.8
2.4

2.0

0.8
2.4

2.0

2.4

0.2

2.0

1.3
1.1
1.1

1.3

1.5

2.0

2.2

2.4

2.6

3.1

1.5

0.2

2.2

1.3

2.0

1.5

1.3

1.5

0

1.1

1.3
1.1

1.1

1.3

1.5

2.0

2.2

2.4

2.6

0.4

2.6

1.5

2.2

0.6

2.2
3.1

0.4

2.6
2.4

2.6

0.6

2.2
3.1

1

3.1

1.1

3.1

1.3

1.5

2.0

2.2

2.4

2.6

3.1

0

1.1

1.1

(a) slocate sources

1.3

1.5

2.0

2.2

2.4

2.6

3.1

(b) slocate tarred sources

Figure 2. Comparison of slocate code sources and tar distributions

"create_trace.data" matrix
1
0.8
0.6
0.4
0.2
0

"locate_trace.data" matrix
1
0.8
0.6
0.4
0.2
0

1

3.1

2.6

0.8
2.4

2.0

0.2

1.1
1.1

1.3

1.5

2.0

2.2

2.4

2.6

3.1

1.5

0.2

2.2
2.0

1.3

1.5

0

1.1

1.3
1.1

1.1

1.3

1.5

2.0

2.2

2.4

2.6

0.4

2.6

1.3

1.5
1.3

2.0

2.4

2.2

0.6

2.2

1.5

2.0

0.8
2.4

3.1

0.4

2.6
2.4

2.6

0.6

2.2
3.1

1

3.1

1.1

3.1

(a) slocate database creation

1.3

1.5

2.0

2.2

2.4

2.6

3.1

0

1.1

1.1

1.3

1.5

2.0

2.2

2.4

2.6

3.1

(b) slocate locate in database

Figure 3. Comparison of slocate execution traces: create and locate

In figure 1, we showed a comparison of the binary executables for each release. Figure 2(a) shows a comparison of
the sources (concatenated but unmodified ‘.h’ and ‘.c’ files)
with figure 2(b) showing an even simpler comparison of the
complete tar files as provided by the source distributions.
Figure 3(a), on the other hand, provides a comparison
of behaviour. It shows a comparison of the different versions of slocate during the indexing of a set of known data.
Likewise, figure 3(b) compares the behaviour of each of the
versions when performing the same search on the database
created in the indexing phase. The input data used to generate these diagrams were the unmodified system call traces
produced by monitoring the applications using the program
strace running under Linux.

series. It further shows a similarity between versions 2.0,
2.1 and 2.2. Versions after that show only similarity to their
neighbours indicating continuous development.
Figure 2(a) is most interesting for showing the clear
grouping of the sources (only) into their release classifications. Figure 2(b), on the other hand, shows that in the
second series of release tarballs 2.0 to 2.4 (makefile only)
differed from 2.5 to 2.7 (autoconf files, doc directory).
Now examine figures 3(a) and 3(b). The first of these
shows that a quite striking change in behaviour was introduced in version 1.6. Creation of the indexing database involved similar operations in versions 1.0 to 1.5 and in versions 1.6 to 2.7. The second figure, however, shows extreme
similarity between versions during location operations. The
first and the last version are the most different and there are
hints that versions 1.5 to 2.2 involved similar sequences of
system calls as did versions 2.3 to 2.7.

4.1.2 Analysis
In some situations, we might not have source code so the
comparison shown in figure 1 could be quite useful. It
clearly shows the similarity between members of the 1.x

562

303: instr
370: instr

309: instr
437: instr

353: instr

436: instr

387: instr
304: if
371: if

310: if
438: if

354: if

437: if

388: if
305: instr
372: instr

373: instr

311: instr
355: instr

306: instr

312: instr
439: instr

356: instr
389: instr

438: instr

390: instr

440: instr

439: instr

307: if
374: if

313: if
441: instr

357: if

440: instr

391: if
308: instr
375: instr

314: instr
442: if

358: instr

441: if

392: instr
309: instr
376: instr

315: instr
359: instr

366: break

322: break

336: break
443: instr

380: break

442: instr

393: instr
310: if
377: loop

316: loop
444: instr

360: loop

443: if

394: if
312: instr
378: instr

311: return

319: break

333: break

317: instr
445: if

361: instr
429: break

396: instr

407: break

444: if

395: return

313: loop
379: if

318: if
446: instr

362: if

447: if

445: instr

397: loop
314: instr
380: break

381: switch

320: switch
364: switch

319: break
448: if

363: break

446: instr

398: instr
315: if
394: instr

382: instr

386: instr

384: instr

392: instr

323: instr
367: instr

369: instr

378: instr

374: instr

365: instr

381: instr

376: instr

382: if

375: break

325: instr

334: instr

330: instr

321: instr

337: instr

332: instr

338: if

331: break

449: instr
447: if

399: if
317: switch
383: break

395: if

387: if

385: break

393: break

324: break
368: break

370: if

379: return

326: if

335: return

316: break

333: break
450: instr

377: break
401: switch
320: instr

397: if

388: if

327: if
371: if

322: instr

331: instr

327: instr

318: instr

334: instr

329: instr

335: if

328: break

389: instr

329: break
373: break

372: instr

328: instr

323: if

332: return

398: instr

396: instr

391: break

339: instr
383: instr

460: break

410: instr

404: instr

406: instr

423: instr

425: instr

427: instr

412: instr

402: instr

421: instr

419: instr

450: loop

430: instr

330: break
487: break

324: if
400: instr

448: return

342: if

386: if
409: break

385: instr

387: instr

341: instr

343: instr

411: break

405: break

424: break

426: break

428: return

413: if

403: break

422: break

420: break

507: break

453: instr

452: return

464: break

451: instr

431: if

337: if

344: instr
454: loop

388: instr
414: if
326: break

401: if

325: instr

433: if

452: if

432: instr

339: if

345: if
455: instr

389: if
415: if
336: instr
402: return

449: instr

451: if
408: instr

390: instr

503: break

384: if
321: break

399: if

483: break

400: break

340: if

403: return

346: return
390: return

338: instr

340: instr

418: break

453: break

435: if

454: switch

341: instr

347: return
456: if

391: return
416: instr

434: instr

436: instr

504: instr

437: instr

455: instr

465: instr

476: instr

486: instr

490: instr

459: instr

501: instr

474: instr

463: instr

457: instr

488: instr

484: instr

472: instr

461: instr

342: if
457: break
417: instr
343: return

505: if

438: if

456: break

466: if

477: loop

487: break

491: loop

502: return

475: break

464: break

458: break

489: break

485: break

473: break

458: switch

462: break

344: return
508: instr
439: return

507: if

440: return

467: if

478: instr

459: instr

471: break

468: if

479: if

460: break

480: break

481: instr

495: instr

482: return

496: if

475: break

497: instr

498: instr

508: instr

463: instr

505: instr

495: loop

478: instr

506: return

467: instr

479: break

461: instr

468: break

492: instr

462: break

488: instr

493: break

476: instr

489: break

465: instr

477: break

466: break

496: instr

483: if

473: instr

497: if

484: break

485: instr

499: instr

498: break

500: break

515: loop
513: break

474: instr

486: return

500: if

503: instr

506: instr

524: instr
515: instr

494: instr

491: break

482: instr

472: if

499: instr

514: instr
512: if

514: loop

490: instr

481: loop

471: if

494: break

513: if
470: instr

480: instr

470: if

493: if

511: if
469: instr

511: loop

469: instr

492: instr

509: if
509: if

510: instr

520: instr

516: if

501: instr

502: instr

504: break

521: return

518: loop

517: break

512: instr

510: instr

516: if

519: instr
518: instr

525: return

517: break

520: if
519: instr

522: instr

521: break

523: instr

496: instr

497: if

445: instr

498: instr

499: instr

494: instr
472: instr
446: if

500: instr
495: if
473: if

447: instr

448: instr

501: if
496: instr
474: instr

497: instr

475: instr

449: instr

502: instr
498: instr
476: instr

450: if

503: instr
499: if
477: if

451: instr

504: if
500: instr
478: instr

452: instr

505: instr

506: if

501: instr
479: instr
453: if

507: if
502: if
480: if

454: instr

455: if

508: instr
503: instr
481: instr

504: if

482: if

456: if

509: instr
505: if
483: if

457: instr

510: if
506: instr
484: instr

458: instr

511: return

523: break

550: break

572: break

512: instr

507: instr
485: instr
459: if

513: loop
508: if
486: if

460: return

499: break

519: break

461: instr

472: break

514: instr
509: return
487: return

499: break

526: break

548: break

521: break

548: break

570: break

510: instr

488: instr

462: loop

515: if
511: loop
489: loop
463: instr

517: switch

516: break

512: instr
490: instr
464: if

520: instr

524: instr

539: instr

530: instr

518: instr

555: instr

543: instr

557: instr

532: instr

541: instr

522: instr

570: instr

533: if

571: return

553: instr

551: instr

526: instr

528: instr

568: instr

573: instr

513: if
491: if
466: switch

465: break

521: break
515: switch
493: switch

473: instr

475: instr

477: instr

467: instr

479: instr

469: instr

500: instr

506: instr

517: instr

507: loop

518: return

481: instr

502: instr

471: instr

492: instr

504: instr

488: instr

490: instr

518: instr
476: break

478: break

468: break

480: break

470: break

501: break

482: if

503: break

493: loop

505: break

489: break

491: break

500: instr

515: instr

506: instr

494: instr

531: instr

519: instr

533: instr

508: instr

517: instr

498: instr

546: instr

529: instr

527: instr

502: instr

504: instr

544: instr

509: if

494: instr

484: if

511: instr

510: break

487: break

485: instr

501: break

516: break

507: break

495: break

532: break

520: loop

522: instr

537: instr

528: instr

516: instr

553: instr

541: instr

534: loop

509: if

547: return

518: break

530: break

528: break

503: break

505: break

545: break

486: instr

555: instr

530: instr

539: instr

520: instr

568: instr

551: instr

549: instr

524: instr

526: instr

566: instr

545: instr

559: instr

534: if

546: if

560: if

535: if

523: break

538: break

529: break

517: break

554: break

542: loop

556: loop

531: if

521: instr

535: instr

510: if

522: if

536: if

511: if

543: instr

557: instr

532: if

569: return

540: break

552: break

550: break

525: break

527: break

567: break

544: if

558: if

533: if

548: instr

562: instr

527: break

529: break

569: break

574: if

537: break

576: if

538: break

561: break

578: if

536: instr

579: instr

552: if

514: break

536: break

563: if

566: instr

537: instr

580: loop

576: if

554: if
565: instr

538: instr

552: break

572: if

549: return

524: instr

554: break

574: if

526: instr

498: return

542: break

571: instr

525: if

496: break

512: instr

546: instr

560: instr

559: break

534: instr

564: instr

567: break

581: if

583: loop
547: return

513: instr

516: break

536: instr

539: if

542: instr

513: instr

561: if

535: instr

529: break

540: instr

543: break

557: if

562: instr

565: break

579: if

582: break

575: instr

590: return

587: instr

565: instr

530: loop

585: if
581: loop
559: loop

537: return

577: instr

578: loop
584: instr

563: instr
524: instr

564: instr

556: loop

528: if

541: instr
522: instr

589: instr

577: instr

555: instr

527: loop

525: return
514: instr

558: loop

550: if

545: break
515: instr

544: loop

547: break

523: break
512: if

556: break

523: if

495: if

497: instr

519: break

549: instr

519: break
483: if

531: break

521: if

497: break
508: instr

540: break

520: instr

496: instr
474: break

525: break

514: break

492: break

553: instr

558: break

575: instr

580: break

573: instr

551: instr

531: instr

586: break
582: instr
560: instr

587: instr

588: return

566: return

532: if

588: instr
583: if
561: if

533: break

534: instr
584: break
562: break

585: instr

563: instr

535: instr
586: instr
564: instr

492: instr
594: instr
596: instr

1093: instr

575: instr
493: if
595: if
597: if

1094: if

576: if
494: instr

495: instr
596: instr
598: instr
577: instr

597: instr

599: instr

1096: instr

578: instr

496: instr
598: instr
1097: if

600: instr

1095: goto

579: instr
497: if
599: if
601: if

1099: if

1098: goto

580: if
498: instr
600: instr
602: instr

1100: instr

1102: if

581: instr
499: instr
601: instr
603: instr

1101: goto

1103: instr

1118: if

582: instr
500: if
602: if
604: if

1141: instr

1119: if

583: if
501: instr

502: if
603: instr
605: instr

1142: goto

1121: if

584: instr
503: if
604: if
606: if

1122: instr

1120: instr

585: if
504: instr
605: if
607: if

1104: if

1123: instr

586: if
505: instr
606: instr
608: instr

1105: instr

1124: loop

587: instr
506: if
607: instr
609: instr
588: instr
507: return

519: break

546: break

568: break

599: break

630: break

620: break

618: break

668: break

670: break

1106: if

1125: if

652: break

508: instr
608: loop
610: loop

1108: if

1126: break

1127: if

1143: instr

1129: instr

589: loop
509: loop
609: instr
611: instr

1109: instr

590: instr
510: instr
610: if
612: if

1107: goto

1110: if

1130: loop

591: if
511: if
612: switch
614: switch
593: switch
513: switch

1111: instr

627: instr
623: instr
520: instr

535: instr

526: instr

514: instr

551: instr

539: instr

553: instr

528: instr

537: instr

518: instr

566: instr

529: if

567: return

549: instr

547: instr

522: instr

524: instr

564: instr

602: instr

604: instr

594: instr

606: instr

596: instr

633: instr

635: instr

637: instr

650: instr

598: instr

608: instr

620: instr

615: instr

613: instr

653: if

648: instr

629: instr

625: instr

615: instr

627: instr

646: if

668: instr

649: if

666: instr

619: instr

655: instr

636: instr

617: instr

621: instr

641: instr

653: instr

634: instr

623: instr

527: break

515: break

552: break

540: loop

554: loop

538: break

550: break

548: break

523: break

525: break

565: break

603: break

605: break

595: break

607: break

597: break

634: break

636: break

638: loop

651: return

609: if

621: if

610: if

622: instr

616: if

614: break

654: instr

649: break

630: if

626: break

616: break

628: break

647: instr

669: return

650: instr

667: break

656: loop

637: if

618: break

622: break

642: if

654: break

635: break

624: break

530: if

614: break

645: instr

644: if

625: instr

626: break

617: instr

648: break

651: instr

657: instr

638: instr

643: instr

646: break

632: instr
640: if
556: if

531: if

534: break

611: instr

623: instr

618: instr

652: break

658: if

639: instr

644: instr

558: instr

557: break

532: instr

641: break

612: break

624: loop

619: break

617: instr

666: instr

667: return

647: if

639: instr

648: instr

649: instr

669: if

640: if

615: instr

670: instr

641: instr

619: instr

616: break

1131: if

1128: instr

651: instr

620: break

1132: if

1136: break

652: break
1133: if

1135: break

671: instr

642: instr

650: break

1137: instr

1134: break

672: if

659: break

660: instr

640: break

1113: goto

645: break

658: instr

657: break

638: break

643: break

1116: instr

1138: if

674: if

676: if

1117: goto

1139: goto

1140: instr

658: if
659: if

562: instr

533: instr

646: instr

625: instr

664: instr

661: if

665: break

662: instr

662: instr

676: if

678: if

1144: instr

660: if

576: loop
661: instr
645: instr

560: instr

634: instr

575: instr

643: if
559: if

561: instr

635: if

674: if

631: break

544: instr

653: instr

636: instr

637: instr

656: if

633: break
543: break

664: instr

654: loop

1115: if

656: if

574: if

642: instr

545: return

632: instr

665: break

655: instr

673: instr

655: instr

572: if
630: instr

542: if

633: break

1114: instr

629: if
631: if
555: instr

622: break

672: instr

632: break

570: if

639: instr
541: instr

613: instr

1112: if

628: if
624: break
536: break

621: instr

671: if

631: instr

569: instr

601: break
521: break

611: break

613: break

592: break

512: break

600: instr
516: instr

517: break

563: break

577: if

644: instr

647: break

626: if

663: instr

679: goto

660: instr

663: break

677: instr

680: if

1145: return

661: instr

585: instr
673: instr

685: if

678: loop

681: instr
628: instr
579: loop

573: instr

578: break

627: break

662: loop

671: instr

571: instr
686: instr
675: instr
629: return

580: instr

657: instr

698: instr

679: if

682: if

663: if

586: return
687: loop
683: loop
659: instr

664: break

680: instr

683: break

677: instr

665: loop

581: if
675: instr
684: if
672: return
582: break

688: if

681: if

701: instr

666: instr

583: instr
690: loop

689: break

684: instr

682: break

685: instr
667: if
584: instr
691: if
688: break
668: break

699: return

686: if

669: instr
692: instr
687: break

689: instr

670: instr
693: if

695: break

690: loop

696: instr

694: break

691: if

697: instr
692: break

702: return

693: loop

694: if

695: instr

698: break

696: if

697: break

699: instr

700: instr

Figure 4. CIL: control flow for the sequence of slocate main routines (shown in reading order)

4.2

slocate : CIL Analysis

ment directly on the files describing control flow for each
version’s main routine. The flows for each version of slocate are sketched in fig. 4. Fig. 5 shows in detail the flow
for slocate version 1.0.

In this subsection, we compare the logical flow of the
program across versions by determining the control flow
graph (CFG) for each of the releases. The CFG is a representation of decision points within the routines.

4.2.2 Experiments
We perform two experiments. In figure 6(a), we compare
the control flow for the top level main routines for each release by comparing their dot file representations. In figure
6(b), we compare the control flows for each release by looking at the concatenations of the dot files representing all of
the routines in each release.

4.2.1 CIL
CIL [30], C Intermediate Language, is a high level representation of C code and a powerful set of associated tools
intended for code analysis and transformation. For our limited purposes, it can, however, be thought of as a library of
Objective CAML routines that can be directed to perform
analysis of C code.
Using the CIL system [29], a short OCAML program
was written (based on sample code available from [18]) that
would accept all of the preprocessed .i files corresponding
to program compilation, would merge and combine them
and then use its analysis to create a set of dot files describing the control flow within the program. Each decision point
in the routine becomes a node in the diagram. We experi-

4.2.3 Analysis
First look at diagram 6(a). The lack of plateaux spreading out towards corners of the main diagonal is indicative
of steady change. The slocate main routines operate differently in each version. Nevertheless, we can see four blocks
along the main diagonal: 1.0 to 1.4, 1.4 to 2.1, 2.1 to 2.5
and 2.5 to 2.7. The extreme difference between the versions

563

4.3

370: instr

In this subsection, we consider the program structure in
terms of the linkage between its routines. This time we
compare call graphs.

371: if

372: instr

slocate : Call Graph Analysis

373: instr

374: if

4.3.1 ncc
375: instr

ncc [44] can be thought of as a front-end for the gcc compiler. It extracts a call graph from the source code before
passing it on to gcc for compilation. Again ncc will produce dot files corresponding to the code presented to it for
analysis. Each of these represents the call graph for the program under analysis: each routine becomes a node in the
graph. It does not, however, show control flow.
We applied it to the sources for each version of slocate to
produce call graphs for the main routine. Each node is the
name of a routine: main, rindex, load dir, and so on. For
space reaons, we show only one example as figure 7.

376: instr

377: loop

378: instr

379: if

380: break

394: instr

383: break

382: instr

395: if

381: switch

386: instr

387: if

397: if

390: instr

398: instr

392: instr

385: break

4.3.2 Experiments

393: break

Again we perform two experiments. In figure 8(a), we look
at the call graphs for the top level main routines. In figure 8(b), although we consider the main routines, this time
we omit calls to the system memory management routines
malloc, free and realloc.

388: if

399: if

400: instr

384: instr

396: instr

389: instr

391: break

401: if

4.3.3 Analysis
402: return

403: return

The first item of note about figures 8(a) and 8(b) is the
strong similarity between the two. Omitting or including the
calls to the sytem memory management functions makes no
noticeable difference to the results. The comparison method
does not see these as being noteworthy functions.
Looking at the figures in more detail, we see three clear
divisions represented as blocks along the diagonal corresponding to the major release numbers. It is reassuring to
see that the last two members of the 1.x series had some degree of similarity to the 2.x series leading to a ‘halo’ effect
around the central block. The sole member of the 3.x series
is seen to be fundamentally different in structure to the 1.x
series and even the 2.x series as we would expect. The 2.x
series, however seems to be split into two sub-blocks: 2.0
to 2.3 and 2.4 (perhaps 2.5) to 2.7. Again, this is reflected
in the code. 2.0 to 2.3 were indeed structured differently. A
patch was required to get these versions to compile.

Figure 5. CIL: control flow for slocate main routine, version 1.0

2.5 to 3.1 and the others is indicated by values close to zero.
These final versions are strongly different from their predecessors. Also striking are the very low values for the similarity. Only for routines in the block 1.0 to 1.4 is their any
sign of close similarity. The main routines being analysed
are short but steadily increase in complexity as additional
functionality is added. This representation, therefore, seems
to be less informative than the previous ones (although we
will need to carry out additional research to find out why).
Now look at diagram 6(b) that shows the similarity for
the concatenation of all routines’ representations. We see
that, apart from some slight degree of similarity for the initial few versions, perhaps as far as version 1.5, there seems
to be very little similarity detected by the method. The most
striking feature is the trough to be seen between versions 2.0
and 2.3. It seems that these versions were quite different
from all of the others.

5 Information Theoretic Approach
All of the experimental results were obtained using an
implementation of a similarity metric based on the concept
of Kolmogorov complexity. Here we sketch the theory behind these, the implementation, and how they were applied

564

"plot_dots_blocksort.data" matrix
1
0.8
0.6
0.4
0.2
0

"plot_all_dots_blocksort.data" matrix
1
0.8
0.6
0.4
0.2
0

1

3.1

2.6

0.8
2.4

2.0

0.8
2.4

2.0

2.4

0.2

2.0

1.3
1.1
1.1

1.3

1.5

2.0

2.4

2.2

2.6

3.1

1.5

0.2

2.2

1.3

2.0

1.5

1.3

1.5

0

1.1

1.3
1.1

1.1

1.3

1.5

2.0

2.2

2.4

2.6

0.4

2.6

1.5

2.2

0.6

2.2
3.1

0.4

2.6
2.4

2.6

0.6

2.2
3.1

1

3.1

1.1

3.1

1.3

1.5

2.0

2.4

2.2

2.6

3.1

0

1.1

1.1

(a) slocate: CFG for main only

1.3

1.5

2.0

2.2

2.4

2.6

3.1

(b) slocate CFG, all procedures

Figure 6. Comparison of slocate control flow graphs produced from CIL data

main

rindex

create_db

usage

free_right

printf

load_dir

init_2D_list freemalloc

add_down

add_right

opendir

readdir

seekdir

tel dir

closedir

MYfchdir

exit

fprintf

match_exclude

lstat

statmalloc

fchdir

strlen

__lxstat

strerror

getuid

parse_exclude

__builtin_strchr

__rawmemchr

put_short

MYchdir

__errno_location

getgid

getopt

memmove

frcode

open

close

rename

fputs

Uput_short

strcat

strstr

get_cur_dir

__builtin_strncat

chmod

chown

get_gid

calloc

_IO_putc

__builtin_strcmp

realloc

fopen

decode_db

fclose

atoi

free

_IO_getc

Uget_short

strtol

chdir

malloc

get_short

snprintf

fgetc

__strtol_internal

Figure 7. ncc: call graph for slocate main routine, version 1.0

"plot_dots_blocksort.data" matrix
1
0.8
0.6
0.4
0.2
0

"plot_no_mfr_blocksort.data" matrix
1
0.8
0.6
0.4
0.2
0

1

3.1

2.6

0.8
2.4

2.0

0.2

1.1
1.1

1.3

1.5

2.0

2.2

2.4

2.6

3.1

1.5

0.2

2.2
2.0

1.3

1.5

0

1.1

1.3
1.1

1.1

1.3

1.5

2.0

2.2

2.4

2.6

0.4

2.6

1.3

1.5
1.3

2.0

2.4

2.2

0.6

2.2

1.5

2.0

0.8
2.4

3.1

0.4

2.6
2.4

2.6

0.6

2.2
3.1

1

3.1

1.1

3.1

(a) slocate: call graph

1.3

1.5

2.0

2.2

2.4

2.6

3.1

0

1.1

1.1

1.3

1.5

2.0

2.2

(b) slocate call graph, no malloc/free/realloc

Figure 8. Comparison of slocate call graphs produced from ncc data

565

2.4

2.6

3.1

where xy denotes the concatenation of x and y. C(x), for
example, denotes the approximation of a Kolmogorov complexity K(x) by the length of the compressed data produced
by an instance of a real compressor. Provided the compressor possesses certain properties (idempotency, monotonicity, symmetry and distributivity), they show that the NCD
provides an approximation of the NID [22].
The publicly available toolkit CompLearn [6] contains
an implementation of the NCD. We employ the blocksort
compressor of version 1.0.2. Given two strings to compare,
it produces a number constrained to lie between zero and
(approximately) one: zero means that the comparands are
identical. Performing pairwise comparisons on a set of objects, the program ncd produces a symmetric distance matrix which is used for our visualisation.

to produce the final results. In addition to an extensive bibliography on these topics, pointers to references on Shannon
entropy and Kolmogorov complexity in the context of software engineering are presented in our earlier paper [4].

5.1

Kolmogorov Complexity

The Kolmogorov complexity, discovered independently
by Solomonoff [37], Kolmogorov [20] and Chaitin [5], can
be defined as follows [22].
Formally, the Kolmogorov complexity, or algorithmic entropy, K(x) of a string x is the length
of the shortest binary program x∗ to compute x
on an appropriate universal computer — such as
a universal Turing machine.

5.4

Kolmogorov complexity measures messages’ individual
information content, rather than, as in the Shannon case,
information transfer based on the probabilistic selection of
messages from a set. For more details see [23, 8].

5.2

The Similarity Metric is a universal comparator. If two
objects are close using any reasonable distance measure,
then they will also be close using the Similarity Metric. Furthermore, it can compare objects not normally considered
comparable – a mitochondrial genome and a Unix binary,
for example.
The Similarity Metric is also, in some sense, a feature detector. It finds the characteristic most similar between compared entities as the basis for its similarity measurement.
This may not be what is intuitively the most comparable
feature and what is chosen may not be the same even when
one member of a pair is substituted by a third item.
The NCD has already been applied successfully in a diverse range of fields from genomics to musical style classification. Concerning Kolmogorov complexity-based metrics,
in a section of the recent paper by Allen et al. [1] discussing
‘size’ metrics, the authors show that they are strongly correlated with counting metrics.

Similarity Metric

A means for comparing how similar two objects are in
terms of their shared information content, the Similarity
Metric, was published by Li et al. [22]. Their normalised information distance (NID) is a relative metric in that it takes
the quantities of information in the objects to be compared
into account. It is given by the following equation.
N ID(x, y) =

max{K(x|y), K(y|x)}
max{K(x), K(y)}

(1)

Here K(x|y), for example, is the conditional Kolmogorov
complexity of x given y. This is the length of the shortest
program for a universal Turing machine to output x when
given an input y. The NID has been shown to obey the
standard metric properties up to an additive term. It takes
values from [0, 1] with 0 indicating identical objects.

5.3

6 Common experimental analysis

Implementation

In our experiments, all of the comparisons for each of
the different types of input data were performed in the same
way. Data samples representing the software releases were
compared using the NCD to produce a distance matrix. This
matrix denotes pairwise comparison between each of the
samples and is symmetrical (about its minor diagonal). The
values plotted, both in 2D and 3D, are 1.0-NCD to permit
easier viewing of the results. Therefore, a value of 1.0 represents identical samples whereas a value closer to zero represents samples differing greatly from each other.
Note that we performed no filtering on the input data for
comparison of sources or behaviours. We made no attempt
to find a common alphabet of symbols or make edits of any

The practical difficulty with using Kolmogorov complexity is that it is non-computable. Kolmogorov complexity is not partial recursive and so it is impossible to find
its exact value. This is a consequence of the nonexistence
of an algorithm solving the halting problem which is itself
closely connected with G¨odel’s incompleteness theorem.
Kolmogorov complexity can, however, be approximated.
Cilibrasi and Vit´anyi [7] created the normalised compression distance (NCD).
N CD(x, y) =

C(xy) − min{C(x), C(y)}
max{C(x), C(y)}

Interpretation

(2)

566

kind1. Similarly, in the comparison of logical structure, we
relied directly on the dot files as being representative of decisions made in the software. Finally, the dot files concerning program structure in terms of linkages (routine calls) between the different elements of the program were not modified in any way to produce the graphs shown.
We believe that the techniques described in this paper
have additional applications in software engineering. Some
examples include software clustering, clone detection, implications for testing resulting from added software complexity, project management and feature detection. Concerning visualisation, one possible avenue of investigation
might mirror D’Ambros and Lanza’s work showing ways
to visualise changes in information content as a means of
predicting where bugs may have been injected [9].

References
[1] E. B. Allen, S. Gottipati, and R. Govindarajan. Measuring
size, complexity, and coupling of hypergraph abstractions of
software: An information-theory approach. Software Quality Control, 15(2):179–212, 2007.
[2] R. A. Amar and J. T. Stasko. Knowledge precepts for design
and evaluation of information visualizations. IEEE Transactions on Visualization and Computer Graphics, 11(4):432–
442, 2005.
[3] T. Apiwattanapong, A. Orso, and M. J. Harrold. A differencing algorithm for object-oriented programs. In ASE ’04:
Proceedings of the 19th IEEE international conference on
Automated software engineering, pages 2–13. IEEE Computer Society, 2004.
[4] T. Arbuckle, A. Balaban, D. K. Peters, and M. Lawford.
Software documents: Comparison and measurement. In
Proc. 18th Int. Conf. on Software Eng. & Knowledge Eng.
(SEKE 2007), pages 740–745, July 2007.
[5] G. J. Chaitin. On the length of programs for computing finite binary sequences: statistical considerations. J. ACM,
16(1):145–159, 1969.
[6] R. Cilibrasi. The CompLearn Toolkit, 2003.
[7] R. Cilibrasi and P. Vit´anyi. Clustering by compression. IEEE
Trans. Information Theory, 51(4):1523–1545, April 2005.
[8] T. M. Cover and J. A. Thomas. Elements of Information
Theory. Wiley-Interscience, 2006.
[9] M. D’Ambros and M. Lanza. Software bugs and evolution:
A visual approach to uncover their relationship. In CSMR
’06: Proc. Conf. Software Maintenance and Reengineering,
pages 229–238. IEEE Computer Society, 2006.
[10] S. Demeyer, S. Ducasse, and O. Nierstrasz. Object Oriented
Reengineering Patterns. Morgan Kaufmann Publishers Inc.,
2002.
[11] S. Ducasse, M. Lanza, and R. Bertuli. High-level polymetric views of condensed run-time information. In CSMR ’04:
Proceedings of the Eighth Euromicro Working Conference
on Software Maintenance and Reengineering (CSMR’04),
pages 309–318. IEEE Computer Society, 2004.
[12] S. G. Eick, J. L. Steffen, and E. E. Sumner, Jr. Seesoft-a tool
for visualizing line oriented software statistics. IEEE Trans.
Softw. Eng., 18(11):957–968, 1992.
[13] R. F. Erbacher. Exemplifying the inter-disciplinary nature
of visualization research. In IV ’07: Proc. 11th Int. Conf.
Information Visualization, pages 623–630. IEEE Computer
Society, 2007.
[14] M. Fischer, J. Oberleitner, H. Gall, and T. Gschwind. System evolution tracking through execution trace analysis. In
IWPC ’05: Proc. 13th Int. Workshop on Program Comprehension, pages 237–246. IEEE Computer Society, 2005.
[15] B. Fluri and H. C. Gall. Classifying change types for qualifying change couplings. In Proc. 14th IEEE Int. Conf. on Program Comprehension (ICPC’06), pages 35–45. IEEE Computer Society, 2006.
[16] R. Holt and J. Y. Pak. GASE: visualizing software evolutionin-the-large. In WCRE ’96: Proc. 3rd Working Conf. on Reverse Eng., pages 163–167. IEEE Computer Society, 1996.

7 Conclusions and Future Work
In visualisation, the problem of information overload is
well-known and several means of ameliorating it — multiple views, hierarchical views, abstraction, interactive visualisation — have been proposed. In this paper we have
shown that, by applying an information theoretic approach
to analyze software artefacts, we can create a visualisation
that, firstly, finds and highlights the most significant differences between software versions; secondly, provides a
numerical measure of similarity between compared artefacts; and, thirdly, in conjunction with the visualisations
presented here, allows researchers, developers and managers to quickly grasp areas of significant change without
need for extensive and difficult analysis.
Clearly there are implications for several software engineering fields in view of the results of the information theoretic model sketched in this paper. Within the field of visualisation, we will proceed to make more detailed studies
of how much can easily be revealed using these techniques
throughout the software development process with the aim
of providing as much information for practitioners as possible in their never-ending challenge to understand unfamiliar
code.

Acknowledgements
The author would like to acknowledge the helpful comments made by the reviewers. The author thanks Adam
Balaban, Mark Lawford and Dennis K. Peters for encouragement, additional comments and insight.
1 To compile releases 2.0, 2.1, 2.2, 2.3, on line 819 of file sl fts.c ‘#ifdef
DT WHT’ became ‘#if defined DT WHT && defined S IFWHT’.

567

[17] B. C. Hungerford, A. R. Hevner, and R. W. Collins. Reviewing software diagrams: A cognitive study. IEEE Trans.
Softw. Eng., 30(2):82–96, 2004.
[18] R. Jones. Using CIL to analyze libvirt, 2007. Canonical
URL is http://et.redhat.com/∼rjones/cil-analysis-of-libvirt/.
[19] H. M. Kienle and H. A. M¨uller. Requirements of software
visualization tools: A literature survey. In Proc. 4th IEEE
International Workshop on Visualizing Software for Understanding and Analysis, pages 2–9, June 2007.
[20] A. N. Kolmogorov. Three approaches to the quantitative
definition of information. Probl. Inform. Trans., 1(1):1–7,
1965.
[21] M. Lanza, S. Ducasse, H. Gall, and M. Pinzger. CodeCrawler: an information visualization tool for program comprehension. In ICSE ’05: Proc. 27th Int. Conf. on Software
Eng., pages 672–673, 2005.
[22] M. Li, X. Chen, X. Li, B. Ma, and P. Vit´anyi. The similarity metric. IEEE Trans. Information Theory, 50(12):3250–
3264, 2004.
[23] M. Li and P. Vit´anyi. An introduction to Kolmogorov complexity and its applications (2nd ed.). Springer-Verlag, 1997.
[24] W. Li, P. Eades, and S.-H. Hong. Navigating software architectures with constant visual complexity. In VLHCC
’05: Proceedings of the 2005 IEEE Symposium on Visual
Languages and Human-Centric Computing (VL/HCC’05),
pages 225–232. IEEE Computer Society, 2005.
[25] D. R. Licata, C. D. Harris, and S. Krishnamurthi. The feature
signatures of evolving programs. In Proc. 18th IEEE Int.
Conf. on Automated Software Engineering, pages 281–285,
October 2003.
[26] K. Lindsay.
slocate, 1998.
Canonical URL is
http://slocate.trakker.ca/.
[27] R. Lintern, J. Michaud, M.-A. Storey, and X. Wu. Pluggingin visualization: experiences integrating a visualization tool
with Eclipse. In SoftVis ’03: Proceedings of the 2003 ACM
symposium on Software visualization, pages 47–56, 209.
ACM, 2003.
[28] A. McNair, D. M. German, and J. Weber-Jahnke. Visualizing software architecture evolution using change-sets. In
WCRE ’07: Proceedings of the 14th Working Conference on
Reverse Engineering (WCRE 2007), pages 130–139. IEEE
Computer Society, 2007.
[29] G. C. Necula. CIL home page, 2005. Canonical URL is
http://hal.cs.berkeley.edu/cil/.
[30] G. C. Necula, S. McPeak, S. P. Rahul, and W. Weimer. CIL:
Intermediate language and tools for analysis and transformation of C programs. In CC ’02: Proc. 11th Int. Conf. on
Compiler Construction, pages 213–228, London, UK, 2002.
Springer-Verlag.
[31] J. Ratzinger, M. Fischer, and H. Gall. EvoLens: Lens-view
visualizations of evolution data. In IWPSE ’05: Proceedings of the Eighth International Workshop on Principles of
Software Evolution, pages 103–112. IEEE Computer Society, 2005.
[32] S. P. Reiss. The paradox of software visualization. In VISSOFT ’05: Proc. 3rd IEEE Int. Workshop on Visualizing
Software for Understanding and Analysis, pages 1–5. IEEE
Computer Society, 2005.

[33] S. P. Reiss. Visual representations of executing programs. J.
Vis. Lang. Comput., 18(2):126–148, 2007.
[34] F. V. Rysselberghe and S. Demeyer. Studying software evolution information by visualizing the change history. In
ICSM ’04: Proc. 20th IEEE Int. Conf. on Software Maintenance, pages 328–337. IEEE Computer Society, 2004.
[35] A. P. Sawant and N. Bali. DiffArchViz: A tool to visualize
correspondence between multiple representations of a software architecture. In 4th IEEE Int. Workshop on Visualizing Software for Understanding and Analysis, 2007., pages
121–128, June 2007.
[36] J. Sillito, K. D. Volder, B. Fisher, and G. Murphy. Managing
software change tasks: an exploratory study. In Int. Symp. on
Empirical Software Engineering, pages 23–32, November
2005.
[37] R. J. Solomonoff. A formal theory of inductive inference.
part I and part II. Information and Control, 7(1 and 2):1–22
and 224–254, 1964.
[38] M.-A. D. Storey and H. A. M¨uller. Manipulating and
documenting software structures using SHriMP views. In
ICSM ’95: Proceedings of the International Conference on
Software Maintenance, page 275. IEEE Computer Society,
1995.
[39] M.-A. D. Storey, K. Wong, and H. A. M¨uller. Rigi: a visualization environment for reverse engineering. In ICSE
’97: Proc. 19th Int. Conf. on Software engineering, pages
606–607. ACM Press, 1997.
[40] R. Vasa, J.-G. Schneider, and O. Nierstrasz. The inevitable
stability of software change. In IEEE Int. Conf. Software
Maintenance, pages 4–13, Oct. 2007.
[41] L. Voinea and A. Telea. Multiscale and multivariate visualizations of software evolution. In SoftVis ’06: Proceedings of the 2006 ACM symposium on Software visualization,
pages 115–124. ACM, 2006.
[42] S. Wenzel, H. Hutter, and U. Kelter. Tracing model elements. In IEEE Int. Conf. on Software Maintenance, 2007.,
pages 104–113, October 2007.
[43] J. Wu, C. W. Spitzer, A. E. Hassan, and R. C. Holt. Evolution spectrographs: Visualizing punctuated change in software evolution. In IWPSE ’04: Proc. 7th Int. Workshop on
Principles of Software Evolution, (IWPSE’04), pages 57–66.
IEEE Computer Society, 2004.
[44] S. Xanthakis. ncc home page, 2002. Canonical URL is
http://students.ceid.upatras.gr/∼sxanth/ncc/.
[45] T. Xie and D. Notkin. Checking inside the black box: Regression testing by comparing value spectra. IEEE Trans.
Softw. Eng., 31(10):869–883, 2005.
[46] Z. Xing and E. Stroulia. Analyzing the evolutionary history of the logical design of object-oriented software. IEEE
Trans. Softw. Eng., 31(10):850–868, 2005.
[47] Z. Xing and E. Stroulia. UMLDiff: an algorithm for
object-oriented design differencing. In ASE ’05: Proc. 20th
IEEE/ACM Int. Conf. on Automated Software Engineering,
pages 54–65. ACM, 2005.

568

