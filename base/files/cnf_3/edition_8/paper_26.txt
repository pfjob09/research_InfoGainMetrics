Computer-Aided Surgery based on Auto-Stereoscopic Augmented Reality
Céline Paloc1, Eduardo Carrasco1, Iván Macía1, Rubén Gómez1, Iñigo Barandiarán1, José Manuel
Jiménez2, Oskar Rueda3, Jorge Ortiz de Urbina4, Andrés Valdivieso4 & Georgios Sakas5
1

Medical Applications Group, VICOMTech, Donostia-San Sebastián (Spain).
2
STT Engineering & Systems S.L., Donostia-San Sebastián (Spain).
3
Bilbomática S.A., Bilbao (Spain).
4
Hepatobiliary Surgery & Hepatic Transplant Unit, Cruces Hospital, Bilbao (Spain).
5
Cognitive Computing & Medical Imaging Department, Fraunhofer IGD, Darmstadt (Germany).
Abstract
Although Augmented Reality (AR) promises to
provide valuable means for Computer-Aided Surgery, the
underlying technologies often create a cumbersome work
environment that is inadequate for clinical employment. A
great deal of research is still needed to develop
comfortable and easy-to-use tools providing an augmented
view of the patient and its main internal structures. In this
paper, we propose to develop an AR system for enhanced
visualization of the liver that involves minimal annoyance
for both the surgeon and the patient. The ultimate
application of our system is to assist the surgeon in
oncological liver surgery.
Keywords--- Augmented Reality, ComputerAssisted Surgery, Medical Image Segmentation,
Registration

1. Introduction
Although modern medical imaging offers the surgeons
a precise representation of the internal anatomy of patients,
its interpretation often remains a difficult task. Indeed, as
the patient is being represented on a set of two-dimensional
images (MRI or CT-scan), the surgeon is often required to
mentally reconstruct a three-dimensional representation of
its internal anatomy.
Advancements in computerized image processing
enables the development of Computer-Aided Surgery
(CAS) tools, providing surgeons with three-dimensional
organ models reconstructed from medical imaging.
However, current systems often require a time-consuming
pre-processing, such as the manual interactive
segmentation of organs requiring 30 minutes or up to one
hour, thus making them unsuitable in routine procedures.
Moreover, the intra-operative presentation of the 3D data is
mostly visualized on a simple monitor, forcing the surgeon
to redirect his view from the patient to the data, and viceversa.
Recently, Augmented Reality (AR) technology has
been applied to CAS, so that the surgical team can directly

visualise the three-dimensional data correctly registered on
the patient in the operating theatre. Although AR promises
to provide valuable means for CAS, most of the
applications remains in the prototype stage, due to the fact
that the underlying technologies create a cumbersome work
environment that is inadequate for clinical employment.
Indeed, the major drawback of current AR-based CAS
system is to obstruct the view of the surgeon or distract
him during the operation.
Current research projects [1-4] have mostly focused on
the use of see-through Head Mounted Displays (HMDs),
which suffer from limited field of view, poor ergonomic
designs and excessive weight. Others have developed
optically transparent display systems, mounted on a freely
movable swivel arm [5]. While being promising, this
display unit still lacks in image brilliance, since contrast
and brightness of the displayed graphics is tightly coupled
to the lighting conditions of the surrounding real
environment.
A great deal of research is thus still needed to develop
comfortable and easy-to-use tools providing an augmented
view of the patient and its main internal structures in the
operating theatre. Our strategy is to concentrate on
providing an AR platform designed specifically for
surgical purposes, so that it is well accepted by the
surgeons. This involves the following system requirements:
x the system should be not only fast and accurate,
but also easy-to-use, robust, and relatively
inexpensive;
x it should not invade the surgeons work or distract
them during the operation;
x it should provide visual depth perception;
x it should render high-resolution images;
x all hardware must fulfil the sterile conditions in
the operating theatre.
In this paper, we propose a CAS platform aiming at
satisfying the above requirements. On one hand we assist
organ segmentation by employing a semi-automatic
method significantly reducing the time needed for pre-

Proceedings of the Eighth International Conference on Information Visualisation (IV’04)
1093-9547/04 $ 20.00 IEEE

processing down to a level acceptable for clinical routine
applications. In addition we apply AR to the operating
theatre in an intuitive, easy-to-use form making it suitable
for daily clinical routine. The development of our platform
was carried out within the TRAC project [6,7]. Its ultimate
application is to assist the surgeon in oncological liver
surgery for either minimal invasive surgery applications
(RF ablation, alcohol injection, cryo- or laser therapy…) or
the path planning in open liver interventions.
The rest of this paper describes the methodology of
our AR-based CAS platform and presents our current
results and achievements.

3. Medical Image Analysis
In the pre-operative stage, the patient undergoes a
standard MRI scan with three MR-visible markers attached
to its abdomen, as shown on Figure 2. These markers are
easy and quick to fix, and can be repositioned accurately at
a later stage using a single tattoo point or ink marker.
These markers are easily identifiable on the MRI images as
seen on Figure 3, and can be extracted as threedimensional points in the local coordinate system of the
dataset. These 3D points will be used as reference to
position the virtual liver in the real scene when creating the
augmented view, as described in the next section.

2. System Overview
Our CAS platform consists of two function blocks.
The first is a medical image analysis tool used in the preoperative stage. It generates an automatic and accurate
segmentation of the patient’s anatomy from an input MRI
dataset with minimal user interaction. The second is an AR
system, providing real-time enhanced visualisation of the
patient and its internal anatomy. The AR system is based
on the combination of two AR technologies – an optical
tracking system and an auto-stereoscopic display involving minimal annoyance for the surgeon. Each block
is described in the next sections.

Figure 2 MR-visible markers are attached to
the patient’s abdomen prior to scanner.

MRI Dataset

Medical Image Analysis
Automatic Segmentation.

Figure 3 Markers are easily identified
on MRI images.

3D Reconstruction.

Augmented Reality System
Registration via optical tracking.
Live video via stereo camera.
Graphical overlaying with OpenGL.
Visualisation via auto-stereoscopic monitor.

Figure 1 Schematic overview of our ARbased CAS platform

A 3D representation of the liver parenchyma is then
extracted from previously acquired MRI data of the patient.
We implemented a semi-automatic segmentation method
based on Geodesic Active Contours [8]. The resulting
isolated contours can then be automatically converted into
a proper geometric representation by transforming surface
coordinates to a mesh of polygons.
The process was implemented within a prototypical
user interface, based on the Insight Toolkit [9] for the
segmentation task and the Visualization Toolkit [10] for
the visualization A snapshot of the interface is shown on
Figure 4.

Proceedings of the Eighth International Conference on Information Visualisation (IV’04)
1093-9547/04 $ 20.00 IEEE

(a) Reflective markers attached
on patient’s abdomen.

(b) Infrared camera
mounted on the ceiling.

Figure 5 Optical tracking system in the operating
theatre for real-time wireless tracking.

Figure 4 Snapshot of our medical image
analysis software.

4. Augmented Reality System
In the operating theatre, the AR system merges the
resulting 3D anatomical representation onto the surgeon’s
view of the real patient. Our system is based on an optical
system providing wireless tracking and an autostereoscopic monitor providing depth perception without
additional wearable equipment. The technology is
explained in the next subsections.

4.1 Registration via Optical Tracking
One of the most challenging components of a valuable
AR system is the correct registration of the virtual
representation in the real world coordinate system.
Mechanical devices have been prohibited, due to their
moving constraints. Magnetic systems offer unconstrained
movements, but require the sensors to be linked to a
measurement instrument via cables [11]. We use here an
optical system, offering wireless tracking with millimeter
accuracy and real-time capabilities [12].
Reflective markers are placed on the tattoo or ink
points of the patient’s abdomen previously defined in the
imaging process, as shown on Figure 5(a). Four infrared
cameras like the one shown on Figure 5(b) are mounted on
the ceiling at each corner of the operating theatre, allowing
to detect the markers and to compute their 3D positions in
the real world. The reference points of the virtual model
are then aligned with the positions of the markers by matrix
computation and least-squares minimisation. The result is a
geometric transformation which allows to compute the
position of the virtual liver in the real scene.

4.2 Augmented View Generation
Once the position of the virtual liver in the real world
is known, the AR view is created by merging the real
image of the patient and the virtual image of its internal
structures on a high-resolution auto-stereoscopic display.
The real image consists of a live video stream acquired
by a pair of stereoscopic video cameras in the operating
theatre [13]. These cameras are compact and light-weight,
which makes them possible to be attached to a mobile arm
that can be easily positioned by the surgeon during the
operation. The surgeon can then obtain the best view of the
augmented scene without interfering his own field of view.
The position of the camera is tracked by our optical system
via three reflective markers attached to it. Our camera is
shown on Figure 6.

Figure 6 Miniaturized stereoscopic camera
mounted by three reflective markers.

The virtual image consists of graphically displaying
the virtual liver generated by a virtual camera. The intrinsic
parameters of the virtual camera, such as focal length and
stereo separation, are assigned to those of the real camera.
Its extrinsic parameters, such as position and orientation,
are given by the markers mounted on the real camera.

Proceedings of the Eighth International Conference on Information Visualisation (IV’04)
1093-9547/04 $ 20.00 IEEE

The live stereo video stream is then augmented by
overlays displaying the virtual structures adequately. An
auto-stereoscopic monitor was chosen among other
stereoscopic devices to display the enhanced video stream
with depth perception and no specific wearable equipment
[14]. The monitor consists of a high-resolution liquid
crystal colour display panel displaying a high-quality
stereoscopic image without the use of spectacles, filters or
other external viewing aids (Figure 7). A tracking system
built in the monitor continuously tracks the position of the
surgeon’s head, allowing him to move freely, without
being distracted or disturbed by additional equipment.

Moreover, the automatisation of the segmentation task
drastically decreases the pre-processing time, making
quality assessment possible as well as the integration of
interventional MRI during the surgical procedure.

Figure 8 Resulting segmentations. Right:
Overlap of the manual (white) and automatic
(dark gray) segmentations.
Figure 7 Auto-stereoscopic monitor providing depth
perception without cumbersome wearing equipment.

4.3 Software implementation
We built our own software library called 3DArt, using
C++ and OpenGL to handle the main functionalities of the
whole AR system, such as acquisition, registration and
mergence of the virtual and real images, communication
with the optical tracking system and output to the autostereoscopic monitor.
The whole system was designed to be very intuitive
for the surgeon, who is simply required to position the
stereo camera towards his region of interest. Some optional
interactions based on key presses were integrated, allowing
the surgeon to switch between mono and stereoscopic
views, or between real and virtual images.

5.2 Liver visualization
The three-dimensional liver representations resulting
from the above segmentations were used to perform inhouse testing of our AR system (Figure 9). Three reflective
markers were fixed on the reference positions of a torso
placed inside the tracking room. The virtual liver was
successfully aligned to the reflective markers and displayed
accurately on the auto-stereoscopic monitor, as shown on
Figure 10. When the position of the stereoscopic camera
was changed and/or when the torso was moved, the
registered position of the virtual liver was correctly
updated in real time.

5. Results
5.1 Hepatic segmentation
Our medical image analysis software was applied to
the automatic segmentation of the liver parenchyma in
axial MRI volumes of several abdominal datasets. For
evaluation purposes, each dataset was also segmented
manually. Each manual segmentation required about 45
minutes, while the automatic segmentations took less than
10 minutes.
The results were qualitatively and quantitatively
evaluated by a validation tool for segmentation [15]. The
overlapping ratios of the manual segmentations with
respect to the automatic ones varied between 0.89 and 0.97,
showing that our automatic method preserves highaccuracy. Graphical results are shown on Figure 8.

Figure 9 Final setup of our AR-based CAS
platform for in-house testing.

Proceedings of the Eighth International Conference on Information Visualisation (IV’04)
1093-9547/04 $ 20.00 IEEE

In the next stage we will apply the system first on
minimal invasive applications where the body remains
closed and geometric distortions are naturally minimized.
The different errors that might arise from the MRI image
processing, the markers accuracy/skin shifting and the
internal displacements due to breathing will be evaluated.

Acknowledgements
Real image of the torso

Registered virtual image of the liver

This work has been financed by STT Engineering &
Systems and Bilbomática S.A.
We would also like to thank the cooperation of
Dr. F. Sáez, director of the Radiology Department of the
Cruces Hospital in Bilbao (Spain).

References
Augmented view

Figure 10 Resulting augmented view
(snapshot of the monitor’s screen).

6. Discussion and Conclusion
We have undertaken the systematic development of
the different components of an AR system to assist the
surgical team in liver surgery by visualizing an enhanced
view of the patient with a virtual reconstruction of its liver.
Based on a high-resolution auto-stereoscopic display,
the system presents a high-quality rendering particularly
required by medical applications. The stereoscopy provides
adequate depth perception facilitating the understanding of
the spatial relationships between the real and virtual
images. Moreover, special attention has been put into
designing a system with minimal annoyance for both the
surgeon and patient during the operation, by suppressing
additional glasses and cables, which could distract the
surgeon and result in significant eye fatigue. Finally, our
prototype was built using affordable hardware and software
solutions, making it available for widespread use.
These main characteristics make our AR system more
adequate for surgical purposes than previous existing AR
prototypes and provide a valuable tool for computer-aided
surgery, leading to the acceptance and clinical applicability
of AR technology within the operating theatre.
Our future work will focus on the evaluation of our
system in a clinical environment. The pre-operative and
intra-operative procedures described in this paper will be
applied to real patients. Some source of errors can be
evaluated only in operating theatre routines. One of them is
the possible error caused by skin-shift; another one are
geometric distortions of MRI images due to the nonperfect homogeneity of the magnetic field. Both errors are
independent from the tracking accuracy of markers, which
is a technically solvable problem. A third source of error
can be the internal movement of liver due to breathing
shifting. We measured up to 4 cm of shifting. Fortunately,
this effect can be minimized by adequate ventilation
procedure under anaesthesia.

[1]

E. Sorantin, G. Werkgartner, R. Beichel, A. Bornik,
B. Reitinger,
M. Riccabona,
R. Wegenkittl,
and
A. Fuhrmann The Virtual Liver Surgery Planning System.
In European Congress of Radiology, Vienna, 2004.
[2] ARAS–Augmented Reality Aided Surgery:
www.vrvis.at/brl/aras
[3] T. Suthau, M. Vetter, P. Hassenpflug, HP. Meinzer, O.
Hellwich. A concept work for Augmented Reality
visualisation based on a medical application in liver
surgery. ISPRS Commission V Symposium 2002
[4] M. Liévin and E. Keeve, Stereoscopic Augmented Reality
System for Computer Assisted Surgery 15th International
Congress and Exhibition in Computer Assisted Radiology
and Surgery (CARS) 2001
[5] M. Schnaider, B. Schwald, H. Seibert, T. Weller Medarpa A Medical Augmented Reality System for MinimalInvasive Interventions. Medicine Meets Virtual Reality
(MMVR) 2003 pp. 312-314
[6] The TRAC project: www.vicomtech.es/ingles/html
/proyectos/index_proyecto19.html
[7] E. Carrasco, I. Macía, R. Gómez, G. Sakas. TRAC Augmented Reality Project in Liver Surgery. In Computer
Graphik Topics, Vol 15 pp 34-35, 2003.
[8] I. Macía, C. Paloc, E. Carrasco, R. Gómez, I. Barandiarán.
Geodesic Active Contours for Hepatic Segmentation in
MRI Images. Medical Image Computing and Computer
Assisted Interventions (MICCAI), 2004 (submitted).
[9] L. Ibanez, W. Schroeder, L. Ng, L. Cates The ITK
Software Guide. Published by Kitware Inc., ISBN: 1930934-10-6
[10] W. Schroeder, K. Martin, B. Lorensen: The Visualization
Toolkit, An Object-Oriented Approach To 3D Graphics.
3rd Edition, published by Kitware Inc., ISBN 1-930934-076
[11] D.A. Simon, Intra-Operative Position Sensing and Tracking
Devices, in Proc. First joint CVRMed and MRCAS

Conference, pp. 62-64, June 1997.
[12] STT Engineering & Systems: www.simtechniques.com
[13] StereoImaging Corporation: www.stereoimaging.com
[14] SeeReal Technologies: www.seereal.com/default.en.htm
[15] G. Gerig, M. Jomier, M. Chakos. VALMET : A New
Validation Tool for Assessing and Improving 3D
Segmentation. Proc. of International Conference on
Medical Image Computing and Computer Assisted
Interventions (MICCAI), 2001.

Proceedings of the Eighth International Conference on Information Visualisation (IV’04)
1093-9547/04 $ 20.00 IEEE

