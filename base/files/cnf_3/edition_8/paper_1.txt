Modern Visualisation Tools for Research and Education in Biomechanics
Serge Van Sint Jan1, Marco Viceconti2, Gordon Clapworthy3
1

2

Department of Anatomy (CP 619), Faculty of Medicine, University of Brussels (ULB), Belgium
Laboratorio di Tecnologia Medica, Istituti Ortopedici Rizzoli, via di Barbiano 1/10, Bologna 40136, Italy
3
Dept of Computing & Information Systems, University of Luton, Luton LU1 3JU, UK

sintjans@ulb.ac.be, viceconti@tecno.ior.it, gordon.clapworthy@luton.ac.uk

Abstract
The DataManager presented in this paper allows the
multimodal visualisation of heterogeneous data
originating from the biomedical field and, more
particularly, Biomechanics. In the latter, the aim is to
increase our understanding of the musculo-skeletal
system, and to achieve this, numerous disparate data
must be collected and combined. Previously, no software
tool fully allowed such integration, but the DataManager
and its development environment (the MAF) now provide
an answer to that problem.
This paper presents the current visualisation and
data processing tools available from the DataManager.
Its usefulness for research, educational and clinical
activities will be demonstrated.
The system developers hope that the data
management mechanisms available within the software
will stimulate data sharing between scientists and will
encourage them to participate in enhancing the system
by integrating their own software tools.
Keywords--- Multimod project, MAF, DataManager,
Biomechanics, biomedical visualisation, education,
anatomy, multimodality.

Traditionally, such data are visualised individulally
using specialised tools. It is up to the observer mentally
to synthesise the information available from the various
data sources. Such an operation demands a high level of
skill and training and is prone to errors of judgment in
some conditions (e.g., junior or tired observer). In
clinical practice, such problems are crucial.
Though
less
dramatic,
interpretation
of
heterogeneous data is even more complicated for
students that must study the various aspects of the
Human Anatomy using the above sources of information.
Medical students are usually poorly trained mentally to
combine information; full interpretation of the content is
therefore often not optimal [1].
The availability of efficient software tools for the
combination of heterogeneous data is critical to improve
the interpretation and increase the understanding of the
available information. To answer these needs, the ECfunded MULTIMOD project has developed an
architecture (called the Multimod Application
Framework, or MAF) and a set of visualisation tools
(Fig. 1).

1. Introduction
There is a continuing demand for more effective
visualisation tools from many biomedical applications
due to the complexity and heterogeneity of the data that
must be considered.
Typically, data collected for biomechanical
applications are extremely disparate:
- limb motion data from video (stereophotogrammetry);
- muscle activity (electromyography);
- joint kinematics data (electrogoniometry);
- medical imaging (magnetic resonance imaging, MRI,
and computerised tomography, CT);
- three-dimensional reconstruction of anatomical
structures;
- etc.

Figure 1. Example of heterogeneous data visualised within
the DataManager. A: MRI data, B: 3D bone modelling, C:
multimedia class showing a dissection, D: arteriography.

Proceedings of the Eighth International Conference on Information Visualisation (IV’04)
1093-9547/04 $ 20.00 IEEE

The MAF architecture and visualisation tools are
presented in other papers, including the concepts behind
the data combination and registration [2, 3]. This paper
describes a typical application, called the DataManager,
developed from the MAF architecture, and its use in both
research and pedagogical contexts.

It must be emphasised that the data available from
each VME node is stored separately on the hard disk,
while the description of the VME tree is stored in a
independent file (with extension MSF). This allows large
amounts of data to be combined without the sacrifice of
flexibility and interactivity.

2. Data Management and Data Visualisation

2.2. VIZ approach

Conceptually, two kinds of end-users can be considered
when using vertical applications like the DataManager
implemented from the MAF: management users (MNG)
and visualisation users (VIZ). These will use the
interface for different purposes, so it must answer the
expectations of both sides.

Some users do not need to organise data but, rather, need
to visualise them (for example, a medical professional
who consults a patient report, or a student studying the
content of a tutorial). The above VME tree can become
extremely large and complex and thus tend to confuse for
a VIZ user. The MAF architecture, therefore, allows the
creation of so-called layouts, which are shortcuts that
will automatically display pre-selected data from the
VME tree. The data pre-selection is typically performed
by MNG users, and stored into labelled layouts within
the MSF file. VIZ users load available layouts from the
layout dialog box (Fig. 3). This feature is a key-element
for allowing non-technical users to access large amount
of heterogeneous data swiftly with just a few mouse
clicks.

2.1. MNG approach
MNG users are typically individuals who need to
organise their data hierarchically either for research
purposes or to prepare data distribution to third parties
(e.g. students) who will adopt the VIZ approach.
The interface must address data management issues
related to organising large disparate data stored on the
user system. An important MAF feature is the ability to
allow the MNG user to sort the available data within a
multiple-level hierarchy. The data is organised into a
tree-like structure, called the VME tree, in which nodes
and branches represent the available information as
organised by the MNG user (Fig. 2).

Figure 3. Layout dialog
box. The list displays all
available
pre-selected
data.
Loading
the
unlighted layout will pop
up the user screen visible
at Fig. 1.

A user can easily switch between MNG and VIZ
modes according its current needs.

3. Using the DataManager interface
One of the aims of the MAF architecture is to offer the
possibility of creating an environment for simultaneous
visualisation of heterogeneous data. An environment
such as the DataManager offers both import and export
facilities, combined with various kinds of visualisation
windows and data processing tools.
Figure 2. Example of VME tree. The VME tree illustrated here
is related to heterogeneous data used to describe various
aspects of the knee anatomy (e.g. Powerpoint presentation,
multimedia files, medical imaging, 3D modelling). In this
particular example, more than 1 Gb of data is available from
the VME tree, which runs on standard PCs.

3.1. Data import/export
Heterogeneous data currently accepted by the
DataManager includes standards from various data
collection procedures (Table 1). Non-standard data can
be imported using raw formats.

Proceedings of the Eighth International Conference on Information Visualisation (IV’04)
1093-9547/04 $ 20.00 IEEE

Table 1. Standard formats available within MAF

DATA TYPE
Property format
Exchange format
Motion data
3D modelling
Medical imaging
Images

FORMATS
MSF
VTK
C3D, PGD
STL, VRML
DICOM
BMP, JPG, PNG, TIF

viewer (top-left window in Fig. 5). Displaying a 3D
model, with or without transparency, in such window
allows the visualisation of particular anatomical
structures (e.g. bones, as in the illustrated example) with
the surrounding environment (e.g. soft tissue).
Such a feature is of interest when estimating the
extension of a structure within the subject’s anatomy or
when learning how to recognise anatomical features
within medical imaging datasets.

Once a dataset has been imported it becomes a
member of the current VME tree (see Fig. 2). Its position
in the VME hierarchy can be altered using copy/paste
operations.

3.2. Data viewers
Once data of a particular type is imported into a VME
tree, it can be visualised by the system viewers. Each
viewer is able to detect automatically compatible data
from the VME tree (Fig. 4).

Figure 5. Orthoslice viewer. A CT dataset of a knee is
displayed together with the 3D bone models of the joint.

3.2.3. RX-CT viewer (Fig. 6)
This presents several slices in a slightly different way
from the previous viewers. The main difference is the
ability to interpolate X-ray-like images from a CT
dataset. This is useful when digital X-ray images are not
available. Displaying 3D models is also possible (see
Fig. 6, femoral bone in red, patella in blue) and allows a
better understanding of the available information.
Figure 4. Automatic detection of “visualisable” VME
elements. The current viewer (here a “surface viewer”)
indicates which data can be displayed by the presence of
empty clickable boxes next to the compatible VME data.
Crossed boxes indicate the data that is currently displayed
in the window. All viewers in the DataManager are based on
the same principle.

3.2.1. Surface viewer (Fig. 4)
This allows visualisation of any data (geometry, motion,
medical imaging) spatially defined according to some
technical frames. The technical frame of each dataset
available in the VME tree can be modified either by
associating it with a VME element located higher up in
the VME tree hierarchy, or by performing registration.
The latter is the key-feature allowing heterogeneous data
combination (see Section 3.3).
3.2.2. Single Slice and Orthoslice viewers (Fig. 5)
Both of these deal with medical imaging datasets. The
Single Slice viewer displays a single slice along one of
the original dataset axes, while the Orthoslice viewer
shows four images – a slice along each axis and a 3D

Figure 6. RX-CT viewer. The left half of the screen shows the
X-ray interpolation obtained from the CT-Scan. The levels of
the slices on the right are selected by dragging coloured
bars in the X-Ray viewer. Contrast windowing is also
available.

Proceedings of the Eighth International Conference on Information Visualisation (IV’04)
1093-9547/04 $ 20.00 IEEE

3.2.4. Arbitrary slice viewer
This allows a user to interpolate slices through a medical
imaging dataset. The difference from the previous slice
viewers is that the arbitrary slicer is able to perform the
interpolation along any orientation (the previous slicers
were limited to the orthogonal planes of the dataset).
This allows images to be provided according to the
orientation of particular anatomical structures, rather
than the way in which the imaging equipment captured
the data. This reduces the need to perform further real
(and costly) medical imaging sequences to align the data
captured with the particular orientation of each of the
anatomical structures of interest in the patient.
3.2.5. The isosurface viewer (Fig. 7)
This is based on a novel and extremely fast algorithm
that allows the generation of 3D isosurfaces in real time
on standard PCs. Surfaces are generated at speeds of 10100 times faster than the standard Marching Cubes
algorithm. This allows modification of the threshold
levels (i.e. the Houndsfield Unit, or HU) , characterising
the structure of interest in the dataset, to take place
interactively – a dramatic improvement on standard
procedures. Fine-tuning of the final results is improved
compared to standard isosurface algorithms.

Figure 7. Isosurface generation has been performed using a
CT dataset of a knee joint. Results of three different
thresholds are shown (left: skin = -220 HU; centre: muscles
and veins = 40 HU; right : bone = 180 HU). Results are
displayed instantaneously when modifying the threshold.

3.3. Data registration and landmark setting
Data registration is the basis for combining
heterogeneous data. Most suchprocedures are based on
registering the coordinates of particular landmarks that
are located within the datasets [4]. Spatial setting and
location are available from the DataManager in a
convenient way: the user has the possibility to create a
personalised landmark dictionary.

Figure 9. Setting of anatomical landmarks (ALs). ALs are
first selected in the dictionary list on the right, then set on
the 3D surface by clicking on the area of interest. A sphere
located on the selected area is displayed, and the selected
AL string is flagged with a coloured bullet in the list (this
avoids selecting the same AL twice). Spatial AL coordinates
are stored into the VME tree.

Once loaded, the dictionary allows a landmark name
to be chosen from the dictionary, and the corresponding
point to be identified on the surface of 3D models (Fig.
9). This operation is called virtual palpation.

3.2.6. Volume rendering (Fig. 8)
This use more complex algorithms that process the
projection of rays through the dataset according to
several properties (colour, opacity, gradient) given to
particular HU values found in the dataset [3]. Anatomical
structures can be simultaneously distinguished according
their intensity properties.
Figure
8.
Volume
rendering of a CT
dataset (same dataset
& orientation as Fig.
7). Three different
materials are shown
(skin = -238 HU, in
green; muscles = 62
HU, in blue; bone =
1036 HU, in red).

Figure 10. Registration of two tibial bones. Left: before
registration. Right: after registration (using similarity mode).
At first, each 3D model is associated with an AL cloud (pink
spheres for red tibial bone, green spheres for yellow tibial
bone). Then, registration takes place based on the
transformation interpolated between the spatial attitudes of
both AL clouds. The same transformation is applied on the
3D bone model (here the yellow bone). In this particular
case, scaling has been performed as well.

Proceedings of the Eighth International Conference on Information Visualisation (IV’04)
1093-9547/04 $ 20.00 IEEE

All selected ALs for a particular 3D model are
grouped in an AL cloud. In order to be registered, two
datasets must each have their own AL cloud including
landmarks located on the same anatomical spots. Once
several clouds of landmarks are available, registration
can take place. Registration processes the relevant spatial
location and orientation of AL clouds in the dataset, and
determines a spatial transformation matrix that will align
them (Fig. 10). Because anatomical structures rarely
have the same sizes and proportions, several registration
procedures are implemented into the DataManager (rigid
if the datasets have the same sizes and proportions;
similarity if sizes are different but not the proportions;
affine is both sizes and proportions are different).

3.4. Registration of motion data and 3D bone
modelling
Simultaneous observation of motion data and the
underlying joint anatomy is of great assistance in
increasing our understanding of motion mechanisms and
joint pathology [5]. Thanks to the operations described
above, such real-time motion simulation is
straightforward within the DataManager (Fig. 11).
At first, the motion data and 3D bone models are
imported according to the above-mentioned formats. The
motion data file usually includes spatial trajectories of
particular ALs recorded by some motion analysis system.
Each AL is associated with a particular limb segment
(e.g. thigh, shank, or foot). The DataManager is able to
sort ALs into segmental clouds automatically based on
user-defined dictionaries (Fig. 11A).

attitude of the limb segments at the beginning of the
analyzed motion (Fig. 11B).
Once registration is satisfactory, motion data are
used to transform the 3D bone models (Fig. 11C,D,E).
The quality of the visualisation strongly depends upon
the quality of both the virtual palpation and the motion
data collection.

3.5. Data processing operations
The DataManager does not only provide visualisation of
imported data, it also supports processing of the data and
storing of the results.
Several useful operations are already included in the
interface, besides the above registration procedures:
generation of finite element properties, on-line distance
determination between 2 ALs (Fig. 12), volume
sampling, volume cropping, mapping, surface filtering
(decimation, smoothing), etc.

Figure 12. The variation of the distance between 2 particular
landmarks is processed on-line during a motion simulation.
This allows the study of, for example, muscle excursion or
tendon lengthening during particular tasks.

4. Conclusions

Figure 11. Real time motion data registered to 3D bone
model obtained from CT-Scan (see text for explanations).

The same AL clouds are attached to the imported 3D
bone models using virtual palpation. Registration is then
performed in order to transform the models to the

This paper has presented a vertical application, the
DataManager, built from the MAF architecture.
Although more features will be added in the future, the
DataManager has already shown itself useful for
extensive registration of heterogeneous data. Such an
interface is very promising to facilitate more extensive
analysis of the various disparate datasets generated
within the biomedical fields.
It is also a compact way of exchanging data between
locations that usually use different standards. This is
important in a field, such as Biomechanics, that deals
with numerous data obtained from a variety of sources.
No individual department has convenient access to
all the data collection tools that are needed to obtain the
wide range of quality data essential for making
significant progress towards more realistic and more
anatomically correct musculo-skeletal models. Such
tools include medical imaging for morphological data,
motion analysis for limb motion, electrogoniometry for
joint kinematics, electromyography for muscle activity,
constraint gauges, body donation for cadaver dissection,
3D modelling software, histological properties of bone

Proceedings of the Eighth International Conference on Information Visualisation (IV’04)
1093-9547/04 $ 20.00 IEEE

and soft tissue, advanced registration algorithms, finite
element modelling, etc.
An environment like the DataManager, including
many attractive tools for both visualisation and data
processing, should motivate teams, worldwide, to
translate their data into a MAF-compatible format. Such
standardisation should help to increase data sharing and
international collaboration.
The ability of the DataManager to allow the
visualisation of multimodal data is also interesting to
produce simultaneous visualisation of anatomical (see
Fig. 1) or clinical information (Fig. 13). In the latter case,
this should help to improve the diagnosis of musculoskeletal disorders, for which the etiology is usually very
complex, and difficult to interpret even for well trained
and highly experienced clinicians.

Besides encouraging data sharing, the DataManager has
a structure that will allow continuous improvement by
the integration of new software tools developed by thirdparty programmers willing to share their work. Such
participation will certainly help to maintain the
improvement to our understanding of the human
musculo-skeletal system that developments of recent
years have furnished. Medical education and research,
both fundamental and clinical, can only benefit from
such progress.

Acknowledgements
This study is part of the MULTIMOD project, 2001-04,
ref. IST-2000-28377, which is funded by DG IST of the
European Commission.

References
[1]

[2]

[3]

[4]
Figure 13. Multimodality analysis of heterogeneous data
collected as part of a diagnosis protocol of a 5-year old
child suffering of bone cancer. Displayed data include: CT
data, interpolated X-ray, 3D bone models, video of gait,
motion analysis data, landmark location, motion simulation.

[5]

Proceedings of the Eighth International Conference on Information Visualisation (IV’04)
1093-9547/04 $ 20.00 IEEE

S Van Sint Jan, M Crudele, et al. “Development of
Multimedia Learning Modules for Teaching Human
Anatomy: Application to Osteology and Functional
Anatomy”, The Anatomical Record (Part B: the New
Anatomist), 2003, 272B(1), 98-106.
M Viceconti, A Leardini, C Zannoni, D Testi, F Taddei,
L Astolfi, M Petrone, S Imboden, P Quadrani, “The
Multimod Application Framework”, Proc Information
Visualisation 04, IEEE Computer Society Press, 2004
M Krokos, A Savenko, G J Clapworthy, H Lin, R
Mayoral, M Viceconti, S Van Sint Jan, “Real-Time
Visualisation within the MULTIMOD Application
Framework”, Proc Information Visualisation 04, IEEE
Computer Society Press, 2004
S Van Sint Jan, P Salvia, et al. “Registration of 6-DOFs
Electrogoniometry and CT Medical Imaging for 3D Joint
Modelling”, Journal of Biomechanics, 2002, 35, 14751484.
S Van Sint Jan, V Sholukha, et al. “Advanced modelling
and simulation of the lower limb using medical imaging,
electrogoniometry and gait analysis data”, Proc. 7th
International Symp. on the 3D Analysis of Human
Movement, Newcastle upon Tyne (UK), 2002.

