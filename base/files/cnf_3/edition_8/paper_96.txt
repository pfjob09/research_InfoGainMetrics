MS-Taxonomy: A Conceptual Framework for Designing Multi-sensory Displays
Keith V. Nesbitt
Charles Sturt University, School of Information Technology, Bathurst, Australia
knesbitt@csu.edu.au
Abstract
One important task that the designer of Multi-sensory
displays must perform is the comparison of displays designed
for the different senses. Comparing designs for different
visualisations is difficult enough but comparing a visual
display with an auditory display, or haptic display is harder
still. Yet the designer of multi-sensory displays would like to
make sensible decisions about when to use each modality.
This paper describes the MS-Taxonomy, a classification of
abstract data displays that is general for all senses. This
allows the same terminology to be used for describing
visualisation, sonification and haptic display designs. The
classification of displays is hierarchical and describes
multiple levels of abstraction. In software engineering terms
the taxonomy allows a designer to consider reuse at both an
abstract architectural level and also a more detailed
component level. Thus design mappings can be discussed
independently of the sensory modality to be used. This allows
for exactly the same design to be implemented for each sense
and subsequently compared or transferred between
modalities.

1. Introduction
With multi-sensory interfaces the user can potentially
perceive and assimilate multi-attributed information more
effectively. By mapping different attributes of the data to
different senses, such as the visual, auditory and haptic sense,
it may be possible to better understand large data sets.
Unfortunately much previous work involving multisensory display is split across the different fields of
Information Visualisation, Information Sonification [1] and
the embryonic field of Haptic or touch displays. It would be
an advantage for designers of multi-sensory display to be
better able to integrate work from these existing fields of
study. For example, a typical question often raised, during the
design of multi-sensory display, is whether one sense is
superior to another for displaying abstract data? Some people
suggest that vision is the dominant sense. While it is true that
vision is highly detailed and well suited to comparing objects
arranged in space, it is equally true that hearing is effective

for monitoring sounds from all directions, even when the
source of the sound is not visible.
In fact, all senses are well suited for different kinds of
tasks. This is supported by what is known as the Modal
Specific Theory [2]. This psychophysical theory states that
each sensory modality has distinct patterns of transduction.
So, each sense has unique sensory and perceptual qualities
that are adept with certain kinds of complex information.
Despite more rigorous attempts to categorise the visual
display space [3] and the emergence of standard
methodologies such as earcons [4] and auditory icons [5] and
suggested design patterns [6] in the sonification domain, it is
still not clear when designing a display of abstract data what
mapping should be used for certain types of data and for
particular tasks.
The situation for the multi-sensory designer is further
complicated as they seek to develop a mapping from data
attributes to visual, auditory and even haptic parameters. It is
often unclear what types of abstract data to map to each sense.
Unfortunately direct comparisons between say a visual and
auditory display are very difficult. How can we compare the
pitch of sound to the shape of an object or it’s texture.
For the multi-sensory designer it would be useful to have
a more common description of display mappings, so that we
could compare and discuss different display modes. This
would also allow display mappings to be simply transferred
between modalities. To solve this problem this paper
introduces a classification of the multi-sensory design space
called the MS-Taxonomy. The classification is hierarchical
and describes multiple levels of abstraction. At the higher
levels of abstraction the same terminology can be used for
describing information displays for every sensory modality.

2. Metaphors and Senses
In the field of information display, classifying the multisensory design space is an important first step in the
development of general principles of design. This is
necessary, as any design should consider the full range of
possibilities offered by the design space. A typical division of
the multi-sensory design space bases categories around the
different senses. This is an intuitive division and leads

Proceedings of the Eighth International Conference on Information Visualisation (IV’04)
1093-9547/04 $ 20.00 IEEE

naturally to specialist fields such as visualisation and
sonification. However, because this division accentuates the
differences of each sense it makes it hard to compare or
transfer display concepts between the senses.
By contrast, the MS-Taxonomy makes a primary division
of the design space using the types of metaphors used in
information displays. This results in three main classes,
Spatial metaphors, Direct metaphors and Temporal
metaphors (figure 1).
Spatial metaphors relate to the scale of objects in space,
the location of objects in space and the structure of objects in
space. For example, Spatial metaphors concern the way
pictures, sounds and forces are organised in space and can be
described for the visual, auditory and haptic senses. Thus
different types of spatial metaphors may be described for each
sense. Spatial visual metaphors concern the way pictures are
organised in space. Spatial auditory metaphors concern the
way sounds are organised in space. Spatial haptic metaphors
concern the way forces are organised in space.
Spatial metaphors involve the perception of a quality
(space) that is not uniquely associated with any particular
sense. Although different classes of spatial metaphors (visual,
auditory and haptic) can be described, the concepts that define
a spatial metaphor are general and therefore independent of
the senses. Spatial metaphors are discussed in more detail in
section 3.
Direct metaphors are concerned with direct mappings
between sensory properties and some abstract information.
For example, a specific colour, the volume of sound or the
hardness of a surface may be used to represent a particular
data attribute. Once again, a class of direct metaphors can be
defined for each sense. Direct visual metaphors concern the
perceived properties of pictures. Direct auditory metaphors
concern the perceived properties of sounds. Direct haptic
metaphors concern the perceived properties of touch.
Unlike spatial metaphors, direct metaphors are highly
specific for each modality. Each sense is described by it's own
capability to perceive sensory properties. For example, the
eye perceives colour, the ear perceives pitch and the haptic
sense can perceive the hardness of an object. These different
sensory capabilities are described as direct properties.
However, the concept of a direct property is general for all
senses. Thus, for example, it is possible to compare or
exchange a direct property of one sense with another. Direct
metaphors are discussed in more detail in section 4.
Temporal metaphors are concerned with how we
perceive changes to pictures, sounds and forces over time.
The emphasis is on displaying information by using the
fluctuations that occur over time. Once again Temporal
metaphors can be considered for each of the senses. Temporal
visual metaphors concern the way pictures change with time.
Temporal auditory metaphors concern the way sounds
change with time. Temporal haptic metaphors concern the
way haptic stimuli change with time.
Temporal metaphors are like spatial metaphors in that
they involve the perception of a quality (time) that is not

associated with any particular sense. Though the three
different classes of temporal metaphors (visual, auditory and
haptic) are described, the concepts that define a temporal
metaphor are general and therefore independent of the senses.
Temporal metaphors are discussed in more detail in section 5.
In this section of the paper the discussion of the MSTaxonomy has been described for the three senses of vision,
hearing and touch. In further sections only the auditory and
visual senses will be discussed. For interested readers a
discussion of these concepts with haptic display is available
elsewhere [8]
Sensory Display
Modes

Task Domain
Metaphors

Spatial
Metaphors

Direct
Metaphors

Temporal
Metaphors

Visual
Display

Auditory
Display

Haptic
Display

Spatial
Visual
Metaphors

Spatial
Auditory
Metaphors

Spatial
Haptic
Metaphors

Direct
Visual
Metaphors

Direct
Auditory
Metaphors

Direct
Haptic
Metaphors

Temporal
Visual
Metaphors

Temporal
Auditory
Metaphors

Temporal
Haptic
Metaphors

Figure 1 UML diagram showing the high-level
architecture of the MS-Taxonomy

3. Spatial Metaphors
In the real world a great deal of useful information is
dependent on the perception of space. For example, driving a
car requires an understanding of the relative location of other
vehicles. Parking the car requires a comparison of the size of
the car with the size of the parking space. Navigating the car
requires an understanding of the interconnections and layout
of roadways. Real world information is often interpreted in
terms of spatial concepts like position, size and structure.
Abstract information can also be interpreted in terms of these
spatial concepts.
Because the concepts that describe spatial metaphors are
independent of each sense it is simply the different ability of
each sense to perceive space that needs to be considered.
Because the concepts abstract across the senses it is also
possible for spatial metaphors to be directly compared
between senses. For example, the ability of the visual sense to
judge the position of objects in space can be compared with
the ability of the auditory sense to locate a sound in space.
This sensory independence also enables concepts to be reused
between senses. For example, a spatial visual metaphor, such
as a visual scatterplot, can be directly transferred to a spatial
auditory metaphor to describe an auditory scatterplot. In this
case an auditory scatterplot would use the position of sounds
in space to mark points of abstract data. The design space for

Proceedings of the Eighth International Conference on Information Visualisation (IV’04)
1093-9547/04 $ 20.00 IEEE

spatial metaphors can be described using the following
general concepts: the display space; spatial structure and
spatial properties (figure 2).

Display
Space

Orthogonal Spaces
Distorted Spaces
Subdivided Spaces

Position
Scale
Spatial
Metaphors

Spatial
Properties

Orientation

Global
Spatial
Structures
Spatial
Structures
Local
Spatial
Structures

1D
2D
3D
Length
Depth
Area
Volume
Angle
Slope
Curvature
Field
Connection
Containment
Grouping
Global spatial artefacts
Line
Point
Region
Surface
Solid
Glyphs
Local spatial artefacts

Figure 2 The general concepts that describe Spatial
Metaphors.
The display space is the region where the data is
presented. All spatial metaphors have as their basis an
underlying display space that is used to arrange the display
elements. For example, the scatterplot defines a 2D
orthogonal display space by mapping data attributes to the x
and y axis. Points are then interpreted in terms of this display
space. In the real world, space is perceived as constant,
however in an abstract world the properties that define the
space can also be designed. For example, one axis of the
scatterplot could be defined as a logarithmic space. This has
the effect of changing the way the position of points is
interpreted.
There are a number of strategies for designing the display
space when presenting information and these include using
orthogonal spaces (1D, 2D, 3D), distorted spaces and
subdivided spaces.
The entities that occupy the display space are described
as spatial structures. For example in the scatterplot, the points
are spatial structures. Spatial structures also describe the
arrangement of entities within the display space. For example,
a group of points in the scatterplot can be considered a more
global spatial structure. The MS-Taxonomy distinguishes two
levels of organisation for presenting information and these are
global spatial structures and local spatial structures.
Spatial structures may also have spatial properties.
Spatial properties describe qualities that are defined in terms
of the display space. For example, in the scatterplot the
position of points is used to convey information. This
information is interpreted in terms of the abstract space
defined by the x and y axis. The spatial properties used for
presenting information include position in space, scale in
space and orientation in space.
There are some obvious points to make. Firstly these
spatial concepts applied to the auditory sense are not as

intuitive as the application of the same concepts to the visual
sense. There are also a much greater number of examples of
spatial metaphors to be found in the field of visualisation.
This is probably not surprising as hearing is predominantly
temporal and one would assume it is more adept at identifying
temporal rather than spatial relationships [2].
The auditory display space is continuous and can be
designed to display quantitative, ordinal or nominal data.
However, auditory position is not a very accurate way of
representing data [9]. To overcome this problem a categorical
subdivision of the auditory display space is more appropriate.
A number of areas of the auditory design space have not
been explored. These include the use of distorted and
subdivided space. Hence there are possible opportunities for
developing new types of auditory designs. In particular,
adopting strategies from the better explored domain of spatial
visual metaphors could lead to new types of auditory
displays. In terms of spatial properties, the problem of
accurate identification of auditory position suggests that other
auditory spatial properties, such as auditory scale and
auditory orientation are not recommended for displaying
information.
The scale of a sound is a good example of a less intuitive
concept for sound. However, it has been suggested real sound
sources are rarely point sources and usually have some scale
or extent to them [10]. For example, the sounds of wind or the
ocean waves have a size, although rarely is the auditory scale
or for that matter auditory orientation ascribed much
importance.
Perhaps the least intuitive from an auditory perspective
are the concepts of auditory structure. A fundamental problem
with auditory representations is that sounds are transient and
so do not provide an external representation on which the
person can form a spatial mental model [10]. Kramer notes
that the edges of an audible object are defined when a sound
appears to move from one location to another or the subject
moves through the sound [1]. For a subject to scan a single
object or to look back and forth between objects is a simple
task visually but judging spatial extent by listening to
multiple sounds moving from edge to edge is not [1]. Despite
this there have been some investigation into displaying spatial
structure using sound 11]. The intuition is that spatial
properties are not as effectively displayed to a temporal sense
like hearing as they are when displayed to a spatial sense like
vision.

4. Direct Metaphors
In the real world a great deal of useful information is
perceived directly from the properties of sights and sounds.
For example, a sound may have a certain loudness or pitch.
Objects in the real world may be recognised on the basis of
visual properties such as colour or lighting. Real world
information is often interpreted in terms of properties like
pitch and colour. Abstract information can also be interpreted
in terms of these direct properties.

Proceedings of the Eighth International Conference on Information Visualisation (IV’04)
1093-9547/04 $ 20.00 IEEE

An important distinction between spatial metaphors and
direct metaphors is that direct metaphors are interpreted
independently from the perception of space. While the
concepts of spatial metaphors apply generally for each sense
this is not true for direct metaphors. There is very little
intersection, for example; between the low level concepts of
direct visual metaphors and the low level concepts of direct
auditory metaphors. This is not surprising as direct metaphors
relate to the properties that the individual sensory organs can
detect.
Direct metaphors are concerned with direct mappings
between the properties perceived between each sense and
some abstract information. Direct metaphors are described
using the following design concepts: spatial structure and
direct properties (figure 3).

Direct
Visual
Metaphors

Direct
Metaphors

Direct
Auditory
Metaphors

Direct
Haptic
Metaphors

Visual
Spatial
Structures
Direct
Visual
Properties
Auditory
Spatial
Structures
Direct
Auditory
Properties

Haptic
Spatial
Structures
Direct
Haptic
Properties

Visual Texture
Direct Visual Shape

Colour

Hue
Saturation
Intensity (grey scale)
Loudness
Pitch

Musical
Properties

Timbre

Everyday Properties
Synthesis Properties
Force
Haptic Surface Texture
Direct Haptic Shape
Compliance
Friction
Weight
Vibration

Figure 3 The general concepts that describe Direct
Metaphors
Spatial structures are a component of spatial metaphors
that can be used to convey information. These structures can
be encoded with additional information by using a directly
perceived property of any sense. For example, colour can be
used with a visual display or pitch with a sound display.
The key component of direct metaphors is the direct
property used to convey the information. In terms of design,
the effectiveness of a direct metaphor is independent of the
display space and the spatial structure. However, in some
cases there needs to be consideration for the size of the spatial
structure. For example, while sound is generally associated
with a point source, very small areas of colour may not be
visible to the user.
The ability to accurately interpret direct properties varies
between senses and properties. In general, the perception of
all direct properties is of insufficient accuracy to allow
accurate judgement of quantitative values [9]. This suggests
that direct properties should only be used to encode ordinal or
nominal categories of data. Because direct properties such as
colour or pitch are continuous they can easily be mapped to
continuous data. However, it should never be assumed that a
user is capable of interpreting exact data values represented as
direct properties.

The MS-Taxonomy distinguishes between direct visual
and direct auditory metaphors. At a low-level of the
hierarchy, the concepts do not abstract across the senses
(figure 3). This makes it difficult for direct metaphors to be
directly compared between senses. For example, it makes
little sense to compare the ability of the visual and auditory
sense at judging the pitch of sounds. However, at a higher
level, the concept of a direct property does apply across the
senses. Therefore at a conceptual level the designer can
consider substituting one direct property with another. For
example, the direct visual property of colour could be
substituted with the direct auditory property of pitch for
representing categories of data.
Direct visual metaphors use direct mappings from the
attributes of data to the perceived properties of sight. These
properties include colour hue, colour saturation and visual
texture (figure 3).
Using direct visual properties to represent information
has been well studied. Bertin described the basic properties of
visual objects as retinal properties [3]. Bertin's retinal
properties include the scale and orientation of objects. These
concepts are dependent on the visual space and so are
included in the MS-taxonomy as visual spatial metaphors.
However, Bertin's other retinal properties are all concepts
within direct visual properties. They are: colour-hue; coloursaturation; colour-intensity (grey scale, value); visual texture
and direct visual shape.
Direct auditory metaphors use direct mappings from the
attributes of data to the perceived properties of sound. The
use of direct auditory properties for representing abstract data
is a relatively recent field of study. Many of the perceived
properties of sound are not well understood [12]. The direct
auditory properties are less generally agreed on than the
retinal properties of Bertin [13]. The commonly used
properties of sound include loudness, pitch and timbre. These
direct auditory properties have also been referred to as
musical properties [14]. The direct auditory properties are not
independent or orthogonal. For example, the pitch of the
sound affects the perceived loudness of the sound [9].
Furthermore, both pitch and loudness are not equally
prominent to the listener [15].

5. Temporal Metaphors
In the real world a great deal of useful information is
dependent on the perception of time. For example, a
pedestrian crossing a busy road is required to interpret the
amount of time between vehicles. The rate and frequency of
traffic may also impact on the pedestrian's decision of when
to cross. Temporal concepts like duration, rate and frequency
can also be used to encode abstract information.
Temporal metaphors relate to the way we perceive
changes to pictures and sounds over time. The emphasis is on
interpreting information from the changes in the display and
how they are positioned in time. Temporal metaphors are also
closely related to both spatial and direct metaphors. For

Proceedings of the Eighth International Conference on Information Visualisation (IV’04)
1093-9547/04 $ 20.00 IEEE

example it is the changes that occur to a particular spatial or
direct metaphor that encodes the information.
Of course all the senses require some amount of time to
interpret a stimulus. This is very fast for vision, while with
hearing most sounds are more prolonged events with some
temporal structure. Even a single sound event, such as a bottle
breaking, contains a complex temporal pattern that is
perceived over a short period of time. The MS-Taxonomy
does not try to resolve this ambiguity except by noting that
the intent of temporal auditory metaphors is on how the
changes that occur in sound events are used to represent
abstract information. That is, the focus with temporal
metaphors is how temporal changes convey information.
They therefore directly involve the user's perception of events
in time.
The MS-Taxonomy distinguishes between temporal
visual and temporal auditory metaphors. However the general
concepts that describe temporal metaphors are independent of
sensory modality (figure 4). It is simply the ability of each
sense to perceive changes over time that need to be
considered. Because the concepts abstract across the senses it
is possible for temporal metaphors to be directly compared
between senses. For example, the ability to identify a visual
alarm event can be compared with the ability to identify an
auditory alarm event.
The design space for temporal metaphors can be
described using the following general concepts: the display
time; an event and temporal structure (figure 4).
Temporal metaphors are composed of events that occur
within the display time. The display time provides the
temporal reference for the data events that are displayed. This
is analogous to the way a metronome is used in music to
provide a background measure of time. The display time is
not usually considered as part of the design space, but simply
assumed to be constant. However, it is possible to consider
the display time during the display design. For example,
distorting the display time could speed up or slow down the
rate at which data is displayed.
Events have two main properties, the event time and the
duration of the event (figure 4). Both the event time and event
duration are interpreted in relation to the display time. These
events affect changes to the visual or auditory display. It is
these changes and the timing and duration of these changes
that are interpreted by the user as information. An event can
affect a change to the display space, a spatial property, the
spatial structure or a direct property in the display. This
allows events to be categorised by reusing many of the
concepts described for spatial metaphors and direct
metaphors. The MS-Taxonomy defines the following types of
event; a display space event; a movement event; a transition
event and an alarm event.
Display space events cause a change to the perceived
display space. For example, a distortion event can change the
metric at a location in the display space. A navigation event
can affect a change in the user's position in the display space
and is usually associated with user interaction.

Movement events are related to changes in spatial
properties of structures and can be characterised by properties
such as direction, velocity and acceleration (figure 4). Distinct
types of movement events include; translation events, rotation
events and scale events. Translation events involve a change
to the spatial property of position. Rotation events involve a
change to the spatial property of orientation. Scale events
cause a change to the spatial property of scale.
Display
Time
Duration
Event Time

Event

Movement Event

Velocity
Direction
Acceleration
Translation Event
Rotation Event
Scale Event

Temporal
Metaphors

Display Space Event

Distortion Event
Navigation Event

Transition Event
Alarm Event
Temporal Artefacts
Temporal
Structure

Rate
Rhythm
Variation

Figure 4 The general concepts that describe
Temporal Metaphors
The other types of events are transition events and alarm
events. Transition events cause a slow change to either spatial
structures or direct properties. By contrast alarm events cause
a very sudden change to either spatial structures or direct
properties.
A user may interpret information based on a single event.
For example, a visible object changing position may be
interpreted in terms of the old position and the new position,
as well as the speed of movement. However, information may
also be interpreted based on patterns that occur in a sequence
of events. This is described as temporal structure. Types of
temporal structure include the rate of events, the rhythm of
events and the variations between events.
The concepts of temporal metaphors are intuitive when
described for the auditory sense. This is not surprising as
hearing is usually identified as a temporal sense [2]. Indeed
many of the concepts described in temporal auditory
metaphors have been developed within the field of music.
Indeed much work in sonification domain has been based on
this assumption [16, 17, 18, 19, 20].
Temporal auditory metaphors provide some advantages
over visual temporal metaphors. Sound has been identified as
a useful way for monitoring real time data as audio fades
nicely into the background but users are alerted when it
changes [21].
Kramer makes many other useful observations about
sound [1]. Other objects do not occlude sounds. Therefore, an
object associated with the sound does not have to be in the
field of view for the user to be aware of it. Sounds act as good

Proceedings of the Eighth International Conference on Information Visualisation (IV’04)
1093-9547/04 $ 20.00 IEEE

alarms and can help orientate the user’s vision to a region of
interest. Because of the high temporal resolution of the
auditory sense, sounds can often be compressed in time
without loose of detail.
One consideration with the design of temporal metaphors
is the general perception of events over time. Comparing
events or perceiving relations between events requires that
past events be held in short term memory. There is an often
quoted limit of seven on the number of items that can be held
in short term memory [22]. Another general aspect of
perception that can influence the interpretation of temporal
metaphors is known as perceptual constancy [9]. When a
slow change occurs to a sensory signal it may not be
perceived.

[4]

[5]
[6]

[7]
[8]

[9]
[10]

6. Conclusion
This paper has introduced a categorisation of the multisensory design space called the MS-Taxonomy. This
taxonomy is not based on sensory modalities but rather on
high-level information metaphors. The MS-Taxonomy
describes three general classes of metaphors called spatial
metaphors, direct metaphors and temporal metaphors. The
contention is that this conceptual framework better allows
display mappings to be transferred and compared between
sensory modalities.
Most importantly for designers, the taxonomy is defined
at multiple levels. At the higher levels the classes are abstract
and general and thus they apply for all senses. However,
detail is not sacrificed and at the lower levels the taxonomy is
comprehensive, allowing display mappings to be described to
the level of a single perceptual unit. Thus using these
metaphor classes allows the designer to work with concepts
that are suitable for both overview and detail. These two
levels of work have previously been described as fundamental
modes of operation in software design [7]. In software
engineering terms the MS-Taxonomy allows a designer to
consider reuse of designs at an abstract architectural level and
also a more detailed component level.
The MS-Taxonomy aims to provide a structured model
of display concepts. While it generally succeeds, there is no
doubt that some concepts (such as auditory scale) are unusual.
Refining the MS-Taxonomy, especially at the lower level is
the subject of further research.

References
[1]
[2]

[3]

G. Kramer, An Introduction to Auditory Display. AddisonWesley Publishing Company. 1994. pp. 1-78.
D. Friedes, “Human Information Processing and Sensory
Modality: Cross-Modal functions, Information Complexity,
Memory and Deficit.” Psychological Bulletin 81(5): 284-310.
1974
J. Bertin. “Graphics and Graphic Information Processing”.
Readings in Information Visualization. S. K. Card, J. D.
Mackinlay and B. Shneiderman. San Francisco, USA, Morgan
Kaufmann, 1981. pp. 62-65.

[11]

[12]

[13]

[14]

[15]

[16]

[17]
[18]

[19]

[20]

[21]

[22]

Proceedings of the Eighth International Conference on Information Visualisation (IV’04)
1093-9547/04 $ 20.00 IEEE

M.M. Blattner, D. Sumikawa, et al. “Earcons and Icons: Their
Structure and Common Design Principles.” Human Computer
Interaction 4(1). pp. 11-14. 1989.
W. Gaver, “Auditory Icons: using sound in computer
Interfaces.” Human Computer Interaction 2: 167-177. 1986.
S. Barrass, “Sonification Design Patterns” Proceedings of the
2003 International Conference on Auditory Display, pp. 170175. Boston, MA, USA. 2003.
W. S. Humphrey. “A Discipline for Software Engineering”.
Boston, Addison Wesley. 2000.
K. Nesbitt. “Designing Multi-Sensory Displays for Abstract
Data”. Information Technology, Science. Sydney, University
of Sydney. 2003.
R. Sekuler and R. Blake, “Perception”. McGraw-Hill
Publishing Company. New York, USA. 1990.
A. J. Hollander and T. A. Furness III, "Perception of Virtual
Auditory Shapes". International Conference on Auditory
Display, Santa Fe, New Mexico. 1994.
D. J. Bennet and A. D. N. Edwards, “Exploration of Non-seen
Diagrams”. International Conference on Auditory Display,
Glasgow, UK. 1998.
T. M. Madhyastha and D. A. Reed, “A Framework for
Sonification Design”. Auditory Display: Sonification,
Audification and Auditory Interfaces. G. Kramer, AddisonWesley Publishing. XVIII: 267-290. 1994.
M. M. Blattner, A. L. Papp III, et al. “Sonic Enhancement of
Two-Dimensional Graphic Displays”. Auditory Display:
Sonification, Audification and Auditory Interfaces. G. Kramer,
Addison-Wesley Publishing Company. XVIII: 447-470. 1994.
W. W. Gaver, "Using and Creating Auditory Icons". Auditory
Display:Sonification, Audification and Auditory Interfaces. G.
Kramer, Addison-Wesley Publishing Company. XVIII: 417446. 1994.
S. Bly, “Multivariate Data Mappings”. Auditory Display:
Sonification, Audification and Auditory Interfaces. G. Kramer,
Addison-Wesley Pub. XVIII: 405-416. 1994.
G. Mayer-Kress, R. Bargar, et al. “Musical Structures in Data
from Chaotic Attractors”. Auditory Display: Sonification,
Audification and Auditory Interfaces. G. Kramer, AddisonWesley Pub. XVIII: 341-368. 1994.
L. Grégory and S. Brewster, "An Investigation of Using Music
to provide Navigation Cues". ICAD, UK, 1998.
P. Vickers and J. Alty, “Towards some Organising Principles
for Musical Program Auralisations”. ICAD, Glasgow, UK,
1998.
S. K. Lodha, D. Whitmore, et al. "Analysis and User
Evaluation of a Musical-Visual System: Does music make any
difference?" International Conference on Auditory Display,
Atlanta, Georgia, USA. 2000.
Q. T. Tran and E. D. Mynatt, “Music Monitor: Dynamic Data
Display”. International Conference on Auditory Display,
Atlanta, Georgia, USA. 2000.
J. Cohen, “Monitoring Background Activities”. Auditory
Display:Sonification, Audification and Auditory Interfaces. G.
Kramer, Addison-Wesley . XVIII: 499-534. 1994.
G. A. Miller, “The Magic Number Seven, Plus or Minus Two:
Some Limits on Our Capacity for Processing Information.”
Psychological Review 63: 81-97. 1957)

