Interacting with real objects in virtual space
John Counsell
UWE, Bristol
john.counsell@uwe.ac.uk
Abstract
While much has been made of the potential of Virtual
Reality, VR is one end of a spectrum. ‘Augmented Reality’
requires that the virtual vision be accurately
superimposed on the real, with matching shading, which
remains a technical challenge, or that real objects are
accurately located in virtual space. A step change seems
now to be occurring in this latter.
This paper reviews some of the opportunities and
issues that are likely to arise from the use of new location
and detection technologies in buildings and building
construction, and in the virtual representation of the realtime movement and location of these objects. These new
tools for remote monitoring and representation are just
emerging from Pandora’s box. It is argued that standards
are needed to ensure their proper use, and to ensure that
the remote representation does not imply greater
accuracy than can be measured.

1. Introduction
While much has been made of the potential of Virtual
Reality, particularly for training and simulation, VR is
just one end of a spectrum. It is easier to create an entire
digitally modelled immersive virtual environment than to
successfully fuse the virtual and the real, since
‘Augmented Reality’ requires that the virtual vision be
accurately superimposed on the real, with matching
shading, which remains a technical challenge, or that real
objects are accurately located in virtual space. A step
change seems now to be occurring in the latter.

1.1. Analogic Interfaces
In 1979, in a perceptive vision of the future, Bateson
described the increasing use of analogic interfaces with
the virtual. He pointed out that" one of the ironies of the
digital revolution is that as more and more media go
digital, the means by which people interface with these
media are becoming increasingly analogic in form. The
desktop metaphor, digital gloves and body suits, the
increasing mix of how we interact with digital systems:
all are movements towards a powerful user illusion based
on an analogy with a familiar world of objects located in
space. Cyberspace is digital but the way we interface with
the digital computer systems that mediate our use of
cyberspace still depends on analogy.”[1] There is a strong
inference that such familiar analogies make people more

comfortable with the virtual world and thereby aid
understanding.
Familiar analogies are becoming both increasingly
real and diverse. For example, VRML, the ISO standard
for 3D on the web, was prophesied to become a more
natural and intuitive interface than HTML based text,
particularly for portals to virtual shopping malls and the
like. Interactive real-time 3D models of new buildings
have been proposed for use beyond the design and
construction phase in a cradle to grave role of facilities
management, and even demolition management. In one
facet of Facilities Management they would be interfaced
to the actuators of the building management system, using
a virtual model as the means of controlling ventilation,
temperatures, and even opening windows and doors.[2]

1.2. Ubiquitous Computing
In a similar vein Hewlett Packard have been
developing the Cooltown project,, which researches
infrastructure and applications for nomadic computing
systems—ubiquitous systems in which people move about
while using portable devices to access services and
applications integrated with the physical world. In the
Cooltown world “beacons broadcast a URL for the object
or place, pointing you to a web presence providing
product information, entertainment, advertising, or a
gateway to e-services for the item or the location.
Capturing information from a beacon on your mobile
device is like bookmarking the physical world. In effect,
your pocket device becomes a remote control for the
world-at-large.”[3] This implies an interface free unconscious interaction with the virtual world in which
presence or proximity, actions or profile trigger a
computer event such as a service. While there are clearly
many occasions where people would wish service to be
intuitive unobtrusive and automated, complex issues to be
discussed with others may be better served by analogic
interfaces that aid understanding of the virtual model and
real consequences. This paper is focused on the often
highly complex interface issues that arise on construction
sites, but similar circumstances arise in many other
industries.

2.0. 2D Drawing Instructions on Site
The new code on production information[4] states ‘to
date, the construction industry has, in the main, used
computer hardware and software to improve the

Proceedings of the Eighth International Conference on Information Visualisation (IV’04)
1093-9547/04 $ 20.00 IEEE

presentation of drawn information, but the potential to
improve the underlying quality of the information has
been under exploited.’[5] A CIOB workshop, in 2003 - 5
years after Egan, is still demanding that 'more time should
be taken to inform those working on site about the end
product that they are helping to produce.'[6] The code
also claims that alteration and repair work (a significant
part of construction activity) is often best described rather
than drawn in detail, from which one may infer that
procedural descriptions are often more useful than drawn
end states. and that there is a need for more appropriate
information and more effective interfaces to inform those
working on site.[7]
Yet the majority, perhaps 78%[8], of the use of
building related CAD is still as layered 2D digital
drawing, generating multiple paper sets for use by site
personnel and sub-contractors. This is predicted to
continue for at least the next 5 years by the new code.
(That is in stark contrast with GIS where users share
digital access to common data and cartography is a
separate specialist process.) 2D drawn construction
information contains inherent ambiguities and uses a
technical and thus ‘exclusive’ language. Many of the
problems that arise on construction sites continue to be
traceable to drawing errors and ambiguities, particularly
in dimensions. Knowledge on site is acquired from a mix
of previous experience, end-state drawings, annotation,
and specification clauses re workmanship. Consequently
some construction staff rely on experience to build, as
much as on construction drawings. It is often the case that
drawings are difficult to use out on site, and so are studied
in advance in the site hut or foreman's office. Light levels
are often not high enough on site to read drawings in
situ.[9] This can also lead to additional errors, for
example Westbury site staff were found to ignore detailed
drawing changes because they built from memory of
previous similar house-types.[10]
The problem is
compounded when changes are implemented on site,
since as-built records are inherently difficult to acquire
and maintain. [11]

3.0. New Interfaces to Work on Site
Over 20 years ago Professor John Frazer developed a
Lego-like digital interface to enable users to plan their
houses. Moving the lego boards on the base board
manipulated the digital house model on the computer
screen. Development of what they now term ‘Tangible
User Interfaces’ has continued since. ‘TUIs (Tangible
User Interfaces) offer natural means of interaction with
computers and have already been shown to simplify
existing computerized applications and offer solutions
for tasks that were considered to be “out of the scope”
of human-computer interaction’.[12]
One of the areas where there is a demand for this
amalgam of digital modelling and simulation fused with
information is in planning change in the built
environment. Moves have been made to foster greater
community involvement in planning and thus ownership
by the community of the outcomes. In the UK this has
been termed ‘planning for real’. To avoid the problems

posed by the arcane language of maps and drawings, most
of the research and development in this field has been in
the use of physical models that the community manipulate
in order to discuss and develop their views. More recently
however ‘Tangible User Interfaces’ have begun to be
developed for this purpose.
“Some markers representing virtual objects, such as
an office building, a parking lot, a residence or a gym, are
put on a big table. Several users wearing wearable
computers and HMDs[13] look at the big table. Users see
graphic images of the virtual objects superimposed on the
associated markers through the HMDs. The users can
discuss the design of the campus and relocate any
facilities either by moving the marker associated with the
facility to a new location, or by translating or rotating the
virtual objects through user interfaces such as keyboard
and mouse. Those pose changes of one user will be
distributed to the other users through a wireless connected
server. The other users will be able to see the virtual
objects in a changed position.”[14]
Up to now the development of tangible user
interfaces has been focused on manipulating virtual
models that only represent facsimiles of reality. For
changes that result from these community-planning
exercises to be implemented on the ground there has still
been a further conventional stage of communicating and
realizing the proposals, often using 2D drawings.

3.1. Full size interfaces
Virtual Reality (VR) based interaction with building
models has developed but is still largely confined to
increased collaboration at these design and project
planning stages. Thus also augmented reality research
projects are largely limited to the superimposition of
schematic networks on existing buildings. While some
research indicates visual health risks from prolonged use
of head up displays, in fact the major barrier is likely to
be the hazardous nature of building sites themselves,
where obscured vision of any sort is likely to pose risk.
There is also some evidence that augmented reality, as a
real-time overlay of virtual instructions during
performance of a task, may be a distraction rather than an
asset, causing fulfillment of the task to take longer.[15]

3.2. RFID
In the ‘Hitch-hikers Guide to the Galaxy’ Adams
describes all-powerful multi-dimensional beings whose
manifestation in our reality is in the form of tiny white
mice – “protrusions into our dimension of hyperintelligent pan-dimensional beings”[16]. The latest
emergent technology to become mature is that of radio
frequency ID (RFID) tags, the closest step yet to the
disposable computer, to suit the throwaway needs of the
consumer society. The new wave of development and
adoption of RFID is creating an analogous real-time
representation in the digital world of tiny beacons
representing real world objects. Their cost is steadily
declining and already some tags are less than US$ 0.2.
Printable antenna have been developed so that complete

Proceedings of the Eighth International Conference on Information Visualisation (IV’04)
1093-9547/04 $ 20.00 IEEE

tags can be printed onto packaging, and a wide range of
other variants are now available for many different uses
and applications. Some of these ‘beacons’ are being used
to locate the objects in three-dimensional space, not just
track their movement from factory to shelf to purchaser.
Both the US Dept of Defence, and Walmart have
announced programs whereby all their principal suppliers
will be using RFID to track consignments within the next
two years.[17] There is now increasing use of RFID tags
to monitor the movement and location of key components
in many industries, including construction, as the cost of
the tags and readers fall. Use on construction sites has for
example been proposed for automated measurement of
the construction process, but it is not yet widespread.
Familiar objects are starting to populate virtual space in
an increasing fusion of the real with the digital world.

You, Suya, Neumann, and Azuma effectively
summarized the issues and the argument for hybrid
solutions as: “The signal sensing range of as well as manmade and natural sources of interference limit activetarget systems. Passive-target systems are also subject to
signal degradation, for example poor lighting or proximity
to steel in buildings can defeat vision and compass
systems. Inertial sensors measure acceleration or motion
rates, so their signals must be integrated to produce
position or orientation. Noise, calibration error, and the
gravity field impart errors on these signals, producing
accumulated position and orientation drift. Position
requires double integration of linear acceleration, so the
accumulation of position drift grows as the square of
elapsed time. Orientation only requires a single
integration of rotation rate, so the drift accumulates
linearly with elapsed time.”[21]

3.3. Antecedents for RFID location
3.4. Location Detection
The basis for these uses of RFID technologies is not
as new. The mobile phone is an example of detection of
wireless id’s within a cell, so that the location of the user
is known, and with increasing demand in dense urban
areas pico cells will provide significantly enhanced
positioning. More sophisticated ‘beacons’ detect location
by vector and signal strength or the time taken in
reflecting a pulse. Overlapping beacons can detect
location by triangulation of vectors. Broadcast and
reception signals measured in these ways include both
light and sound, laser, infrared, and acoustic signals as
well as wireless.
The Olivetti infrared based Active Badge system,
available in the late 1980's, was proposed as a means of
detecting whether people were available to speak on the
phone on the premise that if alone in the room they were
available, if in the company of others they were in a
meeting.[18] Although only useable in line of sight
situations it was experimented with quite extensively and
only stopped being used[19] to track staff in Olivetti’s
research labs when widespread use of personal mobile
phones provided a satisfactory alternative to using a
building based computer system that knew the location of
the person being called.
In a research project funded by HP at the Exploratory
in Bristol, Priscilla Heard of UWE, with colleagues, used
a combination of infrared active badges to locate users by
exhibits, and mobile phones to deliver audio information
about the exhibit, that became more detailed the longer
the user lingered to listen. Part of the research was into
the usability and part into ways of structuring audio
guidance in multi-layers from sound-bites to
expositions.[20]
Each technology is more or less constrained by
obstructions and capable of confusion by reflections. For
greatest accuracy a hybrid mix of these signal
technologies is likely to be more reliable. Several other
tracking technologies are often put forward, from inertial
tracking to electronic compasses, perhaps combined with
video servoing, measuring the occlusion between
overlapping pairs of images, feature matching with
reference images, and even feature recognition.

Location detection is key to self-guided robotic tools,
but is yet to be usefully applied to detecting the position
of people, plant, and resources on site to automate the
capture of project based knowledge. This is almost
certainly because the location technologies outlined above
are still in development, there is no one emergent low cost
solution that dominates other than RFID. While it is
possible to locate RFID tags in zones or rooms or on
passing through portals relatively cheaply other precise
location technologies are needed to scan and to locate tags
in ad-hoc situations such as assemblies of construction
components. These technologies are significantly more
expensive and currently may need to include inertial
tracking. However RFID and other tagging and real-time
location technologies promise to be able to locate
components (and personnel) as they are moved on site in
real-time. Such systems may thus begin to provide an ICT
feedback mechanism that detects progress, monitors for
mistakes, and captures project-based knowledge for reuse
on the next project.

3.5. Arguments for real-time monitoring
The ‘Accelerating Change’ study[22] argues for the
tracking of goods and materials through the supply chain
from manufacture to the point of use. The Think 2010
conference[23] also identified a need to ‘define
mechanisms to identify and capture project based
knowledge AND make it available to future projects.’[24]
Navon and Goldschmidt argue that real-time control
of on-site construction, based on high-quality data, is
essential to identify discrepancies between ‘‘desired’’ and
actual performances. They state that the longer it takes to
identify discrepancies, the more serious the potential
damage is and the more complex and costly corrective
measures will be. They argue that monitoring and
measuring construction as it happens is essential, and
adduce support for this from the BRE and many large
construction organisations including including Bechtel,
Morrison Knudsen, Fluor Daniel, Cianbro, and Pizzagalli
Construction. These companies currently use bar code

Proceedings of the Eighth International Conference on Information Visualisation (IV’04)
1093-9547/04 $ 20.00 IEEE

technology for materials management, time and
attendance, tool and capital equipment tracking and asset
management. They discuss the use of RFID for tracking
personnel on site in real-time. "Knowing the worker’s
location at a given time, his/her craft and candidate
activities for a given day, the activity he/she is working
on can be deduced. Consequently, a potential indirect
parameter can be the worker’s location." They then
propose a system of RFID-based portals to monitor
movement around the site because of the problems of
obstructions to the radio waves.[25]

3.6. Monitoring Efficiency
Construction Confederation chairman Alan Crane,
who heads the Egan working group looking at
performance measurement, argues that contractors should
assess their performance using a set of "key performance
indicators" and then publish the results on a common
database and compare the findings with their peers. This
argument is extended to monitoring work efficiency on
site.[26]
F. B. Gilbreth analysed efficiencies in brick laying
around in the late 19th century and developed an abstract
system of notation for motion study still used today. Both
the BRE Calibre approach and that developed by S.
Slaughter[27] at MIT still rely on similar abstract notation
by observers, depending on training for consistency, and
subsequently computerised for efficiency analysis of
future projects. Calibre observers both note and use
digital cameras to record what each operative is doing to
which element or work package, where each task is being
carried out, and who each operative is; is in order to
identify how much time spent adds value.
Slaughter's team studied 12 processes: installing
structural steel, wood framing, cast concrete, glass or
metal
curtain
wall,
hot-water
heating,
heating/ventilation/air conditioning, fire protection,
plumbing, electrical wiring, interior stud walls, and
ceilings. They created a detailed computerized simulation
of each part of the construction process. That gave them a
baseline, confirmed by industry specialists as realistic,
from which to measure the effects of changing basic
materials
or
methods.
"It's a decision support system," she says. "The computer
keeps track of all those little things that you can't hold in
your head" every time you want to measure the impact of
a design change or a materials substitute on the
construction process.[28] However this is most useful at
the construction planning stage, and has yet to take a form
where it is suitable for instruction personnel at the
workface.
There are powerful arguments for real-time
monitoring of the location of staff, tools and plant, and
components on site, and the technologies are becoming
increasingly affordable. RFID tags can already be used to
track people and objects passing through portals more
affordably and in similar ways to the Olivetti Active
Badge. Number plate recognition accuracy has improved
to the point of commercial success, and enormous effort is
being made by security and defence organizations in real-

time facial recognition and tracking using CCTV. It only
takes two live video camera/computer systems to jointly
‘recognise’ a face to then calculate vectors and position.
Inertial tracking technologies are also becoming
affordable.

3.7. Issues of Privacy and Consent
Tracking people already takes place in real-time, but,
so far, this data is not publicly accessible. Nevertheless
mobile phones ring when switched on and within a cell.
Indications are that the UK data protection registrar has
accepted that while names and addresses are protected,
this does not apply to or cover the mobile phone devices,
their numbers, trajectories, or transactions. Protocols are
needed to cover real issues about privacy and consent
that, if mishandled, could easily exceed in fury the debate
that took place when it was proposed to put “spy in the
cab” tachographs into HGV cabs. It will also be necessary
to determine when it is appropriate to de-activate tags,
and this is the current focus of the privacy lobby in the
use of these tags for retail.

4.0. More Interactive Potential
There are likely to be a range of location-based needs
on construction sites. Current RFID technologies such as
checkpoint portals may suffice for many. Closed boxes on
palettes are already scanned in this way to generate virtual
parts lists, and shelves scanned for virtual inventories.
Intermittent mobile scanning may be enough to usefully
check locations for other items, and this will depend on
the cost and portability of the scanner, together with the
scanning distance that is the limitiation of the specific
type of tag. In general more expensive active tags can be
read at greater distances, but depend then on batteries, for
which life is limited. However real time detection is going
to be important for undertaking task analysis.
When the technologies mature it may be necessary to
distinguish between different forms of interaction such as:
object to object; object to virtual representation; tool to
object; object to person; and person to person. Other
choices that already arise are when it is most appropriate
to use live tags or passive tags; spectrum; noise; and
bandwidth.

4.1. Object to Object - meeting and mating
Many assembly situations occur on site for which flat
pack assembly of furniture is a useful analogy. RFID
offers the potential of moving beyond just checking that
the parts are all in the packing at purchase, to assisting in
the assembly process. Checking the correct mating of
parts requires peer to peer communication, what Nokia,
Sony and Philips have termed the 'magic touch',[29] or
highly accurate location detection, not yet easily
achieved. Currently RFID is based on detection of the tag
by a transponder, rather than on detection by the
transponder of the proximity or contact of two tags. Thus
one can expect first that transponders are embedded in
tools that check correct assembly, but the longer term

Proceedings of the Eighth International Conference on Information Visualisation (IV’04)
1093-9547/04 $ 20.00 IEEE

indications are that RFID can be used to detect
appropriate proximity or contact between two devices.
"Kit-of-parts architecture involves organizing the
millions of individual parts and raw material in a building
into assemblies of standard easy-to-manufacture
components, sized for convenient handling or according
to shipping constraints."[30]
Not everything is an assemblage of parts. Other
technologies are needed to measure whether a concrete
pour has reached the planned level for example. These
other technologies may include the calculation of position
from the overlap of common objects in two real-time
video images.

4.2. Person to Object - real-time instruction
Given accurate detection of the focus of the
construction person it may also be possible to deliver
useful audible task based prompts and information, to
supplement prior study of for example a VR simulation
on a mobile screen. After construction is complete
buildings become like Corbusier's machines for living in,
machines that require regular service and occasional
repair. Maintenance management requires similar
assistance to that for instructing construction workers on
site: guidance about when to go; where to go – wayfaring;
what to do – lubrication and/or (dis)assembly,
replacement; recording presence - (security personnel
swipe cards to record a visit to a room); and recording
that the task has been completed satisfactorily. Systems
exist for every aspect of these tasks, but are not yet
integrated or using a common technology and standards
such as RFID and location detection. The COMIT project,
a consortium led by Arup, has recently published a survey
of these dis-integrated systems and applications in current
construction and maintenance use.[31]

4.3. Person to Person - close encounters
In further developments a situation can be envisaged
where two people, one disabled and one able-bodied,
enter a room, both wearing tags that invoke their user
profile. This data is read, as they approach the door, by
the Building Management System, which either finds the
most appropriate compromise between their requirements,
or possibly gives priority to the needs of the disabled user.
To go further in inducing information about people in the
company of others (as was trialled with Active Badges)
requires more sophisticated detection of the location of
each (to calculate proximity), orientation (are they facing
each other?), and stance, (is one seated and working at a
desk?). While RFID alone may not be able to satisfy these
additional locational cues, technologies such as the
gyroscope on a chip from BAE (for location),
accelerometers or marker-less detection systems (for
stance and movement detection), and electronic
compasses (for orientation) can be added to create a more
comprehensive wearable real-time location system.[32]

5.0. From Tag to Virtual Representation
There is significant evidence from GIS that shows
visual perception to be a useful tool in understanding
complex patterns of movement and interaction. At one
time Olivetti Active Badge systems held real-time data
about interactions between people and objects. With the
advent of mobile phones this data still exists, is now far
more widespread, but is held by the mobile phone
companies. RFID and other tagging and location
technologies are already building new variants of this
real-time data. Standards need to be developed to
determine how people, objects and tools will be depicted
in the virtual representations that reveal patterns of
movement and activity to managers. For example will
people be represented by avatars as in shared VR
community spaces, or in more symbolic forms? If people
are represented will it be possible to identify individuals
from their context, their profile, their actions or their
representation? If so what assurances about privacy will
be necessary to gain their consent to being monitored?
One can assume that a 3D VR representation of a
building is available for use from CAD, but that the
moveable objects such as furniture, phones, documents,
could all be tagged and revealed in real-time to a manager
studying the VR scene to evaluate efficiencies. RFID is
only just achieving critical mass and there are still many
conflicting standards, while interoperability of the tagged
unique Ids for objects is still subject to proprietary
competition between manufacturers. Contractor’s or their
site staff cannot yet refer to a manufacturers database to
find the meaning of the codes with certainty. Equally such
codes cannot yet link to the CAD objects that instigated
their procurement. However it is almost inevitable that
such links and standards will develop. There are accepted
and even international standards for some symbols and
icons. However these are usually for objects too small to
show at full size in conventional technical drawings, and
are usually two-dimensional. This does not necessarily
make them suitable for re-cycling to represent similar
perhaps mobile objects in VR environments. For items of
furniture many CAD libraries now hold 2D symbolic plan
representations and fully photo-realistic and even VR
objects. However in CAD or VR environments the
orientation and relative positions of these objects is
known. It may be highly misleading to use the photorealistic 3D representation of for example a chair in a
specific orientation when the data from RFID only
confirms its current presence in a room, and not where in
the room it is or its orientation. There are situations where
orientation can be induced, such as for example if all
bricks in a wall are tagged, their relative arrangement can
be assumed to be inter-locking bonding. However while
this may usually be the case, there are going to be
situations where they are stack bonded, and photorealistic representations of what has been scanned as lying
concealed behind plaster may be quite misleading.
Equally these representations may need to visually
display the type of tag, whether active and needing battery
replacement, or passive, and other data that arises from
the location detection technology in use. New ways of

Proceedings of the Eighth International Conference on Information Visualisation (IV’04)
1093-9547/04 $ 20.00 IEEE

representing real objects in virtual spatial representations
need to be developed that can accommodate fuzziness
about orientation and accurate location.

Conclusions
There is a need to capture the process and positions
of personnel, plant and components undertaking the tasks
on site in order to either adequately simulate, or to
instruct less skilled personnel. Detailed simulation of
personnel and plant is not at the moment part of a CAD
design system, although the 'bolt-on' downstream 4D
CAD VR based project management systems have gone a
little way towards this[33]. A number of rugged new
mobile digital devices are becoming available. Wireless
connections are becoming increasingly effective. It is now
conceivable that personnel can be instructed in what to do
step by step using these devices. However the information
that is needed to instruct them is not captured or recorded

[1] Gregory Bateson. Mind and Nature a Necessary Unity.
Fontana 1979, quoted in The Cyberspace Lexicon, B Cotton &
R Oliver Phaidon 1994.
[2] http://www.navisworks.com/case_study_milltech.htm Chris
Milford of Mill Technology in Case Study by Navis Works
[3] Mpulse Magazine February 2003.
[4] Production information: a code of procedure for the
construction industry – the Construction Project Information
Committee
[5] http://www.productioninformation.org/final/S23.html
[6] http://www.cbpp.org.uk/pdf/CIOB/CIOB improving site
conditions.pdf report of CIB workshop March 5th 2003.
[7] http://www.productioninformation.org/final/S33.html
[8]Autodesk UK AEC Industry Survey of Customers 2003
[9]http://www.whichcad.com/documents/Onsite%20View%20
Case%20Study.pdf
[10] J. Counsell ‘Issues in WWW Management and Delivery of
Libraries of 3D CAD Components’ in R Amor Ed, ECPPM '98
- Product and Process Modelling in the Building Industry published by the Building Research Establishment, 1998, pp
151-160.
[11] Many documents need to be updated periodically to reflect
progress and changing project conditions.
http://vega.sunderland.ac.uk:8080/Transact/doc/Context_Awar
e_Environments
[12] Ehud Sharlin, Benjamin Watson, Steve Sutphen, Robert
Lederer, Pablo Figueroa and John Frazer ‘3D Computer Action
– Using Tangible Interfaces’ Leonardo Electronic Almanac, 9,
7 (Aug 8 2001).
[13] (Head Mounted Displays)
[14] P. Liu, N.D. Georganas “Designing Real-Time Vision
Based Augmented Reality Environments for 3D Collaborative
Applications”, Proc. Can. Conf. on Elec. And Comp. Eng.,
Winnipeg, May 2002
http://www.mcrlab.uottawa.ca/papers/Peiran_CCECE2002.pdf
[15] A.C. Boud, D.J. Haniff, C. Baber, S.J. Steiner Virtual
Reality and Augmented Reality as a Training Tool for
Assembly Tasks IV99 1999 International Conference on
Information Visualisation.
http://www.computer.org/proceedings/iv/0210/02100032abs.ht
m
[16] http://www.bbc.co.uk/cult/hitchhikers/guide/mice.shtml
[17] On-going discussion in the online RFID Journal

yet in easy to understand and suitable digital step-by-step
form. Should it become available it might significantly
reduce the need for 2D drawings on site.
It is suggested that effective implementation of realtime location of construction elements, personnel, plant
and tools, can create a full-sized ‘tangible interface’ on
site. A number of other location detecting technologies
are becoming mature, leading to a variety of applications
for real-time location and recording, which is a prerequisite to: accurate superimposition of digital
augmentation on physical reality; automated detection of
differences between digital proposal and physical
outcome; and for re-cycling as generic instruction sets for
the next project. However standards have yet to be
formulated to guide the use of these technologies and to
determine in which new ways real objects are represented
in virtual spaces for visual analysis.

References
[18]ACM Transactions on Information Systems Vol. 10, No. 1,
January 1992, Pages 91-102; Olivetti The Active Badge
System.
[19] http://koo.corpus.cam.ac.uk/projects/badges/
[20] P.F.Heard, S.A.Duvall, S.D.Johnston, ‘Can “Ears-On”
help hands-on science learning for girls and boys’; Intl Jrnl of
Science Education, Vol 22 No.11 Nov 1 2000
[21] You, Suya, Ulrich Neumann, and Ronald Azuma. Hybrid
Inertial and Vision Tracking for Augmented Reality
Registration. Proceedings of IEEE VR '99 (Houston, TX, 13-17
March 1999), 260-267.
[22] The Accelerating Change report published on 12th
September 2002 by the Strategic Forum for Construction
[23] the Think 2010 conference. BSRIA March 2003 Think
2010 - Virtual Prototyping – the final declaration by the Mars
Syndicate
[24] Dr M A P Murray ‘An Innovative Vision for the Future Think 2010’ BSRIA March 2003
[25] Monitoring labor inputs: automated-data-collection model
and enabling technologies Ronie Navon, Eytan Goldschmidt
Automation in Construction 12 (2002) 185– 199
[26] Made to measure Building Magazine, 1999 Issue 04
[27] Rethinking the Nuts, Bolts, and Beams of Building -An
MIT professor's system for analyzing complex constructionproject innovations lands her at the head of a startup - Business
Week Magazine November 9, 2000
[28] Rethinking the Nuts, Bolts, and Beams of Building
[29] Wireless alliance touts 'magic touch' RFID technology
Graeme Warden ZDNet UK March 18, 2004
[30] Howe, A.S., (2002). The Ultimate Construction Toy:
Applying Kit-of-parts Theory to Habitat and Vehicle Design.
Online proceedings of the 1st Aerospace Architecture
Symposium (SAS2002), 10-11 October 2002, Houston, Texas.
Reston, VA: American Institute of Aeronautics and
Astronautics. Available online at: http://www.aiaa.org/
[31] “The Current Status of Mobile IT” report was released in
Nov ’03. www.comitproject.org.uk.
[32] The Bristol Wearable Computing Project
http://wearables.cs.bris.ac.uk/index.htm
[33] ‘Their goal is to find a better alternative to the widely used
Gantt Chart when planning construction processes.’ A state of
the art report Stefan Woksepp and Odd Tullberg Internal
publication 02:3, Department of Structural Mechanics,
Chalmers University of Technology pdf

Proceedings of the Eighth International Conference on Information Visualisation (IV’04)
1093-9547/04 $ 20.00 IEEE

