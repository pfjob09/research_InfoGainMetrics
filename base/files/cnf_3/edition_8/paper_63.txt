DIMENSIONALITY REDUCTION FOR CONTENT-BASED IMAGE CLASSIFICATION
E. Mr´owka1 , A. Dorado2,4,∗ † , W. Pedrycz3 , and E. Izquierdo4
1

Systems Research Institute, Polish Academy of Sciences, Warsaw, Poland
2
School of Engineering, Universidad Javeriana, Cali, Colombia
3
Electrical and Computer Engineering, University of Alberta, Edmonton, Canada
4
Electronic Engineering Dept., Queen Mary, University of London, UK
ABSTRACT
Effective ways of organizing image descriptors is a critical
design step of content-based image classification systems.
Suitable descriptors are selected according to the problem
domain for generating the feature space. Using several descriptors improves accuracy of representation but rises some
challenges such as non linear combination, expensive computation and the curse of dimensionality. In this paper an
approach using a non parametric statitical test for effective dimensionality reduction is presented. The proposed
method facilitates feature discrimination and keeps relevant
information.

the data dimensionality. A tree structured wavelet decomposition for dimensionality reduction of feature vectors is
presented in [3]. [4] reduce dimensionality preserving the
local topology of the original space. [5] applies an adaptive
clustering method to select representative features.
This paper presents an approach for reducing the dimensionality with a smaller loss of effectiveness. It uses
a non parametric statitical test to reduce the search space
by selecting salient features. A significantly reduction is
achieved without affecting performance. In addition, experiments show that this approach is suitable to deal with
heterogeneous feature spaces.

1. INTRODUCTION

2. PROBLEM DEFINITION

Development of content-based image applications require
to take two important facts into consideration: effectiveness
and efficiency. Normally, these applications populate and
retrieve information from huge databases.
In order to improve the efficiency, images are associated with descriptors (feature vectors) for representing their
content. Feature vector representation facilitates indexing,
browsing, searching and retrieval of images from large-scale
databases.
Effectiveness is increased by combining different descriptors, i.e color and texture. However, such a combination produces a high dimensionality in the resulting feature
space which drastically reduce efficiency of storage and retrieval. This shortcoming is known as the curse of dimensionality.
Methods based on Principal Component Analysis (PCA),
Self-Organizing Maps (SOM), and statistical moments are
used to deal with high dimensional spaces. [1] applies Independent Component Analysis (ICA) which uses higher
order statistics to reveal salient features. In [2] an orthogonal subspace projection approach is presented to reduce

This work addresses the problem of dimensionality reduction of low-level features to perform content-based image
classification.
Let X = {x1 , . . . , xN } be a set of still images and Φ =
{Φ(1) , . . . , Φ(n) } be a set of functions used to extract lowlevel descriptors from the image database.
The feature vector or image descriptor

∗ Support from the Natural Sciences and Research Council of Canada
(NSERC) and Canada Research Chair (CRC) is gratefully acknowledged.
† The research leading to this paper was done within the framework of
the Network of Excellence SCHEMA.

(d)

xi

= Φ(d) (xi )

(1)

is obtained by applying feature map Φ(d) on image xi .
Then, a feature space H is built using
Φ:X→H

(2)

where H consists of all the feature vectors extracted from
X.
Let X = {x1 , . . . , xm } be a sample of input images
and Y = {y1 , . . . , ym } be a sample of output targets where
X ⊂ X, Y ⊂ Y , and yk ∈ {0, 1} k = 1, . . . , m.
Given a function
f (x) : X → Y

(3)

the problem is stated as: How to reduce the dimension of
(d)
feature vectors, xi ∈ H, holding or improving the classification performance of f (x).

Proceedings of the Eighth International Conference on Information Visualisation (IV’04)
1093-9547/04 $ 20.00 IEEE

3. DIMENSIONALITY REDUCTION USING
STATISTICAL LEARNING
Feature selection has effects in the design of a classifier.
Identification of salient features is useful in such a selection. In the context of image classification, feature vectors
are histograms used to described the visual properties of the
image content.
Salient features allow discrimination between images
belonging or not to a certain class. In addition, they keep
valuable information related to the image content. The proposed approach uses a non parametric statistical test, Wilcoxon test, for detecting these features.
The method is similar to median test in scope, but it
is much more sensitive. For small numbers with unknown
distributions this method is more sensitive that the Student
t-test. In the case of large numbers it is almost as sensitive
as the Two Sample Student t-test [6].
Detection of salient features is carried out using two
groups of observations: k and k˜ with samples of feature
vectors extracted from two sets of images X1 and X2 , respectively. Set X1 contains images belonging to a certain
class K. On the other hand, images in set X2 that do not
belong to class K.
The Wilcoxon test (see Fig. 1) is used to verify the following hypothesis:
(d)

µk˜ ([xj ]r )

(d)

µk˜ ([xj ]r )

H0 : µk ([xi ]r )
H1 : µk ([xi ]r )

(d)
(d)

Differences are predominant positive (or negative) if the
alternative hypothesis, H1 , is true. Features satisfying the
null hypothesis are considered irrelevant. The remaining
ones are selected as salient features.
Fig. 2 and Fig. 3 show differences between two distribution with 62-point feature vectors. These features correspond to the homogeneous texture descriptor which extracts
values from a frequency layout to give a quantitative characterization of the image texture in terms of directionality,
coarseness, and regularity of patterns [7]. As is illustrated,
the mean values of features fulfilling null hypothesis are
closer values than those satisfying the alternative hypothesis.

(4)
(5)

Fig. 2. Sample of features satisfying null hypothesis.

where µk (·) and µk˜ (·) are the mean values of group k and
˜ respectively.
k,

Fig. 1. Wilcoxon test.
(d)

(d)

The rth features, [xi ]r and [xj ]r , are symmetrically
distributed when the null hypothesis, H0 , is true. In this
case, the statistic approximates a χ2 distribution with two
degrees of freedom.
The probability value (in short, p-value) of a statistical
hypothesis test is used to verify this condition –the smallest
significant level at which the null hypothesis can be rejected.
The p-value is compared with the desired significance
level, hereinafter α-value. If it is smaller the results is significant. For instance, if the null hypothesis were to be rejected at the 5% significance level, this would be reported
as p < 0.05.

Fig. 3. Sample of features satisfying alternative hypothesis.
Fig. 4 depicts a plot showing the effects of varying the
p-value on a 256-point feature vector. These features correspond to the color structure descriptor which summarizes
into a histogram the localized color distribution of an image
according to a quantized color map [7]. The original feature
vector cardinality is obtained when p-value = 1.

Proceedings of the Eighth International Conference on Information Visualisation (IV’04)
1093-9547/04 $ 20.00 IEEE

Fig. 7. Samples of images for class “Landscape”.

Fig. 8. Samples of images for class “Panoramic sights”.
Fig. 4. Dimensionality reduction varying p-value.
4. EXPERIMENTAL RESULTS
Experiments were conveyed using 1000 color images of different sizes from Corel Stock Gallery and FreeFoto.com.
Images were grouped into five classes namely animal,
building, landscape, panoramic sights, and vegetation. A
picture was manually categorized by a single subject into a
certain class if the camera is focused in an object satisfying the name of the class. Fig. 5-Fig. 9 show some sample
images belonging to each class.
The initial feature space was built combining feature
vectors extracted from imagery using the MPEG-7 visual
descriptors Color Structure (256 points), Edge Histogram
(80 points), and Homogeneous Texture (62 points) [7].

Fig. 9. Samples of images for class “Vegetation”.
In order to assess the accuracy of the classification procedure, a statistical performance evaluation based on a confusion matrix is applied. The accuracy is improved when
confusion rate is reduced.
Table 1 presents experimental results for classes “Building” and “Landscape’, respectively. Three α-values are selected to show the effects of dimensionality reduction on the
image descriptors. New dimensions of these descriptors and
the full feature vector combining them is given along with
the resulting confusion rate.

α-value
1e-04
1e-06
1e-08

Fig. 5. Samples of images for class “Animal”.

1e-04
1e-06
1e-08

Fig. 6. Samples of images for class “Building”.
Training and testing datasets were randomly generated.
60% of the images were used for training and 40% for testing. Datasets of each class have the same size. A classifier
model based on a RBF-type neural network was used to test
the approach.

Class: “Building”
CSD EHD HTD
60
61
10
36
55
9
25
41
8
Class: “Landscape”
97
71
49
71
24
21
49
20
14

FV
131
100
74

CR
0.117
0.125
0.136

217
116
83

0.258
0.216
0.177

Table 1. Dimensionality reduction and confusion rate for
classes “Building” and “Landscape”. CSD, EHD, HTD,
FV, and CR stand for color structure, edge histogram, homogeneous texture, feature vector, and confusion rate, respectively.
In contrast with obtained results for class “Building”,
confusion rate is improved for class “Landscape” decreasing the significance level.

Proceedings of the Eighth International Conference on Information Visualisation (IV’04)
1093-9547/04 $ 20.00 IEEE

Figures 10 and 11 depict compression ratio of each descriptor and feature vector after varying the α-value. The
ratios are grouped by class. Compression ratio is calculated
as follows:
ratio =

dimension(xˇi (d) )

(6)

(d)

dimension(xi )
(d)

where xˇi (d) is the reduced feature vector and xi
original one.

is the

Fig. 12. Confusion rates for α = {1e−04, 1e−06, 1e−08}.
6. REFERENCES

Fig. 10. Dimensionality reduction using α = 1e − 04. “A”,
“B”, “L”, “S”, “V” stand for “Animal”, “Building”, “Landscape”, “Panoramic Sights”, and “Vegetation”, respectively.

[1] M. Lennon, G. Mercier, M.C. Mouchot, and L. HubertMoy, “Independent component analysisi as a tool
for the dimensionality reduction and the representation
of hyperspectral images,” in Proc. IEEE Int’l Geoscience and Remote Sensingi Symposium, IGARSS’01,
Jul 2001, vol. 6, pp. 2893–2895.
[2] J.C. Harsanyi and C.-I. Chang, “Hyperspectral image
classification and dimensionality reduction: An orthogonal subspace projection approach,” IEEE Trans. on
Geoscience and Remote Sensing, vol. 32, no. 4, pp.
779–785, Jul 1994.
[3] M. Kokare, B.N. Chatterji, and P.K. Biswas, “Dimensionality reduction of tree structured wavelet transform
texture features for content based image retrieval,” in
Proc. 7th IEEE Int’l Conf. on Control, Automation,
Robotics and Vision, ICARCV2002, Dec 2002, vol. 3,
pp. 1647–1652.

Fig. 11. Dimensionality reduction using α = 1e − 08
Fig. 12 depicts confusion rate values for different significant levels. The perfomance is slightly affected even with
reductions below to 50% of the original dimensionality.
5. CONCLUSIONS
An approach using a non parametric statitical test for effective dimensionality reduction was presented. The proposed
method selects salient features to compress the search space
and facilitate discrimination. Compression ratios below to
50% of original dimension are achieved with classification
performance above of 80%.

[4] P. Wu, B.S. Manjunath, and H.D. Shin, “Dimensionality reduction for image retrieval,” in Proc. IEEE Int’l
Conf. on Image Processing, ICIP2000, Sep 2000, vol. 3,
pp. 726–729.
[5] A. Dorado and E. Izquierdo, “Fuzzy color signatures,” in Proc. IEEE Int’l Conf. on Image Processing,
ICIP2002, Rochester, New York, Sep 2002, vol. 1, pp.
433–436.
[6] “The wilcoxon two sample test,” www.fon.hum.uva.nl/
Service/Statistics/Wilcoxon Test.html.
[7] B.S. Manjunath, J.-R. Ohm, V.V. Vasudevan, and A. Yamada, “Color and texture descriptors,” IEEE Trans. on
Circuits and Systems for Video Technology, vol. 11, no.
6, pp. 703–715, Jun 2001.

Proceedings of the Eighth International Conference on Information Visualisation (IV’04)
1093-9547/04 $ 20.00 IEEE

