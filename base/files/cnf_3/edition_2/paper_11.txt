2010 14th International
Information
Conference
Visualisation
Information Visualisation

Kinetic Inter-Acting: A System for Visual Analysis of Interaction Dynamics

Kristine Deray

Simeon Simoff

Faculty DAB, Dept. of Design
University of Technology, Sydney,
Sydney, Australia

School of Computing and Mathematics
University of Western Sydney,
Sydney, Australia

kristine.deray@uts.edu.au

s.simoff@uws.edu.au

The advent of Web 2.0 social computing applications has
invoked the development of visualisations of various
networks, derived from social interactions between
individuals [8]. These networks are formalised as graphs,
hence, interactions are visualised primarily as static graph
structures. Visualisation of the temporal structure of
interactions and interaction patterns has been considered in
the context of knowledge co-creation in the various
visualisations of Wiki's data, for example, in IBM History
Flow visualiser [9]. In [10] colour palettes are used to
capture interactions in design. Although visualisation of this
nature deals with temporal patterns of the interaction, the
increased complexity of information can lead to issues with
semantics and readability. As noted in [11], this is a problem
with knowledge domain visualization: the communication of
knowledge instead of displaying abstract data as information.
The aim of this work is to interprete interactions through
information derived from the interaction process. In this
paper the KIA (Kinetic Inter-Acting) system for visual
encoding and reasoning about the way interactions unfold
that enables both humans and machines to utilise such
information is presented. Section 2 presents KIA design
principles and basic concepts, Section 3 - the KIA visual
language, Section 4 demonstrates the language for visual
analysis of interactions. Section 5 presents an evaluation of
KIA estimates against expert judgments on cases from the
area of healthcare and Section 6 concludes the paper.

Abstract—Interactions are central to our endeavours. Whether
in a face-to-face session with a doctor or via one of Web 2.0
applications, the way interactions unfold has an impact on the
final outcome of the session. This paper addresses the problem
of the development of a visual language and analysis system,
enabling visual reasoning about the quality of interactions. The
paper presents a system of encoding the way interactions
unfold. It presents the foundations of KIA (Kinetic InterActing) visual language and the visual analysis system with this
language. The language is then evaluated through comparison
with expert judgments when applied to cases in health care.
KIA (the language and the analysis system) enables both
humans and machines to utilise information about how
interactions unfold in order to improve interactions and the
processes that depend on them.

Keywords- Interaction analytics, Information visualisation,
Visual language, Visual computing.
1.

INTRODUCTION

Interactions constitute a process that unfolds. The way
interactions unfold can tell us a lot about the interactions
themselves. It provides essential additional information in
processes that rely on interactions. For instance, in online
and mobile learning, such information can provide aid to an
on-line lecturer to steer the learning session, as noted in
healthcare and nursing education [2]. The work-based
mobile learning process and practice involve interactions
between nurses and health-care practitioners, on the one side,
and their patients on the other side. In participative
healthcare, information about interaction patterns will assist
practitioner in evaluating the communication with the patient
and identify the bottlenecks [3].
Means for studying the structure and content of
interactions have been developed primarily for
conversational interactions [4], including gesture-based
interactions [5] and social cues [6]. For example, parameters
like number, length and content of messages in an interaction
have been used to identify emergent leaders in asynchronous
and synchronous virtual environments [7]. However, the
focus is upon the results of the interaction rather than the
dynamics of the process of interacting that produce these
results.
1550-6037/10 $26.00 © 2010 Crown Copyright
DOI 10.1109/IV.2010.20

2.

KIA DESIGN PRINCIPLES

The KIA system visualises the phenomenon of
interaction itself, by representing the construction of the
interaction process. Providing natural criteria for the design
of a visual language, visual analysis method, and the
delineation of the visualization space has distinct advantages.
Intuitive knowledge provides access to domain semantics.
Thus, parties, coming with diverse backgrounds, can be
provided with information about the interaction process in
which they are involved. The method applied for the design
of KIA language, shown in Fig. 1, is based on analogical
reasoning, following the Source-Target model of linking
conceptual space in metaphor analysis in cognitive
linguistics [12] (hence, the respective indexes “S” and “T”).
The argument for the choice of human movement as a source
73

domain is twofold: (i) there is a need for a visual language
that is understandable by people with different backgrounds,
that can enhance communication, and; (ii) cognitive
psychology [13] and artificial intelligence [14] emphasise the
phenomenon that the knowledge about human body is well
embedded in us, hence satisfies (i).
Physical system (Source domain): Human movement

S[t1]

S[t2] S[t3]

S[t4]

[t1]

FSS

[t2 ] [t3] [t4 ]

Physical system (Target domain): Interactions

" S[tn ]

S[t1]

"

DS

" [tn ]

DT

FST

Formal system: Movement observation science

VLS

S[t2]

S[t3]

S[t4] " S[tn ]

P1[t1]P2[t1] P1[t2 ]P2[t2 ] P1[t3]P2[t3] P1[t4]P2[t4]

P1[tn ]P2[tn ]

"

[t1]

time

"

between two partners, were derived. All interactions were
expressed through human movement. The software was
adapted to provide for analysis of movement fusion between
parties that directly affects the output represented in the
morphology of the interaction. Morphodynamics perceived,
as dynamic form is reflective of decision-making between
parties represented as changing geometry in space.
Morphodynamics here is used in a non-geological sense, to
label the evolution of the interaction landscape (i.e. treating
interaction as a single entity) as a result of the contributions
of participating parties. This was a top-down approach from
the surface of the representation to deep structures of the
system that provided a simple relational ontology of the
source. Kinematic features were linked as (i) low level, and
(ii) intermediate level features. Low-level kinematical
features referenced basic mechanisms that affect positional
information, while intermediate–level kinematical features
provided information related to the expression of movement.
Together these two sets of motion information mapped the
structure of a kinetic space.
Fig. 2 shows an example of the video data about a state,
which consists of a sequence of movements over a time
period. Fig. 3 and Fig. 4 show the directions and
approximated trajectories of movements in a range of planes.
They illustrate the derivation of the shape type and visual
behaviour of the qualities of the R-S and C-E elasticities,
respectively. As graphically indicated, the action of the two
elasticities has been separated in vertical and horizontal
directions, respectively, spanning a 2D representation of
interactions The shapes in Fig. 3 and Fig. 4 act as the visual
constraints for the quantitative approximations of the
qualities that describe interactions.

[t2 ] [t3] [t4 ]

" [tn ]

time

"

Formal system: Based on human movement, music

VLT

Visual Language: Phrases organised in scores

Visual Language: Phrases organised in productions

Figure 1. Method applied to the design of KIA langauge

Horizontally, the diagram is separated in three sections.
Section D shows the similarity between the domain of
analysis of human movement, in particular, dancing (DS) and
the domain of analysis of human interactions (DT), when
both domains are considered from a physical system
perspective. Both domains can be structured as a sequence of
states (S) that are a result of the sequences of activities of the
interacting parties (P) in respective time intervals (t).
The formalisms (Section FS in Fig. 1) that describe the
source domain FSS are taken from Movement observation
science [15], known also as Laban/Bartenieff Movement
Analysis. The derivation of the sets of constructs, elasticities
and qualities, that are central to the development of
computational representations of interactions and respective
visualisations, is achieved by the application of elements of
Movement observation science to the analysis of contact
improvisation data. The two groups of constructs provide the
forms and behaviour rules of the ‘shaping affinities’ for
expression of information about interactions. In particular,
we have mapped into the target domain the Rising-Sinking
(R-S) elasticity and the Contracting-Extending (C-E)
elasticity. Elasticities are movement constructs that refer to
anatomical actions alongside the dimensions in the human
body focused on three aspects of human movement
‘elasticity.’ Qualities are dimensions associated with each
elasticity. The target domain is expressed in terms of the
behaviour of the ‘shaping affinities’ that follows the
computational models of the elasticities and qualities.
For the design of the visual behaviour of the visual
elements that will represent the elasticities and qualities in
the interaction domain, analysis of videos of contact
improvisation (with the video analysis software Dartfish),

ti−

ti+
Figure 2. Example of a video sequence that forms a state

S[t ] ,
i

[ti ] = ª¬ti− , ti+ º¼
Once the shapes and behaviour were established through
the conceptual modeling of the source domain, we have
considered a list of requirements towards the elements of the
visual language. In order to achieve the goal of providing
information about how interaction process unfolds
represented through the dynamics of the visual elements, to
enhance information flow at the point of decision-making, a
set of principles for designing visual languages for
representing interactions in [3] have been formulated. These
were extended to cover mobile systems in [16]. Together,
with the guidelines for multimodal user interface design,
presented in [17], the user interface principles for
multimodal interaction, presented in [18] and the broad
consideration of the body, gesture, gaze, and affective
interaction, presented in [19], have been synthesized into a

74

set of high level design requirements and ten rules of specific
requirements for multimodal display interfaces in [20]. These
sets of principles have been followed when developing KIA
visual language and its support.

which indicates the amount of control applied in the
interaction. The C-E elasticity comprises of a single quality intensity q1C − E , which indicates the strength of the
interaction.
{Pk(A1), Pl(A2), Pk(A1), Pl(A2), Pk(A3)}

P1
P1

P2

P1

S[1]

{Pk(A3), Pl(A1), Pk(A2),}

P2

P2

S[2]

P1

S[3]

P1

P2

S[4]

{Pl(A3), Pl(A4), Pk(A2), Pk(A5), Pl(A4)}

P1

P2

Productions

{ Pk(A3), Pk(A4), Pk(A5), Pl(A2)}
{Pl(A3), Pl(A4), Pk(A4), Pk(A5), Pl(A5)}

P2

S[5]

Interactions

{Pk(A1), Pl(A2), Pk(A1), Pl(A2), Pk(A3)}

S[6]

Figure 3. Deriving the shape and behaviour of the visual elements of the
R-S elasticity.

Pk(A1) Pk(A2) Pk(A3) Pk(A4) Pk(A5)
Pl(A1)

Pl(A2)

Pl(A3)

Pl(A4)

Figure 5.
P1

P1

P2

S[1]

S[2]

P1

P2

S[4]

Figure 4.

P1

P2

P2

P1

Actions

KIA framework

Strength, in this context, indexes the intensity of the
interaction and is an indicator of reciprocal effects. The
notion of ‘extend’ is similar to increasing tension in space in
movement, resulting in greater connection between parties.
The notion of’ ‘contract’ is one of lessening strength
between parties resulting in less tension and thus less
connection between parties.

S[3]

P1

S[5]

P2

Pl(A5)

P2

S[6]

Production element

Deriving the shape and behaviour of the visual elements of the
C-E elasticity.

Body element
Effort-Shape element

3.

KIA VISUAL LANGUAGE

q1C − E

q1R − S q2R − S q3R − S q4R − S

q1C − E

Behaviour of the RS-elasticity

Earlier it is mentioned that knowledge about how
interactions unfold needs to be presented in a form
understandable by people with different backgrounds. In
order for the overall process to be feasible, such knowledge
needs to be represented in computational form and captured
automatically (to the extent possible). Then, to make the
process operational in real-time, computationally efficient
approximations and visualizations are required.
The KIA framework is shown in Fig. 5. The formalism
treats interactions as a sequence of activities, composed of
tasks that in turn are composed of actions Pi(Aj). The
qualities of the elasticities that describe interactions and
drive the behaviour of the visualisation elements are
computed as functions of the parameters of the sequences of
actions. In the current version of KIA the R-S elasticity
comprises of four qualities derived through the analogical
process outlined in Fig. 1. Flow q1R − S , which characterizes
the obstruction to interactions (e.g. language/social/cultural,
etc); transition q2R − S , which characterises the smoothness of

Behaviour of the CE-elasticity

Figure 6. The main expressive unit in KIA

The visual elements that correspond to respective
elasticities, the directions of their behaviour and their
aggregation into the main expressive unit in KIA are shown
in Fig. 6. Elasticities represent reciprocal effects as integral
dimensions of the domain of interaction, while qualities
represent performatives as cooperative processes,
cooperation interpreted as “common ground” between
parties in the interaction domain. How the interaction
functions, for instance, is it independent from other
interactions, is it symmetrical or asymmetrical, balanced or
unbalanced - all these can be expressed by the changing
shape and structure of the elasticities. Qualities generate a
canonical structure in both domains. The basic idea is that

the actions run within the interaction; exertion q3R − S , which
correlates to the amount of effort required for an interaction
to achieve some perceived position, and; control q4R − S ,

75

the presence of a decision fork - an activity where a decisionmaking has happened. The segmenting rule is that the
decision fork is the first action in the first sequence of
actions in a subtask segment, except for the first subtask,
where it is the last action in the first sequence. Subtasks then
form the interaction segments ISi which corresponds to
completion of a task. For Case II we have four interaction
segments, where the action structure of IS1 is shown in
details in Fig. 7. Arrows crossing the horizontal bars indicate
turn taking.

each part expresses a variable on a dimension that is integral
to the domain, and parts combine to make the whole.
As described in Fig. 6 the R-S qualities are aggregated
into the ‘Effort-Shape’ element, the C-E qualities - into a
‘Body’ element. An Effort-Shape element is labelled as the
element that visually represents the qualities of the ‘Rising
and Sinking’ elasticity. The Body element is the element that
visually represents the qualities of the ‘Contracting and
Extending elasticity. Together these elements constitute a
Production element - the main expressive unit in KIA.
Production elements are aggregated vertically into
Productions – KIA’s visual ‘sentences’. The expressions that
compute the model parameters of the qualities are presented
in details in [21]. In these models we use a suite of ‘length’
estimates (e.g. length of an action, length of an interaction).
The computation of these estimates varies when considering
different modes of interaction. For instance, in a face-to-face
interaction, these are measures of time. In an on-line chat or
the text chat of a virtual world, these estimates are functions
of the number of words or characters, or other statistics of
the text utterance. Regardless of the underlying estimates, the
visualisation engine to compute the visual representations of
the R-S qualities and the C-E quality then uses the
parameters of the qualities.
The formal visual models of the elasticities include rules
for adding new qualities to each of them. These rules enable
consistency and comparability of the Effort-Shape and Body
elements, generated from different data sets and with
changes in the number of visualised qualities of the
elasticities. The rules ensure that correspondence of position
of the qualities to the index number does not change, thus
preserving backward compatibility with previous
configurations of the visual elements.
Further, we use some examples from the domain of
healthcare to demonstrate the expressive power of the
language and to evaluate its performance. The choice of
healthcare domain is motivated by the developments in
telehealth and the shift from episodic care to continuous and
individual healthcare mode. The need to utilize data about
practitioner-patient interactions has been well recognized, as
well as the complexity of the problems to be addressed.
4.

TABLE I.

Case
I
II
III
IV
V

CASES AND THEIR DESCRIPTIONS

Description
Assessment of cognitive abilities of a child.
Parties: Occupational Therapist and Patient.
Aging patient assessed for discharge from hospital.
Parties: Occupational Therapist and Patient.
Patient follow-up consultation.
Parties: Doctor and Patient
Home visit to assess patient in own environment
Parties: Nurse, Occupational Therapist and Patient
Patient follow-up consultation.
Parties: Doctor and Patient
Interaction Segment IS1
A1

A2

A3

A4
B1

q1C − E

Subtask
Introduction to patient

A5

A6

A7

B2

B3

B4

B6

Subtask
Establish motivation to go home

A9

A10 A11

B7

B8

B9

A12

q1C − E

q1R − S q2R − S q3R − S q4R − S

q1C −E

q1R − S q2R − S q3R − S q4R − S

q1C −E

q1R−S q2R − S q3R− S q4R − S

q1C − E

PE(IS1)

A8
B5

R −S
R−S
qq2
qq33R − S qq44R − S
qq1
2
1

A13

B10 B11 B12 B13

Subtask
Patient’s ability to manage at home

Interaction Segment IS2
Interaction Segment IS3

q1C − E

PE(IS2)
q1C − E

PE(IS3)
q1C −E

PE(IS4)

Interaction Segment IS4

VISUAL ANALYSIS WITH KIA

Five cases of health-related interactions were used in
different scenarios to test KIA expressive power and to
evaluate the language. Table 1 presents briefly the scenarios
of the example cases. The analysis is based on video records.
Fig. 7 shows the generation of KIA production using
Case II as an example. This case relates to self-management
and shared decision making in the treatment plan and
timeline for an elderly patient’s discharge from a hospital.
The interaction follows the assessment of the patient along
some fitness criteria. The details of the segmentation process
are illustrated in the first interaction segment. Practitioner A
interacts with patient B through actions that are verbal and
non-verbal. The initial video stream data is segmented into
time-stamped actions performed by the practitioner and the
patient, labeled as A and B, respectively. These actions then
are grouped into subtasks, where a subtask is identified by

Data segmentation
and action sequence analysis

Generate KIA production elements
and productions

Figure 7. Constructing KIA expressions

The right-hand side of the diagram in Fig.7 shows the
production for Case II. The time length of each action and
the number of actions by A and B, respectively, computed
for each interaction segment during the data segmentation
and action sequence analysis, are the arguments in the
functions that compute the values of the respective qualities
within the range [0; 1] of the production elements PE(ISi).
Comparing the visual patterns for each IS over the
Production furthers content analysis of the visual patterns.
The visual patterns of the Production, for Case II,
indicate that the flow of the communication between parties

76

has been average, declining in the last segment; transition
indicates that communication between parties occurred with
reasonably quick responses to actions of fairly short lengths;
exertion indicates complex level of interaction as it shows
greater effort, especially in the last segment; control shows
some flexibility in the middle of the session (segments IS2
and IS3) with a dominance of the practitioner towards the
end..
Fig. 7 demonstrates productions as visual expressions.
They can provide a rich and compact view of the different
sets of interactions, allowing to grasp the macro-picture of
the interaction flow and to compare across different sets.
Productions can be understood on a number of levels, as: (i)
continuity across the qualities; and (ii) as individual slices
read vertically down the production score. Positions of the
qualities will be updated automatically or semiautomatically. This produces two modes of operation for the
visualisation layer: (i) static display with regular updates
factored into the interface; and, (ii) animation mode where
the dynamics of interaction are unfolding in real time (albeit
there may be a slight delay for transmission).

mid

max
int-high

min

mn
il
md
ih
mx

int-low

mid

mid

int-low

int-low

min

min

R-S

C-E

Case II
Elasticity

R-S

C-E

Interface for entering expert scores

Quality

1

L
md
Flow
Trans
ition il
Exertion il
md
Control
Intensity il

E
md
md
il
ih
il

Interaction Segme
nt
2
3
4
L E L E L E
ih ih ih md mx mx
md md md md mn mn
mn mn md md ih ih
mx mx md md il il
il il il il il il

5
L E
md md
il il
md md
il il
il il

InteractionSegment
2
3
4
L E L E L E L E
md il md md md md il
il
Flow
Transition ih md ih md ih ih md md
ih ih md md mn mn ih md
Exertion
ih ih ih md mx ih il
il
Control
il
Intensity mx ih mx mx md md l
Quality

1

Figure 9. Comparison of KIA and expert evaluations

TABLE III.

Elasticity

R-S

KIA range
[0; 0.1[
[0.1, 0.4[
[0.4, 0.6[
[0.6, 0.9[
[0.9, 1[

C-E

TABLE IV.

KIA and expert scores for Case I, Case II, listed in Table
I, are shown in Fig. 9 in “L” and “E” columns, respectively,
with the mismatches highlighted. We adapted SokalMichener matching coefficient ([22], p. 148) to evaluate,
over the whole period of interaction, the degree of matching
of evaluations of individual qualities (Mq), elasticities (Me)
and the overall case (MI). The values of these measures,
based on the results in Fig. 9 are presented in Table III and
Table IV. On average, the match in qualities across the cases

Me(R-S)
Me(C-E)
MI

MQ MEASURES FOR ALL CASE STUDIES

Quality
Flow
Transition
Exertion
Control
Intensity

CATEGORICAL SCALE FOR QUALITIES
Label
min
int-low
mid
int-high
max

min

mid

max
int-high

CaseI
Elasticity

In order to evaluate the accuracy of the underlying
approximation of interactions that KIA utilises and the
adequacy of the visual language we compare KIA and expert
estimates of qualities. Use was made of a partially ordered
five step categorical scale for scoring the values of the
qualities. The scale, the labels and the mapping onto the [0;
1] range used by KIA and experts are shown in Table II.
Experts scored segmented videos of each case study. For
entering the evaluations, experts were provided with an
interactive interface, visually identical to a production
element, but with attached categorical scale and the ability to
adjust the values of the qualities, as shown in Fig. 8. These
additional interfaces are switched off when the expert
visually evaluates provided estimates. Video examples of
value ranges for each quality are shown and discussed prior
to the assessment.

Scale
minimum
intermediate-low
middle
intermediate-high
maximum

max
int-high

Figure 8.

KIA VS EXPERT EVALUATIONS

TABLE II.

int-low

int-high
max

5.

is reasonably good - above 75%. Flow and Intensity are with
higher agreement between model and expert cases.

I
0.80
0.80
1.00
0.80
1.00

II
0.75
0.50
0.75
0.50
0.75

Case
III
0.75
1.00
0.75
0.50
0.75

IV
1.00
0.67
0.67
0.67
1.00

V
0.75
1.00
0.75
0.75
0.80

ME AND MI MEASURES FOR ALL CASE STUDIES

Case
I
II III IV V
0.85 0.63 0.75 0.83 0.81
1.00 0.75 1.00 1.00 0.75
0.88 0.65 0.75 0.80 0.85

Range
min max
0.63 0.85
0.75 1.00
0.65 0.88

mean
0.78
0.85
0.79

Statistics
stdev median
0.08 0.81
0.14 0.75
0.09 0.80

The largest mismatch is observed in Case II. The analysis
of the mismatches shows that in this case expert evaluations
have been systematically lower than the language. It seems

77

that the bias has come from the pitch and softness of the
patient’s voice as well as perceived physical weakness.
6.

[7]

CONCLUSIONS
[8]

In this paper we have presented the KIA visual language
and visual analysis system. Since interactions are complex
and operate in dynamic operational environments, it is
impossible to pre-define everything at design time.
Consequently, the design and evaluation of a language for
interactions need to have the capability for dynamic
reconfiguration and extendibility to cope with complexity.
The visual language KIA provides insight into interactions
partially because the modelling of the behaviour of the visual
elements provides a simplification of the complexity of the
domain and partially because interpretation of the behaviour
of the visual primitives is supported by the familiarity of the
embodied constructs that reflect the physical forms of the
source into the target.
The language has been demonstrated and evaluated using
examples from practitioner-patient interaction in healthcare.
The evaluation demonstrated that the models and the visual
elements performed with reasonable accuracy. The future
work will be focused on the refinement of the approximation
models, the design of KIA’s visual elements, as well as on
increasing the degree of automation of the segmentation
procedures. The benefit of an intuitive basis for the reasoning
through KIA ‘s visual elements is promising. Bodily
knowledge can assist parties by revealing semantics of the
structural and expressive patterns of the interaction process,
made available at the point of decision-making.
7.

[9]

[10]

[11
[12]
[13]
[14]
[15]
[16]

ACKNOWLEDGEMENTS

This research is supported by the University of
Technology, Sydney, and the University of Western Sydney.
8.
[1]
[2]
[3]

[4]
[5]

[6]

[17]

REFERENCES

G. Small and G. Vorgan, iBrain: Serving the Technological
Alteration of the Modern Mind, Collins Living, 2008.
R. Gabb and S. Keating, Work-based learning curricula in
nursing: A literature review, Victoria University, Melbourne
2005.
K. Deray and S. J. Simoff, Designing a visual language for
interaction representation based on aspects of human
movement, in F. Ferri, Ed., Visual Languages for Interactive
Computing: Definitions and Formalizations. Hershey, PA:
IGI Global, 2007, pp. 205 - 231.
D. Tannen, Conversational Style: Analyzing Talk among
Friends, Oxford University Press, 2005.
C. Dicke, S. Deo, M. Billinghurst, N. Adams, and J.
Lehikoinen, Experiments in mobile spatial audioconferencing: key-based and gesture-based interaction, in
Proceedings of the 10th Conference on Human-Computer
Interaction with Mobile Devices and Services - Mobile HCI
2008, Amsterdam, The Netherlands, 2008.
M. M. Louwerse, A. C. Graesser, S. Lu, and H. H. Mitchell,
Social cues in animated conversational agents, Applied
Cognitive Psychology, 19, 2005, pp. 693–704.

[18]

[19]
[20]

[21]

[22]

78

S. Simoff and F. Sudweeks, The language of leaders:
Identifying emergent leaders in global virtual teams, in K. St
Amant, Ed., Linguistic and Cultural Online Communication
Issues in the Global Age: Idea Group, 2007.
S. A. Golder, D. Wilkinson, and B. A. Huberman, Rhythms
of social interaction: messaging within a massive online
network, in Proceedings of the 3rd International Conference
on Communities and Technologies (CT2007), East Lansing,
MI, 2007.
F. B. Viégas, M. Wattenberg, and K. Dave, Studying
cooperation and conflict between authors with history flow
visualizations, in Proceedings of the International
Conference for Human-Computer Interaction CHI2004,
Vienna, Austria, 2004, pp. 575-582.
C. Stones, Diagramming design: Visualizing user
interactions with colour palettes, in Proceedings of the Ninth
International Conference on Information Visualisation,
2005, pp. 445-450.
C. Chen, Top 10 Unsolved Information Visualization
Problems, IEEE Computer Graphics and Applications, 25
(4), 2005, pp. 12-16.
G. Lakoff and M. Johnson, Metaphors We Live By. Chicago,
University of Chicago Press, 1980.
M. Wilson, Six views of embodied cognition, Psychonomic
Bulletin & Review, 9 (4), 2002, pp. 625-636.
M. L. Anderson, Embodied Cognition: A field guide,
Artificial Intelligence, 149, 2003, pp. 91–130.
J. Newlove and J. Dalby, Laban for All. London, Nick Hern
Publishers, 2004.
K. Deray and S. J. Simoff, Visualising the dynamics of
unfolding interactions on mobile devices, in Advances in
Conceptual Modeling - Challenges and Opportunities,
Proceedings of the ER 2008 International Workshop on
Modeling Mobile Applications and Services (M2AS'08 ), 2023 October 2008, Barcelona, Spain, 2008, pp. 238-247.
L. M. Reeves, J. Lai, J. A. Larson, S. Oviatt, T. S. Balaji, S.
Buisine, P. Collings, P. Cohen, B. Kraal, J.-C. Martin, M.
McTear, T. Raman, K. M. Stanney, H. Su, and Q. Y. Wang,
Guidelines for multimodal user interface design,
Communications of the ACM, 47 (1), 2004, pp. 57-59.
T. V. Raman, User interface principles for multimodal
interaction, in Workshop on Principles for Multimodal User
Interface
Design,
CHI
2003,
2003,
pp.
http://www.almaden.ibm.com/cs/people/tvraman/chi2003/mmi-position.html.
A. Jaimes and N. Sebe, Multimodal human-computer
interaction: A survey, Computer Vision and Image
Understanding, 108, 2007, pp. 116-134.
K. Deray and S. J. Simoff, Visualising interactions on
mobile multimodal systems, Multimodal Human Computer
Interaction and Pervasive Systems. Hershey, New York: IGI
Global, 2009, pp. 430-442.
K. Deray and S. J. Simoff, Designing technology for
visualisation of interactions on mobile devices, Journal of
Computing Science and Engineering, 3 (4), 2009, pp. 218237.
H.-H. Bock and E. Diday, Analysis of Symbolic Data:
Exploratory Methods for Extracting Statistical Information
from Complex Data. Berlin, Springer, 2000.

