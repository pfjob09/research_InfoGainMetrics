2010 14th International
Information
Conference
Visualisation
Information Visualisation

Real-Time Immersive Table Tennis Game for Two Players with Motion Tracking

Yingzhu Li / Lik-Kwan Shark

Sarah Jane Hobbs

Advanced Digital and Signal Image Processing Centre
School of Computing, Engineering and Physical
Sciences
University of Central Lancashire
Preston, U.K.
YZLi@uclan.ac.uk / LShark@uclan.ac.uk

Centre for Applied Sport and Exercise Science
University of Central Lancashire
Preston, U.K.
SJHobbs1@uclan.ac.uk

James Ingham
School of Journalism, Media and Communications
University of Central Lancashire
Preston, U.K.
JIngham@uclan.ac.uk
This paper is organised into five sections. Section 2
provides a brief review of related work, and Section 3
presents system hardware in terms of tracking, display and
computing systems. This is followed by software
implementation in Section 4, which describes scene
generation, physics based calculation of the ball’s trajectory,
stereoscopic rendering, and a simple user interface. System
performance is presented in Section 5 and finally,
conclusions are given.

Abstract—Presented in this paper is a novel real-time virtual
reality game developed to enable two participants to play table
tennis immersively with each other’s avatar in a shared virtual
environment. It uses a wireless hybrid inertial and ultrasonic
tracking system to provide the positions and orientations of
both the head (view point) and hand (racket) of each player, as
well as two large rear-projection stereoscopic screens to
provide a view-dependent 3D display of the game environment.
Additionally, a physics-based ball animation model is designed
for the game, which includes fast detection of the ball colliding
with table, net and quick moving rackets. The system is shown
to offer some unique features and form a good platform for
development of other immersive games for multiple players.

II.

Keywords- Immersive Game, Motion Tracking, Stereoscopic
Display, Interaction Techniques

I.

INTRODUCTION

One of the most challenging research areas in virtual
reality (VR) [1] is to enable fast interaction among multiple
participants in real time, which requires not only high speed
movement tracking of multiple objects but also high update
rate of multiple displays. In an effort to address the challenge,
the paper reports the design and development of a virtual
table tennis game to allow two participants to immerse in a
physical play against each other in real-time.
To achieve high speed movement tracking of rackets and
player view points, the hybrid inertia and ultrasonic sensing
technology from InterSense [2] is used, with each player
holding a hand tracker as grasping a racket, and wearing a
head tracker. To achieve visual immersion, two large rearprojection stereoscopic screens are used to provide an
individual view for each player based on the player’s
perspective. By wearing a pair of polarised glasses, each
player is able to see his/her own virtual racket, a standard
table tennis table and a flying ball, as well as the opponent’s
avatar holding a racket, in 3D with an impression of depth.

1550-6037/10 $26.00 © 2010 IEEE
DOI 10.1109/IV.2010.97

PREVIOUS WORK

There are several ball-racket based games that support
real-time physical interaction between players. One based on
network is CamBall [3] that allows two remote users to see
and play with each other using PCs with web cameras. The
others based on mobile phones are SymBall [4] and
ARTennis [5] which allow face-to-face playing over the
Bluetooth connection. All these three games employ optical
tracking technology and use simple game strategy. In the
video game industry, the best-selling console Nintendo Wii
[6] with its motion sensing controllers allows the player to
interact with virtual items or opponent by the hybrid inertia
and optical tracking technology. Some ball-racket games
were released for Wii, which deliver complex game strategy
and support multiple players. However, none of the above
games deliver sufficient visual immersion.
By using stereoscopic display, more immersive games
have been developed. One employs marker-based infrared
tracking, rear-projection stereoscopic screen and complex
physics-based animation model [7]; and the other is AR
Table Tennis [8] that employs video tracking for a HeadMounted Display (HMD). However, these two systems are
only available for a single player. Although CyberTennis [9]
employs two HMDs to enable interaction of players, its use
of magnetic tracking restricts the movements of players.
The investigation of the related work has led to the
design of the proposed system based on the hybrid inertia

490
500

and ultrasonic sensing technology for fast motion tracking
and two large stereoscopic screens to provide view
dependent real scale immersion. Since table tennis game is
characterised by fast movements in a relatively small space,
it is a good prototype for demonstrating the capabilities of
the proposed system.
III.

SYSTEM HARDWARE

Figure 2. MicroTrax Tracking Devices

The hardware of the system contains three major
components: the tracking system, the display system and
computers with advanced graphic cards.

B. Display System
To create a visual illusion of depth, two large rearprojection stereoscopic screens are used with each providing
a correct 3D view for each player. The size of each screen is
2.74m in length and 2.06m in height to enable display of the
table tennis gaming environment in a real physical scale, and
the resolution is 1024h768 pixels. The configuration for
each screen is shown in Fig. 3. Two Epson PowerLite8800
projectors, situated at the back of the screen with a pair of
circular polarizing filters placed in front of the lens, are used
to superimpose two differently polarized images on the same
screen via a reflecting mirror. Each screen with two
projectors is driven by one computer through its graphics
card output ports. By wearing a pair of light-weight polarised
glasses, each player is able to see the 3D table tennis gaming
environment with depth effect.

A. Tracking System
Two most crucial parts for tracking in an immersive table
tennis game are the hand and head of each player. While
hand tracking is used to control the virtual racket, head
tracking enables the virtual scene to be changed in real-time
according to the viewpoint of each player. An IS-900
wireless tracking system from InterSense is used for this
purpose, since it is able to track in 6-DOF (6 degrees of
freedom: X, Y, Z, Yaw, Pitch, and Roll) without line of sight
requirements.
The InterSense system configuration is shown in Fig. 1,
SoniStrips containing ultrasonic SoniDisc transponders is
mounted on the ceiling, which transmits ultrasonic pulses
upon receiving addressed signals from the Processor Unit
connected to the serial port of the application host computer.
Each player wears a MicroTrax wireless head tracker and
holds a MicroTrax wireless wand (shown in Fig. 2), with
each one of them containing inertial sensors and ultrasonic
receivers. Whilst the outputs from the inertial sensors,
consisting of accelerometers and gyros, are used to
determine the position and orientation of each sensor in 3D
space, the range measurements based on time-of-flight
between ultrasonic emitters and receivers are used to correct
the drifting effect inherent within the inertial sensors.
SoniStrips

Figure 3. Rear-projection Stereoscopic Screen

MicroTrax Wireless Head Trackers and Wands

C. Computing System
The computing system consists of three PCs and each one
runs on an Intel Xeon 3.06GHz CPU with 2G RAMs and a
256MB NVIDIA Quadro FX3000 Graphic Card. One PC is
used as the server to run the application program, which is
responsible for the InterSense tracking control, data
processing and animation computation. The other two PCs
are used as clients, which each one renders the scene
according to the computation results sent from the server,
and drives a pair of projectors to provide an individual
stereoscopic display according to the viewpoint of each
player. The communication between the server and two
clients is based on the TCP/IP protocol, and data is
transmitted through a 1G Ethernet connection.

Wireless Receivers

Processor Unit

Application Host

Figure 1. InterSense System Configuration

501
491

IV.

SOFTWARE IMPLEMENTATION

With the application program run in the server and the
displays generated by the two clients, the software
implemented using the C++ programming language is based
on the software modules and data flow diagram illustrated in
Fig. 4. For the server computer, it runs the Motion Data
Acquisition Module to acquire position and orientation data
of the head and hand of each player from the tracking system
based on the InterSense Application Programming Interface
(API), the Motion Data Processing Module to provide player
viewpoints as well as positions and orientations of the virtual
rackets and avatars to be drawn by the two client computers,
and the Ball Animation and Audio Feedback Module to
provide the motion of the ball according to simplified
physical laws and a sound if a collision is detected. For the
two client computers, all fixed static virtual objects (e.g.
table, wall and floor) are pre-computed, and each one runs its
own Scene Generation Module to produce a stereo pair for
each screen upon receiving the dynamic object data from the
server.
1 Server
Tracking
System

Data

Ball
Animation
& Audio
Feedback

InterSense
Coordinate
System
xI
zI

Motion Data
Processing

.2.74m
1.88m
0.06m

Screen
y

.2.06m

60°

z

Global
Coordinate
System

x
2.37m

Floor

Figure 5. Projection and Coordinate Systems

The objects in the scene are formed by using basic
geometric models. The sizes of the ball (0.04m diameter) and
table (2.74m in length; 1.525m in width; 0.76m in height)
with net (0.1525m in height) are created according to the
specifications of a standard table tennis game. Since there are
no particular specifications for size or shape of the rackets,
two round shape rackets with the size of 0.16m in diameter
are used.
Two simple avatars with rigid bodies are used to show
the opponent position based on the player head positions
acquired. The right shoulder of each avatar is connected to
the corresponding racket with its position based on the hand
positions acquired. Although the movements of the avatars
are not realistic, they give players a good impression of
“playing with a moving opponent”. A screenshot of the view
created for one player is shown in Fig. 6

Screen
Generation

Responds

Commands

Motion Data
Acquisition

OpenGL
Frustum

1.76m

2 Clients
Data

yI

Ceiling

Stereo
Screen

Figure 4. Software Modules and Data Flow

A. Scene Generation
All objects in the scene are generated by using the C++
programming language with the OpenGL API [10]. OpenGL
uses a frustum of a pyramid to assign which parts of the
scene need to be rendered, and the virtual camera (player’s
viewpoint) is placed at the apex of the pyramid. With Fig. 5
illustrating the spatial relationship between the global
coordinate system, the local coordinate system used by
InterSense, and the OpenGL frustum. By using 60º viewing
angle, the origin of the global coordinate system is located at
the middle of the screen at a distance of 2.37m in front of the
screen along the z-axis. Since the InterSense coordinate
system has different coordinate orientations and origin
position as shown in Fig. 5, geometrical transformations are
need to bring InterSense data into the global coordinate
system, and this is performed in the Motion Data Processing
Module by the server before sending the acquired motion to
the two clients.

Figure 6. Scene Generated

B. Ball Animation
The ball movement model is derived from the method
proposed in [11], by applying simplified physical laws to
two basic states. One is flying that describes ball movement
due to inertia and is influenced by gravity (air resistance is
ignored for simplicity). The other is collision that describes

502
492

interaction between the ball and other virtual objects to gives
a new initial position and velocity of flying.
1) Flying
&
For a&ball at coordinate pb in the current frame with a
velocity vo , if there is no collision, the position of the ball in
next frame based on simplified physics laws is given by
&
p b'

t

&
&
1 &
vot  at 2  pb
2

(1)
and

time between update,
9.8 m s 2
to provide acceleration
in the vertical direction due to gravity. To simplify the
calculation, the velocity of ball in each time interval between
two frames is regarded as constant, &and is given by
&
a

is the
where
>0  g 0@T with g

If both ball and racket are moving, the position of the ball
is transformed into a moving coordinate system with respect
to the racket for collision detection. This is illustrated in Fig.
&
&'
8, where a ball flies& from pb to p b in two consecutive
v
frames with velocity b if no collision occurs, and a racket
&'
&
&
p
p
moves from p to p with velocity v r at the same time. To
&
p'
detect the collision, the predicted position b is shifted to
&
p b'' by the negative movement of the racket. This transforms

&
vb

the moving racket into a static one with respect to the ball
&
& ''
& ''
& ''
& ''
flying from pb to p b with velocity v b , with v b and p b
given by
&
&
&
&
&
vb" vb  v r
p b" v b" t  p b
(5)

&
at
vo 
2

If there is an intersection between the flying path and
&
p'
racket, such as c shown in Fig. 8, a collision occurs. Let
rr be the radius of the racket, d 1 and d 2 be the
&
& ''
p
displacements to the collision plane from p and p b
respectively, the conditions for a collision to occur can be
expressed as
&
&
d1d 2 d 0 and p c'  p p d rr
(6)

(2)
2) Collision Detection
In a table tennis game, the ball collides with three kinds
of objects at least: table, net and racket. The collisions with
table and net are treated as the situation that a ball collides
with a fixed stationary racket.
All the collision events are simulated as a particle
colliding with a flat plane. The collision between a ball and
the stationary racket is illustrated in Fig. 7, where
the particle
&
p
b to a collision
is at the
& centre of the ball, which flies from
p
as a disc with a thickness
point c . The racket is simplified
&
d thick , and its centre is at p r . Since the vertical distance

where
d1

from any potential collision point to the red surface of the
racket is equal to the radius of the ball rb , the centre of the
collision plane is given
by& Eqn.3.
&
&
p p p r  rb  d thick n red
(3)
&
n
where red is the normal of the red surface. Since a racket
&
n red
has two
potential
collision
planes
(with
two
normals
of
&
and nblack ), a collision plane is considered as correct if it
satisfies
& &
vb x n  0
(4)
&
&
v
n
where b is the velocity of the ball, and is the normal of
the corresponding collision plane.

of Ball)
& Particle (Center
&
pb
n red
&
&
pc
pp
Collision Plane

&
pr

>p& b  p& p @x n&
&
p c'

d2

§
d1
¨
¨d d
2
© 1

>p& b  p& p @x n&
·& '
¸v b t  p& b
¸
¹

&
the real collision point p c is given by
·&
§
d1
&
¸v t  p& b
pc ¨
¨d d ¸ b
2 ¹
© 1

&
pb

(7)

d1

rb

&
p 'p

&
pc

Collision Point

&
n

&
pp

&
pc'

&
pb'

&
pb''
d2

rb
d thick

Figure 8. Ball-Racket Collision Detection

&
nblack

3) Collision Response
Collision response follows collision detection. As
illustrated in Fig. 9 for a collision between a ball and a racket,
if the racket is stationary and there is no bounce damping, the

Figure 7. Particle and Collision Plane

503
493

&
&
ball flying into the racket from p b with velocity v b will
&'
&'
move to p b with velocity v b after collision. Since the angle
&'
of incidence is equal to the angle of reflection, v b is given
by

&
vb'

d shift

>

@

moves backward, its velocity does not act on the ball
movement.

&
pb'

&
vb'

Left eye

d eye

Right eye

d shift

FrustumShift

d near

d screen

D. User Interface
As shown in Fig. 11, a simple menu is provided with
three buttons of ‘Training’, ‘Start Game’ and ‘Quit’, which
can be selected by a virtual stick tracked by wireless wand.
The training mode allows a player to adjust the distance
between the virtual racket floating in space and his/her actual
hand holding the wireless wand, and to play with a ball
served by computer that is triggered by pressing the button
on the wireless wand. Selection of ‘Start Game’ activates the
game for two players.

&
vb
&
pc

(11)

Figure 10. Frustum Setting for Right Eye

&
pb
&
& v r'
&
& vr
n
vb"

0.00127m

Screen
Viewing

& & & &
2vb x n n  vb

(8)
If the racket is moving and the friction effect (spin)
is
&
v
r
only
ignored for simplicity, the velocity of the racket
&'
&
v
affects the ball along n as r if the racket goes forward to
& &
the ball v r x n t 0  . In this case, the ball will move towards
&
&
&
&
p b"
v"
v
p"
with velocity b after collision, with b and b given
by.
&
&
& & &
vb" f r vb'  v r x n n 0 d f r d 1
(9)
& " &"
p b vb t
(10)
f
r
is the bounce damping of the racket. If the racket
where

&
pb"

§ d eye ·§ d near ·
¸
¨¨
¸¸¨
¨
¸
© 2 ¹© d screen ¹

rb

Figure 9. Ball-Racket Collision Response

Since collisions may occur more than once in a time
interval between two consecutive frames, the next potential
collision point need to be calculated subsequently after the
first collision is detected. Therefore, if there is another
&
p"
collision occurs before the ball arrives b , the trajectory of
the ball will be changed again.

C. Stereoscopic Rendering
OpenGL supports stereo pair display, which is rendered
by left and right buffers. The asymmetric frustum parallel
projection method is adopted. Fig. 10 illustrates the frustum
settings for the right eye, where the frustum is first translated
from the tracked eye position (middle of two eyes) to right
d
side by half of intraocular distance eye , then shifted to
d
0.06m d near 0.1m
,
,
match the viewing screen. With eye

Figure 11. User Menu with Virtual Stick

V.

SYSTEM PERFORMANCE

As an example to show the immersive table tennis game
in operation, Fig. 12 shows two players standing in front of
their own stereoscopic screen and playing interactively with
each other through each other’s avatar in a shared virtual
environment.

d
and d screen 2.37m , the Frustum Shift parameter shift
that describes the degree of asymmetry is given by

504
494

in a client-server mode. The software development involves
the use of simplified physical laws to model ball movement
and collision. The system is seen to offer both players good
visual and audio effects with physical interaction. These
effects and physical interaction will be further investigated
by running a competition and questionnaire based user
evaluation. The system is viewed to provide not only a good
platform for many possible improvements, such as more
realistic avatars with full-body tracking and more realistic
ball movement by including other physical effects like
spinning, but also a useful basis for developing various
cooperative or competitive virtual reality applications.
REFERENCES

Figure 12. Two Players Play against Each Other

From the perspective of static object visualisation, each
player can physically move around in front of the display
screen and see a correct view of the 3D virtual table tennis
table with a depth impression.
From the perspective of dynamic object visualisation,
each player is able to see the position and orientation of
his/her virtual racket floating in space at the near side of the
virtual table tennis table, but also the position and orientation
of the opponent virtual racket at the other side of the virtual
table tennis table. The move made by one player will result
in a corresponding move of the position of his/her avatar
being displayed in the other screen. Although the movement
of avatar is not realistic, it does provide a good indication of
the opponent position. Furthermore, each player is able to
see the virtual ball flying into/out of their own screen as well
as hear a colliding sound when the virtual ball hits the virtual
table and rackets.
From the perspective of interaction, the simplicity and
intuitiveness of the game were seen to enable a new player to
control the virtual racket to hit the virtual ball quickly by just
holding and waving the wireless wand. Adjustment of the
virtual racket position with respect to the actual hand
position is found to be a good feature, as each player has
each own preferred distance to hit the virtual ball.
The performance of the system in terms of speed was
investigated. By recording the time taken for executing every
100 cycles, the execution time for each cycle was found to
vary between 16.56ms and 17.04ms with an average of
16.77ms. Hence, the system is capable to provide an
updating rate of 58.69 frames/s in the worst case.

[1]

Kay M. Stanney. Handbook of Virtual Environments: Design,
Implementation, and Applications. Lawrence Erlbaum Associates.
ISBN-10: 080583270X. ISBN-13: 9780805832709. 2002.
[2] D. Wormell, E. Foxlin. Advancements in 3D Interactive Devices for
Virtual Environments. Proceedings of the workshop on Virtual
environments 2003. ISBN: 1-58113-686-2. 47-56. 2003.
[3] Charles Woodward, Petri Honkamaa, Jani Jäppinen and Esa-Pekka
Pyökkimies. Camball: augmented virtual table tennis with real rackets.
Proceedings of the 2004 ACM SIGCHI International Conference on
Advances in computer entertainment technology. ISBN: 1-58113882-2. Vol.74. 275–276. 2004.
[4] Mika Hakkarainen, Charles Woodward. Symball: camera driven table
tennis for mobile phones. Proceedings of the 2005 ACM SIGCHI
International Conference on Advances in computer entertainment
technology. ISBN: 1-59593-110-4. Vol.265. 391–392. 2005.
[5] Anders Henrysson, Mark Billinghurst, Mark Ollila. Face to Face
Collaborative AR on Mobile Phones. Proceedings of the 4th
IEEE/ACM International Symposium on Mixed and Augmented
Reality. ISBN: 0-7695-2459-1. 80-89. 2005.
[6] http://www.nintendo.co.uk/NOE/en_GB/wii_54.html, Nintendo of
UK.
[7] Stephan Rusdorf, Guido Brunnett, Mario Lorenz and Tobias Winkler.
Real-Time Interaction with a Humanoid Avatar in an Immersive
Table Tennis Simulation. Transactions on Visualization and
Computer Graphics. IEEE. Vol.13. Issue1. 15-25. 2007.
[8] Jong-Seung Park, TaeYong Kim and Jong-Hyun Yoon. AR Table
Tennis: A Video-Based Augmented Reality Sports Game. Advances
in Artificial Reality and Tele-Existence. Springer Berlin/Heidelberg.
ISBN: 978-3-540-49776-9. Vol.4282/2006. 197-206. 2006.
[9] Tom Molet, Amaury Aubel, Tolga Çapin, Stéphane Carion, Elwin
Lee, Nadia Magnenat-Thalmann, Hansrudi Noser, Igor Pandzic, Gaël
Sannier, Daniel Thalmann. Anyone for Tennis? Teleoperators and
Virtual Environments. Vol.8. Issue.2. 140-156. 1999.
[10] Mason Woo, Jackie Neider, Tom Davis, Dave Shreiner. OpenGL
Programming Guide: The Official Guide to Learning OpenGL(R).
Version 2. Addison-Wesley Professional. Edition 5th. ISBN:
0321335732. 2005.
[11] Hansrudi Noser, Christian Stern, Peter Stucki, Daniel Thalmann.
Generic 3D Ball Animation Model for Networked Interactive VR
Environments. Proceedings of the Second International Conference
on Virtual Worlds. ISBN: 3-540-67707-0. Vol.1834. 77-90. 2000.

CONCLUSIONS
The paper presents a new and unique way for two players
to engage in immersive play of the table tennis game in realtime. The hardware development is based on integration of a
high speed wireless tracking system, two large rearprojection stereoscopic screens and three computers running

505
495

