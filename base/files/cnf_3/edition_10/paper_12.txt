A New Animation Approach for Visualizing Intelligent Agent Behaviours in a
Virtual Environment
Zhigang Wen, Q.H. Mehdi, and N.E. Gough
School of Computing and Information Technology
University of Wolverhampton, 35-49 Lichfield Street
Wolverhampton, WV1 1EQ, United Kingdom
E-Mail: IN6716@wlv.ac.uk

Abstract
Animated intelligent agents play an important role in
dynamic virtual environments. They are able to perform
behaviours based on internal states and external stimuli.
Animation techniques are crucial to agent behaviour
visualization in order to achieve effective interaction
between agents and human users. This paper proposes a
new animation procedure to visualise realistic intelligent
agent behaviours. The animation system consists of three
parts, namely synthetic vision, FzFSM with memory and
an animation library that uses mesh skinning techniques.
The agent is capable of exhibiting non-repetitive
behaviours to reflect change from both its internal states
and its environment. The system is implemented on a PC
platform with modern 3D acceleration hardware. The
result of this work can be applied to real time 3D graphics
applications in the field of entertainment and multimedia.

1. Introduction
Current software titles demand ‘smarter’ participants in
the simulated virtual world. For instance, in PC games,
the Non-Player-Characters (NPCs) controlled by the
computer are expected to appear as intelligent agents to
present the player with a better realism of the simulated
world. This demand also arises in other multimedia
software such as educational applications that present the
user with a virtual world populated with intelligent agents
such as virtual humans. Since intelligent agents inhabit a
dynamic and unpredictable world, they must be able to
perceive their environment and decide on their actions so
that they can achieve the goal using appropriate
behaviours. The required behaviours can then be
visualised by an animation (motor) library. This kind of
animation technique is categorized as behavioural
animation when compared to other traditional animation

techniques such as rigid body animation and physically
based animation. Generally, a typical behavioural
animation system comprises three main components,
namely perception, behaviour and motor [1, 2]. Due to the
limited computational power and real time performance,
realistic agent animation is one of the main concerns for
PC-based simulation. Various methods such as
hierarchical articulated rigid body animation and single
mesh blending animation have been applied to produce
real time character animation.
The hierarchical articulated body animation method
uses a hierarchical set of interconnected mesh pieces that
form the body of a character [3]. During the rendering, the
final transformation matrix is calculated in such a way
that it traverses the transformation matrices from the
higher hierarchy down to the lower hierarchy in forward
kinematics or vice versa in inverse kinematics. Since the
vertex information for the model including position,
texture co-ordinate and lighting normal needs to be stored
only once during program runtime, the memory usage
would be small. Another advantage of this technique is
that it is simple to implement and it can be executed
relatively quickly in software, which was an important
prerequisite for early real time 3D computer software [4].
However, one of the drawbacks of this method is the
result of an undesirable effect when a character’s limb is
rotated too far about a joint. Furthermore, it would be very
difficult to achieve smooth shading across the boundaries
of the separate mesh pieces because of the anomalous
perturbation of the vertex normal surrounding a joint.
A mesh blending method was introduced to implement
smooth character animation [4]. Rather than breaking a
character into separate body parts, the mesh blending
method produces a character in a single mesh object,
produces multiple slightly different copies of the character
model and generates real time animation by blending
these different models using various interpolation
methods. The main advantage of this method is the

Proceedings of the Sixth International Conference on Information Visualisation (IV’02)
1093-9547/02 $17.00 © 2002 IEEE

creation of smooth animation with no gaps or selfpenetration parts in the character model during runtime.
However, the shortcoming of this method still remains a
major issue. This is because the animator needs to model
all of the possible poses of the character in advance and
store them in a huge system database for use in runtime.
The problem is that after all the poses of the character
have been modelled and stored, it leaves hardly any
flexibility for the real time rendering engine to generate
various or non-repetitive animations based on user
interaction and changes of game environments.
Mesh skinning animation was introduced in order to
combine both advantages from articulated body animation
and single mesh blending animation, namely flexibility
and smoothness [5, 6]. Generally speaking, the mesh
skinning technique achieves this effect by allowing more
than one transformation matrix to affect the vertex’s final
position and lighting normal. The equations used to
calculate the transformation matrix are illustrated as
follows [7]. It is noted that the normal must be
For vertex position:
n

V final = ∑ wi M i v
i

∑w

i

=1

i

Where:

v is the vertex position
n is the number of matrices
wi is the associated weight
M i is the transformation matrix

(1)

For lighting normal of a vertex:
N

N final = ∑ wi M i−1 n
i

T

∑w

i

=1

i

Where:

n is the vertex normal
(2)
N is the number of matrices
wi is the associated weight
T
M i−1is the transposed inverse of transformation matrix
transformed by the transpose of the inverse of the matrix
used to transform geometry in order to achieve the correct
effect for back-face culling and shading [8].
The mesh skinning technique allows a mesh to be
deformed based on an underlying hierarchical
transformation matrix set. This animation method mimics
the way in which the skin is deformed by a skeleton in
reality. Furthermore, the animation can easily be
parameterised as a traditional pure skeletal animation,
which thus makes it a superior choice for intelligent
character animation. The following section depicts the
animation architecture developed by the present authors to
reflect the above method.

2. The animation architecture
The animation architecture used here is based on that
proposed in [9] and enhances the behavioural and graphics
part so as to adapt to the mesh skinning method. The
character perceives its environment from several data
channels named virtual sensor [1, 10]. The animation
architecture is shown as Figure 1. It shares some
similarities with the Quake SOAR architecture but differs
in the animation technique used [11].

2.1. The Sensorial input
The agent possesses two information channels, namely
vision and audition. Synthetic vision is the primary
information channel. Most autonomous animated agents
use “direct sensing” in which sensing is performed via
interrogation (or via direct state accessing method to
another agent). This approach has been widely applied in
most of the real time simulations such as NPC
construction in entertainment titles. However, this
approach has severe limitations in that it relies heavily on
a strict communication protocol and is not efficient in
obstacle avoidance and low-level navigation [12].
Compared to this direct state accessing method, synthetic
vision for animated agents would have several distinct
advantages including efficiency, scalability and less
dependence on the underlying implementation of virtual
environments. Since synthetic vision acts as the primary
information channel for the agent in the virtual
environment, the implementation of fast and efficient
vision becomes the primary issue in intelligent agent
animation. Numerous methods have been proposed [13,
14] to address this problem. Our choice is to use
hierarchical spatial scene representation for agent’s virtual
perception, which is similar to that proposed in [13].
The 3D environment needs to be pre-processed as a
hierarchical spatial representation. For instance, Octree
method is used in this work. An Octree simply organises
the voxels into a hierarchy. Any sub region that is
occupied by objects is further subdivided until the size of
the sub-region corresponds to the maximum resolution
required of the representation scheme. There are two ways
in which an Octree decomposition of a scene can be used
to represent the scene [11]. Firstly, an Octree can be used
in itself as a complete representation of the objects in the
scene. An alternative is to use a standard data structure
representation of the objects in the scene. In the C++
coding, they will be eight pointers that point to 8 different
memory locations that store the spatial information for the
rest of the scene objects. The Octree is constructed by
enclosing the entire scene in a minimal axis-aligned box.
The rest of the procedure is recursive, and starts by
checking whether the box contains fewer than a threshold

Proceedings of the Sixth International Conference on Information Visualisation (IV’02)
1093-9547/02 $17.00 © 2002 IEEE

information of “floating plant” will likely be discarded and
the information of “moving fish” will enhance the shark’s
dominant internal state “HUNGER” resulting in
behavioural actions such as chasing, rotating tail etc.
However, in another similar scenario, assume that the
above scenario is applied to a small fish. If the small fish
is hungry, object “float plant” will trigger the food hunting
related internal states and will subsequently affect certain
behaviours. Meanwhile, object “moving fish” may
increase its internal state “CAUTION”. Therefore, the
rules of this perceptual component may vary differently
depending on the character’s own behavioural routine.

number of primitives. If it does, the algorithm binds the
primitives to the box and then terminates the recursion.
Otherwise, it subdivides the box along its main axes using
three planes, thereby forming eight boxes. Each new box
is tested until it contains fewer than the threshold number
of primitives or the recursion has reached a pre-specified
depth [8]. Once the Octree has been constructed, the
visibility of objects in a complex scene can be performed
against the agent’s view frustum efficiently by traversing
or descending the tree structure. The computation can
dramatically be reduced since most of the visibility
calculations fall into a rather simple view frustum to box
intersection. Local area Z-buffering algorithm is used to
determine which specific object is visible to the agent via
synthetic vision.
The sensorial information is then passed to the
perception component to form the agent’s own “image” of
the world. The reason for this stage is that the intelligent
character’s beliefs are distinct from the actual states of the
world [15]. Therefore, the character cannot be allowed
access to the world model. Furthermore, not all perceived
information should be passed through this component to

2.2. FzFSM and memory
The FzFSM receives input information from the
perception component. A FzFSM differs from a traditional
finite state machine by giving each distinct state a fuzzy
set that normally ranges from 0 to 1 [16]. This “degree of
state” is useful for producing “degree of animation” that
will be described later. This information flow will
determine which internal states need to draw attention to

Sensorial Information
(Synthetic vision, virtual audition)
System
Clock
Perception Component

FzFSM

Parameters
Adjustment

Memory
Degradation
State 1

High Level
Behaviours

Behaviour 1

Low-level
Behavioural
Elements (BE)

BE 1

Skeletal
Bones

Bone 1

…

State 2

Behaviour 2

State N

Behaviour 3

…

BE 3

BE 2

BE N

Bone 3

Bone 2

Behaviour N

…

Bone N

Skin vertices bone indices
Skin Mesh

Skin patch 1

…

Skin patch 2

Skin patch N

Interaction
The Character Animation

Environment
&
Human User

Figure 1. Architecture of intelligent agent animation using mesh skinning

reach the internal states of character. This perception
component will also act as an “information filter”, which
extracts the useful information for the character’s active
internal states. For instance, when a hungry shark detects a
moving fish and a floating sea plant ahead, this sensorial
information will then be passed to the perception
component. The perception component firstly translates
these two objects’ world positions into positions relative to
the head of the shark so that once the action is determined,
the shark would know which direction to take. The

the newly arriving external stimuli. Some of the internal
states such as "HUNGER" may change according to the
time even without external stimuli. In the character’s
behaviour design, high-level behaviours refer to complex
behaviours that normally comprise of several behavioural
elements located in the lower layer of the animation
architecture. It is a fact that high-level behaviours are
more goal-oriented and more intuitively related to an
agent’s mental states. For instance, if the agent’s internal
state “HUNGER” reaches a high level, it would be more

Proceedings of the Sixth International Conference on Information Visualisation (IV’02)
1093-9547/02 $17.00 © 2002 IEEE

meaningful that a task-oriented high-level behaviour like
“Hunting for food” should be activated rather than directly
triggering several low-level behaviours elements such as
“chasing”, “turning” and so on. In the layer of
“behavioural elements”, each behavioural element is
associated with one or more of the character’s high-level
behaviours. For example, the high-level behaviour,
“Hunting for food”, will activate several behavioural
elements such as “chasing”, “accelerating”, etc.
During its navigation through the environment, an
intelligent agent will be able to form a mental map about
the spatial location of the objects. Each object that the
agent can remember will reside in the Octree and be
represented by an Octal Code representation such as
1324…. As time elapses, the agent will begin to forget
information, which therefore will affect the agent’s
behaviours. An agent’s “forgetting” can be implemented
as memory degradation [17] by losing the Octal Code of
locations lower in a hierarchy. This means, in effect, that
the agent will tend to forget exactly where an object and
increase the search for the possible location area.

2.3. Animation layer
As in mesh skinning animation, motion is applied to the
character’s skeletal bones rather than the “skin” seen by
the player and the behaviours will then have direct links to
the corresponding bones inside the character’s skeleton.
For example, the behavioural element “accelerating” will
activate the transformation matrix for the bone “tail” to be
manipulated during rendering. This implies that the
information contained in the bone transformation matrix

(a)

how hungry the character is, which can be a parameter
supplied to interpolating the transformation matrix of a
key position to generate different “degree of animation”
for sake of non-repetitive. Except for the character’s root
transformation matrix that can contain both translation and
rotation elements, all the transformation matrices that are
in the lower hierarchy will only contain rotation
information. The Quaternion method can be applied for
producing a smooth animation sequence between the key
positions via the Spherical Linear Interpolation [18]. In
this way, the behaviours that the character presents will be
more flexible and none-repetitive during run-time, which
substantially increases the believability of the character.
Thus, this bone layer will perform the most important task
in this animation system since it is in charge of generating
the underlying motions for the agent based on the its
internal states and other external stimuli such as run-time
simulation environments.

3. Example animation
This section applies the methodology described above
to a human character animation. The example animation is
implemented on a PC platform (Pentium4 1.5 GHz) with a
3D acceleration graphic card (nVidia Geforce 3) using
DirectX and C++. DirectX is a set of low-level
programming API to produce high performance real time
3D multimedia in PCs. With the introduction of a
“programmable rendering pipeline” via vertex shader and
pixel shader in DirectX 8, this has become more powerful
and flexible for use in other graphics applications. The
vertex shader was introduced to replace the transformation

(b)

(c)

Figure 2. Screen shots from the example animation
(a) Character* is walking
(b) Character is walking and looking around with caution
(c) Character is running away and looking around in a scared manner
*Mesh data from Poser

needs to be updated to reflect any change in the
character’s internal state. In addition, there is information
flow from the internal state layer. As every internal state is
a fuzzy set, it can normally vary from 0 to 1. For example,
“HUNGER=0” means that the character is not hungry;
“HUNGER=1” means that the character will die of
hunger. When the number is between 0 and 1, this reflects

and lighting fix-functions inside the DirectX
transformation pipeline in order to produce more desired
effects by the programmer. It is a small assembly language
program with 128 instructions. The instructions have
access to four different types of memory locations, namely
per-vertex data of an incoming vertex, constant memory,
temporary registers and per-vertex output-registers [19].

Proceedings of the Sixth International Conference on Information Visualisation (IV’02)
1093-9547/02 $17.00 © 2002 IEEE

When it is activated in program, it replaces the transform
and lighting computation from the fixed-function pipeline
for a vertex. A vertex shader operates on a single vertex at
a time. By incorporating the programmable vertex shader,
matrix palette skinning via vertex shader becomes the
most flexible way to implement mesh-skinning for
character animation in real time [20]. This implementation
method is fully supported in hardware and can
accommodate a flexible number of bones per vertex
depending on different rendering requirements. Therefore,
this method has been adopted in our animation example. A
typical vertex format that can employ the above mesh
skinning method is shown below, noting that the vertex
has a special index pointing to more than one
transformation bone matrix.

behaviours in a virtual environment. This method has been
shown to be an efficient way to generate real time
intelligent agent animation. The agent is capable of
performing various movements based on the run time
simulation environment, user interaction and its own
internal states. Future work will be carried out on
navigating the agent with its own synthetic vision in a
complex virtual environment to perform tasks such as path
finding, object relocation and obstacle avoidance. Another
concern will be to address a requirement to optimise the
vertex shader to produce more complicated character
animation.
Future work would also introduce a
benchmark test to assess the computational efficiency of
the proposed methodology.

struct VERTEX
{
ÃÃÃÃfloat x,y,z;
// vertex position
float weight0, weight1 ;
// bone matrices blend weights
DWORD matrixIndices[2]; // indices to matrices palette
float normal[3];
// vertex normal for lighting
float tu, tv;
// texture co-ordinate
D3DCOLOR color;
// diffuse colour

5. References

}

The character has around 19 bones and it is designed to
be able to exhibit its behaviours based on run-time of the
game environment and its internal states in real time. In
this example, the character is designed to several
behaviours based on the anthropomorphic qualities of
CAUTION, HAPPY, ANGER and DEAD. These qualities
represent four fuzzy sub-states of the agent. The character
also has several high level behaviour such as “navigating”,
“searching for object” and “running” together with
behavioural elements such as “waving arms”, “waving
legs”, “looking around”, etc.
In Figure 2a, the character is walking around with
HAPPY and CAUTION being kept at an intermediate
level. Figure 2b shows that the character is walking and
looking around with increased caution due to a sound
being detected. Figure 2c shows that after the CAUTION
level has reached a high level, the character is starting to
run away while looking around in a scared manner. The
“degree of internal states” can thus be visualised as
different “degrees of animation”. For instance, in the
example animation, the behaviour “running” and “looking
around” can have various values for speed and look
around frequency according to the degree of internal state
“CAUTION”. The rendering was executed on a Geforce 3
based computer system and achieved around 150 fps. It is
believed that any increase of agent complexity wouldn’t
slow the rendering speed excessively as most of the
rendering tasks are executed in the Graphics Processing
Unit (GPU) on the graphics card rather than in the CPU.

4. Conclusion and future work
This paper has outlined a design methodology and
proposed an architecture for visualizing intelligent agent

[1] D. Thalmann, “Physical, Behavioural, and Sensor-based
Animation”, Proc. Graphicon96 (St Petersburg, Russia), pp.214221.
[2] X.Tu, and T. Demetri, “Artificial fishes: physics, locomotion,
perception, behaviour”, Proc. SIGGRAPH’94, (Orlando, FL
USA, July24-29, 1994), pp.43-50.
[3] E. F. Anderson, “ Real-time character animation for
computer game”. http:// www.pope-mp.org.uk/ projects/tentacle,
last accessed 01/09/2001.
[4] B. Freidlin, “DirectX8: Enhancing real-time character
animation with matrix palette skinning and vertex shaders”. http:
//msdn.microsoft.com/ msdnmag/ issues/01/06/Matrix/print.asp,
last accessed 01/09/2001.
[5] J. Lander, “Skin them bones: game programming for the web
generation”,
http://www.darwin3d.com/gamedev.htm,
last
accessed 01/09/2001.
[6] J. Lander, “Slashing through real-time character animation”,
http://www.darwin3d.com/gamedev.htm,
last
accessed
01/09/2001
[7] S. Domine, “Mesh Skinning”, http://partners.nvidia.com /
Marketing/
Developer/
DevRel.nsf/
TechnicalPresentationsFrame?OpenPage,
last
accessed
01/09/2001.
[8] T. Moller, and E. Haines, Real-time Rendering, A K Peters
Natick, Massachusetts, 1999.
[9] Q. Mehdi, Z. Wen, N.E. Gough, “Visualization system for
agent behaviours in virtual environments”. Proc. 10th
International conference of Intelligent System, (Arlington,
Virginia USA, June 13-15, 2001), pp.47-50.
[10] D. Thalmann, D. “Virtual Sensors: A key Tools For the
Artificial Life of Virtual Actors”, In Proc. Pacific Graphics’95
(Singapore) 22-40.
[11] A. Watt, A. and F. Policarpo, 3D Games: Real-time
Rendering and Software Technology. Addison-Wesley, UK,
2001.
[12] B. M. Blumberg, “Go with the flow: synthetic vision for
autonomous animated creatures”, The First International
Conference on Autonomous Agents, 1997, Marina del Rey,
California, United States.
[13] R. Olivier Renault, “A vision-based approach to behavioural
animation”, The Journal of Visulization and Computer
Animation, Volume1, No.1, August 1990, pp18-21.

Proceedings of the Sixth International Conference on Information Visualisation (IV’02)
1093-9547/02 $17.00 © 2002 IEEE

[14] H. Noser, O. Renault, D. Thalmann, and N.M. Thalmann,
“Navigation for digital actors based on synthetic vision memory
and learning”, Computer and Graphics, Vol.19, No1, 1995, pp.719.
[15] I. D. Burke, R. Downie, M. Ivanov, Y and B.M. Blumberg,
“ Creature smarts: the art and architecture of a virtual brain”,
http://www.gdconf.com/archives/proceedings/2001/burke/Burke
R.htm, Last accessed 01/09/2001.
[16] N.E. Gough, H. Suliman, and Q. Mehdi, “Fuzzy state
machine modelling of agents and their environments for games”,
Proc. SCS Game On 2000, International Conference on
Intelligent Games and Simulation (London, UK, November 1112, 2000), pp. 61-68.
[17] H. Suliman, Q. Mehdi, N.E. Gough, “Spatial cognitive
maps in agent navigation and path planning”, Proceeding of
10thInternational Conference in Intelligent Systems, (Virginia,
USA, June 13-15, 2001), pp.27-31.
[18] K. Shoemake, “Animating rotation using quaternion
curves”. Proc. SIGGRAPH’85 (NewYork, NY, USA), pp.245254.
[19]
P.
Taylor,
“Using
vertex
shaders”,
http://www.microsoft.com/directx, last accessed 10/11/2001.
[20] M. Wloka, and C. Maughan, “Vertex shader introduction”.
http://partners.nvidia.com/Marketing/Developer/DevRel.nsf/Whi
tepapersFrame?OpenPage, last accessed 01/09/2001.

Proceedings of the Sixth International Conference on Information Visualisation (IV’02)
1093-9547/02 $17.00 © 2002 IEEE

