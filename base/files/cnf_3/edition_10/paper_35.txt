Do Four Eyes See Better than Two?
Collaborative versus Individual Discovery in Data Visualization Systems
Gloria Mark, Alfred Kobsa, Victor Gonzalez
Department of Information and Computer Science
University of California, Irvine
{gmark, kobsa, vmgyg}@ics.uci.edu
Abstract1
We present an empirical study investigating collaborative and individual decision-making about data using
two different information visualization systems. Based on
previous research, one system is considered more transparent than the other in terms of visual representation and
functionality. We found that people who worked in groups
were more correct in their answers for objective questions,
based on searching a large dataset. These results held for
the more transparent system, but not the less transparent
system. In a second task, groups were more accurate in
their results for a free data discovery task. Again, these
results held for the more transparent system only. Subjects
using this system also produced results that were higher in
complexity but judged lower in importance. Groups and
individuals did not differ. We suggest that given the right
visualization system, groups do better than individuals in
finding more accurate results, but not necessarily
increased or more meaningful results.

1. Introduction
A fairly large number of collaborative visualization
environments have been deployed to date, to support
learning, communication and discovery in groups (see e.g.,
CoVis [7], Cspray [14], CVD and Cave6D [9], TIDE [16],
iScape [4], COVISA [21], and several prototypes of DIVA
[17] and [5]. A tacit assumption underlying these systems
is that learning, communication and discovery will
improve when performed collaboratively.
Indeed, the development of these systems coincides
with an increasing trend of collaboration in organizations,
1

This research was supported by the National Science Foundation under
grant no. 9729843, by the Center for Research on Information
Technology and Organizations (CRITO), and by instrument grants from
Smart Technologies Inc, humanIT AG and Spotfire Inc. We would like to
thank Jeffrey Cheng, Cristina Gena and David Lim for helping with the
experiments and their evaluation.

with people working both collocated and remote from each
other [13]. In addition, organizations are becoming more
distributed [6], which is leading to new forms of collaboration and new technologies to support them.
The intent of this paper is to investigate whether and
how collaborative and individual decisions about information differ when different information visualization systems are used. We have specifically chosen to study two
forms of collaboration that are common in organizations
today: collocated and remote collaboration. We also
selected two information visualization systems with
different characteristics, according to previous research
[8]. We expected that these systems would have different
effects on group performance.

1.1. Collaborative
about data

and

individual

reasoning

Reasoning from visual information is a complex task,
and there are several rationales to suggest that such reasoning might be done differently by groups and individuals.
First, evidence suggests that the quality or accuracy of a
problem solution depends on the appropriateness of the
external problem representation [2, 11, 18]. Individual
differences in the representation of problems, displays, and
data have been well-documented (e.g. [3]). Individual
differences in problem-solving are also well-known (e.g.
[12]). Yet when people are in a group, a problem representation may be appropriate for one person, but not for
another. In this case, the group needs to negotiate a
common representation.
A second difference concerns the coordination cost of
working in a group. Group members need to make various
decisions at all phases of a collaborative decision-making
process. They must choose roles (e.g. who will operate the
system), they need to decide on a common strategy, and
they need to interpret the results.
We expect many other differences to exist as well. To
give some examples, a group’s pace may be limited by its

Proceedings of the Sixth International Conference on Information Visualisation (IV’02)
1093-9547/02 $17.00 © 2002 IEEE

slowest member. In contrast, the so-called "Eureka problems" are known to be solvable by the group in the time
that the quickest group member finds a solution [10].
There can be status or social effects in the group that
determine which decisions will be made. A person who is
deemed the expert can also affect the process.

1.2. Visualization systems used in this study
In this experiment, we have chosen two different visualization systems to examine group and individual differences: InfoZoom (formerly Focus [19, 20]) and Spotfire
(formerly IVEE [1]).2 InfoZoom presents data in three
different views. The wide view shows the current data set
in a table format, with rows representing the attributes and
columns the objects. The compressed view compresses the
visualization horizontally to fit the window width.
Numeric data values are thereby plotted as horizontal cellwide bars whose distance from the row bottom corresponds to their values. A row may be sorted in ascending
or descending order, with the values in the other rows
being rearranged accordingly to make each column represent one object. This operation reveals dependencies
between characteristics (like positive or negative correlations between numeric attributes). Hierarchical sorting of
two or more attributes is possible as well and can, e.g.,
reveal differences in the distribution of numeric attributes
in dependence of one or more non-numeric attributes). In
the overview mode, the values in the rows become
detached from their objects. Rows here represent the value
distributions of attributes in ascending or descending
order, and are independent of each other. In all three
views, values of (identical adjacent) attributes become
textually, numerically or symbolically displayed whenever
space permits this, which facilitates the comprehensibility
of the data [8].

We see that the years of work experience are highly correlated with age since their values increase in roughly the
same slope as age. In contrast, there is only a loose
relationship between age and years of education. Many
people of all ages have a high school education, which
becomes visible as a faint horizontal line. There is a higher
frequency of older people than younger people with less
than 12 years of education.
InfoZoom's central operation is “zooming” into information subspaces by double-clicking on attribute values,
or sets/ranges of values. InfoZoom thereupon shows
records only that contain the specific attribute value(s).
InfoZoom also allows one to define new variables that are
functionally dependent on one or two existing ones, to
highlight extreme values, and to create a variety of charts
(mostly for reporting purposes).
Spotfire offers several types of mostly familiar visualizations, including scatterplots, bar charts, pie charts,
graphs, parallel coordinates, trellises, etc. Unlike in
InfoZoom, they are interactive primary visualizations
between which the user can switch with ease. For each
visualization, two variables can be selected in pulldown
menus for display in the x and y coordinates, and a few
additional variables through a dialog window. Focusing on
information subspaces is performed by excluding or
including attribute values using sliders, checkboxes and
radio buttons.
Fig. 2 shows two bar charts in Spotfire that represent
average hourly wages, which are higher for union members
than for non-members. Filtering people by their residence
(by checking and unchecking the property "Live in
South?") reveals that this salary difference between union
members and non-members is more distinct in the South.

Fig. 1: InfoZoom's compressed view (gray datapoints
blackened for better reproduction)
Fig. 1 shows portions of a population survey in InfoZoom's compressed mode. The individuals are sorted by
age in ascending order (the database contains adults only).
2

The software versions used were InfoZoom 3.40 EN Professional from
humanIT AG (www.humanIT.com) and Spotfire DecisionSite 6.3 from
Spotfire, Inc. (www.spotfire.com).

Fig. 2: Bar chart visualization in Spotfire
In a prior study reported in [8], we found that Spotfire
imposes fairly high "cognitive setup costs": users took
considerable time to choose among the different visualizations that Spotfire offers and to set them up correctly,

Proceedings of the Sixth International Conference on Information Visualisation (IV’02)
1093-9547/02 $17.00 © 2002 IEEE

particularly when solutions included several variables and
therefore several steps. This seems to be due to the fact
that a significant portion of the data and the system's
functionality is not immediately visible and directly
accessible. Each different visualization that Spotfire offers
displays relatively few variables only, and setting up a
visualization requires accessing a fairly complex
"properties" menu. Users must plan in advance what
variables to use and how to visualize them. Since selecting
visualizations for the first one or two variables imposes
severe restrictions on how the remaining variables can be
visualized, the upfront planning must be very thorough and
comprehensive to avoid dead ends. This planning moreover must be performed without assistance from a visualization and takes considerable time.
Users of InfoZoom, in contrast, can rely much more
often on visual cues when accessing both data and system
functionality. (The only major exceptions are the dialog
windows for defining new "derived" variables and for the
charting function, both of which violate the otherwise
relatively straightforward "click on what you want" paradigm.) As we saw in video recordings of the prior study,
users therefore interact very effortlessly with the system.
They can also plan incrementally, i.e. perform a few steps,
see how far they have come, and proceed or switch to a
different view if the partial plan turned out to be wrong
(some users even developed a "click first - think
afterwards" problem solving behavior). InfoZoom can
therefore be regarded as more transparent than Spotfire,
where transparency refers to the system's quality to invoke
an easy-to-understand system image in users [15].
Taking this notion of transparency of systems into
account, along with the differences described earlier with
group and individual problem solving, we have developed
the following hypothesis: the higher planning efforts
required by the less transparent system Spotfire would lead
to more coordination overhead in a group situation, which
would negatively impact the group performance.

2. The Experiment
Subjects. One hundred undergraduate students with
majors in Information and Computer Science or Engineering at the University of California, Irvine participated in
the experiment. Subjects qualified for the experiment if
they had at least one year of computer usage. They
received $25 for their participation and competed for a
$100 prize for the best results in the discovery task of the
experiment.
Experimental Tasks. We chose two distinct types of
tasks to test, namely a focused question task and an openended discovery task, as we expected that the group
coordination required by these task types may be different.
The first task asked subjects to use anonymized data from

an online dating service to answer ten specific questions,
such as: "Did males cheat more on their girlfriends than
females on their boyfriends?" This problem resembles a
“Eureka problem” in that the problem has only one correct
answer that is immediately recognizable once it is located
on the information display. In the second task, subjects
were given 40 minutes and instructed to discover as many
findings in the data of a population survey as they could.3
The second task is free-form, and no specific background
knowledge is required to comprehend the data. Subjects
would need to make decisions as to whether a finding was
relevant, unlike the first task where only one correct finding exists and is (presumably) realized as correct once it is
seen.
Measures. In the first task, we measured the correctness
of responses based on subjects’ written answers on paper.
In the second task, we measured the number, accuracy, and
significance of findings, also based on their written
descriptions.
Experimental Design. The experiment used a twofactor between-subjects design. The factors were:
1) System - two factor levels:
a) InfoZoom: subjects used the Infozoom system in
both tasks.
b) Spotfire: subjects used the Spotfire system in both
tasks.
2) Interaction type - three factor levels:
a) Alone: subjects sat at a workstation by themselves.
b) Remote: subjects sat at workstations in adjacent
rooms. They performed the task while interacting
via Microsoft NetMeeting and a speaker phone.
They used either InfoZoom or Spotfire as shared
applications. Subjects did not see each other.
c) Shared Electronic Whiteboard: Two subjects
worked side-by-side in front of a large 60” diagonal
touch-sensitive electronic Whiteboard (SmartBoard), using either InfoZoom or Spotfire.
Subjects were randomly assigned to one of the
combined conditions of System and Interaction Type. In
the Remote and Shared Electronic Whiteboard conditions,
subjects were unacquainted with each other.
Procedure. In all conditions, subjects first received a
30-minute training on their visualization system. During
the first 10 minutes of the training, subjects received a
general demonstration of the main system functionality,
followed by a 20-minute hands-on tutorial using six
questions from an auto statistics database. Experimenters
3

[8] describes the dating data in more detail, as well as the auto
statistics data that we used for training. The free discoveries were made
using the http://lib.stat.cmu.edu/datasets/CPS_85_Wages file from the
CMU StatLib repository (variables were renamed to make them more
meaningful). All data sets used in the experiment are available from
http://www.ics.uci.edu/~kobsa/visexp/ .

Proceedings of the Sixth International Conference on Information Visualisation (IV’02)
1093-9547/02 $17.00 © 2002 IEEE

verified that subjects covered all questions and, if necessary, helped answer additional questions. After the training, the subjects were familiarized with the content of the
two datasets to be used in the tasks. Subjects in the Remote
and Electronic Whiteboard conditions additionally
practiced using these systems.
The first experimental task (focused questions) took 30
minutes and the subsequent free discovery task took 40
minutes. Subjects then filled in a short questionnaire and
were interviewed about their experience with the system.

3. Results
In general, subjects had little difficulty using the
systems to perform the tasks (this was also confirmed by
their responses in the final questionnaire). They also easily
adjusted to the usage of NetMeeting and the Smartboard.
We present the results for the focused question task first.
Task 1. In the first task, coders counted the correct
number of responses out of ten questions, based on verifying correctness beforehand. Table 1 shows the mean
number of correct responses, by condition.
Table 1: Mean and standard deviation of correct
responses to ten questions in the first task.
System
Interaction
Alone
Remote
Electronic
Whiteboard
Groups
combined

InfoZoom

Spotfire

Total

6.8 (1.7)
8.4 (1.0)

6.7 (1.6)
7.2 (2.1)

6.8 (1.6)
7.8 (1.7)

8.0 (2.0)

6.7 (1.2)

7.4 (1.8)

8.2 (1.6)

7.0 (1.7)

7.6 (1.7)

An ANOVA shows that subjects in the InfoZoom
condition answered more questions correctly, F(1,54)=4.1,
p<.05. Although there was a trend towards more correct
responses in both Remote and Electronic Whiteboard
group conditions, it did not reach significance at the .05
level: F(2, 54)=2.1, p<.1. There was no significant interaction.
As there was no difference between the two group
conditions, we combined their results to compare whether
being in any group differed from being alone when using
the systems. An ANOVA shows that being in a group (see
Groups Combined in Table 1), yielded higher correct
responses than working alone (F(1,56)=3.4, p<.07).
Broken down by system, with InfoZoom, the responses of
groups were significantly more correct than those of
individuals (F(1, 28)=5.0, p<.03), while no difference was
found for Spotfire.

Thus, for the focused question task, being in a group
(whether remote or face-to-face) resulted in more correct
responses than being alone. This difference, however, is
due to using the more transparent system (InfoZoom).
We now turn to the results of the second part of the
task: making discoveries with the data. One extreme
outlier was eliminated from the Alone condition since the
high number of responses were mostly nonsensical. Table
2 gives a summary of the findings. The column on the right
shows the average of both Remote and Electronic
Whiteboard conditions combined, to enable a simple individual and group contrast. Subjects in the Remote condition made the most discoveries using InfoZoom, nearly
25% more than Alone or Electronic Whiteboard. However,
an ANOVA showed the difference between Interaction
Types did not reach significance, F(1,53)=1.8, p<.17. This
was due to the large variability within each Interaction
Type condition. There was a significant difference
between systems, however. Subjects using Infozoom
produced significantly more findings than subjects using
Spotfire, F(1,53)=4.8, p<.03. There was no significant
interaction.
However, looking at the raw total of findings can be
misleading. Findings can be false, and they can also be
meaningless. We first verified the correctness of all
findings that subjects reported, and computed the ratio of
accurate findings to overall findings. An ANOVA did not
reveal differences between Remote and Electronic Whiteboard, so we combined these conditions. Using combined
groups, there was a significant Group by System interaction, F(1, 55)=3.9, p<.05. There were no main effects,
i.e. effects of Interaction Type or System. The interaction
means that groups were more accurate than individuals
when using InfoZoom. With Spotfire, groups and
individuals showed no difference in accuracy.
We next looked at the proportion of meaningful
findings. We developed criteria of what constitutes a
meaningful result. Such a result must include a comparison
between variables, indicate a minimum or maximum,
and/or it must have “surprise” value. For example, a result
of “The average age of a male construction worker that
lives in the south, and is married, is about 44 years” would
not be considered a particularly meaningful finding, as this
statement alone is only descriptive and not very
informative. It does not contrast this result with another
which would give it more meaning. On the other hand, a
result like “union members earn more than other workers”
would be considered meaningful as it represents a
comparison. Two coders first coded sample results to
calibrate themselves. They then coded the results
independently, with an agreement of 95.5%. Where there
was disagreement, the coders discussed each coded result
until they reached agreement. Most coder discrepancies
were due to oversights. An ANOVA on the proportion of

Proceedings of the Sixth International Conference on Information Visualisation (IV’02)
1093-9547/02 $17.00 © 2002 IEEE

meaningful results showed that the difference of System
approached significance, F(1,53)=3.5, p<.07. Using
Spotfire yielded more meaningful results. There was no
significant effect of Interaction Type, and no interaction.
Table 2: Summary of free data discovery task.
Means and standard deviations are shown.
Electronic Groups
W'board Comb.
21.10
13.9
17.5
(11.5)
(6.8)
(9.9)
12.7
12.3
12.5
(5.8)
(5.8)
(5.6)
.87
.87
.87
(.05)
(.05)
(.13)
.80
.81
.80
(.05)
(.05)
(.12)
.79
.79
.79
(.27)
(.26)
(.26)
.87
.97
.92
(.13)
(.03)
(.10)
28.5
20.5
24.5
(16.5)
(21.0)
(9.9)
18.8
19.7
19.3
(6.9)
(8.6)
(7.6)

Alone Remote

Mean
no. of
findings
Correctness

Infozoom
Spotfire
Infozoom
Spotfire
Infozoom

Meaningfulness
Spotfire
Net Productivity

Infozoom
Spotfire

14.2
(6.9)
11.8
(4.8)
.75
(.05)
.84
(.05)
.81
(.25)
.84
(.17)
23.1
(11.4)
16.6
(8.5)

We also investigated the complexity of the findings.
For instance, “Females with 30 or more years of work
experience make less per hour ($9.47) than males with 30
or more years of work experience ($15.02)” refers to the
variables of gender, years of work experience, and hourly
wage. This is more complex than a simple descriptive
finding of “There are 23% working in the Service sector”
(one variable). We defined complexity as the number of
variables involved and found that Spotfire results
(mean=1.52, sd=2.0) had significantly more findings with
a complexity of one variable than InfoZoom (mean=.27,
sd=.52), F(1,53)=11.8, p<.001. We then computed a
coarse measure of the total "net productivity" of each data
discovery session by adding the number of correct and
meaningful findings weighed by their complexities. An
ANOVA showed a main effect of System that approached
significance (InfoZoom mean=24.0, sd=4.4; Spotfire
mean=18.4, sd=4.4), F(1,53)=3.3, p<.08, but no Interaction Type effect and no interaction.

4. Discussion
In this experiment, we examined the effects that
different information visualization systems have on groups
and individuals. We selected two systems that we considered to differ in the amount of transparency they offered,
in terms of visual cues of the data and the available
functionality. Our hypothesis was that groups would

perform better than individuals with a more transparent
system, and most of our results are consistent with this
hypothesis.
To summarize our results, for the focused questions,
we found that being in a group yielded higher correct
responses than working on the answers individually, and
using the more transparent system (InfoZoom) resulted in
more correct responses than the less transparent system
(Spotfire). In the free data discovery task, we found a
significant Group by System interaction for accuracy of the
responses. Using the more transparent system led Groups
to have the most accurate responses, and Alone the least
accurate responses. Yet this difference did not occur with
the less transparent system (Spotfire). Using Spotfire
yielded more meaningful results for all Interaction Types.
Using the more transparent system (InfoZoom) led people
to make more complex findings.
In the focused question task, groups — whether
remote or working on a large Electronic Whiteboard —
did better than individuals. We attribute this result to
groups being more likely to find the correct answer than
individuals. In other words, the probability of finding the
correct result is the probability that the group contains one
person who can find the result. Groups of two have a
greater probability of finding the correct result than an
individual. While not exactly Eureka problems, the
problems in the focused question task resemble them
closely in that there was only one correct response. Once
the appropriate problem representation (i.e. visual
information display) was found, the answer could be
identified by anyone in the group. These results follow
those of Lorge and Solomon who found groups to perform
superior to individuals with Eureka problems [10].
The focused question problems can be broken down
into two stages. In the first stage, the appropriate problem
representation needed to be found, which involves
planning. In the second stage, the answer had to be identified from this display. When we broke the results down by
system, we found that they were due to the use of
InfoZoom, and not Spotfire. One explanation is that with
InfoZoom, there is less planning for groups in finding the
appropriate problem representation. In the second stage,
groups would also have a greater likelihood than individuals of finding the correct answer once the right information
display was selected. A system that is less transparent, and
which involves more planning, will not provide groups an
advantage over individuals, which is consistent with our
Spotfire results. However, a caveat is that it remains yet to
be learned where the groups’ superior performance
occurred: in the planning, the identification stage, or even
in both stages.
In our second task, we investigated free discovery of
data facts. Groups were more accurate than individuals.
Again, this advantage occurred with the more transparent

Proceedings of the Sixth International Conference on Information Visualisation (IV’02)
1093-9547/02 $17.00 © 2002 IEEE

system, InfoZoom, and not with the less transparent
system, Spotfire. We interpret our results to mean that
groups are more likely to locate and correct errors in their
findings than individuals. In a system where the visual
cues are more transparent, we would expect that the errors
are easier to recognize. Four eyes are better than two for
finding errors.
Spotfire users delivered more meaningful results, but
InfoZoom sessions yielded a higher total “net productivity”, taking the number, complexity, and meaningfulness of
all findings into account. It seems that with a transparent
system, one will wind up with a higher net productivity,
but will achieve this gain with quite a bit of noise (i.e. nonmeaningful findings). Unfortunately groups are no better
than individuals in sifting through and eliminating trivial
findings.
Though our results did not yield differences between
Remote and Electronic Whiteboard conditions, it is
important to keep in mind that in this study we just present
quantitative measures. We suspect that there are strong
differences in group processes, due to the different
physical proximities of the participants. Furthermore, the
Electronic Whiteboard provides an immersive experience
with the data. Gestures, body stance, and gaze were important features of this interaction with respect to using the
system. In the remote condition, this social information is
absent. To truly understand where these differences lie
would involve a qualitative study of the group processes.
We believe that our quantitative measures did not detect
these differences and intend to investigate them using
qualitative measures, e.g. video analysis, in future
research. Another avenue of future research will study
practice effects: it may be the case that data analysts with
long-time experience with a visualization system behave
very differently than newly-trained subjects.

5. Conclusions
Several collaborative information visualization systems
have been developed with the intent of providing a means
for viewing common data or for enabling different professions to view data. However, no one has addressed the
benefits that may arise simply by bringing people together,
independent of whether or not people have different
backgrounds. In this experiment, our results suggest that
bringing people together to view data can have benefits,
but they depend heavily on the kind of visualization
system used. We suggest that with a more transparent
system there is less coordination overhead for groups. The
main strengths of group work based on our data are that
groups are better at filtering out errors in the results. Four
eyes do not necessarily see more, but they see better than
two eyes (particularly if they are given the right lenses, i.e.
the right information visualization). A system that enables

clarity in a visual representation will tap the strengths of a
group in locating errors. It still remains to be seen,
however, whether the same benefits could be achieved in a
more cost-effective manner by having the two users work
individually in a sequence: one making the findings and
the other verifying them.

6. References
[1] C. Ahlberg and E. Wistrand, "IVEE: An Information Visualization and Exploration Environment", InfoVis'95, New
York, NY, 1995, pp. 66-73.
[2] J. R. Anderson, Cognitive Psychology and its Implications.
San Francisco, CA: W. H. Freeman and Co, 1980.
[3] C. L. Borgman, "Individual differences in the use of
information retrieval systems: Some issues and some data."
10th International ACM Special Interest Group on
Information Retrieval Conference, New Orleans, 1987, pp.
61-71.
[4] K. Börner, "A Collaborative Memory Palace for Digital
Library Search Results," in Usability Evaluation and
Interface Design. Proceedings of the 2001 International
Conference on Human-Computer Interaction., vol. 1, M. J.
Smith, G. Salvendy, D. Harris, and R. J. Koubek, Eds.
London: Lawrence Erlbaum, 2001, pp. 1160-1164.
[5] I. Brewer, A. M. MacEachren, H. Abdo, J. Gundrum, and
G. Otto, "Collaborative Geographic Visualization: Enabling
Shared Understanding of Environmental Processes",
InfoVis 2000: IEEE Symposium on Information Visualization, Salt Lake City, UT, 2000, pp. 137-141.
[6] M. Castells, The Rise of the Network Society. Blackwell:
Oxford, 1996.
[7] D. Edelson, R. Pea, and L. Gomez, "Constructivism in the
Collaboratory," in Constructivist Learning Environments:
Case Studies in Instructional Design, B. G. Wilson, Ed.
Englewood
Cliffs,
NJ:
Educational
Technology
Publications, 1996.
[8] A. Kobsa, "An Empirical Comparison of Three Commercial
Information Visualization Systems", IEEE Symposium on
Information Visualization, San Diego, CA, 2001, pp. 123130.
http://www.ics.uci.edu/~kobsa/papers/
2001INFOVIS-kobsa.pdf
[9] C. Lascara, G. Wheless, D. Cox, R. Patterson, S. Levy, A.
E. Johnson, and J. Leigh, "TeleImmersive Virtual Environments for Collaborative Knowledge Discovery", Advanced
Simulation Technologies Conference, San Diego, CA, 1999
http://evlweb.eecs.uic.edu/aej/papers/ astc99.pdf
[10] I. Lorge and H. Solomon, "Two models of group behavior
in the solution of Eureka-type problems.," Psychometrika,
vol. 20, pp. 139-148, 1955.
[11] A. Newell, "Reasoning, problem-solving, and decision
processes: The problem space as a fundamental category,"
in Attention and Performance VIII, R. Nickerson, Ed.:
Erlbaum, 1980.
[12] D. A. Norman, Memory and Attention. New York: Wiley,
1976.
[13] G. M. Olson and J. S. Olson, "Distance matters," HumanComputer Interaction, vol. 15, pp. 139-179, 2000.

Proceedings of the Sixth International Conference on Information Visualisation (IV’02)
1093-9547/02 $17.00 © 2002 IEEE

[14] A. Pang and C. M. Wittenbrink, "Collaborative 3D Visualization with CSpray," IEEE Computer Graphics and
Applications, vol. 17, pp. 32-41, 1997.
[15] J. Preece, Y. Rogers, and H. Sharp, Interaction Design:
Beyond Human-Computer Interaction. New York, NY:
Wiley, 2002.
[16] N. Sawant, C. Scharver, J. Leigh, A. Johnson, G. Reinhart,
E. Creel, S. Batchu, S. Bailey, and R. Grossman, "The TeleImmersive Data Explorer: A Distributed Architecture for
Collaborative Interactive Visualization of Large Data-sets",
4th International Immersive Projection Technology
Workshop, Ames, Iowa, 2000 http://evlweb.eecs.uic.
edu/cavern/TIDE/tide_ipt2000.pdf
[17] B. Schönhage, DIVA: Architectural Perspectives for
Information Visualization. Dissertation, Vrije Universiteit,
Amsterdam, Netherlands, 2000.
[18] S. Schwartz, "Modes of representation and problem solving:
Well evolved is half solved.," Journal of Experimental
Psychology, vol. 91, pp. 347-350, 1971.

[19] M. Spenke and C. Beilken, "Discovery Challenge: Visual,
Interactive Data Mining with InfoZoom – the Financial
Data Set", Workshop Notes on "Discovery Challenge", 3rd
European Conference on Principles and Practice of Knowledge Discovery in Databases, PKDD'99, 1999, pp. 33-38.
http://fit.gmd.de/~cici/InfoZoom/Discovery
Challenge/Financial.ps
[20] M. Spenke, C. Beilken, and T. Berlage, "The Interactive
Table for Product Comparison and Selection", UIST 96
Ninth Annual Symposium on User Interface Software and
Technology, Seattle, 1996, pp. 41-50. http://fit.gmd.de/
~cici/Focus/Paper/uist96.htm
[21] J. Wood, Collaborative Visualization, School of Computer
Studies, The University of Leeds, Leeds, England, 1998.

Proceedings of the Sixth International Conference on Information Visualisation (IV’02)
1093-9547/02 $17.00 © 2002 IEEE

