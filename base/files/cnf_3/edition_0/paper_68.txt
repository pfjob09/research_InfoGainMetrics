2012 16th International Conference on Information Visualisation

Augmented Reality for Construction Control
Kim Kirchbach
Institute for Technology and Management in Construction (TMB)
Karlsruhe Institute of Technology (KIT)
Karlsruhe, Germany
Kim.Kirchbach@kit.edu

In addition to the mentioned functions the vehicles are
endowed with software agents and act by means of them
in teams. They are able to swap information among each
other and eventually take further enquiry to a higher control
center. The main objective is to get the involved components
in a continuous ﬂow without any latency or downtime. The
result is a more efﬁcient utilization.
The idea is to provide a control center. These construction
site control center enables the operator to obtain an overview
of these huge data or rather of the running, relevant processes
on his site through a vr-based graphical user interface.
The planning and monitoring of a construction site is
not only a spatial complex problem but also strongly multidisciplinary shaped. Many people from several different
disciplines and educational backgrounds and with different
amounts of information have to work together. Vr and ar
are able to make a signiﬁcant contribution to achieve this.
Using vr visualization techniques an ergonomic and intuitive
layout is possible, which professionally supports all types of
users. A simple, clear display on the basis of ﬁrm data allows
achieving an established decision.
The potential of “visual management”, automation and
mobile user interfaces at construction sites is huge [3], [4],
[5].

Abstract—The development of a physical building control
center has got the purpose of supporting the management
and control of a project to optimize the ﬂow of the complex
processes at a construction site.
The concept consists of equipping vehicles with sensors,
using virtual reality and augmented reality-techniques to visualize these realtime information and allow an optical adaption
to current circumstances. A more efﬁcient utilization and
enhanced cost effectiveness will be the result.
Based on a previous performed requirement analysis a
software architecture (AR4CC, “Augmented Reality for Construction Control”) has been developed, which allows the use of
virtual reality (vr) and augmented reality (ar) at a construction
site. The basic idea of information transparency and the
generated software is introduced.
Two test-phases were performed and will be presented, one
of them in a computer on a virtual construction site and the
other one on a construction site mock-up, which was built
especially for this purpose.
Keywords-virtual reality; augmented reality; control center;
information transparency; process optimization; construction
site; information visualization;

I. I NTRODUCTION
The whole construction process is dynamic and consists
of many parallel processes. It is affected by troubles, which
appear within the construction sequence, and can inﬂuence
the workﬂow of a whole chain of building vehicles. Here
troubles can occur during the construction work, which
cannot be anticipated during the planning phase. Not optimal
co-operating teams of building vehicles are referred as
disturbance of the workﬂow. Aggravatingly each building
project is unique and a planning and control system does
not exist.
To address the mentioned issues building vehicles are
equipped with sensors. This is not a GPS-receiver like a car
sat, but rather a speciﬁc technology with increased accuracy.
Additional sensors are able to collect the excavator bucket,
shield tilting dozer position and orientation in an exact
way. Furthermore technical data like maintenance interval,
amount of diesel and pressure of engine oil are known, so
that a huge data basis exists.
This kind of continuity of 3D- and technical data may be
supported by attempts like Building Information Modeling
(BIM) and the 5D Initiative [1], [2].
1550-6037/12 $26.00 © 2012 IEEE
DOI 10.1109/IV.2012.76

Christoph Runde
Virtual Dimension Center (VDC)
Competence Center for Virtual Reality
Fellbach, Germany
Christoph.Runde@vdc-fellbach.de

II. I NFORMATION T RANSPARENCY
The basic idea is to use transparency to reduce waste.
This is a proved method within the area of building above
ground level. [6] In earth work this approach has not been
applied as it differs from the other parts in construction
engineering. Earth work is characterized by great uncertainty
and a huge dynamic. But still this principle is applicable
for continual improvement. The way is data transparency
for all concerned: A control center which combines all the
information.
Using this control center, which combines all the information and offers a data transparency to all participants, visualizing the differences between planning and execution phase
by virtual reality, it is possible to improve the construction
site into two different areas:
440

dynamic
Changes through the dynamic of the construction
process (e.g. change of the soil class, weather
conditions, . . .) can be identiﬁed. By offering a
decision support system based on real-time information the construction site can be optimized in a
faster and in particular a global way.
coordination
Through an improved constructive cooperation and
coordination of the numerous partners waste (e.g.
waiting or unproductive times) can be reduced.
Owing to an improved management of the dynamic processes and higher process-transparency (ﬁnding deviations
at shorter intervals) it is possible to better analyze the
reasons for the differences. A transparent analysis of the
root defect is furthermore allowing an implementation of
a continuous improvement process, covering even highly
dynamic environments such as the earth work.

It is the most common platform-independent programming
interface for the development of 2D and 3D computer
graphics (for further information see [10]). Additionally
with Glut4 (OpenGL Utility Toolkit) and Glew5 (OpenGL
Extension Wrangler Library) two OpenGL near libraries
are used. Glut simply appropriates platform-independent
functions for window management, menus and input devices.
Glew on the other hand provides support within the loading
of OpenGL extensions. A wrapper will be implemented
around ARToolkitPlus to accelerate the marker recognition
and adjust ARToolkitPlus to the special needs.
To ensure a dynamic and simple conﬁgurability, xmlParser6 , an open source library to read XML ﬁles, is integrated, which captivates by simplicity and efﬁciency. Also
a rudimentary math library was developed to make it easier
to work with angles, vectors and quaternions.
It is possible to use the generated architecture without
camera and augmented reality by parameterization. Therefore it allows the simultaneous use of it as “control center
software” but still providing the same functionality - parallels and double developments are to be avoided.

III. AR4CC
A requirements analyses were performed to identify the
speciﬁc needs within the project’s context. The instrument
chosen was interviews of experts and users (see [7]). A requirements analysis always starts with clarifying the relevant
object to be presented in VR. The second step is to ﬁnd out
the required way of computing, viewing and manipulating
this data. Finally a hardware setting is designed to fulﬁll the
derived requirements best possibly [8]. Among other things
it was requested, which objects, resources and parameters
were important and relevant and should be visualized in
which context. At the same time, which interaction, if at all,
with the visualized data should be reasonable conducted.
Also necessary action and animations, like alarms, were
identiﬁed. After the completion and evaluation of this requirements analysis and clarifying the relevant objects to be
presented in VR (see [7], [9]) a requirements speciﬁcation
document was the result. Based on this document a technical
speciﬁcation document was worked out and a software
architecture named “Augmented Reality for Construction
Control” (AR4CC) has been developed to meet with the
requirements relating to it. It is possible to create huge multi
marker scenes and interact with them. Value was attached
to capsulate all augmented reality functionality to easily add
new objects bases on inheritance structures, which can act
free from the ar problems. Knowledge within the ﬁeld of
augmented reality is not necessary to add new objects or to
set up “new” construction sites.
The architecture is based on ARToolkitPlus1 for marker
recognition and OpenCV2 as video-capture-framework.
OpenGL3 (Open Graphics Library) is used to display it.

A created geometry library manages all OpenGL objects,
their properties and global rendering methods. To display a
3D model or digital terrain model a model loader class is
implemented (using the template method, [11]). It is possible
to load VRML-, 3ds- and OBJ-ﬁles, which offers a wide
base for feasible 3D formats. Especially by integrating the
free formats VRML and OBJ, every common 3D modelling
program offers an export function; a high level of coverage
of available 3D formats is reached. Also framebuffer objects
and shaders are used to improve performance and for a more
realistic visualization.
Generally it must be possible to dynamically modify the
properties of the logical objects at runtime. That is why
several functions for information reload are provided, local
solutions based on XML but also databases can be connected. The display of context-sensitive information is easily
available e.g. by clicking on building vehicles. CEGUI7 is
used as a GUI visualization base, embedded in a modelview-controller pattern and with use of the observer pattern
(see [11]).
A graphical overview of AR4CC’s architecture can be
found in ﬁgure 1.
According to the result of the requirement analysis two
use cases were identiﬁed and elaborated. The control center
use case is presented in the following section IV, the on-site
use case in section V.

4 http://www.opengl.org/resources/libraries/glut/
1 http://handheldar.icg.tugraz.at/artoolkitplus.php

5 http://glew.sourceforge.net/

2 http://opencv.willowgarage.com/

6 http://www.applied-mathematics.net/tools/xmlParser.html

3 http://www.opengl.org/

7 http://www.cegui.org.uk/

441

Figure 1.

understand more precisely what happens in such an unclear
situation context-sensitive information can be called. After
processing this information, getting support by the software
and evaluating the scene, instructions can be displayed
directly to the dumpers’ drivers cab to adjust truck disposal.
He can then add refueling, bring forward his lunch break or
be advised to slow down his dumper to rest its’ material.
As a result all dumpers can drive equally-distributed at the
building site and are all in a continuous work ﬂow again.
By e.g. overlapping with a semi transparent digital terrain
model differences can easily be uncovered. By using a
history function, the site manager is able to track down
elapsed work tasks and might see what went wrong to take
appropriate steps for improvements or changes to prevent
them from happening again. The data will be saved, so
discrepancies between planning and execution phase (e.g.
changed type of soil) are documented. This might be the
base for change-order-management if external inﬂuences
unexpectedly cause delay.
Variance comparison in an operating state is the base
for efﬁcient project management and control as well as the
disposition and adaption of building vehicles to the current
situation. Consequences of changes in the ﬂow chart will
automatically adjust the time schedule. The impact will be
shown directly. The same applies to the interaction of costs,
so the site manager is knowledgeable at his best.

AR4CC architecture

IV. C ONTROL C ENTER U SE C ASE
For test purpose exemplary a virtual construction site is
drafted (see ﬁgure 2). In this regard it was made clear
that it is simple to obtain a good overview of the whole
construction site, which allows a global and not just a local
optimization. Additionally it is possible to move completely
unconstrained over the construction site and adjust the
camera the needs of the operator. Not only building vehicles
but also a digital terrain model and any objects to reproduce
the construction site close to reality are visualized.

Figure 2.

V. O N -S ITE U SE C ASE
To support the site manager during his inspection of the
construction site, AR4CC can be applied on a mobile device
on site. It is able to access context-sensitive information,
regarding to his position or what he sees (through a camera
on his mobile devices). By overlaying a digital terrain model
variance comparison is possible.
[12] and [13] also see AR as the adequate technique to
optimize processes at construction sites. Workers are able
to do their action simpler and more efﬁcient, supported in a
comfortable way by visual information, usable in different
areas at the building site.

construction site overview

Long queues of dumpers while removing binder soil can
be recognized straightforward just by watching the screen,
even if the construction is several kilometers long. In order to

Figure 3.

442

setup construction site mock-up

To get a more realistic test environment a construction
site mock-up is build. Therefore an “in-house sandbox” of
4x3,5m is constructed, a terrain model with height proﬁle
is backﬁlled and model-making building vehicles on a scale
of 1:14,5 are used. The excavator for example has a length
of approximately 80cm and a height about 22cm. Figure 3
shows an early state of part of this mock-up.
For the recording and conversion of the terrain model into
a digital one, several processes were compared and it was
decided to use a time-of-ﬂight camera, as it achieves very
good and fast results by easy preparation. The scene will
be illuminated by light pulses and the camera measures for
each image point the time of the light on his way to the
object and back (see [14]). This time is commensurate to
the distance and in this way the camera detects oblique the
distance of each point. Knowing the distance from camera
to the ground it is possible to generate an elevation model
of the terrain. At a real construction site the recording of
the terrain will be done by laser scanning, gps, tachymeter
and additionally sensors at e.g. the shield of a dozer.
As gps is not a proper solution for tracking in-house and in
a small area, marker-based tracking is appointed to track the
mobile devices (see [15]), because of the free working area
during use of the tablet pc there will be lots of occlusion to
deal with. In addition this is supported by AR4CC’s function
of multi-marker scenes. Although the marker-based tracking
is a bit slower than other methods, it allows an unrestricted
working area as expected by a tablet. An adaption of the
AR4CC’s conﬁguration to the limited computing power of
the tablet pc took place.
All recorded data shall be saved and distributed by a
consistent communication platform. It is used directly at the
construction site, stores position and orientation of building
vehicles among other things in a database and allows its
real-time demand and distribution. The only difference is
the generation of these data by vr and ar tracking methods
instead of gps.

tion has been very sufﬁcient. It is an easy opportunity to
gather information by seeing real vehicles trough a camera
and just clicking on it. It helps to understand the current
situation or the progress of a task in a simple manner without
the need to browse planning sheets or walk to the drivers.
Using a table-top interface the construction site mockup can be controlled and monitored (see ﬁgure 5, compare
section IV).

Figure 5.

control center mock-up

Performing tests within the sandbox is the ﬁrst step of the
evaluation of AR4CC. After a more detailed consideration in
the mock-up, the next step is to test it on a real construction
site.
VI. C ONCLUSION
Using AR4CC, a ﬂexible and dynamic architecture is
developed, which enables the use of vr and ar technology.
Therefore it makes varied functions and methods available,
which permit detailed adaptions to the current problem and
at the same time remains conﬁgurable even for users without
programming skills or computer science background.
A construction site mock-up was built for the purpose of
testing the vr and ar functionality and clearly demonstrated
the applicability to the construction site as well as the beneﬁt
for the site manager.
The control center information does not only show the
direct environment but also vehicles working far away,
which allows a global and not just a local optimization.
Information transparency is a great opportunity to an enhanced performance on construction sites and promises good
beneﬁts.
ACKNOWLEDGMENT
The project referred to in this report has been co-funded
by the Federal Ministry of Economics and Technology; the
project funding reference number is 01MA09015. The author shall be responsible for the contents of this publication.

Figure 4. Screenshot using a tablet pc viewing context-speciﬁc information

Figure 4 shows the screen of a tablet pc while viewing
context-speciﬁc information about a dumper. This experience underlines, that using this way of retrieval of intorma-

443

R EFERENCES

[13] D. H. Shin and P. S. Dunston, “Identiﬁcation of application
areas for augmented reality in industrial construction based
on technology suitability,” Automation in Construction, Vol.
17, No. 7, 2008.

[1] C. Eastman, P. Teicholz, R. Sacks, and K. Liston, BIM handbook: a guide to building information modeling for owners,
managers, designers, engineers, and contractors. John Wiley
and Sons, 2008.

[14] T. Ringbeck and B. Hagebeuker, “A 3d time of ﬂight camera
for object detection,” Proceedings Optical 3-D Measurement
Techniques, ETH Z¨urich, 2007.

[2] Zueblin AG, “Position paper of the european construction
industry for developing model-based it tools for planning, realising and operating buildings, facilities and infrastructure,”
5D Initiative - Initiative of the European construction industry
for the development of new IT tools for design, realisation and
operation of buildings and infrastructure, 2009.

[15] H. Kato and M. Billinghurst, “Marker tracking and hmd
calibration for a video-based augmented reality conferencing
system,” in Proceedings of the 2nd IEEE and ACM International Workshop on Augmented Reality. Washington, DC,
USA: IEEE Computer Society, 1999, pp. 85–94.

[3] C. T. Haas and Y.-S. Kim, “Automation in infrastructure
construction,” Construction Innovation 2002, pp. 191–210,
2002.
[4] A. Tezel, L. Koskela, and P. Tzortzopoulos, “Visual management in lean construction,” 8th International Postgraduate
Research Conference, 2008.
[5] C. R. Wood and M. W. Alvarez, “Emerging construction
technologies - a ﬁatech catalogue,” Fiatech, Construction
Industry Institute, University of Texas, USA, 2005.
[6] L. Koskela, “An exploration towards a production theory and
its application to construction,” Dissertation, VTT Publications 408, VTT Technical Research Centre of Finland, 2000.
[7] K. Kirchbach and C. Runde, “Optimized work ﬂow through vr
and ar technology on construction sites,” Proceedings of the
15th International Conference on Information Visualization,
IEEE Computer Society, London, United Kingdom, pp. 549–
551, 2011.
[8] J. Whyte, “Business drivers for the use of virtual reality
in the construction sector,” in Chalmers University of Technology (editor): Conference on Applied Virtual Reality in
Engineering & Construction. Applications of Virtual Reality.
Current Initiatives and Future Challenges, Oct. 4.-5., 2001.
Gteborg/Sweden: Chalmers University of Technology, 2001,
pp. 99–105.
[9] K. Kirchbach and C. Runde, “Vr-based construction site
control center,” in Proceedings of the 11th International
Conference on Construction Applications of Virtual Reality.
Bargst¨adt, Hans-Joachim and Ailland, Karin, November 2011,
pp. 136–141.
[10] D. Shreiner and O. A. R. Board, OpenGL programming guide:
the ofﬁcial guide to learning OpenGL, version 2, ser. OpenGL
Series. Addison-Wesley, 2006.
[11] E. Gamma, Design Patterns: Elements of Reusable ObjectOriented Software, ser. Addison-Wesley professional computing series. Addison-Wesley, 2009.
[12] P. S. Dunston and D. H. Shin, “Key areas and issues for augmented reality applications on construction sites,” in Mixed
Reality In Architecture, Design, And Construction, X. Wang
and M. A. Schnabel, Eds. Springer Science + Business
Media B.V., 2009.

444

