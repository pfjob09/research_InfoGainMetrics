2012 16th International Conference on Information Visualisation

PRISMA-MDE - Distributed and Scalable Environment for Multiple Views of
Data Coordinates.
Roberto Yuri da Silva Franco¹, Ranieri Barros Teixeira², Rafael Veras Guimarães², Nikolas Jorge
Santiago Carneiro², Aruanda Simoes Meiguins², Bianchi Serique Meiguins¹.
¹Programa de Pós-Graduação em Ciência da Computação – Universidade Federal do Pará (UFPA).
²Rede de Informática Ltda.
{roberto.yuri.franco@gmail.com, ranibtx@gmail.com, rafaveguim@gmail.com,
nikolas.carneiro@gmail.com, aruanda@redeinformatica.com.br, bianchi.serique@terra.com.br}
The big challenge is on the adaptation of the usual
visualization systems to distributed environments of
multiple viewers. The distributed visualization
information environment of multiple viewers is
composed by several display devices [1] and the user has
the screens projected in front of him. Those devices can
be of different kinds and sizes (monitors, multimedia
projectors, and others) [2] and also can be connected one
by one to various computers. [1].
Like this, this article presents an interactive IV tool
with multiple views of coordinated data in a distributed
computing environment using multiple screens, called
PRISMA-MDE. Besides, it proposes a redirection
system of keyboard and mouse for MDE environments,
evaluates the user behavior with the tool, and presents
performance preliminary tests of the tool. The project
uses the PRISMA tool of IV responsible for generate the
multiple coordinated views and the LIBGLASS [10]
framework for distributed computing that manages the
communication between the computers.
The rest of the paper is organized as: In section 2
presents the related works and some references. Section
3 shows the MDE and the PRISMA tool. The section 4
contains the proposal of this article and how it was
developed. Section 5 presents the preliminary results and
the last section the conclusion and future works.
References are presents in the end of the paper.

Abstract
Multi-display environment (MDE) has evolved in
recent years; however, the adjustment of common
visualization system to MDEs poses several challenges.
This paper describes an information visualization (IV)
tool for a distributed and scalable environment with
coordinated multiple views of data, which simulates an
extended desktop across multi-display. This work is
limited to the use of three monitors. This document
presents satisfactory results of preliminary tests of
usability. Performance tests showed an IV pipeline is
more optimized than the common visualization tool.
Keywords--- Information Visualization, MDE,
Visualization Tool, Distributed Computing.

1. Introduction
The use of multiple data views has been frequently
used in IV tools, aiming improve the perception about
the data and their relationships, enhanced demand by the
large amount of analysis data in several areas of human
knowledge.The multiple data views can be understood as
various individual information visualization tools, so it’s
natural to realize that is a visualization pipeline (read,
filter, map, render, Interact) for each one of those tools,
which needs more “processing”, the greater the number
of data views. Besides, the visual analysis of large data
amount can be damaged by the physical limitation of the
viewers, causing occlusion of the information. On the
one hand, the use of multiple coordinated data views
allows the visual analysis of the data in various
perspectives, on the other, the views compete for space,
compromising the massive database visualization, due to
the aforementioned occlusion problem.
A distributed environment of IV can provide the
processing power that is needed to attend the various
demands of an IV process, allows a larger view to
represent the some data views, using multiple views, and
grow naturally as the demand requires visual analysis.

1550-6037/12 $26.00 © 2012 IEEE
DOI 10.1109/IV.2012.108

2. Related Work
Were used several papers about MDE, then, the
contribution of this work are present. Was used to design
considerations for the visualization application with
multi-display, proposed by WALDNER, et al. [5], we
haven’t used the design considerations for multi-display
collaborative environment, because the focus of this
paper isn’t collaborative environments. This uses the
taxonomy of visualization types with multiple visions in
MDE proposed by: SHEN, et al. [4].

646

Multiple coordinated views can facilitate the user’s
perception on a context of large amount
multidimensional data. This approach allows it to be
established correlation between different views of the
same data set. The coordination ensures that interactions
performed on a data view are propagated trough the other
views.It can be present on the tasks of filtering, selection,
zoom, sorting or visual mapping of attributes [12].
PRISMA supports the main features considered
essential by the community of an IV tool: overview,
zoom, filters, details on demand, presents relations
between the data and action history [8]. However, the
multiple coordinated views resource imposes to the user
an important trade off. On the one hand, the resource
allows the visual analysis of the data under several
perspectives, on the other, the views compete for space,
compromising the massive databases visualization, due
to already mentioned problem of occlusion. The Figure 1
and 2 present two options of tool layout. It’s possible to
see that in both viewing space isn’t enough.

This paper used the concepts of redirection system
for keyboard and mouse to be used in MDE, with
multiple computers, proposed by: JOHANSON,
HUTCHINS, et al. [1]. We used the methods of multiple
devices environments presented by FORLINES and
LILIEN [2] and BRAGDONI, et al. [3].

3. Information Visualization (IV)
The IV research area studies the transformation of
abstract data in images easily understood by humans [6].
Computational tools of IV must support the interaction
and the mechanisms of data presentation, allowing the
reorganization of multidimensional data easily,
efficiently and visually [7].
Characteristics of a good IV tool, proposed by
Spence [6] are: Overview of data set, zoom: focus on
subset of data, filter: reduction of the data set according
with the values of the specified attributes, details on
Demand: Additional data provided by an action taken by
the user, relations: the ability to link the data items with
similar characteristics and history: the ability to undo an
action and show the performed steps to the current point.

3.1. Multi-Display Environment (MDE)
MDEs are computer systems where several monitors
are used to solve the problem of lack of space for
graphical interface viewing [1]. The monitors can be of
different kinds [2] and be connected to one or various
computers [1].
There are various interaction techniques for MDE, in
order to explore their specifics possibilities. An
important point is how the system handles with input
devices and how the content is presented trough the
several screens. Various projects based on this type of
environment apply input redirection or content
redirection for interaction with the devices [9].
On the input redirection, the user controls one only
input device to interact with objects on the several
screens, in other words, to reach an item on a screen, the
user must move the mouse there.
There are two mains approach to let this
displacement. On the Extended Desktop mode, the user
moves the mouse cursor trough the screens, as if was
interacting with a single desktop. On the Multi-Monitor
Mouse mode, the user moves the cursor from a screen to
another by pressing one key of the keyboard.
The content redirection allows that the content of
one screen be viewed in other. The user uses one only
screen to interact with the content of the others. Unlike
input redirection, isn’t cursor that moves, but the content.

Figure 1. PRISMA organized in mosaic.
On figure 1, the views are organized like a mosaic.
Although this layout facilitate the simultaneous analysis
of the views, it is necessary present them with reduced
size, so that the screen can comprises them fully. On
these conditions, the high density of visual items on the
scatter plots and parallel coordinates makes very difficult
the selection of individual items. Even the treemap,
space filling technique [13] less vulnerable to space
limitations, also has problems when used in an high
number of hierarchical levels – the less representative
groups are practically omitted. In a different way, the
interface of Figure 2, with the views arranged side by
side, is also not ideal. Although the visions have more
appropriate scale, the user needs to use the scroll bar,
which results in great efforts, especially to realize the
relationship between the data.

3.2. PRISMA tool
The starting point to the development of the proposed
system is the PRISMA IV tool [11]. This tool was
chosen because is a desktop tool based in multiple
coordinated views, which has three principal techniques:
scatter plot [6], parallel coordinates and treemap.

Figure 2. Multi-views arranged side by side.

647

to input information exchange (keyboard and mouse) or
coordination between views (select, filter, color).

4. Prisma MDE (Multi-Display Environment)
The PRISMA-MDE tool with support to multiple
distributed displays allows the user to interact with three
complete instances of the application in parallel. I.e.,
each instance is executed on a computer itself, displaying
the results of a different visualization technique.
Using complete computers, and not just plug more
monitors in the system, is possible to count with the
computer resources to load and manipulate increasing
databases, without harming the user’s interaction. The
choice of three machines was motivated by the use of the
three main visualization techniques supported by
PRISMA. The user can still add more techniques to each
instance of PRISMA, or more computers.
Was chosen on this project give the impression of a
continuous extended desktop to the user, like the layout
of Figure 3, with the proposal of facilitate the interaction
with mouse between the different screens giving the
impression of a continuous view. Like this, the monitors
organization was arranged side by side and the way of
interaction chosen was input redirection (Figure 3). One
disadvantage occurs in environments with many screens,
eg, if it has ten monitors the mouse’s movement will be
slow.

Figure 4. Architecture of the PRISMA MDE tool.
The figure 4 presents the architecture of PRISMA
MDE tool, for the configuration of three screens on three
computers. The tool has a common database to all the
computers, and a control Server (GlassServer), that is
located on the master client (PRISMA 1), but it could be
installed in a forth computer. The system operates inside
of a computer network, but can be easily extended to
work in the cloud concept.

4.2. GlassServer
GlassServer is a client control Server (GlassClient),
i.e., is responsible for forwarding the data and the mouse
and keyboards events (user’s input) to the appropriated
client. This server stays inside of the “master client” that
is usually executed on the central computer on your own
JVM (JAVA Virtual Machine), and ensures that clients
exchange encapsulated informations in Event objects.

Figure 3. Example of a MDE.
The figure 3 exemplifies a MDE with input
redirection (mouse and keyboard).

4.3. GlassClient

4.1. PRISMA MDE architecture

The clients with the role “common node” usually are
executed on the side computers and are responsible for
synthesizing in your computer, input events sent by the
“master”. Both the “master” client and the “nodes” can
send and process coordination events. Besides, the
clients process the database, and output data of filters.

To support the communication of the computers was
used the libGlass library to distributed computing and
cloud computing, focusing on high performance, low
latency applications, virtual and augmented reality [10].
The libGlass framework is a scalable set of
components that can be used for applications to execute
distributed computing. The main objective of libGlass is
be a user-friendly framework, not only suitable for new
applications, but also for legacy code. This library was
developed on JAVA programming language. [10].
The Glass computing units are called “clients” or
“nodes” and are implemented by the GlassClient class.
The clients do not communicate among themselves
directly, but use a ClassServer as intermediary.
GlassServer manages the communication of the nodes
and sincronize your execution.
The nodes exchange encapsulated informations in
abstract data types offered by Glass, like shared
variables, barriers, alias and events [10]. Specifically, on
this work, was used the event type, from the Event class,

4.4. Operation

Figure 5. Overview of system PRISMA with
multiple screens.

648

The Figure 5 shows three instances of PRISMA,
organized according to the client-server architecture.
Each instance is executed in your own computer, keeps
one GlassClient object for communication and loads all
the items in a same base (red lines).
The nodes execution/communication steps are:
• GlassServer executes and waits connections;
•
“Master” client executes and initializes thread
to wait the nodes initiation;
• The side nodes execute and inform the master
your location (left or right) and your ID (used by the
master to specify the server wants to communicate);
• The user begins the interaction and, if needs to
manipulate other view, moves the mouse to the side until
the cursor reaches the screen edge (the applications run
in full screen mode);
• The master identified the event and redirect the
input to the correspondent screen, basing on the location
and ID of the node;
• Any mouse interaction with components of the
GUI (buttons clicks) Will be reproduced on the computer
where the cursor is activated. Any interaction with data
(items selection) will reproduced in all clients.
The figure 6 shows an overview of PRISMA MDE.

Science Computer formation and users with information
visualization experience.
The selected database to the usability tests was a
data set about cars, containing informations about
Americans cars, Japanese and Europeans manufactured
between 1970 and 1982 [14]. The data set was chosen
because of the familiarity that the users have with cars
information, and the use in previously works [11; 21].
The data set includes 789 items, including five
continuous attributes, (acceleration, MPG, weight, shift
and Power) and three categorical attributes (year,
cylinder and origin).
Below are presented the four tasks that were used
during the tests, two with low complexity (1 and 2) and
two with medium complexity (3 and 4).
1. The most cars that have two cylinders are heavier
than those with eight cylinders? Answer: No.
2. Are there any car produced in 1980 that has greater
value than cars produced in 1990? A: Yes.
3. What years were made only cars with gas? A: 1987.
4. What are the value, brand and type of the car with
major potency? A: 288, Porsche, hatch, 31780.
At the end of the test was applied a form with 14
questions to evaluate the functioning of the tool and how
the user felt when using it.
In questions 1, 2, 3, 4, 5, 9 and 10, users had to rank
the four tasks, rank understanding of the database, rank
an action of configure and filter in: Very easy, Easy,
Normal, Hard, And Very Hard. Questions 6 and 7, users
had to rate the feelings of using mouse in three monitors
and three monitors in: Very comfortable, comfortable,
normal, uncomfortable, and very uncomfortable.
Questions 8, 12 and 13 users respond if set up more
than one technique in the same task, if made use
brushing and if the tool helped. The question 11, users
should rate the function coordination between the views,
in: doesn’t help, helps a little, helps, and helps a lot. The
question 14 asks if it is better to have different
techniques or different views of the same data.
The tests were made in an environment with two 40
inches screens, one 42 inches screen, two notebooks with
core 2 duo processor and 4GB RAM memory, and one
notebook with core i3 processor and 4GB RAM memory,
one mouse and one keyboard. On figure 7 is showed a
Picture of this environment.

Figure 6. Overview of MDE of PRISMA tool.
The interaction with the tool is done with the mouse
and keyboard of the central computer, being extended to
all screens. Each screen has your own minimized
configuration, and be accessed at any time. Those
configurations include filters on the database, hierarchy,
and the specific configurations of each technique and are
displayed in all screens.

5. Preliminary Results
Two issues were initial approached, and still need
more investigation: the first referring the environment
usability, and the second concerns about the performance
characteristics.
The usability test used on this work was the same
realized by MACIEL, M.[15]. MACIEL classified the
tasks by complexity, using as parameters the quantity of
analysis attributes and response type. For the preliminary
tests was a defined task with low and medium
complexity, with the characteristics:
• Task with low complexity:
Requires a simple response, like “Yes” or “no”.
Don’t require the analysis various attributes, max two.
• Task with medium complexity:
Require a simple response, but concrete, not only
yes or no. Requires analysis max four attributes.
Were defined three users groups profiles, each one
with five user: Users with diverse formation, users with

Figure 7. Tests environment of PRISMA MDE
tool.
At the end of the tests, the users were invited to
answer the NASA Task Load Index (NASA TLX) that is
a multi-dimensional scale projected to obtain estimates
of workloads of one or more operators, while they are
performing a task or immediately after [16].

649

Workload is a term that represents the cost of
performing the task’s requirements for the human
operator. If people could perform all expected to do with
speed, accuracy and reliability using the available
resources, the concept would have little practice
importance. For example, the cost of having a good
performance in a hard task can be an unacceptably high
level of workload [16].
The tests workload amount to 38, on a scale from 0
to 100, this shows that users have not had great mental
effort, physical and neither were stressed, frustrated or
pressured by the time. Other information that we can
infer is that the level of physical demand was small, that
is, the tool did not require great physical effort from the
user for your performance. On the other hand, the user,
on a scale from 0 to 100, had a mental demand of 50,
which demonstrates that these users used more
reasoning, decision, calculation, memory, and
identification than pressing buttons, movements with
mouse and interaction with the tool.

the other groups. The PCS and RVI groups needed less
time to solve the tasks than the PDA group, this is due to
prior experience of these two groups in TI. The figure 9
shows these informations graphically.
Hereafter, will be presented the form results that
evaluates the users satisfaction when using the tool.

Figure 10. Tasks complexity.
According to the users answers, task 1 has a
complexity degree between easy and normal. The
complexity of task 2 was between very easy and easy for
the RIV group, the others groups found the task between
easy and normal. On task 3, the RIV and PCS groups
found between hard and normal, unlike the PDA group
that defined the task between normal and easy. The task
for all the groups defined between easy and normal.

Figure 8. Mean score.
Figure 8 shows the average performance of the
users. The research groups in information visualization
(RVI group) and the professionals group of different
areas (PDA group) had very close results, with
performance of 95% accuracy approximately. The
professionals group of Computer Science (PCS group)
had 70% of accuracy. The three groups had the lowest
accuracy rate on task 3.

Figure 11. Rating of dataset and actions.
In figure 11, we can inferred that the user rated the
understanding complexity of the database and the action
of filtering between easy e normal. The configure action
for the PDA and RIV groups is between easy and
normal, but for the PCS group is more normal.

Figure 9. Average time graphic (seconds).
The average time to complete the task 1 was
approximately 111 seconds. On task 2 the PDA group
needed more time than the others groups to realize the
answer, but all had the same success rate. The task 3, the
three groups have almost the same time to see the
answers, but the results of PCS group were lower than

Figure 12. Satisfaction of the mouse and monitors.

650

In general, the users felt comfortable to perform the
configuring and filtering actions. The PRISMA MDE
tool, when compared to PRISMA DESKTOP [11],
makes more optimized use of the information
visualization pipeline and this is due to the tool
distributed process.
The future works are suggested below:
• Evolution of the tool for interaction with the user.
• Measure the impact of the tool in the network traffic.
• Evaluation of the tool for use in projective
environments of multiple screens.

Most of the users from PCS and PDA groups felt
comfortable using the mouse in the three monitors, but
the RIV group mostly felt normal. Using three monitors,
most users of RIV and PDA groups felt comfortable, but
on PCS group most felt very comfortable.
Of the 15 interviewed users, 10 used more than one
technique to solve the tasks. 12 used brushing, and 14
found that multiple screens are useful.
Most of the users think that the coordination
function between the data views helps a lot.
Also most of the users think that is better different
techniques than data view.
A performance test are also early and serve to guide
future tests, is based on the initial load time, composed
by process time of the database and the rendering time,
and indicates if the PRISMA-MDE solution makes more
optimized use of the IV pipeline, performing a
comparison with PRISMA desktop.

References
[1]
[2]

[3]
[4]

[5]
[6]
[7]

Figure 13: Average time of initial load.

[8]

Figure 13 shows a graphic of the average time of the
initial load of 100 executions from PRISMA MDE and
PRISMA DESKTOP [11] for each database. Were used
four databases, the frist is exactly the same database
from the usability tests, with 789 items, the second with
the double of data from the first one, 1578 items, the
third with five times the quantity of the first, 3945 items,
and the forth with ten times the first, 7890 items.
PRISMA MDE took about 12% less time for the initial
load than PRISMA DESKTOP [11].

[9]
[10]
[11]

6. Conclusion and Future Works

[12]

Despite the tests are preliminary, and the small
database, the tool proved effectiveness in facilitating the
perception of the users. The three different groups had a
low workload, which strengthens the assertion of 14
from 15 users, that the use of multiple screens
environment is useful for an IV tool.
The simulation of an extended desktop, with mouse
through the screens and the view on three screens left the
user comfortable, but this work did not evaluated the
behavior with more than three screens.
The average accuracy of the three groups was
approximately 84%, which demonstrates that the users
were able to understand and use the tool solving all the
tasks in an average time of 9.1 minutes.

[13]
[14]

[15]

[16]

651

JOHANSON, B. et al. PointRight: Experience with
Flexible Input Redirection in Interactive Workspaces.
Proceedings of the 15th ACM UIST. Paris, France. 2002.
FORLINES, C.; LILIEN, R. Adapting a single-user,
single-display molecular visualization application for use
in a multi-user, multi-display environment. Proceedings
of the working conference on AVI. Italy: ACM. 2008.
BRAGDONI, ANDREW et al. Code Space: Touch + air
Gesture Hybrid iteractions for Suporting Developer
Meetings. ACM ITS 2011, Kobe, Japan.
SHEN, C. et al. Three Modes of Multi-Surface
Interaction and Visualization. Information Visualization
and Interaction Techniques for Collaboration across
Multiple Displays Workshop CHI’06. 2006.
WALDNER, M. et al. Design Considerations for
Collaborative Information in MDE. CoVIS. USA. 2009.
Spence, R. IV. Addison Wesley - ACM, 2001. 459 p.
LEVKOWITZ, H. et al. From Visual Data Exploration to
Visual Data Mining: A Survey. IEEE TVCG. 2003.
Carr, D. A. Guidelines for Designing Information
Visualization Applications. Proceedings of ECUE'99.
Stockholm, Sweden. December 1999.
WALLACE, J. R.; MANDRYK, R. L.; INKPEN, K. M.
Comparing content and input redirection in MDEs.
Proceedings of the 2008 ACM CSCW. USA. 2008.
GUIMARÃES, M. D. P.; GNECCO, B. B.; ZUFFO, M.
K. Graphical Interaction Devices for Distributed Virtual
Reality Systems. ACM VRCAI. [S.l.]: [s.n.]. 2004.
GODINHO, P. et al. PRISMA - A Multidimensional
Information Visualization Tool Using Multiple
Coordinated Views. IEEE IV '07. Zurich. 2007
PILLAT, R. M.; FREITAS, C. Coordinated Views in the
InfoVis Toolkit. AVI '06 Proceedings of Advanced
Visual Interfaces. Venezia, Italy: ACM Press. 2006.
STASKO, J. T. et al. An Evaluation of Space-Filling
Information Visualizations for Depicting Hierarchical
Structures. IJHCS, p. 663-694, November 2000.
Newman, D.J.; Hettich, S.; Blake, C.L., Merz, C. J. UCI
Repository of machine learning databases. Irvine, CA:
University of California, Department of Information and
Computer Science, 1998.
MACIEL, M., Meiguins, B., Lourenco, R., Meiguins,
A., Godinho, P. The Impact of Multiple Coordinated
Views on the Visual Data Exploration and Analysis. IV
08.London, England, 2008.
Hart, S. G. (2006) NASA-TASK LOAD INDEX
(NASA-TLX); 20 YEARS LATER. NASA-Ames
Research Center, Moffett Field, CA.

