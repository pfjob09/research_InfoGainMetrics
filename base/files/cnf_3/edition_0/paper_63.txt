2012 16th International Conference on Information Visualisation

Using a Shifted Lens to Achieve Visual Depth
in Facade Projections More Efficiently

Lukas Treyer, Sofia Georgakopoulou, Gerhard Schmitt
Department of Architecture,
Swiss Federal Institute of Technology, ETH
Zurich, Switzerland
treyer@arch.ethz.ch, georgakopoulou@arch.ethz.ch, schmitt@arch.ethz.ch
Abstract—This paper describes a method for creating spatial
illusion projections in a simple yet efficient way. It uses the
horizontal and vertical lens shift properties of a virtual camera
in a 3D modelling software to produce a normalized image that
can be subsequently mapped with a traditional mapping technique, as cornerpin keystone correction for instance, onto a
real facade. Our calculations describe how to automatically
derive horizontal and vertical shift values. The method was
developed during the creation process of a series of projections
created with the 3D modelling software “Blender”. [1]

here may help shift the architects’ views on new visualization methods and consequently influence the development
of the tools themselves.
II.

A. The Art of Projection
Renowned artists like Gerry Hofstetter or Jenny Holzer
work mainly with projected symbols to establish a dialog
between the projection surface and the image being projected. This is very different from projection mapping, where
the projection and its canvas are being mapped graphically
and not only symbolically. Nevertheless they are very successful in their puristic manner.
On the streets projections are used as a tool to achieve
some sort of subcultural publicity, documented mainly on
websites. [3-5]
On light mapping festivals also interactive installations
are shown, where either visual user tracking methods are
applied, as Christian Schneider [6] did with his thermal
camera driven projections. Other projections are being controlled by smart phones. [7]
Additionally, we should not disregard the large field of
party visuals, which rely strongly on the music being
played. Only if intended by the artist such projections make
reference to or influence any architectonical qualities, e.g.
with graphical patterns used like tapestries.

Projections art; augmented reality; shifted lens photography

I.

INTRODUCTION

During the last two decades the availability of projectors
influenced different kinds of art like exhibition installations
or street art as well as some daily life experiences like advertisement or party visuals. Regarding public projections,
we observe the emancipation from its aforementioned origins towards an art on its own. At least it seems to be en
vogue to decorate many kinds of festivals with public projections, especially in winter.
To use projections in a more architectural context it is
not enough to merely map graphics on a surface. The architect has to begin from a different conceptual basis, treating
the projection as the mapping of a facade onto another facade and then using the appropriate 3D techniques to create
the desired spatial illusion.
Since spatial illusions are part of architectural visualization, the techniques an architect has to learn to map spatial
illusion projections are of great use in daily visualization
tasks. Projected facades might also open an architect’s mind
on how to communicate a project and how it is perceived,
because she or he needs to focus only on image creation of
facades, thus, narrowing down the usually very complex
problem space.
This paper reports a straightforward method for efficiently creating spatial illusion projections on single planar
surfaces. While making use of standard 3D modeling and
image transformation tools, it enables users to develop illusive projections, which cover some basic features of spatial
augmented reality. [2] In the future, it might be daily routine
to generate not only renderings of architectural projects but
also game-like augmented reality models, which can be
viewed through people’s smart phones and tablets. Starting
to develop and use projection tools like the one described

1550-6037/12 $26.00 © 2012 IEEE
DOI 10.1109/IV.2012.118

RELATED WORK

B. Spatial Illusions
With the appearance of Alhazen’s (~965 – 1041 AD)
“Book of optics” [8] in the 14th century as an Italian translation, many renaissance artists in Florence started to adopt
his theory of vision successfully in their paintings. Frescos
that seek to evoke spatial illusions have been created ever
since. While in the 20th century artistic demands may have
shifted, there are still artists like Edgar Muller, who create
spatial illusions painted directly on streets (figure 1).
What these illusions have in common is that they assume
one viewpoint for which the illusion works perfectly. When
looking at the painting from a different perspective, the result seems distorted and unrealistic. Spectators may still be
able to guess what the painting was meant for – especially
when they are close to the assumed viewpoint, since human
visual perception is able to compensate the incorrect perspective to a certain extent; however the 3D visual effect
will be lost.
410

Figure 2 Texture on a quad (left) and on a mesh (right). Due to triangulated textures in computer graphics, some extra effort is needed to distort a
texture in perspective. Subdivision of a quad into a mesh is a simple method to achieve this.

Figure 1 Examples of spatial illusions:
- Holy Trinity by Masaccio, Florence, 1427
- The Crevasse by Edgar Muller, Dun Laoghaire, 2008
- 555 Kubik by urbanscreen.com, Hamburg, 2008

3) Rasterized and Content-Aware Mesh Correction With
the mesh warp method all the vertices of a mesh can be
mapped, and not only the four corner vertices. Simple methods [13] use a simple raster of vertices, which can be repositioned. A more complex solution, as implemented in the
“Mesh Warp Server” [14] allows for importing the 3D
mesh, project it into two dimensions, and then adjust a 2D
mesh that is not regularly rasterized, but conforms to the
image being displayed.

C. Projection Mapping Techniques in Art
Projection mappings technically consist of distortions to
map a projection onto the canvas object. Sometimes it is a
combination of techniques but with some abstraction there
is always a content creation phase, where the content is put
in relation to the canvas object, and a final mapping step.
This is where the projected image is being transformed, so
its content fits perfectly onto the facade. The mapping
methods are explained later in this section.
Only in few cases the content adapts to the projection
surface in real-time. Mostly the content of the projection
needs to be prepared. To make a projection react to an existing surface, it needs to be referenced in the content creation
process already. This is usually done with a photograph or
even a 3D model of the given façade.
1) Keystone Correction: When projecting an image onto
a surface at a certain angle, the image will be skewed to a
trapezoid. Since this effect mainly occurs with projectors
that are placed on tables and are facing upwards, it is called
a “keystone effect”, referring to the architectural keystones
in arches that have the same trapezoidal form.
Software correction methods exist that transform the
projected image in order to finally produce a straight rectangle. Those methods are based on the creation of a trapezoid
image on a black background that mirrors the former trapezoid on the projection surface.
The correction methods built in most projectors allow
for re-adjustment of only regular trapezoids. In order to correct the projected image for different kinds of distortions, a
variety of computer software allows the user to adjust every
corner of the image individually. This enables the projection
artist to map his or her projection exactly on the screen surface, as he or she wants it.
2)
Cornerpin keystone correction: To address the
trapezoidal transformation, most software implementations
[9-13] treat the image as a texture on a 3D mesh. One very
simple way to transform this mesh is by bilinear interpolation of the position of every vertex in the mesh, once one of
the four corners has been moved. Due to computer graphics
relying mainly on triangular geometry, when mapped on a
quad, a texture usually gets transformed in a way that is
unexpected for the human eye. As shown in Figure 2, the
quad needs to be subdivided into a mesh in order to downsize the triangles until they are not visible anymore.

Figure 3

Rasterized (left) and content aware (right) mesh correction

4) Photogrammetric Methods While photogrammetric
methods are mainly used in computer vision today, the basic
research on the calculation of a camera’s parameters with
only a single image at hand was done in the 1950s and
1960s under the term “photogrammetric research”. [15]
As the keystone correction is a straightforward method
for mapping projections on a planar façade with a projector
centred onto it, photogrammetric methods are only considered when the image is projected on more than one face.
Photogrammetric methods are also applied when mapping a virtual 3D object onto an image. In this case, photogrammetric algorithms are able to calculate the position,
angle and lens distortion of a camera, using markers that are
applied to the image. The same is applicable when mapping
a virtual object onto a real object: the location, angle and
lens distortion of the virtual camera coincides with the location, angle and lens distortion of the projector in the physical space.
Since the lens distortion can be modelled only approximately, the resulting image in most cases needs to be
mapped with a second correction method in order for the
mapping to be precise.

411

D. Spatial Augmented Reality
In contrast to traditional Augmented Reality, Spatial
Augmented Reality (SAR) uses images that are integrated
directly in the user’s environment, instead of images that are
superimposed onto reality with Head-Mounted-Displays. [2]
This means that SAR-images are projected directly onto
objects with projectors. Projection Mapping therefore could
be seen as an artistic kind of Spatial Augmented Reality.
De Miranda et al. [16] have created similar projections
as presented in this paper. They used a projector to augment
an x-ray vision directly on a wall. As their work is based on
Raskar’s et al. shader lamps [17] and iLamps [18], the augmented view conforms to a viewpoint near the projector
itself. It is intended to work for users who hold the projector
in their hands. While Raskar et al. also provide a method to
augment reflections and other material properties for different user viewpoints, the mapped geometry always conforms
to the projection angle of the projector, as opposed to the
method presented here.
The simulation of material properties has been developed by Aliaga et al. [19]. They are able to equalize the existing and apply new colours. This allows for projections
onto real objects and enables Aliaga and his team to virtually restore antique vases using just light. To achieve this, the
real objects are scanned with structured light 3D scanners.
In order to obtain a very precise model of the object during
that process, photographs are also applied as textures to the
model.
III.

seems to be tilted backwards, since its roof is farther away
from the image plane than its base because the camera and
therefore the image plane needed to be tilted backwards to
frame the whole building. Human perception normally
compensates this effect unconsciously, since we assume
walls to be perpendicular.
Shift lenses allow the image plane to remain parallel to
the subject as they are raised parallel to the image plane.
This is how converging verticals are skewed to appear
straight on a photograph [21].

Figure 4

Mapped Projection, ETH Zurich, Christmas time 2010

C. Setup
In order to create a spatial illusion, a virtual camera is
positioned at the estimated viewpoint of a spectator. As
shown on the left side of figure 5, a camera with no shifted
lens captures an image as we know it: objects that are far
away are smaller than close objects. But since the projector
is located centric to the projection surface, the rendered image needs to be transformed to an image similar to the one
on the right side in figure 5, where the most left and the
most right column have the same size.
When applying a keystone correction to a rendered image in order to accomplish this transformation, the pixel
resolution on the skewed side might get very low, depending on the viewing angle. To come around this, the resolution might be increased, with potentially a lot of wasted resolution and therefore wasted rendering time and energy consumption.
A better alternative is to shift the camera lens, which
produces an image that is distorted in a similar way but with
a different kind of distortion process. One of its main advantages is that the transformation is being applied BEFORE any image is rendered. Metaphorically speaking, the
image is being distorted in the virtual camera’s lens, as it is
the purpose of shift lenses also in physical world photography.
The shifted lens method could be described as a visual
normalization process as well. It is possible to create images
with exactly the same outline, while being captured from
different viewpoints. The details on that will be covered in
section F “Viewpoint Movement”.

SHIFTED LENS METHOD FOR PROJECTIONS

A. Preconditions
The camera shift method suits very well the needs of a
spatial illusion projection. As described in section II.B
“Spatial Illusions”, this kind of projection requires the assumption of a viewpoint. In addition, the camera shift method describes a workflow with which to capture and render
(animated) 3D models. Therefore it is only applicable for
projections whose content is being created with 3D models,
since this is considered as a simple but effective way of creating a spatial illusion. Furthermore it is presupposed that
the projector is positioned more or less centric and orthogonal to the projection surface.
B. Development
The method was developed during the preparation for a
Christmas projection mapping in fall 2010 (see figure 4). In
order to project a virtual façade onto the real façade, a virtual model of the real façade has been created using photographs and plans of the building.
Thereupon the virtual facades have been modelled using
scanned drawings of St. Katharine’s Church in Oppenheim
[20] amongst others, which coincided approximately with
the given real façade. As 3D modelling software we chose
Blender, since it has a built-in Game Engine that would allow for interactive spatial illusions.
Lens shifting is a well-known technique in architectural
photography as it used to prevent “converging verticals”, an
often seen effect in photographs. The building in figure 4

412

sensor. As illustrated in figure 6, a different focal length
leads to incorrect illusions, since the perspective lines of
illusion and context don’t match in their direction.
The distance between the rendering camera and the virtual screen surface is ruled by the camera’s focal length and
the size of the object being captured and not by the actual
distance of the spectator to the screen object. As explained
in section F “Viewpoint Movement”, using the camera shift
method this distance is easily applied, since the camera’s
location does not have to follow a circle around the object in
order to keep the distance but is allowed to move parallel in
front of it. The distance is calculated as follows [22]:
𝑑𝑖𝑠𝑡   =   𝑜𝑏𝑗𝑒𝑐𝑡  ℎ𝑒𝑖𝑔ℎ𝑡 ∗

!"#$%  !"#$
!"#!$%  !!"#!!

(1)

where image distance is the distance between image sensor
and lens. Due to simplification or some irregularities in
Blender’s implementation the image distance needs to be
replaced with the focal length in Blender:
𝑑𝑖𝑠𝑡   =   𝑜𝑏𝑗𝑒𝑐𝑡  𝑠𝑖𝑧𝑒   ∗

!"#$%  !"#$%!
!"#!$%  !"#$

(2)

where size is the maximum out of object width and height.
Figure 5 Left side: “normal” camera; right side: shifted camera; Top row:
Situation; Middle row: Comparison of “normal” and shifted camera perspectives; Bottom row: Feature comparison: Note that the viewpoint for
both of the cathedral facades is the same. You can notice this, when comparing the area of side face visible of the most right columns.

F. Viewpoint Movement
One major advantage of the camera shift method is its
ability for camera movement, parallel to the facade, without
any need for recalibration. While a not shifted camera would
need a separate cornerpin keystone transformation for every
new camera position, the shifting method frames the object
always exactly the same (figure 7).

D. Lens shift method step by step
Put a camera in front of the virtual model, so that it faces
the virtual model orthogonally. Then the camera is being
moved to the estimated viewpoint of a spectator. To observe
the transformation effect best, it is proposed to test this
method with viewing angles that clearly distinguish from
the orthogonal view. Once the camera is repositioned, instead of rotating the camera to face the virtual model again,
the camera’s lens is shifted until the model appears in the
camera’s view.
E. Focal length over camera distance
As we know from photography, it is possible to frame an
object at different distances, if we have a camera with a
zoom-able lens. This is so common that we might not even
think about different distortions of pictures taken at different
focal lengths. For spatial illusions, however, it is crucial to
render the projected content with approximately the focal
length of the human eye – 50mm on a camera with a 36mm

Figure 7 Two different viewpoints: on the left side the boxes face to the
left, on the right side they face to the right. The outline of the façade nevertheless remains the same.

To achieve this throughout camera movement, the horizontal shift parameter of a Blender camera can be automated, which means calculated based on the position of the
camera as follows:
𝑠ℎ𝑖𝑓𝑡!    =   

!""#$%  !
!"#$%&'(

∗   

!"#$%  !"#$%!
!"#!$%  !"#$!

(3)

Since the distance between virtual camera and facade is
determined by the camera’s focal length, as mentioned in
section 3.5, in order to augment a spectators viewing angle
the camera must not only copy the viewing angle but keep
the given distance towards the framed object.

Figure 6 Images taken at different focal lengths than the focal length the
illusion was generated with. Left: 16mm; right: ~80mm. Note that the
perspective lines of projection and context differ.

413

As illustrated in figure 8 a constant distance results in a
spherical movement of the camera around the subject to
frame it from different viewing angles.

imum distance from the wall, in order to avoid infinite values.
IV.

RELEVANCE

During the creation process of a projection the artist either on purpose or unconsciously studies very closely the
facade that is being used as a projection surface. In case the
projection is a facade, all the proportions, columns, capitals,
window frames etc. have to be treated very carefully, because the projected and the existing architecture communicate directly with each other. Therefore, projections can be
also used as a tool to visually communicate classical to
modern architecture, and thus also to help laymen get into
closer contact with architecture.
Besides, projections offer a special opportunity for an
architect to look at architecture from a different point of
view, using animation tools. Visual appearance is in this
case much more important than constructive correctness and
regulation strictness or well and precise designed floor
plans. At the same time it is clear that the design produced
in this way can be used only for visualization purposes; it is
only a show, only light, not to be inhabited.
With the means of animation, architectural rhythms inherent to the repetition of visual elements (patterns) can be
explored in combination with time by highlighting their
relations.
One main feature of modelling classical architecture
with animation tools in order to create facade projections is
the didactical benefit. Architecture students learn a 3D modFigure 8 Not shifted (top) and shifted (bottom) cameras with fixed focal
length / distance but the same viewing angle as the spectators. The posielling tool that focuses on 3D sculpting workflows, which
tions of the shifted cameras consist of an orthogonal projection (xy) and a
means they acquire a different understanding of precision.
viewpoint extension (z).
At the same time, by digitally manipulating modern structures in order to use them as projection surfaces, they expeAs we know from architectural photography (section 3.2) a
rience what i.e. gothic or roman design means in terms of
camera with a shifted lens must remain perpendicular toform, structure or dimension, compared to modern design.
wards the subject. Therefore it is only allowed to move
Projections can be used to visualize reconstructed faalong a plane perpendicular to this very subject.
cades in real scale. Nowadays they are often used to exhibit
In order to adjust the projection, so that a passer-by
information on urban models that would otherwise be invisstanding close to the projection surface (figure 8) still perible and consequently hard to imagine. While such visualiceives the projected image as a 3D structure (the illusion
zations may be very impressing on urban models, they don’t
effect), we need to situate the virtual camera on point “A”.
have much success on a larger, 1:1 scale, since projections
For a normal camera, point A is at the intersection of the
are only available publicly at night.
extension of the viewing angle and the “constant-distance”
Being widely applied in the field of party visuals, colsphere. In the case of a shifted camera, point A can be deours and light can change the perception of a room or an
fined as a combination of the following: in the xy plane, it is
urban space and influence people’s feelings, or create spatial
the projection of the viewpoint onto the “constant distance”
illusions.
plane, while in the z direction it lies on the extension of the
Supporting ephemeral activities like light festivals is a
viewpoint angle. In general this leads to possible camera
good way to keep people feeling proud about the city they
positions that either follow a sphere (camera not shifted) or
inhabit or at least make them aware that somebody cares
a plane (camera shifted).
about it.
In order to calculate the vertical position of the virtual
In a way similar to technical visualizations, projections
camera we use the approximation:
can be used to visualize daily information, like the remaining minutes until a bus’s departure, or the number of availa(4) ble parking lots.
𝑐𝑎𝑚! =    𝑜𝑟𝑡ℎ. 𝑑𝑖𝑠𝑡!"#$%& −    𝑜𝑟𝑡ℎ. 𝑑𝑖𝑠𝑡!"#
With augmented reality applications becoming more and
This moves the camera downwards to the same amount
more common, especially on smart phones and tablets, it is
as the viewpoint approaches the facade. Currently this
time to think about how architects could create content for
method is restricted to the viewpoint being at a certain minand make use of such tools. The presented method enables
them to do so with standard animation/modelling tools.
414

V.
[1]
[2]

[3]

[4]
[5]
[6]

[7]
[8]
[9]
[10]
[11]
[12]
[13]
[14]

[15]

[16]
[17]

[18]
[19]

[20]
[21]
[22]

REFERENCES

Blender-Foundation. Blender. 2012; Available from: http://www.
blender.org.
Raskar, R., G. Welch, and H. Fuchs, Spatially Augmented Reality, in
First International Workshop on Augmented Reality1998: San
Francisco. p. 1-7.
Collective, G.B. Guerrilla Projection Projects. 2007-2010 [cited
2012; Available from: http://www.glassbeadcoletive.org/projects
/projection/index.htm.
Funk, S. Urban Projection. 2007-2011 [cited 2012; Blog on Urban
Projections]. Available from: http://www.urbanproject ion.com/.
Lab, G.R., Graffiti Research Lab. 2008.
Schneider, C. and S. Wipfli. The Sensitive Tapestry: Built
Architecture as a Platform for Information Visualization and
Interaction. 2009. Barcelona.
Projektil, Interactive Mapped Projection mLove, 2010, http://www.
projektil.ch.
Belting, H., The Double Perspective: Arab Mathematics and Renaissance Art. Third Text, 2010. 24(5): p. 521-527.
Bouchard, D. keystone. 2011 [cited 2012 March 20th]; Available
from: http://keystonep5.sourceforge.net.
Gilje, H. Video Projection Tool. 2012 [cited 2012; Available from:
http://hcgilje.wordpress.com/vpt/.
memo.tv. msa Quad Warp. 2008; Available from: http://vdmx.memo.
tv/msa_quad_warp.
VidVox. VDXM5. 1999-2012 [cited 2012; Available from: https://
vidvox.net/.
Schneider, P. and F. Wunschel. MadMapper. 2005-2012 [cited 2012;
Available from: http://www. madmapper.com/.
Froehlich, M. MeshWarpServer. 2011 [cited 2012; MeshWarpServer
is a versatile Mapping Tool to create complex Video Projection
Installations.]. Available from: http://meshwarp server.org/.
Clarke, T.A. and J.G. Fryer, The development of camera calibration
methods and models. Photogrammetric Record, 1998. 16(91): p. 5166.
de Miranda, F.R., et al., Designing and implementing a Spatial
Augmented Reality X-Ray. RITA, 2008. XV(3): p. 48-73.
Raskar, R., et al., Shader Lamps: Animating Real Objects With
Image-Based Illumination, 2000, University of North Carolina at
Chapel Hill.
Raskar, R., et al. iLamps: Geometrically Aware and Self-Configuring
Projectors. in SIGGRAPH. 2003. San Diego.
Law, A.J., D.G. Aliaga, and A. Majumder, Projector Placement
Planning for High Quality Visualizations on Real-World Colored
Objects. Ieee Transactions on Visualization and Computer Graphics,
2010. 16(6): p. 1633-1641.
Kallenbach, G.G., Atlas zur Geschichte der deutsch-mittelalterlichen
Baukunst1847, München: Primus Verlag.
Saxby, G., The Science of Imaging2010: Taylor & Francis. 330.
Gilbert, P.U.P.A. and W. Haeberly, Physics in Arts2012, Amsterdam:
Elsevier Inc. 306.

415

