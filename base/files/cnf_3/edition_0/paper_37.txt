2012 16th International Conference on Information Visualisation

Unsupervised visual data mining using Self-Organizing Maps and a Data-Driven
Color Mapping
Cyril de Runz, Eric Desjardin, Michel Herbin
CReSTIC
University of Reims Champagne-Ardenne
Reims, France
{cyril.de-runz,eric.desjardin,michel.herbin}@univ-reims.fr

al. [12], the color mapping does not result in a combination
of predefined colors but is fully data driven: colors result in
an automatic unsupervised process that reduces the data
dimensionality from a high number to three components (the
triplet <R,G,B>).
This paper proposes to combine both Kohonen and
Blanchard approaches in order to obtain a fully unsupervised
visual data mining tool where the color mapping is fully data
driven. The resulting map will give us a reduction of both
sample number and dimensionality.
The article is organized as follows. Section 2 presents the
Self-organizing map approaches. Section 3 introduces the
Blanchard’s approach. Section 4 proposes the pipeline of our
unsupervised visual data mining method. Section 5 shows
some results based on classical datasets. The conclusion is
exposed in section 6.

Abstract— This paper presents a new approach for visually
mining multivariate datasets and especially large ones. This
unsupervised approach proposes to mix a SOM approach and
a pixel-oriented visualization. The map is considered as a set of
connected pixels, the space filling is driven by the SOM
algorithm, and the color of each pixel is computed directly
from data using an approach proposed by Blanchard et al. The
method visually summarizes the data and helps in
understanding its inner structure.
Visual data mining; self-organizing map; oriented pixel
visualization.

I.

INTRODUCTION)

Discovering knowledge from large datasets resides in the
ability to identify the core of high dimensional data. Indeed,
the curse and blessing of dimensionality [1] – the huge
number of data samples and the high number of variables –
may dissimulate the information sought. This is why an
important aspect of knowledge extraction relies on the ability
to reduce data size (sample number, variable number)
without hiding the core (i.e. the meaning) of data. In this
context, the use of efficient visualization tools is a good
mean, and so it is fundamental in data mining processes.
For dealing with the meaning of the visualization, those
tools and methods mainly use for rules from graphic
semiology as proposed by Bertin [2, 3] and/or Tufte [4, 5].
Reviews of main visualization approaches are proposed in
[6].
In the main kind of approaches, the visualization of
quantitative data takes an important place. In this context,
Kohonen maps (also called Self Organizing Maps (SOM))
[7, 8, 9] and derived approaches [10] summarize sample
number and reflect the data topology through, respectively,
the map size and the output space dimension. SOM allow
building a grid-based neural network where weight vectors
associated to cells are defined by the data pipeline. The
number of cells is generally lower than the number of data.
Nevertheless, data visualization does not reduce the
dimensionality of quantitative information. Some other
approaches – the pixel-oriented methods – consider that each
pixel represents a data value and the related color spatial
configuration visually helps to extract clusters. The main
aspects of this kind of approaches are presented in [11].
Within the pixel-oriented approach proposed by Blanchard et
1550-6037/12 $26.00 © 2012 IEEE
DOI 10.1109/IV.2012.48

II.

SELF-ORGANIZING MAP

The Kohonen’s visualization approach produces selforganizing maps on a set of quantitative data. Kohonen
introduces this approach in [7, 8, 9].
A SOM is a type of neural network that is trained using
unsupervised learning. It usually produces two-dimensional
and discretized representation (the map) of the input data
space. Its components are called nodes (or neurons). Each
node is linked to a weight vector of the same dimension (the
same number of variables) as the input data. A node has
coordinates in the map space. The most common choice is
that nodes make a grid.
The learning matches the input data space and the map:
the weight vector values of nodes are adapted in order to link
neighbor input data to the same node (or at least to close
nodes). It matches groups of data with nodes with respect to
the topology of the input data space: two neighbor instances
in the data space are linked to the same node or of neighbor
nodes. SOM could be viewed as a data mapping approach
which preserves the data characteristics.
A classic algorithm approach is as follows. First, the
weights W are randomly initialized. Then for each input
datum d (randomly chosen), the node j of which the weight
vector Wj is the closest to d is selected and declared winner.
After that, the neighborhood of j is evaluated. Using this
evaluation, for each node of the map, its weight vector is set
up: the higher the adaptation, the closer to j the node. At the

241

data) in accordance with a Peano-Hilbert curve [19]. The
final step assigns to each data its color.
The <R,G,B> triplet of each pixel is obtained using the
values of the involved projected data using the following
transformation matrix:

end of the process, the spatial configuration is auto-adapted
by the data.
Therefore, for a classic data set (IRIS [13]), the built
SOM consist of 64 nodes. The figure 1 shows the IRIS SOM
with different configuration: the U-Matrix [14] (which
highlights the distances between cells and therefore, between
clusters), and for each dimension of the input data, a color
mapping according to a prefixed set of colors.

R = (6 * C1 + 3 * C2 – 2 * C3)/6 ;
G = (3* C1 + 2 * C3)/3;

(1)

B = (6* C1 í 3 * C2 í 2 * C3)/6.
Therefore, a color triplet may be built for each datum
according to its three first components thanks to PCA.
Transformation in other color spaces could be computed
using usual transformation from the <R,G,B> color space.
A global view of the approach is presented in figure 2.

Figure 1. SOM visualizations for the iris data according to the U-Matrix
and to each input data variables.

The U-Matrix allows visualizing combinations of weight
for each node and the distances between neighbor nodes. We
can remark that the spatial organizing of the map is coherent
for each variable.
Nevertheless, the color mapping is given considering a
prefixed set of colors – it is not fully data-driven – and the
map does not present a coherent combined representation of
the weight vector dimensions.
III.

PIXEL-ORIENTED VISUALIZATION: BLANCHARD’S
APPROACH

The main interest of oriented-pixel visualization
techniques is that it links each input data to a pixel in an
image [15, 11]. It is an efficient way to visualize classic and
large databases. In usual approaches the color is mapping
according to a prefixed set of color. The spatial configuration
may use a space-filling curve.
The Blanchard’s approach [12] uses the same principle
for the spatial organizing: it exploits a Peano-Hilbert curve.
Its main originality is the color mapping process. It does not
use a prefixed set of color. It is inspired by the work of Ohta
et al. [16], which proposes a transformation matrix from
<R,G,B> color values of an image to the three first
components of the principal component analysis (PCA).
Blanchard et al. consider that the color of each pixel could be
defined using the inverse of the Ohta’s transform.
The pipeline for the visualization is as follows. In a first
time, a PCA [17, 18] is made and the three first components
<C1,C2,C3> are kept. During the second step, projected
data are ranked in order to make a list: a sort is used
according to C1, then C2 and lastly C3. The third step links
the pixel to the projected data (and therefore, to the input

Figure 2. Blanchard’s approach pipeline.

An illustration of the result of the method is proposed in
Figure 3. The clusters may visually be extracted.
This visualization process is thus an interesting tool.
Even though it is an efficient tool, the size of a pixel limits
the possible interaction with data through the image in case
of very large dataset.

242

a)

b)

Figure 3. Visualization of the IRIS dataset using the Blanchard’s
approach: a) Color Image, b) Label Image. Each pixel represents a datum.
The label image is built using the spatialization processus of the
Blanchard’s approach; the color is given according to the label. The color
image is built according to the Blanchard’s approach without any a priori
of the data. The label image gives the information about the pixel true class
represented by the same pixel in the color image.

IV.

Figure 4. Pipeline of our fully unsupervised visual data mining method

UNSUPERVISED VISUAL DATA MINING

V.

The principal idea is to combine the main advantages of
both the Kohonen maps and the oriented-pixel approach
proposed by Blanchard et al. In this paper, we do not deal
with color image compression as proposed by [20] but we
address the problem of visualizing large multidimensional
datasets with a color image.
SOM visually organizes data and summarizes it in an
apprehensible number of visual elements and generates the
weight vectors. At this level, we only consider the spatial
summarization.
The Blanchard’s oriented-pixel approach gives us an
unsupervised pixel-oriented visualization where the number
of pixel corresponds to the number of data, the spatialization
is given by a space-filling algorithm and where the color of
each pixel is given by data without any prefixed set of
possible colors.
The idea is to use SOM and to obtain the color map using
the Blanchard’s approach on the SOM weight vectors.
Firstly, we build a Kohonen map on data. The color
values are computed using the weight vectors as follows.
These vectors are projected in a new space using Principal
Component Analysis (PCA). The values of three first
components are utilized for computing the color values using
the inverse of the Ohta’s transform.
The figure 4 presents the full pipeline.
The process is thus fully unsupervised: the spatial
configuration and the color are driven by data without any
prefixed set of values or colors. The reduction of the number
of data is then given by SOM when the color represents a
reduction of the data dimensionality.

EXPERIMENTATIONS

We illustrate the effectiveness and the usability of our
approach through the visualization of usual datasets from the
UCI [21].
The experimentations were made using MATLAB and
the somToolBox without any preprocessing on data.
The size of the map is computationally obtained using the
default automatic process given by the SOM toolbox: let the
integer nc be equal to 5*(number of instances)2, the map size
is then [round(√nc), round(nc/round(√nc))].
For each data set, the figure presents: firstly, how the data
are linked to the neural network; secondly, the result of the kmeans [22] on the weight vectors for the coloring where k is
the number of the data set classes; thirdly the U-Matrix;
fourthly our method result.
The IRIS data set [13] is composed with 150 instances
defined using 4 variables. Data represent 3 classes of iris
flowers. The figure 5 shows the results of the
experimentation. The SOM built on data contains 64 cells.
In this data set, a first class could easily be extracted
when the limit between the two others is less well defined:
using k-means, the best k according to the Davies-Boulding
index is 2 and the U-Matrix shows only one limit. Using kmeans and k=3, a separation between the two last classes is
defined but does not fit well to the data label (6 over 24 cells
of the pink class should have been grouped with the green
class). Using our approach, color nuances introduce fuzzy
limits between classes and then drive users for nuancing his
decision. We should also notice that in this approach, the
visually efficient reduction of the number of instances (150
to 64) is due to the SOM building when the colors
summarize the dimensionality (4 to 3).

243

have no associated data), b) SOM using k-means color mapping, c) SOM
and U-Matrix, d) SOM using our data-driven color mapping.

a)

b)

c)

d)

In this data set, the classes are not easily separable. Using
our approach, color nuances introduce small but still visible
variations that are globally coherent with the labeling. The
usual SOM approach reduces the number of data from 214 to
70 and the colors represent the dimensionality reduction (9 to
3).
The New-Thyroid data set (given by Stefan Aeberhard to
UCI) is composed with 215 instances defined using 5
variables. The data represent 3 classes of thyroid disease.
The figure 7 shows the results of the experimentation. The
SOM built on data contains 72 cells.
In this dataset, the classes are visually easily separable
using our approach while the k-means color mapping
suggests errors in the class boundaries. Indeed, the closeness
between weight vector values impacts the quality of the kmeans while the data-driven approach reflects data nuances
and is thus helpful for the decision-making process. The
usual SOM approach reduces the number of data from 215 to
72 and the colors represent the dimensionality reduction (5 to
3).
Finally, our approach visually suggests classes that are
globally coherent with both node labels and U-Matrix
visualization.

Figure 5. Visualization of the IRIS data set: a) SOM where the grey scales
represent the major class throughout associated data (black cells have no
associated data), b) SOM using k-means color mapping, c) SOM and UMatrix, d) SOM using our data-driven color mapping.

The GLASS data set [23] is composed with 214 instances
defined using 9 variables. The data represent 6 classes of
glass identification. The figure 6 shows the results of the
experimentation. The SOM built on data contains 70 cells.

a)

a)

b)

c)

d)

b)

Figure 7. Visualization of an extract of the Thyroid Disease Data Set: a)
SOM where the grey scales represent the major class throughout associated
data (black cells have no associated data), b) SOM using k-means color
mapping, c) SOM and U-Matrix, d) SOM using our data-driven color
mapping.
c)

d)

Figure 6. Visualization of the GLASS data set: a) SOM where the grey
scales represent the major class throughout associated data (black cells

244

VI.

CONCLUSIONS

[7]

In this paper, we propose to combine both Kohonen map
and Blanchard’s approach in order to obtain a fully
unsupervised visual data mining tool where the color
mapping is data driven.
The method visually summarizes a data set using a
reduction of the number of data and of the number of
dimension: the reduction of the number of instances with the
preservation of data set topology is allowed by SOM
algorithm and the dimensionality reduction is produced by
the data-driven color mapping algorithm without any
prefixed color or label.
The experimentation results of our approach give
visualizations that allow the extraction of clusters. The
unsupervised automation of the coloring permits us to
nuance the membership of the cells to a class. The results
show the interest of our approach for mining data set where
the clusters are unknown.
In our future work, we will develop our approach for
selecting fuzzy agronomical quantities and interacting within
GIS. We will inspire ourselves with [24, 25] for the use of
SOM in GIS.

[8]
[9]
[10]

[11]

[12]

[13]
[14]

[15]

[16]

[17]

ACKNOWLEDGMENT
We would like to thank the Seine-Normandy Water
Agency, Champagne-Ardenne Region Council, France and
European Union, through the FEDER, for their funding of
the AQUAL State-Region Planning Project.

[18]
[19]

REFERENCES
[1]

[2]
[3]

[4]
[5]
[6]

[20]

D. L. Donoho, “High-Dimensional Data Analysis: The Curses and
Blessings of Dimensionality,” Proc. AMS Conference Mathematical
Challenges of the 21st Century, aug 2000.
J. Bertin, Semiology of graphics: diagrams, networks, maps. USA:
University of Wisconsin, 1983.
J. Bertin, “Graphics and graphic information processing,” Proc.
Readings in information visualization, S. K. Card, J. D. Mackinlay,
and B. Shneiderman, Eds. San Francisco, CA, USA: Morgan
Kaufmann Publishers Inc., 1999, pp. 62–65.
E. R. Tufte, The visual display of quantitative information. USA:
Graphics Press, 1983.
E. R. Tufte, Envisioning information. USA: Graphics Press, 1990.
G. Grinstein, M. Trutschl, and U. Cvek, “High-Dimensional
Visualizations,” Proc. Proceedings of the Visual Data Mining
workshop, KDD’2001, San Francisco, California, 2001.

[21]
[22]
[23]

[24]

[25]

245

T. Kohonen, “Self-organized formation of topologically correct
feature maps,” Biological Cybernetics, vol. 43, pp. 59–69, 1982.
T. Kohonen, “The Self-Organizing Map,” Proc. IEEE, vol. 78, pp.
1464–1480, 1990.
T. Kohonen, Self-Organizing Maps. Springer, Berlin, 1995.
M. Lebbah and K. Benabdeslem, “Visualization and clustering of
categorical data with probabilistic self-organizing map,” Neural
Computing & Applications, vol. 19, pp. 393–404, 2010.
D. A. Keim, “Designing Pixel-oriented Visualization Techniques:
Theory and Applications,” IEEE Transaction on Visualization and
Computer Graphics (TVCG), vol. 6, no. 1, pp. 59–78, 2000.
F. Blanchard, M. Herbin, and L. Lucas, “A New Pixel-Oriented
Visualization Technique Through Color Image,” Information
Visualization, vol. 4, no. 4, pp. 257–265, dec 2005.
R. Fisher, “The use of multiple measurements in taxonomic
problems,” Annual Eugenics, vol. 7 (Part II), pp. 179–188, 1936.
A. Ultsch and H. Siemon, “Kohonen’s self organizing feature maps
for exploratory data analysis,” in Int. Neural Network Conf.
Dordrecht, Netherlands: Kluwer, 1990, pp. 305–308.
D. A. Keim, “Pixel-oriented Visualization Techniques for Exploring
Very Large Databases,” Journal of Computational and Graphical
Statistics, vol. 5, no. 1, pp. 58–77, 1996.
Y. Ohta, T. Kanade, and T. Sakai, “Color Information for Region
Segmentation,” Computer Graphics and Image Processing, vol. 13,
pp. 222–241, 1980.
H. Abdi and L. J. Williams, “Principal component analysis,” Wiley
Interdisciplinary Reviews: Computational Statistics, vol. 2, no. 4, pp.
433–459, 2010.
A. Hyvärinen, “Survey on independent component analysis,” Neural
Computing Surveys, vol. 2, pp. 94–128, 1999.
B. Moon, H. V. Jagadish, C. Faloutsos, and J. H. Saltz, “Analysis of
the Clustering Properties of the Hilbert Space-Filling Curve,” IEEE
Transactions on Knowledge and Data Engineering, vol. 13, no. 1, pp.
124–141, 2001.
S.-C. Pei, Y.-T. Chuang, and W.-H. Chuang, “Effective palette
indexing for image compression using self-organization of kohonen
feature map,” Image Processing, IEEE Transactions on, vol. 15, no. 9,
pp. 2493 –2498, 2006.
A. Frank and A. Asuncion, “UCI machine learning repository,” 2010.
A. K. Jain and R. C. Dubes, Algorithms for clustering data. Upper
Saddle River, NJ, USA: Prentice-Hall, Inc., 1988.
I. W. Evett and E. J. Spiehler, “Rule induction in forensic science,”
Central Research Establishment, Home Office Forensic Science
Service, Tech. Rep., 1987.
B. Jiang and L. Harrie, “Cartographic selection using self-organizing
maps,” in Workshop on Generalisation and Multiple Representation.
Paris, France: ICA, 2003.
P. Agarwal and A. Skupin, Eds., Self-Organising Maps: Applications
in Geographic Information Science. Wiley, 2008.

