2012 16th International Conference on Information Visualisation

A User Assistant for the selection and parameterization of the visualizations in visual
data mining
Abdelheq Et-Tahir Guettala∗ , Fatma Bouali‡ , Christiane Guinot∗† and Gilles Venturini∗
∗ Computer Science Laboratory, University Franois-Rabelais of Tours, France
Email: {abdelheq.guettala, venturini}@univ-tours.fr
† C.E.R.I.E.S, Biometrics and Epidemiology unit, Neuilly-sur-Seine, France
Email: christiane.guinot@ceries-lab.com
‡ University of Lille2, IUT, Dpt STID, France
Email: fatma.bouali@univ-lille2.fr

on a model of the visualizations, of the data and of the user’s
objectives. They may use an inference engine or a mapping
algorithm in order to map the data attributes with the visual
attributes (or the visual signs) of the visualizations. Only a
few approaches exist and they are interesting (see section
2).
In this work, we wish to contribute to this domain by
enhancing visual data mining assistants along these two
directions: we would like to improve the genericity of such
assistants, i.e. the ability to handle new visualizations within
the same model and framework. Also, we would like to
improve the interaction between the user and the assistant.
The remaining of this paper is organized as follows:
section 2 describes the main existing user assistants which
can be found in the literature, as well as their advantages and
drawbacks. In section 3, we present the architecture of our
system. Then, we explain the approach used to match the
data and user’s objectives with the visualizations handled by
our tool, and outline the interactive genetic algorithm which
we use to adjust and reﬁne the suggested mapping between
visual attributes and data attributes. Section 4 is devoted to
the user evaluation of our tool and the obtained results. In the
last section, we conclude and propose several perspectives.

Abstract—We deal in this paper with the problem of automating the process of choosing an appropriate visualization
and its parameters in the context of visual data mining (VDM).
To solve this problem, we develop a user assistant that performs
2 steps: the system starts by suggesting to users different
mappings between their data and possible visualizations. This
is performed with a simple but generic heuristic that can be
applied to any visualization. Then, the user selects a visualization among those proposed by our assistant, and he may
further improve the parameters set that deﬁnes the mapping
between the visual attributes and the data attributes. For this
purpose, we use an interactive genetic algorithm (IGA), which
allows users to visually evaluate and adjust the mappings. We
present a user evaluation that conﬁrms the interest of our
system in two tasks.
Keywords-User Assistant; Visual Data Mining; HumanComputer Interaction; Interactive Genetic Algorithm.

I. I NTRODUCTION
According to [1], “a genuine visual data mining system
must not impose knowledge on its users, but instead guide
them through the mining process to draw conclusions”. In
VDM, many methods are intended to be used by experts (in
visualization or in data mining), and novice users or even
domain experts may have difﬁculties to use such methods
or may even fail to do so [2] [3] [4] [5]. There are at
least two sources of difﬁculties. First, users must choose
the visualization that will efﬁciently represent their data
and that will help to reach their objectives. This requires
knowledge about visualizations such as the type of data they
can deal with or the objectives they may serve. Then, once
the visualization has been selected, users must ﬁnd the best
possible parameter that is the best possible mapping between
the data attributes and the visual attributes. If the selected
visualization is not correctly chosen or is improperly parameterized, it is highly probable that the user will not reach his
objectives.
In this paper, we focus on user assistants for visual data
mining. The aim of such assistants is to guide the user
through the process of selecting appropriate visualizations
as well as their parameter setting. They are generally based
1550-6037/12 $26.00 © 2012 IEEE
DOI 10.1109/IV.2012.50

II. S TATE OF THE ART
An early effort at the automatic generation of graphics
representations was the BHARAT system developed by
[6]. It was based on a simple design algorithm. Its main
function was to transform a numerical data into graphic representations. For this purpose, different parameters emerged
from various related properties (data characteristics, user’s
objectives, graphic design principles, feedback of experts,
etc.) were used. Although BHARAT’s system takes into
account a lot of parameters for representing effectively the
user data, it is limited to some 2D graphic representations. In
addition, those used by the system are limited in the number
of their visual signs. Also, its effectiveness criteria (used
to evaluate the graphic representations) about issues such
as font and color choice were “wired” into the code that
252

attributes. Also, it uses a small evaluation weight difference.
This can imply a subtle variation on the proposed mapping,
thus the users may not agree about which visualization is
the “best” choice. Moreover, ViA is based only on anecdotal
feedback from domain experts in its evaluation process.

rendered the design, making it difﬁcult to extend the system
to a broader range of input.
In [2] is proposed a graphical presentation tool called
APT, which is based on rules that automatically design
effective graphical representations. APT takes into account
the data type (qualitative, quantitative or ordinal) and the
visual properties of the graphical representations. In order to
generate a representation of relational information, APT uses
a set of primitives in a graphical language, a composition
algebra and an inference algorithm. However, the design
algorithm used by APT does not take into account the
tasks that each of the graphical representations can achieve.
Consequently, APT cannot exploit directly the beneﬁts related to the perceptual tasks of each visualization. Another
limitation of APT is that it deals with a limited number of
visualizations (it does not consider 3D visualizations) and
does not model interaction.
VISTA [7] is another automated system which represents
an extension of APT. It adds 3D visualizations. It is based on
a priori knowledge (data characteristics, visualization vocabulary, primitive visualization techniques, composition rules
and rules of visual perception). The graphical compositional
rules are an important advantage of this system. Compared
to APT, VISTA allows users to modify interactively its
suggested graphic representations. However, as mentioned
in [7], the rules of visual perception used in VISTA are
also far from being complete and extensive. In fact, some of
them are somewhat controversial and conﬂicting, and need
to be reﬁned according to the different studies on the visual
perception.
In contrast to APT and VISTA, Vis-WIZZ [4] suggests
a new approach to resolve the addressed problem that it
is based on data characteristics and user’s goal. This system
uses several inﬂuencing factors (data and interpretation aims
speciﬁcation) in order to reduce the set of the visualizations
that can be proposed to users. Despite its advantages, VisWIZZ has some limitations. Its ﬁrst limitation is related to
its interface. In fact, the user must pick manually the data
variables to be displayed, and ask the system to correlate
them. If the user aims to choose and alter data variables at
each time he needs to visualize his data in a new way, this
step can quickly become tedious and time-consuming. Its
second limitation is related to the nature of its visualizations.
Indeed, it uses just 2D static graphic representations.
ViA is the most recent interactive visual assistant [5]
[8]. It is based on two engines. The ﬁrst engine called
“search engine” is used to search and generate an appropriate
mapping between the data attributes and the visual attributes.
The second is rather a collection of engines that are called
“evaluation engines”. Every evaluation engine is responsible
to evaluate a combination of only one visual sign with the
data attribute that it can visualize in the generated mapping.
ViA has some limitations. In fact, it uses just visual features
attached to geometric glyphs to represent different data

III. P ROPOSED MODEL
A. Models of data, user objectives and visualizations
We deﬁne a model to represent data. Let D = {d1 , ..., dn }
be the set of the n data to be visualized. Each data di
is represented with k attributes A1 , .., Ak . Each attribute
Ai is characterized by its data type ti and its importance
ui . Our system can represent different data types (numeric/quantitative, symbolic/ordinal or nominal, temporal,
image, sound, text, web link, etc.). The value of ui belongs
to [0, 100]. This value represents the interest of Ai for
the user, and can be determined either manually by the
user based on its a priori knowledge, or automatically
using selection methods. If no knowledge is available on
the importance of data attributes then the ui values are
all equal. The user can also specify his objectives from
a predeﬁned list (discovery of clusters, overview of all
data, outlier detection, correlations detection, data selection,
attribute selection, etc.) and may assign to each of them a
priority pj (“not important”, “less important”, “important”
and “very important”).
On the basis of works like [9] and [10], we develop a
model of visualizations. Each visualization Vi is represented
by its graphical elements (points, lines, 2D or 3D widgets).
Each of these elements has visual attributes, and we denote
by Ai1 , .., Aim the set of all visual attributes of Vi . For each
visual attribute Aij , we represent the following information:
vtij , its visual type (position, length, color, etc.), dtij , the
data type which values can be used to set the Aij values, and
vij an importance weight. The values of vij are determined
by the ability of each visual attributes to describe any
one of the data attributes handled by our system. For this
purpose, we deﬁne an importance matrix (“data type” ×
“visual type”) which values are determined from studies like
[2]. Furthermore, for each visualization Vi , and for each
objective Oj , we deﬁne a weight oij that depends on the
ability of Vi to achieve Oj . These weights are determined
by the knowledge that exists about each visualization in the
literature.
B. Matching algorithm between a visualization and the data
The matching algorithm between the visualizations and
the data starts by the pre-selection of the visualizations
that can achieve the user’s objectives. For this purpose,
the assistant computes a matching score between the user’s
objectives and those of each visualization Vi . This score is a
scalar product between pj and oij (i.e. j pj × oij ). Once a
subset of visualizations has been pre-selected, a mapping
is computed between the data attributes and the visual

253

attributes of each visualization. For a visualization Vi , this
mapping consists in selecting, for each visual attribute Aij ,
the most appropriate data attribute Ai . Our assistant uses a
simple heuristic: it sorts the visual attributes by their type,
and then by their importance in decreasing order, to create a
list LV . Then, the data attributes are sorted in the same way,
and placed into a list LA . Next, the ﬁnal mapping consists
in establishing a correspondence between the two sorted
lists. For each visual attribute in LV , one selects the ﬁrst
available data attribute in LA of the same type. This heuristic
procedure favors visualizations 1) that take into account
data attributes, which are important from the user’s point
of view, 2) that represent such data attributes with adapted
and informative visual attributes. Finally, for a visualization
Vi , a matching score can be computed as a scalar product
between vij (the importance of visual attributes) and uj
(the importance of data attributes), i.e. ( j vij × uj ). The
suggested visualizations are ordered according to this score
and the user may select those with the highest scores.

user may not know the real importance of the data attributes,
this importance may be disclosed during an interactive
exploration of the data. For these reasons, we have proposed
a second interface, which allows the user to adjust and reﬁne
the mapping of the chosen visualization in an interactive
manner.
D. Interactive Genetic Algorithm
Once the user has selected a visualization Vi , he may
improve further the mapping between visual and data attributes through an interactive step. For this purpose, we
deﬁne an IGA [12]. In such algorithms, the user replaces the
ﬁtness function used in standard genetic algorithms [13] to
evaluate the individuals of the population. IGAs have proven
their efﬁciency in several domains [14] [15] where it is
difﬁcult to deﬁne a ”mathematical” objective function. This
is especially the case when the quality of generated solutions
depends on the human perception and subjectiveness. In the
problem we deal with, ﬁnding a relevant mapping between
visual and data attributes strongly depends on the user.
IGAs have been previously applied to interactive knowledge
discovery [16].
In our IGA, an individual I of the population represents a
possible mapping between visual and data attributes. More
precisely, we use for I an indirect encoding deﬁned as a
vector of weights g1 , ..., gk , where each weight represents a
”gene” and belongs to [0, 100]. These weights replace the
initial ui weights used in the matching procedure described
in section III-B. So an individual I indirectly represents
a new mapping, because I inﬂuences the order in which
attributes are considered during the matching procedure. The
advantage of this encoding is that, at the end of the process,
a new vector of attributes importance can be given to the
user. The results of the IGA can thus be easily explained
to the user. So for each individual I, we represent its genes
with real-coded values [17], and each gene represents the
new importance of its corresponding data attribute.
For presenting the individuals to the user, our IGA computes for each individual I the resulting visualization obtained by loading the user’s data with the mapping imposed
by I. Eight individuals can be displayed at the same time
(see Figure 2) in order to let the user select those of the
highest interest.
This second interface is simple and can easily guide
novice users to reﬁne and adjust the suggested mapping
of the visualization proposed at the ﬁrst step. Thus, the
user is not expected to be a specialist in IGAs. Indeed, the
user may explore his data, select any visualizations, and has
the possibility to save the parameters set of any selected
visualization.

C. Selection of the visualization
In order to help the user to choose the appropriate
visualization, the assistant uses the interface represented in
Figure 1. In this interface, the user may observe the results
proposed by each visualization on his data set. In this way,
the user can really test what each visualization can provide
him. In fact, the user does not have a static view of what
is displayed by the visualization but rather he has the possibility to dynamically test all the functionalities offered by
the visualizations. This includes all the possible interactions
that each visualization may propose (see Figure 1). In this
interface, the visualizations are ordered in decreasing order
of the matching score described in the previous section.
The user may explore his data with several visualizations
at once. Thus, he can check whether the visualizations are
suitable for him, or whether the proposed interactions will
help him to achieve his objectives. In addition, when this
is possible, we have implemented the ”brushing” method
described in [11]: when the user selects a subset of the data
in one visualization, the same subset can be selected in the
other visualizations.
This ﬁrst part of our assistant can be seen not only as a
tool allowing the user to automatically choose appropriate
visualizations, but also as a multi-visualizations interface.
However, we consider that at the end of this ﬁrst step, the
proposed mapping may not to be sufﬁciently appropriate
to the user’s objectives or to his data, and this for two
reasons. First, the mapping is done according to general
criteria on the visual perception (see the visual attributes
importance computing in section 3.2). The mapping can
also be considered as sufﬁciently adapted to give an idea
of the interest of the visualization to the user. But since the
visual perception is subjective, it is possible that the user
wishes to change or adjust the mapping. In addition, the

IV. U SER EVALUATION
A. Protocol
In order to evaluate our system, we have conducted a
ﬁrst user evaluation in which we have compared our user

254

Figure 1. First step of our assistant: visualizations are suggested to the user with an appropriate mapping between data attributes and visual attributes.
Several interactions are possible in this interface, including brushing.

For a given task, we use the same database for both tested
methods. However, we randomly change the data attributes
names and the order of such attributes in order to avoid a
learning effect. The testing order of the tasks and of the two
systems is also randomized. We have recruited 15 people
whose average age is 23 years (between 21 and 31 years) and
whose education level ranged from college to Master/PhD
in Computer Science. The average time of a test is one hour
and a half. A session is conducted as follows: 1) characterize
the user with a questionnaire (proﬁles, educational level,
multidimensional database knowledge level, use of a graphical representation application and the degree of experience,
level in a 3D environment, etc.), 2) explain to the user the
two tasks to be solved and let him perform some tests with
both methods and with standard databases (IRIS, WINE,
etc. [19]), 3) perform the test, 4) the user ﬁlls in a ﬁnal
questionnaire.

assistant with another visualization system called VRMiner
[18]. This last system uses a manual mapping interface
as many other visualization tools. Both systems have used
exactly the same information.
We deﬁne two tasks as well as their corresponding data.
Task 1 aims at evaluating the ﬁrst interface of our system and
more precisely the ability of users to obtain a predetermined
visualization mapping. The problem to be solved is stated
as follows: the user is asked to ﬁnd a visualization that can
represent 4 numeric attributes, 1 image attribute and 1 text
attribute. For this task, we generate a speciﬁc database with
150 data where each datum is described by 7 attributes (4
numeric, 1 image, 1 text, 1 class). Task 2 aims at evaluating
the second interface of our assistant, i.e. the IGA. The
problem to be solved consists in ﬁnding the attributes that
are the most relevant with respect to three predeﬁned classes.
The user must ﬁnd three attributes that visually reveal these
classes the best. 30 such attributes have been deﬁned. The
three ﬁrst attributes represent the correct answer to the task.
An increasing amount of noise has been added to the 27
remaining attributes. In order to estimate gradually the user’s
responses of this task, we have deﬁned a quality measure.
This quality measure gives to each data attribute a score that
is inversely proportional to the noise that we added for each
attribute. If we ﬁnd the data attributes that give the correct
answer, the quality is 1, and if the most noisy data attributes
are selected, the quality is 0.

B. Results
The results are presented in table I. Regarding T1, we
ﬁnd that users have successfully achieved this task with
the two systems: they ﬁnd at every time the requested
visualization. However, the time spend to answer is very
clearly in favor of our assistant. For T2, 6 participants among
the 15 aborted the manual interface. The quality values show
that the best responses are obtained more efﬁciently with
our assistant than without an assistant. In fact, we have

255

Figure 2.

Interface for the interactive and genetic optimization of the visualization mapping.

Tasks

Methods

T1
T1
T2
T2

VRMiner
Assistant
VRMiner
Assistant

Times (s)
mean ± SD
145 ± 90
31 ± 16
173 ± 92
181 ± 113

Quality
mean ± SD
1±0
1±0
0.37 ± 0.34
0.64 ± 0.10

Aborts/total
0/15
0/15
6/15
0/15

Table I
T HE USER

EVALUATION RESULTS OBTAINED FOR BOTH TASKS , WITH OR WITHOUT USER ASSISTANT.

applied directly on their data. The second step allowed
adjusting and optimizing visually that parameterization of
the visualizations. Another advantage of our system is that is
based on a generic architecture that can make easier for users
to add a new visualization, that we will complete with some
classic 2D visualizations. Our tool can also used to explore
interactively the databases in two ways: whether in a multivisualizations manner as described for the ﬁrst interface,
or in an interactive exploration as in the second interface.
Through the user evaluation that we have performed, we
have collected an objective and subjective observations on
the use of our tool. By analyzing these collected results
we ﬁnd that the interfaces that we have built are very
helpful for novice users because they do not require a priori
knowledge’s from them. The users have shown also, in a
subjective manner, their interest for future use of our system.
We will complete this work in different directions. We want
to implement more visualization and integrate them into our
knowledge-based visualization. Another perspective, which
is currently in study, involves taking into account the user
feedback to improve the recommendations of our system.
Thus, the user could beneﬁt of more appropriate suggestions
in its future use of the user assistant.

observed that users that perform T2 without assistant abort
after making few manual mapping tests. In contrast, the
use of our IGA facilitates and accelerates the convergence
toward the best answers. This highlights the abilities of
our tool for automatically adjusting the parameterization
of the visualizations and the selection of the attributes.
According to the results obtained from the subjective user
questionnaires that we have collected for each participant
after the test, 93% of users found that our assistant is easier
to use and more interesting to visualize their data than the
VRMiner system. 66% think that our tool gives them a better
manner to parameterize the visualization than VRMiner and
87% prefer to visualize their data with our assistant for
future use.
V. C ONCLUSION
In this paper, we have presented a user assistant which
integrates a data model, the user’s objectives, a knowledge
base on the visualizations, and two interfaces for the selection, parameterization and interactive optimization of the
visualizations. One of the major contributions of our tool is
that it proposes a new technique to automatize the visualization process based on two steps. The ﬁrst, allow to suggest to
user a several visualizations with their best possible mapping

256

R EFERENCES

[17] D. E. Goldberg, “Real-coded genetic algorithms, virtual alphabets, and blocking,” Complex Systems, vol. 5, no. 5, pp.
139–167, 1991.

[1] P. C. Wong, “Guest editor’s introduction: Visual data mining,”
IEEE Computer Graphics and Applications, vol. 19, no. 5, pp.
20–21, 1999.

[18] H. Azzag, F. Picarougne, C. Guinot, and G. Venturini, “Vrminer: A tool for multimedia database mining with virtual
reality,” Processing and Managing Complex Data for Decision Support, no. Ea 2101, pp. 318–339, 2005.

[2] J. Mackinlay, “Automating the design of graphical presentations of relational information,” ACM Transactions on Graphics, vol. 5, no. 2, pp. 110–141, 1986.

[19] C. L. Blake and C. J. Merz, “Uci repository of machine
learning databases,” UCI repository of machine learning
databases, p. http://archive.ics.uci.edu/ml/, 1998. [Online].
Available: http://www.ics.uci.edu/ mlearn/MLRepository.html

[3] H. Senay and E. Ignatius, “Vista: A knowledge based system
for scientiﬁc data visualization,” Tech. Rep., 1992.
[4] S. Lange, “Problem-oriented visualisation of multidimensional data sets,” Proceedings of the International
Symposium and Scientiﬁc Visualization, vol. 14, pp. 1–15,
1995.
[5] C. G. Healey, R. S. Amant, and M. S. Elhaddad, “Via: A
perceptual visualization assistant,” in In 28th Workshop on
Advanced Imagery Pattern Recognition (AIPR-99), 1999, pp.
2–11.
[6] S. Gnanamgari, “Information presentation through default
displays,” Ph.D. dissertation, Philadelphia, PA, USA, 1981.
[7] H. Senay and E. Ignatius, “A knowledge-based system for
visualization design,” IEEE Computer Graphics and Applications, vol. 14, no. 6, pp. 36–47, 1994.
[8] C. Healey, S. Kocherlakota, V. Rao, R. Mehta, and R. St
Amant, “Visual perception and mixed-initiative interaction for
assisted visualization design,” IEEE Transactions on Visualization and Computer Graphics, vol. 14, no. 2, pp. 396–411,
2008.
[9] J. Bertin, Semiology of graphics.
Wisconsin Press, 1983.

Berlin: University of

[10] S. K. Card, J. D. Mackinlay, and B. Shneiderman, Readings in
Information Visualization: Using Vision to Think (Interactive
Technologies). Morgan Kaufmann, 1999.
[11] R. A. Becker and W. S. Cleveland, “Brushing scatterplots,”
Technometrics, vol. 29, no. 2, pp. 127–142, 1987.
[12] R. Dawkins, The Blind Watchmaker.
1986.

San Mateo: Norton,

[13] J. H. Holland, Adaptation in Natural and Artiﬁcial Systems.
University of Michigan Press, 1975.
[14] N. Tokui, “Music composition with interactive evolutionary
computation,” Communication, vol. 17, no. 2, pp. 215–226,
2000.
[15] H. Kim, “Application of interactive genetic algorithm to
fashion design,” Engineering Applications of Artiﬁcial Intelligence, vol. 13, no. 6, pp. 635–644, 2000.
[16] G. Venturini, M. Slimane, F. Morin, and J.-P. Asselin de
Beauville, “On using interactive genetic algorithms for knowledge discovery in databases,” in Genetic Algorithms: Proceedings of the Seventh International Conference, T. Back, Ed.
Michigan State University, East Lansing, MI, USA: Morgan
Kaufmann, 1997, pp. 696–703.

257

