AutoFocus: Semantic Search for the Desktop
Christiaan Fluit
Aduna BV, The Netherlands
{Christiaan.Fluit@aduna.biz}

Abstract
Desktop search is a new application area for information retrieval technologies, focused on searching
in the local information sources on a user’s PC. These
applications typically operate as local search engines
and consequently exhibit all problems associated with
full-text search. AutoFocus is a new desktop search
application, focused on offering semantically rich interaction and serendipitous exploration instead,
through the use of the Cluster Map information visualization technique combined with explicit metadata
navigation. We discuss AutoFocus’ user interface and
Semantic Web-based architecture and report on its
applicability and usability based on preliminary user
feedback.

1. Introduction
Desktop search applications are a class of information retrieval tools for searching information stored on
a user’s PC, such as files, emails or contacts. They help
a user by providing fast and efficient access to his files
without having to remember where they are stored.
These applications have existed for some time, but
recently there has been a significant increase in attention. One reason for this is the common realization that
sophisticated tools for dealing with the ever-ongoing
growth of personal information sources are becoming a
necessity. Another factor is the involvement of major
software and service providers like Google [3] , Microsoft [5] and Apple [7] , as well as many smaller players, who are all offering or announcing desktop search
tools. The incorporation of these technologies in the
platform, as planned for Mac OS X Tiger and possibly
also for Windows Longhorn, is further proof for this
common realization as well as an indication that there
is growing consensus about what such a solution
should look like.
An observation about the current state-of-the-art in
desktop search tools is that they are all very similar in
nature. They typically provide a search engine-like

interface, featuring a query field and a paginated list of
results, with Grokker [4] being the only exception we
are aware of that provides a graphical interface to its
results. Consequently, they all suffer from the same
human interaction problems associated with full text
search (see [15] for an overview), such as under- or
over-specification of queries, leading to too many or no
results, the vocabulary problem, little help with query
refinement and a general lack of overview of the available information.
As with any system flooding the user with answers,
there is an opportunity for information visualization
techniques to provide better overview and richer interaction with the information. There is also an opportunity for semantic web technology to provide a technological basis for this richer interaction, by providing
semantic metadata, aggregation of heterogeneous information sources and services like reasoning support.
Aduna AutoFocus is a commercial desktop search
application that applies both information visualization
and semantic web technologies. It combines conventional keyword search with various other means to
browse and explore the information space, using the
metadata provided by the semantic web back-end. This
helps the user with formulating queries, interpreting
the results and getting a comprehensive overview and
makes the application useful for directed search as well
as explorative browsing of the available information.
Users can easily switch between these two modes, resulting in an effective and serendipitous interface.
Information visualization and semantic web technologies are by nature relatively independent. Information visualization is, as part of the user interface, a
front-end matter, concerned with communicating information to the user. It can just as easily be populated
with information originating from more traditional
database and text indexing components. Semantic web
technologies on the other hand are usually considered
to be a back-end or middleware matter and can also be
utilized using a simpler, textual interface. However, in
AutoFocus we have tightly combined these two technologies in a synergistic way. The metadata of the information is explicitly utilized in the user interface.

Proceedings of the Ninth International Conference on Information Visualisation (IV’05)
1550-6037/05 $20.00 © 2005 IEEE

Figure 1. AutoFocus' main screen
Browsing the metadata alone can already lead to an
increased insight in the information, as they explain
how the information space is partitioned. Furthermore,
any metadata value can be used as a query whose results are visualized, providing flexible access to the
information. Several improvements are envisioned that
take AutoFocus further along this path, by offering
richer metadata navigation and result visualization.
This paper is structured as follows: section 2 introduces AutoFocus and briefly explains the semantic
middleware. Section 3 evaluates the effectiveness and
usability of the application based on preliminary user
feedback and outlines possible ways to improve the
application. Finally, section 4 concludes this paper.

2. Aduna AutoFocus
Aduna AutoFocus1 is a desktop application for
browsing and searching a user’s personal information
sources, such as his files, emails or favorite web sites.
It uses a faceted classification approach: all informa1

Download a free copy of Aduna AutoFocus for personal use at
http://aduna.biz.

tion items are classified along several dimensions that
are meaningful to the user, e.g. by author or date.
These facets form the basis for browsing, querying and
visualization of this information space.
AutoFocus builds on earlier work on the Cluster
Map [10] [15] [17] [18] and its application in the
DOPE [8] [9] [16] and SWAP [13] [14] [16] projects.

2.1. Information Sources
AutoFocus 2005.1 supports the exploration of the
following types of personal information sources:
• File systems, both local and remote/shared.
• Email boxes (currently IMAP only).
• Web sites.
The application contains a wizard through which the
user can define a source, e.g. by specifying a web page
and a crawl depth for a website source.
After definition, a source is scanned by the application: the source is crawled exhaustively to collect all
information items that it contains. The metadata of
each item, such as its location, size and modification
date, is indexed for fast query evaluation. Furthermore,

Proceedings of the Ninth International Conference on Information Visualisation (IV’05)
1550-6037/05 $20.00 © 2005 IEEE

Figure 2: All available metadata facet panels
for supported file types such as MS Office and Internet
documents, the full text and any metadata contained
inside the document is extracted and indexed as well,
enabling keyword queries on the document text.
Note that the user explicitly defines all sources, the
application has no implicit or default sources. This
gives the user a sense of control, as he is aware and in
control of what is being indexed, preventing indexation
of information that may be considered too confidential.
This has recently been an issue with the Google Desktop Search, which by default automatically indexes
chat logs and the web browser history, of which some
people strongly disapproved. Additionally, it prevents
indexation of a lot of irrelevant files, such as the Windows system folder.
For enterprise use, the user can also define a source
that connects to an Aduna Metadata Server. This server
is capable of scanning file systems and websites and
provides programmatic access to its scanned sources
through a network protocol. With this server people
can immediately start to search and explore pre-defined
information sources, transparently blending personal
and enterprise search. They do not have to precisely
define an information source, which can be a complex
task. Also they do not have to wait for the scanning to
complete and are not required to keep the indexed information up-to-date.

2.2. User Interface
The information sources together form an information space consisting of items classified along several

dimensions. Once the user has defined one or more
sources, he can browse and navigate this information
space using keyword queries or by selecting values
from any of the other facets.
Figure 1 shows AutoFocus’ main screen. In this example, the user has defined four information sources,
here visible in the Scope panel at the upper left. The
first two sources are file system sources, the third is a
mail source and the last is a website source. Each
source has been scanned for information items and all
document texts and metadata have been indexed.
The panels at the left side, labeled Search, Location, etc., represent facets or metadata dimensions, with
the Scope panel being an exception explained below.
Each facet has its own specific user interface, tuned
towards presenting the values that occur in that dimension in a proper way. Figure 2 shows all facets.
When a user selects or enters a facet value, e.g. a
date range or a keyword, the application queries the
indexed metadata for all matching information items.
The resulting document set is shown in the Cluster
Map in the upper right corner of the screen.
Figure 1 shows the user interface after the user has
evaluated four queries: a keyword search for the term
“autofocus”, two phrase searches and a search for all
documents that were created or modified in the past
month. The documents resulting from these searches
are shown as spheres, with colors corresponding to the
source type: yellow spheres represent files; green
spheres are web pages, etc. Each of the four document
sets is symbolized by a rounded rectangle, labeled with
the facet value and an icon indicating the facet. The

Proceedings of the Ninth International Conference on Information Visualisation (IV’05)
1550-6037/05 $20.00 © 2005 IEEE

colored edges rendered in the background connect
documents to labels, indicating that these documents
belong to that result set. A document contained in multiple result sets is displayed only once but connected to
the labels of the sets that contain it. Subsets of documents with the same set memberships are placed together, thus clustering the total set of documents.
When a cluster contains more than 250 documents, it is
displayed as a cylinder labeled with the number of
documents, to prevent very large clusters from disturbing the usability of the visualization. This threshold has
been determined through trial and error, as a trade-off
has to be made between how long you can show individual icons without causing a cluster diameter that
disturbs the graph layout too much. When the graph
becomes too big to display in the available space in its
natural size, the visualization is automatically scaled so
that the graph is always visible in its entirety.
The Cluster Map visualization essentially provides
the same information as a Venn diagram or Euler diagram of the result sets, similar to the InfoCrystal [21]
and Cougar [19] visualizations, but without showing
the empty segments. It has the attractive property that
graphical closeness relates to semantic closeness, as
result sets that overlap are placed near each other, as
are documents that share set memberships. The information about existence and volume of overlaps between result sets provides valuable information about
the information space. For example, the visualization
in Figure 1 shows that the user’s documents about
desktop search all mention AutoFocus. Some of them
are about knowledge management as well, but not
those documents that were edited during the last
month.
In order to further inspect the contents of the visualization, the user can select a cluster or result set by
clicking on it. Its contents will be listed in the table
below the map. Figure 1 shows the table contents after
the user has clicked on the “desktop search” result set.
The table displays attributes such as the title, date and
location of the items, as well as a number of significant
terms extracted from the document text, based on term
occurrences and stopword lists. These keywords fulfill
a dual role: they act as document metadata, showing
what the document is about, but they can also be used
as queries to narrow down the search.
Details about individual results in the map are also
shown in a tooltip (see Figure 3). For optimal usability,
these tooltips behave slightly different from regular
tooltips: there is no delay before they popup and they
immediately follow the mouse pointer’s movement.
Documents can be opened in their native application by double-clicking or right-clicking on their
spheres in the graph or on their table entries.

Figure 3. The Cluster Map's tooltip
When the user selects documents in the Cluster
Map, statistical measures are used to determine relevant terms for this set. These terms are listed as suggestions in the Search panel, ordered alphabetically,
and can also be used to narrow down the search. When
no selection is made, the union of all document sets is
used in the determination of the suggestions.
The Scope panel mentioned earlier differs from the
other navigation panels in that it is not used to formulate queries. Instead, it allows the user to specify on
which information sources a query should be evaluated. By default, all sources are selected, but the user
can narrow this down to any subset. The outcome differs from selecting that source from the Location facet
and visualizing its documents, as now only documents
from these sources will be shown in the entire visualization. This is a way to overcome cluttered Cluster
Maps, when the user is already certain in which location an item resides.
Several switches are available for tuning the visualization, each one filtering out or stressing a part of
the displayed information. This sometimes helps the
interpretation of complex graphs.

2.3. Architecture
AutoFocus and the Metadata Server are based on
Sesame [11] , an open source server and framework for
RDF storage and querying. Each information source is
internally represented by an RDF repository that contains all metadata extracted from the source.
Sesame distinguishes two types of repositories. Local repositories are used to locally and persistently
store statements. Remote repositories are proxies for
repositories that are physically stored elsewhere and
that are queried and managed over a network. As the
Metadata Server uses Sesame’s standard facilities for
network communication, AutoFocus can use remote
repositories to communicate with the local repositories
inside a Metadata Server.
Each repository uses the same conceptual RDF
schema for the modeling of document metadata. User
queries in AutoFocus are internally translated to queries in the SeRQL [6] RDF query language, using the
vocabulary defined in this schema, and evaluated on all
repositories selected in the Scope panel. The schema
models typical document metadata such as title, author
and location. The properties are, where appropriate,
defined as sub-properties of Dublin Core [2]

Proceedings of the Ninth International Conference on Information Visualisation (IV’05)
1550-6037/05 $20.00 © 2005 IEEE

properties, as they are similar in use but have stricter
constraints on the format of the values. Keyword
searches are also “modeled” using this schema: a special matches property is introduced that connects a
document resource to a literal containing the search
string.
This use of Sesame’s protocols and components
provides great flexibility. On the one hand, other frontend applications can easily be built on top of the Metadata Server, for example interfaces optimized for specific tasks and domains, as its communication protocols and metadata model are publicly available. On the
other hand, proprietary systems such as databases or
document management systems can just as easily be
queried and explored by AutoFocus as another remote
source, by creating a Sesame-based wrapper around the
data source that answers queries expressed in the
schema’s vocabulary.
Inside a repository, two different storage formats
are used side-by-side for optimal query performance
and minimal storage requirements. In principal, all
RDF triples are stored in a Sesame-native store. The
full text is indexed using Lucene [1] , an open source
Java library for full text indexing and querying. Besides better performance this also gives us the ability to
evaluate more complex keyword queries, e.g. wildcard,
phrase and proximity searches, which are not supported by Sesame out-of-the-box. A layer on top of the
two storage formats splits up the original SeRQL query
in sub-queries to Lucene and the native RDF storage
and joins the results.
The Sesame framework has allowed us to separate
the conceptual model in which queries are formulated
from the way the information is physically stored. The
aforementioned wrappers around legacy information
systems may for example use a radically different implementation design and still provide access using the
same conceptual model, thereby requiring no adaptations in the applications that query them.

2.4. Related Work
As explained in section 2, AutoFocus builds on earlier work in the DOPE and SWAP projects. In both
projects a similar application has been built, using the
Cluster Map as an instrument to visualize query results.
The DOPE Browser, one of the deliverables of the
DOPE Project, differs from AutoFocus in that it uses a
single medical thesaurus of 45,000 terms to browse a
collection of millions of documents. Both the thesaurus’ size and the amount of documents posed technical
and usability-related scalability problems. For example, browsing such a broad and deep thesaurus turns
out to be a cognitively challenging task, whereas
AutoFocus’ rather straightforward metadata facets are

much simpler to learn and use. Consequently, we can
use simple trees and lists to display the occurring
metadata values.
Xarop, the end-user application built in the SWAP
project, allowed people to directly browse folders of
other peers in a peer-to-peer network and use a central
concept hierarchy to retrieve files classified with those
concepts. The initial feedback on this application has
been inspirational for the development of AutoFocus.
Both applications resulted in many generic improvements to the visualization such as the use of nonfigurative document icons, icons to indicate facet types
and ways to render the edges between clusters and set
labels, which could directly be reused in AutoFocus.
AutoFocus bears a strong similarity to the Haystack
[20] project in that both provide a single point of access to a variety of information sources through semantic integration. Currently we see a difference in focus
between the two approaches. Haystack excels in providing a unified view on information from different
sources, by separating the conceptual information from
the way it is contained in documents or mails. This
allows for e.g. the creation of interface parts that deal
with displaying messages, regardless of whether the
message is an email, an instant message or some other
kind of message. AutoFocus on the other hand is primarily concerned with giving the user powerful searching and browsing tools and providing continuous contextual, visual cues about his location and possible
paths in the information space. These two approaches
could very well complement each other and it is therefore interesting to see how ideas from the two projects
can be combined.

3. Preliminary Evaluation
We have received a considerable amount of feedback on AutoFocus through our support email address
and online forum. Furthermore, feedback was elicited
through demonstrations at customer sites and exhibitions. Also, a more structured evaluation of the Cluster
Map visualization and various forms of metadata navigation took place within the DOPE and SWAP projects. Some of the evaluation results generalize to other
Cluster Map-based applications such as AutoFocus.
What follows is an overview of our qualitative findings
regarding the effectiveness and usability of AutoFocus.
A quantitative comparison with other desktop
search tools or similar visualizations still has to be performed, e.g. using statistical information retrieval
measures such as precision and recall, time necessary
to complete a task or questionnaires. This feedback is
therefore only indicative for user satisfaction and is
used to determine future developments of the tool.

Proceedings of the Ninth International Conference on Information Visualisation (IV’05)
1550-6037/05 $20.00 © 2005 IEEE

First we will summarize the effectiveness of the
application for explorative searching, as noted by our
users. After that we will comment on the usability of
the visualization and metadata navigation facilities and
comment on ways in which they can be improved.

3.1. Effectiveness of the Application
The primary observation is that most users experience AutoFocus to be an engaging application, with
several users using the term “addictive”. People are
seen to interact intensively with their information, discovering information they were not aware they had
(anymore), even documents they wrote themselves.
Also, people frequently encounter unexpected patterns
in their information, such as overlaps between result
sets that cannot immediately be explained or the existence of query results in a location they would not have
looked in, leading to interesting discoveries. With the
Cluster Map they can quickly focus on these parts of
the information space, changing desktop search into a
serendipitous interaction with their information.
Typical usage of the application is often a mixture
of directed searching for specific topics, where the user
enters highly specific and precisely formulated queries,
and exploration of the result sets for other interesting
information, where for example the suggested search
terms are more used. The visualization and its interaction stimulate a shift from directed search to exploration, which on its turn can inspire users to new directed
searches for related topics, thus closing the loop.
One user remarked that, rather than being an intelligent application, AutoFocus is an application that
utilizes its user’s intelligence, relying on the human
quality of being good at recognizing that which is of
value, rather than having to specify it beforehand. Another quality is the sense of control or empowerment
that users experience from the combination of advanced search and rich overview facilities.
Most users consider the application to be very useful for people whose daily tasks are of an analytical
nature, such as researchers, students, medical doctors,
police investigators, etc.

3.2. Cluster Map Interpretation
Many users explicitly indicate that they appreciate
the information revealed in the Cluster Map visualization. They value the way in which they can see how the
results relate to their search terms, telling them whether
the result set is homogeneous (high overlap between
the result sets) or heterogeneous (relatively little overlap between the result sets) and providing a sense of
relative volume of the result sets.

A frequently occurring complaint concerns the
visualization’s graphical complexity: after a number of
queries Cluster Maps tend to get complex fast. Three
result sets are visualizable as a planar graph, graphs
with four result sets are often still manageable, but
with five or more result sets it depends on the degree of
overlap of the result sets whether the visualization is
still comprehensible.
Other feedback concerned the interpretation of the
icons. It is not immediately clear what the colors of the
document icons mean; there is no indicator that this
relates to a type property. We have experimented in the
past with more figurative icons indicating file type, e.g.
documents, archives, media files, etc. However, the
Cluster Map uses small 12-by-12 pixel images with a
round shape in order to scale to large amount of items,
which is too small for figurative icons.
AutoFocus as a whole and the Cluster Map in particular are based on handling categorical information:
the entire set of items is subdivided in possibly overlapping subsets, which are used as a basis for searching
and exploration. However, some of the information
captured in the metadata is of a relational nature, for
example the relation between a mail and its attachments, an archive and the files it contains or the hyperlinks between web pages. Users have expressed that
this information is lacking in the interface. It remains
to be seen how this information can be incorporated in
our visualization.
Finally, there is a group of users that indicate that
they would rather prefer a simpler interface, requiring
less interpretation efforts from the user. We should
investigate whether this preference is caused by a steep
learning curve or whether there is a fundamental difference in personal preferences and if we can still accommodate these users. In our experience some users
can be trained in a matter of minutes in interpreting the
visualization, but we cannot tell yet whether they are
representative for this entire user group.

3.3. Cluster Map Interaction
For some users it is not immediately clear how
documents can be opened. Double-clicking a document
icon to open the document is apparently not a perceived affordance in the Cluster Map. This may be
caused by the fact that clicking on a document icon
selects the entire cluster instead of that single icon.
There is a common requirement for displaying detailed document information inside the visualization.
The Cluster Map’s tooltip only shows metadata of a
single result. Hovering over a large collection is cumbersome and time-consuming. Clicking on a cluster or
result set to list the documents in the table works much
better, but requires the user to shift his attention to a

Proceedings of the Ninth International Conference on Information Visualisation (IV’05)
1550-6037/05 $20.00 © 2005 IEEE

different part of the interface. Also, the table constantly
takes up valuable screen space that could also be used
to display the graph in more detail. Several users expressed the desire to be able to view this document
information inside the visualization itself.
We envision several ways in which this display of
additional details can be accomplished. All of them
rely on user interaction, as the static display of a Cluster Map is already complex enough.
A simple solution is to superimpose the table on the
graph when the user clicks on a document set and position it near the selected documents. The table can then
be hidden when the selection is undone. This change is
merely cosmetic, as the table is removed from its fixed
location and is placed near the region of interest. A
drawback is that the number of attributes per item that
can be shown at a time is smaller than what is shown
now, as the table will have to be a lot narrower.
Another solution is to offer a kind of semantic
zooming, where parts of the title, file name or other
identifying information are shown as the user zooms in
on a part of the graph. As the icons get bigger, there is
more space for these details to be displayed. Zooming
can take place by simply increasing the rendering scale
or by using a Focus+Context approach.
A third alternative for revealing details in the visualization is by showing an animation using rapid serial
visual presentation (RSVP) techniques [12] when the
user clicks on a cluster. In this approach, short textual
descriptions or thumbnails of the items in a collection
are shown in a brief sequence, mimicking the experience of riffling through a book to get an impression of
its contents. Experiments have shown this to be a valuable technique for acquiring oversight in a set of items,
e.g. the set of files in a folder.
Finally, a number of interactive features are commonly requested: a “shopping basket”, i.e., a means to
collect interesting documents for later inspection, some
sort of bookmark support to save a set of interesting
queries for later use and a mechanism for monitoring
changes in result sets over time. People requesting the
latter feature are also aided by the mentioned bookmark support, as it becomes easier to repeat investigations over time, but the visualization could also be extended to explicitly highlight the changes.

facets may provide a very deep hierarchy, e.g. the location facet.
There are several ways in which metadata navigation can be improved. One of them is the generalization of suggestions. Currently, users are provided keyword search suggestions when they select documents
in the map. This can be generalized to other facets, e.g.
by filtering or highlighting those authors, locations and
dates whose document sets overlap with the currently
selected set of documents. This alleviates the need for
users to browse the entire metadata set.
Another major improvement lies in the use of userdefined taxonomies. Instead of having to search using
semantically shallow and domain-agnostic facets such
as location and date, users can then define their own
semantically meaningful categories or taxonomies. A
category or class can be defined intentionally, by formulating a rule in terms of the existing metadata facets,
or extensionally, by listing a set of document URIs.
This gives the user the ability to organize his information space according to his own view, rather than having to rely on existing models that fail to capture his
personal view on the information.

4. Summary
In this paper, we reported on the design and applicability of AutoFocus, a new kind of desktop search
application. AutoFocus differentiates itself from other
desktop search tools in that it is a first step towards a
semantically rich, explorative and serendipitous search
environment for personal information sources. Besides
offering facilities for directed search found in all desktop search tools, a variety of functionalities let him
browse and inspect the results of his queries and obtain
insight into the information at his disposal.
Preliminary user feedback on this new application
has been positive, showing that this application fulfills
a practical need. The application has been recognized
to support analytical tasks in particular.
A number of future developments have been formulated, primarily focusing on richer metadata navigation and richer interaction with search results, which
will improve AutoFocus’ serendipitous abilities.

References
3.4. Metadata Navigation
The amount of metadata provided in the facet panels poses a new navigation problem: that of navigating
a large conceptual space. Some facets may simply
show a very long list of values, e.g. the list of all senders of emails. This problem is enlarged by noisy metadata, such as people appearing up to five times in this
list because they use different email addresses. Other

[1]
[2]
[3]
[4]
[5]
[6]

Proceedings of the Ninth International Conference on Information Visualisation (IV’05)
1550-6037/05 $20.00 © 2005 IEEE

Apache Lucene. url: http://lucene.apache.org/
Dublin Core Metadata Element Set, version 1.1. url:
http://dublincore.org/documents/2004/12/20/dces/
Google Desktop Search. url: http://desktop.google.com
Grokker 2.2. url: http://www.groxis.com/
MSN Toolbar. url: http://toolbar.msn.com/
The SeRQL Query Language, revision 1.1. url:
http://www.openrdf.org/doc/SeRQLmanual.html

[7]
[8]

[9]

[10]

[11]

[12]

[13]

[14]

Spotlight (part of Mac OS X Tiger, to be released). url:
http://www.apple.com/macosx/tiger/spotlight.html
R. Bhogal, J. Broekstra, J. van Buel, I. Crowlesmith,
C. Fluit, F. van Harmelen, A. Kampman, E. van Mulligen, T. Scerri, H. Stuckenschmidt and A. de Waard. A
Topic-based Browser for Large Online Resources.
Proceedings International Conference on Knowledge
Engineering and Knowledge Management 2004
(EKAW’04). Springer-Verlag, 2004.
R. Bhogal, J. Broekstra, J. van Buel, I. Crowlesmith,
C. Fluit, F. van Harmelen, A. Kampman, E. van Mulligen, T. Scerri, H. Stuckenschmidt and A. de Waard.
Exploring Large Document Repositories with RDF
Technology: The DOPE Project. IEEE Intelligent Systems, 19(3), 2004.
J. Broekstra, C. Fluit, F. van Harmelen, H. ter Horst,
A. Kampman, J. van der Meer and M. Sabou. Ontology-based Information Visualisation. Proceedings Information Visualization 2001 (IV2001). IEEE Computer Society, 2001.
J. Broekstra, A. Kampman, F. van Harmelen. Sesame:
A Generic Architecture for Storing and Querying RDF
and RDF Schema. Proceedings International Semantic
Web Conference (ISWC 2002). Springer-Verlag, 2002.
O. de Bruijn and R. Spence. Rapid Serial Visual Presentation: A Space-Time Trade-off in Information Presentation. Proceedings of Advanced Visual Interfaces
(AVI 2000). ACM Press, 2000.
M. Ehrig, editor. SWAP Final Report. 2004. url:
http://swap.semanticweb.org/public/public/Publication
s/finalReport.pdf
M. Ehrig, C. Fluit, P. Haase, Esteve Lladó, M. Plechawski, S. Staab and C. Tempich. Xarop: A Midterm

[15]

[16]

[17]

[18]

[19]

[20]

[21]

Proceedings of the Ninth International Conference on Information Visualisation (IV’05)
1550-6037/05 $20.00 © 2005 IEEE

Report in Introducing a Decentralized Semantics-based
Knowledge Sharing Application. Proceedings International Conference on Practical Aspects of Knowledge
Management (PAKM 2004). Springer-Verlag, 2004.
C. Fluit, F. van Harmelen and M. Sabou. OntologyBased Information Visualisation. V. Geroimenko, C.
Chen, editors, Visualizing the Semantic Web. SpringerVerlag, 2002.
C. Fluit, F. van Harmelen and M. Sabou. Ontologybased Information Visualisation: Towards Semantic
Web Applications. V. Geroimenko, C. Chen, editors,
Visualizing the Semantic Web. Springer-Verlag, 2005
(to appear).
C. Fluit, F. van Harmelen and M. Sabou. Supporting
User Tasks through Visualisation of Light-weight Ontologies. S. Staab, R. Studer, editors, Handbook on Ontologies in Information Systems. Springer-Verlag,
2003.
C. Fluit and J. Wester. Using Visualization for Information Management Tasks. Proceedings Information
Visualization 2002 (IV2002). IEEE Computer Society,
2002.
M. Hearst. Using Categories to Provide Context for
Full-text Retrieval Results. Proceedings of RIAO ’94,
Intelligent Multimedia Information Retrieval Systems
and Management. Rockefeller, 1994.
D. Karger and D. Quan. Hot to Make a Semantic Web
Browser. Proceedings 13th World Wide Web Conference (WWW 2004). ACM Press, 2004.
A. Spoerri. InfoCrystal: A Visual Tool for Information
Retrieval. Readings in Information Visualization: Using Vision to Think. Morgan Kauffman, 1999.

