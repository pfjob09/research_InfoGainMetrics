Mode Independent Interaction Pattern Design
Christopher Frauenberger, Tony Stockman, Veronika Putz, Robert H¨oldrich
Graz University of Technology, Signal Processing and Speech Communication Laboratory
Queen Mary University of London, Department of Computer Science
University of Music and Dramatic Arts Graz, Institute of Electronic Music and Acoustics
frauenberger@dcs.qmul.ac.uk, tonys@dcs.qmul.ac.uk, putz@iem.at, hoeldrich@iem.at

Abstract
This paper proposes an approach for cross-modal user
interface design using interaction patterns. A meta-domain
is introduced in which the user interface can be designed
without the determination of its realisation in a particular interaction domain. When fully described in the metadomain, the user interface can be realised in different domains (visual, auditory, tactile etc) exploiting the strengths
of each different mode to its maximum. The paper proposes
a set of interaction patterns along with visual and auditory
realisations. To prove the concept a prototype was designed
for a real-world application, Microsoft Explorer. An auditory display prototype was developed making extensive use
of virtual audio environments for non-visual visualisation
of objects in the Explorer interface, taking advantage of a
spatial layout. The prototype was evaluated with visually
impaired, blind and sighted computer users.

1

Introduction

The design of user interfaces for modern information
technology is up to now primarily dominated by graphical
concepts and technologies. New challenges, however, urge
the scientiﬁc ﬁeld to reconsider approaches for developing
user interfaces and make use of all human senses to maximise the efﬁciency and usability of user interfaces. Challenges we face when designing user interfaces for modern
information technologies include:
• Increased complexity of tasks
• Miniaturisation of devices
• Mobility of the user
• Naturalness of interfaces
• Accessibility for disabled users

Figure 1. Mode independent user interaction

In this paper we propose a new approach to these challenges by introducing a mode independent meta domain
where user interfaces may be designed without determining
their means of realisation. By de-coupling the problem of
realising a user interface in a speciﬁc representation domain
from user interaction tasks and the interactive content, it is
possible to exploit the strengths of the different human interaction modes (eg. visual or audio) to their maximum. A
user interface described in the meta domain is then realised
from a transformation process speciﬁcally designed for that
particular representation domain. Figure 1 illustrates the
concept.
In this paper we focus on the auditory domain, but propose an approach equally applicable for every other interaction mode. However, the auditory domain is a good candidate for an additional interaction mode, as it addresses
some of the challenges mentioned above, because it is almost complementary to the shortcomings of the visual domain. Many requirements for an improved user interface
resulting from the points above can be achieved by auditory displays, whether sound is being used as an element of
a multimedia interface or on its own as a single medium.
In particular, the availability of virtual audio environments
enables us to convey a non-visual visualisation of objects
and supports the creation of a spatial sensation without visual cues. Currently, mechanisms for providing an overall

Proceedings of the Ninth International Conference on Information Visualisation (IV’05)
1550-6037/05 $20.00 © 2005 IEEE

perspective are under exploited in auditory interfaces, such
as those presented by screen readers and Braille displays.
Spatial layout is employed here both to help distinguish one
object from another, and to convey a sense of overall perspective of the layout of objects within the application.
We begin by discussing related work in section 2 ranging
from audio techniques, auditory displays to user interface
design. In the following section the design and organization of the patterns is described. Section 4 describes the
patterns developed along with their transformations into the
auditory domain. Subsequently, section 5 describes an evaluation test conducted for proving the feasibility of our approach. Finally, section 6 concludes the paper and provides
an outlook on further work.

2

Related Work

The increasing computational power available for digital
signal processing has made increasingly complex simulations of acoustical environments possible. The term Virtual Audio Environment describes the simulation of acoustical scenes with sound reproduction techniques. The goal is
to create natural environments which are customisable and
controllable in real time, very much as visual virtual environments were developed [10]. Acoustical rendering of
objects (sound sources), the environment and the listener
can be realised using a number of different approaches like
Ambisonics [1], Wave Field Synthesis [21] or Vector Based
Amplitude Panning [18]. Recently these techniques were
introduced to auditory displays as a major step towards natural interfaces [7, 4].
A variety of auditory displays were developed for speciﬁc problem domains (e.g.: [13, 20]) and some efforts were
taken towards a structured approach to more generic solutions. Early proposals include the Mercator project, the ﬁrst
framework targeting customary Unix desktops [22]. Another proposal was Y-Windows also following the idea of
building alternative, audio rendering engines (servers) for
existing clients requesting their user interface representation [11]. However, both approaches implied that graphical concepts were translated into the auditory domain and
therefore had their limitations. A ﬁrst attempt to depart
from this approach and introduce a mode independent meta
domain was made in [3] and subsequently led to the proposal made in this paper.
Employing usability engineering methodologies in the
design of auditory displays include the investigation of audio metaphors [5] and other structural approaches to include
sound into human-computer interaction (Earcons [14]). Recently, the proposal of using patterns in soniﬁcation highlights the advantages of such methods in re-usable designs
[2, 12]. However, much more may be exploited from the
discipline of usability engineering. Auditory representa-

tions of user interfaces are in need of profound heuristics
to assess user satisfaction similar to those in the graphical
domain [16]. Examples of where work is needed to identify
heuristics to guide the process of auditory display design include minimising the problems incurred due to the transient
nature of sound, quantifying how the effectiveness of interactions can be improved through learning and providing
guidelines for how sound can best be integrated with other
media [6]. Also the design pattern method is a promising
approach and other design principles may also give more
control over the efﬁciency of auditory displays.

3

Pattern Design and Structure

The concept of interaction patterns is a well known and
well accepted design methodology for creating user interfaces. However, most sets are heavily graphically orientated and make use of concepts like windows or pointers.
As a starting point for the development of our mode independent design patterns we were looking for abstract descriptions of user tasks. Such user centred design patterns
are re-formulated easily because they do not stress the technical realisation, but the users point of view. A set of patterns satisfying these requirements was found in [15] and
was chosen as the basis for our development. These patterns
are task-related and address different types of user problems
based upon several of interaction principles [17]:
Availability: 1 The required parts of the application need
to be available at the right time and should imply correct usage. Availability concerns the mapping between
intended actions of the user and the operations actually
required.
Affordances provide strong clues to the operation of things
(e.g. knobs are for turning, buttons for pushing). When
affordances are effectively used within an interface,
the user knows what to do with no further instruction
needed.
Constraints minimise the number of possible actions and
give additional information about the correct usage of
the interface elements.
Natural mapping: If the relationship between the controlling elements of an application and their results are natural for the user, it simpliﬁes the learning of the application and assists recall. Natural mapping depends on
physical analogies and cultural standards and is therefore subjective to different user groups.
Conceptual models: By interacting with an application,
the user builds up a conceptual model of it. If this
1 Instead of the term Availability, Visibility was originally used in [17],
but it was replaced due to its strong association with the visual domain

Proceedings of the Ninth International Conference on Information Visualisation (IV’05)
1550-6037/05 $20.00 © 2005 IEEE

model is equivalent to the task model of the application, it allows the user to predict the effects of his actions.
Feedback: Information about the result of his actions is
sent back to the user and enables immediate control
of the input.
The re-formulation of the patterns to make them independent from the used interaction mode demanded a change
of the terminology for the description of the patterns. The
representation medium means the domain or the combination of the domains in which the user interface will be realised. Within this representation medium there are representation areas deﬁned which provide the boundary for
objects of the user interface. These objects may result from
one or more interaction patterns transformed into the representation medium. Despite these small changes to the terminology, the existing interaction patterns were easy to reformulate so that they would not prejudice the process of
realisation.
While developing the patterns, we recognised that certain tasks or parts of patterns recurred in other patterns too.
This led to the concept of atoms and contextual attributes.
Similar to a vocabulary for instantiating designs. A set
of atoms were developed from which patterns may draw
when addressing a particular set of user requirements. This
also implies consistent representation of similar elementary
units throughout the whole interface although atoms are not
sufﬁcient to solve any interaction problem. The name indicates that this level should be the smallest piece in any
pattern to avoid over exaggerating modularity.
In order Not to end with a totally unrelated patchwork of
small pieces of a user interface, each atom provides contextual attributes. These attributes need to be set by the parent
pattern in order to indicate their context. In the graphical
domain this would, for example, mean that certain elements
like buttons or text ﬁelds are in the same window sharing
the same frame and background colour. The following contextual attributes were identiﬁed for our set of atoms:

a real user interface, but also the contextual attributes must
be mapped into the different representation media. Their
realisation in the auditory domain will differ considerably
from the visual domain.

4

The interaction patterns are described verbally in the following format: The user problem describes the initial problem the user is faced when interacting with a system. Further conditions to meet are deﬁned to determine a possible solution to the user problem. If the solution uses atoms
some attributes are provided which need to be transformed
in order to link the atoms to the pattern. Additionally a short
description of a realisation approach is provided for the visual and the auditory domain. The auditory realisations refer to a virtual audio environment which implements movements of the user within this environment. This enables the
user to use her position in analogy to the visual pointer device.
Table 1 shows all patterns developed using a subset of the
description scheme stated above. The whole set is described
in detail in [19].

All of these patterns are using the set of atoms developed.
The atoms were described in the very same manner as the
patterns, but to describe them in detail is not possible in this
paper. An overview is given below, for detailed description
see [19].
• Selection
• Selection with browsing
• Triggering elements
• Link
• Dataﬁeld
• Continuous increase/decrease of a value

Similarity: Atoms in the same pattern share properties like
timbre, rhythm or type of voice in their acoustical representation.

• Discrete increase/decrease of a value
• Raw information

Proximity: Atoms in the same pattern are grouped together
based on the available dimensions of the representation
area (space or pitch ranges).
Homogeneity: The same types of atoms should be placed
adjacently in a pattern on the basis of the available
dimensions of the representation area (space or pitch
ranges).
It is important to state that not only the patterns and the
atoms undergo the transformation process in order to form

The set of Design Patterns

• Tree structure
• List
The auditory realisations described here are currently under development and apart from those used in the evaluation
test covered in section 5 not yet tested. However, introducing them to a broader community with the aim of parallel
development of each pattern (as proposed in [12]) by building prototypes may result in robust and widely accepted design patterns.

Proceedings of the Ninth International Conference on Information Visualisation (IV’05)
1550-6037/05 $20.00 © 2005 IEEE

Table 1. The mode independent interaction patterns
User problem
Solution
Visual realisation
The user needs to know Put the shortcuts to the pos- A menu bar with
where to ﬁnd the possible sible commands in a speciﬁc shortcuts on the top
commands and how to acti- recognisable area
edge of the applicavate them
tion

Name
Command
Area

Wizard

The user wants to achieve a
single goal but several decisions need to be made before the goal can be achieved
completely

Contextual
Menus

At any time users need to
know what their possibilities
are in order to decide what to
do

Auditory realisation
A menu area in the
3D space with selectable auditory objects which spatially
unfold their contents
A sequence of similar acoustical rooms
with designated entries and exits

Take the user through the entire task one step at the time.
Let the user step through the
tasks and show which steps
exist and which have been
completed
Put the choices in a menu related to the active object

A sequence of similar windows with
navigation buttons

Mode Cursor

Connect the cursor with
functions and show the interface state in the cursor

Different icons for
the pointer (cursor,
arrow etc.)

Setting
tributes

The user is creating or modifying an object and needs to
know which edit function is
selected
At- Users want to see the attributes of the objects they
are working on and additionally they need to know how
to modify them

Create special feedback
shortcuts that present the
attribute values and can
be used to set the attribute
values

Link in the The user needs to know how
real world
to control an object in the interface which resembles an
object the user knows from
the real world
List browser The user needs to browse or
process several items out of
a set or list

Match the input device and
the widget used

Buttons in the shortcut area indicating
the state and allowing the user to alter
the state (e.g. bold,
italic in word processors)
Special interaction
devices

Auditory
objects
have special sound
properties attributed
indicating the state.
Altering the state
is shortcut into the
command area.
Special
interaction devices, may
integrate
speech
recognition

Find a natural ordering and
allow the user to navigate directly from one item to the
next and back

Ordered lists with
navigation through
cursor and scrolling

Continuous
ﬁlter

The user needs to ﬁnd an
item in an ordered set

Flexible search ﬁelds
pre-sorting a list selection

Preview

The user searches one item
in a set of items and tries
to ﬁnd it by browsing the
set. Often, other search criteria than the items name are
more effective
The user needs to access
an amount of information
which cannot be put on the
available representation area

Provide a ﬁlter component
with which the user can in
real time ﬁlter only the items
in the data that are of his interest
Allow the user to preview
the item

Spatially distributed
auditory objects with
indicated order and
browsable with an
acoustical lens
Flexible search ﬁelds
pre-sorting a list selection

Preview content areas (e.g. thumbnails
for images)

Switching temporarily to a different virtual room with a preview of the content
(auditory cartoons)

Group the information in
several categories and allow
the user to navigate between
them

E.g. Tabs

Acoustically themeable groups of content with fast navigation shortcuts

Navigating
between
categories

Proceedings of the Ninth International Conference on Information Visualisation (IV’05)
1550-6037/05 $20.00 © 2005 IEEE

Right click pop-up
menus at the position
of mouse pointer

Sticky objects with
trigger items which
surround the user and
perform the same
movements as the
user
Background sounds
indicating a state

Name
Container
navigation

Table 2. The mode independent interaction patterns (part 2)
User problem
Solution
Visual realisation
The user needs to ﬁnd an Split up the representation Frames and Winitem in a collection of con- area in regions for the con- dows
tainers
tainers and the ﬁnal selection

Unambiguous The user needs to supply
format
the application with data but
may not know which type or
format of data is required or
what syntax to use

Only allow the user to enter
data in the correct syntax

E.g. Pre-formatted
textﬁelds

Focus / Selec- Users want to quickly get
tion
information about an object
they see and possibly want
to modify the object

Introduce a focus in the application

Frame
Grouping
Layout

/ The user needs to quickly
understand information and
its structure. Several different objects have to share a
limited amount of representational space
The user wants to know
whether or not the operation
is still being performed as
well as how much longer the
user will need to wait
The user needs to know
how to select functions, especially if they are accessible in more than one way
(menu, keyboard shortcut,
toolbar)
/ The user may unintentionally cause a problem situation which needs to be resolved
The user may accidentally
select a function that has irreversible effects

Arrange objects due to a ﬁtting pattern

E.g. selection of text
or objects with the
pointer device. Selected objects change
their
background
colour
Frames are clearly
marked by their border and background
colour

Preferences

Favourites

Progress

Hinting

Warning
Message

Shield

Show that the application is
still working and give an indication of the progress

Progress
bars,
pointer modes

Give the user hints for other
ways to access the same
function

Tooltips providing
help when pointer
is near a function
button

Warn the user before continuing the task and give the
chance to abort the tasks

Pop-up
messages
with required user
interaction

Protect the user by inserting
a shield

Pop-up
messages
with required user
interaction

Each user is different and
prefers to do things slightly
different

Allow the user to adjust
preferences

Preferences window
including all options

The user needs to ﬁnd a regularly used item within a
large set of items

Allow
the
usage
of
favourites that point to
the items of choice

E.g. bookmarks in
browser applications

Proceedings of the Ninth International Conference on Information Visualisation (IV’05)
1550-6037/05 $20.00 © 2005 IEEE

Auditory realisation
Bordered space in
a 3D environment
like Walls or entire
Rooms including an
intelligent way of
navigating through
this environment
Represent the properties of an interaction
object with common
sound properties or
with detailed speech
instructions on demand
Selected
objects
change their acoustic
properties, e.g. become louder and play
in the foreground
Spatial grouping in
the virtual environment e.g. Walls and
rooms

Background sound
information exploiting metaphors for
progress (like a
raising pitch)
Short spoken hints
initiated by a function key

Sticky objects at the
users location which
require user interaction
Sticky objects at the
users location which
require user interaction
A certain room in
the virtual environment controlling the
options of the application
User deﬁned shortcuts allowing ”to
beam” to a certain
location within the
virtual environment

Figure 2. Layout of the auditory Explorer prototype

5

Evaluation

The evaluation had the goal of testing the concept by
designing a real world application using the set of mode
independent patterns and instantiating its auditory realisation. This auditory display was then tested with visually
impaired, blind and sighted users.
Being one of the most fundamental applications on computers, a ﬁle-managing application was chosen because its
basic features are familiar to most computer users. The idea
of the test was to analyse an existing application, describe it
through the mode independent patterns and then create the
auditory realisation from scratch. Analysing Microsoft Explorer resulted in a description using the following patterns
(atoms):
• Container Navigation (tree structure, list)
• Command Area (triggering element, selection)
• Context Menu (triggering element, selection)
• Message (triggering element, raw information)
The realisation of the description resulted in a prototype
navigable using a joystick and using a binaural Ambisonics
toolkit to simulate the virtual audio environment [9]. Applying the Container Navigation pattern the basic layout of
the virtual environment is illustrated in ﬁgure 2. Basically,
the menu is located along the left wall, the main content
area to the front, the tree view to the right and some short
cuts were laid out on the rear wall of the environment. Additionally, sticky objects were used to realise context menus
and other messages as given by the patterns.
The prototype was tested by 15 users, 7 being either visually impaired or legally blind. After instruction, the participants got 15 minutes of training time with the application,

participants were given a list of 7 tasks to perform. The
tasks involved ﬁnding out how many ﬁles are in a speciﬁc
folder, ﬁnding the size of ﬁles, copying, moving and creating ﬁles or folders.
The test showed that the proposed design approach led
to a very usable auditory realisation of an existing graphical application. The most remarkable results of the test
demonstrate the effectiveness of employing spatial sound to
provide a model of the application workspace. The virtual
distance covered by the participants for one successful selection of an item shows that it lies within the dimension of
the virtual room (10m x 14m and 12m high = 26m diagonal). It is slightly more for group B (the visually impaired
and blind), but lies within the standard deviation (Figure 3).
More detailed results with an analysis of the collected
bottom line data and subjective questionnaires are published
in [8] and [19].
The main advantage of using this design approach evidently was that usability problems of the interface could be
attributed to certain patterns. This enables us to improve
the patterns (whether their mode independent description
or their realisation in an interaction domain) instead of redesigning the whole interface.

6

Conclusion

This paper proposed an design approach for user interfaces with realisations in other domains than the visual by
introducing a meta-domain in which interfaces could be described mode independently. It showed a re-formulated version of a set of interaction patterns that can be used to design user interfaces in this meta-domain without determining their means of realisation. This enables us to take into
account the strengths and weaknesses of each human sense
independently, because no sense-speciﬁc concepts are used
as the foundation for design in another mode, for example,
visual concepts are not used as the basis of auditory design.
Furthermore, the approach provides the possibility to associate identiﬁed usability problems with certain interaction
patterns, so far not available in other modes than the visual.
Further work is required to improve the patterns and their
realisations to make them easy-to-use components for interface designers. For evaluation purposes a possibility to
compare the efﬁciency and user acceptance over different
interaction modes would be extremely helpful.

References
[1] J. S. Bamford. An analysis of ambisonic sound systems of ﬁrst and second order. Master’s thesis, University of Waterloo, http://audiolab.uwaterloo.
ca/˜jeffb/thesis/thesis.html, 1995.

Proceedings of the Ninth International Conference on Information Visualisation (IV’05)
1550-6037/05 $20.00 © 2005 IEEE

Figure 3. Covered distance per selection
[2] S. Barrass. Soniﬁcation design patterns. In ICAD Proceedings, Boston, USA, July 6–9 2003. Internation Conference
on Auditory Display.
[3] A. d. C. C. Frauenberger, R. H¨oldrich. A generic, semantically based design approach for spatial auditory computer
displays. In ICAD Proceedings, Sydney, Australia, July 6–9
2004. Internation Conference on Auditory Display.
[4] R. H. C. Frauenberger, V. Putz. Spatial auditory displays
- a study on the use of virtual audio environments as interfaces for users with visual disabilities. In DAFx04 Proceedings, Naples, Italy, October 5–8 2004. 7th Int. Conference
on Digital Audio Effects (DAFx’04).
[5] W. K. E. E. D. Mynatt. Extraordinary Human-Computer
Interaction, chapter Metaphors for Nonvisual Computing.
Cambridge University Press, 1995.
[6] G. K. et. al. Soniﬁcation report: Status of the ﬁeld and
research agenda. http://icad.org/websiteV2.0/
References/nsf.html, February 2005.
[7] M. S. et. al. A spatial audio interface for desktop applications. In AES Proceedings, International Conference on
Multichannel Audio, Banff, Canada, June 26–28 2003. AES:
Audio Engineering Society.
[8] C. F. et.al. Interaction patterns for auditory user interfaces.
In ICAD Proceedings, Limerick, Ireland, July 6–9 2005. Internation Conference on Auditory Display.
[9] M. N. et.al. A 3d real time rendering engine for binaural
sound reproduction. In ICAD Proceedings, Boston, USA,
July 6–9 2003. Internation Conference on Auditory Display.
[10] T. L. et.al. Creating interactive virtual auditory environments. IEEE Computer Graphics and Applications,
special issue ”Virtual Worlds, Real Sounds, 22(4):49–57,
July/August 2002. Electronic publication http://www.
computer.org/cga/.
[11] M. Kaltenbrunner. Y-windows: Proposal for a standard aui
environment. In ICAD Proceedings, Kyoto, Japan, July 2–5
2002. International Community for Auditory Display.
[12] S. B. M. Adcock. Cultivating design patterns for auditory
displays. In ICAD Proceedings, Sydney, Australia, July 6–9
2004. Internation Conference on Auditory Display.
[13] C. S. M. Kobayashi. Dynamic soundscape: Mapping time to
space for audio browsing. In ACM/SIGCHI 97 Proceedings,

[14]

[15]

[16]
[17]
[18]

[19]

[20]

[21]
[22]

Proceedings of the Ninth International Conference on Information Visualisation (IV’05)
1550-6037/05 $20.00 © 2005 IEEE

pages 194–201, Los Angeles, CA, March 22–27 1997. ACM
Conference on Human Factors in Computing Systems.
R. M. G. M. M. Blattner, D. A. Sumikawa. Earcons
and icons: Their structure and common design principles.
Human-Computer Interaction, 4(1):11–44, 1989.
H. T. M. van Welie. Interaction patterns in user interfaces. In
PLOP Proceedings, Monticello, Illinois, USA, August 13–
16 2000. 7th. Pattern Languages of Programs Conference.
J. Nielsen. Usability Engineering. Academic Press, London,
1993. ISBN 0125184050.
A. D. Norman. The Design of Everyday Things. Doubleday
Books, 1990.
V. Pulkki. Virtual sound source positioning using vector
base amplitude panning. Journal of the Audio Engineering
Society, 45(6):456–466, June 1997.
V. Putz. Spatial auditory user interfaces. Master’s thesis,
Institute of Electronic Music and Acoustics, University of
Music and dramatic Arts Graz, 2004. http://iem.at/
projekte/dsp/spatial/dp_putz.
C. Schmandt. Audio hallway: A virtual acoustic environment for browsing. In Proc. ACM Conference of Computer
Human Interactions, pages 163–170. ACM Press, April 18–
23 1998. Los Angeles, California, USA.
E. Verheijen. Sound Reproduction by Wave Field Synthesis.
PhD thesis, TU Delft, 1998.
T. R. W. K. Edwards, E. D. Mynatt. The mercator project, a
nonvisual interface to the x window system. The X Resource,
1993. O’Reilly Publishers.

