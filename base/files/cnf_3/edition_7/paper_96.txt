A Novel Efficient Algorithm for Determining Maximum
Common Subgraphs

Yu Wang and Carsten Maple
Department of Computing and Information Systems
University of Luton, UK.
yu.zwang@luton.ac.uk
carsten.maple@luton.ac.uk
Abstract
Graph representations are widely used for dealing
with structural information. There are applications, for
example, in pattern recognition, machine learning and
information retrieval, where one needs to measure the
similarity of objects. When graphs are used for the
representation of structured objects, then measuring the
similarity of objects becomes equivalent to determining
the similarity of graphs. The measurement of similarity is
normally performed by determining the maximum
common subgraph of the graphs in question. This paper
presents a new algorithm for determining the maximum
common subgraph of a pair of graphs which offers better
performance than existing algorithms.

1. Introduction
There exist many application areas in which the process
of comparing graphs is fundamental. Application areas
include analysis of consumer purchasing, process
analysis and pattern recognition. A key area in which
graph comparisons are instrumental is that of finding
similarities between pairs of two- or three-dimensional
objects. Such comparisons are required in areas such as
"Biology, Chemistry, Anthropology and Archaeology to
name a few", see Novotni and Klein [9]. Room planning
problems have been considered using geometric matching
techniques that rely on graph matching [10].
Much of the work involving graph matching techniques
concerns finding the maximum common subgraph (MCS)
of two graphs. In [3], the efficiency of similarity
measures based on the Maximum Common Substructure
(MCS) and their ability to bring together compounds with
similar behaviours are assessed. The results are

encouraging in terms of the use of MCS as a base for
structural description, either to screen a molecular
database, or to outline a new compound. The most
promising way seems to consider the MCS as one
attribute inside a heterogeneous vector. It also shows
MCS as a probable way to enrich significantly the
structural depiction of a compound and to increase the
interest of the chemical databases. Research undertaken
by Hagadone [7] involves extracting a selection of
compounds from a chemical database. A fragment-based
similarity is used to calculate an upper bound on the size
of the MCS between the target and each database
structure. The molecules of the database are then ordered
according to this upper bound. Finally, a MCS is
determined between the target and each compound of a
first selection.
The organisation of this paper is as follows. In section 2
we present a background to the problem, give formal
definitions and notation and present the motivation for
the work. In section 3 we present fundamental existing
algorithms for the comparison of two graphs before
presenting the proposed algorithm in section 4. The
results from experimentation are given in section 5 and
allow a comparison of the proposed algorithm with those
used in practice currently; a summary and
recommendations for further work concludes the paper in
section 6.

2. Definitions, Notation and Motivation of
the Work
In this paper we require the following definitions and
notation:
Definition 2.1: A labelled graph is a 4-tuple g = (V, E, α,
ß), where

Proceedings of the Ninth International Conference on Information Visualisation (IV’05)
1550-6037/05 $20.00 © 2005 IEEE

V is the finite set of vertices (also called nodes)
E ⊆ ҏV × V is the set of edges
α : V → L is a function assigning labels to the vertices
ß : E → L is a function assigning labels to the edges
Edge (u, v) originates at node u and terminates at node
v.
Definition 2.2: Let g1 = (V1, E1, a1, ß1) and g2 = (V2,
E2, a2, ß2) be two arbitrary graphs. A common subgraph
of g1 and g2, cs(g1 ,g2), is a graph g = (V, E, a, ß) such
that there exist subgraph isomorphism from g to g1 and
from g to g2. We call g a maximum common subgraph
of g1 and g2, mcs(g1,g2), if there exists no other common
subgraph of g1 and g2 that has more nodes than g.

2.1 Determining a common subgraph of a
minimum size
While a great deal of emphasis has been placed upon
determining to what extent two graphs are similar, it
remains a very relevant problems to determine whether
two graphs are similar to some predetermined threshold.
Indeed, such problems are of more significance in the
fields of chemistry and molecular biology than the issue
of the extent of similarity. Similarly, other application
areas that utilise clustering techniques are more
concerned with whether or not some structure is similar
enough to be considered a member of some class. Such
problems are not only relevant but lead to
implementations that are less computationally expensive
than the problem of determining the extent of similarity.
The focus of this work is to consider both the problem of
determining whether two graphs are similar to some
predetermined threshold and the level to which two
graphs are similar.

3. Existing Algorithms For MCS Detection
Though there are numerous algorithms to determine the
MCS of a set of graphs, there are two existing algorithms,
which are considered to be the fundamental. All other
algorithms usually follow the same principles as either of
the two, but have minor modifications that enhance
performance according to the application area.
The first algorithm by McGregor (first published in
1982), [11] searches for the MCS by finding all common
subgraphs of the two given graphs and then chooses the
graphs with the largest size. The second algorithm by
Durand and Pasari is well known for the reduction of the
MCS problem to an MC (maximum clique) problem. It
first builds the association graph between the two given
graphs and then searches for the maximum clique (MC)

of the association graph [5]. The MC detection problem
has been proved to be an NP-complete problem [6]. As
such many approximate algorithms have been developed
and are often used in preference to exact algorithms. A
survey of such algorithms, including an analysis of their
complexity, and potential applications is provided in [1].

3.1 McGregor’s Incremental Approach
McGregor’s MCS detection algorithm follows an
incremental approach. The algorithm begins by finding a
least common subgraph (one node from each graph
having the same attribute) of the two input graphs, if one
exists. If none exists then the MCS is the null graph. The
algorithm then attempts to enlarge the current common
subgraph called current state, by adding feasible
matching pairs. The requirement for feasibility is “two
nodes having the same attribute, which are connected to
the current common subgraph”. If multiple feasible pairs
exist from the current state, the algorithm follows one
pair and saves the decision point for backtracking
reasons. The subgraph detection ends when new more
pairs are feasible for each state, and every state has been
backtracked for enlarging. In this way, all the common
subgraphs of the two input graphs are found. The size of
each graph is then calculated (which should be very
straightforward if the implementation tracks the size for
each graph dynamically) and only those graphs having
the largest size are returned as the final maximum
common subgraphs.
Procedure MCS(state, n1, n2)
Begin
If (NextPair(n1, n2)) then
Begin
If(PariIsFeasible(n1, n2)) then
AddNewPair(n1, n2);
CloneCurrentState(s, snew);
While (snew is still expandable)
Begin
MCS(snew, n1, n2);
BackTrack(snew);
End
Delete(snew);
End
End Procedure

3.2 The Durand-Pasari Reduction of MCS to MC
The Durand-Pasari algorithm is based on the well-known
reduction of the search of the MCS between two input
graphs to the problem of finding a MC (maximum clique)
in a graph. The first step of the algorithm is the
construction of the association graph, whose vertices
correspond to pairs of vertices of the two starting graphs

Proceedings of the Ninth International Conference on Information Visualisation (IV’05)
1550-6037/05 $20.00 © 2005 IEEE

having the same attribute. The edges of the association
graph represent the compatibility of the pair of vertices to
be included; hence, MCS can be obtained by finding the
MC in the association graph.

3.3 Other Techniques
In situations where multiple objects are to be processed in
order to find a maximum common feature, the multiple
maximum common subgraph problems arises. The
algorithms of Varkony et al. [13] and Takahashi et al.
[12] begin by choosing the smallest graph. From this,
they take all the subgraphs containing just one edge and
search for the presence of this subgraph in all the other
graphs. If this is successful, the subgraph is grown
(according to the connections in the first graph) and the
process repeated until it is no longer possible to grow a
subgraph compatible with all graphs.
In 1992, Denis et al. [4] proposed a backtracking
algorithm with a pre-processing function that finds the
correct solution. This algorithm uses “favourable”
numbers at each node of each graph and other heuristics
to improve its efficiency. Then a multiple largest
common subgraph algorithm is exposed which

incorporates a quick method to find a priori minimal size
for a solution.
The most significant contribution of Denis et al.’s work is
the use of the “favourable” numbers to estimate the most
possible match path. However, the selection of
“favourable” numbers is largely dependent on the fact
that the graphs to be matched represent molecular
compounds, hence making their algorithm limited to a
certain application area within biology.

3.4 Comparison of Existing Algorithms
Bunke and Foggia [2] have conducted experiments on the
performance of the two fundamental MCS algorithms. In
their work, a database containing randomly connected
pairs of graphs, having a maximum common graph of at
least two nodes is presented and the performance of the
two algorithms on this database is evaluated. The tests
show that for graphs with a low edge-density it is more
convenient to search for the MCS by finding all the
common subgraphs of the two given graphs and
subsequently choosing the largest; for high edge-density,
it is efficient to build the association graph of the two
given graphs and then to search for the MC of the latter
graph.

Figure 1.Two graphs, G1 and G2, with a maximum common subgraph of H1 (= H2). The numeric
values indicate attribute values, the characters are indices.

Proceedings of the Ninth International Conference on Information Visualisation (IV’05)
1550-6037/05 $20.00 © 2005 IEEE

4. A New Algorithm for the Detection of
Maximum Common Subgraphs
In this section we present an algorithm to determine
whether to input graphs are similar to within some
tolerance. An input parameter is used to indicate if the
maximum common subgraph is required rather than a
subgraph that meets some minimum size criterion.
MCS(G1, G2,
Find_All);

Threshold_Percent,

Threshold_Size,

G1 and G2 are the two input graphs; the user can either
specify the threshold_percent (a value between 0.0 and
1.0), or the threshold_size (an integer value smaller than
the size of the smallest graph of the two). The Find_All is
used to indicate immediate return once a common
subgraph is found that satisfies the threshold value.
The MCS detection algorithm has the following five steps
in a procedure call
1.

Produce the matching pairs of the two input graphs; a
matching pair consists of one node from G1 and
another from G2, which have the same attribute. The
nodes of the input graph are sorted according to the
attribute, so that given a particular attribute all nodes
having the same attribute can be retrieved directly. If
the nodes of input graph are not sorted, the procedure
will sort the nodes. For every node of G2, the
procedure will search nodes of the same attribute in
G1 and put the matching pairs in a series of linked
lists. Consider Figure 1, in which numeric values
indicate attribute values, and the characters are
indices. It can be seen that two nodes in G2 have
attribute 1 (G2-1a, G2-1a) and can be matched
with one node in G1, (G1-1a). The complete series
of linked lists for this pair of graphs is:
G2-1a * G1-1a
G2-1a
G2-1b * G1-1a
G2-1b
G2-2a * G1-2b
G2-2a
G2-2a * NULL
G2-3a * G1-3a
G2-3a
G2-3a * G1-3c
G2-4
* G1-4
G2-5
* NULL

* NULL
* NULL
* G1-2a
* G1-3b
G2-3a * NULL

Note that for each node of G2, there’s also a NULL
node being attached to it; this indicates the end of the
linked list of possible matches.
2.

The procedure then will sort the order of pairs for
each list according to suitability of match. The

Proceedings of the Ninth International Conference on Information Visualisation (IV’05)
1550-6037/05 $20.00 © 2005 IEEE

characteristics used to determine suitability are
similarities in the degree, node attribute and edge
attribute.
Minimising Degree Difference – The degree of a
node is the number of edges connected to this node.
In our MCS procedure, for each node we will
calculate the degree of the node itself as well as the
degree of direct neighbour nodes. The direct
neighbour nodes are those who are connected to this
node directly by at least one edge. The degree of this
node and the degrees of neighbour nodes will be
summed as the SNDegree (self and neighbour
degree). The degree difference of two nodes is the
difference between the SNDegree of each node in
question; this calculation is straightforward. For
example, in graph G1, the degree of Node(2b) = 3;
the degree of Node(1a) = 4; the degree of Node(3a) =
2; the degree of Node(2a) = 1. Hence SNDegree
(Node(2b)) = 3 + 4 + 2 + 1 = 10. Similarly
SNDegree (Node(2a)) = 1 + 3 = 4. For graph G2,
SNDegree (Node(2a)) = 2 + 3 + 2 = 7.
Therefore we can define the degree difference
(DD) of these nodes: DD (Node(G1-2b), Node(G22a)) = |10 –7| = 3; DD (Node(G1-2a), Node(G2-2a))
= |4 – 7| = 3
Node Attribute Similarity – We define a procedure
to calculate the NAS (Node Attribute Similarity) of
two nodes. The procedure examines the neighbours
of the two nodes under consideration, NodeA and
NodeB, say. For each neighbour of NodeA, the
procedure attempts to map a corresponding
neighbour of NodeB that has the same attribute. If
such a mapping is successful, the NAS value
(initialised as 0) is increased by 1. Thus the NAS
value indicates how many neighbours of NodeA
match (in terms of attribute) neighbours of NodeB.
The calculation time of NAS is more than that of the
calculation of the SNDegree, however, it is
insignificant in terms of overall MCS detection cost
if the sizes of input graphs are large. Considering the
example in Figure 1 we see Node(G1-2b) has three
neighbour nodes Node(G1-1a), Node(G1-2a) and
Node(G1-3a); Node(G2-2a) has two neighbour nodes
Node(G2-1a) and Node(G2-3a). Therefore there are
two neighbour nodes of Node(G1-2b) of G1 can be
mapped to the neighbour nodes of Node(G2-2a):
NAS (Node(G1-2b), Node(G2-2a)) = 2; NAS
(Node(G1-2a), Node(G2-2a)) = 0.
Edge Attribute Similarity – The concept of edge
attribute similarity is similar to that of NAS, but
rather the procedure examines the edges of the two
nodes under consideration. For each edge of NodeA,

the procedure attempts to map a corresponding edge
of NodeB that has the same attribute. If such a
mapping is successful, the EAS value (initialised as
0) is increased by 1. Thus the EAS value indicates
how many edges of NodeA match (in terms of
attribute) edges of NodeB.
The procedure orders nodes in increasing degree
difference. When to pairs have the same difference
(reasonably common in the case of large graphs) they
are ordered by NAS, and then by EAS,
3.

The next step is to build a common subgraph path
through the series of linked lists. A path consists of
series of pairs, taking exactly one pair from each list.
Note that due to the existence of a match with the
NULL node, each node in G2 is assigned one
(possibly NULL) node in G1. The procedure follows
a depth first approach to ensure every possible path
through the lists is obtained. If we consider each row
as a tier of nodes, then we can consider the problem
as searching for some kind of optimal path through a
tree. Note that when adding a new pair to the current
path, it will be tested for feasibility. One requirement
is that the pair does not contain any node, which is
already in the path (since the same node cannot be
paired with two distinct nodes).

4.

As each path is constructed, the size of the
corresponding common subgraph is determined; if
this is smaller than the size of the current largest
common subgraph, it is discarded. If it is the same
size as the current largest, it is stored in the results
database. If a new common subgraph is of larger size
than the current largest, the current result database is
cleared and only this subgraph stored and its size will
be noted as the new current maximum size.

5.

This procedure of finding paths through the tree is
continued until all paths have been considered. If
however, the user has specified a threshold percent
or a threshold size, the procedure will return during
step 4 as soon as a common subgraph is found to
satisfy the threshold requirement.

feature in this database: Dense and sparse, higher and
lower attribute variety, connected or unconnected,
smaller and larger graph size are all included.
As is standard, we define a graph’s density to be the ratio
between the number of edges and maximum number of
edges in a simple graph with the same number of nodes.
For a graph G with |E(G)| edges and |N(G)| nodes, the
edge density Den(G) is given by Den(G) = (|E(G)| * 2) /
(|N(G)| * (|N(G)| - 1)). For two graphs with an equal
number of nodes, the higher the density greater the
processing time required to determine the MCS.
We define a graph’s node attribute variety as the ratio
between the number of node attributes and the number of
nodes. Graphs of higher node attribute variety are usually
less expensive to determine MCS than those of lower
node attribute variety.
A similar concept to the graph’s node attribute variety is
edge attribute variety. It’s the ratio between the number
of edge attributes and the number of edges. Graphs of
higher edge attribute variety are usually less expensive to
determine MCS than those of lower edge attribute
variety.
In order to test the performance of the algorithms in a
non-application dependent situation, we generate a
database of synthetic graphs with random values for the
node and edge attributes. The attributes are represented
by integer numbers with uniform distribution over a
certain interval. Graphs of size range from 10 to 60 are
tested in our database. The constitution of our database is
summarised in the table below.

By following all paths of the search tree this MCS
algorithm is guaranteed to find all maximum
common subgraphs.

5. Results
The new MCS algorithm has been implemented, as have
McGregor’s and Durand-Pasari’s algorithms.
The
database of graphs used for testing performance covers
types of graphs that are widely found in practical
application areas. Graphs with varying characteristics

Proceedings of the Ninth International Conference on Information Visualisation (IV’05)
1550-6037/05 $20.00 © 2005 IEEE

Edge
Density
0.1
0.1
0.1
0.1
0.2
0.2
0.2
0.2
0.3
0.3
0.3
0.3
0.4
0.4
0.4
0.4

Average Graph
Size
10,15,20,…,60
10,15,20,…,60
10,15,20,…,60
10,15,20,…,60
10,15,20,…,60
10,15,20,…,60
10,15,20,…,60
10,15,20,…,60
10,15,20,…,60
10,15,20,…,60
10,15,20,…,60
10,15,20,…,60
10,15,20,…,60
10,15,20,…,60
10,15,20,…,60
10,15,20,…,60

MCS Size
(%)
20%
40%
60%
80%
20%
40%
60%
80%
20%
40%
60%
80%
20%
40%
60%
80%

Number
of Pairs
200
200
200
200
200
200
200
200
200
200
200
200
200
200
200
200

In order to test the ability of each algorithm to find
common subgraphs satisfying a certain threshold (the
ability to find nearly maximum common subgraph), we
modified McGregor’s and Durand-Pasari’s algorithms so
that the procedure will return immediately when a
common subgraph is found that satisfies the threshold.
Durand-Pasari’s procedure returns a result when a clique
size equal to or larger than the threshold is found, and the
corresponding common subgraph is then constructed for
that clique. The threshold we set for the database is 75%.
The performance of the algorithms is presented in tables
below; the unit time is 1ms. The figures are calculated
averages from 10 consecutive tests of the same
parameters.
Table 1 MCS Size = 60% ED = 0.2
G Size
McG
D-P
New

10
8
30
22

15
48
180
164

20
25
30
35
40
120 4893 51002 120021 523001
428 18280 122339 202399 398020
600 17234 100020 153303 401120

Table 2 MCS Size = 60% ED = 0.4
G Size 10
McG 83
D-P 120
New 324

15
20
25
30
35
40
840 4200 62003 831140 1620329 4025440
1310 3920 42003 402240 1042880 1524220
2920 11023 70032 372331 1211820 1721990

Table 3 MCS Size = 80% ED = 0.2
G Size
McG
D-P
New

10
2
7
8

15
11
45
46

20
32
112
120

25
1321
4521
4221

30
12001
32229
30119

35
40
32001 132104
50021 102111
42341 92110

Table 4 MCS Size = 80% ED = 0.4
G Size
McG
D-P
New

10
21
30
70

15
222
420
723

20
25
30
35
40
1023 14592 201123 390234 1025440
1290 13912 102213 201230 572555
1592 14442 92210 231120 772005

Table 5 MCS Size = 80% Threshold = 75% ED = 0.2
G Size
McG
D-P
New

10
12
30
12

15
54
180
44

20
143
428
120

25
30
35
40
5621 49002 119990 423001
9280 122339 202399 598020
3234 30020 73303 201120

Table 6 MCS Size = 80% Threshold = 75% ED = 0.4

G Size 10
McG 83
D-P 120
New 27

15
104
370
88

20
25
30
35
40
281 9212 92112 201123 801237
800 15123 192341 361234 790012
242 6124 72212 132214 521247

6. Summary
In this paper, we have presented a new algorithm for
determining the maximum common subgraph (MCS) of a
pair of graphs. The focus of the new design is to consider
both the problem of determining whether two graphs are
similar to some predetermined threshold and the level to
which two graphs are similar.
Though there are numerous algorithms to determine the
MCS of graphs, there are two existing algorithms that are
considered to be fundamental. The first algorithm by
McGregor [11] uses an incremental approach. The second
algorithm by Durand and Pasari [5] relies on the
construction of an association graph and the search for a
maximum clique.
Our new MCS searching model is presented and a
comprehensive performance test is carried out for the
comparison of the three algorithms. From the test results,
it is clear that by using heuristics to sort the matching
pairs, our new algorithm appears to offer significant
benefits in finding results satisfying a predetermined
threshold. The new algorithm also appears to have a clear
advantage when handling graphs of large size and
complexity.
Further work involves looking at how well the algorithm
can perform in a parallel computing network and
mathematical proof of algorithm efficiency. More
heuristics will also be incorporated to deal with graphs
having additional assumptions, restrictions and
properties. Benchmark will be carried out in a real
application area such as image extraction or molecular
analysis to verify the algorithm with real and practical
problem.

7. References
[1] I. M. Bomze, M. Budinich, P. M. Pardalos, and M.
Pelillo, The Maximum Clique Problem, Handbook of
Combinatorial Optimization, vol. 4, Kluwer Academy
Pub., 1999.
[2] Bunke, H., Foggia, P., Guidobaldi, C., Sansone, C.,
Vento, M., A comparison of algorithms for maximum
common subgraph on randomly connected graphs, In

Proceedings of the Ninth International Conference on Information Visualisation (IV’05)
1550-6037/05 $20.00 © 2005 IEEE

Proc. IAPR Workshop on Structural and Syntactic Pattern
Recognition, 2002.
[3] Cuissart B., Touffet F., Crémilleux B., Hébrard J. J.
Relevance of Molecular Similarities Based on the
Maximum Common Substructure Health and Medical
Informatics Medinfo 01, pp. 16-20, London, UK,
September 2001
[4] Denis M. Bayada, Richard W.Simpson, and A.Peter
Johnson. An algorithm for the multiple common
subgraph problem. J. Chem. Inf. Comput. Sci., 32:680685, 1992
[5] P. J. Durand, R. Pasari, J. W. Baker, and Chun-che
Tsai, An Efficient Algorithm for Similarity Analysis of
Molecules , Internet Journal of Chemistry, vol. 2, 1999.
[6] M. R. Garey, D. S. Johnson, "Computers and
Intractability: A Guide to the Theory of NPCompleteness", Freeman & Co, New York, 1979.
[7] T. R. Hagadone. Molecular substructure similarity
searching: Efficient retrieval in two-dimensional structure
databases. J.Chem Inf.Comput.Sci, 32:515-521, 1992
[8] Novotni, M., Klein, R., 2001, A Geometric Approach
to 3D Object Comparison, in proceedings of International
Conference on Shape Modeling and Applications, 167175, 2001.
[9] Novotni, M., Klein, R., 2003, 3D Zernike Descriptors
for Content Based Shape Retrieval, in proceedings of 8th
ACM Symposium on Solid Modeling and Applications
2003.
[10] Maple, C., 2003, Geometric Design and Space
Planning Using the Marching Squares and Marching
Cube Algorithms, Proceedings of the IEEE International
Conference on Geometric Modelling and Graphics,
GMAG2003.
[11] J. J. McGregor, Backtrack Search Algorithms and
the Maximal Common Subgraph Problem", Software
Practice and Experience, Vol. 12, pp. 23-34, 1982.
[12] Takahashi, Y., Satoh, Y., Sasaki, S., Recognition of
Largest Common Fragment among a Variety of Chemical
Structures. Anal. Sci.1987, 3, 23-28.
[13] Varkony, T.; Shiloach, Y.; Smith, H. Computer –
Assisted Examination of Chemical Compounds for
Structural Similarities. J. Chem. Inf. Comput. Sci. 1978,
19, 104-111.

Proceedings of the Ninth International Conference on Information Visualisation (IV’05)
1550-6037/05 $20.00 © 2005 IEEE

