Mapping Domain Expertise within Teams: Visual Stimulation of Knowledgebuilding through Collaboration
Clifford Behrens, Devasis Bassu and Hyong-Sop Shim
Applied Research
Telcordia Technologies, Inc.
{cliff, dbassu, hyongsop}@research.telcordia.com

Abstract
Recent R&D efforts for the U.S. Intelligence
Community have been directed towards providing new
Information
Technology
that
better
supports
collaborative war-gaming and decision-modeling among
expert teams so as to produce valid and reliable
intelligence in a more-timely, less-costly manner. This
paper describes Schemer, a web service that provides
knowledge validation and collaboration support to
virtual panels of experts. Of particular interest is the
way that Schemer uses visualization of knowledge
distribution among panelists to motivate collaboration,
with the goal of fostering greater consensus and
knowledge-building, hence, better intelligence. Since an
additional requirement for supporting virtual panels is
incremental data acquisition from panel members,
models must often be computed from incomplete data.
The same visualization techniques for evaluating
consensus formation and knowledge-building among
panelist also prove useful for evaluating the impact of
data imputation on model validity and reliability.
Keywords--- knowledge validation, collaboration,
multidimensionsal scaling, Procrustes analysis,
consensus model

1. Introduction
A major goal of recent research and development
efforts for the United States Intelligence Community is
developing information technology capable of
supporting collaboration among teams of subject matter
experts (SMEs) in war gaming and decision-modeling
activities. While greater collaboration seems a desirable
objective, we think it will only find wide support within
the Intelligence Community if there is the belief that
greater collaboration will produce a collective good, i.e.,
better intelligence. This means that models derived
through greater collaboration should be valid and
reliable, and represent a demonstrable improvement over
those produced with little or no collaboration among
intelligence experts. Moreover, the cost of greater

collaboration should be minimal and acceptable to all
those involved. In fact, one could argue that more use
isn’t made of human experts due to the widespread
perception that decision models produced by humans are
biased and unreliable, i.e., of low quality, and the cost of
bringing experts together in panels, particularly in faceto-face meetings, is often prohibitive. Thus, there exists
a need for new collaboration infrastructures that ensure
the involvement of the most qualified domain experts,
are able to validate the models they produce, and also
reduce the cost of their collaborations.
To meet the challenge above, Telcordia is
developing the Schemer Web Service [2,3], a flexible
knowledge-driven
technology
that
motivates
collaboration through a heightened awareness of “who
knows what.” Key to our approach is support for
collaboration within virtual panels, involving the
brightest and most qualified individuals. By virtual, we
mean panels whose members may be distributed in space
and time. Individual panelists may submit their model
inputs over the Web incrementally and asynchronously,
i.e., at their own convenience. Furthermore, panelists, if
they desire and are permitted by policy, may collaborate
with each other over distance and time by using both
synchronous and asynchronous means of communication
to share information. Our expectation is that, by hosting
interactions between the most qualified experts in a
knowledge domain, and by imposing a rigorous scientific
methodology on collaborative modeling, it will be
possible to produce valid and reliable intelligence in a
much more timely and less costly manner. The rest of
this paper describes how Schemer uses visualizations to
create greater awareness among members of virtual
teams, and stimulates collaborations leading to
consensus formation and knowledge-building.

2. Schemer Knowledge Map
Much of the motivation for Schemer knowledge
validation services is to drive use of collaboration tools,
primarily through the support of knowledge validation
metrics and visualizations derived from both static and
longitudinal analyses of panel data [3,4]. We believe
that some of this motivation might be provided by giving

©2005, Telcordia Technologies, Inc. All Rights Reserved.

Proceedings of the Ninth International Conference on Information Visualisation (IV’05)
1550-6037/05 $20.00 © 2005 IEEE

users greater insight into how knowledge is distributed
within their work environments along with new
communications interfaces which, based on this insight,
facilitate interactions between those who possess and
those who need knowledge. This perspective is a
departure from more process-based collaboration
approaches designed to enforce prescribed work flows;
instead, we propose a more flexible and informal
knowledge-driven approach where collaboration grows
out of an appreciation for peer review and the need to vet
or corroborate one’s point of view.

Figure 1. Schemer knowledge map (KMap).
Schemer contributes to heightening awareness by
producing a knowledge map (KMap), which is a contour
plot (analogous to a topographical map) that graphically
displays relative distances among panelists in terms of
their estimated competencies and differences in their
domain knowledge (see Fig. 1). KMaps are computed
with the image and contour functions in the R library.
The x-y coordinates of the panelists plotted in this image
are
obtained
by
computing
a
non-metric
multidimensional scaling (MDS) of an agreement matrix,
using the isoMDS function in the R library [9]. An
agreement matrix is really just a distance matrix
containing the probabilities that pairs of panelists would
answer a set of questions about a domain exactly the
same, and is computed as part of a consensus analysis of
panel response data [2, 10]. The Kruskal non-metric
MDS algorithm provides a point configuration that, in
this case, is the two-dimensional solution best preserving
the relative distances between panelists while reducing
the total sum of squared distances between the distances
in the agreement matrix and those in the computed
configuration [12]. The typical KMap image resembles
a “fried egg,” with the most knowledgeable panelists in
the center or “yolk” of the egg, and the least
knowledgeable panelists plotted towards the edges or

“white” of the egg. (Though unlike a real fried egg, the
center of a KMap is rendered white to give the most
knowledgeable panelists greater visibility). The closer
two panelists are on this image, the more similar they are
in the knowledge they possess; conversely, those
panelists plotted most distant from one another have the
most different perspectives. In addition, competency
contour lines are overlaid on a KMap image to provide
references for groups of panelists possessing equivalent
knowledge, and a legend is also provided for more
detailed visual interpretation of the plot.
These
competencies are also derived from consensus analysis
and merely estimate the degree to which a panelist’s
knowledge coincides with the consensus view. Put
another way, competency is directly related to the
probability that the panelist would correctly answer any
question “randomly” drawn from the same knowledge
domain. The means for estimating knowledge domain
competencies for panel members involves the
computation of a maximum likelihood factor analysis of
the agreement matrix, using the factanal function in the
R library [9]. Once it has been established that this
analysis yields a single factor solution, then panelists’
competencies are estimated by each one’s loading on this
factor. A single factor solution suggests that the selected
knowledge domain is salient to panelists, and no panelist
seems to bring an extreme perspective or bias to the
collaboration. This formal methodology is based on the
fundamental assumption that consensus is an indicator of
core knowledge. (The reader is encouraged to consult
[2,3,10,11] for more technical details on consensus
analysis and its many applications.)
The KMap computed and returned to panelists by
Schemer is crucial to our notion of knowledge-driven
collaboration. By giving panelists greater insight into
the manner in which knowledge is distributed among
them, Schemer motivates further collaboration and the
formation of advice networks. For example, a panelist
with a question might seek an answer from another
panelist who seems to be more knowledgeable, in this
case a neighbor plotted on the KMap within a higher
competency contour, but not necessarily one of the socalled “gurus.” This reduces the cognitive load on the
most knowledgeable individuals in the panel. One might
also wish to use information about other panelists
represented on the KMap to determine those whose
perspective seems most different from their own, then
initiate further collaboration in attempt to resolve or
explain these differences. In this case, those panelists
possessing perspectives most different are plotted at the
opposite end of an axis connecting the two panelists’
coordinates and passing through the center of the KMap
configuration. The critical assumption here is that
panelists vary in the knowledge they possess, insight into
the distribution of knowledge among panelists will
motivate them to collaborate, and this collaboration will,
in turn, lead to knowledge-building and model
improvement. In fact, Schemer actually facilitates
collaboration by offering KMaps as a communication
interface to collaboration tools in panelists’ IT

Proceedings of the Ninth International Conference on Information Visualisation (IV’05)
1550-6037/05 $20.00 © 2005 IEEE

environment. For example, KMaps currently bind
dynamically with tools, e.g., instant messenger, in the
Groove® collaboration environment, making it easy for a
panelist to communicate with others merely by clickingon their point in the KMap configuration [3,4].

³/RQHZROI´

collaboration tools. Through collaboration one of two
things can happen. It may be discovered that, indeed, the
“lone-wolf” expresses a viewpoint that is not wellreasoned or supported by existing evidence. In this case,
collaboration might bring this panelist closer to the
consensus view, though still well outside the center of
the KMap occupied by the most knowledgeable
panelists. Alternatively, the “lone-wolf” may offer a
well-reasoned argument supported by new, but not
widely-known, evidence. In this case, collaboration may
lead to a dramatic shift of positions so that the “lonewolf" eventually becomes the center of the consensus
cluster of panelists in the KMap.

3. Longitudinal Analysis

Figure 2. Schemer KMap revealing novel
thinker or "lone-wolf."

2.1. Biases and special insights
Recent events have demonstrated how unchecked
social dynamics and “group think” during intelligence
analysis can lead to conclusions that are neither valid nor
reliable. Through consensus analysis, Schemer attempts
to counter the effect of dominant personalities and
“group think” by qualifying panelists and exposing any
biases they bring to the collaborative modeling effort.
For purposes here, bias is used in the statistical sense and
is interpreted to mean a perspective drawn from a
different community of interest than the one represented
by other panelists. This is a critical distinction since
communities of interest can significantly differ in their
respective domain theories, vocabulary, semantics, and
the heuristics they employ to make sense of the world
[2]. Different biases are represented in a KMap by
distinct clusters of points. For example, Figure 2 shows
a KMap with a consensus cluster of panelists on the left,
and a single “lone-wolf” panelist to the right. It appears
that the latter possess unique knowledge, or brings to the
panel a perspective very different from the rest.
Discoveries such as the one above beg greater indepth examination and invite further collaboration.
Other panelists may like to know whether the “lonewolf” is really less knowledgeable in the domain, is “offthe-wall” or extreme in his views, or offers a keen
insight unknown to them. Schemer makes it easy for
panelists to explore these differences using available

A KMap is useful as a “snapshot” that provides
panelists with a current view of knowledge distribution
within a panel. Again, the hope is that this view will
motivate panelists to use collaboration tools in their IT
environment to exchange ideas and, when appropriate,
revise their opinions. This form of knowledge-building,
and the role played by collaboration and consensusbuilding, can actually be monitored by longitudinal
analysis of KMaps. Here too, visual cues can contribute
to greater understanding in important ways.
In principle, it should be reasonably easy to compare
a time series of KMaps to determine whether any
panelists have changed their position relative to others.
For example, over time a “lone-wolf” with keen or deep
insights may persuade others to his point of view. In this
case, his position would move towards the center of the
plot, within the “yolk.”
In other cases, more
knowledgeable panelists may further educate or persuade
less knowledgeable ones so that the latter are brought
closer to the plot’s center. The same overall properties
should hold true, with the most knowledgeable panelists
located in the plot’s center, and least knowledgeable
panelists in the plot’s periphery.
However, if
knowledge-building
is
taking
place
through
collaboration, then one would expect two other patterns
to emerge over time. First, the plot of points should
become more compact and second, more points should
fall within higher competency contours.
Schemer performs longitudinal analysis on a series
of KMaps to compute visualizations and metrics useful
for assessing the amount of consensus formation and
knowledge-building produced by collaboration, as
illustrated in Fig. 3. However, longitudinal analysis is
complicated by the fact that the MDS algorithm produces
a KMap whose axes orientation and scale is arbitrary.
This means that before successive KMaps can be
compared, and associated knowledge validation metrics
computed, all KMaps used for longitudinal analysis must
be referenced to the same coordinate configuration.
Schemer uses the procrustes function in the R library for
this coordinate rotation and transformation [9].
Greater concordance between data sets after
Procrustes rotation produces a smaller residual sum of
squared differences in Euclidean multivariate space [5].

Proceedings of the Ninth International Conference on Information Visualisation (IV’05)
1550-6037/05 $20.00 © 2005 IEEE

3

15
25

14
2
31
2924

10

26

20
22
6
33

23
16
17

36

1
9

14

25

3

15

8 7
35

2
31

10
26

21

34 12

27
11 4

2924
7

20

23
16

22
6

33

13
32

19

30

30

Compactness = 0.72

35

17

5

34 12
21

8

13

27
32

36
19

1

28
18

9

KMap for
Fri
Nov
07
11:20:41
2003

11 4

Corr(t,t-1) = NA
p-value = NA

5

28
18
9

30
13

19

1 14 30
19
13
15 16 36 227 5
247
33 6 29
25 23 10 35 33121 12
28
22
261720 8 3234
411
18

36

16

15

33
5

23

2

17 20

35
28
22

5

27
24
297
31
21
3

6

10
26

KMap for
Fri
Nov
17
11:25:04
2003

14

1

9

8

4
18

Corr(t,t-1) = 0.56
p-value < 0.001

34

32

11

Compactness = 0.4
12

14
30

1
15

5

19

16

13

2
14 30
5
1
1516 192 3613
3322 24727
6 29
10
31 21
25 2035
26 2883 12
23 17 4 113234
18

36
24 7 27

33 22

26
23

9

6
35

10

5

20

28

17

2931

21

3

12
34

8
4

11

32

KMap for
Fri
Dec
10
11:34:10
2003
Compactness = 0.31
Corr(t,t-1) = 0.78
p-value < 0.001

18
9

Figure 3. Longitudinal analysis on a series of KMaps showing growing consensus and knowledge building.
See main text for details.
Schemer measures this concordance with a correlationlike statistic (Corr) derived from the symmetric
Procrustes sum of squares (SS) as Corr = 1 − SS .
As the concordance between plots increases, the value of
Corr
1.0. The R function protest computes Corr, then
conducts a randomization test to estimate its significance
(or p-value) by calling the procrustes function repeatedly
(1,000 times), keeping track of the proportion of times
the value of Corr obtained for the permuted data is
greater than or equal to the observed value [7,8]. Along
with the rotated plots and correlation between each
rotated plot and its reference configuration, a
Compactness metric, measuring the overall knowledge
variability among panelists, is also reported. Based on
intra-configuration standard deviation, it is computed as
follows:
 

sdev( X ) =

1
N

N

¦d

2

( xi , x )

i =1

d 2 ( xi , x ) is the squared Euclidean distance
between a vector xi and x , the centroid of X; and N is

where

the number of points (panelists) in the KMap
0 as the
configuration [1]. The value of Compactness
configuration becomes more compact, indicating greater
consensus among panelists.
The reason for providing all of the visualizations
and supporting metrics described above is to foster
 

knowledge-building and intelligence improvement
through increased collaboration among panelists. Again,
our hope is that, by giving panelists greater insight into
how knowledge is distributed within a panel, they will be
further motivated to share what they know. This
includes a heightened awareness of key concepts and the
negotiation of their meaning, and growing agreement on
first principles and assumptions key to the relevant
domain theory. Schemer provides a means for actually
monitoring this process. For example, the plots and
statistics computed from a longitudinal analysis of
KMaps, presented in Fig. 3, indicate a scenario in which
collaboration is, indeed, promoting consensus and
knowledge-building.
As panelists exchange more
information and increase their knowledge of the topic
domain, they eventually come to share a similar domain
theory, and the following pattern emerges. The leftmost
column of scatter plots exhibit a single cluster of points,
and this cluster of points grows more compact over time,
suggesting that panelists are converging on a shared or
“consensus” model. This conclusion is further supported
by a gradual decrease in the compactness metric over the
same time periods. The middle column of plots shows
how the knowledge possessed by panelists, with respect
to their peers, changes over time. The length of an arrow
is directly proportional to the shift in a panelist’s
position, and the amount of overlap (or “spaghetti”)
among arrows indicates the amount of uncertainty
among panelists. The last plot in this series exhibits
relative stability with few panelists having shifted much
from their previous position. The rightmost column of

Proceedings of the Ninth International Conference on Information Visualisation (IV’05)
1550-6037/05 $20.00 © 2005 IEEE

plots is a replotting of each KMap after Procrustes
rotation, if rotation was applied. The trend in this
sequence of plots is for a greater concentration of
panelists within higher-valued competency contours.
The increase in correlation between successive KMaps in
the series also confirms growing consensus and panel
convergence on a shared domain theory.
0% Imputation
Compactness=0.26
Corr(t,t-1)= NA
p-value= NA

20% Imputation
Compactness=0.24
Corr(t,t-1)= 0.9
p-value= <0.001

40% Imputation
Compactness=0.11
Corr(t,t-1)= 0.45
p-value= 0.01

60% Imputation
Compactness=0.03
Corr(t,t-1)= 0.26
p-value= 0.33

80% Imputation
Compactness=0.01
Corr(t,t-1)= 0.21
p-value= 0.6

Figure 4. Effects of 0%, 20%, 40%, 60% and 80%
data imputation on KMap compactness,
configuration stability and consensus model
reliability.

4. Data Imputation
Virtual panels create special data acquisition
challenges: panelists are distributed in space and time,
yet services are needed so that they can provide data
incrementally and at their convenience. Moreover,
models are to be computed from panel data in a timely
manner. These conditions lead to a likely scenario
where, at any moment in time, a consensus model must
be computed from incomplete data. While it is possible
to impute missing data, this only makes sense if
panelists’ responses have been acquired so that they are
representative and balanced, i.e., guided by data
acquisition plans based on sound experimental research
design. By collecting panel data following a data
acquisition plan, knowledge will be uniformly sampled,
and no panelist will be burdened with more data
acquisition than any other.
To address these concerns, we have begun to
implement new panel administration middleware called
the Collaborative Panel Administrator [4,13]. This
middleware computes data acquisition plans, and then
manages panel inputs according to these plans. Data

acquisition plans are computed from panel size, the size
of the data acquisition instrument, the amount of data
already collected, the number of data acquisition
increments, and deadlines for each increment. Since data
are missing for all but the final increment, these must be
imputed. Hence, it is worth assessing the impact that
data imputation has on model validity and reliability. It
happens that the same visualization tools useful for
monitoring consensus-formation and knowledgebuilding are also useful for assessing the effect of data
imputation on consensus-modeling.
Figure 4 shows (from top to bottom) a series of
KMap configurations that were computed from a single
set of data for a panel of twenty-six experts, each
providing fifty responses (yielding a total of 1,300
responses). These response data were generated with
0%, 20%, 40%, 60% and 80% of their values imputed,
using a K-nearest neighbor estimation algorithm [6,14]
As expected, the left-most column shows that the scatter
of a KMap configuration becomes more compact with
greater data imputation since variance is under-estimated
when consensus models are computed from increasing
amounts of imputed data. The center column of plots
illustrates the results obtained after Procrustes rotation of
these KMap configurations.
These plots reveal
decreasing stability of configurations with increasing
data imputation, evidenced by many shifts in the position
of points, more “spaghetti” among arrows, and
decreasing correlations between successive plots
accompanied by increasing p-values. Of course the
interpretation here is that the derived consensus models
are less reliable. The right-most column of plots shows
the KMaps after Procrustes rotation. As anticipated, the
pattern of the KMap configuration changes from the
archetypical “fried-egg” pattern with no data imputation,
to a more amorphous configuration with 80% imputed
data.
By examining these visualizations and
accompanying metrics for evidence of convergence, they
can suggest when enough data have been acquired to
compute consensus models that are both valid and
reliable, and for reducing the amount of time and cost
needed to produce them. Moreover, by underscoring the
value and effect of each panelist’s contributions to the
consensus model, these visualizations may also motivate
them to provide their inputs so that they meet the
deadlines prescribed by a data acquisition plan.

Conclusions
In this paper we described visualizations produced
by our Schemer Web Service to improve knowledgebuilding within panels of domain experts by providing
insights into the manner in which domain expertise is
distributed among them. This insight is important for
stimulating collaboration, with the intent of yielding
greater information sharing and model improvement.
Support for virtual teams, those whose members are
separated in space and time, was mentioned as critical to
collaborative modeling. Specifically, incremental data
acquisition from the best and brightest domain experts is

Proceedings of the Ninth International Conference on Information Visualisation (IV’05)
1550-6037/05 $20.00 © 2005 IEEE

necessary for producing valid and reliable models, and at
reduced costs in time and other resources. Schemer
provides the desired support by delivering to panelists
knowledge validity and reliability statistics along with
KMaps, visual snapshots showing intrapanel differences
in knowledge domain competency. Not only is a KMap
useful for motivating collaboration, it also binds with
collaboration tools in a panelist’s IT environment to
facilitate information sharing and peer review.
Analysis of KMaps computed over the lifecycle of a
panel can also provide a means for monitoring consensus
formation and knowledge-building, and the contribution
of collaboration to this process. Since incremental data
acquisition entails analysis of incomplete data, data
imputation is typically required for consensus analysis of
panel response data. It was shown that KMaps can prove
valuable when assessing the impact of data imputation
on the stability and reliability of models derived from
consensus analysis, and can suggest when enough data
have been acquired from panelists.
Here again,
visualization of consensus models computed, in part,
from imputed data can contribute to improving the
validity and reliability of models at reduced costs. While
the results reported in this paper were obtained for
simulated data, assuming model panels with different
response distributions, we have plans to evaluate
Schemer using real domain experts in a government
testbed later this year.

Acknowledgements
This material is based upon work supported by the
Space and Naval Warfare Systems Center, San Diego
under Contract N66001-03-C-8005. We would like to
acknowledge Julie Rosen and members of her SIAM
INET modeling team at Science Applications
International Corporation (SAIC) for the sample data
used for this paper.

[3]

[4]

[5]
[6]

[7]
[8]

[9]

[10]

[11]

[12]

[13]

References
[1]

[2]

Maria Halkidi, Yannis Batistakis, and Michalis
Vazirgiannis, “On Clustering Validation Techniques”,
Journal of Intelligent Information Systems, 17, 2001, pp.
107-145.
Clifford Behrens, and Vipul Kashyap, “The ‘Emergent’
Semantic Web: A Consensus Approach to Deriving
Semantic Knowledge on the Web”, in V. Kashyap and L.
Shklar (eds.), Real World Semantic Web Applications.
Frontiers in Artificial Intelligence Applications, 2, IAO
Press, Amsterdam, 2002, pp. 69-90.

[14]

Proceedings of the Ninth International Conference on Information Visualisation (IV’05)
1550-6037/05 $20.00 © 2005 IEEE

Clifford Behrens, and Hyong-Sop Shim, “Web Services
for Knowledge-based Collaborative Modeling”, Paper
presented in session entitled, IT for Counterterrorism,
2004 IEEE Aerospace Conference, Big Sky, MT, March
9-14, 2004.
Clifford Behrens, Hyong-Sop Shim, and Devasis Bassu,
“Schemer:
New
Knowledge
Validation
and
Collaboration Services for Virtual Teams of Intelligence
Experts”, to appear in R. Popp and J. Yen (eds.), 21st
Century Enabling Technologies and Policies for
Counter-Terrorism, IEEE Press, Piscataway, NJ, 2005,
chapter 4.2.
J. Gower.
“Generalized Procrustes Analysis”,
Psychometrika, 40, 1, 1975, pp. 33-51.
T. Hastie, R. Tibshirani, G. Sherlock, M. Eisen, P.
Brown, and D. Botstein, Imputing Missing Data for Gene
Expression Arrays, Stanford University Statistics
Department Technical report, 1999.
K. V. Mardia, J. T. Kent, and J.M. Bibby, Multivariate
Analysis, New York, Academic Press, 1979.
P. R. Peres-Neto, and D. A. Jackson, “How Well Do
Multivariate Data Sets Match? The Advantages of a
Procrustean Superimposition Approach over the Mantel
Test”, Oecologia, 129, 2001, pp. 169-178.
The R Development Core Team, The R Environment for
Statistical Computing and Graphics: Reference Index
Version 1.7.0, R Development Core Team, April 16,
2003.
A. K. Romney, S. C. Weller, and W. H. Batchelder,
“Culture as Consensus: A Theory of Culture and
Informant Accuracy”, American Anthropologist, 88,
1986, pp. 313-338.
A. K. Romney, William H. Batchelder, and Susan C.
Weller, “Recent Applications of Cultural Consensus
Theory”, American Behavioral Scientist, 2, 1987, pp.
163-177.
Susan Schiffman, M. Lance Reynolds, and Forrest
Young, Introduction to Multidimensional Scaling:
Theory, Methods, and Applications, New York,
Academic Press, 1981.
Hyong-sop Shim, C. Behrens, and D. Bassu,
“Middleware Platform for Recruiting and Proactively
Managing Virtual Panels of Intelligence Experts”, paper
presented in a session entitled, AI Technologies for
Homeland Security, 2005 AAAI Spring Symposium
Series, Stanford University, Stanford, CA, March 21–23,
2005, R. Popp and J.Yen (organizers).
Olga Troyanskaya, Michael Cantor, Gavin Sherlock, Pat
Brown, Trevor Hastie, Robert Tibshirani, David
Botstein, and Russ B. Altman, “Missing Value
Estimation
Methods
for
DNA
Microarrays”,
Bioinformatics, 17, 2001, pp. 520-525.

