Towards Adaptive Occlusion Culling Using Camera Coherence

1

I. Mansa1, A. Amundarain1, E. Elizalde2, A.García-Alonso2, L. Matey3
CEIT, 2 Euskal Herriko Unibertsitatea, 3 CEIT and Tecnun (University of Navarra)
{imansa,aamundarain@ceit.es, alex.galonso@ehu.es, lmatey@tecnun.es}
Abstract

Occlusion culling proves to be useful for the
interactive visualization of environments that are not
densely occluded. Those which are built up by dense
geometric sets like aerospace engines composed of
thousands of components and millions of polygons. In first
place the convenience of using occlusion culling is studied
with a simple scheme. Then improvements are analyzed.
The key points to obtain frame rate speed-ups are: a
convenient occlusion query scheduling provides the
performance required; depth sorting is performed only
when camera orientation changes more than a given
threshold; coherence reduces the number of occlusion
queries posted per frame. It is possible to select the
percentage of occlusion queries that will be performed in
each frame, from non-conservative schemes up to a
conservative one. Furthermore, we propose a small
addition to the GPU occlusion queries to perform faster
renderings.

1. Introduction
Interactive visualization of large data sets makes use
of different strategies and algorithms: occlusion culling is
one of them. Large data sets may model quite different
environments, urban walkthroughs, flight simulators,
Geographic Information System (GIS) data, factories,
vehicles, etc. Other culling techniques, like frustum
culling, will not be discussed here and the results analyzed
try to be independent of their use.
This research studies the benefits that can be achieved
using occlusion culling when visualizing interactively large
engineering data sets like aircraft engines. The research has
been integrated with a VR system used for maintenance
simulation: man and tool accessibility analysis in order to
analyze assembly-disassembly sequences and times [1, 2].
In these pages the expression direct drawing means
that the image is generated without using culling
techniques. They seek to improve the display frame rate at
which images are generated.

Proceedings of the Information Visualization (IV’06)
0-7695-2602-0/06 $20.00 © 2006

IEEE

The occlusion scheme analyzed in this work is based
on experience gathered in a previous occlusion-culling
scheme [3]. Some concepts were born there. However, the
changes that have occurred in the GPUs and buses have
required a full revision of the algorithms. Before
attempting new developments in this area, it was necessary
to answer two questions: whether scenarios need to
improve the frame rate that can be achieved by direct
drawing; and, whether efforts in occlusion culling frame
rate improvements could be justified.
Size of data sets that can be interactively visualized
has increased exponentially in the last two years due to
GPU performance improvement [4]. Current GPUs allow
us direct drawing of models that could not be interactively
rendered a few years ago. Densely occluded scenarios have
enough margin to clearly benefit from occlusion culling.
However, it was not clear whether non-densely occluded
scenarios could improve frame rate using occlusion
culling.
Next section explains the characteristics of dense
geometric scenarios, which cannot achieve large frame rate
improvements, but can clearly be improved using simple
and efficient occlusion culling methods (sections 3 and 4).
The results achieved justify the effort of implementing
simple occlusion culling to improve the interactive
visualization of these scenarios.
The experiments have been carried out using a single
PC configured with one Pentium 4 at 3.2 Ghz, 2 Gb of
RAM and running under Windows XP. The frames were
rendered at a resolution of 1280x1024 on an NVIDIA
GeForce 7800 GTX 256 RAM and PCI-express bus.
The data sets that base these experiments are large
enough, but there are even larger visualization challenges.
For instance, there are models currently available, which
exceed at a great length current PC based systems, i.e.
Boeing has provided us with a model whose source files
take 18 Gb of hard disk. Another research group is using
16 Itanium processors (32 Gb local memory in 8 sharedmemory nodes) to manage a similar model [5].

2. Background and problem context
It is usual that published occlusion algorithms deal
with specific scenarios. Aila and Miettinen [6] have
implemented an occlusion system that applies different
strategies to different scenes. They assert, “No single
algorithm is expected to solve all types of applications
satisfactorily”. The following paragraphs describe the
features that characterize the environments that are the
objective of this research.
Models of aerospace engines used within haptic
systems [7], require millions of polygons to provide
smooth enough descriptions -it also happens with similar
engineering models-. This is required to feel a realistic
force feedback.

achieved when this type of objects are split into a few
independent elements.
Experiments show a low percentage of occluded
objects in these scenarios, about a 50%, which means they
are NOT densely occluded scenarios. This percentage is
significantly lower than those reported by authors that deal
with other scenarios [8, 9, 10], which are densely occluded.
It is a fact that occlusion culling cannot achieve in
mechanical scenarios drastic frame rate improvements as it
does in densely occluded scenarios. However, it should not
lead to disregard the benefits that are achieved. This fact
compels us to briefly analyze the visualization process of
one frame using occlusion.
Before entering sections 3 and 4, the visualization
process can be summarized in the following way:
evaluating whether an object is occluded and, if it is not,
passing it to the rendering process. Occlusion techniques
try to save time when rendering one frame by reducing the
number of objects that must be rendered [11].
So, they trade between two goals. On first place,
reducing the number of objects that must be displayed, that
is, saving time in the display process. And, on the other
hand, consuming time for evaluating if an object is
occluded. As our scenarios reach only about a 50% of
occluded objects, then the time available for occlusion tests
is very short, compared with densely occluded scenarios.
This makes necessary to use simple and fast algorithms to
trade between finding as many as possible occluded objects
and spending as few time as possible looking for them.

3. Occlusion culling: basic scheme

Figure 1 Engineering models with dense
geometric sets: “turbine 2” and engine
Some engineering models are dense geometric sets:
geometric models build up by a large amount of polygons up to millions-, contained into a relative “small” volume
(see Figure 1). This is often the case of mechanical
assemblies.
All the objects are near to the point of view. So, the
traditional use of levels of detail (LODs) might seem not to
be an alternative.
These scenes usually have shell objects: rings,
cylinders, frames, bodies, etc., in general, objects that
“envelop” many other objects. They are often the best
occluders, but their good occluding behavior is hindered by
the fact the object itself is also "half" occluded.
Amundarain [3] has studied the benefits that can be

Proceedings of the Information Visualization (IV’06)
0-7695-2602-0/06 $20.00 © 2006

IEEE

Following the guidelines commented in the previous
sections, the implementation is based on a very simple
scheme adapted to current GPUs and CPU-GPU
communication buses. The simplicity of the approach
permits an easy implementation. This section describes and
discusses specific aspects of the basic scheme; the
following section considers specific techniques that
improve its performance. All the same, this basic scheme
in itself improves rendering frame rates and is the base for
further achievements. The basic occlusion culling
rendering process for each frame is the following one:
1. Draw objects that are probably visible,
2. Send queries to GPU requesting occlusion data for
objects that are probably occluded,
3. Collect the result for all those queries,
4. Draw objects that are not occluded.
There is a trade off between time spent in the
discrimination of probable visible objects in the first step
and the effectiveness of this process: ideally all the visible

70

Frame rate (fps)

60
50
40
30
20

OccQuery simplified objs.

10

OccQuery AABB

0
0

2

4

6

8

10

12

14

16

18

20 Frame
22

Figure 2 AABB and simplified models
The time spent by the third step is nearly negligible
due to the efficient scheduling used in this scheme. When
all the queries have been placed, all of them are gathered in
a unique third step. This scheduling is much better that
placing each individual query and retrieving it individually.
Computation savings achieved in the last step generate
the benefits of the whole process.
Figure 3 shows frame rate improvements using this
basic scheme. It shows that basic occlusion culling

Proceedings of the Information Visualization (IV’06)
0-7695-2602-0/06 $20.00 © 2006

IEEE

provides benefits and it also shows that there is a need for
further improvements. Next section deals with them.
18
16
14

Frame rate (fps)

objects should be drawn in this step and all the remaining
objects should be identified as occluded in the last one.
This is the first critical point: to achieve the best balance
between computing cost of the discrimination analysis in
the first step and the global performance.
Schemes developed for older GPUs had to put effort in
selecting optimal occluders [12]. On the contrary, in this
architecture a key point is the efficient discrimination of
objects as probably occluded. Objects that are classified as
probably occluded, and are not, penalize the global
performance. Objects that are occluded, and have not been
considered for possible occlusion, do not penalize
performance -compared with direct drawing-, but a chance
of improving display frame rate is lost. Following these
considerations, the new scheme modifies an older
discrimination method [13].
When the first step is completed, the data generated in
the z-buffer of the GPU are used for the occlusion queries
that will be posted in the following step. In this way, CPU
resources are not expended in overlapping tests as it is
done in Zhang method [14]. GPU-CPU traffic is also
reduced compared with occlusion methods used in older
systems.
The second step requires querying the GPU whether
each remaining object -probably occluded- is really
occluded. This is performed by the GPU using the z-buffer
data written in the first step. One problem is which
representation of the probably occluded object is used for
the occlusion test. We have tested bounding boxes (AABB)
and simplified models (see Figure 2). The results show the
benefits of using simplified models in mechanical scenes.

12
10
8
6

basic scheme
direct drawing

4
2
0
0

100

200

300

400

500

600

700 Frame
800

Figure 3 Frame rate improvements using basic
occlusion culling (turbine 2 model)

4. Exploiting frame to frame coherence
The basic scheme can be improved in different ways.
Coherence properties provide a convenient choice for this
purpose. This section shows a new scheme that integrates
two techniques based on frame-to-frame coherence. Our
algorithm has considered the following previous works.
Results are analyzed in the following sections.
Güdükbay et al. [15] use a discrete frame-to-frame
paradigm they call “camera deviation” (CD): the occlusion
state of the objects is analyzed only when eye position or
orientation has changed more than a threshold value. They
apply this criterion to view frustum culling, and this
section studies how camera deviation can improve
occlusion-culling results in the scenarios considered in this
research.
Due to the frame-to-frame coherence, the visibility
information is similar in continuous frames. This feature
allows an effective scheduling of the occlusion queries,
where some queries can be launched in one frame and
requested in the following one. This technique provides an
efficient synchronization between GPU and CPU. Sekulic
[16] and Bittner et al. [17] used similar techniques for other
scenarios.
The occlusion scheme analyzed here assumes that
before drawing a new frame there is information inherited
from the previous frame: two lists of objects. One list
includes all the objects that were considered as visible or
partially visible when drawing the previous frame and a
second list of objects that were considered as occluded.
The list of visible objects is a sorted list. Its elements are
sorted by a simple depth priority criterion. Depth is
measured between the viewpoint and the object AABB
nearest corner. The purpose of using a sorted list is to
improve occlusion queries effectiveness.
When a new frame is generated, the following steps
are followed (see Figure 4).

Figure 4 Pseudocode for Occlusion Fraction
algorithm (OCF x%)
The first step is to recover from the GPU the occlusion
queries placed in the previous frame. As following
paragraphs show, this process is similar to that used by
Bittner et al., but differs in the policy designed for the
request and post of the queries.
Using the results of those queries the lists of objects
are updated, placing the new visible objects at the end of
the sorted list. The list of visible objects is sorted only
when the following criterion is met: if the camera’s
position or orientation exceed a threshold, then the list is
sorted again (camera deviation). This criterion is similar to
that used by Güdükbay et al. for view frustum culling. In
their case the threshold was conditioned by image quality
because large camera changes without culling
computations is non-conservative. Here the threshold does
not affect image quality, but algorithm performance.
Larger thresholds mean that the list is sorted in a fewer
number of frames, which saves computing time; but on the
other hand occlusion efficiency decreases when the objects
in the visible list are not well depth sorted. So, a
convenient threshold must be used. Using a threshold of
0.070 rad has proven a good balance.
In a second step, all the objects that are assumed as
visible are drawn and, at the same time an occlusion query
for each of them is posted to the GPU. The result of these
queries will be retrieved when drawing the next frame, as it
has been already explained in the first step of the scheme.
Then, third step, a fraction of the objects assumed as
occluded are rendered using a simplified model (instead of
AABBs) and, at the same time, an occlusion query is
posted: Occlusion culling fraction (OCF). Some of these
objects result being visible. In these cases, the simplified
image generated for the query produces another benefit: it
reduces the possible visual artifacts in the image.
Adjusting the fraction of objects in the occluded list,
which are checked for occlusion in each frame, permits to
trade between frame rate improvements and possible small
visual artifacts. These flaws are due to objects that become
visible and whose occlusion status is not checked for a
number of frames. This number of frames is the function of

Proceedings of the Information Visualization (IV’06)
0-7695-2602-0/06 $20.00 © 2006

IEEE

the fraction of occluded objects tested in each frame: set to
50% means one possible frame fault, 25% 3, etc. It is also
possible to set the fraction to 100% (query all occluded
objects in each frame) and then we have a pseudoconservative method, which is more similar to those
described by Sekulic [16] and Bittner et al. [17]. We say
that it is “pseudo” because we use a 100% of occlusion
information, but it was computed in the previous frame
position of the camera.
The scheme integrates the camera deviation (CD) and
the Occlusion culling fraction frame-to-frame coherence
techniques. We will refer to it as the OCF scheme,
although some times we will refer to it as the OCF 25%
meaning that the fraction of occluded assumed elements
that are analyzed is a 25%.

5. Analysis of CD and OCF
Data in Figure 5 adds two experiments to Figure 2.
Figures in this section are also based in model turbine 2.
The first experiment adds “camera deviation” (CD) to
our basic scheme. Improvements were not impressive and
threshold changes appear clearly in the figure as “small
frame rate drops” in those frames where visibility analysis
is performed. The second experiment presents results
obtained with the OCF 100% scheme. This case is pseudoconservative; all the objects in the occluded list are tested
for occlusion. CD erratic behavior disappears because
sorting in the OCF scheme is based on a nearly sorted list.
Frame rate improvements are notable, but there are
situations where the frame rate falls notably bellow the
mean frame rate. These situations mark the limitations of
this approach, because a uniform frame rate is desired.
The next experiment analyzes the use of different
occlusion culling fractions (see Figure 6). It analyzes a
pseudo-conservative approach and more aggressive
choices. Using non-conservative fractions improves frame
rate, but as we suspected, it does not improve the critical
situations, because they are due to camera positions that
are less “densely occluded”.
30
25

Frame rate (fps)

1.a Recover from GPU the visibility queries placed in
the previous frame
1.b Update visibility lists (visible & occluded objects)
1.c If (camera movement > Threshold)
Then sort the list of visible objects
2. Draw list of visible object placing a query (query
result is not recovered here)
3. Render only an x% and a simplified model of the
objects contained in the list of occluded placing a
visibility query

20
15
OCF 100%
camera deviation
basic scheme
direct drawing

10
5
0
0

100

200

300

400

500

600

700

Frame
800

Figure 5 Frame rate with f2f coherence

20
15

OCF 10%
OCF 12.5%
OCF 25%
OCF 50%
OCF 100%

10
5
0
0

100

200

300

400

500

600

700

Frame
800

Figure 6 Frame rate using OCF fractions
We also studied the loss of quality of the images
generated with the different fractions and they were
negligible. A parameter measures quality: the number of
pixels that differ from the image generated with a given
OCF fraction and the direct drawing one. We measure
error as the % of wrong pixels generated. It ranges from a
0.0015% (OCF 50%) to a 0.0028% (OCF 10%). Although
these values seem negligible, we have made a moderate
selection a 50% fraction for the experiments.
Figure 7 presents results for three different turbines
built up by 1.6, 2.9 and 3.5 M polygons respectively (see
turbine 2 in Figure 1). All of them show similar critical
situations. As pseudo-conservative or even nonconservative occlusion culling cannot provide a uniform
frame rate in certain situations. A more general approach
to solve the problem presented by these situations must be
considered.
Changes in visualization conditions while moving the
camera -like reducing the number of light sources, or
reflections, etc.- are not an acceptable solution. Image
changes would be more noticeable than the artifacts
generated by non-conservative OCF. Some systems do not
draw objects whose projection is lower than a number of
pixels; other incorporate semantic knowledge and mark
which objects are more relevant, then they do not draw less
relevant objects; similar approaches substitute object
models by simpler representations or even icons, etc. Of
course this is done while image is changing, when camera
or visualization parameters do not change, a complete
image is generated. Nevertheless, simulations are much
more “dynamic” than other design tools and most of the
visual information comes from that continuous eye
movement.
The algorithms that use level of detail make use of the
following concept: the graphical relative relevance of an
object within a frame. This relevance is measured by the
number of pixels cast on the screen by the projection of the
object. This knowledge is often used to save time when
rendering objects that are small or far away. Occlusion
queries get from the GPU the number of visible pixels

Proceedings of the Information Visualization (IV’06)
0-7695-2602-0/06 $20.00 © 2006

IEEE

70
OCF 50%
OCF 100%
basic scheme
direct drawing

60

Frame rate (fps)

25

50
40
30
20
10
0
0

100

200

300

400

500

600

700

Frame
800

35
30

Frame rate (fps)

Frame rate (fps)

30

drawn when rendering an object. This is an upper bound;
some pixels can be later on covered by other objects.
In compact scenarios objects are not far away but there
is also a graphical relevance hierarchy. That is, objects that
are partially occluded usually have less interest to the
viewer: there are objects that cover a significant number of
pixels in the screen, but their graphical importance is really
low because they are covered by many other objects. In
these cases the number of covered pixels does not provide
enough information. So, a new magnitude is needed to
assess the graphical relative importance: the quotient
between the number of visible pixels and the number of
pixels cast on the screen by the projection of the object. It
should be desirable that a unique query to the GPU could
provide these two parameters.

25
20
15
OCF 50%
OCF 100%
basic scheme
direct drawing

10
5
0
0

100

200

300

400

500

600

700

Frame
800

30
OCF 50%
OCF 100%
basic scheme
direct drawing

25

Frame rate (fps)

35

20
15
10
5
0
0

100

200

300

400

500

600

700

Frame
800

Figure 7 Frame rate using turbines 1, 2 & 3

Therefore, when occlusion culling cannot provide the
required frame rate, the information gathered with
occlusion queries can be used as the parameter that
determines which objects have less image significance.
Then drawing time can be saved not only with occluded
objects but also with those that have less image
significance. This requires more experiments to extend the
knowledge here presented in order to improve “lower
frame rate gaps”. This will lead to an adaptive occlusion
culling based scheme that should present as few as possible
image artifacts.

[3]

[4]
[5]

[6]

Improvements in query computation efficiency does
not improve much the global frame rate (see Figure 3) but
additional improvements could be analyzed: object
clustering [17], or using BSP [18] [19] instead of depth
sorting, although the need to split objects could be a
problem.

[7]

Conclusions

[9]

The experiments presented show the interest of
occlusion culling for the interactive visualization of large
data sets in compact environments that are not densely
occluded.
Some
simple
techniques
permit
significant
improvements in the frame rate. The scheme is based on
two frame-to-frame coherence techniques: camera
deviation threshold and occlusion culling fraction.
The paper also shows the advantages of using
simplified models of the objects instead of their AABBs
for the occlusion queries.
However, there are situations that require more
aggressive use of the information that is gathered from the
occlusion queries if a uniform frame rate is required.

Acknowledgements
The research work presented in this paper is supported
by the European Commission, under the FP6 IST-2002002114 Enactive NoE (http://www.enactivenetwork.org).
Dr. Garcia-Alonso research was partially supported by the
Spanish Ministry of Educationl and Science MEC and the
Gipuzkoako Foru Aldundia with FEDER.

[8]

[10]

[11]

[12]

[13]

[14]

[15]

[16]
[17]

References
[1]

[2]

Borro D., Hernantes J., Mansa I., Amundarain A., GarcíaAlonso A., Matey L., Virtual maintainability for dense
environments,
7th
Virtual
Reality
International
Conference, Laval (France), pp 141-148, 2005.
Borro D., Garcia-Alonso A., Matey L., Approximation of
optimal voxel size for collision detection in maintaina-

Proceedings of the Information Visualization (IV’06)
0-7695-2602-0/06 $20.00 © 2006

IEEE

[18]

[19]

bility simulations within massive virtual environments,
Computer Graphics Forum 23(1), 13-23, 2004.
Amundarain A.: Análisis de visibilidad y algoritmos de
oclusión en maquetas digitales masivas y compactas, Ph.
D. dissertation, University of Navarra, 2004.
Geer D., Taking the Graphics Processor beyond Graphics,
Computer 38(9), 14-16, 2005.
Dietrich A., Wald I., Slusallek P., Large-Scale CAD Model
Visualization on a Scalable Shared-Memory Architecture,
10th International Fall Workshop - Vision, Modeling, and
Visualization VMV05, 303-310, 2005.
Aila T., Miettinen V., dPVS: An occlusion culling system
for massive dynamic environments. IEEE Computer
Graphics & Applications, 24(2), 86-97, 2004.
Borro D., Savall J., Amundarain A., Gil J.J., García-Alonso
A., Matey L. A Large Haptic Device for Aircraft Engines
Maintainability.
IEEE
Computer
Graphics
and
Applications. 24(6), 70-74, 2004.
Wonka P., Wimmer M., Schmalstieg D., Visibility
preprocessing with occluder fusion for urban walkthroughs. Proceedings of the 11th Eurographics Workshop
on Rendering, 71-82, 2000.
Cohen-Or D., Fibich G., Halperin D., Zadicario E.,
Conservative Visibility and Strong Occlusion for
Viewspace Partitioning of Densely Occluded Scenes.
Computer Graphics Forum, 17(3), 243-253, 1998.
Govindaraju N., K., Sud A., Yoon S., Manocha D., Parallel
occlusion culling for interactive walkthroughs using
multiple GPUs. IEEE Visualization Workshop on
Commodity-Based Visualiza-tion Clusters, 2002.
Klosowski, J. T., Silva C. The Prioritized Layered
Projection Algorithm for Visible Set Estimation. IEEE
Transactions on Visualization and Computer Graphics,
6(2), 108-123, 2000.
Amundarain A, Borro D, García-Alonso A, Gil JJ, Matey
L., Savall J., Virtual reality for aircraft engines maintainability, Mécanique & Industries, 5(2), 121-127, 2004.
Mansa I., Amundarain A., Hernantes J., García-Alonso A.,
Borro D., Occlusion culling for dense geometric scenarios,
8th Virtual Reality International Conference, Laval
(France), in press, 2006.
Zhang H., Manocha D., Hudson T., Hoff III K.E.: Visibility
culling using hierarchical occlusion maps. Computer
Graphics (SIGGRAPH '97), 77-88, 1997.
Güdükbay, U., Yilmaz T., Stereoscopic View-Dependent
Visualization of Terrain Height Fields. IEEE Transactions
on Visualization and Computer Graphics, 8(4), 330-345,
2002.
Sekulic D., Efficient Occlusion Culling, GPU Gems, R.
Fernando, Ed. Addison-Wesley, Chapter 29, 2004.
Bittner J., Wimmer M., Piringer H., Purgathofer W.
Coherent Hierarchical Culling: Hardware Occlusion
Queries Made Useful, Computer Graphics Forum 23(3)
615-624, 2004.
Fuchs H., Kedem Z.M., Naylor B.F., On Visible Surface
Generation by a Priori Tree Structures, Proc. SIGGRAPH,
Computer Graphics, 14(3), 124-133, 1980.
Morer P., García-Alonso A., Flaquer J., Optimization of a
Priority List Algorithm for 3-D Rendering of Buildings,
Computer Graphics Forum, 14(4), 217-227, 1995.

