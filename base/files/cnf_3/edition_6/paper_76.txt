A Tangible Interface for Hands-on Learning
Satoshi Yonemoto1
Takahiro Yotsumoto1
Rin-ichiro Taniguchi2
1
Kyushu Sangyo University, Japan 2Kyushu University, Japan
yonemoto@is.kyusan-u.ac.jp
rin@limu.is.kyushu-u.ac.jp
Abstract
In this paper, we describe a tangible interface for
Hands-on Learning using physical-tangible objects
( pattern blocks). A computer recognizes the states of the
user-handled objects in real time and it gives the users
advice to execute learning tasks if necessary. In our
approach, a pattern block is employed as a primitive
piece. It helps the users to do direct manipulation in real
environments, while displayed events in virtual
environments help them to support the learning tasks.
Concretely, we have developed the interaction system
can support Hands-on Math activities.
Keywords--- Augmented reality, computer vision.

1. Introduction
Many tangible interface technologies and its
applications are emerging to realize smart interaction
with real/virtual environments [3][4][5]. Tangible
interfaces are intuitive, so it is easy to use and to master
them. This paper describes a tangible interface for
Hands-on Learning. The approach of tangible interface
will make a user easy to learn in educational experience.
As one of Hands-on Learning, hands-on math activities
are often introduced in primary education so as to
explore mathematical concepts in the concrete world.
In several tangible interfaces, special input/output
devices (i.e., hardware) are developed, and they are
accordingly not extensible. Their approaches also have
serious problems such as wireless setup and sustainable
power supply. Therefore, we realize perception-based
tangible interfaces by using computer vision technology.
Although this approach is also realized by many HCI
communities or in many AR groups [1][2], the user's
action recognition techniques such as gesture recognition
and hand position tracking is mainly focused on. Also, in
vision based approach, physical objects attach markers
are often used. We also employ physical objects to be
easily detected in marker based approach.

2. Hands on Learning by physical objects
In this work, we describe a tangible interface for
Hands-on Learning using physical-tangible objects. A

Proceedings of the Information Visualization (IV’06)
0-7695-2602-0/06 $20.00 © 2006

IEEE

computer recognizes the states of the user-handled
objects in real time and it gives the users advice to
execute learning tasks if necessary. Examples of such
events are displayed as visual and audio effects.
Therefore, the users can interact with both physical
objects and virtual ones. As such physical objects, we
employ ’pattern blocks’.

2.1. Using pattern blocks
Pattern blocks are often used as a hands-on learning
tool. For example, they help children learn math in a
multitude of ways; A teacher imposes a target pattern as
a fitting task and the children sketches an object that has
this shape in it. Also, the children can explore
mathematical concepts in the concrete world.
We use a pattern block as a primitive piece. A set of
connected pieces makes a pattern.
Figure 1 shows pattern blocks. Six pieces are
available in our approach because most shape patterns
can be made from these types of pieces. The piece is flatshape and is painted single color. It is easy to identify
what kind of pieces might be used because every piece
has the different color.

2.2. Workspace description
In our approach, the user actions can be grasped in
limited space. We call it workspace. The workspace
consists of menu area, sensing area and detection area.
Figure 2 shows the workspace description.
In the menu area, menu icons about the selectable
target patterns are displayed. The sensing area indicates
piece detection area, in which visual events are
dynamically displayed according to the proceeding tasks.
In the detection area, start/end timing of the user actions
is detected.

2.3. Vision-based sensing
We use piece detection by computer vision
technology. This is extensible approach, so even physical
objects used in daily life are available as tangible objects.
2.3.1. Piece detection To detect every piece on the
sensing area, color region detection algorithm is used.
The algorithm is low level processing, so the structure of

the connected pieces is recognized by using a priori
knowledge in each task. New pieces can be detected just
in the user actions are not active because occlusion
problem can be occurred in vision based sensing.

(Sony DFW-V500) mounted downward and a display
table (17 inch monitor) to maintain the workspace.

3.1 Hands-on Math activities
2.3.2. Start/end timing detection The user action
timing is detected by observing the intensity change of
detection area.

Concretely, the following tasks are implemented:
• Pattern fitting tasks
• Symmetry pattern generation tasks
• Area comparison tasks

2.4. Pattern recognition
After the piece detection process, the structure of the
connected pieces, i.e., pattern is recognized. The pattern
information in each task is registered in advance. A
target pattern is often imposed as a silhouette pattern, so
many combinations of pieces must be considered. Figure
3 shows the examples of the silhouette patterns. Figure 4
shows the fitting examples of each silhouette pattern in
Figure 3.

Figure 1 pattern blocks.

menu area

sensing area

detection area
Figure 2 Workspace description.

In pattern fitting tasks, a target pattern is imposed as
a silhouette pattern on the display table. Many
combinations of pieces can be generated for one
silhouette pattern. When a new piece is put on the
display table, the next choices of pieces that connect it
can be displayed with blink. Figure 6 shows the next
choices in putting a new piece.
In symmetry pattern generation tasks, the half shape
of the target pattern is displayed on the table. Rotate
animation around the symmetry axis are displayed as a
clue. Figure 7 shows a snapshot of symmetry pattern
generation.
Area calculation is typical problem for mathematics.
First, two target patterns are displayed on the table. By a
fitting task, the user puts pieces so that one of the
patterns can be filled with. The other pattern is also filled
with at the same time. When the fitting task has been
completed, the difference pieces between two patterns
indicate the result of area calculation.
In this implementation, we have set up virtual
environment which floats on the water. Concretely, the
following tasks are implemented:
• Making ripples in putting a piece
• Sound in putting a piece
• School of fish animation
Display effects are overlaid on the display table.
Figure 8 shows a snapshot of the effects by making
ripples. Also, ending events can be displayed when the
task has been completed. For example, in fitting tasks,
augmented animations are overlaid on the display table,
so the user can understand what the pattern imply. Figure
9 shows two examples of the ending events (flower and
human).

3. Implementation
We have implemented a tangible interface for
Hands-on Math using pattern blocks. Hands-on Math
activities allow the children to explore mathematical
concepts in the concrete world. A computer (i.e., teacher)
imposes learning tasks to explore mathematical concepts.
Following the teacher's instructions, the user (i.e., the
children) manipulates pattern blocks.
Figure 5 shows the system setup. The minimum
system setup consists of two parts: a IEEE1394 camera

Proceedings of the Information Visualization (IV’06)
0-7695-2602-0/06 $20.00 © 2006

IEEE

Figure 3 Silhouette patterns.

Figure 4 Fitting examples.

Figure 8 Display effects: making ripples.

Figure 9 Ending events: (left) flower. (right)
human.

Figure 5 System setup.

Figure 6 Next choices are displayed.

3.2 Handling virtual objects
Since the merit of hands-on learning by augmented
reality technology is to make possible smooth interaction
with real/virtual environments, we have also
implemented the additional functions to handle virtual
objects. The following setup is executed in advance:
registration of new pattern and real cursor setup.
The user can build a new pattern using pattern
blocks. The pattern is registered as a new virtual object.
Figure 10 shows a snapshot in making a new pattern (a
butterfly).
Virtual objects can be controlled by moving real
objects (i.e., pattern blocks) on the display table. A real
cursor which consists of two connected blocks is
employed to handle virtual objects. By moving the cursor,
the user can freely rotate and translate virtual objects.
Figure 11 shows a snapshot in handling the butterfly.

Figure 7 Symmetry pattern generation: (left) half
shape. (right) the completed pattern.

Figure 10 Making of a new pattern.

Proceedings of the Information Visualization (IV’06)
0-7695-2602-0/06 $20.00 © 2006

IEEE

real cursor

target

Figure 11 Handling virtual objects.

4. Conclusions
We have demonstrated a tangible interface for
Hands-on Math activities using pattern blocks. Our
interface can give the children advice to explore
mathematical concepts. Concretely, the following tasks
are implemented: Pattern fitting tasks, symmetry pattern
generation tasks and area comparison tasks. We have
realized a perception-based tangible interface by using
computer vision technology.
We plan to extend the implementation into multiusers interaction system that is equipped with large scale
table and with multiple cameras.

References
[1]
[2]

[3]

[4]
[5]

P.Wellner, Interacting with Paper on the DigitalDesk,
Communications of the ACM, pp.86-107, 1993.
Koike, et.al., Integrating paper and digital information on
Enhanced Desk: a method for real-time finger tracking
on an augmented desk system, ACM Trans. on CHI,
Vol.8, No.4, pp.307-322, 2002.
Ishii H. and Ullmer B., Tangible Bits: Towards Seamless
Interfaces between People, Bits and Atoms, Proceeding
CHI 97, pp.234-241, March 1997.
Ullmer B. and Ishii H., MediaBlocks: Tangible interfaces
for online media, Proceeding os CHI 99, pp.31-32, 1999.
H. Suzuki and H. Kato. AlgoBlock: A tangible
programming language - a tool for collaborative learning.
Proceeding the 4th European Logo Conference, pp.297303, 1993.

Proceedings of the Information Visualization (IV’06)
0-7695-2602-0/06 $20.00 © 2006

IEEE

