The visualisation of building data in VR-DIS.
M.K.D. Coomans and H.J.P. Timmermans
Eindhoven University of Technology, Faculty of Architecture, Building and Planning
PO BOX 513,Mail station 20, 5600MB Eindhoven, The Netherlands
Abstract
The VR-DIS system is a design application for the
Building and Construction industry (VR-DIS stands for
Virtual Reality - Design Information System). The user
interface is characterised by a mixed representation of the
task domain. A pictorial representation of the appearance
of the building is combined with a visualisation of the
formal description of the design. The latter visualisation
is worked out as a highly interactive 3D graph in which
relation types are mapped on distinct planar directions
and the browsing history is visualised in the third
dimension. We discuss the theoretical foundations of the
interface as a whole and those of the developed 3D graph.

1

Introduction

Design tasks, in particular architectural design tasks,
have been found hard to support by means of computers.
We point out two reasons. One reason is that design
decisions are stored in subsequent graphic representations.
Graphic representations are a generally acknowledged
medium through which the architect develops the design
[1]. Design representations are instrumental to both visual
reasoning (idea generation) and evaluation. In the
conceptualisation phase of the design process designers
typically use sketches. Sketches are quick and easy, and
support visual reasoning [2]. The current graphical
computer systems lack this “perceptual interactivity” of
the sketch. To support design evaluation, many aspects of
the design (appearance, costs, physical behaviour, etc.)
can currently be simulated in dedicated computer
applications. Unfortunately, this split-up into unrelated
applications results in different, unrelated data
presentations and faulty mutual feed-back functionality.
A second reason is that the design objects provided by
conventional CAD systems do not reflect the designer’s
thinking. The designer’s elements are task specific and
differ between individuals. Moreover, during a particular
design process, these elements of design are not static but
are invariably subject to change [3]. Design is a problem

solving process that requires the computer to handle the
information in a dynamic way.
VR-DIS is a research project in which possible
solutions for these problems are investigated. VR-DIS
stands for Virtual Reality - Design Information System.
Key characteristics are information modelling using
features, and Virtual Reality (VR) user interfaces. Feature
based information handling is expected to provide a
bridge between the user’s dynamic design concepts, and
the information storage capabilities of the computer. The
medium of Virtual Reality is expected to constitute the
medium through which successful multi-aspect
visualisations can be offered, and with which an intuitive
and quick interaction method can be developed.
This paper discusses the theoretical grounds of the
developed visualisations. We discuss in detail the notion
of mixed representation interfaces, and the 3D graph
drawing that has been developed for browsing the feature
data model.

2

Virtual Reality user interface

The VR-DIS user interface has a direct manipulation style
because of the general performance advantage of such
interfaces in design applications [4]. With VR technology,
the direct manipulation style can better be worked out than
with conventional GUI technology. VR establishes a
virtual environment that appears ‘natural’ to the user. He
can grab and manipulate through the natural movements
of his hand or head. As a result, the user experiences
immersion which leads to a much higher level of
engagement [5].
VR as a User Interface is expected to replace many of
the existing techniques due to the (added) possibilities [6].
In particular in the architectural environment the challenge
lies in developing a new work environment in which the
design process can take place [7].
Unlike conventional windows and mouse interfaces,
VR has yet to evolve a dominant interaction paradigm.
Currently, the design of a VR user interface requires the
design of both the data visualisation and the interaction
method. In this paper though, we focus on the
visualisation part of the VR-DIS interface.

.

.

.
.

Figure 1: Virtual visit to the Tajmahal (a) and a
planned office (b). [8]

The visualisations found in other VR applications can
roughly be divided in two categories: visualisations of
inherently spatial data , and visualisations of abstract data
using a spatial metaphor. The first form of VRvisualisations can present an architectural or mechanical
site with a high level of verisimilitude. It provides visual
access on the working place to sites that really exist, that
are disappeared, or that will exist in the future. Figure 1
shows examples of the usage of VR in that way . It is the
most common application of VR technology.
VR can also be used to communicate abstract
information. Visuals presented by these VR applications
include 3D chart and starfield representations, information
landscapes (e.g. city methaphor), and 3D graph drawings.
See figure 2.
A unique property of the VR-DIS user interface is that
it combines two visualisations of both categories in a
single interface. There combination is based on the notion
of mixed-representations.

3

Mixed representations

VR-DIS is set up to compile all disciplines that are
involved in an architectural or urban design process. As a
result, VR-DIS will handle information of many different
kinds: geometry data, lay-out data, appearance data,
stability data, hydro-thermal data, cost information, ageing

Figure 2: 3D Abstract data visualisations: (a) 3D
starfield representation [9], (b) information landscape
[10].

data, organisational data for the building process, and so
on. What kind of representation can present all these
different kinds of data? Clearly, a visualisation of the
appearance of the building is insufficient.
UI modality analysis distinguishes between two types
of interface representations: linguistic and non-linguistic
representations (e.g. [12]). In cognitive psychology, an
analogue distinction is made between verbal and pictorial
mental representations. For VR-DIS, both types of
representations seem equally relevant. Some data can best
be communicated verbally (e.g. names, labels), other data
can best be communicated in a pictorial way (e.g.
appearance characteristics).
Because the VR-DIS system deals with such a hybrid
set of data, a single representation can not visualise all
data. A combination of a verbal and pictorial
representation is required. (See also [13])
The interface representation of VR-DIS is a
combination of two views: the "feature" view and the
scale-model view. The feature view is a spatially
structured verbal representation of the data structure that
underlies the VR-DIS system. This data structure is
organised in "features", hence the name. (See also later.)
The scale-model view is a pictorial representation of
the design information, based on the physical appearance
of the designed building. This view will feature a high
level of verisimilitude.

In [4], the authors discuss four demands for a
successful integration of multiple views. The feature and
the scale-model representations of the VR-DIS system are
integrated on the basis of these four demands. The most
important aspects are the following.
1. Supplementary representations: the features display
exact numbers (e.g. "width = 5.20m" and "thermal
performance has been estimated at 67K"). The scalemodel will only visualise a selection of these numbers in
qualitative way (e.g. dimensions are presented as such;
thermal performance could be visualised by a colour in the
range from red (badly isolated) to blue (well isolated).) On
top of that, the scale-model provides a means to evaluate
the spatial experience of the designed spaces.
2. Integration in one view: while navigating through
the scale-model, the user will be able to point out an
object (i.e. a building part) and ask for the features that
described that object. The demanded features will appear
in a frame near the object. The frame with the feature
representations is itself an object that behaves similarly to
other objects of the scale-model.
3. Consistency: the consistency will be maintained
between the representations of the task data. For example,
the dimensions of an object in the scale-model will always
correspond with the numbers that can be read from the
dimension features of that object.
4. Mutually referring: the frames in which features
appear will be visually connected to the scale-model
object. The objects in the scale-model and the
corresponding features in the frames will always be
simultaneously highlighted. When a feature is touched
(pointed out) or grabbed (selected), both the feature and
the scale-model object will be highlighted, and vice versa.
Finally, when a property of either an object or a feature is
modified by manipulating a particular handle or hot-spot,
then all the handles and hot-spots of the other
representation with which the same result could be

.

Figure 3: VR-DIS interface

obtained, will also be highlighted during the execution of
the operation. Figure 3 shows the set-up of the interface.
The features are visible in the frame in the front ; the scale
model is visible in the background.
Figure 3 also shows the flying mouse with the red
virtual pen with which the user can grab, relocate, and
activate features in the feature view and building parts in
the scale model view. The whole interface is worked out
as “fish tank VR” system in which the perspective
distortion of the image on the screen is in real time
updated according to the viewer’s head position in front of
the screen. Details of the interaction and control
characteristics of the interface are described in [13].

4

Designing by features

The VR-DIS system applies an innovative information
modelling technique: Feature Based Design. This
techniques has evolved from Feature Based Modelling
that originates in the disciplines of mechanical
engineering and industrial design. Van Leeuwen [3] has
transported the design-by-Features approach to the context
of architectural design.
In this architectural form of Feature Based Design,
feature types can represent any physical or abstract
concept involved in the design process: space, function,
costs, safety, comfort, form, … . In a design project, one
feature-instance might represent a particular wall, another
might represent the building as a whole, yet another
feature might represent the principal’s demand that the
meeting room should be ''comfortable". The designers can
make instances of predefined feature-types, but they can
also define new types, reflecting the precise design
concepts they have in mind.
Features are linked together forming feature models. A
single feature model stores all information related to a
particular design project. There are two main predefined
relation types between features: composition relations, and
specification relations. All other possible relations are
termed "associations". Examples of associations are: "is
supported by" (a beam supported by a column), "is
accessible by" (the building by the road), and so on. As
with the feature types, the designer can add his own kinds
of relations if he feels that's appropriate. Features can be
linked together on both the type and the instance level.
Type level relations are used to form complex feature
types, to be stored in a feature library. Instance level
relations are used to describe the relations between the
feature instances of a design project at hand.
The cost of the great flexibility and extensibility of this
data model is that it lacks almost any structure. While
designing with the VR-DIS system, feature models grow
that are not ordered in any strict predefined way: no
hierarchy, no matrix structure, no list structure. Feature
models are just (chaotic) relational data structures,
consisting of features that are of an extensible list of types,

and mutually connected by relations which are
decompositions, specifications, or other types of relations.
On top of this, in real design projects feature models can
grow as large as (presumably) 10 to 100.000 features. It is
clear that the flexibility, the extensibility, and the scale of
the feature models constitute high demands for the
representation through which the feature models are
communicated to the user.

5

The Feature View

Relational data sets are currently typically displayed either
in table format or in 2D graphical layouts. Tables can
display lists of object-relation-object sets in a very
efficient way and are very readable at the same time. The
disadvantage of tables is that they do not very well
support the discovery of implicit data structuring.
Graphical layouts do provide a much better insight in
the structure of the data sets. Object clustering and
relation sequences can much easier by denoted. The
drawback of graphs is that they are often less efficient in
screen area usage.
The most used graphical layout format is the
“treeview” (figure 4a) which is suited for hierarchical data
sets. It’s screen efficiency is close to that of tables.
Non-hierarchical (cross linked) data sets can best be
visualised in graph layouts (figure 4b). Graph layouts are

badly supported by software developed tools. This has
resulted in the inappropriate usage of treeviews in many
applications, showing the data at hand only fragmentally.
In VR-DIS, we have chosen to visualise the feature
models as interactive 3D graphs. We discuss subsequently
the visualisation of single features and their relations, and
the interactive graph drawing technique.
A feature is visualised as shown in figure 5. Each
feature consists of a front plate and a rectangular area
behind it. The front-plate features a textual representation
of the feature’s name and type. The rectangular area
behind the front-plate represents the content of the feature.
This area is subdivided in a left and a right half.
The left half represents the content that has been
defined on the type level. In the case of a primitive
(“simple”) feature type, the content is something like a
number, or a string. Such a primitive content is
represented by a 3D icon. In the case of a complex feature
type, the content is constituted by all the components (cf.
component relations). In this case, the left half of the
content area is filled with small visualisations of all the
features that have been defined as components at the type
level.
The right half of the content area represents the content
that has been defined on the instance level. For all feature
types, this area is filled with the visualisation of the
components that have been added at the instance level.
When a feature has specification relations, those
specifications are hidden in a drawer that is connected to
the bottom of the front-plate. The drawer has a left typelevel part, and a right instance-level part. The drawer can
be opened by pulling the handle downwards. When the
drawer is opened, all features appear that specificy the
central feature (see figure 6). The specification relations

.

.

.

Figure 4: Graph layouts: (a) a treeview, (b) 2D graph.

.

Figure 5: A Simple and a
Complex Feature, in
initial state

Figure 6: A Complex
Feature, in exploded state

themselves are visualised by arrows with an overprint of
the relation’s name. The top of the front-plate features a
similar drawer that hides all associations of the feature. It
can be opened in a similar manner.
Because the front-plate hides most of the componentfeatures, those component features can be pulled to the
side of the front-plate. When pulled to the side, the
components are visualised similar to the specifications and
associations: the component-relations are visualised as
bands with an overprint of the relation’s name.
Specifications, association, and components each
appear in specific directions relative to the parent feature.
This systematic grouping eases the “reading” of features.
It also eases feature browsing because we can map users’
input gestures to these directions: pointing the 3D input
device to the right indicates that one wants to manipulate
user defined compositions, pointing to the left refers to
type defined compositions, etc.
Since we are dealing with large data-sets, only a small
subset of the information at hand is drawn at once.
Therefore, an interactive graph drawing technique is
needed such that the user can specify subsequent steps
from which part of the graph he/she wants to see more.
Eades and Graham have both [14] [15] proposed an
interactive drawing techniques for the visualisation of
very large graphs. Both produce 2D images in which
child-nodes are placed on circles around parent nodes. The
spatial distribution of the child nodes around their parent
depends on the number of the children’s children, and on
the browsing history (= which “uncle” and “nephew”
nodes that have been looked at before). This layout
mechanism makes the technique difficult to apply for
feature models. We already organised child features
around their parent on the basis of the type of their
relation. Eades’ and Graham’s layout mechanisms
suppose only one relation type. Their layout mechanisms
cannot be superimposed on our’s because the two would
interfere and result in an unreadable graph.
In VR-DIS, we have chosen to visualise the browsing
history in the third dimension. When a feature’s relations
are visualised, the feature first moves to a new transparent
plane that is laid on top. Recursive requests for more
detail results in multiple display layers. This mechanism
has been inspired by Lieberman’s multiple translucent
layering technique [16]. We have designed a specific
virtual tool through which this browsing process can take
place. We refer to this tool as the "feature box".
When starting, the feature box looks just like a real
closed box. The box represents the whole feature model of
a specific design project. The box can be opened, after
which a pyramidal area lights up. In the enlightened
pyramid, the shell of a sphere emerges concentric around
the box. The shell is orthogonally subdivided in a number
of rectangular fields. In each field, a single feature and its
directly related features can appear.

.

Figure 7: Feature Tool.

The user can formulate type and name based queries to
retrieve a first feature from the database. When this
feature has components, specifications,
and/or
associations, they can appear around the original feature,
all within a single field of the feature box’s shell. The
related features are shown smaller than the central feature.
When the designer asks such a related, small feature to
explode its relations, then it will first move to a new
empty field of its own. This new field will be located at a
shell that’s concentric around the previous shell, but with
a bigger radius. While moving to the new field, the
relations to the features on the original field stay intact:
arrows and bands are bend to S-like shapes. In this new
field, the feature can then explode its own related features.
These will again appear around their parent, unless the
relation goes to a feature that is already visible on any of
the other fields of the feature box. In that later case, the
related feature stays where it is, and is connected by a bent
arrow or band.

6

Experimental Evaluation

The described design of the feature view is based upon 5
main thesis. The first 3 relate to the feature visualisation :
1. Positioning features onto fixed locations in the 3D
graph would improve the user’s data retrieval
performance (=landmark effect). This characteristic is
exploited in so called information landscapes. We
postulate that the same effect is achieved when a
second representation is mixed with the feature view
(the scale model view) that provides fixed locations
for a minority of the data objects present in the
feature view (the geometry features only).
2. Mapping relation types onto fixed directions in the
(3D)
representation
would
improve
their
distinguishability, and thus the user’s data retrieval
performance. We postulate that a similar performance
advantage is achieved when only the end sections of
the relations have fixed directions and the rest is
allowed to bend into S-like shapes.
3. We postulate that animating events like features
appearing, hiding, being deleted, … will improve the

learnability, decrease the error rate, and improve the
user's subjective satisfaction.
The following 2 relate to the control of the interaction
with the feature set:
4. We postulate that a more efficient set of user
commands for manipulating 3D graphs can be
developed for a flying 3D mouse then for a
conventional 2D mouse.
5. We postulate that using a “Fish tank VR” set up
(coupling
head motion with the perspective
distortion) decreases the user’s error rate when
working with the designed feature tool.
Most of the theoretical grounds for these theses were
visualisation were described in previous sections. There
validity is currently experimentally being verified. The
experiment involves about 50 test persons. The conducted
experiment has a fractional factorial design, allowing the
measurement of the main effects of the 5 postulates, as
well as their interaction effect with the size of the database
at hand (a 6th factor).

7

Conclusion

[3] J.P. van Leeuwen and H. Wagter, "Architectural Design-byFeatures", in CAAD futures 1997. Proceedings of the 7th
International Conference on Computer Aided Architectural
Design Futures, Munich, 4-6 August 1997, Junge, Richard (ed.),
Kluwer Academic Publishers, Dordrecht, p. 97-115
[4] M.K.D. Coomans and H.H. Achten (1998) Mixed Task
Domain Representation in VR-DIS. Proceedings of the 3rd AsiaPacific Conference on Human Computer Interaction, APCHI’98,
Shonan village Center, Japan, July 15-17, 1998.
[5] Smets, G.J.F. (1992) Designing for telepresence: the
interdependence of movement and visual perception
implemented, in IFAC Man-Machine Systems, the Hague, The
Netherlands, 1992, pp. 169-175
[6] W. Bauer, H.J. Bullinger, and A. Rössler, “Virtual Reality –
the Ultimative Interface?”, in Symbiosis of Human and Artifact,
Y. Anzai, K. Ogawa, and H. Mori (eds.), Elsevier Science B.V.,
1995, P.587-596
[7] B. de Vries, "VR-DIS research program", internal report,
Eindhoven University of Technology, 1998. An extract of the
report can be , http://www.ds.arch.tue.nl/Research/program/
[8] Design presentations developed by Calibre BV, The
Netherlands, http://www.calibre.tue.nl/

We have presented the information visualisation in the
VR-DIS system. Because the VR-DIS system deals with a
hybrid set of data, it requires a combination of a
descriptive and a pictorial representation: the feature view
and the scale model view. There integration is worked out
on the basis of the four demands: complementarity,
integration, consistency, and mutual reference.
The descriptive feature view presents the architectural
design data as a 3D graph. In this graph, relation types are
mapped on distinct planar directions and the browsing
history is visualised in the third dimension. A tool
composed of spherical transparent layers has been
designed to facilitate the browsing process.
Further we discussed the 3d graph browsing tool that
has been developed for the visualisation of feature models.
This tool is expected to facilitate working with large
relation datasets. It supports user extendable data units,
and dynamic data models.

[9] Starlight, by Pacific Northwest National Laboratory,
http://multimedia.pnl.gov:2080/showcase/?it_cont
ent/starlight.node

References

[15] Graham, J.W. (1997) NicheWorks – Interactive
Visualization of Very Large Graphs, G. Goos, J. Hartmanis and
J. van Leeuwen (eds.) 1997. Graph drawing, Proceedings of the
5th International Symposium, GD’97, held in Rome, Italy, Sept.
18-20, 1997. Springer-Verlag, Berlin, pp. 403-414.

[1] Achten, H.H. (1997). Generic representations - Knowledge
representation for architectural design. G. Ang, L. Hendriks, P.
Nicholson and M. Prins (eds.) 1997. Journal of Architectural
Management 13
[2] Goldschmidt (1994) On Visual Design Thinking: the vis kids
of architecture, Design Studies, vol. 15, pp. 158-174.

[10] 3D Information Landscape, by Institute for Information
Processing and Computer Supported New Media, Graz
University of Technology, http://www2.iicm.edu/
[12] N.O.Bernsen, "A toolbox of output modalities", the
Amodeus-II WWW-site at http://www.mrc-apu.cam.ac.uk/
amodeus/, 1995.
[13] M.K.D. Coomans, “A Virtual Reality User Interface for a
Design Information System”, Tom De Paepe (ed.), Journal for
the Integrated Study of Artificial Intelligence, Cognitive Science
and Applied Epistimology, vol 15 n°4, 1998.
[14] Eades, P., F. Cohen and M.L. Huang (1997) Online
Animated Graph Drawing for Web Navigation. G. Goos, J.
Hartmanis and J. van Leeuwen (eds.) 1997. Graph drawing,
Proceedings of the 5th International Symposium on Graph
Drawing, GD’97, held in Rome, Italy, Sept. 18-20, 1997.
Springer-Verlag, Berlin, pp. 330-335.

[16] Lieberman H. (1994) Powers of Ten Thousand: Navigating
in Large Information Spaces. Proceedings of the ACM
Symposium on User Interface Software and Technology, 1994.
p.15-16

