Visualisatiion to Assist Non-speaking Users of Augmentative
Communication Systems
Andrew Taylor, John Arnott and Norman Alm
Department of Applied Computing, University of Dundee,
Dundee DDl 4HN, Scotland, United Kingdom.
{ ataylor, jarnott, nalm} @computing.dundee.ac.uk

sate (either temporarily or permanently) for the impairment
and disability patterns of individuals with severe expressive
communication disorders”. The field therefore exists to
develop techniques, aids and systems to enhance the communication abilities of disabled and non-speaking people.
The advent of low-cost computers expanded radically
the scope for technical AAC solutions; in particular the
creation of text-to-speech technology allowed nonspeaking people the opportunity to engage in spoken
conversation. If a system user can enter the word, phrase or
speech act they wish to use, then a speech synthesiser can
vocalise it to produce speech output and make conversational participation more feasible. An AAC system can also
contain a large amount of pre-stored material (words,
phrases and stories) which the user can select from and use
during communication, as well as access and input techniques to improve the efficiency of use of the system.
An important aspect of an AAC system is that its use
should not place an excessive cognitive load on its user.
The system should perform as much of the communication
process as possible, leaving the user free to concentrate on
the most important aspect - deciding on what he or she
wants or needs to say. The cognitive task of reviewing the
content of an AAC system and selecting from that content
must therefore be minimised wherever possible, and in this
context information visualisation may have much to offer.
There is a potential partnership between AAC and visualisation which could offer significant benefits to AAC users.

Abs tra ct
Many non-speaking people use augmentative and
alternative communication (AACJ systems to assist them to
communicate with other people. Access to an AAC system
is generally slow f o r its user, who may have other
disabilities as well as being non-speaking. An AAC system
can contain stored words, messuges and stories f o r use in
communication, and there can be a large quantity of such
information f o r the user to search through and select from
while he or she is trying to participate in conversation.
New interface techniques are required to assist a user to
navigate through the information stored in an AAC system
and select appropriate items f o r use during live
conversation. Information visualisation techniques may be
able to assist a user to overview and appraise the contents
of an AAC system as part of tkat selection process, and
therefore improve its efficiency of use. This paper outlines
key AAC issues and explores visualisation techniques
which may be ofvalue in an AAC context.

1. Communication and disability
Most people take communication for granted; often the
act of communication is effort1e:js. They are rarely required
to consider the mechanics of communication and can
concentrate solely on conveying what they want to say.
Communication for those who have physical or mental
disabilities can, in contrast, be a major struggle. Where a
person has reduced or no speech capabilities, effective
communication can be extremely difficult, particularly in a
conversational situation.

1.2 Rate of communication
An important factor in AAC is rate of communication.
People without speech difficulties can converse at rates
ranging from 150 to 250 words/minute [2]. Communication
for AAC users is not as simple as merely entering or selecting a phrase for use, however, and even if it were it would
still take place at a slower rate than vocal communication.
Speech impairment is often associated with other physical
impairments which make the selection process very slow.
AAC users are usually slow communicators, with equiva-

1.1 Augmentative and alternative communication
Beukelman and Mirenda [2] quote an ASHA definition
[ 11 of augmentative and alternative communication (AAC)

as “[the] area of clinical practice that attempts to compen-

251
0-7695-1195-3/01
$10.000 2001 IElEE

Between these two phases lies the part of the conversation
where the main transaction or exchange of information
takes place. Though this section can seem to be unique it is
still the case that a large part of conversation is re-usable;
information or stories may be related several times to
different audiences, and topics of interest to the user will
be discussed frequently. Several systems have been
developed that utilise these conversation models.

lent word rates which in many cases are less than 8 words/
minute [2]. Various acceleration techniques have been
developed in the AAC field to try to improve this, but the
basic difference in rates between non-disabled people and
AAC users remains very large.
One approach to the problem is to try to use symbol or
coding structures that reduce the physical effort required of
the user to make a selection. Given that the majority of
words and phrases used in conversation are used fiequently, it is possible to make these available via shortened input
methods [30]. Another approach is to use probability and
prediction algorithms to present the user with a set of
probable required words or phrases from which to make a
selection [28,29]. Such methods usually require the user to
expend extra cognitive effort in the input task in order to
offset difficulties in entering text, and any improvement in
input rate is unlikely to make an AAC user a fast
communicator. The continuing problem with low
communication rate means that more new methods are
required to improve the efficiency of the selection process
for AAC users.

2.1 Conversation
The Conversation Helped by Automatic Talk (CHAT)
schema 1311 was built around the conversational stages of
Open, Respond, Small-talk, Main, Wrap-up and Close. It
offered a variety of opening and closing phrases for the
user to utilise during the opening and closing stages of a
conversation and also a set of small-talk phrases and
feedback comments for use during the core part of the
conversation. The purpose of CHAT was to improve the
scope for a user to engage in what has been termed “phatic
communion’’ with another person, that is, communication
for the purpose of establishing an atmosphere or
maintaining social contact rather than information transfer.
Another approach considered topic shifting and how to
give the AAC user the ability to change topics within a
conversation, an important aim if the user is to be able to
control and guide conversations [ 13,14,15]. TALK (Talk
Aid using pre-Loaded Knowledge) presents the user with
three sets of conversation perspectives - person (me, you),
time (past, present, future) and orientation (where, what,
how, when, who, why). A set of possible phrases for use in
conversation is displayed based on the current perspective
settings. A topic shift can be made by changing one of
these three perspectives. If the user is discussing themself
(person = me) they can shift the topic to the subject of their
conversation partner (person = you) and be presented with
a set of appropriate phrases for this new stage in the
conversation.
TalksBack E321 presents likely phrases to the user based
on parameters which they specify. The system allows the
user to enter and store information regarding conversation
partners, subjects for conversation and particular utterances. This knowledge is appropriately stored and used to
predict suitable utterances when the user has stipulated
who their conversation partner is, the subject they are
discussing and the type of phrase required.
Fuzzy set theory has also been shown [6] to offer
benefits when used to produce a set of conversational
predictions. A conventional database categorises phrases
absolutely; each phrase is either usable for a given subject
or it is not. This has an impact on the search and retrieval
process in that each phrase in the database will either be
marked as relevant or not given the current search
parameters. With fuzzy set theory, category values that

1.3 Potential application for visualisation
Visualisation has been described as “the use of
computer-supported, interactive, visual representations of
data to amplify cognition” [3]. Visualisations present large
amounts of data and information in visual form so as to
reduce the cognitive processing required to make sense of
the data. A visualisation performs part of the representation
and processing of the information, the aim being that the
user is free to concentrate on the most important aspects,
such as locating trends, clusters, peaks and areas of interest
and finding the relevant piece of information quickly from
the large dataset. Visualisations seek to present data such
that the human vision system can more easily detect
important features in the dataset [22].
Attempts to visualise textual information have used
geographic metaphors [ 17,191, spatial mappings [20,2 I ]
and self-organising maps [23,24]. Each allow overviews of
a large corpus or document-set and make the detection of
themes and clusters of similar documents easier by using
terrain maps.

2. Conversation and story-telling
Researchers have been active for many years in trying to
facilitate conversation for AAC users, and a number of
techniques have been investigated [4,5], as some of the
following examples will illustrate. Though conversation is
infinitely varied, some general models can be abstracted.
Conversations generally contain an opening introduction
phase, incorporating small-talk, and a closing phase where
the conversation is wound up and farewells are made.

252

range between the binary values of 0 (no) and 1 (yes) make
for a more flexible categorisation and hence a more
flexible search and retrieval system. A major advantage of
the use of fuzzy theory is that every search will produce
predictions for the user. Conventional database storage has
the potential to fail to find any relevant items, thus leaving
the AAC user with no options to use in the conversation.

reasons why we tell stories categorised according to
whether they affect the storyteller (me-goals), the listeners
(you-goals) or the conversation itself (conversation goals).
We tell stories to satisfy our own personal needs whether
we're looking for cathartic benefits from the release of a
story, to win approval and praise, or simply to gain
attention. We also tell stories for the benefit of those
listening whether it is purely as an entertainment or as a
means of transferring information and knowledge. Sometimes a story is told with conversational goals, to start a
topic, to shift topic, to revive or continue a conversation.
Sometimes stories are the expected outcome of a request
and so become the required next stage of a conversation.
It is thus desirable for AAC systems to allow the storage
of long stories for later re-use. The question then becomes
how does the user access these complete narratives so that
they may be used in a conversation. Narrative storage and
retrieval features [ 161 have been developed which predict
the likely required story based on the partner and subject,
presenting suggested stories to the user until the desired
one is found. Once a story has been selected it can be
narrated, with the user having control over whether constituent phrases are spoken or not. Further research on stories
in AAC [ I I ] has shown that the development of storywriting and story-telling skills has a positive effect on the
interactive communication of young people with unintelligible speech. It is therefore important for AAC users to be
able to compose and relate stories using their AAC
systems.

Figure 1. Example Scene in the ScripTalker
Interface
In certain dialogues there are clear sequences to be
followed. Ordering a meal in a restaurant, for example, will
typically involve requesting the menu, placing the order
and dealing with the bill. Here there is scope for predicting
likely required phrases at each stage of the dialogue by
forming scripts that map out the stages involved in the
scenario and associated useful phrases [ 181. ScripTalker is
a script-based AAC system [ 101 presenting a scene-based
interface (Figure 1) that facilitates recognition by presenting pictorial representations of the scene. Items in the
scene represent access to scripits which prompt the user
through common transactions such as visiting the doctor or
ordering food in a restaurant. As an example, the user may
be presented with a picture of a restaurant containing
objects which one would expect to find there. By clicking
on the menu image, for example, the user can access the
meal-ordering script. By clicking on the image of the till
the user can access the payment script. ScripTalker has
recently been extended with the addition of a script authoring system [8] for use by therapists and carers to guide
them through the process of creating new scripts for use
with ScripTalker.

Visualisation of conversational material is an active area
of research. Chat Circles [25], a simple visual chat system
in which users appear in the conversation space as coloured
circles within which their messages appear, incorporated a
simple means to view the archive of the current chat
session. A timeline shows the point at which participants
joined and departed and when they said something in the
chat room. As a visual overview it effectively shows the
entire conversation; one can see how many people participated, when they joined and how actively they participated.
Similarly work has been done to represent better the conversation threads within newsgroups [26]. Such systems
consider stored, asynchronous conversation and give little
or no consideration to the content and creation of new
conversations.

2.2 Story-telling

3.1 Possible metaphors and models

A good deal of conversation consists of the telling of
stories. These stories are often told to many people at
different times and are an impa'rtant part of conversation
and of showing our personality. Schank [ 121 lists several

Many AAC systems employ similar interfaces, from the
simple provision of a list of predicted next words within a
text editor to the display of words and phrases in a twodimensional (2-D) grid layout from which selections can be

3. Visualisation of conversation

253

within the topic would be seen displayed upon it. This
representation can be seen as equivalent to a keyword
search of the story database as the user is locating stories
by one primary topic. The sizes and relative positions and
orientations of the pyramids could give visual cues about
the content of and links between individual topics.

made. It may be that three-dimensional (3-D) interfaces
could offer benefits by allowing the display of an increased
number of selectable phrases within metaphor-based information landscapes.
Traditional 2-D computer interfaces have often been
considered limited in that they are restrictive in terms of
display space and they do not correlate with the way people
see the world. The use of metaphors is thought to offer
several potential benefits for user interfaces. A natural
metaphor based on real-world scenarios and objects such
as landscapes allows the user to utilise their existing
knowledge and expectations to make sense of the interface.
This is the concept on which the aforementioned ScripTalker interface (Figure I ) is based [lo]. Several possible
metaphors have been considered, and the advantages and
drawbacks which each may present if used in an interface
to a story-telling AAC system. Spatial mappings, timeline
metaphors and abstract models have been postulated.

3.2 Spatial mappings
A spatial mapping of objects in 3-D space and the
ability of the user to navigate through the 3-D environment
to locate speech items for use could offer several benefits.
It may be possible to have all of the pre-stored stories
mapped into the scene and positioned according to some
criterion such as topic.
The use of naturalistic metaphors could play an
important part in reducing the cognitive load on the system
user. The visualisation could be seen as taking over some
of the cognitive processing for the user, the user and
visualisation forming a partnership, with the visualisation
doing as much as possible to lessen the effort required of
the user to select an appropriate story to tell. This could be
of especial benefit for users who have a cognitive
impairment - the visualisation could be seen as a form of
cognitive
augmentation
for the user. Amott et al. have
"
"
discussed the concept of the AAC system as a cognitive
prosthesis, highlighting the importance of the locus of
control and ensuring that the AAC system functions as a
slave to the system user who remains the master [7,27]. We
need to consider providing new means by which the user
can quickly and efficiently select items for use in
conversation, but the user must remain in control.
Two examples of spatial metaphor are a desert
landscape and a forested landscape. The desert landscape
(Figure 2) would present the user with a landscape sparsely
populated by discrete objects (pyramids, in the example
shown here). Each pyramid could represent a story topic
with individual stories on that topic possibly displayed
upon it (e.g. on the outside walls of the pyramid) or
positioned around it. The pyramid may be seen as a
repository for stories stored within it. The user would
initially choose the topic by moving towards the appropriate pyramid, and as they approach it the names of stories

Figure 2. Desert View
The forested landscape (Figure 3) would present the
user with a landscape populated by trees. Such a landscape
would be more densely populated than the desert view,
with each story represented by a single tree in the forest.
Once again stories could be mapped according to topic
with stories covering the same topic clustering together and
forming dense sections of forest. Visual features of the
trees could be used as cues to differentiate between
different stories. The height of the tree, for example, could
indicate the length of the story represented by that tree, or
the density of the foliage the amount of detail in the story.

15

Figure 3. Forest View

254

the size of nodes, the thickness of branches and the colour
and texture of nodes and branches could indicate features
of the story and its relationship to other stories in the system. Dynamic aspects such as animated nodes and
branches could also act as useful indicators to the user.
While these examples all relate to the storage and
retrieval of stories as the conversational task, visualisation
methods like these could be useful in helping the user to
locate other kinds of conversational material.

3.3 Timeline metaphors
It has been suggested [9] that a timeline-based interface
might be a good means for users, to locate items of interest.
A user trying to locate a particular file might struggle to
remember in which directory they saved it. It is likely that
the user will remember better when they worked on the file,
so if file location were done via a timeline interface presenting all files ordered by date of’ creation, this might assist
the user to quickly locate the desired file. This approach
could also be applied in an AAC system.

4. Conclusion
Information visualisation techniques could offer potential benefits to users of augmentative and altemative communication (AAC) systems in the metaphors that can be
employed in the user interfaces of the systems. The power
to gain an overview of the content of an AAC system, and
the relationships between items within that content, could
give the user valuable assistance in locating and accessing
stored material for use in communication. Successful
participation in conversation depends on the user being
able to access items in the system rapidly and easily, and
new access methods are required for the AAC systems of
the future which will contain ever-increasing quantities of
stored material. Future work will need to develop AAC
interfaces based on visualisation metaphors such as those
described in this paper, and make them available for use by
people with impaired communication.

Figure 4. Road View

5. Acknowledgements

A stretch of road (Figure 4) lends itself well to a
temporal display of stories. People often associate stories
and events with the period in which they occurred. The
road can represent time, with roadside objects representing
stories and signs by the side of the road indicating dates
along the timeline. The user can move forward and backward through time by driving up and down the road to
locate stories by the date the user associates with the story.
It can be seen from the three metaphors so far discussed
that each allows access to potentially the same set of stories
in slightly different ways. The spatial approach suits topicbased displays, while the road scene suits the time-based
display of objects.

This work is partly supported by a University of Dundee
Postgraduate Research Award.

6. References
[ 11 ASHA (American Speech-Language-HearingAssociation}
(1 989) “Competencies for speech-lang. pathologists providing
services in augmentative communication”, Asha, Vo1.3 1, p. 107.

121 Beukelman, D.R. & Mirenda, P. (1998)“Augmentative and
Alternative Communication: Management of Severe Communication Disorders in Children and Adults”, Second Edition.
Baltimore, Maryland, USA: Paul Brookes Publishing Co.
131 Card, S.K., Mackinlay, J.D & Shneiderman, B. (1999)
“Readings in Information Visualisation - Using Vision to Think”,
San Francisco, CA, USA: Morgan Kaufman Publishers Inc.
141 A h , N.& Amott, J.L. ( 1 998) “Computer-AssistedConversation for Non-vocal People Using Pre-stored Texts”, IEEE
Trans. on Svstems, Man and Cybernetics - Part C , Vol. 28, No 3,
August, pp. 318-328.
151 Alm, N., Newell, A.F. & Amott, J.L. (1997)“Lessons from
Applying Conversation Modelling to Augmentative and
Alternative Communication”, Proc. of 12” Annual Conference

3.4 Abstract models
Another approach is to devellop interfaces using abstract
metaphors, using nodes and interconnections, for example,
to represent stories and text items and the links between
them. Here the display would present a system or network
of inter-connected nodes connected by branches. Stories
could be associated with the nodes, with the branches
indicating semantic links between the stories.
Visual features of the nodes and branches could be used
to provide further information to8the user. Variables such as

on Technology f o r People with Disabilities (CSUN ’97),
Northridge, Califomia, USA, March. Available online at:

h ttp://~~~.dinf.org/csun~97/csun97~003.
htm

255

1201 Rennison, E. ( 1 994) “Galaxies of News: An Approach to
Visualizing and Understanding Expansive News Landscapes”,
Proc. of Seventh Annual Symposium on User Interface Sofmare
and Technology (UIST ‘94), Marina Del Ray, California, 4-6
November, pp. 3-1 2.
1211 Rennison, E. (1995) “Personalised Galaxies of Information”: Proc. of the ACM Conf on Human Factors in Computing
Systems (CHI ‘95): Demonstrations, Denver, Colorado, USA, 71 I May, pp. 3 1-32.
1221 Healey, C.G., Booth, K.S. & Enns, J.T. (1996) “High-speed
Visual Estimation Using Pre-attentive Processing”, A. C.M.
Transactions on Computer-Human Interaction, Vol. 3, No. 2, pp.
107-135.
1231 Lin, X. (1992) ”Visualisation for the Document Space”,
Proceedings of the IEEE Visualisation ’92 Conference, Boston,
Massachusetts, USA, pp. 274-28 1.
1241 Chen, H.; Nunamaker, J., Orwig, R.. Titkova, 0. (1997)
”Information Visualisation for Collaborative Computing”, IEEE
Computer, Vol. 31, No. 8, pp. 75-82.
1251 Viegas, F.B., Donath, J.S. (1999) *‘Chat Circles”, Proc. of
the ACM Conference on Human Factors in Computer Systems
(CHI ’99), Pittsburgh, Pennsylvania, USA, 15-20 May, pp. 9-16.
1261 Donath, J.. Karahalios, K. & Viegas, F. (1999) “Visualizing
Conversation”, Proc. of the 32’Id Hawaii International ConJ on
System Sciences, Maui, Hawaii, USA, 5-8 January.
1271 Amott, J.: Alm, N. & Waller. A. (1999) “Cognitive
Prostheses: communication, rehabilitation and beyond”, Proc. 01’
IEEE International Conf on Systems. Man and Cybernetics,
Tokyo, Japan, 12-15 Oct., Vol. VI, pp. 346-35 1.
1281 Newell, A.F., Amott, J.L., Booth, L., Beattie, W., Brophy,
M.B. & Ricketts, I.W. (1992) *‘Effect of the PAL Word
Prediction System on the Quality and Quantity of Text Generation”, Augmentative & Alternative Communication, Vo1.8, No.4.
December, pp. 304-3 1 1.
1291 Lesher, G.W., Moulton, B.J. & Higginbotham, D.J. (1999)
“Effects of N-gram order and training text size on word
prediction”, Proc. of the RESNA ‘99 Annual Conf, Long Beach,
California, USA. 25-29 June: pp. 52-54.
1301 Moulton, B.J., Lesher. G.W. & Higginbotham, D.J. (1999)
“A system for automatic abbreviation expansion”> Proc. of the
RESNA ’99 Annual ConJ, Long Beach. California USA, 25-29
June. pp. 55-57.
1311 A h , N., Arnott, J.L. & Newell, A.F. (1992) “Prediction and
conversational momentum in an augmentative communication
system“, Communications of the ACM, Vo1.35, No.5, May, pp.
46-57.
1321 Broumley. E., Amott. J.L.. Caims, A.Y. & Newell, A.F.
(1990) “TalksBack: an application of AI techniques to a
communication prosthesis for non-speaking people”, Proc. of 9”’.
European Conf on Artificial InteNigence. Stockholm, Sweden. 6I O August, pp. 117-1 19.

161 Alm, N., Nicol, M., & Amott, J.L, ( 1 993) ”The Application
of Fuzzy Set Theory to the Storage and Retrieval of Conversational Texts in an Augmentative Communication System”,
Proc. ofthe Idh.RESNA Conf.’. Las Vegas, Nevada, USA, 12-17
June, pp. 127-129.
17) Amott, J.L. (1990) “The Communication Prosthesis: a
problem of Human-Computer Integration”, Proc. of European
Conference on the Advancement of Rehab. Technology (ECART),
Maastricht, Netherlands, 5-8 November, Paper 3.1, pp 22-26.
IS] Amott, J.L., Murray, I.R., Harper, G., Dye, R. & Alm, N.
(2000) ”ScriptAuthor: an Authoring Tool for a Script-based AAC
System”, Proc. of the gh Biennial ISAAC Confirence,
Washington DC, USA, August, pp. 123-125.
191 Fertig, S., Freeman, E. & Gelernter, D. (1 996) ”’Finding and
Reminding’ Reconsidered”, SlGCHl Bulletin, V01.28~No. I, pp.
66-69.
1101 Dye, R., Alm, N., Amott, J., Harper. G. & Murray, I. (1998)
”Prediction Using Scripts in an AAC System”, Proc. of the
Biennial ISAAC Conference, Dublin, Ireland, 24-27 August, pp.
123- 124.
1111 Waller, A., Francis, J., Tait, L., Booth, L. & Hood, H.
( 1 999) ”The WriteTalk project: story-based interactive communication”, Proc. of European Conference on the Advancement o j
Assistive Technology (AAATE ’99), Diisseldorf, Germany, 1-4
November, pp. 180-184.
1121 Schank, R.C. (1990) ”Tell Me A Story - Narrative and
Intelligence”. Evanston, IL, USA: Northwestern University Press.
1131 Todman, J., Alm, N. & Elder, L. (1994) “Computer-aided
conversation: a prototype system for non-speaking people with
physical disabilities”, Applied Psycholinguistics. Vol. 15, p.45-73
1141 Todman, J., Elder, L. & Alm, N. (1995) “Evaluation of the
Content of Computer-Aided Conversations”, Augmentative and
Alternative Communication, Vol. 1 1 No.4, pp. 229-234.
[IS] Todman, J. & A h , N. (1997) “Pragmatics and AAC
Approaches To Conversational Goals”, Proc. of ACL Workshop
on Natural Language Processing for Communication Aids,
Madrid, Spain, 12 July, pp. 1-8.
1161 Waller: A. (1992) “Providing Narratives In An Augmentative Communication System”, PhD Thesis. University of
Dundee, Dundee, Scotland, UK.
(171 Havre, S., Hetzler, B. & Nowell, L. (2000) -‘ThemeRiver:
Visualizing Theme Changes over Time”, Proc. of IEEE Symp. on
Information Visualization (InfoVis ‘OO), Salt Lake City, Utah,
USA. 9-10 October, pp. 115-123.
(181 Schank, R.C. & Abelson, R. (1977) ”Scripts. Plans, Goals
and Understanding”. Hillsdale, New Jersey, USA: Lawrence
Erlbaum Associates.
191 Wise, J.A., Thomas, J.J., Pennock, K., Lantrip, D., Pottier,
M., Schur, A. & Crow, V. (1995) “Visualizing the Non-Visual:
Spatial Analysis and Interaction with Information from Text
Documents”, Proc. of IEEE Svnip. on Information Visualization
(InfoVis ‘95): Atlanta, Georgia, USA, 30-31 October, pp. 51-58,
~

256

