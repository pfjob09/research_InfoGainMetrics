Visualising Intra-Corpal Plagiarism
Fintan Culwin
Thomas Lancaster
School of Computing, Information Systems & Mathematics,
South Bank University, London, SE1 OAA, United Kingdom.
fintanC$sbu.ac.uk and lancaste@,sbu.ac.uk
as Web plugiurism [I]. Students have also been known to
copy from other reference works, an example of extrucorpul plugiurism, where the plugiurism source is outside
a corpus, or collected and related group, of student
submissions. Web plagiarism is itself an example of extracorpal plagiarism. Students also copy from one another, a
process known as intra-corpul plugiurism.

Abstract
This paper describes VAST U prototype Visuulisution
und Analysis of Similurity Tool, which tutors cun use to
investigute student submissions for intra-corpul
plugiurism. VAST displuys U puir of student submissions
and U gruphicul representation of their similurity,
ullowing tutors to nuvigute directly to ureus of potentiul
plugiurism. It improves on the humun eye upprouch by
identifiing similurities U tutor might otherwise miss und
suving investigative time. VAST is demonstruted using
noise-pee synthetic texts und ilctud student submissions
contuining intru-corpul plugiur ism.

A number of Web based services are able to detect
Web plagiarism. Culwin and Lancaster investigated a
number of such services and found that they were able to
find incidences of Web plagiarism within submissions
made to them, but the services varied greatly in the quality
of replies and the amount of plagiarism detected [2]. A
smaller investigation by Denhart had similar conclusions
[ 3 ] . Such Web-bused plugiurism detection services can
also be used to detect intra-corpal plagiarism, with each
submission added to an internal database and compared
with previous submissions, in much the same way that a
submission can be compared with a database of Web
pages.

Associuted ideus, including similarity visuulisutions,
similurity intersections und the Four-Stuge Plugiurism
Detection Process are ulso introduced.

1. Plagiarism By Numbers

In its most basic form, a similurity unulyser takes a pair
of student submissions, extracts from them some
representative information, such as an ordered sequence
of uncommon words, then compares the extracted
information in order to compute a similarity score. This
measure is then communicated to a user of the system,
who can then examine closely those pairs of student
submissions with a high similarity score and manually
decide whether plagiarism has occurred.

The media regularly makes reference to the volume of
student plugiurism, the presentation of another person’s
thoughts or material, for academic credit, as if it were
one’s own. The media claim student plagiarism is on the
increase and that it threatens to undermine the value of
university qualifications. In 1995, Franklyn-Stokes and
Newstead suggested that over half of students they
sampled committed student plagiarism during their
academic course [4]. They said that 66% paraphrased
without acknowledgement, 64% copied from other
students and 54% plagiarised from texts. Although there is
no anecdotal evidence, many academics speculate if the
current Web plagiarism was factored in, the figures today
would be much higher.

Figure 1 shows the Four-Stuge Plugiurism Detection
Process through which a corpus of student submissions
can be collected and any plagiarism found and verified. It
is primarily designed to be used in conjunction with
automated systems.

Much of this perceived problem has been traced to the
growth of the Web, with material available and in a format
that can be reused in student submissions with a minimum
of effort. In their plugiurism tuxonomy, Culwin and
Lancaster defined this re-use, without acknowledgement

The first stage is corpus collection. With the currently
available Computing and Information Technology
infrastructure, documents can easily be collected
electronically and prepared for processing.

289
0-7695-1195-3/01$10.00
0 2001 IEEE

similarity constitutes plagiarism, or acceptable similarity,
such as a properly cited common quotation. With the
evidence collected, appropriate measures should then be
taken.
The process that has been tested here seems to work
relatively well. The collection stage is routine. Metrics
have been found that rank pairs highly with high levels of
similarity, whilst being found to usually avoid false hits.
Investigations have revealed that the results of applying
the metrics have been used successfully to find intracorpal plagiarism.
The current bottleneck in this system is in the human
led stages, confirmation and investigation. The manual
confirmation and investigation of suspect pairs increases
the work for the tutor in charge of the unit. Previously
many such pairs would simply have been missed, since the
technology was not present to detect intra-corpal
plagiarism and the pressures of academia work against the
likelihood of tutors discovering plagiarism by eye.

Figure 1. Four-stage plagiarism detection
process
Next, the corpus is put through analysis, a stage
roughly similar to the similarity analyser described above.
This paper deals mainly with intra-corpal plagiarism, so it
is the finding of similarities within a corpus that will be
described here. In contrast, the Web-based plagiarism
detection services follow a similar pattern, but mainly
look for Web plagiarism. It is relatively straightforward, if
computationally intensive, to find documents within a
corpus that are similar. Such similarities might be an
overly large shared vocabulary, or a series of sections
presented in the same order throughout two or more
student submissions. Measures of similarity can be
obtained using a number of simple metrics, ranging from
word frequency distribution to document structure. Such
measures can be useful individually, but are most usually
combined to give a single numeric measure of similarity
to a pair of student submissions; this measure is known as
a similarity score.

Whilst a computer cannot be used alone to aid a tutor
with verification, it can certainly be used to assist in the
process. Studies have shown that users are more
productive when using tools that employ visual methods,
such as presenting data to users in a graphical form.
Representing data by graphical means is not a new
concept; presenting data in terms of graphs and charts has
long since been commonplace since it is more easily
interpreted by humans. Tutors using a system to
investigate similarities need also to know which sections
of a pair of documents are most.
Hence there is a need for a tool to allow tutors to
investigate pairs of student submissions, which is useable
by non-computer specialists and makes is possible to
navigate documents to those places which contain most
similarity. This paper covers the development of such a
prototype Visualisation and Analysis of Similarity Tool,
known forthwith as VAST, showing how it has been
successfully used to investigate the presence of intracorpal plagiarism in student submissions in the authors’
institution.

The list of pairs of student submissions can now be
sorted on this similarity score. Those with a high ranking
are instantly suspect, although at this stage there is no
evidence that plagiarism has occurred. Each highly ranked
pair of student submissions now goes through a stage of
confirmation. This is where a human manually verifies
that each suspect pair does not represent a false hit, which
is a pair that is ranked highly, but contains little similarity.
There is no related method to confirm the non-existence
of missed pairs, which are pairs ranked low, but which
contain similarities, other than going through all results by
hand. This is unlikely to be possible, since just 100
student submissions generate a corresponding 4950
possible pairings. The number of possible pairings
increases at an exponential rate compared to the number
of student submissions to be checked.

2. Fragmentary Granularity Matrix
A similarity analyser takes in two student submissions
and returns a similarity score, which a tutor can use to
decide whether manually investigating the submissions for
possible plagiarism is worth the time involved. Usually
the metrics used to compute the similarity score are
applied at gross granularity. This means that a
representation of the whole of the first student submission
is compared with a representation of the whole of the
second student submission. Such a comparison generates a
single similarity score for each metric applied; these

The final stage of the Four-Stage Plagiarism Detection
Process is investigation. This is where a human manually
checks those pairs which are highly ranked, but confirmed
to not be false hits, in order to assess whether the
290

scores are then combined in some fashion to give the
similarity score returned to the user.

words, the filler words of the language, such as ‘a’, ‘by’,
‘from’ or ‘to’. The most common word in the English
language is ‘the’, which alone usually accounts for around
10% of any fragment, and hence a substantial part of any
noise from a fragmentary interception similarity score.

In order to implement a visualisation system, a single
numeric similarity score is not sufficient. What is needed
is a method by which a number of such similarity scores
can be returned for a pair of student submissions,
providing a piecemeal representation of its similarity.

An example may make the process of generating
fragmentary interception similarity scores clearer. Table 1
shows a case of expansive plagiarism, plagiarism with
word additions and perhaps minor rearrangements. Table
1 shows two documents, in this case phrases, the second a
slightly expanded version of the first. For the purposes of
tracing, the first phrase is labelled SI and the second
phrase is labelled S2.

This thought process has led to a visualisation system,
where student submissions that rank highly under gross
granularity are further compared at fragmentary
granularity. In this case each submission is seen not only
as a whole, but also as a large number of overlapping
fragments of continuous words. Consider a student
submission. The first fragment is obtained from it simply
by taking words from the start, up to a given fragment
length. A second fragment could be obtained by taking the
student submission, removing the first word and then
repeating the fragmenting process. Words next to one
another in a fragment were always next to one another in
the original student submission.

Table 1. Expansive plagiarism phrases
S1 = “the cat sat on the mat”

S2 = “the black cat sat on the bathroom mat”

A simple count reveals that 100% (6 of 6) of the words
in SI are also in S2. In the other direction 75% (6 of 8) of
the words in S2 are also in SI. Under this simple word
count metric, the ordering of the words is unimportant, but
the word frequency is. Averaging these values would give
a similarity score between SI and S2 of 87.5. Using a
different metric might give a different similarity score.

In most cases it is not necessary to take every possible
fragment from a student submission, since this would give
too much detail for useful visualisation. Instead only some
of the fragments are removed; for visualisation purposes,
these must have the same spacing between them and cover
the entirety of the student submission. For this afiagment
gap is needed, this is the value denoting how many words
in the student submission there are between the first word
in subsequent fragments. For a fragment gap of one, every
possible fragment would be removed from the student
submission. For a fragment gap of two, every alternate
fragment would be removed. For a fragment gap of three,
every third fragment would be removed and so on.

In Table 2, the phrases from SI and S2 have been split
into fragments. The splitting process, in this example,
used a fragment size of four words and a fragment gap of
one word. The fragments have been labelled according to
which phrase they were removed from and their position
within the phrase. The first two characters in the new label
denote the source phrase, the third character denotes the
position of the first word of the fragment within the source
phrase.

A representation of each fragment from the first
student submission can now be compared with a
representation of each fragment from the second student
submission. This gives a frugmentary interception, a
representation of the contents of both fragments,
providing for it a fragmentary interception similariv
score, a similarity score localised to the fragmentary
interception. A tutor then now only needs to concentrate
human examination on those fragments which, when
compared, provide a higher fragmentary interception
similarity score than would usually be expected.

Table 2: Expansive plagiarism fragments
S 1 1 = “the cat sat on”

S2 1 = “the black cat sat”

S 12 = “cat sat on the”

S22 = “black cat sat on”

SI3 = “sat on the mat”

S23 = “cat sat on the”
S24 = “sat on the bathroom”
S25 = “on the bathroom mat”

Table 3 is derived by comparing every fragment from
SI with every fragment from S2, using the word count
metric. There are a total of fifteen comparisons to make to
generate the fragmentary intercept similarity scores,
comparing every fragment from S 1 against every fragment
from S2. Comparing S 1 1 (“the cat sat on”) and S2 1 (“the
black cat sat”) gives three words in common between the
two, which is the number given in parentheses. This value
is scaled between 0 and 100, by simply multiplying by 4,
to give the main value in the cell, the fragmentary

It would be very rare to get a fragmentary interception
similarity score of zero. This is due to the background
effects of noise. Consider a simple word count metric that
simply counts the number of words common to a
fragmentary interception. There is a certain background
distribution to student writing that means that certain
words will appear over and over again, regardless of
whom is writing. In English, these are usually function

291

similarity, apart from a 200 word stretch in the middle of
both documents, where every word is common to both.
This represents a short section of text copied from one
document to the other. The uniqueness of the rest of the
documents eliminates the problem of noise, since the
usual responsible background word distribution is not
preserved by the synthetic documents. The similarity
visualisation has been computed with using a fragment
size of 200 words and a fragment gap of 10 words, to
create an image 181 pixels by 181 pixels. The similarity
visualisation is shown both at its usual size and zoomed in
on at the similarity intersection.

intercept similarity score of 75. Comparing S2 1 and S 1 1
under this metric would give the same value, so there is no
need to calculate a backwards score and average the
results, but under some metrics, for instance where word
positioning is important, this might be needed. The rest of
the table, known as a fragmentary intercept similarip
score matrix is determined in a similar fashion.

Table 3: Fragmentary Intercept Similarity Score
Matrix

I

I

S11

I

S12

I

S13

s22

75 (3)

75 (3)

50 (2)

S23

100 (4)

100 (4)

75 (3)

I

Due to the nature of the comparisons of adjacent cells,
the count of similar words never varies by more than one
and in many cases is identical. Since this example is
necessarily simple, the similarity score is high in every
case. The two cases where it is 100 are of particular
interest. The fragments SI2 and S23 are identical and
show a place in the two documents that should be of great
interest to a tutor. The fragments SI 1 and S23 are also
identical under this metric, where word ordering is
unimportant. This demonstrates that there is always a need
for tutors to manually validate all reported similarities.

Figure 2. Synthetic similarity visualisations - 200
words
The similarity intersection features an intensely black
area in the centre, where an exact match of 200 words is
found. Radiating outwards are ever-lighter shades, until
the edge pixels of the hexagon, which are imaged from
fragmentary interceptions sharing only ten words in
common.

3. Similarity Visualisations

The positioning of the similarity within the documents
is also important. In the similarity visualisation, the first
document is positioned along the x-axis and the second
document is positioned along the y-axis. The origin point
for both is in the top-left comer. The similarity
intersection is situated approximately half way through the
first document and half way through the second document
two. It is also situated on the primury diugonal, the
diagonal running from the origin, at the top-left, to the
bottom-right.

The similarity comparison using fragmentary
granularity allows the pinpointing of similar areas of two
texts in a much better way than a simple examination by
tutors. But it is still not the basis of a viable tool, since
tutors are expected to hunt through a matrix of numbers a process which can be daunting and time consuming in
itself. To have a usable system, the similarity score matrix
must be presented in a more eye-friendly form.
The table can easily be presented as an image, where
colour information can be used to display the extent of
similarity within fragments. Each cell within the
fragmentary intercept similarity score matrix can be
mapped onto a grayscale value, with a fragmentary
similarity score of 0 corresponding to white, and a score
of 100 corresponding to black, and plotted onto a
similarity visualisation. The joining together of many
pixels makes some areas prominent; these areas are known
as similarity intersections.

The system cannot tell us which document represents
the source of the plagiarism. The similarities might be
through the writer of the first document copying from the
second, or vice-versa. Alternatively the writers might have
collaborated on both submissions, or both copied from the
same source. A similarity visualisation generated by
comparing the second document with the first document
would generate the same graphic, only mirrored along the
primary diagonal. In this case, both similarity
visualisations would be identical.

Figure 2 shows the similarity visualisation generated
by comparing two synthetic documents. The synthetic
documents are each 2000 words long and contain no

292

Figure 3 shows a number of other similarity
visualisations generated from synthetic documents. All are
again 2000 words long, using a fragment size of 200
words and a fragment gap of 10 words.

visible that would be too small to see with larger fragment
gaps.
The discussion of the visualisation of synthetic
documents prepares for the interpretation of a similarity
visualisation derived from a pair of true-life documents,
which have been judged by humans to be examples of
intra-corpal plagiarism, with an attempt at disguise. Figure
4 shows a similarity graphic for two such documents. The
first document, along the x-axis, is 2728 words long. The
larger second document, along the y-axis, is 3341 words
long. As in the synthetic cases, the similarity visualisation
is generated with a simple word count metric, a fragment
size of 200 words and a fragment gap of ten words. The
size of the resulting similarity visualisation is 253 pixels
by 315 pixels; the slight discrepancy from what would be
expected caused by the intricacies in the parser used to
produce the similarity graphic.

Similarity visualisation A shows the unlikely situation
of the two documents being identical. The similarity
intersection runs down the entirety of the primary
diagonal. The centre of the similarity interception shows
the series of 200 word matches. The edge of it shows
where just ten words are identical.
Similarity visualisation B shows the case where 400
words are identical, under much the same pattern as
before. Again the similarity is positioned in the centre of
both documents.
Similarity visualisation C features two similarity
interceptions. Each represents a set of words identical to
each document, but not to the other similarity interception.
The common words are situated in the same place in both
documents, one near the beginning of both, the other near
the end of both. Here the central extent of the similarity
interceptions is lighter than before, since at most 100
words match out of 200, demonstrating the need for
careful selection of fragment sizes. However, in practice
this would be sufficiently different from the background
colour to stand out in most situations.
Similarity visualisation D shows a theoretical first
document, along the x-axis, where the same 400 words are
repeated five times, compared with a second document,
along the y-axis containing these 400 words just once.
There are five similarity interceptions, one for each set of
matching words, in much the same shape as the similarity
interception in similarity visualisation B. The leftmost and
rightmost similarity interceptions start and end abruptly
where the first document starts and ends. Similarity
visualisation D demonstrates that one can expect to find
extensive similarity only once at any given point on the x
and y-axes. Later examples will show extensive plagiarism
seems to occur most often close to the primary diagonal.

Figure 3. More synthetic similarity visualisations
The first thing apparent compared to the synthetic
graphics, is the background noise. However the similarity
interceptions, of which there are at least ten, are still clear
to see. As expected, the similarity intersections appear
close to the primary diagonal, where the second document
seems to be a somewhat expanded version of the first. In
particular, similarities in the introduction, conclusion,
references and other sections of the text make this an
interesting case. Although many words are changed here
and there this does not fool a computerised checker,
although it may get past a human marker, since the
fragment size takes this into account. The similarity
interception identified as A on Figure 4 showed, on
investigation, two short sentences in each document that

A smaller fragment size would decrease the width of
each of these similarity intersections, since the area
through which fragmentary intersections continue to
contain some similarity would decrease. It would also
serve to increase the intensity of the similarity
intersections in C, since the maximum proportion of
similarity within a fragment would increase and hence, so
would some of the fragmentary similarity scores.
A smaller fragment gap would increase the number of
fragments to be compared and correspondingly, the size of
the similarity visualisation. Each similarity intersection
would see a corresponding increase in size. On occasions
an increase might make other similarity intersections

293

were identical. This suggests that the fragment size and
fragment gap values were appropriate.

Figure 5: Intra-corpal plagiarism -word
sequences
Figure 4. Intra-corpal plagiarism - word count

4. Visualisation and Analysis of Similarity

Tool

The similarity visualisation generated from one further
fragmentary metric is worth showing. Figure 5 shows a
refinement that reduces the noise and shapes the
highlights. It shows the same two student submissions as
Figure 4, with the same fragment size and fragment gap,
but a different metric. The fragmentary metric used is
more coinputationally intensive than the last, but is
responsible for a clearer similarity visualisation. The
colouring is derived from the word sequence mefric that
takes the longest common ordered sequence of words
within the fragment. The previous metric did not take such
ordering into account. That is to say that the sequences do
not have to be contiguous, but must contain the ordering.
For example, the longest common ordered sequence of
“apples bananas cherries damsons” and “apples apples
bananas bananas damsons damsons” is “apples bananas
damsons” of length 3 words.

The similarity visualisations in themselves are very
useful as part of the process of verifying if plagiarism has
occurred. However there is no easy way for a tutor to find
the parts of a pair of documents that a given similarity
interception represents. This is a problem ideally suited to
computer assistance, with a prototype navigation system
available to guide the tutor around the documents.
Figure 6 shows the Visualisation and Analysis of
Similarity Tool (VAST) being used to navigate around the
two student submissions suspected of intra-corpal
plagiarism in the previous section. The user highlights an
area of the similarity visualisation that is of interest and
the corresponding sections of the text are shown in the
windows on the right. The similarity visualisation can be
scrolled about if it is bigger than the window it is in. The
section of text by the area selected is marked with a red
side bar highlighted, so that it can be scrolled through if it
extends beyond the viewable window. The user can then
carry out the final two stages of the Four-Stage Plagiarism
Detection process, confirming that each similarity
interception does not represent a false hit and
investigating whether the similar sections are plagiarism,
or if they contain legally cited materials.

In this case the similarity interceptions highlight much
the same areas for inspection as before, but the noise level
is much lower allowing the similarity interception
identified as A to be much more clearly seen. It might be
possible to use graphical techniques to filter the noise
from the graphic still further, however this is sufficient to
demonstrate the principal behind the graphics.
VAST uses a combination of the fragmentary intercept
similarity score matrices generated using the word count
and word sequence metrics, combining them with colour
information to generate a similarity visualisation. This will
be seen in Figure 6.
294

The previous section demonstrated how VAST can aid
with the verification of intra-corpal plagiarism. It can also
be very used to verify extra-corpal plagiarism, where a
source can be determined. This example represents a
chapter of a final-year student project where the tutor
marking it noticed stylistic differences to the rest of the
document and with the aid of a Web search engine was
able to trace the chapter to a Web source.
Figure 7 shows the similarity visualisation for the
suspect chapter of the project, plotted against the Web
source.

Figure 6. Visualisation and analysis of similarity
tool
The user selects a similarity interception using the
similarity interception selector, the red rectangle in the
navigation window. Users can click and drag the small
rectangle in the top left comer of the similarity
interception selector in order to move it around the
similarity visualisation. They can alter the size of the
selector by clicking and dragging the rectangle in the
bottom right comer of it in order to view the text
represented by larger or smaller similarity interceptions.
Figure 7. Extra-corpal plagiarism

The student submissions used to generate the similarity
visualisation in Figure 6 are the same as in Figures 4 and
5 . Both the word count and word sequence metrics are
used and displayed in the single similarity visualisation,
using colour information to display both. Notably the red
and green components of the image are set using the word
count metric and the blue component set using the word
sequence metric. The coloured graphic seems to be more
effective in this circumstance.

The 5400 word chapter is plotted along the x-axis, the
3500 word Web source along the y-axis. Projecting the

similarity intercepts down onto the x-axis reveals that
around one third of the chapter is made up of similar
material and the intensity of the areas reveals that the
material has been copied word for word. Extracting the
similarity intercepts across onto the y-axis reveals that
almost the entire Web source has been used in the chapter
at some point. However some parts, primarily towards the
end of the Web source, have had new material introduced
so that the apparent extent of the similarity is reduced.
Also of interest is the first section of plagiarism within the
chapter, which shows that the Web source has been
slightly re-arranged. The most interesting section is the
central similarity intercept of around 1000 words, which is
copied verbatim; both its intensity and its positioning
parallel to the primary diagonal illustrate this.

The section of text highlighted in VAST shows an
example of intra-corpal plagiarism with disguise and
restructuring. The essence of the content is essentially the
same, with the same quotes, references and points made in
the same order. However the paragraphs have been broken
in different places, abbreviations replaced with full
wording and section headings altered. There has also been
some simple thesaurising, such as replacing ‘large’ with
‘big’.

The substantial similarity shown in the similarity
visualisation in Figure 7 was later determined to be extracorpal plagiarism.

The plagiarism, although disguised, looks relatively
straightforward to find in this case. For a tutor struggling
only with two paper submissions it is much harder. Since
the length of the submissions is different, the similarity
intersections will not be on the same page and a tutor will
have a needle in a haystack like job to find them. VAST is
a big help in the necessary investigation, with the suspect
similarity interceptions easily highlighted by a user for
examination.

6. User Reviews
VAST is currently being developed as a proof of
concept prototype. As such much of the functionality that
would be needed for a production version has not even
been fully specified. Despite this it has been shown to a
number of academic tutors from a number of different

5. Extra-Corpal Extension
295

The success of this method depends on choosing
appropriate values for the fragment size and fragment gap,
so as not to overwhelm the tutor with too much
information, or to miss any similarity in the submissions
caused by examining fragments that are either too small or
too large. The ideal sizes may vary from submission to
submission, or even within different sections of a
submission. This process of choosing correct values could
be machine assisted and is something that requires further
investigation. The current values have been demonstrated
to find and display fragmentary intersections to a VAST
user.

institutions, including a demonstration at the 2000 ITiCSE
conference in Helsinki.
All reactions to the tool have been favorable and its
utility has been readily, though not immediately, apparent.
A few prospective users were simply told that it was a tool
to assist with plagiarism verification and invited to
interact with it. In these cases neither the interpretation of
the image nor the relationship with the text panes was selfevident and instruction had to be given before effective
use could be made of it.
The majority of users have required a short verbal
introduction to what the tool is intended for, what the
image indicates and how the rectangular highlight relates
to the text panes. Following this introduction all trial users
have been able to use the image and the highlighter to
successfully navigate around the documents, verifying the
existence of plagiarised parts. This tends to suggest that
although the tool could not be used on a ‘walk up‘ basis
only a minimal amount of instruction would be required.
All of the tutors that have used the tool have indicated that
they think it would be of use to them in the validation of
plagiarism and most have expressed interest in having
access to it when it is available. One South Bank tutor,
who had assisted with the collection of a corpus of
documents, was invited to comment upon the prototype at
an early stage and was somewhat disappointed that it
would not be immediately available.

One problem outside the current scope of VAST is that

of multiply sourced plagiarism. This is where different
sections of a student submission have been plagiarised
from different sources, for example, one section from the
Web and one section from another student. A method is
needed to display all possible similarity visualisations for
a given student submission, possibly on a single similarity
visualisation. The prototype version of VAST also needs a
front end to allow tutors to select the similarity
visualisation that they wish to examine.
The system can be combined with a pro-active
plagiarism policy, where plagiarism is not only taken
seriously when found, but also actively sought out, say by
routinely sending all student submissions to a plagiarism
detection service. This allows a tutor to quickly illustrate
plagiarism to a suspected student, or the part of an
academic institution responsible for determining the
penalty for such plagiarism. The tool at present is most
suitable for detecting and verifying intra-corpal
plagiarism, but could be used to verify extra-corpal
plagiarism, where the source can be determined by other
means. There are many services available to detect Web
plagiarism. The tool could be refined and used in
conjunction with them to find more than just intra-corpal
plagiarism.

It is intended that a small-scale study will be conducted
in the near future with tutors being required to annotate
pairs of plagiarised documents, one group purely by eye

and one with access to the tool. The tutors will then be
asked to make a simulated decision to exonerate, warn or
start a formal investigation of the pair of students
concemed. An informal observation has indicated that
moving the relative locations of plagiarised sections
makes it more difficult for a tutor to detect them. If this is
the case then VAST should prove to be of significant
benefit.

8. References

7. Conclusion,

[ I ] Culwin F. & Lancaster T., A Descriptive Tmonom-v of
Stirdent Plagiarism. Awaiting publication, available from South
Bank University, London (2000).

Even if there are methods to easily detect plagiarism in
free-text submissions, the process of human verification is
still costly, in terms of time and effort expended. The
visualisation method presented here has many advantages
over relying on the human eye alone. Primarily it provides
a graphical representation of two texts, which may be
source and copy, or the result of collaboration, where
similar areas are visibly highlighted for human
verification. The associated tool VAST allows those areas
to be easily displayed on screen so that a human
judgement can be made.

[2] Culwin F. & Lancaster T., A Review of Electronic
Services for Plagiarism Detecting in Student Submissions. 8Ih
Annual Conference on the Teaching of Computing -organised
by the LTSN Centre for Information and Computer Sciences

(2000).
[3] Denhart A., The Web’s Plagiarism Police. Available at
http:i/wwLv.salon.coni~tech/feature/I999/06/ 14/plaziarism!index.

m(1999).
[4] Franklin-Stokes A. & Newstead S., Undergraduate
Cheating: Who Does What & Why? Studies in Higher
Education, 20,2, p 159- 172 (3995).

296

