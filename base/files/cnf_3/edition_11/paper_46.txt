View Morphing Using Sprites with Depth
Youngsup Park, Kyunghyun Yoon

Dept. of Image Engineering,
Graduate School of Advanced Imaging Science, Multimedia, and Film,
Chung-Ang University, 156-756, Seoul, Korea
{cookie, khyoon Mcgl'ab. cse . cau. ac . k r

on iinages (no 3D shape information is required). This
works by pre-warping two images, computing a morph
between the pre-warped images, and then post-warping
each in-between image produced by the morph. The prewarping step is performed automatically, while the postwarping procedure inay be interactively controlled by
means of a small number of user-specified control points.
However view morphing method assumes that the
objects in these images must be visible' to completely
appear at the new viewpoint. If these images are not
visible, two problems, folds and holes, appear. In detail,
a fold occurs in an in-between image when a visible
object in the left image (or right image) becomes
occluded in the in-between image. A hole appears in an
in-between image when an occluded object suddenly
becoming visible: a region of in-between image having
no correspondence in the left image (or right image).
In this paper. we describe a view morphing using
sprites with depth. This algorithm consists of a 4-step
process. First, divide the image into sprites. We divide
images i n t o sprites to reduce problems in the morphing
procedure. Second. do a pre-warping, the first step of
view morphing. Pre-warping brings the image planes into
alignment without changing the optical centre of the two
cameras. Third. compute a depth with a pre-warped
image using a simple stereo system, then do the
morphing and post-warping. We compute the depth of
each sprite to prevent problems. The last step, compose
each sprite with depth to produce a final result image.

Abstract

Keywords: view inorphing, depth inup. disparity, sprite,
epipolar geometry, stereo system, intcrpolation, image
warping. occluded object.

1

Introduction

2
Recently there has bcen a great deal o f interest in
morphing techniques to produce intermediary images
between two images. View morphing technique enables
current image inorphing methods to easily synthesize
changes in viewpoint and other 3D effects [ 2 ] . When
morphing between different views of an object or scene,
this technique produces ncw views of the same scene,
ensuring a realistic image transition. The approach can
synthesize 3D projective transformations of objects,
which is the class including 3D rotations, translations,
shears and tapering deformations, by operating entirely

0-7695-1195-3/01$10.00 0 2001 1E:EE

Previous Work

Imagc-based Rendering presents methods of using
image depth or image correspondences to re-project the
pixels from one camera position to the viewpoint of
another. View Morphing is also included in Image-Based
Rendering.
T. Beier and S. Neely first presented image
morphing 141, in which the "object" is equal to an image,
as being able to be applied to the image-based virtual
reality systems. The image morphing defines a set of
functions, which morph each pixel from the source image

323

The 8-point algorithm [7] is the simplest method of
computing the fundamental matrix F, involving no more
than the construction and least squares solution of a set
of linear equations. However, in this paper we used the
normalized 8-point algorithm to compute fundamental
matrix F. If input data is exact, we use the simplest
method, the &point algorithm, to compute fundamental
matrix F. If not, we must use the normalized 8-point
algorithm to reduce a measurement error of Input data.
The suggested normalization is a translation and scaling
of each image so that the centroid of the reference points
is at the origin of the coordinates and the RMS distance
of the points from the origin is equal to

to the target image. Chen and Williams’ View
Interpolation [3] employs incomplete plenoptic samples
and image flow fields to reconstruct arbitrary viewpoints
with some constraints on gaze angle. The reconstruction
process uses information about the local neighborhood of
a sample. Chen and Williams also point out and suggest a
solution for one of the key problems of image-based
rendering - determining the visible surfaces and
choosing to presort the quadtree compressed flow-field in
a back-to-front order according to its z-values. Seitz and
Dyer describe a system that allows a user to correctly
model view transforms in a user controlled image
morphing system [2]. H. C. Huang proposes disparity
morphing [5]. Disparity morphing depends on the
estimated disparity map for each image pair based on the
epipolar geometry. Jonathan Shade and his colleagues
present techniques for quickly rendering sprites with
depth and describing a new multi-valued representation,
called a layered depth image (LDI), in which each pixel
can have multiple depths [I].
Laveau and Faugeras [6] have taken advantage of
the fact that the epipolar geometries between images
restrict the image flow field in such a way that it can be
parameterized by a single disparity value and a
fundamental matrix [7] that represents the epipolar
relationship. Their method requires establishing
correspondences for each image point along the ray’s
path.

3

a.

3.2

A pair of partially occluded images results in two
problems, folds and holes, in the view morphing
procedures. A fold occurs in an intermediary image when
a visible part in the left image or right image becomes
occluded in the intermediate image. In this case, the
multiple pixels in the right image (Figure I(B))
correspond to the same pixels in the occluded part of left
image (Figure l(A)). This causes ambiguity. The other
case, of an occluded part suddenly becoming visible,
gives rise to a hole; a region where the right image
(Figure 1(B)) has no correspondence to the left image
(Figure 1 (A)). Figure 1 depicts an ambiguity in an image
with a pair of partially occluded images.

View Morphing with a pair of partially
occluded images

View Morphing is a general class for recent
techniques for producing transitions between images.
Using basic principles of projective geometry, this
technique propose a simple extension to image morphing
that correctly handles 3D projective camera and scene
transformations. This algorithm consists of 3-step
processes (pre-warping, image interpolation and postwarping).

3.1

Ambiguous Points

(A) Image with ambiguous points

Fundamental Matrix

In order to use the 3-step algorithm, we must find a
way to pre-warp the images without knowing the
projective matrix. We first consider what form the
fundamental matrix takes when the views satisfy the
scanline property and then pre-warp the views in such a
way so that the fundamental matrix achieves this form.
The fundamental matrix is defined by the equation

(B) Image with exact points
[Figure 11 A pair of partially occluded images

3.3
x ’ FX
~ = 0

Rectification

(Eq. 1)

for any pair of corresponding points in two images and is
defined up to a scale factor.

Rectification is the first step in the View Morphing
processes,
pre-warping
procedure.
Rectification
determines a transformation (or pre-warping) of each

324

image so that pairs of conjugate epipolar lines [9]
become collinear and partdlel to one of the image axes,
(usually the horizontal one). The rectified images can be
thought of as being acquired by a new stereo rig,
obtained by rotating the original cameras around their
optical centre.

3.4

Image Interpolation

Image interpolation procedure is the second step in
the View Morphing procedure, which is used in a prewarped image. It means that a pre-warped image is a
transformation of a non-parallel image into parallel
image at stereo system. Namely, Epipolar line has the
parallel property.
Feature-based Morphing [4] is the method that is
most frequently used in several image morphing methods.
Figure 2 describes corresponding points and lines in the
stereo system based on epipolar geometry. A set of
features (yellow points) is a corresponding point on a
pair of images. Led lines are feature lines that join a set
of points.

(B) Right Image
[Figure 21 Corresponding Points and Lines
This method needs feature points on a pair of
images, several lines composed of a pair of feature points
and color information of t:he right image (or left image).
Namely, if feature points t:xist in a pair of images based
on stereo system, intermediate image can be produced
though color information that does not exist in the one
image (left or right image).

3.5

A perspective transformation [9, 101 is expressed in
terms of 9 coefficients in the general 3 x 3 matrix T.
Without loss of generality, matrix T can be normalized
so that a33= 1 . This (Eq. 2) leaves 8 degrees of freedom
for projective mapping.

Perspective transformations preserve parallel lines only
when they are parallel to the projection plane. Otherwise,
lines converge to a vanishing point. This has the property
of foreshortening distant lines, a useful technique for
rendering realistic images.

4

Divide Image into Sprites

A sprite is an image with the standard three-color
components (red, green, blue) and an additional channel
that encodes the image’s shape. Composition permits
individual renderings of each sprite, which are then
combined to create a final image. Figure 2 shows the
image (left image or right image) with objects divided
into each sprite. Sprite #2 of Figure 3(A) describes the
image which has the problem, image information lost by
partially occluded image. Despite this problem,
Morphing of a partially occluded image can be computed
because the sprite #4 image corresponds to sprite #3
image of Figure 3(B) visibly. Consequently, the View
Morphing 3-step procedures (pre-warping, image
morphing and post-warping) have no problems because
colour and shape of sprite #2 image can be referred to
those of sprite #4 image. Namely, the above-mentioned
two problems, folds and holes, can be solved even for
partially occluded object in the view morphing.

--

.

~.

Perspective Transformation

Perspective transformation is the last step of the
View Morphing processes, Post-Warping procedure. This
process will be computed by perspective transformation
matrix T of two images.

(A) Two Sprites in the Left Image

325

(B) Image where Gaussian Filter Mask is applied

[Figure 51 Original Image and Image where Gaussian
Filter Mask is applied

(B) Two Sprites in the Right Image

[Figure 31 Divide Image into Sprites

To compute depth Map between two images, we
used a simple stereo system [8][12]. Depth can be
estimated from the disparity of corresponding points and
is inversely proportional to disparity (Eq. 3). In a typical
stereo system with converging cameras, disparity
actually increases with the distance of the objects from
the corresponding points. We obtain Z:

Figure 4 depicts that the sprite #2 shape of Figure 3(A)
can be decided by the sprite #4 shape of Figure 3(B). The
Ghost Point is the false feature point of the sprite #2
image and can become information in the image
morphing.

T

= f ?- (d : disparity)

d

(Eq. 3)

[Figure 41 Sprite #2 image of [Figure 31 (A)

5

Making Sprite with depth

An experiment image used to compute disparity
images makes lots of noise because we don't take images
under adequate conditions. Such an image has one
problem when we compute a disparity. In this instance,
we used the Gaussian Filtering Method to reduce these
noises [ I I]. Gaussian Filtering retains low frequency
components of image components of target process while
removing high frequency components. The sum of each
pixel in the Gaussian Filtering Mask fundamentally is
equal to 1 . Of course we can change the weight value of
the central pixel to increase image quality. The reason is
because the computation referred to the neighboring
pixel's .intensity value in the .disparity computation
procedure. Images taken through this process have a
better disparity than the ones taken using the original
image's disparity. Figure 5 shows an original image and
an i.mage where Gaussian Filter Mask is applied.
I

P

9

+*,
,'
,
;

'
;

,'

'

I

I

'.
(

\\

I

*,

I

\

I

I

'*

*',

I

11

-

[Figure 61 A simple stereo system

/

To compute the disparity in the two images based
on stereo system, there are two methods. One is a
Correlation-Based Method. In a correlation-based
method, the elements to be matched are image windows
of fixed size, and the similarity criterion is a measure'of
the correlation between the windows in the two images.
This method applies to the totality of image points and is

(A) Original Image

326

used two images, II (left image) and I, (right Image), in
which to each point (x, y) we have associated not only
the colour information (R, G, B), but also the Depth (Z)
of the object visible at that point. Write:

certainly easier to implement, and to provide dense
disparity maps. The other is a Feature-Based Method.
This method attempts to establish a correspondence
between sparse sets of irnage features, and is suitable
when a priori information is available about the scene so
that optical features can be used. Feature-based
algorithms can also be proven faster than a correlationbased method. The sparse disparity map generated by
this method may look inferior to the dense map of
correlation-based matching. In this paper, we used the
Correlation-Based Method to compute a dense disparity.
Figures 7(A) and (B) dlzpict the Right Image point
corresponding to the centre: of Left Image Windows. This
window is correlated to several windows of the same size
in the Right Image. The: centre of the Right Image
window producing the highest correlation is the
corresponding point being sought. Figure 7(C) exhibits a
disparity map computed for the Left image in Figure
7(A).

11(x. Y) = (RI (x. Y), GI(x, Y). BI (x, Y), ZI(x, Y))
Y) = (Rr (x, Y), Gr (x, Y), Br (x, Y), Zr Y))
We can define a merging operation h = comp (II, Ir), as
follows:
Ir

~

9

(

~

9

I (x. Y) = 11(x, y) ,if ZI (x, Y) <= Z, (x, Y)
1 (x, Y)= I r k y) if ZI (x, Y)> Z , (x. y)
,

Thus, the merged image, I (x, y) receives at each point
the value of whichever object is closer to the observer.
Figure 8 shows some results on morphing images
between different views of the partially occluded objects.

7

Conclusion and Future Work

In this paper, we proposed a view morphing
technique using depth map and sprites. This method is
much more powerful and efficient than traditional image
morphing and view morphing techniques. This algorithm
consists of a 4-step process. First, divide the image into
sprites. Secondly, use a Pre-Warping, the first step of the
View- Morphing processes. Thirdly, compute a depth
with a pre-warped image using simple stereo system,
then do a morphing and post-warping. Finally, compose
each sprite with depth to attain final result image. In this
paper, the proposed method can reduce distortion of
appearance that happens with the previous method (view
morphing). In addition to thc image-based rendering
systems, this method is also useful for generating
interpolated and extrapolated videos for multi-viewpoint
stereo projection system.
A future project is to generate disparity maps
efficiently for each image in stereo system. Another one
is to extend this method when navigated in the virtual
environment.

(A) Left Image

(B) Right Image

(C) Disparity Image about Left Image

[Figure 71 Compare Original Image with Disparity
Image

6

(

Sprite Composition Using Depth values

It is common in computer graphics to obtain an
image by combining specific elements from different
images belonging to the same image space. This paper

327

Acknowledgements
This work is partially supported by 2000 National
Research Laboratory Program Grant No. 2-253 of the
Korean Ministry of Science and Technology.

References
[I]

J.W. shade et al., Layered Depth Image, Proc.
SIGGRAPH 98, ACM Press, 1998

[2] S.M. Seitz and C.M. Dyer, View Morphing. Proc.
SIGGRAPH 96, ACM Press, 1996, pp.21-30
[3] S.E. Chen and L. Williams, View Interpolation for Image
Synthesis, Proc. SIGGRAPH 93, ACM Press, 1993.
pp.279-288
[4] T. Beier and S. Neely. Feature-Based Image
Metamorphosis, Proc. SIGGRAPH 92, ACM Press, 1992.
pp.35-42
[ 5 ] H.C. Huang and Y.P. Hung, Disp:irity-Based

View
Morphing - A New Technique for Image-Based
Rendering, ACM Symposium on Virtual Reality Software
and Technology (VRST), 1998, pp.9-16

[6] S. Laveau and 0. Faugeras, 3-D Scene Representation as
a Collection of Image and Fundamental Matrices, INRIA.
Technical Report No. 2205, 2.1994
[7]

R.I. Hartley, In defence of the 8-point algorithm. In Fifth
Inter. Conf. On Computer Vision. Massachusetts Institute
of Technology, Cambridge. Massachusetts, 6.1996.
pp. 1064-1070

[8]

E. Trucco and A. Veni. Introduction Techniques for 3-D
Computer Vision, Prrntice Hall.

J]

R. Hartley and A. Zisserman, Multiple View Geometry in
Computer Vision, Cambridge Univ. Press, 9.2000

IO] G. Wolberg, Digital Image Warping, IEEE Compiiter

Society Press
I I ] R.C. Gonzalez and R.E. Woods, Digital Image Processing,

Addison Wesley Press
[ 121 P.E. Debevec and C.J. Taylor and J . Malik, Modeling and

Rendering Architecture from Photographs : A hybrid
geometry- and image-based approach, Proc. SICGRAPH
96, ACM Press, 1996, pp.11-20

[Figure 81 morphing image between different views
of the partially occluded objects

328

