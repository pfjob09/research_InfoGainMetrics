Dynamic Background Correction in 3Dt Body Surface Sensing & Visualisation
C.J. voore’, M Tornow’, P.J. Sharrock’, F. Lilley’ , M.J.Lalor2 and D.R.Burton’
North Western Medical Physics, Christie Hospital, Manchester, UK
2
Coherent & Electro-optics Research Group, Liverpool John Moores University, Liverpool, UK
Email: chris.moore @physics.cr.man.ac.uk

Abstract

derived from CAT scans of the patient at the earlier stage
of treatment planning. In terms of human dynamics, i.e.
the speed at which events would need to be logged and
visualised, it was thought that 3D imaging during the
approach stage would be more tractable than the critical
docking stage. This assumption was ill founded, ignoring
as it did the use of rapid, large angle rotation of the patient
once on the highly manoeuvrable treatment couch. Indeed,
dynamic surface effects arising from normal patient body
function such as breathing are relatively slow, a single
inspiration/expiration cycle of a few centimetres
amplitude taking approximately 5 seconds. In contrast the
initial manoeuvring of patients includes large angle
rotations and displacements larger than transverse body
dimensions within a few seconds. These produce gross
changes in the surface topology visible to any sensor.
The optical sensor used in this study utilises structured
light projection to measure the continuous topology of a
patient body surface and to follow any topological
changes. Specifically the spatial modulation of an
interferometer fringe pattern is captured in the video
stream emerging from a CCD-camera placed some metres
above and forward of the patient. An absolute reference
point is identified in the video frames using an additional
triangulation laser-spot, which is also projected onto the
patient. The changing fringe pattern in the video stream is
phase-analysed frame by frame to generate over 250,000
coordinates per frame across the entire surface of interest.
Each video frame contains data relating to the
modulated fringe pattern and the contrast variations that
make up the normal camera view of the patient’s body.
Since it is the fringe pattern alone that encodes the height
variations of the patient body surface the unwanted
contrast variations must be removed. Originally this
removal was implemented by electro-mechanically
‘washing-out’ the fringe pattern to produce even
illumination of the body surface and then grabbing a
single background reference image frame. The
background frame is then inverted and added to

The sensing and visualisation of 3 0 body sur$ace
inforniation is being researched f o r clinical use in the
radiation treatnietit of cancer, where accurate patient setup and positional nionitoritig is essential. Where 3 0
niecisurenietit is based ON the projection of structured light
onto the patient it is necessaiy to remove background
detail prior to extracting patient surface topology. Rapid
backgroiitid changes render a single pre-emptive
determination of background useless. Instead it becomes
necessaty to update background inforniation at videorates. This precludes disruptive pauses f o r the physical
collection of background data. This paper describes a
niethod of generating backgroutid data from the video
iniages of the structured light projection itself: Results are
presented to show that image franie processing that
includes a randoniised elenient of structural spreading is
the key to successfully itnplementing real-time
background correction.

1. Introduction
Curative radiotherapy using wide field, high energy Xray beams that are spatially conformed to the shape of
localised malignant disease has now moved from the
research domain into mainstream healthcare provision.
Accordingly the importance of gathering and visualising
patient positional information immediately before and
during irradiation has grown. To address this demanding
situation a unique, real-time, prototype opto-electronic 3D
dynamic-surface sensor has been developed to work in the
high-radiation environment of a radiotherapy treatment
room [ I ] . Using video-frame data produced by the sensor,
a dual phase 3D positioning strategy for patient set-up and
monitoring has been reported [ 2 ] . In this strategy an
image-guided manual ‘approach’ is followed by
automated ‘docking’ to a virtual shell, where the shell is

444
0-7695-1195-3/01 $10.00 0 2001 IEEE

subsequent fringe-frames to isolate the fringe pattern.
Close to ‘docking’ this strategy works well. However, in
clinical practice the patient gets on to a treatment couch,
which can then be raised a considerable height to the so
called ‘isocentric’ level and also rotated orthogonal to it’s
original floor level position. In the optical-sensor CCDcamera the rotation produces rapidly changing digital
views of the patient body surface that vary in just a few
seconds from nearly plan-view to side-elevation, see
Figure- 1 .
These manoeuvres suggest that fringe washout should
be used almost at every other video frame to generate a
new background image F x fringe pre-processing.
However, this would disrupt clinical set-up routines and
substantially reduce the rate at which 3D surface maps
could be generated. This paper describes an alternative
solution that is entirely compultationally based.

Figure 2
(Top-left)
Fringes on body shaped surface.
(Top-right) Single linear-spread processing.
(Lower-left) Dual linear spread processing.
(Lower-right) Noise reduction by convolution.
As can be seen from Figure-2, the randomised linearspread operator provides the required solution. This
operator randomly takes a pixel from one location in an
image and places it in another, guided by pre-selected
range limitations. The range limitation is simply the
typical fringe separation. Inevitably this increases noise
levels in the grey level data, so that a final smoothing
convolution operation is advantageous. To work
effectively the linear spread operations must be applied
approximately perpendicular to the fringe pattern itself. In
this application the fringes are projected parallel to the
left-right axis defined by the treatment machine coordinate
system. Consequently, even when modulated by patient
rotation the required fringe orientation is largely
maintained.
A dual pass, randomised spread operation was
implemented for practical use with the optical 3Dt-sensor
system installed at the Christie Hospital in Manchester.
The Research Systems IDL scientific visualisation
language, running on a UNIX Compaq Alpha-station was
used to prototype the approach. This was then ported to a
dual 1GHz-processor NT system used to drive the optical
sensor.
The 8-bit grey-scale data in an optical sensor video
frame are stored in 440x440 pixel matrices. A fringeimage shows the fringes themselves, background contrast

Figure 1
(Left) Optical sensor CCD-cameraview at fringe
washout of body shaped test surface.
(Right) Corresponding view when test surface is
rotated through right angle.

2. Theory and Implementation
Potentially, each video fringe-frame contains the
necessary contrast detail to lbrm a perfect background
image for near perfect correction by subtraction. On first
inspection it might be thought that simple low pass
filtering would be sufficient to remove the fringes and
leave the required contrast detail as a residual image.
However, deterministic filtering of this nature would
simply lead to artefact production when then filtered data
are subtracted from the original fringe-frame. A more
randomised approach is required that operates on single
points and does not reduce and continuously ‘smear’ grey
level information across local areas of adjacent pixels.

445

3. Results

detail on the body and lastly the laser triangulation spot.
Processing is in 3 stages (a) triangulation spot removal,
(b) randomised spread and (c) convolution blurring:
a.

The nearly symmetric triangulation spot is designed
to be the brightest feature in the fringe images and
must be removed prior to background generation. The
spot is of course replaced prior to subtraction and
Fourier phase processing. Thresholding pixels to a
grey level of 150 produces a number of clustered
points within the profile of the triangulation spot. The
centroid of these points is used to define the centre of
a rectangular area of bright pixels for deletion.
Propagating each of the four boundary pixels lines
towards the centroid and averaging the different
values contributing to each location then fills this
cleared area. The approach acts to preserve the
continuity of the underlying fringes. Specifically the
column oriented boundaries convey lefdright vertical
profile information from the underlying fringe
pattern, whilst the row-oriented boundaries are
aligned with the fringes and convey predominantly
bright or dark information, according to their location
in a fringe peak or trough.

b.

The fringe image array, dimension cols by rows is
randomly spread to destroy fringe structure. To do
this a vector ran, dimension rows, of random numbers
is created using a seeded, normally distributed
random number generator. A column of the fringe
image is then read into a spread array with the
elements appropriately shifted using the index
number in ran. In this case the IDL function
RANDOMN, with output range -6.0 to +6.0, is used.
Most of the random numbers returned from this
routine, when truncated to integers have values with
modulus 2 or less. However, fringes can easily be
more than 10 pixels wide (see Figure-3, lower right,
in which over 40 fringes are visible down the vertical
centre line). Accordingly, to ensure fringe peaktrough elimination, the random numbers are
multiplicatively scaled by a factor of 9.0 before being
truncated to integer values using the FIX operation.

c.

Finally, noise in the spread image is reduced by a 3x3
uniform, normalised convolution using routine
CONVOL.

Figure 3
Washout background (top left) removal leaves body
contrast 8, fringes (lower left). Spread removal (top
right) isolates fringes (lower right).
A volunteer was used to obtain a video frame sequence
showing fringed upper torso images with a 0-90-0 degree
bi-directional rotation, using a motorised couch in a
radiotherapy treatment room. The video sequence was
processed using a pre-rotation fringe washout background
image and then processed once again using spread based,
frame by frame correction. Figure-3 shows the video
frame at 90-degree rotation extracted a n d processed using
both washout and spread background correction. It is clear
that the latter provides effective fringe isolation and
background correction. The effect of the entire rotation
video sequence is shown in Figure-4, where 3D
processing has been applied to raw data frames at
approximately 0, 45 and 90 degrees. The upper sequence
shows the progressive failure of washout based correction,
until shortly after 45 degrees there is a total loss of 3D
capability. The lower sequence shows the success of the
spread-based correction. The extreme lower right image in
Figure-4 corresponds to surface height extraction from the
lower right hand fringe image shown in Figure-3. Note the
peripheral
areas
of

446

Figure 4
Live patient imaging showing raw, 3D dynamic optical sensing of rotating chest & shoulder detail.
(Top: left to right) Progressive failure of fringe-washout background correction for 0, 45 & 90 degrees.
(Bottom: left to right) Linear spread based dynamic background correction for 0, 45 & 90 degrees.
indeterminate height at the extreme edges of the 3D data
sets. These are due to the lack of any fringe information,
and can be removed for clinical applications by assigning
a ‘no data’ mask to the fringe frame.

mechanical vibratiodflexing of the treatment couch
supporting the patient. From the Figures above it is clear
that these also have an impact on the customisation of
underlying filtering operations used to extract phase from
the optical sensor video frames, particularly during rapid
rotation where classic ‘ringing’ is visible. These ringing
effects are exaggerated by the severe rendering conditions
used to display 3D surface topology.
Some issues surrounding the use of spread based
correction also warrant further investigation. Any
randomised processing will inevitably produce higher
noise levels in the background correction image. How this
translates into increased errors in the 3D-surface images is
of some importance. Errors that are less than a millimetre
are tolerable, since in radiotherapy applications the
primary alternative source of information about a patient
body surface is usually derived from contours extracted
from CT scanning images. Here pixels represent
in cross sectional slices,
approximately 0.8”‘
corresponding to a 512x512 pixel matrix over a whole

4. Discussion
At one stage the possibility of electro-mechanically
washing out the fringe pattern at every other frame to
produce a sequence of background correction images had
been considered. However, even where there is normal
body motion, let alone gross rotation, background
correction by subtraction of fringe washout images
displays substantial artefacting. This is partly due to the
millimetre scale change in sharp features that can occur
within a time frame approaching one tenth of a second.
Minor body shift, heartbeat and respiration are all sources
of such motion. However, perhaps the most important
source of motion mitigating against washout correction is

447

6. References

body field of view. Moreover, CT images are never
dynamic, and tend to be acquired over a second or more
because of scanning hardware limitations. They also
, include partial volume effects that average body contour
changes over several millimetres of body length.

[ l ] Lilley F, Lalor M J and Burton D R, “A Robust Fringe
Analysis System for Body Shape Measurement.” Optical Eng,
39, 1, 2000, pp. 187-195.
[ 2 ] Moore C J and Graham P A, ‘3D Dynamic Body
Surface Sensing & CT-Body Matching A Tool for Patient
Set-up & Monitoring in Radiotherapy’, Jnl Computer
Aided Surgery, Special Edition on Planning and ImageGuidance in Radiation Therapy, Vol 5, No 4, 2000,
pp.234-245.
..

5. Conclusion
A randomised image processing method for
background correction has been demonstrated for use in
real-time 3D surface sensing in radiotherapy. The method
is clearly effective even for the extreme changes in surface
presentation caused by large angle rotations and
displacements of the patient body surface during initial
positioning for treatment. With this development real-time
dynamic 3D imaging under extreme conditions of patient
motion becomes a practical possibility.
,

7. Acknowledgements
This work was partly funded by the EC Framework IV
BIOMED 2 programme, project ARROW, contract
number BMH4-CT98-3660.

448

