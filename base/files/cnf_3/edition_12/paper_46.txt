Multiresolution Image Morphing in Wavelet Domain
Paul Baoat
Dan Xub
"Department of Computing,
The Polytechnic University of Hong Kong, Kowloon, Hung Hom, Hong Kong
Email: csbao@commDolvu.edu.hk Tel. 852-27667266 Fax 85227740842
bState Key Lab. Of CAD & CG, Zhejiang University, Hangzhou, Zhejiang, P. R. China, 310027
radiometrics [8], and hence so is the intermediate
images, view morphing emphasizes the physical
reasonability, which means that the intermediate
images should be shape-preserving. In other word,
the results of view morphing should be same as the
projective rendering mosaics from different
viewpoints. View morphing algorithm can be
summarized as a three-stage process: first, the prewarp source and destination images are pre-warped
into canonical configuration in the sense that the two
image planes are parallel and corresponding points
satisfy the scanline property. Second, intermediate
images are generated by the image morphing
techniques. Third, the intermediate sequences are
post-warped into the original configuration.
Compared to other IBMR methods, view morphing
possesses the following advantages: very few
reference images are required and no geometry
information may be needed.

Abstract
This paper presents a new view synthesis technique
using the 2 0 discrete wavelet-based view morphing.
The view morphing is completely based on painvise
images without the camera calibration and the depth
information of images. First, the Fundamental Matrix
related to any pair of images is estimated. Then, with
the fundamental matrix, the pair of image planes is
rectified to be parallel and their corresponding
points lie on the same scanline, which gives an
opportunity to generate new views with linear
interpolating techniques. The pre-warped images are
then decomposed into hierarchical structure with
wavelet transfoim. Corresponding coeffcients
between two decomposed images are therefore
linearly interpolated to form the multiresolution
representation of an intermediate view. Quantization
techniques [10,11] can be embedded here to
compress the coeffcients to reduce the morphing
complexity. Finally, when displaying, compressed
images are decoded and inverse wavelet transformed.
A post-warping procedure is employed to transfom
the interpolated views to its desired position.

Image morphing is a well-received technique that
generates a sequence of in-between images such that
the source image is gradually changed into the
destination image. The main problem in image
morphing is to derive a set of warping functions from
specified corresponding features in the source and
destination images. The warping functions are 2D
geometry transforms that distort the source image
towards the direction of the destination image, and
vice versa. The two distorted images are then crossdissolved by properly interpolating their positions [7]
and radiometric [8].

Keywords: Image morphing, Interpolation, Wavelet
transform,
Multiresolution,
Virtual
reality,
Progressiveness

1. Introduction
View morphing [I], proposed by Seitz and Dyer in
SIGGRAPH'96, introduces a new IBMR (Image
Based Modeling and Rendering) method via image
morphing technique. Different from the traditional
image morphing concept where the two reference
images may be very dissimilar in shape and

Mesh-based and field-based morphing are two
commonly used image morphing methods. In the
former approach, features are specified as a nonuniform control mesh, and a warp function is

'All the correspondences should be addressed to Prof. Paul Bao, Dept. of Computing, The Hong Kong Polytechnic
University, Hong Kong

309
0-7695-0743-3\00
$10.00 0 2000 IEEE

example, by Vector Quantization. When
displaying, they can then be decoded quickly.
4. Reconstruction: inverse wavelet transform is
performed to generate new rectified views. The
final views with correct position, orientation and
radiometrics can be made through a postwarping process.

computed by a Spline interpolation. The
disadvantage of the approach is that the controlling
mesh at each step is complicated. The latter approach
provides an easy-to-use interface to specify features,
which are pairwise line segments in the source and
the destination respectively. Each line has a field of
influence. A warp is computed by taking the
weighted average of the influences of line segments.
Both of the approaches are very time-consuming. The
computation time is proportional to the image
resolution as well as the number of features. In
addition, they suffer from influence of high
frequency noise near the features. To accelerate the
performance of the morphing and de-noise the
influence near the features at the same time, wavelet
transform is a good approach for its multiresolution
structure and nice features in both spatial and
frequency domain. There has been some work on 3D
metamorphosis in frequency domain. For example, in
[ 5 ] , Wang and Arie introduced a wavelet-based
volume morphing method to realize smooth transition
between two volumetric data sets. Also, the Fourier
transform has been used for volume morphing [6].

3. Epipolar Geometry And Fundamental
Matrix
Since we concentrate on the uncelebrated cameras,
the only information available is the images
themselves. This is of great practice in applications
where camera parameters may vary due to different
conditions of image generation or may not be
available at all. Based on the knowledge on stereo
vision, the geometric relations between two cameras
are described in projective terms rather than in
Euclidean. This epipolar information is entirely
contained in a 3x3, rank 2 matrix, called the
Fundamental Matrix [2,12,13]. It is the key concept
for image measurements as it contains all the
geometrical information correlating two different
images. To estimate fundament matrix, F, we need to
know the correspondence between two images. We
may interactively specify eight or more
corresponding feature points instead. For a given
point m in the first image, the projective
representation I’ of its epipolar line in the second
image is given by
1’= Fm
(1)
Since the point m’ corresponding to m belongs to
the line 1’ according to epipolar geometry, we have
mF‘m=O
(2)
Therefore, the parameters of F can be estimated by
linear least-square method or nonlinear method
relying on relation (2). We employ a linear method to
fit an initial matrix F,, and then use the non-linear
iterative method to fine-tune a more stable and
accurate solution of F.

In this paper, we propose a fast view morphing
method based on wavelet transform. This method
preserves all the features in both spatial and
frequency domain, while gaining a significant
improvement in performance compared to spatial
domain morphing.

2. Wavelet Domain View Morphing

Our approach, which can be viewed as an extension
of View Morphing [ 11, consists of the following four
steps:
Suppose that I, and 12 are two reference images.
Rectification: two transformation matrixes H I
and H2 are found so that Hill and H212 have
parallel image planes and the corresponding
points are on the same scanlines, i.e. their y
coordinates are the same. This process
guarantees that the interpolation be linear and
shape-preserving.
Image morphing in wavelet domain: the two
rectified images are first decomposed into
pyramid structure by 2D wavelet transform.
Next, using interpolation techniques to construct
the coefficients of new views level by level.
Coefficients coding and decoding: wavelet
coefficients can be quantizated to reduce the
complexity and storage requirement, for

To rectify the known image pair, we need to search
for two transformations HI and H2 such that the two
warped images satisfy the scanline property. As
described in [2], the necessary and sufficient
condition that two images are properly rectified is
that their fundamental matrix has the form:

0 0
F = I

]:

0
(3)

which is up to a constant scale. In [ 2 ] , Beier and
Neely introduced a method to search for the

310

rectification transformation H I and Hz, based on
epipolar constrains of F.

g(n)

= H(-n),G(n) = G(-a) are low-pass and
high-pass filters respectively, which impulse
response is defined as:

4. Wavelet Transform

H ( n ) =< 2-’@(2-’u),45(u- n ) >
G(n)=< ~ - ’ I , Y ( ~ - ’ U ) , V / ( U - n ) >

Wavelet transform has been widely used in
computer graphics, such as surface modeling,
radiosity, raytracing, texture mapping, volume
visualization and image compression. Wavelet
transform possesses a nice feature in localizing image
information in both spatial and frequency domain. In
addition,
wavelet
transform
provides
a
multiresolution hierarchical structure to image
representation: it decomposes a function into a
smooth approximation of the original function and a
set of detailed information at different resolutions
[5,9,10]. This leads to the progressiveness of the
wavelet-based image processing techniques. In this
section, we will brief wavelet transform and 2Dwavelet multiresolution decomposition.

E

Due to the spatial localization properties of
wavelet, it is possible to exploit traditional field
morphing method in each of the subband images in
the of wavelet domain. We need to locate positions of
all the feature lines.

5.1. Energy Distribution of a Point
A simple way to determine the feature lines of
source and destination images in the wavelet domain
is to scale coordinates of x- and y-direction of the
features by a factor of %.

L ~ ( R at
> any resolution 2’ is a projection

Unfortunately, experiments show that not all
wavelets preserve this spatial property because DWT
is not a point-based transform, but a vector-based
transform. Therefore, each coefficient in wavelet
domain may be influenced by many pixels in image
space relying on the length of band-passing filters.
On the contrary, each pixel in image space will
contribute to many coefficients in wavelet domain. In
other word, we must know the distribution of energy
of a point after wavelet transform. Figure 1 illustrates
the energy distribution of a point under different
wavelet transforms. We transform an image with
only one point into wavelet domain and observe its
energy distribution. The higher the energy of a
coefficient, the darker it shows.

denoted as: A : L2 ( R ) + V2,, V2, E L2 ( R ) , and
,

2’

the detail of f at any higher resolution 21 is a
projection of f onto a subspace 0 of L2 ( R ) ,
,

2’
) 0 , j > i . We can
which is denote as p :L ~ ( R+
2’

2’

properly select the projection functions such that
0 .are orthogonal to each other and V . For
,

2’

2‘

discrete functions, there are two sets of functions,
which constitute the orthogonal basis of V . and
2‘

0 , respectively. We call them wavelet function
,

2’

and scaling function denote as:

wj,, = 2 - ’ f 2 ~ ( 2 ’ -t n)neZ

(4)

Note that wavelet transform introduces negative
coefficients, so the coefficients in the wavelet domain
have been absoluted. Even so, some influenced
coefficients are not visible because their energies are
too low and can be neglected. As shown in figure 1,
the shorter the filter, the nearer the energy
distribution is collected to the ideal position whose
coordinates are equal to that of the point in image
space scaled by a constant of ?h level by level.
Inversely, the smoother the wavelet, the larger the
regions of energy influenced. Also note that these
regions may be disconnected.

(5)
~ p ~ , ,= 2-’f2@(2Jt
- n),,z
Using these two functions? the discrete signal and
approximation resolution 2’ are respectively defined
as:

(q,
f)= 2-”*

<f(4,v/j,, >
(A$ f ) , = 2-J‘2 < f ( ~ > , @>~ , ,

(9)

5. Morphing In Wavelet Domain

Formally, the smooth approximation of a function

f

(8)

(6)

(7)
Instead of calculating the inner products in equations
6 and 7, a pyramid algorithm is applied for the
decomposition of the function. For 2D discrete image
functions, this algorithm is applied sequentially along
each dimension, where

5.2. Feature Lines of Different DWT

311

for each line and each end point of it
I . Transform the point image into a particular
wavelet domain, which size is the same as
that of the source and the destination.
2. Select four new points from approximated
band and detail bands respectively to
represent position of current considered end
point.
3. In each subband, create a new line segment
corresponding with current processing line.
end %for line
end %for level

So far we have observed that different wavelet
selection may influence the determination of
positions of feature lines in baseband as well as detail
bands. To obtain feature lines accurately and
adaptively, we design a simple algorithm that can
quickly determine new positions consistent with the
original line positions in the sense that the new
control point of a line would not be selected at a
unreasonable position.

:E
10

10

10

m

20

30

30

40

40

50

20

30

40

.

.

.

.

50

There are several criteria to select control points of
the new lines from non-zero coefficients of the DWT
transformed point image in different subbands, such
as selecting position of minimum energy, maximum
energy, energy mean, and absolute maximum energy
coefficients. Our experiment shows that the criterion
based on the absolute maximum energy coefficients
(i.e. selecting the darkest point as new feature control
point) leads to the best search performance.

60

5.3. Warping of the Wavelet Coefficients

50

I
60
10

:I

20

30

40

50

60

10

20

30

40

50

60

Figure 2. Sequence of transition from the first to the
last

I

Once we have determined four new sets of feature
lines in each subband and on a specified level, it is
obvious that we can compute wavelet coefficients to
generate the distorted source or destination images by
directly applying field morphing algorithm in wavelet
domain. In-between images are obtained by
interpolating values of wavelet coefficients of the
distorted source and destination, and then
transforming by the inverse wavelet the in-between
images to the image space. Figure 2 shows a
sequence of in-between images, the first and last
image are the source and destination respectively.

I

.i
10

M

30

40

50

60

~~

10

20

30

40

50

60

Figure 1. Energy distributions of a point with
different wavelet transforms

Feature lines search algorithm:
for each multiscale level

3 12

The source images are obtained from Seitz’s
database.

level. The morph can be progressively refined level
by level. This feature is very suitable for distributed
and web-based image and video applications,
especially for distributed and Internet IBMR
applications. Second, with the rich and effective
wavelet-based image compression techniques [9,11],
a compression scheme may be embedded in wavelet
domain, such as GFA. This would reduce a large
number of data transmitted and the decoding and
rendering can be performed at the receiver side.

6. Reconstruction and Progressiveness
In the previous sections, we have discussed how to
generate the multiscale representation for interpolated
views in wavelet domain. In this section, we will
address the issue how the views are reconstructed
from the hierarchical representation.

7. Experiment
Compared with field image morphing, waveletbased image morphing can accelerate morphing
process because wavelet analysis can be viewed as a
sub-sampling of the original image and it is known
that field morphing algorithms depend on the
resolution and the number of feature lines. Also,
since DWT transforms images into the frequency
domain, some frequency-based analysis can be
embedded, such as quantization [9], thresholding
[Ill, de-noising, etc. An interesting effect that can
not obtain from the spatial image domain based
morphing method was mentioned in [3]; that is
changing the transition rate of different frequency
bands. For example, we can let the low frequency
band change quicker and high frequency band
slower, or vice versa. An experiment result is shown
in figure 3. It is known that high frequency part of an
image corresponds to the detail of the image. On the
other hand, low frequency part is related to the global
information of the image. So varying transition rate
of different frequency bands, we can obtain some
progressive effect.

To reconstruct the intermediate views in the image
space (spatial domain), we need to inversely
transform the morphed images from the wavelet
domain to the spatial domain and then transform
these images from the canonical configuration to the
original coordination system.
A simple but effective approach for this is to select
four control points of a quadrilateral in two original
images separately, and then linearly interpolate the
intermediate quadrilaterals. Any two quadrilaterals
can derive a transformation, which warp one image
into the shape of another. Therefore, two original
images are warped toward a same intermediate image
and then cross-dissolve the radiometric to generate
the final morphed images.

6.2. Visibility Analysis
Due to the varying of viewpoints, some points of
the scene may become invisible in some views. This
gives rise to the problems of holes and folds
appearing in the synthesized images. A fold is caused
when multiple points are projected to the same
position. It is relatively easy to be resolved. The
common method is using Z-Buffer techniques.
Whereas holes are more difficult to be resolved
because we may have insufficient information at the
hole position in either of the two original images.
Traditional method uses known neighboring points
for interpolation; however, it usually gives “ghost”
appearing in the synthesized image. In our approach,
we try to recover a conceptual surface, which can be
used to predict the information at holes and folds.

A disadvantage of wavelet based image morphing
is that the quality of the morphed images are not as
good as that of traditional method. This accounts for
subsampling of DWT, but not wavelet itself. We
compare our results with the half size image
morphing result from traditional field morphing
algorithm and find that the results are the same. To
improve quality of the wavelet-based morphing, we
may replace the high frequency of wavelet morphed
images with its corresponding high frequency part of
traditional morphed images. An alternative method is
to zoom in the original image and then select feature
lines to generate a more accurately specification. Of
course, we can also get feature lines via an animator.

6.3. Progressiveness of the Wavelet Domain
Morphing

8. CONCLUSION

Our view morphing scheme possesses a nice
feature for distributed and web-based applications.
First, with the multiresolution property of wavelet
transform, we can obtain a coarse morph on the top

In this paper we describe an effective view
morphing method, in which the main image

313

processing was performed in the wavelet domain. We
discuss the influence of using different kinds of
wavelet. We also give different strategies with
respect to different wavelet families. Our method
requires no camera calibration, which is superior for
the IBMR system and communication applications.

[12] D. Xu & P. Bao, Wavelet-based Progressive

View Morphing, Visual Communications and
Image Processing’99, 3653,613-619(1999).
[13] Bao, P., & Xu, D., Image-based Scene
Representation Using Wavelet-based Interval
Morphing, SPIE Proceedings, Modeling and
Simulating Sensory Response for Real and
Virtual Environments It, Vol. 3694, pp. 164172, April 5-9, 1999, Orlando

ACKNOWLEDGMENT
This work is supported by the Hong Kong
Polytechnic University research grant #S723.

REFERENCE
S. Seitz & C. Dyer, View Morphing,
SIGGRAPH’96, Computer Graphics, 21-30
(1996).
T. Beier and S. Neely, Feature-based image
metamorphosis, SIGGRAPH’92. Computer
Graphics, 26(2), 35-42 (1992).
G. Wolberg, Digital Image Warping, IEEE
Computer Society Press, (1990).
T. Nishita, T. Fuji and E. Nakamae,
Metamorphosis using
Bezier clipping.
Proceedings of the First Pacific Conference on
Computer Graphics and Applications, Seoul,
Korea, World Scientific Publishing Co., pp.
162-173 (1993).
T. S. He, S. Wang and K. Arie, Wavelet-Based
Volume
Morphing.
Proceedings
of
Visualization ’94, Washington DC, IEEE
Computer Society Press, pp. 85-92 (1994).

Figure 3. Morphing result using biorthogonal
wavelet: Spline (l,l),Spline (3,3) and Spline (3,9)

3. F., Hughes, Schedual Fourier Volume

Morphing.
SIGGRAPH’92,
Computer
Graphics, 43-46 (1992).
S. E. Chen and L. William View Interpolation
For Image Synthesis, SIGGERAPH’93,
Computer Graphics, 279-288 (1993).
S. J. Gortler, R. Grzeszczuk, R. Szekiski and
M. F. Cohen, The Lumigraph, SIGGRAPH’ 96,
Computer Graphics, 43-54 (1996).
J. M. Shapiro, Embedded Image Coding Using
Zerotrees of Wavelet Coefficients, IEEE Trans.
Signal Processing, 41(12), 3445-3462 (1993).
P. Bao, & D. Xu, Complex Wavelet-based
Image Mosaics using Edge-Preserving Visual
Perception Modeling,
Computers and
Graphics, 23(3), June (1999)
P. Bao, & B. Leung, Wavelet Transform Image
Coding based on Visual Perception Modeling,
Proceedings of SPIE Conference, Wavelet
Application II, 3390, 643-654, Orlando, April
(1998

3 14

