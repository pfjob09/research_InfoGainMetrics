Character Recognition of Arabic and Latin Scripts
Dr FIAZ HUSSAIN

Dr JOHN COWELL

School o f Information Tetlinolony,
-_
Dubni Polyteclinic,
PO Box 1457, Dubai,
United Arab Emirates (UAE).

Devartment o f Comuuter & Information Sciences
De Montfort University,
Kents Hill Campus, Milton Keynes, MK7 6HP,
England.

email: fhussain@dubaipolytechnic . com

email: jcowell@dmu.ac.uk

1

Abstract
The goal to produce effective Optical Character
Recognition (OCR) methods has lead to the
development of a number of algorithms. The
purpose of these is to take the hand-written or
printed text and to translate it into a
corresponding digital form. The multitude
requirements and developments are well
represented in the literature (see for example
Abuhaiba [I] and Suen [2]).

and feature extraction. El-Sheikh and Guindi [5],
on the other hand, provide an insight to
representing isolated Arabic characters; whilst
Amin and et a1 [6] discuss an approach for
recognising hand-written Arabic words and
sentences. This paper concentrates on catering
for isolated characters (and numbers) for Latin
and Arabic, whilst later work will focus on the
recognition of complete words and sentences.
Typical character recognition algorithms often
use time consuming approaches such as thinning
the character to be recognised, for example
Deutsch[7], Stefanelli[8] and more recently by
researchers such as Chouinard[9]. There are
numerous problems associated with this
approach and further processing is required if the
size or orientation of the characters is not known.
The multi-stage algorithm described recognises
characters by comparison between the character
and a set of templates. The characters are
normalised for size and orientation to produce a
robust recognition system which can recognise
both Latin and Arabic (or other) character sets
without modification, all that is required for each
character set is a set of templates which can be
generated in minutes. The system measures the
closeness of fit between the input character and
any member of the set of templates. The higher
the degree of closeness, the more likely it is that
the character has been successfully recognised.

The primary objective of this paper is to provide
an insight into a robust system which has been
successfully developed and employed to
recognise Latin and Arabic characters and
whose workings has been described by the
authors in a sister publication [3]. The focus
here is to discuss the main components used in
the multi-stage system, paying particular
attention to the normalisation process used for
orientation and size for a given bitmapped
character. The effectiveness of the approach is
demonstrated through its workings for the Arabic
and Latin case, both ,for characters and numbers.

Keywords: Arabic, fonts, Latin, normalisation,
OCR, pattern recognition, confusion matrix.

1.0 Introduction
The topic of OCR is not new. A number of
authors have addressed the area, focussing
particularly on Latin characters. For the Arabic
case, notable contribution has been made by
Amin [4] who gives a review of the subject,
touching the areas of handwriting recognition

To aid flexibility and to examine the different
stages of the algorithm more closely, we have
sub-divided the recognition process into a set of
well defined stages:

51
0-7695-0743-3/00$10.00 0 2000 IEEE

.

+

+

+

+
+
+

comparing every edge pixel against every other
edge pixel for the given bitmapped form. An
edge pixel, here, is defined as one that is black
but has one or more adjacent white pixels,
including diagonally adjacent white pixels (that
is 8-connectedness rather than 4-connectedness).
The line defined by these two points is used to
represent the new vertical axis of the normalised
character. The horizontal axis of the new coordinate frame is at right angles to this axis and
the point of intersection (0,O)of both axes is the
lowest edge point. This defines fully the new coordinate frame.

Scan the input character for a bitmapped
form
Normalise the bitmapped form for orientation
Filter out any white pixels as an effect of
changing the co-ordinate frame
Normalise the re-orientated version for size
Compare the normalised version with predefined set of definitions
Output best match

In this paper, we focus on the two normalisation
phases. These, in essence, transform the input
image to a new set of co-ordinates and size, such
that whatever the original shape and size of the
character, the same normalised form is produced.
This normalised form is such that it can be
compared directly to the stored template
definitions. It also provides the attraction that the
system will return a hit regardless of the fact that
the input character has changed orientation or
size. The next section provides an insight to the
approach used for the normalisation for
orientation, whilst section 3 gives an outline for
the normalisation for size. In each case, the
success of the approaches is shown for the Latin
and Arabic case, both for characters and
numbers. Strictly speaking, the numbers used in
the Latin context are in fact Arabic, and the
numbers employed in the Arab world should be
called Hindi. For reasons of clarity, however, in
this paper, we will reference numbers as per their
respected character sets. Section 4 shows the
operation of the system for sample inputs, and
the discussion is completed through some
conclusions and proposed further work in section

To normalise the bitmapped character for
orientation, it is rotated about the intersection of
the axes so it can be mapped onto the new coordinate frame. This is achieved by multiplying
every pixel of the character by the direction
cosines of the new co-ordinate system. Figure 1
shows an illustration of the process for the Latin
character “S”, number “Seven”, and for the
Arabic character “Seen” and number “Three”.
Effectively, the normalisation approach would
cater for any bitmapped outline, besides the
Arabic and Latin cases.
Column two, in Figure 1, shows the result of
rotating the given images onto the new coordinate system. What this also depicts is a
problem that often arises when transforming
bitmapped images. In this case, the distortion is
in the form of white pixels appearing within the
black character as a result of rounding errors in
the rotation calculation. These may be single
pixels, or occasionally pairs of pixels. These are
straightforward to remove by converting all
white pixels (enclosed by black pixels) to black.
The approach here makes use of an 8-connected
rather than 4-connected format.

5.
2.0 Normalising for Orientation
Once a character bitmapped image of the input
has-been gained, it is then mapped onto a new set
of axes using structural information inherent in
the shape of the character being recognised. This
is realised by evaluating the longest chord that
can be drawn between any pair of pixels forming
the character outline. The outline consists of a
series of edges. The longest chord is gained by

3.0 Normalising for Size
The normalised for orientation image, having
been cleaned so that it does not contain white
holes, next goes through another transformation.
This time it is for size so that it correlates with
52

the stored definitions. In this case, a pixel frame
of 100 by 100 is being used so that the longest
horizontal and vertical chords is transformed to
match with this.

identification process, however, is the same for
all four sets: Each figure is compared with all the
members of a set. The results for each
comparison are recorded and expressed as a
percentage. The highest percentage value
returned by a comparison is deemed to indicate
(that is, to recognise) the input figure. One
benefit of this approach is that we do not simply
get a recognised output, but also a good
reflection of what level of confusion is
embedded in the process. This way, we gain
knowledge of likely candidates for misinterpretation and can take steps to minimise
their effect. Details of how the matrix of
confusion (the “confusion matrix”) is produced
and applied to the recognition process can be
found in a follow-up publication. by the authors’

There are some practical problems in expanding
images by a non-integer factor: First, the
character is translated so that its left-most pixel
touches the zero point of the vertical axis. Then,
the bottom-most pixel is extended so it touches
the zero point of the. horizontal axis. If the
existing maximum width and height of the
character is x and y, and it is to be normalised to
a width and height of 100, the new co-ordinates
of a pixel at (XI,y1) are (new-x, new-y) can be
calculated as: new-x = x1 x lOO/x and new-y =
y1 x lOO/y.

Dol.
When the size of an image is expanded each
pixel in the original image may represent more
than one pixel in the new image. The size of the
area occupied by a new pixel in the normalised
image is lOO/x, lOO/y. This is unlikely to be an
integer and as such the resultant mapping yields
an element of distortion in the image. In the
implementation, fractions are rounded-up to the
next integer. Figure 2 shows the effect of this
process for the samples used in Figure 1,
together with the outcome of filling-in the white
holes.

Figure 3 shows the interactive interface of the
recognition system prototype. At this stage, we
simply input the “name” of the character or
number that requires to be recognised. The
system responds by locating the bitmap for the
input, which is shown in the first output window
in Figure 3. The recognition process then follows
the mentioned phases. Looking at Figure 3, from
left to right, the output windows display the
following:

Open and Find Axes Locate bitmap and
calculate new co-ordinate frame
Rotate Convert the bitmap to the new coordinate frame
Tidy Fill any white holes produced during
re-mapping
Normalise Scale re-mapped bitmap to fit 100
by 100 pixel bitmap
Identify Closest match from known set of
figures

4.0 Recognising Characters
Having normalised for orientation and size, the
next phase of the recognition process compares
this transformed image with a set of established
definitions.
Here, the four unique sets
(characters and numbers for both Latin and
Arabic) are used. These act as the knowledge
base for the search engine and have been created
with known facts of the characters and numbers
to be identified.

Since the text data is still limited, the system
currently returns a matching of 100% when a
character has been identified. Once the work is
extended to cater for hard (real) inputs, scannedin images, the percentage value will no doubt be

Since we are attempting to recognise a single
figure belonging to one of the four possible sets,
and to improve efficiency, the algorithm works
with only one set at a time. The actual
53

lower. As the text box in Figure 3 implies,
however, the system will always return an output
that has the highest relative value. This way, we
are not looking for a perfect fit, but of a best-fit
solution.

Cowell, J., and Hussain, F., A Mulit-Stage
Algorithm for Character Recognition,
Proceedings: GITIS 2000 Conference,
Chamber of Commerce & Industry, Dubai,
UAE, pp 140-146, March 2000.

It is also worth noting that in its current form, the
recognition takes about 2 seconds per character.
This can be reduced many times (at least by a
factor of 10) since in its present form it is a
research tool and every stage of the recognition
process is written out to a file which has a
detrimental effect on the conversion speed.

Amin, A., OfSine Arabic Character
Recognition, Pattern recognition, vol 3 1, no
5 , 1998, pp 517-530.
El-Sheikh, T. S., and Guindi, R. M.,
Automatic Recognition of Isolated Arabic
Characters, Signal Processing, vol 14, 1988,
pp 177-184.

5.0 Conclusions
Amin, A., Masini, G., and Haton, J. P.,
Recognition of Handwritten Arabic Words
and Sentences, Proceedmgs: Pattern
Recognition Conference, Montreal, Canada,
pp 1055-1057,1984.

This paper has detailed two processes necessary
for a flexible approach to character recognition.
These are normalisation for orientation and size.
The discussion has looked at the workings of
these, in context with the overall system, for
characters and numbers belonging to both the
Arabic and Latin sets. Although the approach
used is such that it could be adapted in minutes
to deal with a range of other character sets. This
work is on going and as such requires further
research and development to improve the overall
efficiency and the broad nature of the recognition
system.

Deutsch, E., S., Thinning Algorithms on
Rectangular Hexagonal and Triangular
Arrays, A.C.M., vol 15, part 9, 1972.
Stefanelli, R; and Rosenfeld, A., Some
Parallel Thinning Algorithms for Digital
Pictures, Journal Assoc. Computing
Machines, vol 18, no 2, 1971.

6.0 References

Chouinard, C., and Plamondon, R., Thinning
and segmenting handwritten characters by
line following, Machine Vision and
Applications, vol5, no 3, pp 185-197, 1992.

111 Abuhaiba, I., S., I., Mahmoud, S., A., and
Green, R., J., Recognition of Handwritten
EEE
Cursive
Arabic
Characters,
Transactions on Pattern Analysis and
Machine Intelligence, vol. 16, no. 6, 1994,
pp 664-672.

PI

[ 101 Cowell, J., and Hussain, F., The Confusion
Matrix - Identifying Conflicts in Arabic

and
Latin
Character Recognition,
submitted for publication at the British
Machine Vision Conference, Bristol, UK,
September 2000.

Suen, C., Y., Character Recognition by
Computer and Applications, Paper from
handbook of pattern recognition and image
processing, Ed: Young T.Y. 1986.

54

New vertical axis

a) LATIN - Character “S”

co-ordinate frame
New horizontal axis

b) ARABIC - Character “Seen”

New vertical axis

New horizontal axis
New vertical axis
c) LATIN - Number “Seven”

7

(0,O)ofne
co-ordinate fr
New horizontal axis
New vertical axis

d) ARABIC - Number “Three”

co-ordinate frame
New horizontal axis

Figure 1 Depicts the working of the normalisation process for the four cases shown, where the original
character is re-mapped onto a new co-ordinate system (as manifested in the second column of images).
55

s

I

Figure 2 Shows the effect of removing the white holes after normalisation for orientation and the resulting
100 by 100 pixel-scaling normalisation

Figure 3 Demonstrates the working of the recognition system (for the four cases shown) through a set of
phases labelled as: Open and Find Axes, Rotate, Tidy, Normalise and Identify.

56

