Video-Based Camera Registration for Augmented Reality
Ebroul Izquierdo
Department of Electronic Engineering
Queen Mary and Westfield College
University of London
London E l 4NS, United Kingdom
e-mail: e.izquierdo@elec.qmw.ac.uk

Valia Guerra
Group of Numerical Methods
Institute of Mathematics, Cybernetics and
Physics
Havana, Cuba
e-mail: vguerra@cidet.icmJinJcu
the user a realistic impression [ I , 3, 4, 71. Clearly, this
process requires accurate registration between the scene
and the synthesised environment. Currently, there exists
a large collection of application domains for these key
technologies including: entertainment, education,
medical imaging, augmented reality, immersive
telepresence, etc.
In this paper a novel stereo vision based camera
registration technique for the composition of natural and
computer generated images is presented. Camera
calibration is necessary to maintain accurate registration
between the video objects and the virtual environment.
The major shortcoming observed in image based
augmented reality and telepresence systems is the
extreme lack of robustness due to the ill-posed nature of
the calibration problem. Usually, calibration is
performed in two steps: correspondence estimation and
determination of the camera-scene geometry by
calculating the essential or the fundamental matrix. To
carry out these tasks several methods can be found in
the literature [2, 91. Nevertheless, most techniques are
either based on computational expensive nonlinear
models, or they are unstable when a linear model is
used. To overcome these drawbacks we propose to
combine the efficiency of linear methods with suitable
regularization techniques. The presented technique
relies on the definition of an appropriate parametric
linear optimization problem. Then, the optimal
parameters are sought in the solution space defined by
physical meaningful constraints. Solving the underlying
regularized linear problem the above mentioned
drawbacks can be overcome.

Abstract
In this paper a video-based approach for camera
scene registration in augmented reality systems is
presented. The presented technique relies on the
definition of a model, which is derived f.om an
appropriate parametric linear optimization problem.
The optimal parameters are sought in the solution
space defined by physical meaningfiul constraints.
Solving the underlying regularized linear problem we
expect to overcome the major shortcoming observed in
image-based augmented reality and telepresence
systems: the extreme lack of robustness due to the illposed nature of the calibration problem. Several
computer experiments have been conducted in order to
assess the performance of the introduced technique.
Keywords: Camera Calibration, Augmented Reality,
Disparity Estimation, Regularization.

1.

Introduction

Conventional augmented reality systems combine
real objects and virtual worlds using sensors to
determine the location of the viewer (or camera), the
display and the real world. These techniques require
special equipment like magnetic field detectors, radio
frequency and acoustic signals, etc., to track and
measure the position of different objects involved in the
process. Computer vision based approaches offer a
potential for accurate registration and augmented reality
generation avoiding the use of costly equipment. This
process is carried out by analysing images acquired
from cameras at different locations. The goal is to
recover the camera location with respect to the scene
and to use this parameters to estimate the scene
structure. The 3D structural information is then used to
rotate and render video scenes according to the eye
position of the viewer or the position of a virtual
camera. Such a system would be able of compose views
of real scenes with any graphical environment giving to

2.

Let us assume two perspective images of a rigid
scene. The extemal camera geometry and optics of most
cameras can be represented accurately by employing a

499
0-7695-0743-3/00 $10.00 0 2000 E E E

The Stereo Rig and the Epipolar
Geometry

simple pin-hole camera model. Let

(x,
Y ,2) be the

epipolar planes form a pencil of planes through
(0,
and the epipolar lines form two pencils of

,or)

3D coordinates of a visible point
of the scene in the
camera coordinate system, where the Z-axis coincides
with the optical axis, the optical center 0 lies at the
origin and f denotes the distance between image plane
and optical center (see Fig. 1). Let us define the image
coordinate system ( U , v ) , with the origin at the point
( O , O , f ) with respect to the 3D camera coordinate
system and the image plane coinciding with the plane
Z=f: Thus, the 2D projection p of the 3D point

e, respectively. If a point pair
pi and pr are corresponding points, then oi,o, p i
and p r must lie in the same plane. This is the basic

lines through el and

property involved in the epipolar geometry, which is
called co-planarity constraint. The relationship between
the two corresponding points pi and p r can be
formulated as:

Z, M,-'x,

onto the image plane has coordinates p = ( U , v ) (see
figure 1). . The coordinate system used in the computer
or in the respective digitized image will be denoted (x,
y ) . In this coordinate system the principal point
(XO, yo) gives the position of the optical center. The
cameras are first calibrated independently in order to fix
the intrinsic parameters. This process is carried out
using a well established method due to Tsai [6].It uses a
single view of coplanar or non-coplanar points to find
the focal length, two coordinates of the image center,
the first order radial lens distortion coefficient and the
uncertainty factor for the scale of the horizontal scan
line. In our system we use the version implemented by
Willson [8].

=z

~+ T ,~

~

' (1) x

with M the camera intrinsic matrices, R the rotation
matrix from left to right camera coordinate systems, T
the translation vector from the origin of the left camera
coordinate system to the origin of the right camera

x

T

coordinate system, and
= (x,y , 1) the extended
vector with the coordinates of the sampling position
considered in the digitized image. In equation ( I ) the
indexes 1 and r indicate left and right camera systems
respectively. If the camera intrinsic parameter are
known, (1) can be expressed in normalized coordinates.

ui = (UI,V I , = M i 1xi and
U,. = ( U , , vr , I ) T = kf;'xr(the normalized image
Taking

coordinates), (I) can be written as:

+

ZrU, = ZiRUi T .
(2)
The cross-product of ( 2 ) with the translation vector
T = (tl , t2, t 3 ) f followed by the inner product with
U , yields to
U,.EUi = O ,
(3)
- t3
with E = T . R , T = [ t:
a skew

a.]

-t2
symmetric matrix constructed with the translation
vector. ( 3 ) is called the epipolar equation and it reflects
the co-planarity constraint or the fact that the three lines
( 0 1 , p l ) and
p r ) lie in the same
plane (see Fig. 1). The singularity of Z implies
det(E)=O. Moreover, rank(E)=2 is the so-called rank 2
constraint. The epipolar equation was discovered by
Longuet-Higgins [5] in the early eighties. It defines the
epipolar geometry, which comprises all about a stereo
rig. It allows 3D reconstruction of the scene to be
carried out if the intrinsic camera parameters are known
and it reduces the search for corresponding points,
constraining it from the entire second image to a single
line.

Fig 1: Stereo rig and underlying epipolar geometry.

(o~,or),

Let us now consider the stereoscopic rig shown in
Fig. 1, with the two cameras having optical centers at
0,and 0,., respectively. For any point
in the 3D

or,

space, the plane ( 01,
of

) is called epipolar plane

I;. It intersects the image planes

in two conjugate

lines called epipolar lines. The points el and e, of
intersection of the image planes with the base line
( o i , o r ) are called the epipoles of the stereo rig. The

500

(or,

~

Estimating the extrinsic camera parameters and the
epipolar geometry is a matter of estimating the essential
matrix. The epipolar equation can be written as an
homogeneous linear equations in the nine unknown
elements of E:

propose to regularize the problem by applying a
technique based on the truncated single valued
decomposition (TSVD), which is a regularization
approach for this kind problems. Using TSVD and
assuming for instance that k=7 the ill-conditioned
matrix H, is replaced by H ,7 =SA7QT with

hTk=O,
withh = (ulur9 urvl9 ur ulvr 9 vlvr 9 vr

9

V I , 1)

a vector defined by the corresponding points

T

A7 = diag{AI, ...,A7, 0, O} . Notice that Eckart-

U,,

Young-Mirsky theorem's guarantees that H:

U , and E

the nine-dimensional vector, whose
elements are the coefficients of the essential matrix.
Given n corresponding points we obtain a system of
linear equations of the form:

H,,,k=O.

matrix of rank 7 closest to

H , in any norm unitary

invariant. Keeping in mind that H , is not singular we
generate its null space as

N(Hn)=span{q8,q9}.

(4)

3. A Novel Technique to Estimate the
Epipolar Geometry
Since E is defined up to a scale factor eight
corresponding points are sufficient to calculate the
essential matrix. Moreover, rank(H, ) = k and k<9,
because in other case (4) only posses the trivial solution.
Estimating the epipolar geometry consists of estimating
the null space N(H,) of H,. Singular value
T
decomposition (SVD) of H , leads to H , = SAQ ,
with

A = diag{Al, ..., A9},

S = ( s I , .. .,sg),

Q = (41 ...,49)

and

I

N( H , ) = span(qk+],...,q9} . Usually, more than
eight corresponding points are known but they are only
estimates of the exact corresponding points. For this
reason the SVD technique becomes ineffective, because
the matrix H , build from the inexact data is not longer
singular, but ill-conditioned or of deficient rank. This
mean that in practice N(H,) =
and k=9.

{o}

Consequently, solving (4) becomes equivalent to
solving the optimization problem:

1) 11.

is the

I I

min H E , for any

predefined norm . Several methods for solving this
problem can be found in the literature, for a
comprehensive review of them we refer to [9]. Most of
the conventional approaches assume than the errors in
the input data is Gaussian distributed with zero mean,
and use the L2 -norm to solve the problem.
Unfortunately, the least squares method is extremely
unstable because the distribution of errors is not
Gaussian and the initial data can contain outliers. We

Fig. 2: Original stereo scenes GWEN.

501

(5)

Consequently, for any real numbers

e,

Once the essential matrix is known the extrinsic
camera parameters can be estimates using a wellestablished technique proposed by Longuet-Higgins [ 5 ] .
T
Since E T = 0 , T can be found up to a factor scalar

{I, (2 :

+ 5,

E = .gs
. q 9 . Since E is defined up to a
scalar factor, any solution can be multiplied by
1/ ({I
+{ 2 ) ,

&(c)

is

6 = Cl 1((1

i.e., taking

given

by

the

+{ 2 ) ,

subject to

T

one-parameter family

i<<>
= c . qs + ( I - < > . q9 for c E [o,
11.
Using

the unit eigenvector of EET corresponding to the
smallest eigenvalue. The rotation matrix is estimated by
T
solving: minl(E- Z.RI? subject to R R = I and

k(5) we can build the essential matrix E ( { )

as function of

5 . Next,

we estimate the family of

R

de@) =I. Notice that once these optimization problems
have been solved sign ambiguities have to be
considered. Finally, the estimation of the 3D
coordinates of a point i ,given the location of its

matrices E2({) with rank two and closest to E({)
by applying the TSVD technique. The parameter ( is
calculated using the following physical meaningful
constraint introduced in [9].
Let

uf,U:

projectionspl and p,. in the left and right image
planes and the extrinsic camera parameters is
straightforward using the relation (1).
To assess the performance of this algorithm we have
estimated the Essential matrix for several stereoscopic
scenes. Selected results obtained for the scene GWEN
are reported in this paper. The original stereoscopic
image GWEN is shown in Fig. 2. The epipolar lines
obtained with the proposed algorithm are shown in Fig.
3. In this representation both images are shown in the
background. Superimposed on the left image the
matched points are highlighted, on the right image the
epipolar lines corresponding to these points are drawn.

be the it* pair of given corresponding

points. The point

U,!should lies on the epipolar line

ar(c) defined by U1 and E2 ({). Analogously, the
point uf should lies on the epipolar line al(c)
defined by U, and E2
the parameter

(5). We propose to estimate

( that minimize the Euclidean distances

dist(Al (0
Uf
,) between &({) and U f, as well
as

between &({) and

dist(&({),Ui)

Thus,

U,!.

is estimated by solving:

4.

2

(c), uf +

) dkt(&. ({), U:) (6)
i=l
To reinforce the numerical stability of this
procedure, normalization of the input data as proposed
by Hartley [2] is carried out at the start of the algorithm.
Summarizing, the epipolar geometry is estimated by
applying the following algorithmic steps:
Normalize the input data by applying Hartley’s
method.
Use (5) to estimate the null space of H n as

m i n i ( dist(il,!

function of the parameter

{ and build

k ( { ).

5.

E(6).

Find the value of

{*

Summary

A technique for stereoscopic image analysis and
casmera registration for the integration of natural video
objects with computer generated worlds has been
introduced. In this context, the addressed goal has been
the development and implementation of an efficient and
reliable method for camera calibration. This challenge
has been faced by estimating the epipolar geometry of a
stereo rig using regularization techniques. Applications
of the presented approach include manipulation and
integration of natural video with computer generated
worlds. The obtained results demonstrate that the
objectives challenged in the work can be achieved by
the proposed method.

Apply the TSVD technique to determine the
family of matrices E2 ({) of rank 2 and closest
to

llTll= I . Thus, Tis

References

[ l ] M. Bajura, and U. Neumann, “Dynamic
Registration
Correction
in
Video-Based
Augmented Reality Systems“, IEEE Computer
Graphics and Applications, Vol. 15, No. 5, Sep.
1995, pp. 52-60.

that minimizes (6).

Take the essential matrix as E = E2 ((* ) .

502

[71 M. Tuceryan, D. S . Greer, R. T. Whitaker, D.
Breen, C. Crampton, E. Rose, and K. H. Ahlers,
"Calibration Requirements and Procedures for
Augmented Reality", IEEE Transactions on
Visualization and Computer Graphics, Vol. 1, No.
3, Sep. 1995, pp. 255-273.

R. I. Hartley, "In defense of the eight-point
algorithm",
IEEE Transactions on Pattern
Analysis and Machine Intelligence, Vol. 19, 1997,
pp. 580-593.
M. Hirose, Image-based virtual world generation,
IEEE MultiMedia 4, 1997, pp. 27-33.

[SI R. Willson, "Tsai camera calibration software" release
3.0b3,
Online
available:
http://www. cs.cmu. edu/afs/cs.cmu.edu/user/rgw/w
ww/TsaiCode.html, 1995.

E. Izquierdo and X. Feng, "Modeling Arbitrary
Objects
Based
on
Geometric
Surface
Conformity", IEEE Transactions on Circuits and
Systems for Video Technology, Special Issue on
Syntheticmatural Hybrid Video Coding, Vol. 9,
No. 2, Mar. 1999, pp. 336-352.

[91 G. Xu and Z. Zhang, "Epipolar Geometry in
Stereo, Motion and Object Recognition", Kluwer
Academic Publishers, London, 1996.
[IO1

H. C. Longuet-Higgins, "A computer algorithm
for reconstructing a scene from two projections",
Nature 293, 1981, pp. 133-135.

R. Tsai, "A versatile camera calibration technique
for high accuracy 3D machine vision metrology
using off-the-shelf TV cameras and lenses", IEEE
Journal of Robotics and Automation, Vol. 3,
1987, pp. 323-344.

Fig. 3: Epipolar lines estimated with the proposed linear parametric regularisation technique.

503

