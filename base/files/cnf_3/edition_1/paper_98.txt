2011 15th International Conference on Information Visualisation

Intuition in Medical Image Segmentation: Visualizing Graph Edge Weights
Ryan A Beasley, Christopher R Wagner
Texas A&M University, College Station TX 77843, USA; Orthorun, Ltd., Ware, United Kingdom
beasley@entc.tamu.edu, chris@orthorun.com
Abstract

functions effect the segmentations. Meanwhile, graph visualization is an active area of research, often used to investigate the connectivity of a system [5]. Rather than being
interested in how the graph is connected, we are concerned
in combining the voxel position in the image relative to
the seeds with the variations in the lengths of those graph
connections, and thereby investigate the differences such
variations will cause in segmentations.
This paper describes a package developed to visualize
the effects of various edge weighting functions. The software shows the image of interest colored based on the distance as measured on the graph. The user thus gains intuition into the various choices for the edge weighting function based on the respective amount that different areas of
the image change color. A user study demonstrating the
beneﬁts of the package is presented. It is our hope that the
intuition provided by the software will result in less time
required to segment medical images in the clinical workﬂow.

Weighting functions for graph-based medical image
segmentation algorithms (e.g., Graphcut) have a signiﬁcant effect on the segmentation, but to our knowledge no
tool provides the user with intuition towards their proper
selection. The large variety, their complexity, and the limited feedback hinders comparison of choices. This paper
describes a package developed to visualize the effects of
various edge weighting functions and parameters, in which
the image of interest is overlaid with colors depicting the
relative distances from the nearest seed to each voxel. By
seeing the colors vary while changing parameters, the user
gains intuition into the various options for the edge weighting function. A user study demonstrating the beneﬁts of the
package is presented. It is our hope that the intuition provided by the software will result in less time required to
segment medical images in the clinical work-ﬂow.

1

Introduction

2

The result of using a poorly-ﬁtting segmentation algorithm is that labeling structures of interest in a medical
image can take signiﬁcant amounts of time to ensure the
necessary accuracy, such as when quantifying cardiac ejection volume or designing patient-speciﬁc jigs for joint replacement [1]. Graph-based algorithms are popular for
medical image segmentation (e.g., Graphcut is fast and
suitable for either user-guided or autonomous operation),
but the resulting segmentation is signiﬁcantly based on the
weighting function. The variety and complexity of possible weighting functions, as well as the lack of feedback beyond the resulting segmentation, hinders the development
of intuition in the selection of the weighting function and
any parameters.
Several papers have investigated the efﬁcacy of speciﬁc
weighting functions [2], evaluated the relative accuracy of
segmentations performed using a range of values for parameters in a speciﬁc weighting function [3], or provided
a weighting function tailored to a speciﬁc modality and organ [4]. Such works provide advice that is either very general or very speciﬁc, but do not tend to build the users intuition about the mechanisms by which different weighting
1550-6037/11 $26.00 © 2011 IEEE
DOI 10.1109/IV.2011.17

Methods

Graph-based segmentation algorithms treat each voxel
in the image as a separate vertex, connected by “edges” to
its neighbors. The likelihood that two neighboring voxels
belong to the same area is determined by the weight (i.e.,
length or capacity) of the edge. The edge weight is calculated by the weighting function, typically based on the
intensities of the voxels.

2.1

Options in graph-based segmentation

Various deﬁnitions of a “neighborhood” can be used,
changing the layout or connectivity of the graph. Commonly either von Neumann or Moore neighborhoods are
used, with a distance of 1. For two-dimensional images,
the resulting neighborhoods are either 4-connected or 8connected, where the number is how many edges connect to a centrally-located pixel. The former only allows edges between orthogonally-adjacent voxels, while
the latter also places edges diagonally. Equivalent neighborhoods for three-dimensional volumes are 6-connected
or 26-connected. The study presented in this paper uses
616

2.2

a three dimensional image, and a 6-connected (von Neumann) neighborhood is used to construct the graphs.
In addition to the parameters that affect the graph construction, once the graph has been constructed different
algorithms can be applied to that same graph. For the
segmentations performed in this paper we used Dijkstra’s
shortest path algorithm [6]. Using this algorithm, each
graph vertex receives the label of the nearest seed point.
The edge weights are therefore thought of as lengths, and
the weight of an edge should be low between vertices that
should share the same label. An example on another popular segmentation algorithm is Graphcut [7], in which the
max-ﬂow/min-cut approach is used to segment the image.
The edge weight function is an area of active research
and many weighting functions have been proposed. Typically these functions are modiﬁcations to either the Gaussian form (1) or the Reciprocal form (2):
1
exp −βdiff2 (vi , vj ) ,
dist (vi , vj )
1
1
,
=
dist (vi , vj ) 1 + βdiff2 (vi , vj )

wij,gauss =

(1)

wij,recip

(2)

where g (vi ) is the image intensity at voxel vi , diff (·) is the
absolute value of the difference in intensities between two
voxels, β is a free parameter, and dist (·) is the Euclidean
distance between the centers of two voxels. As an example of modiﬁcations, the most popular may be an a priori
intensity-distribution term used to estimate the probability
that the two pixels belong to separate areas.
For the user study in this paper, four edge weight functions were implemented. The functions were chosen for
minimal complexity, but with expected variation in performance. The simplest conceivable weighting function is a
constant value (3), though equal weights result in very poor
segmentation performance. Using the normalized difference between intensities (4) provides relatively good results except at weak boundaries. Squaring that value increases the effect of gradients, making it more likely that
label boundaries will meet at high gradients in the image (5). The ﬁnal function is the natural-log-reciprocal of
the normalized difference (6). The functions implemented
are thus:
wij,constant = 1,
wij,delta = diff (vi , vj ) /max diff,
2

wij,ln recip = −ln

ci,hue,equal = 240

(3)
(4)

wij,squared = (diff (vi , vj ) /max diff) ,
1
1 + diff (vi , vj ) /max diff

Software

We have developed a C++ software package to assist
users in visualizing the effects of various options in graphbased segmentation algorithms. The program utilizes the
Boost Graph Library (BGL) to generate graphs and perform graph-based computations [8]. OpenGL is used for
visualization.
The user starts by loading a medical image. The screen
displays the image in a standard three-slice view, with
slider bars to scan through the slices in each view, Fig. 1.
The user can click on any of the views to place seeds of a
speciﬁc label (i.e., color) determined by a drop-down box.
The user can select different functions for the edge weight
calculation via radio buttons. For the user study in this
paper, the software contains radio buttons that select between the edge weighting functions above (constant, delta,
squared, and reciprocal (3–6)).
Pressing a button labelled “Segment” will segment the
image based on the current seeds and chosen edge weight
function. Speciﬁcally we use BGL’s implementation of Dijkstra’s single-source shortest paths, with all the seeds set
to a distance of zero. Prior to calculating the shortest paths,
we convert our multi-source problem into a single-source
problem by adding zero-length edges from one of the seeds
(the source) to all the other seeds. A BGL “visitor” is used
to propagate the labels. Once the segmentation is complete
(13 seconds for a 126 x 175 x 85 voxel image, on an Intel Core2 2.4GHz CPU), the image is overlayed with the
segmentation colors (i.e., labels).
Pressing a button labelled “Calculate heatmap” will
color the image based on the shortest path distance to any
seed. Voxels relatively close to any seed are given a hue
closer to zero degrees (red), while voxels relatively far
from all seeds are given a hue closer to 240 degrees (blue).
To do so, a segmentation is performed as though the user
had pressed the “Segment” button, but instead of overlaying the segmentation colors, the overlay is a “heatmap” derived from the resulting distance from each voxel to the
nearest seed. The initially attempted calculation for the
overlay color, ci , for a given voxel, vi , with distance, di ,
gave equal weight to the entire range of distances,

ci,saturation = 1,
ci,value = 1,

(5)

di − min distance
,
max distance − min distance

(7)
(8)
(9)

where max distance is the maximum distance for any voxel
in the image, and min distance is the minimum distance for
any voxel. Initial trials using (7) colored the majority of the
image pure red for the squared function (5) as a result of the
outliers the squared function creates in the voxel distances.
Those outliers reduce the ability to differentiate between

, (6)

where max diff is the maximum difference between any
pair of neighbors in the volume.

617

Figure 1: User interface, displaying CT of jaw. Utilizes a standard 3-plane view.
been pre-seeded on one sagittal slice and one coronal slice,
with seeds of one label on the upper jaw and teeth, seeds
of a different label on the lower jaw and teeth, and seeds of
a third label on the non-bone tissue and air.
Subjects were provided with a short description of medical image processing, as well as the purpose of the study
in evaluating the usability of the software package to visualize the effects of different segmentation algorithms. The
proctor demonstrated selecting different radio buttons to
change the edge weight function, and demonstrated how to
observe the resulting heatmap by dragging the sliders for
each view and by varying the transparancy of the heatmap.
Fig. 2 displays the heatmaps on the same slices for each of
the four functions.
Subjects were told that the overlay colors were a function of distance to the segmentation seed points, and therefore higher color gradients are more likely to correspond
to boundaries between segmentation labels. Subjects were
told they had as much time as they needed to determine
which of the four radio buttons they thought would result
in the segmentation that best labeled the upper and lower
jaw bones (and teeth), as well as which radio button they
thought would perform the worst such segmentation.
At no time did the subjects see the seeds or a segmentation. Neither were they allowed to add or remove seeds.
Furthermore, the subjects had no knowledge of the different functions except for the labels on the radio buttons (in
order, uniform (selected the “constant” function), squared,
reciprocal, and delta). The subjects were observed while
they manipulated the software to prevent operational errors, and to answer any questions on operation of the soft-

smaller (but still signiﬁcant) differences in distance. As a
result, the implementation for this paper clamps distances
above a constant value, d∗ ,
ci,hue,clamped =

distance
240 dd∗i −min
−min distance
240

if di < d∗ ,
if di ≥ d∗ ,

(10)

where d∗ was chosen to be twice the mean of the distances. Since the seeds are deﬁned to have a distance of
zero and all the edge weight functions used in this paper
create positive-length edges, it was not necessary to clamp
the low side of the distances.
Other buttons, sliders, and menu options enhance usability. The user can vary the transparancy of any overlay
using a slider widget. All seeds can be removed from the
image with a button. Finally, the user can save and load
segmentations and seeds.

2.3

User Study

A small user study was implemented to demonstrate the
capabilities of the software package. The goal of the user
study was to see if the subjects were able to choose the
edge weighting fuction that best segments an image, solely
by looking at the heatmap. Six subjects, males between
the ages of 18 and 22 with no prior experience in medical image processing, were provided a computer running
the software, on which had been loaded a CT image of
one side of a human jaw (126 x 175 x 85 voxels). The
image is a cropped version of a volume provided on the
OsiriX imaging software website (Pixmeo SARL, Geneva,
Switzerland) under the name INCISIX [9]. The image had

618

(a) Axial, squared.

(b) Sagittal, squared.

(c) Coronal, squared.

(d) Axial, delta.

(e) Sagittal, delta.

(f) Coronal, delta.

(g) Axial, ln-reciprocal.

(h) Sagittal, ln-reciprocal.

(i) Coronal, ln-reciprocal.

(j) Axial, constant.

(k) Sagittal, constant.

(l) Coronal, constant.

Figure 2: The “heatmaps” for the four functions used in the study. The slices shown intersect in the middle of the volume.
The segmentation seeds were placed on the sagittal and coronal slices shown here. Colors indicate distance frome each
voxel to the nearest seed. Ideally, each jaw would be surrounded by a blue outline, signifying signiﬁcant separation, while
the inside of the jaws would be red to signify similar areas.

619

Conclusions

ware. After the subjects indicated their choices for best and
worst functions, they were asked for any comments on the
software or the study. Then they were shown the segmentations that resulted from each function and any questions
they had on the software or the study were answered.
After the experiment, the four segmentations (one per
function) were generated from those seeds. The Dice Similarity Coefﬁcient (DSC) was used to compare each of those
segmentations with a manual segmentation. Here the DSC
is calculated as twice the number of voxels that were labelled for the same jaw in both segmentations, divided by
the sum over both segmentations of the number of voxels
labelled as either jaw. A DSC of 1 would therefore represent that the segmentation labelled each voxel the same as
the manual segmentation. Since the segmentations using
each of the functions used the same seeds, and those seeds
were only placed on one slice of the volume, much lower
DSC’s were expected, but higher DSC’s still indicate better
performance.

3

We have created a software package that assists the user
in visualizing the effects on graph-based segmentation algorithms of various edge weighting functions. The software allows the user to see the variations in vertex distance,
which contains more information than the segmentation
alone. A user study demonstrated that this approach has the
potential to guide users in the understanding of how different graph edge weighting functions affect segmentations.
We believe that this approach has the potential to reduce
the amount of time necessary for medical image segmentation, by promoting accurate selection of edge weighting
functions, parameters, neighborhood connectivity, etc.
Future improvements to the software would strive to investigate common choices in graph-based segmentations.
The most signiﬁcant enhancement would be allowing the
user to choose between the shortest path segmentation approach used in this paper and the max-ﬂow/min-cut approach (Graphcut). We also plan to add selection of the
neighborhood connectivity, various edge weighting functions, the ability to vary parameters speciﬁc to each function, and possibly side-by-side comparisons. Finally, we
will implement a user-modiﬁable transfer function for calculating the heatmap from the distances. The planned approach is to display a histogram of the distances and let
the user pick the minimum and maximum distances (effectively a window/level operation). Following these technical and interface improvements, we will attempt to translate this package into the clinical work-ﬂow.

Results

Table 1 tallies the functions identiﬁed as best/worst by
the subjects. For the best function, ﬁve of the six subjects
selected the “squared” function (5), with one subject selecting the “delta” function (4). For the worst function, all
six subjects selected the “constant” (3) function.
The DSC values between the segmentations and the
manual segmentation are listed in Table 1. The squared
function produced the segmentation that best matched the
manual segmentation, only failing to label the very top of
the upper jaw and very front portions of both jaws 3, and
labelling almost no tissue voxels as bone. In comparison,
the uniform function’s segmentation had the lowest similarity, as it labelled many tissue voxels as bone and many
bone voxels as tissue.

Acknowledgements
ITK-SNAP was used extensively for image viewing and
cropping [10].

References
[1] Hafez, M A, Chelule, K L, Seedhom, B B, Sherman, K P. Computer-assisted Total Knee Arthroplasty Using Patient-speciﬁc Templating. Clinical Orthopaedics & Related Research, vol. 444, pp. 184–
192, 2006.

Table 1: Function quality: qualitatively as identiﬁed by
subjects, and quantitatively calculated as the similarity
(DSC) of the resulting segmentation to a manual segmentation.
Function name
squared
delta
reciprocal
uniform

# best
5
1
0
0

# worst
0
0
0
6

[2] Rother, C. and Kolmogorov, V. and Blake, A. Grabcut: Interactive foreground extraction using iterated
graph cuts. ACM Transactions on Graphics (TOG),
vol. 23, no. 3, pp. 309–314, 2004.

DSC
0.890
0.674
0.655
0.344

[3] Grady, L. and Jolly, M.P. Weights and topology: A
study of the effects of graph construction on 3d image segmentation. Medical Image Computing and
Computer-Assisted Intervention–MICCAI 2008, pp.
153–161, 2008.

The subjects took an average of 6 minutes to manipulate
the software and was observed to look through a range of
slices in each view for each function. The few comments
were positive on the software’s ease of use. Following the
study, each of the subjects asked for details on the speciﬁc
functional forms indicated by the radio buttons.

[4] Funka-Lea, G. and Boykov, Y. and Florin, C. and
Jolly, M.P. and Moreau-Gobard, R. and Ramaraj,

620

(a) Axial, segmentation from squared function.

(b) Sagittal, segmentation from squared function.

(c) Axial, manual segmentation.

(d) Sagittal, manual segmentation.

Figure 3: Sample segmentations, manual and based on the squared function. The upper jaw was seeded red. The lower jaw
was seeded green. Soft tissue and air were seeded blue. The squared function performed the best of the functions tested in
creating a segmentation similar to the manual segmentation (DSC 0.890). Still, some areas were incorrectly labelled (such
as the incisors at the top of the axial view), due to the limited placement of seeds.
R. and Rinck, D. Automatic heart isolation for CT
coronary visualization using graph-cuts. Biomedical
Imaging: Nano to Macro, 2006. 3rd IEEE International Symposium on, pp. 614–617, 2006

[8] Jeremy G. Siek, Lie-Quan Lee, and Andrew Lumsdaine. The Boost Graph Library: User Guide and
Reference Manual (C++ In-Depth Series). AddisonWesley Professional, December 2001.
[9] OsiriX,
Dicom
sample
http://pubimage.hcuge.ch:8080/
ary 2, 2011.

[5] Kaufmann, M. and Wagner, D., Drawing graphs:
methods and models. Springer Verlag, 2001.
[6] Dijkstra, E. W. A note on two problems in connexion
with graphs. Numerische Mathematik 1, pp. 269-271,
1959.

image
retrieved

sets.
Febru-

[10] Paul A. Yushkevich, Joseph Piven, Heather Cody Hazlett, Rachel Gimpel Smith, Sean Ho, James C. Gee,
and Guido Gerig. User-guided 3D active contour segmentation of anatomical structures: Signiﬁcantly improved efﬁciency and reliability. Neuroimage. vol. 31,
no. 3, pp. 1116–28, 2006.

[7] Boykov, Y., Jolly, M.P. Interactive graph cuts for optimal boundary & region segmentation of objects in
N-D images. Proc. of ICCV 2001, pp. 105–112, 2001.

621

