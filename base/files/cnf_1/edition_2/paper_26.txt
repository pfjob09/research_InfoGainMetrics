Towards the Personal Equation of Interaction: The Impact of Personality
Factors on Visual Analytics Interface Interaction
Tear Marie Green & Brian Fisher
School of Interactive Arts + Technology
Simon Fraser University
ABSTRACT
These current studies explored the impact of individual
differences in personality factors on interface interaction and
learning performance behaviors in both an interactive
visualization and a menu-driven web table in two studies.
Participants were administered 3 psychometric measures designed
to assess Locus of Control, Extraversion, and Neuroticism.
Participants were then asked to complete multiple procedural
learning tasks in each interface. Results demonstrated that all
three measures predicted completion times. Additionally, results
analyses demonstrated personality factors also predicted the
number of insights participants reported while completing the
tasks in each interface. We discuss how these findings advance
our ongoing research in the Personal Equation of Interaction.
KEYWORDS: visual analytics, cognition and perception theory,
embodied cognition, visualization taxonomies and models
INDEX TERMS:
H.1.2 [Models and Principles]: Human
Information Processing J.4 [Social and Behavioral Sciences] :
Psychology - Experimentation
1

INTRODUCTION

The primary purpose of visual analytics is commonly defined as
the facilitation of analytical reasoning through use of interactive
visual interfaces [1]. Facilitating analytical reasoning, however,
requires a comprehensive and operational understanding of the
cognitive processes that make up analytical reasoning. Complex
cognition includes a plethora of smaller processes that work
together, including perceptual cognition, categorization, problemsolving, decision-making, judgement, and reasoning. These
processes feed and inform each other throughout each stage of the
analytical task; simply supporting each process individually is not
enough. Visual analytics must also support the temporal and
cognitive flow of reasoning. And yet, an operational
understanding of analytical cognition has, to date, proven elusive.
For example, as is often the case with behavioral
experimentation generally, studies of cognition tend to involve
small, simple, normative or “toy world” tasks, while interaction in
the real world tends to be more complex, harder to predict, and
thus harder to measure. Additionally, these evaluations focus on
the more binary of cognitive processes. Especially in visualization
studies, the cognitive variables measured are usually facets of
vision, given attention, and tactile manipulation. While visual and
motor effectiveness are important to interface interaction, they are
only part of the story.
250 - 13450 102nd Avenue, Surrey, BC, Canada, V3T 0A3
terag@sfu.ca
IEEE Symposium on Visual Analytics Science and Technology
October 24 - 29, Salt Lake City, Utah, USA
978-1-4244-9487-3/10/$26.00 ©2010 IEEE

Complex cognition is not binary nor necessarily sequential.
Reasoning, in particular, uses a variety of heuristics, from quick
elimination heuristics like Gigerenzer’s Take-the-Best [2] or
satisficing [3] to much more complicated processes such as
iterative reasoning, deductive analyses, or rule inferencing. Which
heuristics are used and in what order depend on the task, the
environment, and the user. These heuristics are often used
combinatorially, feeding and informing the analysis until a
solution or hypothesis has been satisfactorily reached.
Unfortunately, at this time, analytical reasoning behaviours can
be described in part and in whole, but not necessarily predicted.
There are no unifying theories of reasoning. And this difficulty of
prediction is compounded by three types of user individual
differences: institutional, environmental, and inherent.
How humans work through reasoning tasks is impacted by
institutional differences. Cognition is a social activity [4], and
domain-specific knowledge, jargon, learned methodologies, and
other cultural factors can influence how analysis tasks are
approached and what heuristics are used in solving them. In
addition, these domain or expert cultures tend to have similar
inherent differences; members of an expert cohort may share
personality or learned proclivities [5, 13].
Environmental differences – such as differences in the
interface or tool used during visually enabled interaction – frame
the task and can help or hinder the reasoning process. These
differences are naturally of particular interest to visual analytics
design, as effective interfaces can facilitate analytical reasoning.
In this paper, we will higlight the impact of inherent indvidual
differences. Individual differences of whatever variety are
obviously not the only factors which demonstrably impact user
interactive performance. But as we will show, individual
differences – and inherent differences in particular – can predict
certain types of performance. Further, these differences seem to
influence performance differently, depending on the cognitive
task being undertaken. Another reason to study inherent
differences is that they, unlike environmental and to some degree
institutional differences, are variables over which interface
designers have no control.
In our research toward the Personal Equation of Interaction, our
goal is to know and understand the impact of these variables, as
well as to develop a battery of predictive measures to aid in the
development of interfaces which cater to the individuality of the
user or user domain. The creation of the Personal Equation of
Interaction at this current time is focused on inherent individual
differences. Inherent differences are those of learning style,
personality factors, self-beliefs, and other cognitive “presets”
which the user brings to the interface. We will demonstrate that
these inherent differences can and do demonstrably impact
interaction outcomes. Further, we can show that, if the inherent
differences are known, interaction performance can be predicted,
and so could, if part of a robust user profile, be used to develop
design requirements for expert systems design as well as real-time
interface individuation.
Inherent individual differences in problem-solving approaches
can affect task orientation and motivation when a user is engaged

203

in goal-oriented behaviors [6]. In particular, personality factors
similar to the ones evaluated in the studies reported here have
been shown to impact cognition and cognitive performance in
other learning environments. For example, personality factors
predicted preferences in visual perception of landscapes [7]. In an
HCI study, Palmer found that interactive behaviors in information
search can be categorized by personality factors [8]. In reasoning
research, individual differences have been found to impact
rationality and metareasoning [9]. These are just a few examples
in a broad literature of how personality factors and other
individual differences demonstrably affect complex cognition.
The findings we currently report are part of this body of work.
The question is not whether individual differences impact
cognition, but how and when. We hope, in the creation of the
Personal Equation, to answer several of these questions.
Furthermore, we can use individual differences to improve
our understanding of visually enabled analysis across knowledge
domains. Research has demonstrated that users in a particular
domain can share personality characteristics and learning
preferences, both inherent and institutional. This implies that traits
common to the user group can be aggregated into specific user
profiles, informing superior design requirements and aiding in
evaluation protocols. A personal equation of interaction could
both a) provide guidelines for individuated interface designs
which could broadly accommodate differences in learning style,
reasoning heuristic preferences, and perceptual behaviors and b)
develop profiles of expert or non-expert user groups, deliniated by
either knowledge domain or cognitive task, that would inform the
interface design for specific user or task domains.
As we discussed previously, individual differences have been
found to have a bearing in traditional learning environments [e.g.
11]. And in an earlier study [10] we found that certain aspects of
trait anxiety had an impact on task efficiency in both inferential
and procedural tasks. Also, Rotter’s Locus of Control [12]
predicted inferential task efficiency; we will review this finding in
Section 3. For user group profiles, characteristics of user domains
has been done in a limited fashion [e.g. 13]; this research would
further these aims.
Learning is not generic. Learning heuristics and processes
vary depending on human individuality, the learning environment,
and the learning tasks. In other work, we discussed the impact of
locus of control on inference learning in the form of category
reasoning [10]. The tasks used in these current studies are
procedural.
Procedural learning, broadly defined, is the
“knowing how” of any sequential task. It is sometimes called skill
learning, as it is the learning most common to motor and iterative
tasks that require repetition to master [14]; it is also referred to as
script learning, which captures the idea that there is a “recipe” or
“roadmap” to be followed. Procedural learning is thought to be
either top-down (i.e. CLARION) [14], or, more commonly, to be
bottom up, first assimilating the necessary declarative facts and
then the use of that information into the deconstruction of the task
procedure [15]. Procedural learning, due in part to repetition, can
become “automatic,” requiring little conscious focus. For the
purposes of these current studies, procedural learning is the
ability to learn to manipulate an interface well enough to find
and identify target information, or to answer straightforward
questions about the target information.
Procedural or script learning is integral to interface
interaction at every level. Some research has been conducted with
an eye toward procedural or target-finding tasks. But, as Plaisant
has outlined [16], many of these studies are tool evaluations of
specific interfaces, and are designed to designate one interface as

204

“better” than another, or done without an understanding of the
learning which underlies task performance.
Individual differences in reasoning ability have been found
to impact procedural learning in non-interface task environments
[e.g. 17]. These current studies evaluate inherent differences in
computer-mediated procedural tasks.
In another vein, visualizations are generally considered
preferable to other interfaces in generating “insight” [18]. But this
claim to date has been poorly supported by empirical research.
Further, research has focused on the visualization and insight
generation, but not necessarily on the tasks that support insight
generation, or the degree to which user individuality impacts the
frequency of insight. In this study, we evaluate the insight
generation by comparing the number of reported insights in the
two interfaces while completing two types of procedural task:
script learning, which involves the use of sequential instructions
and interface learnability, and target identification, which can
involve hunting for information through several layers of
hierarchical organization. In addition, we explore the impact that
individual differences have on the number of insights generated in
both interfaces across task.
The current studies were designed to explore 2 broad
research questions. The first question was whether and to what
degree Locus of Control, Big Five Neuroticism, and Big Five
Extraversion would have a significant relationship with the
outcome variables in task performance. It was hypothesized that
some whole measures or highly-predictive clusters of items would
trend with the outcomes. Based on previous work [10], we
expected that the Locus of Control whole score would be one
predictor, and that more extraverted and neurotic participants
would be quicker in task completion. And based on behavioral
literature[e.g. 24], we hypothesize that participants with an
external locus would be quicker in identifying target information.
The second question was whether and to what degree Locus
of Control, Big Five Neuroticism, and Big Five Extraversion
would have a significant relationship with the number of insights
reported; it was hypothesized that, given the interrelationship
between these constructs, whole score or individual items, would
be found to predict insight generation in both interfaces. Based on
previous locus of control literature [e.g. 22, 24], we predicted that
participants with an internal locus might be more apt to self-report
more insights.
The answers to these questions will aid in the creation of the
Personal Equation on Interaction, by identifying influential
psychometric items for interactive behaviors and reported
insights, which, in the long term will aid in the creation of
predictive measures depending on the type of analytical task being
undertaken.
2

COMPARATIVE STUDIES

Two studies were conducted. Each study employed a withinparticipants design, and compared procedural learning behaviors
in an information visualization and a web table. Study 1 tested
procedural learning performance with a series of 5 questions in
each interface. Study 2 tested procedural learning performance,
with a total 6 questions in each interface (3 training and 3 task).
The procedural task completion times in both studies were
combined for the purpose of analysis. The design and findings of
Study 2 have also been reported and discussed in [10].
2.1

Interfaces

Both studies asked participants to interact with two interfaces
built to display genomic information. These interfaces were
chosen as artifacts because both interfaces were fed by the same
underlying dataset (GenBank), both interfaces supported the types
of tasks we wanted to study, and the presentation and organization
of data and interaction methodology was demonstrable different.
One interface is the web-based National Center for Biotechnology
Information (NCBI) MapViewer for genomic information, which
is publically available and can currently be found at
http://www.ncbi.nlm.nih.gov/mapview. MapViewer is a multiplerow-based hierarchical representation, and uses standard GUI
manipulation, such as menus and hyperlinks. (See Figure 1.)
The other interface is an interactive data visualization (GVis) of
genomic relationships [19] which is not available publically. (See
Figure 2.) GVis primary purpose is to represent relevant
relationships (such as mapped genomes or the phylogenic
organization) between two organisms. Users manipulate the
interface through direct interaction, “drilling down” through each
hierarchy of subcategory directly by pressing and holding down a
mouseclick near the information of interest.
2.2

wide variety of human outcomes, including academic and
workplace performance[21,22].
The Neuroticism and Extraversion subscales of the IPIP 20item Mini Big Five Personality Inventory [20] ask participants the
degree to which each listed characteristic applies to them. The Big
Five factors have a long history in psychology and decades of
literature on their scope and impact. Briefly, Extraversion defines
the degree to which a person is open-minded, action-oriented and
seeks the society of others. Neuroticism is distinguished by
negativity and a propensity to be moody. In previous work [10],
as well in other literature (e.g. [23]), these traits have a
demonstrated relationship to each other, and, in the case of
Neuroticism, to locus of control.

Psychometric measures

These psychometric measures we have chosen have been shown
to capture the impact of these inherent constructs on human
cognitive performance and motivation as discussed in the
behavioral literatures (as discussed briefly in Section 1). Our
purpose was to explore what impact they might have on analytical
performance enabled by a visual interface.

Figure 2. The main view of GVis.

2.3

Figure 1. NCBI MapViewer

Three psychometric measures were administered: the Locus of
Control Inventory, as well as the Neuroticism and Extraversion
subscales of the IPIP Mini Big Five Personality Inventory.
The Internal-External Locus of Control Inventory (LOC) [12] is
a 39-item forced choice measure designed to evaluate the degree
to which participants attribute life events to some action of their
own, or to some uncontrollable action outside of themselves.
Lower LOC scores are associated with an “internal locus” of
control, an inherent belief that events and outcomes are under a
person’s control, and thus, success or failure depends largely on
personal behavior and attitudes. Higher scores indicate an
“external locus,” an inherent belief that events and outcomes are
influenced by external factors such as, unforeseen circumstances,
a higher power, or “good luck.” Rotter postulated that these loci
were traits remaining stable over a person’s lifetime [12].
Research demonstrates that locus of control has an impact on a

Participants

In total, 106 participants agreed to complete the study: 50 in the
first study, 56 in the second study. 94 participants reported being
right-handed; 11 were left-handed. Most (101) were
undergraduates and received course credit for participation.
Students reported having 22 different majors or academic
concentrations, including Business, Nursing, Computer Science,
and Psychology.
The vast majority of all participants 101 (96%) had taken fewer
than 4 biology or biology-related classes. Novices were recruited
specifically to better evaluate procedural learning with novel
information; experts would have had a more advanced
understanding of the knowledge ontology, which would have
weakened the comparison between interface metaphors.
All participants were asked to rate their ability and comfort
level with a computer and mouse on a 5-item Likert-like scale.
They were also asked to identify whether they had previous
experience with the computer interfaces being investigated. 97
reported being comfortable or very comfortable with a computer;
79 reported having “very good” or “expert” computer ability. No
one reported a computer comfort or ability level less than a 3 or
“OK.” Almost all (104) participants had used a web-based
application before. 35 participants reported having used a data
visualization previously. None of the participants reported having

205

a medical condition that might interfere with their use of a
computer or mouse. 2 participants reported being color-blind.

through ‘F’ (failing)). A short debriefing ended the study session,
and there were no follow-up sessions.

2.4

3

Study Protocols

After signing the informed consent, participants were asked to fill
out an online self-report questionnaire that included the 3
psychometric measures and basic demographic information, with
particular emphasis on self-perceived ability, experience and
comfort with computers and computer interfaces. Participants in
the first study were allowed to complete the questionnaire online
before their session in the lab. All data were collected for post-hoc
analysis with task performance data.
In both studies, after completion of the self-report measures,
participants began the procedural learning tasks in one of the two
interfaces. The order of interface was counterbalanced for order
effects; half of the participant used GVis first, and half used
MapViewer first.
In the first study, the tasks started with a brief demonstration
of interface and interaction techniques, such as the use of
hyperlinks or how to zoom into the visualization. After the
demonstration, a short tutorial was administered to introduce
participants to essential tools and concepts in the interface, and to
allow participants to experiment with what was being learned. In
some cases, step-by-step instructions were given. A researcher
was on hand throughout the study to answer any questions.
Following the tutorial was a series of 3 tasks designed to test
procedural performance in finding target information: the
participant was asked to identify a target located somewhere
within the presented informational hierarchy. The question
provided what base categorization or subclass the information was
located within, but did not provide step-by-step instructions.
Participants were also told to find the item as quickly as possible,
as the task was being timed. As soon as the target was located on
screen, the participant pushed a “Found It” button on the screen.
The time taken from the presentation of the question on-screen to
the moment the button was pushed was recorded as completion
time.
In the second study, participants were asked to demonstrate
script learning or tool skill by answering 5 hunt-and-find
questions. All tasks were open response. Each question included
step-by-step “cues” to assist in finding the answer to each
question. A cue was the next step or concept on the current page
or in the current view to look for. Participants were given little or
no help from the researchers while working through the question,
but were allowed or encouraged to experiment with different
interaction paths within the interface in order to find the answer.
If the answer given was incorrect, the error was recorded and the
researcher asked the participant to try again, until the correct
answer was given. The total time from the initial reading of the
question to the indication of the correct answer was recorded as
the completion time. Participants were not told explicitly that they
were being timed.
A third recorded outcome variable was insight. Participants
were asked after finishing each task in both studies to indicate
whether they had “learned anything unexpected while finding the
solution.” Insight was defined as “unexpected” to prompt for only
new knowledge that the participant considered to be novel or
surprising. If the participant reported a new insight, they were
asked to describe what they had learned.
After each participant had answered the questions in both
interfaces, they were asked to specify which interface they liked
better, and to give each interface a letter grade (‘A’ (superior)

206

RESULTS

In Study 1, the mean completion times for the procedural learning
tasks in the MapViewer (M = 684.77, SD = 235.46) were more
efficient than the completion times in the GVis (M = 684.77, SD
= 288.49). In Study 2, the MapViewer procedural completion
times were also faster (M = 133.54, SD = 84.00) than those in the
GVis (M = 161.64, SD = 111.40).
Overall, participants preferred interacting with the
visualization to interacting with the web table. This preference
was indicated by post-study feedback. For example, when asked
to give each interface a letter grade, from A (superior) to F
(failing), 75 (73%) gave the GVis an A or B; 57 (56%) gave an A
or B to the MapViewer. Additionally, when asked, 64(61%)
reported that they both preferred the visualization; 39 (37%)
preferred the web table.
3.1

Completion times and personality factors

The completion times for each condition for the procedural
learning tasks in each study were merged into a single statistic,
with N = 106. Participants completed tasks more quickly in
MapViewer (M = 383.15, SD = 32.38) than in GVis (M = 426.86,
SD = 32.15). A paired t-test between total completion times in
GVis and completion times in MapViewer was significant (t(100)
= 2.11, p = .037, suggesting that the differences in completion
times was due to more than random chance.
A one way Analysis of Variance (ANOVA) was used to test
for the impact of Locus of Control (LOC) across interface
completion times. The ANOVA for GVis was significant (F(14,
88) = 1.89, p = .039) but the comparison for MapViewer was not
(p = .099). In addition, LOC predicted completion times in both
interfaces; a Pearson’s correlation between LOC and completion
times was significant (GVis: r(105) = .234, p = .02, MapViewer:
r(105) = .254, p = .01). (See Figures 3a and 3b.) These findings
suggest that participants with a more internal locus (those who
believe they have control over personal life events) take less time
finding target information than those with a more external locus.
This correlational finding is the opposite of findings reported in an
earlier study [10]. This previous study used inferential tasks, and
found that participants with a more external locus (those who did
not believe that they were in control) tended to solve a series of
inferential tasks more quickly than those with a more internal
locus. These tasks were more cognitively complex than the
current studies, and asked the participants to compare and contrast
multi-dimensional objects and make decisions about similarities
and differences. We will discuss this further in the Section 4.
ANOVAs to test for the impact of Neuroticism in both
interfaces were significant: GVis: (F(16, 86) = 3.42, p < .001),
MapViewer: (F (16, 85) = 5.14, p < .001). Neuroticism also was
negatively correlated with completion times in both interfaces.
GVis: ( r(103) = -.47, p < .001, MapViewer: r(102) = -.54, p <
.001). (See Figures 3a and 3b.) ANOVAs to test for the impact of
Neuroticism in both interfaces were significant: GVis: (F(16, 86)
= 3.42, p < .001), MapViewer: (F (16, 85) = 5.14, p < .001).
Neuroticism also was negatively correlated with completion times
in both interfaces. GVis: ( r(103) = -.47, p < .001) MapViewer: (
r(102) = -.54, p < .001).
Differences in interface completion times and Extraversion
were significant across both interfaces: GVis: (F (14, 88) = 5.37, p
< .001). MapViewer: (F(14, 87) = 4.12, p < .001). These faster

participants also tended to be more emotional and sociable. A
summary of these findings can be found in Figure 5.
3.2

Task Errors and Personality Factors

The two studies measured tasks errors differently, and so must be

analyzed separately. In Study 1, procedural tasks asked
participants only to indicate when they had located the target
information, so no errors were made or recorded. In Study 2, error
was defined as giving the wrong answer to a question. Upon
making an error, participants were asked to continue to try until
they correctly solved the task. Each incorrect solution was
recorded as an error.
Kolomogorov-Smirnov Z was significant in both interfaces
(GVis: p < .001, MapViewer: p < .001). Levene’s test of
homogeneity was significant in for GVis (p = .004), but not
MapViewer (p = .30), suggesting that sample distributions were
not uniformly normal. Due to these two findings, we opted to
conduct non-parametric tests for the purposes of the following
analyses.
Participants made more errors in GVis (M = 1.21, SD =
1.07), than they did in MapViewer (M = .69, SD = 1.07).
Friedman’s chi square was significant (X2 (1) = 5.45, p = .02)
Kendall’s tau was conducted between errors in each interface and
psychometric scores; no significant associations were found.
Generally speaking, only the difference in interface had a
significant impact on how many errors were made; participants
were more effective in the MapViewer interface. A summary can
be found in Figure 5.
3.3

Figure 3a. Correlations of GVis Total Completion Times (in
seconds) across procedural tasks and the Locus of Control,
Extraversion, and Neuroticism scores.

Figure 3b. Correlations of MapViewer Total Completion Times (in
seconds) across procedural tasks and the Locus of Control,
Extraversion, and Neuroticism scores.

Insight generation and personality factors

Participants reported having more “unexpected” insights in the
GVis (N = 73) than in the web-based MapViewer (N = 70). The
distribution of the combined insights reported across both
interfaces was not normal according to the Kolomogorov-Smirnov
(GVis: p < .001, MapViewer: p < .001). Levene’s test of
homogeneity was significant for GVis (p < .001), but not
MapViewer (p = .373). As the distribution was not normal, a
Friedman’s chi square was run between the mean number of
insights generated in both interfaces, and was not significant:
Friedman’s X2 (1) = 1.59, p = .208. Kendall’s Coefficient of
Concordance = .015. This suggests that interface type did not have
a significant impact on the number of insights generated.
In an investigation of the impact of Locus of Control (LOC)
on insight generation, a Friedman’s chi square was run between
LOC scores and the mean number of insights generated in both
interfaces and was significant. GVis: Friedman’s X2 (2) = 174.36,
p < .001. Kendall’s Coefficient of Concordance = .83.
MapViewer: Friedman’s X2 (1) = 101.04, p < .001. Kendall’s
Coefficient of Concordance = .96.
As the sample was large (n > 50), Spearman’s rho was
conducted to evaluate correlations between the psychometric
scores and completion times. Locus of Control predicted the
number of generated insights (GVis: R(103) = .20, p < .04;
MapViewer: R(101) = .239, p = .016). Because both studies had a
within participants design, a Kendall’s tau-b was conducted. LOC
was not associated with the number of generated insights in both
interfaces (GVis: p = .59, MapViewer: p = .46).
These findings demonstrate that LOC had some impact on
the number of insights the participants reported; persons with a
more external locus tended to report a greater number of insights
(Figure 4 (top)).
We also explored the impact of Big Five personality traits
Extraversion and Neuroticism on insight generation in both
interfaces. A Friedman’s chi-square between mean Extraversion
scores across interfaces was significant. (GVis: Friedman’s X2 (1)
= 105.0, p < .001. Kendall’s Coefficient of Concordance = 1.0.
MapViewer: Friedman’s X2 (1) = 105.0, p < .001. Kendall’s

207

Coefficient of Concordance = 1.0). Extraversion was associated
with insight generation (GVis: τ = -.15, p = .051, MapViewer: τ =
-.18, p = ,027), and predicted the number of insights in both
interfaces (GVis: R(103) = -.554, p < .001; MapViewer: R(101)
= -.543, p < .001). These findings suggest the more insights were
reported by participants that were less extraverted (Figure 4
(middle)).
A Friedman’s chi-square between mean Neuroticism scores
across interfaces was significant: (GVis: Friedman’s X2 (1) =
105.0, p < .001. Kendall’s Coefficient of Concordance = 1.0.
MapViewer: Friedman’s X2 (1) = 105.0, p < .001. Kendall’s
Coefficient of Concordance = 1.0).
Neuroticism was not
significantly associated with insight generation (GVis: p = .716,
MapViewer: p = .37), but did predict the number of generated
insights in both interfaces (GVis: R(103) = -.415, p < .001;
MapViewer: R(101) = -.509, p < .001). These findings suggest
that more neurotic participants did not report as many insights as
those who had lower Neuroticism scores (Figure 4 (bottom)). A
summary is in Figure 5.
4

DISCUSSION

The findings of these studies demonstrate that, even when the
procedural tasks are somewhat different, inherent personality
differences can predict interaction and behavioral outcomes across
the interfaces. Aside from generally evaluating interface
learnability, which we did in both studies, we studied procedural
learning tasks in two slightly different ways. The first study
focused on target identification; participants were asked to find an
organism label on the screen: for GVis, this label was attached to
a spherical glyph, for MapViewer, very often the label was also a
textual hyperlink. Once the label had been obtained, the
participant pushed the ‘Submit’ button and the task was done.
In the second study, we asked participants trivia questions
whose answers had to be hunted through the interface. If they
gave the wrong answer, we requested that they keep looking. Like
the first study, nothing other than an ability to use the interface
and identify target labels was required. In both of these tasks,
participants found the targeted information more quickly in the
web table MapViewer; in Study 2, they also made fewer errors in
MapViewer. Given the wide commercial use of web tables, it
seems reasonable that most participants brought some prior
knowledge of the interaction metaphor to the MapViewer tasks
that they did not have for the data visualization. However,
participants still strongly preferred GVis to MapViewer, even if
they were not as effective in task performance. This may have
been due to the novelty of GVis; most participants had never seen
anything like it before. It also may have been due to data
organization; many participants, in post-study open response,
indicated a clear preference for GVis’ organization and
interaction.
Locus of Control proved to be an influential personality trait
no matter what the interface or task. The faster participants in both
interfaces were persons who had a more internal locus of control,
which is typified by a belief in personal control over life events.
This finding is in close agreement with much of the available
literature on locus of control. Persons were a more internal locus
have been found to have better problem-solving skills [21], to be
more resolved to solve a task when it became difficult [22], and to
be more likely to develop an intrinsic (internal) motivation to
finish a difficult task [22]. Thanks in part to positive behaviors
like these, internal locus has also been found to lead to superior

208

Figure 4. Scatter plot overlay the correlation of generated
insights and Locus of Control (top), Extraversion (middle) and
Neuroticism (bottom).

	  

outcomes in academics [24], hospital recovery, and organizational
environments.
What is intriguing is that, while an internal locus led to faster
procedural task outcomes, this is not necessarily the case when the
task becomes more cognitively difficult. In a previous paper [10],
we studied inferential learning. The tasks required participants to
evaluate a multi-dimensional exemplar, and draw a conclusion
about other organisms based on similarities or differences. We
reported that participants who had a more external locus – those
who believe that they are not in control, and who tend to believe
in luck as a cause of events – solved inferential tasks in GVis
more quickly than those with an internal locus. For a discussion of
these results, please see [10]. The results in [10] do not
contradict our current findings, but rather expand on them. In
these studies, we used a larger N, which likely made our analyses
more sensitive to changes in participant scores. Further, we
focused on only 3 constructs that seemed more highly predictive,
unlike [10] which used 6 psychometric measures.
For one type of learning task performance to be predicted by
the degree of internal locus and another type to be predicted by
the degree of external locus lends credence to our introductory
statement that, depending on task, inherent individual differences
can predict interface performance. Yet while locus of control has
been shown to be influential in a wide variety of human
performance, as previously discussed, to date, it has not been
considered by interface designers and evaluators. Based on our
research, as well as a broad locus of control literature, we consider
locus of control to be one construct in the Personal Equation of
Interaction.
In addition to Locus of Control, the Big Five personality factors
of Neuroticism and Extraversion also predicted procedural task
performance. The more extraverted or neurotic the participant, the
more quickly he or she was able to identify target information.
This is interesting, but little in the behavioral literature explains
these correlations; for us, it is a subject of our ongoing research.
Further, Neuroticism in these studies was found to be negatively
correlated with Locus of Control (r(105) = -.284, p = .003). This
does have some precedent in the literature. For example, Judge et
al. [23] evaluated several personality factors, including Locus of
Control and Neuroticism, and found that they were interrelated
and could be shown to be a part of the same construct. This means
that items from these measures trended together and were
statistically predictive of the same personality factor(s). Research
like this affirms psychometric constructs can and do work
together, Further, it lends credence to an approach that seeks to
find items or clusters of items which could work together in the
prediction of interaction efficacy.
Insights were also predicted by personality as in factor scores.
This is compelling because it suggests that the impact of a
predictive Personal Equation may go further than efficacy or
efficiency; it may extend to being able to predict some learning or
problem-solving outcomes as well. Much depends on how the
word “insight” is defined. In the visualization and visual analytics
literature, insight is often undefined. When defined, it is often
broadly defined, as in [25]. This makes “insight” difficult to use
as an evaluative interaction outcome, and thus, as briefly
discussed earlier, leaves certain claims about the superiority of
visual analytics interfaces unproven. Recently, “insight” has been
defined within two categories: knowledge-based insight, and
spontaneous insight [19]. Spontaneous insight is a sudden solution
to an unsolvable problem, and has often, in the psychological
literature, been referred to as an “aha!” moment. Spontaneous
insight was not evaluated in these studies.

In these studies, we evaluated the number of knowledge-based
insights reported across task and interface, which are generally
defined as items or concepts learned or added to the user’s
knowledge base. In evaluating the knowledge-based insights
reported, we categorized insights on the basis of content: insights
about how to use the interface itself were separated from insights
about the informational content presented and manipulated.
In both interfaces, roughly twice as many knowledge-based
insights were reported about interface learnability (GVis: N = 51,
MapViewer: N = 47) as were reported about the informational
content (GVis: N = 22, MapViewer: N = 23). In both interfaces,
the greatest number of interface learning insights was reported in
the first question, which suggests that learnability started early.
As the task set proceeded, the reported count of each insight type
tended to even out somewhat, which is not unexpected; users
started paying attention to content once manipulating the interface
was less of an issue or became more automatic.
Overall, whether learning about the interface or the interface
content, personality factors predicted reported learning as well as
other interaction outcomes. These findings have immediate
implications. For example, these studies have demonstrated that
users who tend to be more extraverted and neurotic are also more
likely to believe that they are in control of the task situation
(internal locus). By extension, this also means highly neurotic or
extraverted users tend to be better at interface manipulation and
target identification. If the personality factors of the user were
known beforehand, we could reasonably predict how quickly he
or she would be able to learn a novel interface and find pertinent
information. For even when the interaction metaphor was
completely unfamiliar, as it was in the GVis visualization,
neurotic/extraverted participants were able to learn to manipulate
the data more quickly.

Figure 5. A summary of the findings in Section 3.

However, what these findings do not do is demonstrably
differentiate between interface and interactive techniques. The
three evaluated personality factors impacted both interfaces
similarly. Given the cognitive simplicity of the tasks, this is
perhaps unsurprising. Ongoing research has been designed to
evaluate learning styles which tend to guide focused attention and
information organization during task, and where behavior research
suggests more delineating personality factors for visualization
technique might be found.
A last note is on the use of novices in evaluations using an
expert system; most of the participants had little or no knowledge
of biological concepts. However, the participants were still

209

capable of ably find target information in both interfaces. Yet
even with the more familiar archetype of the web interface,
participants preferred the visualization.
The intent of these studies was never to evaluate the efficacy of
GVis per se; a formal evaluation of GVis as an expert system is
reported in other literature [19]. The aim of these studies was to
evaluate human cognition during learning interaction using both
interfaces as working artifacts of a kind. In addition, we explored
whether individual differences in personality factors and selfbeliefs could have a large enough impact on interaction outcomes
to warrant their inclusion in the Personal Equation of Interaction.
For these reasons, we recruited non-experts who were
unfamiliar with the knowledge domain. Expertise would have
biased the user’s interaction; they would have had an expert
knowledge of the genomic hierarchies, and thus known where to
look for the requested information. This would have proven a
poor evaluation of how each interface promoted learning.
5

[6]

[7]

[8]
[9]
[10]

ACKNOWLEDGEMENTS

[11]

[12]

[13]

[14]

[15]
[16]

[17]

[18]

[19]

[20]

Many thanks to Paula Goolkasian, Mark E. Faust, Dong Hyun
Jeong, and William Brady Fulmer for their kind assistance. Partial
funding by the North Carolina Renaissance Computing Initiative.

[21]

REFERENCES

[23]

[1]
[2]

[3]

210

[5]

CONCLUSION

The Personal Equation of Interaction is still very much a work in
progress. In the short-term, it serves as an open discovery and
proof of concept. We have shown that inherent differences impact
interaction. Our ongoing research seeks to better define what
differences impact what type of analytical task (for it seems
reasonable to assume that one inherent set of differences will only
generalize to one type or set of task constraints). For example, we
are currently narrowing our task sets to study multiple decision
points in specific types of category or inference reasoning. And
further, we hope to explore whether that impact is temporally
static or dynamic throughout the analytical process.
In the longer term, we intend to isolate predictive matrices and
validate a battery of measures that will successfully inform
interface design based on the types of cognitive task undertaken.
Ultimately, this is the Personal Equation of Interaction. These
measures will likely involve more than personality factor
matrices; other areas of exploration include perceptual logics and
use of decision-making heuristics. In addition to informing design,
the Personal Equation could be used to provide real-time interface
adaptation to accommodate user needs and preferences, and
provide a basis for robust group profiles of users who share
common differences, such as experts or users of a particular
visualization technique. Visual analytics seeks to facilitate
analytical reasoning through the use of interactive visual
interfaces. In the Personal Equation of Interaction, we will
provide a new tool in that pursuit.
6

[4]

P.C. Wong and J. Thomas. Visual analytics. IEEE Computer
Graphics and Applications,. 4(5). 20-21. Sept.-Oct. 2004.
G. Gigerenzer and D.G. Goldstein. Reasoning the fast and frugal
way: Models of Bounded Rationality. Psychological Review. 103(4):
650-669. 1996.
H.A. Simon. Cognitive architectures and rational analysis:
Comment. In K. VanLehn (Ed.), Architectures for intelligence .
Hillsdale, NJ: Erlbaum. 25-39. 1991.

[22]

[24]
[25]

V. Kaptelinin and B.A. Nardi. Acting with technology activity
theory and interaction design, MIT Press, Cambridge, Mass., 2006.
R.E. Boyatzis and D.A. Kolb. From learning styles to learning skills:
the executive skills profile. Journal of Managerial Psychology.
ˆ10(5): 3-17. 1995
P.P. Heppner and W.P. Anderson, The relationship between problem
solving self-appraisal and psychological adjustment. Cognitive
Therapy and Research. 9: 415–427. 1984.
A. Macia. Visual perception of landscapes: Sex and personality
differences. Our national landscape: A conference on applied
techniques for analysis and management of the visual resource,
General Technical Report PSW-35: 279-85. 1979.
J. Palmer. Scientists and information: II. Personal factors in
information behavior. Journal of Documentation. 3:254-275. 1991.
K.E. Stanovich. Who is rational? Studies of individual differences in
reasoning. Erlbaum. Mahwah, NJ. (1999)
T.M. Green, D.H. Jeong, and B. Fisher. Using personality factors to
predict interface learning performance. Proceedings of Hawaii
International Conference on System Sciences 43, January 5-8, Koloa,
Kauai, Hawaii. USA. 2010.
P.R. Pintrich, R.W. Roeser, De ReGroot, and A.M. Elisabeth.
Classroom and individual differences in early adolescents'
motivation and self-regulated learning. The Journal of Early
Adolescence. 14(2): 139-161. 1994.
J.B. Rotter, Generalized expectancies for internal versus external
control of reinforcement. Psychological Monographs (80), Whole
No. 609. 1966.
Heuer, R. J. The Psychology of intelligence analysis. Center for the
Study of Intelligence. Center for the Study of Intelligence, CIA:
Washington, DC. 1999.
R. Sun, E. Merrill, and T. Peterson. From implicit skills to explicit
knowledge : a bottom-up model of skill learning. Cognitive Science.
25: 203-244. 2001.
J.R. Anderson. Acquisition of cognitive skill. Psychological Review.
89(4): 369 – 406. 1982.
C. Plaisant The challenge of information visualization evaluation.
Proceedings of the Working Conference on Advanced Visual
Interfaces, Gallipoli, Italy, 2004.
R.H. Hall, T.R. Rocklin, T.R. Dnsereau, S.F. Skaggs, P. Lisa, A.M.
O’Donnell, J.G. Lambiotte, and M.D. Young. The role of individual
differences in the cooperative learning of technical material. Journal
of Educational Psychology. 80(2): 172-178. 1988.
R. Chang C. Ziemkiewicz, T.M. Green, and W. Ribarsky. Defining
insight for visual analytics. Visualization Viewpoint, Computer
Graphics & Applications 29(2):14-17. 2009.
J. Hong, D. H. Jeong, C. D. Shaw, W. Ribarsky, M. Borodovsky,
and C. Song, GVis: A Scalable Visualization Framework for
Genomic Data Proceedings of IEEE EuroVis, 2005, 191-198.
M.B, Donnellan, F.L. Oswald, B.M. Baird, and R.E. Lucas. The
mini-IPIP scales: Tiny-yet-effective measures of the Big Five factors
of personality. Psychological Assessment (18),:192-203. 2006.
N. Krause, Stress and coping: Reconceptualizing the role of locus of
control beliefs. Journal of Gerontology, 41(5): 617-622. 1986.
H. Weiss and J. Sherman, Internal-external control as a predictor of
task effort and satisfaction subsequent to failure Journal of Applied
Psychology. 57(2): 132-136. 1973.
T.A. Judge, A. Erez, J.E. Bono, and C.J. Thoresen. Are measures of
self-esteem, neuroticism, locus of control, and generalized selfefficacy indicators of a common core construct? Journal of
Personality and Social Psychology 83(3): 693-710. 2002.
S. B. Messer. The relation in internal-external control to academic
performance. Child Development, 43(4). 1972. 1456 – 1462.
C. North. Toward measuring visualization insight. Computer
Graphics and Applications, IEEE 26: 6-9. 2006.

