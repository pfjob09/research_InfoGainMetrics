Using Visual Analytics to Maintain Situation Awareness in Astrophysics
Cecilia R. Aragon1
1

Sarah S. Poon2

Lawrence Berkeley National Laboratory
Berkeley, CA 94720

Gregory S. Aldering1
2

Space Sciences Laboratory
Berkeley, CA 94720

ABSTRACT
We present a novel collaborative visual analytics application for
cognitively overloaded users in the astrophysics domain. The
system was developed for scientists needing to analyze
heterogeneous, complex data under time pressure, and then make
predictions and time-critical decisions rapidly and correctly under
a constant influx of changing data. The Sunfall Data Taking
system utilizes several novel visualization and analysis techniques
to enable a team of geographically distributed domain specialists
to effectively and remotely maneuver a custom-built instrument
under challenging operational conditions. Sunfall Data Taking has
been in use for over eighteen months by a major international
astrophysics collaboration (the largest data volume supernova
search currently in operation), and has substantially improved the
operational efficiency of its users. We describe the system design
process by an interdisciplinary team, the system architecture, and
the results of an informal usability evaluation of the production
system by domain experts in the context of Endsley’s three levels
of situation awareness [1].
CR CATEGORIES: I.3.6 [Computer Graphics]: Methodology
and Techniques–Interaction techniques; I.3.8 [Computer
Graphics]: Applications–Visual Analytics
KEYWORDS: Data and knowledge visualization, scientific
visualization, visual analytics, situation awareness, astrophysics.
1

Rollin C. Thomas1

INTRODUCTION

In a growing number of government, business, and scientific
domains, individuals must make critical decisions under time
pressure while evaluating ever larger and more complex and
changing data streams. Examples and guidelines for development
of visual analytics applications to enable users such as first
responders, pilots, and other decision makers to operate
effectively without cognitive overload is a critical research topic.
In this paper, we describe a visual analytics application we
developed for an international astrophysics collaboration
operating custom-built equipment under tight time constraints.
The astronomer’s task of observing the heavens with a large,
multi-million dollar telescope has many parallels with that of
operating a jet aircraft. The astronomer must monitor a large and
complex set of operational data while maneuvering the telescope
and any attached equipment within particular constraints;
1

email: {CRAragon,GAldering,RCThomas}@lbl.gov
email: sarahpoon@gmail.com
3
email: quimby@astro.caltech.edu
2

IEEE Symposium on Visual Analytics Science and Technology
October 21 - 23, Columbus, Ohio, USA
978-1-4244-2935-6/08/$25.00 ©2008 IEEE

3

Robert Quimby3

California Institute of Technology
Pasadena, CA 91125

although there are some safeguards to protect against this, the
violation of these constraints could lead to damage of the
telescope or its key components. The telescope is frequently
located in an inhospitable environment, such as a remote
mountaintop, where hypoxia (lack of oxygen) is a constant threat.
Adverse weather conditions such as extremely high winds, rain,
sleet, or snow, are relatively common occurrences which
necessitate closing the dome immediately to prevent damage to
delicate optics. Even the rise of the sun is a danger, as equipment
could be damaged by sunlight focused by the telescope.
Equipment failures such as the telescope dome becoming stuck
also occur. Further adding to the operational challenges,
observing must necessarily be done at night, in the middle of the
lowest ebb of human alertness and cognitive ability.
Astronomical objects rise, move across the sky, and set along
arcs which many people have difficulty visualizing. Due to the
expense of telescope time, nights are often fully scheduled with an
array of astronomical objects, which must be observed in a
particular order in a tightly scheduled timetable for maximum
scientific benefit. Further, the phase of the moon, upper air
turbulence, fog, and changing cloud conditions throughout the
night can cause unpredictable variations in the schedule, as certain
objects become no longer visible at their appointed time slots.
Astronomers must be able to analyze and evaluate a large
amount of data and make cognitively demanding calculations
under time pressure, while at the same time being fully aware of
changing weather conditions, the approach of daylight and other
safety issues. They must focus on individually demanding and
precise tasks while maintaining an overall understanding of a
large amount of dynamic data affecting the telescope’s operation
and safety. This need to maintain awareness of an overall
situation while evaluating an overwhelming amount of critical and
ever-changing information was first documented in the aviation
and aerospace industry; it is called situation awareness, and has
been well-researched in the aviation and human factors literature
since the 1980s [2-4].
However, astronomers usually do not have the pilot’s advantage
of a sophisticated cockpit design to facilitate their tasks. The
software and hardware by which telescopes are operated are
usually custom-built, one-of-a-kind systems developed years or
decades ago, with clumsy, poorly designed or text-based user
interfaces. Further, astronomers may be operating telescopes they
are unfamiliar with, or remotely, in a different time zone or under
different weather conditions, so that normal human diurnal rhythms
or other environmental clues are working against their intuition.
In order to assist astronomers at the Nearby Supernova Factory
[5] to maintain situational awareness and perform time-critical
science tasks under these conditions, we developed a set of
visualization and analysis tools collectively called Sunfall Data
Taking. This system is a component of a larger visual analytics
system, Sunfall (SuperNova Factory AssembLy Line), that we
also developed. It has been in operation since 2006.
Usability studies of pilots and first responders have
demonstrated the effectiveness of simplifying visualizations that

27

provide key information aligned to human cognitive abilities [6-8].
Adapting such guidelines to the astrophysics domain, our system
features a visualization consisting of a mapping of the sky to a
rectilinear grid, where astronomical objects move linearly from
left to right over time, enabling easy prediction of multiple object
movement and visibility throughout the night. Other analysis and
visualization tools are also provided to enable the scientists to
make appropriate decisions concerning telescope operation and
data management rapidly and correctly.
This paper is organized as follows: Section 2 describes the
science background for which our system was developed; Section
3 provides a brief introduction to the Sunfall framework. Section 4
discusses related research. Section 5 describes the overall
architecture, design, and implementation of Sunfall Data Taking.
Section 6 presents a case study and the results of an informal
usability evaluation of the production system by astrophysicists
using the software to gather and analyze science data. Finally,
section 7 offers our conclusions and suggests directions for further
work.
2

SCIENCE BACKGROUND

One of the grand challenges in astrophysics today is the effort
to comprehend the mysterious “dark energy,” which accounts for
three-quarters of the matter/energy budget of the universe. The
existence of dark energy may well require the development of
new theories of physics and cosmology. Dark energy acts to
accelerate the expansion of the universe (as opposed to gravity,
which acts to decelerate the expansion). Our current
understanding of dark energy comes primarily from the study of
supernovae [9, 10].
The Nearby Supernova Factory (SNfactory) [5] is an
international astrophysics experiment designed to discover and
measure Type Ia supernovae in greater number and detail than has
ever been done before. These supernovae are stellar explosions
that have a consistent maximum brightness, allowing them to be
used as “standard candles” to measure distances to other galaxies
and to trace the rate of expansion of the universe and how dark
energy affects the structure of the cosmos. The SNfactory receives
50-80 GB of image data per night, which must be processed
within 12-24 hours to find potential supernova candidates
immediately and obtain maximum scientific benefit from the
study of these rare and short-lived stellar events.
Promising supernova candidates are sent for confirmation and
spectrophotometric follow-up by SNIFS (the SuperNova Integral
Field Spectrograph) [11] on the University of Hawaii 2.2m
telescope on the summit of Mauna Kea, Hawaii. Candidates are
imaged through a 15 x 15 microlens array on SNIFS, the spectral
data are processed at the summit, and then saved to a remote
database.
In order to maximize the efficiency of each night of telescope
operation, the scientists put a great deal of effort into parallelizing
operations such as telescope slew with data readout, or calibration
lamp warm-up with image acquisition. This had the effect of
substantially increasing the workload of the person conducting the
observations. On a typical night, the SNIFS schedule contains
approximately 15 supernova spectra, 7 or 8 standard star spectra,
and numerous associated calibration observations (arc lamps for
wavelength/instrument flexure mapping and continuums for flux
calibration). During each exposure, parallel operations must be
conducted while maintaining awareness of the exact moment
when the exposure will end so as to evaluate the observed target
and make an immediate followup decision. Timing is critical
because the schedule is so highly optimized.
It is this portion of the supernova followup pipeline, involving
full nights of observation remotely operating the SNIFS

28

spectrograph on the UH 2.2m telescope, that Sunfall Data Taking
is designed to address. Since the system was put into production,
the average number of supernova targets successfully observed
each night has increased, and the number of human errors causing
missed targets or incomplete schedules has decreased.
Previously, the scientists had believed that the key to solving
the problem of human error was to automate the supernova target
acquisition process as much as possible, and give the individual at
the telescope as little to do as possible. This was reminiscent of
descriptions of “pilot error” a few decades ago; pilots operating
increasingly complex aircraft systems were making mistakes.
When some of these mistakes led to spectacular catastrophes [12],
studies were devoted to finding and eliminating the cause of these
mistakes. The loss of situation awareness figured prominently in
many cases of pilot error [13].
After an evaluation of the scientists’ procedures at the
telescope, it became evident that the observing environment
possessed many of the same characteristics as an aircraft cockpit,
and that some of the principles of usability and situational
awareness which had been successfully applied in the aviation
arena might be adapted to the development of software for the
SNfactory astrophysicists.
3

SUNFALL FRAMEWORK

A multi-disciplinary team of computer scientists and
astrophysicists was involved in all aspects of the design and
implementation of the Sunfall (SuperNova Factory AssembLy
Line) software framework for the SNfactory. Sunfall is a
collaborative visual analytics system that accelerates science
discovery by utilizing novel interactive visualization and analysis
techniques to facilitate insight into complex, noisy, highdimensional, high-volume, time-critical scientific data. The
system combines sophisticated image processing algorithms,
statistical analysis, and machine learning with highly interactive
visual interfaces to enable collaborative, user-driven scientific
exploration of supernova image and spectral data.
Sunfall is currently in operation at the Nearby Supernova
Factory; it is the first visual analytics system in production use at
a major astrophysics project.
A major component of the Sunfall framework is the Supernova
Warehouse (SNwarehouse), a comprehensive supernova data
management, workflow visualization, and collaborative scientific
analysis tool. The SNwarehouse contains a PostgreSQL database
hosted on a dedicated SNfactory database server running SuSE
Linux 9.3, middleware, and a graphical user interface (GUI)
implemented in Java. Sunfall Data Taking is the component of
SNwarehouse that is specifically designed for use during
telescope operation.
Collaboration scientists can access the Sunfall Data Taking
GUI from any networked computer worldwide via a remote
deployment mechanism. Security is provided via password
authentication and encrypted communication channels.
SNwarehouse furnishes project scientists with a shared workspace
that enables easy distribution, analysis, and access of data.
Collaboration members can view, modify, and annotate supernova
data, add comments, change a candidate’s state, and schedule
follow-up observations from work, home, while observing at the
telescope, or even when attending conferences. This access is
critical due to the 24/7 nature of SNfactory operations. All
transactions are recorded in the SNwarehouse database, and the
change history and provenance of the data are permanently stored
(records cannot be deleted in order to maintain the change history)
and continuously visible to all authenticated users.
This paper focuses only on the Sunfall Data Taking component
of the system and its simplifying Sky visualization.

4

PREVIOUS WORK

We discuss related work in the areas of astronomical
applications, including calculations and visualizations, and visual
analytics systems developed for cognitively loaded or timepressured users. We also briefly touch on scientific analytics and
situation awareness research.
The astronomical calculations in the Sky visualization are
derived from SkyCalc, originally written by John Thorstensen
[14]. Previously, astronomers would run SkyCalc from the
command line at the telescope, inputting their observatory
parameters, observing date, and target lists. This would provide
times of sun and moon rise/set and hourly tables of the elevations
of each target. The astronomer would then try to collate this
information, but would have to reinput many parameters to
examine a slightly different “what if” scenario. Visual wrappers to
SkyCalc have been developed before, including Thorstensen’s
“SkyCalc GUI” and “SkyCalcDisp” [37]; however, the former is
simply a graphical version of the command-line interface and the
latter contains a three-dimensional projection of object positions
that does not facilitate prediction of target motion. On the other
hand, the Sky visualization in Sunfall Data Taking was designed
specifically to help the astronomer balance the above-described
constraints in a visually intuitive way—often during a nighttime
observing session—at the click of a button.
The Sky differs from other astronomy visualization programs in
that many of them are after-the-fact image processing programs,
designed to enhance faint or low-contrast image data, rather than
to provide an operational simplification to aid in time-constrained
observational decisions [15, 16]. Astronomers frequently use tools
such as SAOImage ds9 [17] for detailed viewing of their images,
or IRAF [38] for spectral visualization. However, neither of these
is integrated into an observing package as is Sunfall Data Taking.
In the field of scientific visualization for astronomy, software
such as Li et al.’s Scalable WIM [18] focuses on the ability to
browse a large-scale three-dimensional model of the universe.
Again, this technique is not designed for use under time pressure.
In Illuminating the Path, one of the important focus areas laid
out for visual analytics research is the development of systems
designed for first responders and other cognitively-loaded users
[19]. There has been much recent work in this area, including
several systems to visualize time-varying data on mobile devices
[6, 7, 20, 21], noting the constraints of updating time-critical
visual information on a low-resolution device. Other efforts to
develop mobile systems for emergency response include the
Measured Response project of the Purdue Synthetic Environment
for Analysis and Simulation [22].
Related efforts involve approaches to visualizing time-varying
geographic data, such as [23], [24], and [25], and Tesone and
Goodall have developed a visual analytics technique, “smart
aggregation,” specifically to aid with situation awareness [26].
There is a large body of literature on situation awareness in
general, and a full description of such literature is beyond the
scope of this paper. The book by Endsley et al. [4] provides an
excellent survey of the work in this area.
Similarly, there is a developing body of work on scientific
analytics, or the application of visual analytics to science
problems. Examples can be found in [27] and [28], among others.
In general, however, there has not been much work on timecritical visualizations of scientific data, or on the combination of
situation awareness enhancement and scientific data, since it is a
de facto assumption that scientists must be pondering and
analyzing their data in a contemplative fashion in their offices.
Our case study of the application of visual analytics to improve
situation awareness for astrophysics users appears to be unique.

5

SUNFALL DATA TAKING

5.1
Design Process
In order to design an effective collaborative visual analytics
system for the SNfactory, we first conducted, in mid-2005, an
extensive, two-month evaluation of the existing SNfactory
procedures and environment. Data sources used for evaluation
included individual interviews, observation of team members
performing typical project tasks, review of existing source code,
literature reviews, examination of other supernova search projects,
and consultation with physicists and computer scientists with
relevant experience building similar scientific software systems.
All Sunfall user interfaces were designed and implemented
using participatory and iterative design techniques; for example,
interactive prototypes were used to evaluate areas where existing
interfaces did not support scientists’ workflow. Scientists’
feedback sometimes led to major redesigns of the interface. The
system was implemented from the beginning with this possibility
in mind, so that changes were easily made and accepted as an
appropriate part of the development process [29].
Participatory design was a natural choice for Sunfall Data
Taking, especially given that expert domain knowledge was
needed to define the use cases. Scientists were involved in the
design process from the start, helping to define the problem space
and outlining the necessary functions.
The design of the Data Taking GUI went through several
prototypes prior to release, including low fidelity paper prototypes
and high fidelity, semi-functional prototypes. Each prototype was
evaluated by the scientists, who provided feedback on areas where
the interface was confusing or too tedious to use (i.e. too many
steps to perform a particular task). Once deployed, we spent
several weeks observing the use of the interface, noting any areas
where the interface failed to support tasks or was confusing.
Informal followup interviews were conducted after such sessions,
to gather additional information needed to make incremental
improvements (or major changes) to the interface.
5.2
Telescope Observing Procedures
Each night of spectral observations with SNIFS at the
University of Hawaii 2.2m telescope requires a complex set of
procedures involving collaboration among a geographically
distributed team, and the operation of legacy software telescope
controllers driving one-of-a-kind hardware.
The scientist performing the night’s observations is known as
the “shifter.” The shifter may be located anywhere in the world,
although SNfactory collaboration members attempt to distribute
the operational tasks among time zones so as to minimize
nighttime work. Additional members of the team include a
telescope operator physically located in the Hilo, Hawaii operations
room, and senior scientist experts who may be physically located
on the other side of the Earth from the current shifter. At the end
of the shift, another scientist evaluates each night's set of
observations using a slightly different view of the same data.
5.2.1
Legacy Software Interface
The telescope interface is complex, involving a number of shell
scripts which must be run from the command line at various
times. Functions of the interface include data monitoring as well
as telescope control. The scripts interface directly with the
telescope and spectrograph device drivers. There are several
systems that directly control the telescope.
The telescope control system (TCS) user interface was written
using curses, a Unix terminal control library originally developed
in 1977 [30]. When TCS was originally written, space was at such
a premium on the screen that the developers were forced to use
every possible shortcut; for example, the Scottish word “hie” is

29

used to describe the state of one of the mirrors when it is in
between two positions.
There are also two “directors,” which monitor a large amount of
information from three CCD cameras, the SNIFS instrument
itself, as well as the TCS. These five information streams are
piped into two windows, resulting in an extremely rapid flow of
information past the eye. The display is filled with blinking and
scrolling text, as numeric values are dynamically updated and
various internal program status messages rapidly scroll across
several text windows (Figure 1). High priority error messages are
printed in red to distinguish them from lower priority status
messages; however, all the flickering and movement on the screen
can be distracting, especially since relatively unimportant status
messages are continuously scrolling past the window.

Figure 1. Part of a VNC window of the telescope control system.

To start the night’s observing, the shifter must first establish an
SSH tunnel to the Mauna Kea summit computer (a Dell
Dimension PC running Red Hat Linux), then connect to a VNC
(Virtual Network Computing) [31] server on the summit machine,
opening two local windows to establish the interface. Two other
machines at the summit are custom-built, possessing Tyan
motherboards that each enable operation of two camera PCI
interfaces simultaneously. The shifter must also connect to a
prearranged chat room where all scientists involved in the

30

observation participate, ask questions, provide advice, and use an
informal protocol to transfer positive control of telescope
operation.
5.3
Data Taking Development
To a novice user, the telescope interface is dauntingly complex.
The learning curve is extremely steep at the beginning of training.
The scientists concluded that it was critical to reduce the shifter’s
decision-making load. They initially decided that the best method
of doing this was to create an “autopilot,” an automated
instrument control program that would run the entire observing
process without human intervention. However, unexpected
hardware interactions as well as operational changes ensured that
the automated instrument control program could not
autonomously run throughout the night. Additionally, it proved
impossibly complex to modify the program to reliably compensate
for the plethora of unexpected events that could occur during a
night’s observing; human intervention was consistently required.
Based on this initial experience, it was determined that the
shifters needed a decision support system to supplement the
automation. Although some level of automation was necessary to
reduce drudgery and lighten the shifter’s workload, it became
clear that a system was needed that combined automation with a
visual interface that facilitated human intervention. The scientists
instituted various protocol changes and added to the existing
system. The Data Taking system was designed and implemented
by an interdisciplinary team of computer scientists and
astrophysicists, alleviating many sources of shifter error. Tasks
the shifters performed with Data Taking included viewing spectral
images, exploring data, keeping a standardized “notebook” on sky
and instrument conditions, and decision making. The intent was to
have the shifters allocate their attention to higher-level tasks; in
particular, to evaluating their rate of performance on the schedule,
determining whether or not conditions sufficed to perform lowerpriority observations, and assessing data quality.
5.3.1
Data Taking Components
The Data Taking GUI is depicted in Figure 2. This interface
runs as a separate window on the summit computer and is
intended to augment rather than supplement the existing telescope
control interface.
Operational constraints during software
development precluded a complete redesign of the entire telescope
control interface, although incremental improvements were made.
The automated instrument control program was left in place; if
nothing goes wrong during the night, it will automatically slew
the telescope to each target in turn, start an exposure of the correct
length, record the data, and move on to the next target. However,
in the event of weather or mechanical problems, quick and
accurate decision-making is required. Data Taking was designed
to support such decisions, with the express goal of improving the
shifter’s situational awareness. To this end, a number of
components were designed to provide supplemental information
about critical observing conditions, as well as provide predictive
tools to enable the shifter to make scheduling decisions easily and
correctly.
Since the shifter is operating the telescope remotely, they may
be unaware of deteriorating weather conditions or the approach of
sunrise. A software agent running in the chat room broadcasts
key astronomical events such as sunrise, and provides information
on current telescope operation, including the current exposure or
the process of slewing to new coordinates.
The raw data from the SNIFS spectrograph is complex and
requires a significant amount of processing to yield meaning to
the scientist. A visual depiction of the accuracy of the telescope
aim and signal strength provides more information more quickly

than tables of numeric data. The two small images (“postage
stamps”) on the left-hand side of each observation subwindow are
a custom visualization designed by scientists to indicate whether
the telescope is accurately pointed at the target and whether a
good signal was received by the spectrograph.
The data taken by SNIFS consists of two channels, blue and
red. A channel produces a spectral decomposition of each sample
of a 15x15 pixel image of a 6”x6” square of the sky [11]. Thus,
each channel produces an x by y (position) by λ (wavelength)
“datacube.” To make the Data Taking postage stamps, the
datacube is collapsed (averaged) along the λ axis, leaving an x by
y image. Since this image averages over many wavelengths, it is
more accurate than a single wavelength slice, roughly as
(Nslices)1/2, where Nslices is the datacube dimension in the
wavelength direction. The program that performs this operation is
run as part of the real-time SNIFS pipeline that is run after each
spectrum is read out. One of the outputs of this program is the
“postage stamp” visualizations, which were integrated into the
final version of Data Taking (two images, lower left of Figure 2).

Figure 2. Sunfall Data Taking window. The observer can follow the
targets on The Sky visualization, take notes on the success or
failure of each observation, telescope status and weather
conditions, and can reschedule targets if necessary.

Color-coding and position indicate the accuracy and signal
strength of the received data. A bright dot in the center of both
postage stamps is a clear indicator of “good centering.” A failed
observation (due to, say, the passing of a cloud or dome-close
trigger due to a humidity spike) contains no such bright dot at the
center of the image. A marginal observation may be one where the
target is less than optimally centered in the microlens array.
Prior to each night’s observation at the telescope, a schedule is
made in order to allocate telescope time to each target. In
SNwarehouse, the scheduler starts by filtering for only those
targets with observation requests. With this list, the scheduler
must order and assign exposure times for each target using a
variety of techniques. Exposure times are automatically
determined using a lookup table based on the phase and redshift
of the target. Considering these exposure times, the scheduler
must also order the target list according to when the target will be
visible in the sky by the telescope. The Sky visualization offers
insight for this task (upper section of Figure 2).

5.4
The Sky Visualization
It can be challenging for humans to imagine and visualize the
path of astronomical objects over time, as they appear to move
along the inside of the hemisphere of the night sky. Further, even
an astronomer skilled in the art of visualizing celestial coordinates
can have difficulty predicting the paths of several objects in the
night sky, accurately estimating which of them will avoid clouds,
and calculating when they will reach the optimal position for
observing.
The key idea in the Sky visualization is the mapping of the
spherical night sky to a two-dimensional rectilinear projection,
where astronomical objects’ paths over time move linearly from
left to right. Although there is some spatial distortion (similar to
that of a Mercator projection of the Earth [32]), it is much easier
for observers to predict the future position of objects moving
along a linear path in a plane.
This transformation enables observers to make quick decisions
on what targets to observe during the night after unexpected
events occur. (Examples of typical changes: new targets come in,
clouds increase exposure times, targets are brighter/fainter than
expected, instruments fail, etc.).
One of the major causes of changes in the schedule concerns
the observation of certain targets called final references. If
conditions are not good enough to take a final reference image (a
spectrum of the coordinates after the supernova has completely
faded), then shifters are supposed to replace those observations
with other targets.
Additionally, sometimes a screening
observation is scheduled (to determine whether a target is even
worth following at all), and based on the results, follow-up
decisions must be made.
Another use of the visualization involves detecting “packed”
parts of the schedule in the Sky. If there are many targets at the
same sky coordinates, the shifter knows ahead of time they will
have to be efficient -- this appears in the strip chart as a set of
targets “stacking up” like books. So, it points to trouble spots
requiring extra alertness on the part of the shifter. Thus the Sky
offers an intuitive and fast means of adapting to changing
conditions and predicting areas of difficulty.
5.4.1
Sky Visualization Components
The Sky visualization depicts the positions of targets in the sky
at a given time and ground location. The green lines represent
airmass (how thick the atmosphere is along the line of sight
between an object and the observer on the Earth’s surface) for
target coordinates at the specified time. The blue line represents
the horizon, and the red halo around the moon is the “lunar
exclusion zone,” the area where light cast by the moon makes it
difficult or impossible to view a faint target. The yellow circle
represents the sun. Major telescope names and corresponding
latitudes and longitudes are displayed on a drop-down menu so
the visualization can be applied to other telescopes as well. The
time can be changed so the viewer can plan observations for the
remainder of the night or even further into the future. If the target
appears within the 2.0 airmass lines, it is high enough in the sky to
be visible to the telescope, assuming good weather. Airmass is a
critical factor in determining quality of astronomical observations.
If the airmass increases above 2.0, the quality of the observation
drops dramatically.
5.4.2
Astronomical Calculations and Mapping
The locations of celestial objects are typically specified in
spherical coordinates, right ascension (RA or α) and declination
(DEC or δ). RA and DEC are the celestial analogs to longitude
and latitude on Earth. The celestial equator is the direct projection
of Earth's equator onto the celestial sphere, and defines the
reference for declination. The reference for right ascension is the

31

First Point of Aries, marked by the location of the sun at the
moment of the vernal equinox [33].
Hour angle (h) describes the position of the object based on the
local time and gives information about the object’s position in the
sky relative to a local observer. We map the sky to hour angle vs.
declination, so that the observer could see at a glance how many
hours an object would be visible, or how long it would be before it
rose/set. To do this, the horizon line and lines of constant airmass
are mapped onto the displayed rectangle. These can be calculated
for any latitude and longitude on the earth. We use:

h = α − LST
where h is hour angle, α is right ascension, and LST is local
sidereal time [14, 33].
Given an observer's longitude and the universal time (UT), one
calculates the local sidereal time. Then, given the celestial
coordinates of a target (α, δ), one can calculate the “local”
coordinates (h, δ) used in the Sky.
To calculate the airmass and horizon lines, we determine
airmass by approximating the atmosphere as a plane parallel slab.
In this approximation airmass equals sec(z), where z is the zenith
distance. Airmass goes to infinity at the horizon (an infinite planeparallel slab).
To draw the lines of constant airmass, including the line that
defines the horizon, let a be the altitude, l be the latitude, δ
declination, and h hour angle. Then we have:

sin( a ) = sin( l ) sin( δ ) + cos( l ) cos( δ ) cos( h )
This value is a constant, as these are lines of constant angular
distance from the zenith, or equivalently, constant altitude. This
allows one to draw a curve on the (α, δ) plane for any constant
altitude, including the horizon, altitude = 0.
So, for example, to draw the lines at airmass 2.0, we have for
any altitude a and zenith distance z:
a = π − z
2

and
z = sec

−1

( 2 . 0 ) = cos

−1

( 21. 0 )

So the airmass 2.0 line is calculated from the above by:
a = π − cos
2

−1

( 12 )

The lunar exclusion zone is defined (where p is the lunar phase,
1 at full moon and 0 at new moon) to be a circle of area 70p2
degrees. This is astronomers’ generally accepted estimate for how
close one might be able to work near the moon, at visible
wavelengths, at a good site with clear skies.
5.5
Other Visualization Tools in Data Taking
A key component of Data Taking is the access to current and
historical supernova spectral data. This information assists
scientists to quickly evaluate the priority of a given supernova
target compared to other potential targets, when a decision must
be made as to which targets to drop from the night’s schedule.
Supernova scientists, like many domain experts, demonstrate
strong visual pattern recognition ability in their field of expertise.
They can take a single glance at a picture of a complex spectrum,
and instantly determine its type, age in days before or after peak
brightness, and whether it exhibits any unusual properties. An
early Type Ia supernova (captured well before peak brightness)
will display a certain pattern in its spectral plot. A later supernova
(imaged a few days past peak brightness) will show other

32

characteristic spectral lines and features. The spectral data is
displayed in optimal form in order to facilitate domain experts’
visual pattern recognition ability. Spectral data are plotted in
green and blue. The spiky grey lines depict the spectrum of the
background sky. The broad grey bands represent areas of
atmospheric absorption. Due to the complexity of the data
(thousands of points of flux vs. wavelength for each observation)
and the necessity to make rapid, accurate decisions in order to
maximize the use of limited, expensive telescope time,
visualization provides the most efficient solution to the problem.
The scientist can also access the raw numeric data by clicking on
any of the images or spectra.
6

INFORMAL USABILITY EVALUATION:
CASE STUDY

AN

ASTROPHYSICS

The nature of the telescope interface and the high cost of
telescope and scientist time precluded formal usability testing of
Data Taking. We therefore evaluated Data Taking via informal
interviews with scientists who had used the system in the
production environment, and by “digital ethnography:” analysis of
chat logs recorded during observing sessions at the telescope.
In order to perform this analysis, we evaluated user comments
from interviews and chat logs according to five suggested areas
for evaluation of visual analytics systems proposed by Scholtz
[34]: situation awareness, collaboration, interaction, creativity,
and utility, with particular emphasis on situation awareness.
Although this analysis is necessarily subjective, it is considered
appropriate for operational environments where the user cannot
take time out from critical work to answer usability questions.
Endsley has defined situation awareness (SA) as “the
perception of elements in the environment within a volume of
time and space, the comprehension of their meaning, and the
projection of their status in the near future.” [1, 4, 35] Endsley’s
model defines three stages in the formation of situation
awareness: perception (level 1 SA), or basic monitoring and cue
detection of elements in the environment; comprehension (level 2
SA), the ability to interpret this information correctly and combine
it with other information; and projection (level 3 SA), the ability
to predict what happens next.
The lack of situation awareness has been shown to be a major
cause of human error and accidents in many domains [13, 36],
especially those with high information flow and potentially
serious consequences of errors.
6.1.1
Procedure
We conducted interviews with five domain experts, all of whom
have been using the telescope control interface for at least two
years before Data Taking (DT) was developed and one year after.
We also analyzed six months of chat logs from 2007, comprising
several thousand user comments from a total of 21 unique users.
6.1.2
Analysis of User Comments
We first categorized user comments in the chat logs as positive,
negative, or neutral about the Data Taking interface. Although the
vast majority of comments were neutral, user comments that
expressed an opinion were generally positive (57 positive vs. 13
negative, and the positive comments were much more emphatic
than the negative ones). We then further categorized the user
comments as follows: general positive comments (39), noticing
new features in DT (4), describing DT’s utility (5), using DT to
make decisions (11), using DT for exploration (2), data
processing/image retrieval not completed in a timely fashion (6),
lack of transparency in the data processing (2), and limitations (5).
We annotated the user comments according to the three levels of
SA. These are described below, and examples of each category
and how it illustrates the level of SA are presented.

6.1.2.1
Perception: Situation Awareness Level 1
Level 1 SA, perception, the most basic of the levels of situation
awareness, is typically the easiest for a user to develop and a
system to support, and often it is taken for granted. However,
there were certain cases in our operating environment where it
became clear that our system was fostering previously
undeveloped perception of objects.
This was demonstrated by the following comments:
“DT forces you to pay attention to standard stars. Before, it was
so automatic, it was something that just happened (coffee break
time). Yet the standards are so important to calibration, they
should pay attention.”
“With the new interface, with the targets popping up in the
interface, it reminds you to pay attention, you know there are
certain pieces of information you need to fill out about each
target.”
6.1.2.2
Comprehension: Situation Awareness Level 2
At level 2, the operator is synthesizing information to become
aware of the big picture, to understand the meaning of the data
they are gathering, and to use it to further their own goals.
Examples of this are:
“They've actually been looking at the data, the looking is
important, b/c they wanted to know, what is this guy, what do we
know, we see this is the 10th spectrum, it's a nice candidate,
people are excited, nobody knows about this guy, what can we
find out.”
“When they see the spectrum, they become interested in
learning more about the target, start looking at the other spectra
taken ... they want to know more about this target.”
6.1.2.3
Projection: Situation Awareness Level 3
Finally, at level 3 SA, the user can accurately predict what it
going to happen next. Comments from interviews indicate that
DT was quite successful in fostering this final level of situation
awareness.
“The Sky allows the shifter to know how [to] prioritize tasks,
especially when the schedule changes or falls behind.”
“Having a clear view in one plot of where you stand, and how
much time you have left to perform the observation of the various
target is great... to be ‘blind’ is much worse.”
6.1.2.4

Evaluation Areas: Collaboration, Interaction,
Creativity, Utility
Scholtz suggests four other evaluation areas for visual analytic
systems: collaboration, interaction, creativity, and utility.
Collaboration
User feedback indicated that Data Taking enhanced
collaboration. Several people remarked on the fact that the tool
systematized shifter comments.
“What’s great is now every day I get comments about each
obs[ervation] from the shifter; [the previous system] didn't do
that.”
Interaction
DT greatly enhanced the shifters’ ability to interact with the
data; this also facilitated their interest and attention, and increased
their levels of situation awareness.
“DT gives the shifter data that either they couldn't or was too
difficult to access, and now, the shifters are much more interested
in exploring the targets while on shift.”
Utility
Over and over again, users commented on how useful the
program was. An interesting side effect of this is that the utility of
the program was perceived as having a calming effect on the
shifter. Perhaps this reveals how much an interface with poor

usability can add to stress and cognitive load. The scientists also
commented on how DT improved everyone’s efficiency.
“Having a visual view of the schedule / candidates in this sky
image has been extremely useful. Also, and this is one of my main
remarks, taking data is hard [on] your nerves ... and when you are
nervous ...you make lots of mistake[s] / bad choice[s]”
“In 2007 we had really good efficiency; users [made] minimal
mistakes ... and on this point [DT] helped a lot by ‘cooling down’
the shifter.”
“The quick visualization of spectra and reconstructed images is
also extremely useful.”
“To be brief DT changed my life...”
Creativity: Discovery and Decision-Making
Creativity is not normally a characteristic one would consider in
developing software. However, given the challenging nature of
the observing shift, creative solutions to problems are frequently
necessary. Thus, we categorized effective decision making and
discovery under creativity. User comments indicated that Data
Taking facilitated decision-making.
“Having access to the full SNfactory target history ... this
helped me a lot ... to point out problem[s] on a specific target (no
way we can follow this guy with SNIFS ... make sure that it will
not be put in a schedule again ...)”
“Yes, DT has been very useful during my shifts. The graphical
view of the objects on the sky ... eased the decision of canceling
an exposure or to insert an extra observation in the schedule. I
didn't [m]ake such decisions before DT.”
6.1.3
Discussion and Summary
In general, Sunfall Data Taking received very positive user
feedback. In all five of Scholtz’s areas of evaluation, Data Taking
received favorable reviews.
However, negative comments
indicated directions for future work. The background mechanism
(Data Forklift) which handled the data processing and image
retrieval was sometimes slow or it was unclear what stage of
processing the data had reached. This was due in part to the
necessary reliance on outside services such as the database in
France. This was one area in which scientists’ situation
awareness could be enhanced further. In future versions, we will
include a status window describing the current state of the data
transfer and processing.
However, in taking the user comments as a whole, we found
evidence that Data Taking has improved scientists’ situation
awareness, increased overall efficiency, and has assisted scientists
to make collaborative decisions. Selective presentation of data,
the ability to interact with the data, and the use of simplifying
visualizations were all effective in increasing situation awareness
in this time-critical scientific application.
7

CONCLUSIONS AND FUTURE WORK

We described a case study involving a visual analytics system
developed for astrophysicists collaboratively operating a large
telescope for time-critical supernova observation. Additionally,
we showed the effectiveness of a simplifying visualization,
projecting three-dimensional data to a rectilinear two-dimensional
format, in increasing situation awareness for users needing to
synthesize large amounts of streaming data and make critical
decisions under time pressure. This confirms previous studies [68] on the value of simplifying visualizations in interfaces designed
for cognitively-overloaded users.
Furthermore, we have demonstrated that the cultivation and
maintenance of users’ situation awareness, a concept first studied
in the field of aviation and cockpit management, is crucial in other
fields where time-critical decisions involving large, dynamic data
sets must be made.

33

Finally, perhaps one of the most important lessons to be learned
from this case study is the importance of forming closely
integrated, interdisciplinary teams where members from all fields
are involved in the participatory design process from the
beginning of the project. Designing effective, usable interfaces for
complex, time-critical scientific decision making requires both
domain expertise and software expertise, and the two must be
closely intertwined for the ultimate success of the project. In our
case, the physicists attributed the successful adoption and general
satisfaction with the interface to the participatory design process.
The use of this technique allowed the interface to closely match their
needs and led to a general sense of ownership of all the software, not
just the science algorithms. In addition, all members of the team
participated in the software development process, which included
regular group meetings and informal code reviews, thus facilitating
the marriage of sophisticated science algorithms with software
engineering best practices.
Although the users have indicated high satisfaction with the
system, certain parts of the user interface can be improved further.
For example, when there are many targets displayed in the Sky
visualization, their labels overlap and occlude one another. In a
future version, we plan to implement excentric labeling as
described by Fekete and Plaisant in [39]. Additionally, we plan to
include a data processing status window to alleviate some of the
difficulties discussed in section 6.1.3. Finally, we plan to address
some of the user comments on system limitations, such as adding
the ability to interactively change the Data Taking schedule,
adjust the DT window size, and recover more smoothly when the
middleware fails.
8

ACKNOWLEDGMENTS

We would like to thank the anonymous reviewers for their
thoughtful suggestions, and the scientists of the SNfactory
collaboration for their time and detailed feedback. The authors
wish to recognize and acknowledge the very significant cultural
role and reverence that the summit of Mauna Kea has always had
within the indigenous Hawaiian community. We are most
fortunate to have the opportunity to conduct observations from
this mountain. This work was supported in part by the Director,
Office of Science, Office of Advanced Scientific Computing
Research, of the U.S. Department of Energy under Contract No.
DE-AC02-05CH11231, and by the Director, Office of Science,
Office of High Energy Physics, of the U.S. Department of Energy
under Contract No. DE-FG02-92ER40704, and by a grant from
the Gordon & Betty Moore Foundation. This research used
resources of the National Energy Research Scientific Computing
Center, which is supported by the Office of Science of the U.S.
Department of Energy under Contract No. DE-AC02-05CH11231.
REFERENCES
[1] M. R. Endsley, "Toward a theory of situation awareness in dynamic systems,"
Human Factors, vol. 37, pp. 32-64, 1995.
[2] M. R. Endsley, "Designing for Situation Awareness in Complex Systems,"
Proceedings of the Second International Workshop on Symbiosis of Humans,
Artifacts and Environment, Kyoto, Japan, 2001.
[3] M. R. Endsley, "Situation Awareness and Human Error: Designing to Support
Human Performance," High Consequence Systems Surety Conference,
Albuquerque, NM, 1999.
[4] M. R. Endsley and D. J. Garland, Situation Awareness Analysis and
Measurement: Lawrence Erlbaum Associates, 2000.
[5] G. Aldering, G. Adam, P. Antilogus, P. Astier, R. Bacon, et al., "Overview of the
Nearby Supernova Factory," Proceedings of the SPIE, 2002.
[6] L. Chittaro, F. Zuliani, and E. Carchietti, "Mobile Devices in Emergency
Medical Services: User Evaluation of a PDA-Based Interface for Ambulance
Run Reporting," in Mobile Response, vol. 4458/2007: Springer Berlin /
Heidelberg, 2007, pp. 19-28.
[7] S. Kim, Y. Jang, A. Mellema, D. Ebert, and T. Collins, "Visual Analytics on
Mobile Devices for Emergency Response," IEEE Symposium on Visual
Analytics Science and Technology, Sacramento, CA, 2007.

34

[8] C. Aragon and M. Hearst, "Improving Aviation Safety with Information
Visualization: A Flight Simulation Study," CHI 2005: ACM Conference on
Human Factors in Computing Systems, Portland, OR, 2005.
[9] S. Perlmutter, G. Aldering, G. Goldhaber, et al., "Measurements of Omega and
Lambda from 42 High-Redshift Supernovae," Astrophysical Journal, vol. 1999,
pp. 565-586, 1999.
[10] A. G. Riess, A. V. Filippenko, et al., "Observational Evidence from Supernovae
for an Accelerating Universe and a Cosmological Constant," Astrophysical
Journal, vol. 1998, pp. 1009-1038, 1998.
[11] B. Lantz, et al., "SNIFS: a wideband integral field spectrograph with microlens
arrays," SPIE, 2004.
[12] A. Degani, Taming Hal: Designing Interfaces Beyond 2001. New York, NY:
Palgrave Macmillan, 2004.
[13] C. Hartel, K. Smith, and C. Prince, "Defining aircrew coordination: searching
mishaps for meaning," 6th Int'l Symposium on Aviation Psychology, Columbus,
OH, 1991.
[14] J. Thorstensen, SkyCalc User's Manual, http://zimmer.csufresno.edu/
~fringwal/skycal.pdf, 1994, accessed 2008.
[15] F. Cavicchio, Astroart 4.0 - 96 bit image processing, http://www.msbastroart.com/, 2008, accessed 2008.
[16] L. Christensen, ESA/ESO/NASA Photoshop FITS Liberator,
http://www.spacetelescope.org/projects/fits_liberator/index.html, 2008,
accessed 2008.
[17] W. Joye and E. Mandel, "New Features of SAOImage DS9," Astronomical
Data Analysis Software and Systems XII, vol. 295, 2003.
[18] Y. Li, C. Fu, and A. Hanson, "Scalable WIM: Effective Exploration in LargeScale Astrophysical Environments," IEEE Transactions on Visualization and
Computer Graphics, vol. 12, pp. 1005-1011, 2006.
[19] J. J. Thomas and K. A. Cook, Illuminating the Path: The Research and
Development Agenda for Visual Analytics: National Visualization and Analytics
Center, 2005.
[20] A. Pattath, B. Bue, Y. Jang, D. Ebert, X. Zhong, A. Ault, and E. Coyle,
"Interactive Visualization and Analysis of Network and Sensor Data on Mobile
Devices," Proceedings of IEEE Symposium on Visual Analytics Science and
Technology, Baltimore, MD, 2006.
[21] S. Eick, M. Eick, J. Fugitt, B. Horst, M. Khailo, and R. Lankenau, "Thin Client
Visualization," IEEE VAST, Sacramento, CA, 2007.
[22] Purdue, Synthetic Environment for Analysis and Simulation,
http://www.mgmt.purdue.edu/centers/perc/html, 2008, accessed 2008.
[23] T. Kapler and W. Wright, "Geotime information visualization," Proceedings of
IEEE Symposium on Information Visualization, 2004.
[24] C. Pan and P. Mitra, "FemaRepViz: Automatic Extraction and Geo-Temporal
Visualization of FEMA National Situation Updates," IEEE VAST, Sacramento,
CA, 2007.
[25] RSOE, RSOE HAVARIA AlertMap, http://hisz.rsoe.hu/alertmap/
woalert.php?lang=eng, 2008, accessed 2008.
[26] D. Tesone and J. Goodall, "Balancing Interactive Data Management of Massive
Data with Situational Awareness through Smart Aggregation," Proceedings of
the IEEE Symposium on Visual Analytics Science and Technology,
Sacramento, CA, 2007.
[27] C. D. Shaw, G. Dasch, and M. Eremeeva, "IMAS: The Interactive
Multigenomic Analysis System," IEEE VAST, Sacramento, CA, 2007.
[28] R. Maciejewski, B. Tyner, Y. Jang, C. Zheng, R. Nehme, and D. Ebert,
"LAHVA: Linked Animal-Human Health Visual Analytics," IEEE VAST,
2007.
[29] C. Aragon and S. Poon, "The Impact of Usability on Supernova Discovery,"
Workshop on Increasing the Impact of Usability Work in Software
Development, CHI 2007: ACM Conference on Human Factors in Computing
Systems, San Jose, CA, 2007.
[30] K. Arnold, "Screen Updating and Cursor Movement Optimization: A Library
Package," University of California, Berkeley 1977.
[31] B. Nguyen, VNC: Virtual Network Computing, http://www.tldp.org/
LDP/Linux-Dictionary/html/index.html, 2004, accessed 2008.
[32] R. Israel, Mercator's Projection, http://www.math.ubc.ca/~israel/
m103/mercator/mercator.html, 2003, accessed 2008.
[33] H. Karttunen, P. Kroger, H. Oja, M. Poutanen, and K. Donner, Fundamental
Astronomy, Second Edition ed: Springer-Verlag, 1994.
[34] J. Scholtz, "Beyond Usability: Evaluation Aspects of Visual Analytic
Environments," IEEE Symposium on Visual Analytics Science and Technology,
Baltimore, MD, 2006.
[35] M. R. Endsley, "Situation awareness global assessment technique (SAGAT),"
Proceedings of the National Aerospace and Electronics Conference, 1988.
[36] D. Merket, M. Bergondy, and H. Cuevas-Mesa, "Making sense out of teamwork
errors in complex environments," 18th Annual Industrial/Organizational
Behavior Conference, Roanoke, VA, 1997.
[37] J. Thorstensen, "SkyCalc GUI Manual," http://mdm.kpno.noao.edu/
Manuals/doc/guimanual.html, accessed 2008.
[38] T. Boroson, et al., "NOAO Image Reduction and Analysis Facility,"
http://iraf.noao.edu/iraf/web, accessed 2008.
[39] J. Fekete and C. Plaisant, "Excentric Labeling: Dynamic Neighborhood
Labeling for Data Visualization," Proceedings of CHI '99, Pittsburgh, PA, 1999.

