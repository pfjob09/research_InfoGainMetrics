From Tasks to Tools: A Field Study in Collaborative Visual Analytics
Daniel Ha*, Minjung Kim, Andrew Wade, William O. Chao, Kevin Ho, Linda Kaastra, Brian Fisher, John Dill
Simon Fraser University, SIAT and University of British Columbia, MAGIC

ABSTRACT
This poster presents an exploratory field study of a VAST 2007
contest entry. We applied Cognitive Task Analysis (CTA),
grounded theory (GT), and Activity Theory (AT), to analysis of
field notes and interviews from participants. Our results are
described in the context of activity theory and sensemaking, two
theoretical perspectives that we have found to be particularly
useful in understanding analytic tasks.
CR Categories and Subject Descriptors: H.3.3 [Information
Search and Retrieval]: Information filtering, Relevance feedback,
Selection process; H.4.1 [Office Automation]: Groupware; H.5.3
[Group and Organization Interfaces]: Collaborative computing,
Computer-supported cooperative work
Additional Keywords: field methods, collaboration, theory
building, meta-analysis, evaluation
1

INTRODUCTION

Visual analytics has been defined as “the science of analytical
reasoning with the interactive visual interface”. Our research
focuses on understanding the analytic task per se, which we feel is
a prerequisite to the informed design of analytic tools. Our poster
will describe our application of some theories and methods from
cognitive science to a VAST contest entry. The methods
developed will inform subsequent research on real-world
problems as well as casting new light on the role of distributed
cognition and coordinated use of tool sets in analytic tasks.
Our previous field studies of computer security administrators
[1] found that that their approach to detecting and responding to
potential security threats could best be characterized by:
1) Distributed cognition — the embedding of security
administration tasks within the context of related tasks
performed by multiple individuals in loose coordination.
2) “Bricolage”— the use of multiple special-purpose tools
framed by the administrator’s mental model of computer
security, their institution, and users.
Our test group took this approach to the VAST 2007 contest,
the results of which are described elsewhere. A diverse set of
tools were made available to a group of novice analysts who were
asked to utilize distributed cognition and bricolage in their
approach to the problem, and to document their processes for later
analysis.
1.1
Theoretical underpinnings
Activity theory (AT) is a conceptual framework that has been
used in studies of human computer interaction to help better
understand the structural tensions and contradictions that
characterize tool mediated work environments [4]. AT posits that
* email: dha1@sfu.ca

IEEE Symposium on Visual Analytics Science and Technology 2007
October 30 - November 1, Sacramento, CA, USA
978-1-4244-1659-2/07/$25.00 ©2007 IEEE

the primary unit of analysis for activity is the activity system, a
culturally mediated system comprising the human actor, a
problem space at which actions are directed, and conceptual or
physical tools that enable the actor to accomplish task objectives.
This model was later expanded to include an additional social
dimension that describes activity as also mediated by a division of
labor, a community of practice, and rules of conduct.
For our field study, AT served as a theoretical framework for
examining the analytic problem space, tool use, individual and
group roles, community practices, the rules governing
collaborative work, and the tensions that characterize the
interactions between these elements. It further serves to inform
future design work by helping to identify user needs and to
illuminate both the limitations and possibilities of existing
conceptual and technological tools.
Russell et al. [5] describe sensemaking as a spiral process
involving the identifying of information from a corpus of data to
help answer a specific set of questions within a problem domain.
Russell et al. describe a learning loop as a cyclical sensemaking
process involving four primary stages. First, analysts engage in a
process of searching for information. This is the generation loop,
in which information is generated from a data source and where
initial procedures for searching and using the information is also
generated. Second, representations are created to categorize
information of interest. These schemas serve to guide future
iterations of categorization. Third, in the representation shift loop,
in which schemas are refined and outliers either discarded or
result in the generation of new schema. Lastly, these schemas are
used to guide further analysis and to help generate questions and
answers for the task at hand.
In our study, this model served to guide our investigations of
analytic activity during sensemaking process. In our poster, we
use the term "sensemaking loop" to refer to the learning loop
proposed by Russell et al., but applied to visual analytics. We also
use the terms, information generation, schematization,
argumentation and shifting schemas, and decision making to
denote steps in the sensemaking process, respectively.
1.2

Research methodology

1.2.1
Data
Analysts kept field notes on their problem-solving process. These
could take any format: activity logs, task logs, to-do-lists, general
notes, questions, ongoing workflow analysis, and a list of
challenges. The analysts were also offered the opportunity to keep
track of their progress through audio and video recordings, email,
blogs and wikis. When the solution was well underway, the
analysts were interviewed about use of physical and virtual spaces
and roles in the team effort.
1.2.2
Analysis methods
Grounded theory (GT) is an inductive process for iteratively
generating a theory from empirical data in a bottom-up fashion,
rather than approaching a problem space with a preconceived
hypothesis [2]. It has the advantage of facilitating the discovery of
unknown or unexpected patterns of behaviour, and the drawback

223

of requiring a great deal of time and effort from highly trained GT
practitioners.
When appropriate, Cognitive Task Analysis (CTA) was used, in
order to address the issue of distributed cognition across multiple
actors and artifacts in a more focused, albeit less powerful,
approach than GT. This included the analysts’ observation and
structured recall of their own behaviors and cognitive processes.
2

RESULTS AND DISCUSSION

Early stages were characterized by individual work. Interviews
confirmed that initial information generation was not
collaborative in nature. The task of extracting entities (names,
places, events, and themes) from the data was a tedious process
that was deemed by the group to be more efficiently accomplished
by individual analysts working in parallel. Individual work at this
stage was also seen as a way to mitigate the effects of groupthink
[3] during the discovery process, thereby promoting a larger
diversity of possible entities and hypotheses. The analysts felt that
generating information collaboratively at this stage may have
hindered the generation of comprehensive individual perspectives
on the data.
As the analysts progressed through the schematization stage,
they began to collaborate more frequently, forming sub-groups for
the purpose of comparing their individual findings. Group work
was predominantly virtual in nature; information sharing was
accomplished over email and the online wiki. In face-to-face
meetings with the larger group, discussions resulted in more
focused information search along hypothetical plot lines. Analysts
agreed that openness to a large number of possible plots during
this stage was critical to comprehensive discovery. Following
these meetings, some analysts reverted to conducting information
search alone based on possible plots suggested by other members,
but continued to share their discoveries in small groups, over
email, and on the group wiki.
As the group entered the argumentation and decision making
phases, face-to-face meetings increased and became more regular.
Limited support for collaborative discourse in the tools at hand
necessitated meetings where individual analysts were encouraged
to share and critique their hypothesis as well as the tools and
processes used to generate them.
In the latter phases, tools chosen for argumentation were
interactive and visual. In group meetings, interactions began to
take place simultaneously in physical and virtual environments.
Questions generated through discussions in physical space were
translated into interactive tools and representations using a shared
online spreadsheet provided by Google Docs. These tools were
chosen ad hoc, and used to assess the plausibility of completing
hypotheses and support collective decision making.
2.1
Tool Selection and Combination
Initially, tools were selected to help reveal salient entities. Tools
such as Microsoft Notepad and Word were used to format and
consolidate data, while entity searches were aided by public
license applications such as TextSTAT and Stanford POSTagger.
ATLAS.ti, a commercial qualitative analysis tool was used by
three of the analysts. Tools used early on tended to be more
individual, to support individual analysts to conduct searches,
code entities, and to graph entity relationships and temporal
visualizations, but did not support collaborative interaction and
discourse. Tools designed for collaboration were chosen in later
steps and gained increased use as the need for greater discourse
and face-to-face interaction grew. Table 1 identifies tools used in
the sensemaking process. Tools chosen for argumentation, schema
shifting and decision-making had greater collaborative
functionality, enabling the analysts to more effectively work as a
group to generate a final plausible hypothesis.

224

Table 1. Analyst tool relative to the process of sensemaking
Phase

Analyst 1

Information
generation

Analyst 2

Analyst 3

Analyst 4

Analyst 5

MS Word,

MS Word,
Atlas.ti

MS Word,
Atlas.ti
TextSTAT

Notepad,

Atlas.ti
Stanford
POSTagger

Schematization wiki

Wiki,
TextSTAT

Wiki,

Atlas.ti,

Argumentation Wiki,
Wiki
Google Docs Google Docs Google Docs
and schema
Dia,
Dia,
shifting
GraphViz
GraphViz
GraphViz
PowerPoint
Decisionmaking

3

TextSTAT

Wiki,
Wiki,
TextSTAT
TextSTAT
Freemind
Freemind
Timeline
Maker,
Search Utility
Timeline
Maker,
Dia
GraphViz
Powerpoint
TextSTAT

Dia
GraphViz

Google Docs Google Docs Google Docs Google Docs Google Docs
Cmap
Cmap
Cmap
Cmap
GraphViz
GraphViz
GraphViz
GraphViz
GraphViz,
TextSTAT

CONCLUSION

Results from preliminary observations suggest that group
sensemaking activity is characterized by phases of independent
and collaborative work. The nature of the work began as a
primarily individual activity and gradually became more
collaborative in the later phases. Tools selected by analysts over
the course of the challenge reflected immediate individual needs
and became increasingly collaborative in functionality as the work
progressed. These observations suggest that during the early
stages of sensemaking, focused individual work should be
supported to allow for greater independent thinking. This can
benefit sensemaking by fostering the generation of a larger
number of possible perspectives, thereby promoting a more
comprehensive understanding of a particular case, which may lead
to more effective decision making and action. This initial finding
is part of work in progress and research is currently underway to
further examine and test these results.
REFERENCES
[1]

[2]

[3]
[4]

[5]

David Botta, Rodrigo Werlinger, André Gagné Konstantin
Beznosov, Lee Iverson, Sidney Fels, Brian Fisher. Towards
Understanding IT Security Professionals and Their Tools.
Symposium On Usable Privacy and Security (SOUPS) ‘07,
Pittsburgh, PA, USA. July 18-20, 2007.
J. Corbin and A. Strauss. Grounded Theory Research: Procedures,
Canons, and Evaluative Criteria. Qualitative Sociology, 13(1): 3-21,
1990.
I. L. Janis. Groupthink: Psychological Studies of Policy Decisions
and Fiascoes (2nd Ed.). Boston: Houghton Mifflin, 1982.
B. Nardi. Activity Theory and Human Computer Interaction. In B.
Nardi (Ed.), Context and Consciousness: Activity Theory and
Human-Computer Interaction. Cambridge, Massachusetts: MIT
Press, 1993.
D.M. Russell, M.J. Stefik, P. Pirolli, and S. K. Card. The Cost
Structure of Sensemaking. Paper presented at the INTERCHI '93
Conference on Human Factors in Computing Systems, Amsterdam,
The Netherlands, pp. 269-276, April 24-29, 1993.

