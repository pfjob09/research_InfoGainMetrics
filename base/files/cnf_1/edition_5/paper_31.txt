VisPad: Integrating Visualization, Navigation and Synthesis
Yedendra B. Shrinivasan∗

Jarke J. van Wijk†

Dept. Mathematics and Computer Science
Technische Universiteit Eindhoven

A BSTRACT
We present a new framework - VisPad - to support the user to revisit
the visual exploration process, and to synthesize and disseminate
information. It offers three integrated views. The data view allows
the user to interactively explore the data. The navigation view
captures the exploration process. It enables the user to revisit any
particular state and reuse it. The knowledge view enables the user
to record his/her findings and the relations between these findings.

Figure 1: (a) Current state of the user navigation. (b) VisPad model.

Keywords: Navigation, Information synthesis, Presentation
Index Terms: H.5.2 [Information Interfaces and Presentation]:
User Interfaces—Graphical User Interfaces (GUI);
1

I NTRODUCTION

Information visualization helps the user to understand data through
abstract visual representations. Often, the data is so complex and
large that static visualizations are not useful anymore. Hence, interactive visualizations are needed to explore the data.
During the interactive exploration, many discoveries in terms of
relations, patterns,and outliers are made or new hypotheses are generated. However, it can become difficult for the user to keep track
of all the findings. Hence, information synthesis in such a situation
might lead to cognitive overload of the user. Subsequently, dissemination and collaborative analysis becomes difficult.
In this work, we present a new framework - VisPad. VisPad
helps the user to revisit the exploration process and reuse the specifications (such as direct manipulations, filter, color map, etc.) of
the visualizations. It helps the user to synthesize information using
knowledge visualization (such as mind maps, causal maps, cognitive maps, etc.). The whole analysis process can be disseminated
along with the synthesized information.
2

C ONCEPT

The central process of visualization can be summarized as ‘the user
explores the data to gain insight’. From this, it is clear that the user
performs three activities. Firstly, the user sees the data as abstract
visual representations. Secondly, the user interactively explores
through the information space. Thirdly, the user gains insight by
perceiving the images. Hence, we argue that the user has to be provided with the following visual representations, apart from visual
representation(s) of the data, to reduce cognitive overload and gain
better understanding of the data:
• Visual representation(s) of the exploration/navigation process.
• Visual representation(s) of the findings and their relations.
GRASPARC [2] and the branching time model in Visage [4] are a
few examples of the visualization of the navigation process. The
∗ e-mail:
† e-mail:

y.b.shrinivasan@tue.nl
vanwijk@win.tue.nl

IEEE Symposium on Visual Analytics Science and Technology 2007
October 30 - November 1, Sacramento, CA, USA
978-1-4244-1659-2/07/$25.00 ©2007 IEEE

synthesis space in HARVEST [5] and the sandbox in nSpace [6]
are a few examples of the visualization of the findings and their
relations.
Currently, advanced visualization systems support note-taking
through annotations on the visualizations. The annotations are used
as attention pointers to some interesting aspects of the visualization. However, as the number of annotations increases, it becomes
difficult to synthesize them. According to Bauer and Laird [1], the
use of an appropriate diagram helps the user to make explicit all
the possibilities and reason more rapidly and accurately. This supports our argument for a separate visualization space for findings
and their relations within a visualization system. Diagrams such
as mind maps, concept maps, cognitive maps, affinity diagram, argument maps and so forth help to visualize the findings and their
relations.
In summary, some visual representations to visualize the data,
the navigation, and the user’s findings and their relations already
exist. The challenge then is to integrate these visual representations
to support information synthesis and dissemination.
3 VisPad M ODEL
In visualization, the data D is transformed into an image I based on
a specification S. S includes visualization method, attribute filters,
graphical filters applied through direct manipulation techniques,
color mappings and so forth. The user provides the specification
St to the system based on the current knowledge Kt−1 to generate
the image It . Kt is the total knowledge gained by the user. The user
repeats the process of generating a new image It+1 by providing
a new specification St+1 based on Kt , until the desired results are
achieved. Thus, the user navigates through the data by changing S.
The current state of the user navigation is shown in figure 1 (a).
VisPad consists of three components — a data view, a navigation
view and a knowledge view (see figure 1 (b)). The data view helps
the user to interactively explore the data using visual representations. The navigation view records S and a reference to D as the
user moves from one exploration state to another. When an exploration state is revisited, the image I is regenerated based on S and
D captured in the state. The user can reuse the revisited exploration
state by changing S and D. This creates a new branch, resulting in
a tree structured navigation path.
The knowledge view helps the user to synthesize information.
It has a basic graphics editor. A note is the basic entity to record
user findings. Notes can be linked through connector lines with
or without directed arrows to represent relations between findings.
The user can also attach text to the connector lines. Notes can be
organized into a group with a title. The tool supports multiple group

209

Figure 2: Exploration of the digital camera dataset using VisPad. (a) scatter plot and (b) dynamic query interface present the data view. (c) is the knowledge view.
(d) presents the navigation view using a history tree representation. The current state is highlighted in red. When there is a link between the state in the navigation
view and an entity in the knowledge view, they are marked with a star. This figure shows the user cursor over a state (highlighted in blue). The note linked to the
state is highlighted in blue in the knowledge view and the corresponding image is shown in the data view.

levels. These basic entities can be used to create various knowledge
visualizations such as mind maps, concept maps, cognitive maps,
affinity diagrams, argument maps and so forth.
Each entity in the knowledge view, such as a note, a connector
line and a group, can be linked to a particular state in the navigation
view. A state can be associated with more than one entity in the
knowledge view. The linking is an asynchronous process. The user
can create an entity in the knowledge view and link it to a state
at any time during the exploration process. When a state in the
navigation view and a entity in the knowledge view are linked, they
are marked with a star.
4 U SE C ASE
We now present a simple use case where a user explores a digital
camera dataset (about 600 cameras with 15 attributes). There are a
several tasks that the user might perform with the data, such as detecting trends and finding cameras that meet the user requirements.
To perform trend analysis, the user compares the digital camera
attributes for different years. The user uses a scatter plot (see figure 2 (a)) for this comparison. The user records his/her findings in
the knowledge view using a mind map. The mind map is a diagram used to represent ideas linked to and arranged radially around
a central idea [3]. The user records the central idea - trend analysis
- in note 1 (see figure 2 (1)). Firstly, the user plots the number of
megapixels over the years. The user records his/her finding in note 2
(see figure 2 (2)) and links the note to the current state in the navigation view. Subsequently, the user compares the zoom-ratio and
download interface attributes against year by changing the scatter
plot y-axis. Notes 3 and 4 are the user’s findings; each of these
notes is linked to a state in the navigation view. The user completes
the mind map by connecting notes 2, 3 and 4 with note 1 using the
connector line with arrow.
Based on the trend analysis and the user’s own knowledge about
the digital camera market, the user defines requirements for selecting a camera. The user records those requirements in note 5. In
this case, the user is looking for a recent camera from manufacturers such as Cannon, Nikon, and Sony with 8 mega-pixels. The
user revisits the state where the mega-pixels attribute was compared
against the manufacture year, by clicking on note 2. Using the dynamic query interface (see figure 2 (b)), the user selects those manufacturers. This creates a new branch in the navigation view (see
figure 2 (9)). The user then draws a rectangle in the scatter plot (see

210

figure 2 (10)) to select the recent cameras (from 2004 to 2006) having 8 megapixels. Six cameras match the requirements. The user
records this state using the note 6.
The user continues to inspect other attributes by applying different attribute filters using the dynamic query interface. The user
finds that out of 6 cameras, only one camera has the image stabilization option. The user records this state using the note 7. The
user connects notes 5 and 6, and 6 and 7 to indicate the selection
process. The user then groups notes 5, 6 and 7 used for the camera
selection (see figure 2 (8)). Using the data, navigation and knowledge views, the user can revisit the whole exploration process and
disseminate the synthesized information.
5 F UTURE WORK
Currently, we are looking for more use cases and datasets to
evaluate the VisPad model other than the digital camera dataset.
We also face some challenges in designing experiments to evaluate
to what extent the integration of the data, navigation and knowledge
views is useful for the information synthesis and dissemination.
The project is supported by the VIEW programme of the Netherlands Organisation for Scientific Research (NWO) under research grant no. 643.100.502.

R EFERENCES
[1] M. I. Bauer and J. J. Laird. How diagrams can improve reasoning.
Psychological Science, 4(6):372–378, 1993.
[2] K. Brodlie, L. Brankin, G. Banecki, A. Gay, A. Poon, and H. Wright.
GRASPARC - a problem solving environment integrating computation
and visualization. In Proceedings of IEEE Visualization 1993 Conference, pages 102–109. IEEE Computer Society Press, 1993.
[3] T. Buzan and B. Buzan. The Mind Map Book: How to Use Radiant Thinking to Maximize Your Brain’s Untapped Potential. Penguin
Books, 1993.
[4] M. Derthick and S. F. Roth. Enhancing data exploration with a branching history of user operations. Knowledge-Based Systems, 14(1-2):65–
74, Mar. 2001.
[5] D. Gotz, M. X. Zhou, and V. Aggarwal. Interactive visual synthesis of
analytic knowledge. In Proceedings of the IEEE Symposium on Visual
Analytics Science and Technology, Baltimore, MD, October 2006.
[6] W. Wright, D. Schroh, P. Proulx, A. Skaburskis, and B. Cort. The
sandbox for analysis: concepts and methods. In CHI ’06: Proceedings
of the SIGCHI conference on Human Factors in computing systems,
pages 801–810, New York, NY, USA, 2006. ACM Press.

