2012 Ninth International Conference on Computer Graphics, Imaging and Visualization

An Automated Adaption of K-means Based Hybrid Segmentation System into
Direct Volume Rendering Object distinction Mode for Enhanced Visualization
Effect
Arash Azim Zadeh Irani, Bahari Belaton
Department of Computer Science, Universiti Sains Malaysia
{arashazim.cod08@student.usm.my, bahari@cs.usm.my}
Abstract

volumetric data set are treated in an identical manner
without using any a priori information that specifies
object membership on a per-voxel basis [4]. Inability to
properly distinguish among multiple objects of interest
solely based on single or multi dimensional transfer
function(s) is often the case. Segmentation is a
formidable approach to handling this problem. It infers
object membership information for each object of
interest, yielding a tag for each volume’s voxel. In this
context, explicit and implicit designs have been
introduced by different research works. The former is
concerned with technicality of adapting readily available
object membership information into a particular
rendering mode or combination of rendering modes
while the latter summons its own set of object
membership information via a carefully designed
segmentation system, giving peculiar emphasis on
integration issues.

Ray Casting is a direct volume rendering technique
for visualizing 3D arrays of sampled data. It has vital
applications in medical and biological imaging.
Nevertheless, it is inherently open to cluttered
classification results. It suffers from overlapping transfer
function values and lacks a sufficiently powerful voxel
parsing mechanism for object distinction. In this work,
we are proposing an image processing based approach
towards enhancing ray casting technique for object
distinction process. The rendering mode is modified to
accommodate masking information generated by a Kmeans based hybrid segmentation system. An effective
set of image processing techniques are creatively
employed in construction of a generic segmentation
system capable of generating object membership
information. Preprocessing, initialization of cluster
centers, clustering, statistical optimization, edge
detection & analysis and spatial adjustment are
respectively the six main segmentation phases.

1.2 Motivation

Keywords--- Hybrid Image Segmentation, Volume
Rendering, Enhanced Visualization Effect.

Quality volume rendering and promising
visualization outcome could become a direct result of
celebrated union between image processing merit and
computer graphics. So far, wholesome consideration of
an appropriate rendering architecture that is fed by a
viable segmentation system has been an open domain for
innovative solutions. Present literature on segmentation
based volume visualization suggests significantly
exclusive approaches, yielding a gap for generic
solutions with reasonable outcome for handy
visualization tasks. Automation is seldom advertised if
not ignored as compared to non or semi automatic frame
works.

1. Introduction
MRI scan(s) has become a crucial means for
abdominal inspection. In the field of medical / biological
imaging there is an ongoing interest on computer assisted
diagnosis of trunk organs such as liver, spleen, kidney,
heart and lung [1]. Given the great dependency of human
analysis and judgment abilities on realistic and sensible
visualization, appropriate volume rendering techniques
for effective visualization may be deemed fundamental.
Most of the currently available volume rendering
methods such as ray casting, texture mapping, shearwarp and splatting employ transfer function(s) for object
distinction. Lately, non- photorealistic based volume
rendering (NPR) is introduced as another way towards
perceptual object visualization [2, 3]. However, a major
drawback of using these methods is that all voxels of a
978-0-7695-4778-7/12 $26.00 © 2012 IEEE
DOI 10.1109/CGIV.2012.14

1.3 Objectives
The main objective of this work is to achieve
enhanced visualization effect through amendment of ray
casting based volume rendering. In general, the direct
volume rendering process involves classification,
transfer function formulation and rendering as its three
respective and interdependent phases. Thus, in order to
62

improve a particular phase one may need to modify its
prerequisite phase(s). Our main objective could therefore
be broken into three parts. First, adaptation of K-means
based hybrid segmentation system for boosting
classification results. Second, establishment of
representative transfer functions that properly manifest
new classification complications. Third, Adjustment of
the rendering pipeline for optimum implementation of
transfer functions.

Localized transfer functions are then formed via look up
tables for volumetric rendering of each isolated object
[8].

1.4 Outline
This work is divided into five sections. Section 1
raises an issue in the computer assisted visualization
domain. It observes the current volume rendering
techniques as insufficient means for superior
visualization and proposes a segmentation based
solution. Section 2 highlights the particularly pertinent
literature. Section 3 expands on the solution proposed in
section 1. Section 4 carries out objective testing and
comparative study of the results.

Figure 1 Two Conceptual Levels of Volume
Rendering [4]
Currently, design of transfer functions that
successfully associate data values with visual properties
is a difficult and “non-intuitive” task [9]. DVR is
naturally open to ambiguous classification and may
require segmentation based masking to get occlusion free
view of the desired objects [9]. There is however, a risk
of erroneous masking or unintentional assignment of
background to object (s) of interest. This may lead to
fatal misinterpretations, especially in sensitive medical
fields [9]. For instance an error may rise in volumetric
measurement of a tumor. An uncertainty (risk)
assessment of volume segmentation is performed and a
formidable risk reduction and control system is
proposed. The proposed system demonstrates a close
interplay with user [9]. Its four main phases are
probabilistic random walker segmentation to produce
segmentation results with estimable uncertainty level,
risk analysis, guiding user to the regions which are
possibly prone to error and identification of error by user
and insertion of desired fixing to initial segmentation
parameters [9]. Nero Trace is presented as a semiautomatic volume segmentation and visualization system
for neural processing of nervous organ(s) [10]. It consists
of preprocessing, multiphase level set segmentation and
3D tracking and a special ellipse based rendering method
for electron microscopy (EM) data visualization. Prior to
segmentation, volume rendering is used to search the
input volume (volume constructed from raw EM data)
for a region of interest (ROI) [10]. User can select center
of ROI (desired set of neural cells) on an arbitrary 2D
plane using volumetric view [10].

2. Literature review
Hessian-based line filters and fast marching active
contour were used to segment coronary arteries and
pericardial cavity respectively [5]. The volumetric
rendering task is performed using SharpImage
prototyping package [6]. Built in libraries are elaborated
instead of rendering complexities. Explicit segmentation
information was utilized as a main contributing factor to
the rendering pipeline. Each object is separated by an ID
at voxel level [7]. Two level volume rendering approach
allows combination of local per object compositing mode
with global direct volume rendering (DVR) [7]. For
instance, non-photorealistic rendering and maximum
intensity projection (MIP) could be used in combination
with DVR to enable higher quality results [7]. In the
context of GPU based volume rendering where no actual
ray exists, conceptual ray should be able to combine the
contributions of different compositing modes. Local and
global buffers are used to track the current composition
mode for each pixel. The status of each pixel is switched
between local and global buffers [7]. Figure 1
demonstrates the idea. As can be noticed, MIP, NPR and
DVR are used for different objects along a global pass.
Thus, each object utilizes the mode most suitable for it.
A semi-automatic volume segmentation algorithm
(skeleton-cut) based on skeleton topology is presented.
Complex structures could be simplified by appropriately
representative descriptors [8]. Skeletons are utilized to
provide meaningful clues for object distinction.
Skeletons are identified by initially extracting coarse
boundaries and then Euclidean transformation between
the foreground and background voxels [8]. Once
identified, skeletons are connected to their neighbors to
form a graph [8]. The weights among the nodes are
assigned based on intersection area of the cells, intensity
means and radii of inscribed spheres [8]. The min-cut /
max-flow operations induce the graph outcome[8].

3. Proposed solution
A creative general purpose visualization system
potentially capable of object extraction and volumetric
manipulation of images is presented. The architecture of
the system includes a K-means based hybrid
segmentation system and a ray casting based tagged
volume rendering design as two of its main and
complementary components. The former component is
developed via careful rectification of major limitations of

63

K-means algorithm. The limitations entail: First, a global
optimum solution is not guaranteed since appropriate
numbers and locations of cluster centers that may be
required for a particular image cannot be determined. It
works best only when clusters are naturally available
within dataset. Second, spatiality issues are not
addressed. Third, many iterative rounds are usually
required. Fourth, too small or too large clusters may be
formed. An unsupervised neural map is used in order to
determine coherent cluster centers and reduce local
convergences. Recombination and epsilon factor are
devised for spatiality considerations. Edge analysis and
filtering handles the artifacts that may arise from
recombination task. Fisher discriminat ratio not only
helps reduce the number clustering iterations to merely a
few rounds but also facilitates large inter-cluster distance
and small intra-cluster distance. The latter component
offers a solution for critical limitations of direct volume
rendering (ray casting) technique with a focus on trunk
MRI (gray scale) slabs in particular. The limitations
entail: First, overlapping values lead to obscured transfer
function and irrelevant perceptual illustration. Second,
unnecessary rendering of undesired fragments adds to
overall
visualization
delay.
Transfer
function
construction is directed by an important preprocessing
stage (segmentation). Crucial membership information is
provided to reduce undirected and overlapping values. A
culling mechanism is blended into the rendering process
to control the LOD (level of detail) and avoid waste of
graphic resources. Finally, a visualization design which
is a direct consequence of proper integration between the
two foretold components may have to possess four main
characteristics in our point of view. Overall
computational efficiency, ability to properly compromise
(adapt) among multiple parameters of interest,
customizability and reliability can be assumed. In this
work, computational efficiency, proper compromise
among multiple parameters and to a reasonable extend
reliability are addressed. However, since the reliability
means nearly constant quality of results for various
images, it is a very difficult task indeed. An integrated
system must be tested numerous times and be amended
accordingly to reach certain maturity or in other words
reliability level. Extensive customizability and reliability
work could be a remarkable future work.

the instance in section 4, an appropriate early amendment
such as histogram equalization could boost feature
resolution and ensure enhanced segmentation result.

Figure 2 K-means Based Hybrid
Segmentation Flow Design

3.1 K-means based hybrid segmentation system
A comprehensive flowchart may be of great
importance towards better understanding of this section.
Figure 2 is therefore provided prior to any further
elaborations. The rest of this section proceeds in phase
by phase format.

3.1.2. Phase 2- enhanced unsupervised neural
map for cluster initialization unguided cluster centers
initializations often mislead the overall clustering task.
Inability to determine the spread and number of possible
clusters may often trigger imprecise and locally optimum
solutions. An enhanced unsupervised neural network is
used to help identify the required numbers and spatial
locations of potential cluster centers. Automation and
approximation are the two important reasons why a selfcontained neural network was used. As compared to
back-propagation technique in which manual, feedback

3.1.1. Phase 1- preprocessing low quality images
are the specific target of this optional phase. Prior to
actual segmentation operations such as histogram
equalization and noise removal via readily available
filters could take place in order to highlight the otherwise
vague but important features. As may be noticed from

64

oriented training rounds are required to reach a
reasonably accurate result a self-organized network
could impulsively produce useful approximation,
suitable for cluster centers initializations. Figure 3
demonstrates a typical 4 4 self-contained network with
three inputs. Here, the three RGB color bands form input
values (gray level values could also be represented by
elemental blend). The network is established such that
each map node includes three feature vectors and is only
connected to input nodes.

stages. In the first stage, the learning rate begins at 0.9
and gradually reduces to 0.1 and neighborhood size
begins by half of the map size (for instance, in figure 3
the neighborhood size begins at 2) and gradually
decreases to 1. The second stage is more of a refinement.
At this stage the feature vectors of the nodes are
stabilized and would further be refined by a learning rate
of 0.01. Neighborhood size remains at 1 meaning only
the BMU node is adjusted. For ease of calculations
feature vectors are normalized from [0, 255] to [-1, 1].
Upon end of training and convergence numbers,
locations and values that cluster centers should possess
are approximated.
3.1.3. Phase 3- K-means is a statistical clustering
algorithm. Figure 5 formulates how K-means commonly
and
refer to data point
works. The
(pixel), average of a data points set (cluster center),
Euclidian distance and minimum value respectively. A
homogenous cluster is identified when a particular
cluster center possesses the minimum distance (mean
squared error) to several data points as compared to other
cluster centers.

Figure 3 (a) Network Initialization (b)
Neighborhood Adjustments
Figure 5 K-means Clustering Formulation

Prior to training, the range of RGB colors available
within the image is obtained. As indicated by figure 4, in
order to define a range, the smallest (lower bound) and
largest (upper bound) color values available within the
image are found and their difference is calculated. Then,
an interval is calculated.

In this work, few rounds of K-means clustering are used
to produce preliminary classification results or in other
words elementary clusters. The initial cluster centers
required by K-means algorithm are provided by phase 2.
At this stage to avoid ambiguity caused by compromise
over features, dimensions are limited to merely three
color bands and a diagonal busyness factor (DF). DF is
used to probe texture around each pixel. It helps in
clarifying ambiguous situations. For instance, hatches of
a brownish chair could be used to tell it apart from its
brown background. DF is calculated as sum of color
differences among central and diagonal pixels.

Figure 4 Range and Interval Calculation for Map
Nodes Initializations

3.1.4. Phase 4- statistical optimization. Fisher
discriminant ratio is used for refinement of preliminary
and coarse clusters produced in previous phase. K-means
clustering originally requires many iterative rounds for a
valid clustering outcome. However, a fisher discriminant
ratio could perform stable clustering using only few
iterative rounds. In contrast to K-means, a fisher
discriminant ratio enables uniformity across the entire
space. Balanced distribution of homogeneous clusters is
obtained by including variances within ratio calculations.
As can be noticed from figure 6 part (a) the fisher
discriminant ratio is calculated as sum of differences in
means over sum of variances. Larger differences in
means or smaller variances obviously lead to higher
ratio. In an iterative round each pixel (data point) is
temporarily removed from its home cluster and assigned

Feature vectors for each map node are initialized by
traversing from lower bound to upper bound based on
interval (please take note of figure 3 part (a)). After
initialization training starts by randomly selecting pixels
from all over the image, storing their spatial positions
and passing them to input nodes one by one in order to
decide the best match unit. BMU is the map node which
is most similar to input values as compared to other
nodes. As can be seen from figure 3 part (b) once the
best matching node is selected, its feature vectors and
neighborhood are adjusted to most closely resemble the
input values. The amounts of adjustments are determined
by learning rate and neighborhood size factors in two

65

scanned in eight connected directions. For each pixel, the
cluster to which majority of pixels in the eight connected
neighborhood belong is determined. If the central pixel
(pixel whose neighborhood is being scanned) belongs to
the same cluster as the majority of its eight connected
neighborhood pixels, its cluster will not change,
otherwise, its cluster will change to the cluster that the
majority of its eight connected neighborhood pixels
belong. As can be noticed from figure 7 part (a), the
majority of pixels around central pixel are classified
under cluster number 4. Consequently, central pixel’s
cluster is changed to 4 (figure 7 part (b)). Given the
nature of color and texture based clustering, objects with
similar color and pattern characteristics but dissimilar
spatial properties may be classified under the same
group, rendering them impossible to be distinguished. To
tackle this problem an optional tolerance oriented
spatiality factor referred to as epsilon is devised. If sum
of spatial distances of pixels belonging to a particular
cluster is greater than the epsilon value then those pixels
which are further away are identified and if their
magnitude is great enough they are grouped under a
different cluster.

to each of the other clusters one by one. Every time a
temporary assignment occurs the differences in means
and variances are renewed and discriminant ratio is
recalculated. Figure 6 part (b) indicates the routes among
four clusters required for calculation of differences in
means. A pixel is permanently detached and reassigned
to another cluster only if such reassignment causes an
increase in ratio. Thus, promoting larger inter-cluster
distance and smaller intra-cluster distance. Statistical
optimization ends when ratio alteration becomes
ignorable.
3.1.5. Phase 5- edge detection and analysis. Edge
treatment is considered as a prerequisite to phase 6. It
directs the spatial recombination task by discerning
potential object boundaries that may be undermined
during spatial recombination if not specifically
exempted. Sobel algorithm is used to identify and filter
important edge pixels. Long and continues edges are
extracted while short and discrete edges are ignored. In
cases where there are multiple discrete and short but
closely adjacent edges, an aggregation operation is
performed in order to produce a wholesome and
continues edge. Two 3±3 masking kernels are employed
to approximate the derviates (changes) along horizontal
and vertical directions. Throughout the image masking
kernels perform convolution operations and highlight the
edge pixels.

Figure 7 (a) A 3 ±3 Neighborhood Before
Recombination (b) After Recombination

3.2 Enhanced ray casting pipeline
This section preserves the consistency by following
section 3.1’s writing style. Figure 8 is used lucid
comprehension.
3.2.1. Phase 1- directed object Sets construction in its
brief and simple form refers to building an array of
voxels representing an object. It is directed because the
position and membership ID of voxels are determined at
vertex level on each 2D slab by a K-means based hybrid
segmentation system. Depth information is crucial in
identifying the order in respect to which an object is
rendered as compared to other objects in volumetric
space. For instance, if two objects are equal in depth they
stand in the same place on the rendering queue otherwise
the object in front would have the primitive turn in a
typical front to back composition. Depth may be
calculated along each of the main axis (X, Y and Z)
differently, changing the object sorting order. An object

Figure 6 (a) Fisher Discriminant Ratio
Formulation (b) Graphical Representation of
Ratio’s nominator
3.1.5. Phase 5- spatial adjustment. Often few irrelevant
fragments remain within clusters even upon multiple
rounds of refinement. To reduce these artifacts spatial
recombination is employed. To carry out recombination,
image is traversed from top to bottom and each pixel is

66

object and not during the intersection course. Instead
intra-object rendering is handled locally. Occurrence of
an intersection is determined by the depth at which the
ray is traversing and whether there are any objects
available at this depth on the object sets list. Upon
intersecting an object, a secondary but complete
rendering process is initiated, this time given a temporary
local buffer. Given the ID(s) of the intersected object(s) a
relevant interpolation solution is carried out (please refer
to section 3.2.4) and local buffer is updated. The contents
of local buffer are then summed into projection plane
buffer as part of overall composition mode.

set should at least include an array of membership ID,
position and depth along the viewing plane.

3.2.4. Phase 4- interpolation design. The
fundamental prerequisite to rendering a volume is
sampling. A ray has to pass through numerous voxels
obtaining only one sample from each voxel at a fixed
interval. Voxels are actually equal size cubes constructed
from regular grids. Geometrical organization of multiple
adjacent cubes yields a large cube which is usually
referred to as volume. Since each cube has eight vertices
(points) we need to device a mechanism to choose only
one sample out of eight available options at each voxel.
Tri-linear
interpolation
and
nearest
neighbor
approximation are just two of the many ways one could
do such selection. In essence, Tri-linear interpolation
tries to average out among vertices of a cube linearly
yielding an individual representative point. In its
simplest form a tri-linear interpolation could be
performed by a combination of multiple one dimensional
interpolations. For instance, to determine a point
floating right in middle of a cube a combination of four
one dimensional interpolations at X axis, two one
dimensional interpolations at Y axis and a single one
dimensional interpolation at Z axis is sufficient. Nearest
neighbor approximation is a fast method which works in
one or more dimensions. It approximates the value of an
unknown point from the value of a known point closest
to it. This means that a sampling point could simply
absorb the value of the nearest vertex. Now back to this
work’s interpolation design. First, selection of an
appropriate interpolation technique depends on the
number of objects a local ray casting process is ought to
render. If there is only one object, no ambiguities could
be imposed by other objects and therefore a fast nearest
neighbor approximation should be used to yield an
unsurprisingly precise sample value. However, if there
are more than one object, then a tri-linear interpolation is
used. Second, interpolation takes place based on object
IDs rather than RGBA values. This is to reduce errors
raised from blended color bands. IDs provide a single
representative value for each vertex while RGBA is an
elemental factor of four values per vertex which could
lead to obscured interpolation outcome. Therefore,
interpolation is initially performed in terms of IDs and
only then mapped to relevant textures for rendering.
Third, having more than one object at the same depth
necessitates tri-linear interpolation among two or more
objects. Mingle among the boundaries’ voxels and
reduced visualization resolution may be inevitable in this

Figure 8 Enhanced Ray Casting Design
3.2.2. Phase 2- context /focus separation. Inspired
with empty space skipping technique, an effective
solution is proposed. Directed or guided rendering could
accomplish focus on desired regions of the volume
dataset by assigning IDs only to preferred voxels, leaving
the remaining / contextual voxels unassigned. Culling is
used to deny transfer function texture assignment to
anonymous set of voxels. In other words, culling
removes unwanted areas, assisting effective management
of LOD (level of detail) required for the fine and correct
visualization results. The overall interpolation and
composition efficiency are also improved since fewer
voxels are naturally less exhaustive.
3.2.3. Phase 3- global composition mode. Ray
casting is a direct volume rendering technique. Ray
casting is broken into a global traversal and local
traversals as two complementary rendering components.
Starting by a global traversal, as the casted ray traverses
the volume, it updates (renders) the projection plane
buffer (global buffer) only after passing through an

67

situation. A threshold value solution could be set to
separate two objects’ borders clearly such that the
mingled points in between are reassigned to either one of
the objects. However, extending this solution to three or
more objects is not readily possible because one could
not set a single threshold value for iso-separation of more
than two object IDs. To resolve this issue a down scaling
mechanism is used to produce a universal threshold. All
IDs could be normalized to [0, 1] range. The universal
threshold could then be set as 0.5, voxels above and
below threshold could be distinctively reassigned to
relevant IDs.
3.2.5. Phase 5- texture assignment and local
rendering. Standard volume rendering techniques use
global and single dimensional transfer functions for
object distinction process. However, due to existing
complexity and twist within volumetric datasets even
global and multi-dimensional (dimensions refers to
distinguishing factors) transfer functions are not entirely
enough for proper voxel classification. This work
develops the notion of local and singular transfer
functions. A look up table is constructed to assign texture
values (color and opacity) to interpolated points (IDs) for
the local rendering process prior to global composition.
There is one to one relationship between ID and texture
such that for each group of voxels that form an object a
local transfer function is allocated.

4. Experimental results
4.1 Demonstration
Figure 10 (a) - (d) Volumetric Visualization of
Chest, Lung and Spinal Cord Based on Figure 9.
(e) and (f) Pelvic Structural Volume

Figure 9 (a) Low Resolution MRI Scan From
Universiti Sains Malaysia’s Hospital (b)
Preprocessed Slab (c) and (d) K-means Based
Hybrid Segmentation With and Without
Preprocessing

Figure 11 Volumetric Visualization of Skin. Note
the Surgical Mark Highlighted by Red Circle

68

Conclusions
This work proposes a creative visualization system
by integrating a k-means based hybrid segmentation
design into overall direct volume rendering (ray casting
in particular) process, allowing handy visualization of
medical / biological images. The creativity of this work
is due to five main factors. First, K-means clustering
avoids local optima convergences via a well defined
neural map. Clusters initializations depend on the map
organization. Second, stop condition is not merely a
large guess of K value. Search of feature space is
directed by a ratio, preserving the statistical balance
throughout the image. Third, Epsilon spatiality factor is
used along with recombination to improve uniformity.
Fourth, object labeling assists visualization by carefully
delimiting the volumetric space at vertex level. Fifth,
employing nearest neighbor interpolation where trilinear
interpolation is not necessary simplifies the composition
process. In addition, instead of RGB values IDs are used
to reduce the vector based inaccuracies.

Figure 12 (a) Skeleton Based Segmentation [8]
(b) Manual and Explicit Dissection [4] (c) and (d)
Coronary Arteries Visualization Prior and After
Fast Marching Active Contour Segmentation [5]

References

4.2 Analysis

[1]

Campadelli, P. Casiraghi, E. Pratissoli, S. (2008) Fully
automatic segmentation of abdominal organs from CT
images using fast marching methods. In: Proceedings of
IEEE Computer Based Medical Systems, 2008. p.554559.
[2] Csebfalvi, B. Morz, L. Hauser, H. Konig, A. Groller, M.
E. (2001) Fast visualization of object contours by nonphotorealistic volume rendering. In: Proceedings of
EUROGRAPHICS, 2001. p.452-460.
[3] Lu, A. Morris, C. Ebert, D. Rheingans, P. Hansen, C.
(2002) Non-photorealistic volume rendering using
stippling techniques. In: Proceedings of IEEE
Visualization, 2002. p.211-218.
[4] Hadwiger, M. Berger, C. Hauser, H. (2003) High-quality
two-level volume rendering of segmented data sets on
consumer graphics hardware. In: Proceedings of IEEE
Visualization, 24 October 2003, USA. p.301-308.
[5] Mueller, D. (2007) Tagged volume rendering of the
heart. Brisbane: Queensland University of Technology.
[6] Mueller, D. (2007) An image processing prototyping
environment. The Insight Journal. [Online]. [Accessed
7th May 2009]. Available from World Wide Web:
http://www.insight-journal.org/dspace/handle/1926/501
[7] Hauser, H. Morz, L. Bischi, G. I. Groller, M. E. (2001)
Two level volume rendering. IEEE Transactions on
Visualization and Computer Graphics. 7(3), p.242-252.
[8] Xiang, D. Tian, J. Yang, F. Yang, Q. Zhang, X. Li, Q.
Liu, X. (2011) Skeleton cuts-an Efficient segmentation
method for volume rendering. IEEE Transactions on
Visualization and Computer Graphics. 17.
[9] Prassni, J. Ropinski, T. Hinrichs, K. (2010) Uncertaintyaware guided volume segmentation. IEEE Transactions
on Visualization and Computer Graphics. 16(6), p.13581365.
[10] Jeong, W. Beyer, J. Hadwiger, M. Vazquez, A. Pfister,
H. Whitaker, R. T. (2009) Scalable and interactive
segmentation and visualization of neural processes in
EM datasets. IEEE Transactions on Visualization and
Computer Graphics. 15(6), p.1505-1514.

This section briefs on figures presented in section
4.1. As may be noticed, figures 9, 10 and 11 insinuate the
implementation of this work’s methodology. Figure 12
on the other hand enables a sketchy comparison by
demonstrating results from other articles. Depending on
the application (inclusive / exclusive) at hand nature of
segmentation and relevant rendering design may differ.
For instance in figure 12 part (a) an implicit
segmentation design takes advantage of skeletal structure
to visualize abdomen section. Organs closer to main
bones are identified clearly. In figures 9 and 10 organs in
less cluttered areas such as lung and its relevant veins,
chest, spinal cord and pelvic structure are extracted
clearly while liver and kidney are prone to error. In
Figure 12 part (b) segmentation aspect is insignificant
but an elaborate rendering pipeline is proposed. The blue
skin area is comparable to figure 10. Figure 12 parts (c)
and (d) focus on the segmentation and perform the
rendering task via a rather openly available package.
This work undertakes both segmentation and rendering
in detail. Table 1 summarizes the volume rendering
properties of this work.
Sampling Rate
Sampling Nature
Interpolation
Kernel
Exceptionality
Selected Voxels
Acceleration
Accuracy

Arbitrary
Point
N.N Approx / Trilinear
Linear
Viability of Multiple Rendering Modes
Segmented ROI
ID Based Space Skipping
Floating Point

Table 1 Proposed Solution’s Distinctive
Features

69

