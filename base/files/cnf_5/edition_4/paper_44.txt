Neuro-Wavelet Based Approach for Image Compression
Vipula Singh
Navin Rajpal
Research Scholar
Professor GGSIPU,
GGSIPU New Delhi
New Delhi
vipulasingh@yahoo.com
Abstract
Images have large data quantity. For storage and
transmission of images, high efficiency image
compression methods are under wide attention. In this
paper we propose a neuro- wavelet based model for
image compression which combines the advantage of
wavelet transform and neural network. Images are
decomposed using wavelet filters into a set of sub
bands with different resolution corresponding to
different frequency bands. Different quantization and
coding schemes are used for different sub bands based
on their statistical properties. The coefficients in low
frequency band are compressed by differential pulse
code modulation (DPCM) and the coefficients in
higher frequency bands are compressed using neural
network. Using this scheme we can achieve
satisfactory reconstructed images with large
compression ratios.
Keywords: image compression, Neural network, Wave
let transform, Sub band image decomposition.

1. Introduction
Image compression is a key technology in the
development of various multi-media computer
services and telecommunication applications such as
video conferencing, interactive education and
numerous other areas. Image compression techniques
aim at removing (or minimizing) redundancy in data,
yet maintains acceptable image reconstruction. A
series of standards including JPEG, MPEG and H.261
for image and video compression have been
completed. At present, the main core of image
compression technology consists of three important
processing stages:
pixel transforms,
vector
quantization and entropy coding. The design of pixel
transforms is to convert the input image into another
space where image can be represented by uncorrelated
coefficients or frequency bands. Therefore, only those
main frequency bands or principal components are
further processed achieve image compression such as
DCT, wavelets, etc. Vector quantization rounds up the

Computer Graphics, Imaging and Visualisation (CGIV 2007)
0-7695-2928-3/07 $25.00 © 2007

K. Shrikanta .Murthy
Professor PESIT
Bangalore

values of transformed coefficients into clusters where
points within a cluster are closer to each other than to
vectors belonging to different clusters. Entropy coding
is a form of lossless data compression in which
statistical information of input data considered to
reduce the redundancy. Typical algorithms are
arithmetic coding, Huffman coding and run-length
coding etc.
The use of sub band decomposition in data
compression and coding has a long history [2]. Sub
band coding was first proposed by Crochiere et al. [4]
for medium bandwidth waveform coding of speech
signals. This method decomposed the signal into
different frequency bands using a bank of quadrature
mirror filters (QMF’s) [3], [5]. Each sub band was
subsequently encoded using pulse code modulation
(PCM) or differential pulse code modulation (DPCM).
A varying bit assignment strategy was also used to
allocate the bit rate for each sub band according to its
statistical properties. Woods and O’Neil [6] extended
sub band decomposition to two-dimensional (2-D)
signals and proposed a method for QMF design that
eliminates possible aliasing error due to non ideal sub
band filters. Recent advances in signal processing
tools such as wavelets opened up a new horizon in sub
band image coding. Studies in wavelets showed that
the wavelet transform exhibits the orientation and
frequency selectivity of images [1], [7], [8].
Neural networks approaches used for data processing
seem to be very efficient, this is mainly due to their
structures which offers parallel processing of data and,
training process makes the network suitable for
various kind of data. Sonhera et al have used a two
layered neural network with the number of units in the
input and output layers the same, and the number of
hidden units smaller. The network is trained to
perform the identity mapping and the compressed
image is the output of the hidden layer [9]. Arozullah
et al presented a hierarchical neural network for image
compression where the image is compressed in the
first step with a given compression ratio; then the
compressed image is itself compressed using another
neural network[10]. Hussan et al proposed a

dynamically constructed neural architecture for
multistage image compression [11]. In this
architecture the necessary number of hidden layers and
the number of units in each hidden layer are
determined automatically for a given image
compression quality. Gersho et al have used Kohonen
Self-organizing Features Map (SOFM) for designing a
codebook for vector quantization of images [12].

2. Sub band image decomposition based on
wavelets

original signal x(n) can be reconstructed by requiring
that
G1(z) = 2H1(z);
and
G2(z) = -2H2(z)
H2(z) = H1(-z).
Under these assumptions, the z-transform Xˆ ( z ) of
the output signal xˆ ( n) can be obtained as

Xˆ ( z ) = [ H12 ( z ) − H 22 ( z )] X ( z )

(1)
The original signal can be perfectly reconstructed if

xˆ (n) = x(n); or equivalently, if Xˆ ( z ) = X(z).

2.1 Two-channel filter banks

According to (1), perfect reconstruction of the original
signal is guaranteed if

Consider the filter bank structure shown in Fig. 1
where a discrete time signal x(n) is applied to a system
consisting of a pair of filter banks. Given this original
sequence x(n) and its corresponding z-transform X(z),
a lower resolution signal can be obtained by low pass
filtering with a half band low pass filter having
impulse response h1(n) with z-transform H1(z). Then,
the half band signal can be made full band again by
down sampling by a factor of two. The “added detail”
of the signal can be computed in a similar fashion as a
high pass filtered version of x(n) (using a filter with
impulse response h2(n) and z-transform H2(z),
followed by down sampling by a factor of two as
depicted in the lower branch in Fig. 1. At the receiver
end of fig. 1, the signal xˆ (n) is reconstructed using
the filters g1(n) and g2(n) with z-transform G1(z) and
G2(z), respectively. The inputs to the filters g1(n) and
g2(n) are the decomposed signals yˆ1 ( n) and

H12 ( z ) − H 22 ( z ) = 1

yˆ 2 (n) respectively.
If the encoder-decoder and the channel are error-free,
that is, if yˆ1 ( n) = y1(n) and yˆ 2 ( n) = y2(n); then the

Fig 1. Two channel filter Band structure

Computer Graphics, Imaging and Visualisation (CGIV 2007)
0-7695-2928-3/07 $25.00 © 2007

(2)
For simplicity, let h1(n) = h(n). Since H2(z) = H1(-z).
h2(n) can also be expressed as h2(n) = (-1)nh1(n) = (1)nh(n). If h1(n) = h(n) is a low pass filter, then h2(n)
= (-1)nh(n) is a high pass filter. Since H1 (ω) = H(ω )

H 2 (ω ) =

+∞

∑ h ( n) e
2

− jωn

n = −∞

=H(ω-π)
If h(n) is a linear-phase Finite Impulse Response (FIR)
filter with an even number of coefficients, then (2)
holds if
2

2

H (ω ) + H (π − ω ) = 1
Filters that meet the above constraints are said to
posses perfect reconstruction properties and are often
called QMF’s or Conjugate Mirror Filters (CMF’s).
The above results were proposed by Crochiere et
al. [5] as a means to canceling aliasing in a twochannel filter bank. Even though this solution ensures
perfect reconstruction of a signal without aliasing, the
design of filters that meet these requirements is a very
difficult task and it has been a problem for decades.
Fortunately, wavelets can be used to construct FIR

filters with perfect reconstruction properties.
Decomposing a signal using orthonormal filters in the
two-channel filter bank as in Fig. 1 corresponds to
expanding the signal into orthonormal bases, where
the synthesis is the sum of the orthogonal projections.
The orthogonal decomposition sometimes is also
called or “lossless” filter bank. An interesting property
of such a filter bank is that its structure and properties
can be extended to more than two channels. If the twochannel filter bank is orthonormal, this structure
exactly implements an orthonormal discrete wavelet
series, also referred to as discrete wavelet transform in
the literature. For discrete-time signal expansions, the
basis functions are given by the impulse responses of
the synthesis filters. Nevertheless, if the filters are
orthogonal, analysis and synthesis filters are related by
simple time reversal, i.e., gi(n) = hi(-n).

2.2 Wavelet Representation of Images
Fig. 2 shows one level of a sub band image
decomposition scheme using wavelet functions as
analysis filters. Wavelet based sub band
decomposition of an image can be interpreted as an
image filtering process. For a given image A of size 2n
x 2n, wavelet decomposition can be performed as
follows: The wavelet filters h1(n) and h2(n) are applied
to the rows of the image A. The filter h1(n) is a low
pass filter with frequency response H1(ω) and h2(n) is
a high pass filter with frequency response H2(ω).
Filtering the image A with H1(ω) gives low-frequency
information or the background of the image, whereas
filtering it with H2(ω) gives the high-frequency
information or the edges of the image. Subsequent
down sampling by a factor of 2 gives two sub bands:
H1rA and H2rA (subscript r denotes that the filters are

Fig 2 One level of subband image decomposition

Computer Graphics, Imaging and Visualisation (CGIV 2007)
0-7695-2928-3/07 $25.00 © 2007

applied on rows of the image A). Since down
sampling by a factor of two is applied in the horizontal
direction of each sub band , the size of these two down
sampled sub bands is 2n x 2n-1. The filters H1(ω) and
H2(ω) are then applied to the columns of the images
H1rA and H2rA followed by down sampling by a factor
of two, and four sub bands are obtained : H1cH1rA;
H2cH1rA; H1cH2rA; and bands have gone through down
sampling by a factor of two in both directions and the
final size of each sub band is 2n x 2n . The sub band
H1cH1rA contains the smooth information and the
background intensity of the image and the sub bands
H1cH1rA; H2cH1rA; and H1cH2rA contain the detail
information of the image. The sub band H1cH1rA
corresponds to the lowest frequencies, H1cH2rA gives
the horizontal high frequencies (vertical edges),
H2cH1rA gives the vertical high frequencies (horizontal
edges) and H2cH2rA the high frequencies in both
directions (corners and diagonal edges).
Fig 3 shows a two-level wavelet decomposition
scheme for a 256*256 digital image. This
decomposition scheme produces three side bands of
size 128*128 corresponding to resolution level 1 and
four side bands of size 64*64, corresponding to
resolution level 2. Sub-image 1 represents the lowest
frequency components of the original image. Much of
the energy of image is concentrated here. Sub-image 2
to sub image 7 contain detail information of edge,
outline of image at different decomposition layers.
Sub-image 2 and sub-image 6 denote coefficient of
image at vertical edge after the first and second layers
wavelet decomposes. Sub image 3 and sub image 5
denote coefficients of image at horizontal edge. Subimage 4 and sub-image 7 denote the coefficients of
image on the cross edge. This decomposition allows
each band to be coded according to the sensitivity of

the viewer to distortion in that band. The compression
scheme presented in the paper uses DPCM to code
64*64 coefficients in band 1 and neural network to
compress the remaining coefficients in band 2 to band
7.

Fig 4 a multi layered neural network
k

yi = ∑ wij h j

i=1, 2, ……n

(4)

i =1

Fig 3 Decomposition on frequency plane by wavelet
transform

2.3 Neural Network for Data compression
Back-propagation is the first neural network
which is directly applied to image compression
coding. The neural network structure is shown in fig
2.1. Three layers, one input layer, one output layer and
one hidden layer, are designed. Both input layer and
output layer are fully connected to the hidden layer.
Compression is achieved by designing the value of k,
the number of neurons at the hidden layer, less than
that of the neurons at the input layer and output layer.
When the input vector is referred to as n dimensional,
n pixels from one sub band are being referred. All
weights connected to each neuron at the hidden layer
can be represented by {wij , j = 1,2, ... k and i = 1,2...
n}, which can also described by a matrix of k x n.
From the hidden layer to the output layer, the
connections are represented by {wij}, another weight
matrix of n x k, which is set equal to the transposition
of matrix [w]. Image compression is achieved by
training the network in such a way that the weights wij
scale the input vector of n dimension into a vector of
k-dimension (k< n) at the hidden layer and produce the
optimum output value which makes the quadratic error
between input and output minimum.
If we denote the weight from xi to hj as wij, then
the k elements of hidden vector h are related to n
elements of input vector x by expression
n

hi = ∑ wij xi

j=1, 2, ……k

(3)

i =1

the weight between hj and yi is wij, then the n elements
of hidden vector h by expression

Computer Graphics, Imaging and Visualisation (CGIV 2007)
0-7695-2928-3/07 $25.00 © 2007

The weights of neural network are chosen to minimize
the distortion between the input vector and output
vector. Back propagation algorithm is used to
minimize the squared error between input vector and
output vector for the training set. x ∈ [ −1,1] denotes
the normalized values of the wavelet coefficients.
With back propagation neural network, compression is
achieved in two phases, training phase and encoding.
In the first phase, a set of image samples is designed to
train the network via back propagation learning rule
which uses each input vector as desired output. This is
equivalent to compressing the input into the narrow
channel represented by hidden layers and then
reconstructing the input from the hidden to output
layer. In the encoding phase, the input is presented to
the input layer and compressed output is available at
the hidden layer.

3. Proposed method
Fig 5 shows the block diagram of complete image
compression system. First the image is decomposed
using wavelet transform. Because the human visual
system has different sensitivity to different frequency
components, the following scheme is adapted. The
lowest frequency band, band-1 (fig 3) is encoded with
DPCM. After that these coefficients are scalar
quantized. The remaining frequency bands are coded
using neural network. Band-2 and 3 contain the same
frequency contents for different orientation. So same
neural network is used to compress the data in these
bands and a different neural network is used for both
band-5 and 6. Band-4 coefficients are coded using a
separate neural network as frequency characteristics of
this band does not match with other bands. Band-7
information is discarded as it contains little
information to contribute to the image from the stand

Fig 5 Complete image compression system based on
sub band image decomposition and neural network
this band can be assumed to be zero with little effect
on the quality of reconstructed image. The output of
the hidden layer of neural network is then scalar
quantized. Finally these quantized values are entropy
encoded. Huffman encoding is used here. This scheme
was originally proposed in [13].

db18
db6
db4

Bit rate
0.40
bits/pixel
0.39
bits/pixel
0.37
bits/pixel

PSNR
29.371db
29.25db
29.058db

4. Experimental results and discussion

Table 1 Comparing bit rate and PSNR for different
wavelet filters for ‘lena’ image

The set of experiments evaluate the effect of
different wavelet filters on the quality of the
reconstructed image. Experiments were conducted
using the images ‘lena’, ‘pepper’, and ‘house’ of size
256 x 256, with 28 = 256 gray levels. Image was
decomposed using Daubechies’ 4- coefficient filter
(DAUB 4), 6-coefficient filter (DAUB 6) and 18
coefficient filter (DAUB 18). Band-1 is coded using
DPCM, Band-2 and 3 is coded using a neural network
with eight units in the input and the output and 6
hidden units i.e 8-6-8 neural network. Band-4 is coded
using a 8-4-8 neural network, and band-5 and 6 using
16-1-16 network. Scalar quantization and Huffman
coding was used on the coefficients of hidden layer.
Resulting image was evaluated by PSNR defined for
the
image
of
size
M
x
M
as

original image wavelet based decomposition improved
dramatically the quality of reconstructed images.
Wavelet decomposition eliminates blocking effects
associated with DCT. Among the wavelet filters tested
in the experiments DAUB 18 resulted in slightly better
reconstructed image.

PSNR = 10 log10

2552
1

M

M

M 2 ∑∑
i =1 j =1

(a)

(b)

( I ij − Iˆij ) 2

Where 255 is the peak signal value, Iij and Iˆij are the
pixels from the original and reconstructed images,
respectively.

4. Conclusion
In this paper we presented a neuro-wavelet based
paper. Compared to the neural network applied on the

Computer Graphics, Imaging and Visualisation (CGIV 2007)
0-7695-2928-3/07 $25.00 © 2007

(c)
(d )
Fig 6 (a) Original lena image (b) Reconstructed
Image with db18 (c) Reconstructed image with db6
(d) Reconstructed image with db4

(a)

(b)

Fig 7 (a) Original pepper image (b) Image
reconstructed with db18

(a)
(b)
Fig 8 (a) Original House Image (b) Image
reconstructed with db18

5. References
[1]
M. Antonini, M. Barlaud, P. Mathieu, and I.
Daubechies, “Image coding using wavelet transform,” IEEE
Trans. Image Processing, vol. 1, 1992, pp. 205–220.
[2]
P. C. Cosman, R. M. Gray, and M. Vetterli,
“Vector quantization of image sub bands: A survey,” IEEE
Trans. Image Processing, vol. 5, 1996, pp. 202–225.
[3]
D. Esteban and C. Galand, “Applications of
quadrature mirror filters to split band voice coding

Computer Graphics, Imaging and Visualisation (CGIV 2007)
0-7695-2928-3/07 $25.00 © 2007

schemes,” in Proc. IEEE Int. Conf. Acoustics, Acoustics,
Speech and Signal Processing, Washington, DC, 1979, pp.
191–195.
[4]
R. E. Crochiere, S. A. Webber, and J. L. Flanagan,
“Digital coding of speech in subbands,” Bell Syst. Tech. J.,
vol. 55, pp. 1976, 1069–1085.
[5]
P. C. Millar, , “Recursive quadrature mirror
filters—Criteria specification and design method,” IEEE
Trans. Acoust., Speech, Signal Processing, vol. 33, 1985, pp.
413–420.
[6]
J. W. Woods and S. D. O’Neil, , “Sub band coding
of images,” IEEE Trans.
Acoust., Speech, Signal
Processing, vol. 34, 1986, pp. 1278–1288.
[7]
S. G. Mallat, ,“A theory for multi resolution signal
decomposition: The wavelet representation,” IEEE Trans.
Pattern Anal. Machine Intell., vol. 11, 1989, pp. 674–693.
[8]
S. G. Mallat, , “Multi frequency channel
decomposition of images and wavelet models,” IEEE Trans.
Acoust., Speech, Signal Processing, vol. 37, 1989, pp. 2091–
2110.
[9]
N. Sonhera, M. Kawato, S. Miyake and K.
Nakane, “Image data compression using neural networks
model”, Proceeding of IJCNN, Washington, DC, 1989, pp.
1135 -1141.
[10]
Manphol s. Chin and M. Arozullah, ‘‘Image
compression with a hierarchical neural networks”, IEEE
trans. Aerospace and Electronic Systems, vol. 32, no 1.
1996,
[11]
M. H. Hassan, H. Nait Charif and T. Yahagi, , “A
Dynamically Constructive Neural Architecture for
Multistage Image Compression”, Znt. Conference on ~
Circuits, Systems and Computer, (IMACS-CS’98). 1998
[12]
B. Ramamurthi, A. Gersho. “Classified Vector
Quantization of
Images” IEEE Transactions on
Communications, Vol.Com-34, No. 11, 1986,
[13]
T. Denk, K. Perhi, V. Cherkassky, ”Combining
neural network and the wavelet transform for image
compression”, Proceeding of Intl Conf. 1993, pp 637-640,.
[14]
M. Mougeot, R. Azeneott, B. Angeniol, “Image
compression with back propagation: improvement of the
visual restoration using different cost functions” neural
networks Vol 4, No 4
1991, pp 467-476

Computer Graphics, Imaging and Visualisation (CGIV 2007)
0-7695-2928-3/07 $25.00 © 2007

