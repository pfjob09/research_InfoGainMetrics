Fast Motion Vector Generation for Video Coding by Gray Prediction
Dr. Yung-Gi Wu 1 and Guo-Feng Huang 2
1
Department of Computer Science and Information Engineering
2
Institute of Applied Information
Leader University
{wyg@mail.leader.edu.tw, d9416019@ms1.leader.edu.tw}
Abstract

where b is the size of marcoblock, and generally our
marcoblock’s size is 16. Bc( x, y ) denotes the gray

In this paper, we propose an efficient prediction
algorithm for motion vector in video compression.
Motion estimation is an important part of any video
processing system.
Exhaustive block matching
algorithm (EBMA) can get the optimal solution;
however, it takes too much computational burden. In
the proposed method, we use gray prediction to get the
motion vectors. Gray prediction can predict the motion
vectors quickly and accurately.
Several video
sequences are used to evaluate the performance.
Experimental results show that the time needed by the
proposed method is only 1.1% compared to EBMA and
3.25% to three steps searching (TSS) algorithm while
the degradation of PSNRY compared to EBMA is
about 0.8 dB at most for those test sequences.

level of the pixel at position ( x, y ) of the current block

Keywords--- Gray prediction, Motion vector, Motion
estimation

1. Introduction
Video coding has been proposed for many applications.
As the information develops quickly, motion
estimation plays an important role in video coding [1],
[2]. Motion estimation is used to reduce the temporal
correlation and use Discrete Cosine Transform (DCT)
to reduce the spatial redundancy. But, the searching of
motion vector takes a lot of computational burden so
that many searching algorithms have been proposed to
solve this drawback. An EBMA is used to find motion
vector for its regularity and simplicity. In a simple
BMA, a frame is divided into non- overlapped square
blocks.
The matching criterion used is the
accumulated absolute difference (AAD) which is
defined
b b
(1)
AAD(v , v ) =
Bc( x, y) − Br( x + v , y + v )
x

y

∑∑

x

y

x =1 y =1

Computer Graphics, Imaging and Visualisation (CGIV 2007)
0-7695-2928-3/07 $25.00 © 2007

in the current frame and Br ( x + v x , y + v y ) denotes
the

gray

level

(x + vx , y + v y )

of the pixel at position
of the reference block in the re-

ference frame. By (1), the best matching reference
block within the search window is the found block
with the minimal AAD (v x , v y ) .
Motion compensation is a key component of many
video-coding standards due to its high efficiency in
reducing temporal redundancy between successive
frames. Block-based motion estimation is the most
popular method to obtain motion-compensated
prediction. By dividing each frame into rectangular
blocks of equal size, the motion estimator obtains a
motion vector (MV) for each of the blocks within a
search window in the reference frame using the BMA.
The full search algorithm (FSA) is the most
straightforward BMA, which provides an optimal
solution by matching all the candidate blocks inside a
searching window. It is popular in video coding
applications because of its simplicity and easy
implementation. However, its heavy computational
load for large searching range is a significant
bottleneck in real-time video coding applications. In
order to resolve this difficulty, many fast search
algorithms for motion estimation (ME) to reduce the
computation of the FSA have been developed in the
past [3-7]. Generally speaking, these fast ME methods
in the BMA can be classified into two groups. One is
the lossless ME algorithm, and the other is the lossy
one. The lossless ME obtains no degradation of
predicted images compared with the conventional FSA

Fig. 1 Direction #1 of the position relation of the block.

Fig. 2 Direction #2 of the position relation of the block.

(e.g., PDS[3]), and the lossy ME has some degradation
of predicated images compared with the conventional
FSA (e.g., TSS[4], CS[5], DS[6], 4SS[7]). In the fast
lossless ME algorithm, the partial distortion search
(PDS) is an excellent one because it removes
unnecessary computations efficiently and can be easily
realized in VLSI [3].
In [8] and [9], they mainly focus in the image
complexity of the coded block and propose adaptive
matching scan algorithms to determine the matching
order by sorting gradient magnitude of sub-blocks in a
marcoblock (MB) of the current frame in descending
order.
For the motion vectors, the neighboring blocks have
close relationship. In this paper, we employ its
relationship and adopt gray prediction to generate
motion vector. The gray model (GM) can get excellent
prediction, and it has been using in many fields widely
[11], [12]. Based on the characteristic of gray
prediction, we generate motion vector quickly in this
paper.
The remainder of this paper is organized as follows.
Gray prediction we used is presented in Section Ⅱ.
Section Ⅲ presents our proposed algorithm.
Experimental results are demonstrated in Section Ⅳ.
Some concluding remarks are addressed in Section Ⅴ.

del. As most gray systems do, the accumulated generating operation (AGO) is used in the design.

2. Gray prediction
The gray theory, applicable to the prediction problem of a time-varying nonlinear system, was first
proposed by Dr. Deng in 1982 [10] and has been
widely used for many fields, such as economics,
geography, weather, and automatic control. By using a
few data and solving the differential equations, the
gray model can predict the system accurately. In this
paper, A kind of single variable and first-order linear
dynamic gray model, name as GM(1,1), is adopted.
In many cases, the raw data obtained by measuring
those systems is important element to set up a gray mo-

Computer Graphics, Imaging and Visualisation (CGIV 2007)
0-7695-2928-3/07 $25.00 © 2007

X ( 0 ) = ( x ( 0 ) (1), x ( 0) (2),..., x ( 0 ) (n)) denotes the
( 0)
original data sequence, where x (i ) represents the
system output at time i , and n is the length of the data.
The
new
sequence X (1) = ( x (1) (1), x (1) (2),..., x (1) (n)) generated
with the AGO is derived as follows:
k

x (1) (k ) = ∑ x ( 0) (m) k ∈ {1,..., n}

(2)

m =1

According to GM(1,1), we can yield the following
first-order gray differential equation as below:

dX (1)
+ aX (1) = b
dt

(3)

By solving the differential equation, we can get the
prediction function for the gray system

b
b
xˆ ( 0 ) (k + 1) = ( x ( 0) (1) − )e − ak + for k > 0 (4)
a
a
(0)
(1)
(1)
xˆ (k + 1) = xˆ (k + 1) − xˆ (k ) for k > 0 (5)
where xˆ denotes the prediction of x, and a and b are
determined by

a=

CD − (n − 1) E
DF − CE
,b =
2
(n − 1) F − C
(n − 1) F − C 2
k

k

m=2
k

m=2

C = ∑ z (1) (k ), D = ∑ x ( 0) (k )

(6)
(7)

k

E = ∑ z (1) (k ) x ( 0 ) (k ), F = ∑ z (1) (k ) 2
m=2

m=2

k

z (1) (k ) = ∑ (0.5 × x (1) (k − 1) + 0.5 × x (1) (k ))
m=2

(8)

3. The proposed algorithm

X ( 0 ) = ( x ( 0) (1), x ( 0 ) (2), x ( 0) (3), x ( 0) (4))

In [13], it proposed a method using the adjacent four
blocks to predict a new motion vector. In the proposed
method, different to [13], we use more blo-cks to
generate our gray model to predict the motion vector.
In our algorithm, a video frame is processed in left
to right and top to bottom manner. By using the
neighboring block’s motion vectors of the current
block in current image, the GM(1,1) is applied to
predict motion vector of block. Fig. 1 and Fig. 2 show
the position relation of the current block and the
reference blocks used for gray prediction. There are
two directions in our method.
i
r1

i
r2

Here, B and B represent the current reference
block in frame i , and they are in the same position. In
order to determine the motion vector, we deter-mine
i

i

the predicted position of Br1 and Br 2 . The predicted

= ((mx1i + 200), (mx2i + 200), ( mx3i + 200), (mx4i + 200))
(1)

Step 2：Generate the new data sequence X with
AGO [refer to (2)].
Step 3：Determine a and b using (6)－(8).
Step 4：Calculate xˆ

(0)

(3) using (4) and (5). Then,

i
r 1 as

determine xˆ

xˆ

i ( 0)
r1

follows：

= ( xˆ ( 0) (3) − 200)

In order to smooth the gray prediction curve, we
generate the data sequence X
i

i

(0)

by adding 200.

i

Similarly, yˆ r1 , xˆr 2 , and yˆ r 2 are calculated through
the same four steps.
using (9).

Then, Vˆr can be obtained by
i

i

vector of Br1 is denoted as pˆ ri 1 = [ Δxˆ ri 1 , Δyˆ ri 1 ] , and
i

the another predicted vector of Br 2 is denoted as
i

intrablock

i

ˆ r1 and pˆ r 2 hint the
Both p
correlation.
Here,
one
more

pˆ ri 2 = [ Δxˆ ri 2 , Δyˆ ri 2 ] .
i −1

i −1

vector Vr represents the motion vector of Br in the
position of (m, n) of the previous frame which hints
interframe correlation. Vˆri represents the final motion
vector we predict and which Vˆri is given as

Vˆri = w1 × pˆ ri 1 + w2 × pˆ ri 2 + w3 × Vri −1

(9)

Where w1 , w2 , and w3 are the weight of the three
vector components.

i −1

The Vr

is obtained in the
i

ˆ r1
previously estimating process in frame i-1, and p
i

ˆ r 2 are determined by gray prediction process
and p
which are described below.
For example, Fig. 1 shows the position-relation of
reference block and the four neighboring blocks used
i

for interblock prediction. The Br1 is located at
(m, n), where m or n is the column or row number.
The four neighboring blocks which locate at (m-16, n16), (m-16, n), (m+16, n), and (m+16, n+16) are
denoted as B j for j ∈ {1,2,3,4} . V ji = [mx ij , my ij ]
i

represents the MV of B

i
j

i
r1

i
r1

i
r1

ˆ = [Δxˆ , Δyˆ ]
and p
i
r1

i
r1

represent the predicted vector of B . Then, xˆ is
calculated using the following gray prediction steps.
Step 1：Construct the original data sequence

Computer Graphics, Imaging and Visualisation (CGIV 2007)
0-7695-2928-3/07 $25.00 © 2007

4. Experiment results
In this section, some experiments are carried out to
compare the performance among the FS algorithm,
TSS algorithm, PDS, and our proposed algorithm. Our
programming is using Microsoft visual studio.net C#
and AMD K7 2500+ PC. In our experiment, we use
four video sequences and the marcoblock size is fixed
to 16×16 pixels.
The “Mobile,” ”Miss
America,” ”Salesman,” and ”Claire” sequences are
used to test the proposed algorithm. Each frame in the
video sequence is in the size of 176×144. Generally,
PSNR (Peak Signal-to-Noise Ratio) is compared with
preci-sion standard. In video, we use PSNRY to
evaluate because we adopt Y in YUV. The PSNRY is
defined by
255 2
(10)
PSNRY = 10 log10 (
)
MSE
where MSE is the mean square error between the
estimated image frame and original image frame. Four
different video sequences listed in Table 1 will be
simulated for comparison.
Table 1. Four sequences used for simulation and
comparison
sequence

Miss-A

Mobile

Salesma
n

Claire

Frame size

176×14
4
50

176×14
4
50

176×14
4
50

176×14
4
50

Frame
number

Table 2. PSNRY comparison
PDS+FS
TSS
NTSS

FS

FSS

OURS

Miss-A

40.222

40.222

40.194

40.183

40.189

39.528

Mobile

25.803

25.803

25.782

25.803

25.803

25.601

Salesman

37.844

37.844

37.815

37.817

37.779

37.056

Claire

41.263

41.263

41.158

41.154

41.148

40.777

Average

36.283

36.283

36.237

36.239

36.23

35.741

43

27

42

26.5
FS

FS

PDS+FS
TSS

40

NTSS

PSNRY

PSNRY

41

FSS

39

PDS+FS

26

TSS
NTSS

25.5

FSS

OURS

OURS
25

38
37

24.5
1

4

7 10 13 16 19 22 25 28 31 34 37 40 43 46 49

1

4

frame number

7 10 13 16 19 22 25 28 31 34 37 40 43 46 49
frame number

(b)
45

46
45
44
43
42
41
40
39
38
37
36
35
34
33
32
31

44
43

FS
PDS+FS
TSS
NTSS

FS
PDS+FS

42
PSNRY

PSNRY

(a)

TSS

41

NTSS

FSS

40

FSS

OURS

39

OURS

38
37
1

4

7 10 13 16 19 22 25 28 31 34 37 40 43 46 49
frame number

(c)

1

4

7 10 13 16 19 22 25 28 31 34 37 40 43 46 49
frame number

(d)

Fig. 3 Frame-wise performance comparison on PSNRY for the sequence (a)”Miss-A” (b)”Mobile”
(c)”salesman” and (d)”Claire”.
Table 2 shows the PSNRY distortion of each algorithm
to measure the difference between original frame and
reconstructed frame after motion estimation and
motion compensation. The information listed in Table
2 is the reconstruction quality. The FS algorithm is the
optimal solution, and it obtains best quality. We use
gray prediction to generate motion vector, but we also
obtain good performance. Figure 3 show the PSNRY
frame by frame for four methods on four various

Computer Graphics, Imaging and Visualisation (CGIV 2007)
0-7695-2928-3/07 $25.00 © 2007

sequences. In Table 3, we analyze FS algorithm and
gray prediction’s mathematics operation. Obviously,
we can know that gray prediction needs less
computation than FS algorithm. Table 4 shows the
times needed to generate a motion vector for different
methods. Our proposed method reduces 98.9% time
than FS algorithm and 96.8% time than TSS algorithm.
Table 5 shows the probability of finding the true

motion vector.
We can know that using gray
prediction can obtain good degree of accuracy.

＋

Table 3. Mathematics operation
×
－

Gray prediction

38

18

24

Full Search

587520

589824

÷

square

8

12

Table 4. Times needed to generate a motion vector for different methods
FS

PDS+FS

TSS

NTSS

FSS

OURS

190.78(ms)

91.41(ms)

31.41(ms)

31.25(ms)

37.81(ms)

3.13(ms)

Table 5. Probability to find the true motion vector

OURS

Miss_A

Salesman

Mobile

Claire

71.09%

96.86%

93.48%

91.31%

5. Experiment results
In our research, we have presented using gray
prediction to generate the motion vector quickly. We
choose gray prediction to implement our research,
because gray prediction not only is simple but also has
good accuracy. We evaluate the proposed method by
three video sequences, and its performance has been
compared with other algorithms. Experiment results
show that our method have similar performance to FS,
PDS+FS, TSS, NTSS and FSS in terms of PSNRY.
Our method reduces a lot of time better than other
algorithms. The result supports that our proposed
method offers good trade off between speed and
quality.

6. Reference
[1]
[2]
[3]
[4]

A.M Tekalp, Digital Video Processing.
Englewood Cliffs, NJ:Prentic-Hall, 1995
K. R. Rao and J. J. Hwang, Techniques and
Standards for Image, Video, and Audio Coding.
Englewood Cliffs, NJ: Prentice-Hall, 1996.
S. Eckart and C. Fogg, “ISO/IEC MPEG-2
software video codec,” Proc. SPIE, vol. 2419, pp.
100-118, 1995.
Koga T, linuma K, Hirano A, lijima Y, Ishiguro
T., “Motion-compensated interframe coding for

Computer Graphics, Imaging and Visualisation (CGIV 2007)
0-7695-2928-3/07 $25.00 © 2007

video conferencing,” in Proc. Nat. Telecom.
Conf., New Orleans, LA, USA, 1981, pp.
C9.6.1–9.6.5.
[5] N. Ghanbari, “The cross-search algorithm for
motion estimation,” IEEE Trans. Commun., vol.
38, no. 7, pp. 950–953, July 1990.
[6] S. Zhu and K. K. Ma, “A new diamond search
algorithm for fast block-matching motion
estimation,” IEEE Trans. Image Processing, vol.
9, no. 2, pp. 287-290, Feb 2000.
[7] L.-M. Po and W.-C. Ma, “A novel four-step
search algorithm for fast block motion
estimation,” IEEE Trans. Circuits Syst. Video
Technol., vol. 6, no. 3, pp. 313–317, Mar. 1996.
[8] J. N. Kim, S. C. Byun, Y. H. Kim, and B. H. Ahn,
“Fast full search motion estimation algorithm
using early detection of impossible candidate
vectors,” IEEE Trans. Signal Process., vol. 50,
no.9,pp. 2355-2365, Sep. 2002.
[9] Montrucchio, B. and Quaglia, D., “New sortingbased lossless motion estimation algorithms and
a partial distortion elimination performance
analysis,” IEEE Trans. Circuits Syst. Video
Technol., vol. 15, no. 2, pp. 210-220, Feb.2005.
[10] Dhara, B.C. and Chanda, B, “Video motion
estimation using prediction based hybrid
approach,” in Proc. of ICPR’2004, vol. 4, pp.
737-740, Aug. 2004.

[11] R. Li, B. Zeng, and M. Liou, “A new three-step
search algorithm for block motion estimation,”
IEEE Trans. Circuits Syst. Video Tech., vol. 4,
no. 4, pp. 438-442, Aug. 1994.
[12] J. Deng, “Control problems of grey system,” Syst.
Control Lett., vol. 5, pp. 288-294, 1982.
[13] Y. P. Huang and C. C. Huang, “The integration
and application of fuzzy and grey methods,”
Fuzzy Set Syst., vol. 78, no. 1, pp. 107-119, 1996.
[14] Y. P. Huang and T. M. Yu, “The hybrid graybased models for temperature prediction,” IEEE
Trans. Syst., Man, Cybern. B, vol. 27, no. 2, pp.
284-292, Apr. 1997.
[15] J. L. Chen and P. Y. Chen, “An Efficient Gray
Search Algorithm for the Estimation of Motion
Vectors,” IEEE Trans. Syst., Man, Cybern. –Part
C: Applications And Reviews, vol. 31, no. 2, pp.
242-248, May 2001.

Computer Graphics, Imaging and Visualisation (CGIV 2007)
0-7695-2928-3/07 $25.00 © 2007

