Dual-Pivot Pose Determination of Human Head Based on Head Movement
Fakhrul Hazman Yusoff1, Rahmita Wirza O.K. Rahmat2, Md. Nasir Sulaiman3, Mohamed Hatta
Shaharom4, Hariyati Shahrima Abdul Majid5
Universiti Putra Malaysia1,2,3, Cyberjaya University College of Medical Sciences4, International
Islamic University5
{fhazman1975@yahoo.com.my, rahmita@fsktm.upm.edu.my, nasir@fsktm.upm.edu.my,
hatta@cybermed.edu.my, shahrima@iiu.edu.my}
Abstract

The pose determination is very important
especially for system such as face tracking, face
recognition, face analysis and even face modeling
system. Pose determination is a pre-requisite step for
establishing face orientation of which will be used in
determining the shape and structure of the face.
Existing rotation-based pose determination that
describes head movement using a single pivot point
cannot describe rotation that involves changes in
pivot point. In addressing the issue, this paper
suggests a pose determination technique via usage of
two pivot points. The paper will propose a definition
for dual-pivot pose determination, suggest
approaches to calculate head movement along these
pivots, show a brief application for the dual-pivot
and give comment on advantages and disadvantages
of dual- pivot points.

1. Introduction
Head pose determination is an important step in
many applications that involve face processing. Head
pose information will be useful for performance
driven head modeling of which it will be used to
match the acquired human head with the available
generic head stored in database [9], [6]. It is also
useful for face recognition processing of which it can
be used to match the acquired face with the existing
face image repository [4]. Head pose information is
also needed for automatic view cam adjustment in
video-based teleconference settings to enhance faceto-face interaction between two or more
communicating parties [13]. Likewise head pose
determination is needed for machine vision of which
different pose may signal different things or different
priorities.

Computer Graphics, Imaging and Visualisation (CGIV 2007)
0-7695-2928-3/07 $25.00 © 2007

While there are many methods used for head pose
determination, one of the simple method is by
describing movement as rotation in x, y or z direction
from one fixed pivot point. The method is used by
Ben Yip in his paper titled “Pose Determination and
Viewpoint Determination of Human Head in Video
Conferencing based on Head Movement” [14].
According to Yip, turning the head to the left can be
described as rotation on Y-axis. Likewise looking up
can be described as rotation on X-axis. In modeling
human head with expression, head pose
determination based on rotation can be used to
describe the way human move their head as
expressions are manifested. Looking down
depressively can be described by clockwise rotation
on X-axis. Nodding the head signaling the act of
agreement can be described as rotation on Z-axis. In
short, many of the gestures can be described in terms
of rotation relative to X, Y and Z-axis or combination
of these axes. Yip’s method assumes that rotation
will be fixed on one pivot point. The following
pictures illustrate some of the movement that can be
described using one pivot point.

(c)
(a)
(b)
Figure 1 – Example of rotation based movement.
(a) Pitch (Rotation on X-axis). (b) Yaw (Rotation on
Y-axis). (c) Roll (Rotation on Z-axis).
Unfortunately, not all head movement can be
adequately described as rotation of a single pivot. A
situation may arise in which the pivot point moves
forward or backward and the movement does not

involve any rotation. Consider
movement illustrated in Figure 2:

the following

(b)
(a)
Figure 2 - Example of ‘pulling’ face backward.
(a) Front view. (b) Profile view.
Figure 2 shows an act of ‘pulling’ face
backward. ‘Pulling’ face can be described as a
movement of which a person moves his face
backward in a near horizontal movement. This can be
as a result of disgust or surprise situation. In its pure
form, the process does not involve any rotation
relative to the available axes. In fact, the movement is
more towards the displacement of the pivot point
from one place to another. The opposite of ‘pulling’
face will be ‘pushing’ face as illustrated in Figure 3.
Similarly, the existing method by Yip cannot
describe the ‘push’ of face adequately as his method
only involves rotation on one pivot point.

(b)
(a)
Figure 3 - Example of ‘pushing’ face forward.
(a) Front view. (b) Profile view.
As a solution to address the situation, this paper
proposes an extension of Yip’s pose determination
method to enable the description of ‘pushing’ or
‘pulling’ of face. The proposed method introduces
second pivot point to consider a situation in which
the first pivot point is displaced by certain amount
during ‘pulling’ or ‘pushing’ of face.

of elements in doing pose determination. Gemmell
calculates gradient descent of nine feature points
along with face model [3]. On the other hand, Ho and
Huang use the corner of eyes and mouth to determine
the pose [5]. The approach of using eyes and mouth
is also used by Wang and Sung [11]. While Wang
and Sung use both eyes and mouth, Yip utilizes the
eye separation value in determining pose [14]. This
proposed method will be using Yip’s method by
basing pose determination on eye separation.
While the above researches look at ways to
identify vital area on the face for pose calculations,
other researches focus on the view of the face for
pose determination. Some researchers propose single
perspective pose evaluation [14], [2], [15]. On the
other hand, other researchers utilize multiple views in
estimating the pose. Ansari for example proposes two
orthogonal views in the effort for automatic feature
extraction with application to 3D face-recognition
[1]. Meanwhile Gokturk and Strom use multiple
views to estimate movement of head for viewindependent facial expression recognition [4], [10].
Regardless of single or multiple views, a uniform
way to describe the movement of the face is needed.
It is not enough to have a pose description which is
relevant only to single or multiple views. Instead the
pose determination description must encompasses
both multiple and single views.
One of the simple ways to do pose determination
is through a method proposed by Yip. Yip determines
the pose by establishing an arbitrary pivot point
based on cervical vertebrae. He suggests for a pivot
point to be fixed on the third cervical vertebra known
as C3. Yip labels this point as C and treats it as the
pivot point for rotation. The calculation of the
rotation in X, Y and Z axis (referred as α, β, γ) is
done with respect to the C point. Our approach is a
continuation of Yip’s method by complementing his
pose determination so that the description can be
used in both single and multiple views. Furthermore,
our new method enables description of face ‘pullingpushing’ motion that cannot be described by Yip’s
method.

3.0 Pose Determination
2.0 Literature Review
There are various researches done on pose
determination of human head. Some researchers
focus on using features found on the face to estimate
the pose. Zitnick suggests the usage of nostril as the
point of reference for pose determination [16]. Yang
on the other hand relies on pupil’s size, inter-pupil
distance and pupil shape in pose determination
calculation [12]. Other researchers combine a number

Computer Graphics, Imaging and Visualisation (CGIV 2007)
0-7695-2928-3/07 $25.00 © 2007

3.1 The Pivots of Human Head Rotation
We utilize the pivot point as proposed by Yip
and label it as C. On top of that we introduce another
pivot point at the cervical vertebra C7 and we label it
as D. We choose C7 as another pivot point since it is
the base of cervical vertebrae which makes up the
neck section [7]. Assuming no other parts of the
human body moves, the occasional movement of C3

will be tied on the last vertebra of the section which
is C7.
The second pivot point (C7) will be located at
the base of the neck. As our neck at rest is slightly
slanted to the front, D will be farther back from C.
We estimate the location of D to be at (0 ES, -2377
ES, -353 ES). We use ‘ES’ unit which stands for Eye
Separation; a standard unit which is outlined by
MPEG-4 Face Model in neutral state specification [8]
and used by Yip [14]. As different persons may have
different neck flexibility, the estimation of D may
vary from one person to another. Diagram 1
illustrates the location of C and D. The origin of the
used coordinate system is at the center point of the
head measured during a known pose (initial pose). It
means that in order to track the movement, the
subsequent head movement coordinate will be based
on the coordinate system of the initial pose.
Y

Y

Real
World

Z

C
D

Pivot
Point

View

Diagram 1 – The location of pivot points.
Diagram is adapted from Yip [14] and enhanced
by introduction of second pivot point namely D.
C can have a limited back and forth movement
along Z-axis. Based on Diagram 1, the movement
will be a rotation type movement with D as the center
of rotation. However as the displacement is minimal
it is expected that the displacement will appear
almost horizontal along Z-axis.
As the movement of C is near horizontal and it
does not have any distinct physical mark to track, its
displacement can be implied by measuring the
displacement of the ear from its original position.
D, on the other hand, will remain stationary in all
situations. As a result of introducing new pivot point,
the rotational variant will no longer be confined to
pitch, roll and yaw. The following Table 1
summarizes the existing rotational properties
introduced by Yip with additional ‘pulling-pushing’
movement introduced in this paper:

Computer Graphics, Imaging and Visualisation (CGIV 2007)
0-7695-2928-3/07 $25.00 © 2007

Table 1 – Various movements produced by
head.
Angle
Description
Label
Movement on Xα
axis (Pitch)
X
β

Movement on Yaxis (Yaw)

γ

Movement on Zaxis (Roll)

δ

Horizontal
movement of C on
Z-axis while D
remains
fixed
(‘Pullingpushing’).

Y

The calculation for pitch, yaw and roll are
available in Yip’s paper. Please refer to [14] for
further details. The calculation of ‘pulling-pushing’
movement is done by tracking the displacement of C
relative to the known pose. The following section
will proceed with the calculation of δ which describes
the ‘pulling-pushing’ movement of the head.

3.2 Finding the δ Angle
Assuming the coordinate system is at the center
point of the head. Let:
C = (Cx,Cy,Cz) be the first pivot point.
D = (Dx,Dy,Dz) be the second pivot point.
δ = displacement of C (in degree)
C’ = new C position
rs = the distance between C and D
Diagram 2 depicts the geometry used in
establishing the angle δ. δ-angle can be viewed as
almost horizontal change of C either to front or back.

4.0 Result

Y

Y

Real
World

rs

Distance
between C
and D
New
Location
of C

C

C’
rs

View
Plane

Z

Pivot Point

δ

δ Movement
of C (in
degree)

D

Diagram 2 – Introduction of pivot point D to
address the movement of C.

To demonstrate the usage of the formula in
establishing the pose determination with dual-pivot
points, two subjects are asked to do face “pulling”.
As the paper’s intent is to show the applicability of
the new method and not comparing it with other
methods, it is assumed that having two subjects are
sufficient in demonstrating the calculation of dualpivot pose determination.
While getting the precise measurement of the
pose will be difficult, the proposed method offers a
good solution in estimating the degree of face
‘pulling-pushing’. Figure 4 shows the results for face
‘pulling’.

Assuming the movement is confined only to
pivot point C, the formula for calculating δ requires
establishing the length between C and D which will
act as the radius (rs) for rotation:

rs = (C y − D y ) 2 + (C z − Dz ) 2

(a)

(b)

(c)

As the movement is circular, the length of C’D
will be the same as rs (CD) thus the Law of Cosine
can be applied to calculate δ. After simplification the
formula will be as follows:



δ = cos −1 1 −


(C y − C y ' ) + (C z − C z ' ) 

2
2rs

2

2

3.3 Detecting Horizontal Movement from
Frontal View
Detecting the ‘pulling-pushing’ movement from
frontal view will be harder than the typical pitch,
yaw, and roll as the only indication will be a subtle
shrinking or enlarging of the face in a barely
noticeable amount that can be mistaken for noise.
Describing ‘pulling-pushing’ movement will be more
effective if the view is slightly non-frontal allowing
for more depth information. In addition, face
‘pulling-pushing’ can also be implied if there exist
non-uniform displacement values among feature
points on the face. Ultimately, ‘pulling-pushing’ can
be best detected if the view is profiled as the image
acquired in profile view will definitely have
information in the movement relative to Z-axis.

Computer Graphics, Imaging and Visualisation (CGIV 2007)
0-7695-2928-3/07 $25.00 © 2007

(e)
(f)
(d)
Figure 4 – (a) Known pose (front). (b) Known
pose (profile). (c) Face ‘Pulling’ (profile).
0
Estimated δ for 4(c) = 9 . (d) Known pose (front).
(e) Known pose (profile) (f) Face ‘Pulling’
(profile). Estimated δ for 4(f) = 190.
Figure 4(c) does not register much rotation since
the movement is subtle. On the other hand Figure
4(f) registers more rotation as the movement is more
significant.
The simple experiment shows that by knowing
the extend of face “pulling-pushing”, one can
differentiate the level of expressiveness a person may
have compared to others. Using a single pivot, it is
not possible to attribute the displacement to
expressivity as the movement can also be caused by
ordinary rigid movement.

5.0 Summary
The inclusion of an additional pivot point is vital in
describing face movement which cannot be described
with single pivot point. By having δ angle alongside
α, β and γ, pose that depicts face ‘pulling-pushing’
can be described more accurately and can be

distinctly differentiated from ordinary swaying of
head. While the approach has its promises, measuring
the actual angles of δ will be difficult as it involves
calculating depth value. A frontal image alone may
not be good enough to measure the value of δ as
some depth information will be required.
Furthermore, in frontal image, any movement along
Z-axis will have a minimal indication unlike
movement along Y-axis or X-axis. Nevertheless if
some depth information exists, our approach will
give better description than the approach suggested
by Yip. In addition, by having description along Xaxis, Y-axis and Z-axis, the pose determination
process will be much more comprehensive as its
multi-angle nature can be used for either single or
multi view pose determination. In the future, we plan
to do more research in proper pivot point
establishment scheme in order for the pivots to be
person independent.

[7]

Marieb, Elaine. Essentials of Human Anatomy and
Physiology. San Francisco: Pearson, pp. 150-151,
2006.

[8]

Ostermann, Jorn. Face Animation in Mpeg-4.
MPEG-4 Facial Animation – The Standard,
Implementation and Application. Ed. Pandzic, Igor,
Forchheimer, Robert. West Sussex, England: Wiley,
pp. 17-21, 2002.

[9]

Pighin, Frederic. Modeling and Animating Realistic
Face from Images. PhD Dissertation. University of
Washington. 1999.

[10]

Strom, Jacob. Model-Based Real-Time Head
Tracking. EURASIP Journal on Applied Signal
Processing 2002:10, pp. 1039-1052, 2002.

[11]

Wang, J-G., Sung, E. Pose Determination of Human
Faces by Using Vanishing Points. Pattern
Recognition, Volume 34, pp. 2427-2445, 2001.

References

[12]

Yang, R., Zhang, Z. Eye Gaze Correction with
Stereovision for Video-teleconferencing. Microsoft
Research Technical Report. MSR-TR-2001-119,
2001.

[13]

Yip, B., Jin, J.S. Face Re-Orientation in Video
Conference Using Ellipsoid Model. Proceedings of
OZCHI 2003, Brisbane, Australia, pp 167-173, Nov
2003.

[14]

Yip, B., Jin, J.S. Viewpoint determination and pose
determination of human head in video conferencing
based on head movement. Proceedings of the 10th
International Multi-Media Modeling Conference,
Brisbane, Australia, pp. 130-135, 2004.

[15]

Zhu, Zhiwei., Ji, Qiang. Real Time 3D Pose
Tracking from an Uncalibrated Camera.
Proceedings of the 2004 IEEE Computer Society
Conference on Computer Vision and Pattern
Recognition Workshop (CVPRW’04), pp. 400-403,
2004.

[16]

Zitnick, C. L., Gemmell. J., Toyama, J.
Manipulation of Video Eye Gaze and Head
Orientation for Video Teleconferencing. Microsoft
Research Technical Report. MSR-TR-99-46, 1999.

[1]

[2]

[3]

[4]

Ansari, A-Nasser. , Abdel-Mottaleb, Mohamed.
Automatic Facial Feature Extraction and 3D Face
Modeling Using Two Orthogonal Views with
Application to 3D Face Recognition. Pattern
Recognition 38, pp. 2549-2563, 2005.
Chandra, T., Abidi, M. A. Evaluation of A Pose
Estimation Algorithm Using Single Perspective
View. SPIE 1382. Intelligent Robots and Computer
Vision IX: Neural, Biological and 3-D Methods, pp.
409-426, 1990.
Gemmel, J., Zitnick, C. L., Kang, T., Toyama, K.,
Seitz, S. Gaze awareness for video-conferencing: A
Software Approach. IEEE Multimedia 7(4), pp. 2635, 2000.
Gokturk, Burak., Bouguet, Jean-Yves, Tomasi,
Carlo., Girod, Bernd. Model-Based Face Tracking
for View-Independent Facial Expression
Recognition. Proceedings of the Fifth IEEE
International Conference on Automatic Face and
Gesture Recognition (FGR’02), pp. 287-293, 2002.

[5]

Ho, S., Huang, H. An Analytic Solution for the Pose
Determination of Human Faces from a Monocular
Camera. Image and Vision Computing 20(7), pp.
499-511, 1998.

[6]

Lopez, Ricardo., Huang, Thomas. 3D Head Pose
Computation from 2D Images: Templates Versus
Features. Proceedings of the 1995 International
Conference on Image Processing (ICIP'95), pp.
599-602, 1995.

Computer Graphics, Imaging and Visualisation (CGIV 2007)
0-7695-2928-3/07 $25.00 © 2007

