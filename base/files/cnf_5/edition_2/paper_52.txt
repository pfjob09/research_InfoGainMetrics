2009 Sixth International Conference on Computer Graphics, Imaging and Visualization

A Real-time Detecting and Tracking Method for Moving Objects
Based on Color Video
Jianyu Li , Feng Li , Min Zhang
Department of Computer Science and Telecommunication Engineering,
Jiangsu University,Zhenjiang 212013,China
{lijianyu_520@163.com,betta.fli@gmail.com,zhangmin1605@163.com}
will not work well if a new object appears or the
original objects are removed in scene. Stauffer, etc. [2]
proposed a new method to eliminate the illumination
and background confusion moving using adaptive
Gaussian mixture model for background modeling, but
it is mostly applied in gray video, as to color video, the
computation is very large.
In tracking, D. Comaniciu etc.[3] presented a
meanshift kernel tracker. It worked well when part
occlusion occurred, but the model of the object needed
to be offered by user. C. Hue etc.[4] described an
extension of the classical particle filter. But it has
some deficiencies in the situation of background
clustering, occlusion and chaotic objects. In [5], a
method combines template with Monte Carlo Markov
Chain to track vehicles and humans respectively. The
problem of occlusion is solved using templates well,
but the effect of the tracking is not so good when both
vehicles and humans appear. Gary R. Bradski [6]
proposed Camshift algorithm using color features to
track moving objects in color video sequences fast and
robustly, but this algorithm can not be used to track
automatically, and it will be ineffective when there are
occlusion problems. Furthermore, it can only track
single moving object. Thus, in this paper, it is
proposed a method of Gaussian mixture model based
on Bayer pattern combined with improved Camshift to
detect and track the moving objects in color video
sequences. Through actual moving objects detection
and tracking as examples are taken, this algorithm has
advantages of quick speed and good accuracy.
Meanwhile, it can realize multi-moving objects
tracking and overcome occlusion problem in the
process of tracking.
The remainder of this paper is organized as
follows. We introduce the Gaussian mixture model
method in color video based on Bayer pattern in
section 2 and the method of object tracking based on
improved Camshift algorithm is introduced in Section

Abstract
In this paper, a new background modeling method
using Gaussian mixture model based on Bayer color
filter array is proposed. It improves the efficiency of
obtaining the prospect moving objects in the color
video. Besides, it is proposed a method that can track
the multi-moving objects using the combination of
Camshift and Kalman filter based on the prospect
image. Take actual moving objects detection and
tracking as examples, this algorithm has advantages of
quick speed and good accuracy. Meanwhile, it can
realize multi-moving objects tracking and overcome
occlusion problem in the process of tracking.

Key works--- Gaussian mixture model ， Camshift
algorithm, Bayer color filter array，Kalman

1 Introduction
In the past few years, traffic video surveillance has
become a focus in computer vision. The correlative
traffic information obtained by detecting and tracking
the moving objects offer the data support to the
intelligent traffic management. It is the precondition of
tracking the moving objects to detect them in video
sequences. In order to detect moving objects in a
dynamic scene, a lot of adaptive background models
have been developed, of which the average time images
is the simplest one .This method could perform well at
the fixed background, however, it can not deal with the
dynamic scenes due to illumination and repeated
exercise of other small objects (such as branches of the
swing). Ridder ,etc [1] model for each pixel using
Kalman filter and track the changes of each pixel, this
method can deal with illumination in scene, however , it
978-0-7695-3789-4/09 $25.00 © 2009 IEEE
DOI 10.1109/CGIV.2009.30

317

3. Furthermore, the experimental results are presented
at Section 4. Finally, Section 5 gives the conclusion of
this paper.

2.2 Gaussian Mixture background Model
based on Bayer pattern
Stauffer etc proposed the Gaussian mixture
background model, which sets up k-Gaussian
distributions to hybrid simulate the background for
each pixel. That is, for the pixel X (i, j) of the color
video which based on the RGB Color Space
X ij ,t = [ Rij ,t Gij ,t Bij ,t ]T , its probability distribution of

2 Moving Objects Detecting
Stauffer, etc [1] proposed the method of
background modeling based on Gaussian mixture
distributing can eliminate the outside effects effectively,
especially can be used in the complicated surveillance
scene, nevertheless, this method is always applied to
dealing with gray video, and the computation in color
video is as three times as that of the single gray video.
Thus, the Mixture Gaussian modeling method based on
Bayer Color Filter Array (Bayer pattern) proposed in
this paper reduces the computation in color video.

time t is:
K

P( X ij ,t ) = ∑ ωij , k ,t ×η ( X ij ,t , μij ,k ,t , Σij ,k ,t ) (1)
k =1

Where, η is the Gaussian probability density
function. K is the number of Gaussian distributions, it
generally takes 3 to 5. ωij,k,t is the corresponding
weight of the Kth distribution. μij,k,t and Σij,k,t can be
written in the following form:

2.1 Bayer Color Filter Array
Bayer Color Filter Array is derived form the
imaging principle of digital imaging equipment. In
order to reduce the costs, most of the CMOS or CCD
sensors use Bayer Color Filter Array to turn the ray
signal to RGB, and each pixel collect the luminosity of
only one color. As is shown in Figure 1:
R

G

R

G

G

B

G

B

R

G

R

G

G

B

G

B

Where, G occupies half of the whole, and R and B
occupy only 1/4 respectively, which is just due to our
sensitivity of luminosity. The RGB of each pixel can be
obtained by the neighboring regions value of 2×2 array.
As is shown in Figure 2:
R
G1

G2

B

average

G’

R

G’

(2)

Σij ,k ,t = diag ((σRij ,k ,t )2 ,(σGij ,k ,t )2 ,(σBij ,k ,t )2 )

(3)

From the formula (1), (2) and (3), it can be easily
received that the computation of the background
modeling in the color video is as three times as that of
the single gray video. However, there is a certain
degree of spatial correlation between the adjacent
pixels of image frames in the color video. According
to the imaging principle of image sensor based on
Bayer pattern, the color video information acquired by
the imaging equipment is also making use of the
correlation of adjacent pixels. Therefore, we could also
take full advantage of the correlation of adjacent pixels
in the background Gaussian mixture modeling. That is
transforming each video frame, expressed by RGB
three-channel, into single-channel frame in accordance
with the Bayer pattern. On this basis, background
modeling could be taken according to Single-channel
information. Then during the extracting of prospect
picture, using color images of Bayer pattern synthesis
the relevance of principle. That is, as long as not near
the objects’ border, the adjacent pixels will have
similar color values. Therefore, we can replace a pixel
point with its color value. And the other color values
of the pixel can be obtained approximately from the
neighboring regions. For a frame of image received
from the video, we convert it to Bayer array according
to Figure 1,Suppose the value of first line and column
is 1, then the characteristic vector of (i, j) in time t is:

Figure 1 Bayer Color Filter Array

R

μ ij , k , t = ( μ ij , k , t R , μ ij , k , t G , μ ij , k , t B )

R

B
Figure 2 The conversion from Bayer to RGB

318

X ij ,t

⎧ Rij ,t
⎪
= ⎨ Bij ,t
⎪
⎩Gij ,t

First, the background modeling can be set by
considering ω/σ as the priority of sub-models, which
are ordered by the value of ω/σ. This value increases
both as a distribution gains more evidence and as the
variance decreases. Then, the first B distributions are
chosen as the background model,

i , j is odd number
i , j is even

(4)

otherwise

b

B = a rg m in b ( ∑ ω ij , k , t > T )

So the formula (2).(3) can be expressed as follows:

μij ,k ,t

⎧ μij ,k ,t R
⎪⎪
= ⎨ μij ,k ,t Β
⎪
G
⎪⎩ μij ,k ,t

i, j is odd number
i, j is even

Where, T is a measure of the minimum portion of
the data that should be accounted for by the
background.
After modeling the background, for a new
image, the matching relationship between each pixel
Xij,t and the first B distributions obtained from the
formula(11) will be checked. If the pixel value of Xij,t
matches with one of the first B distributions, then the
pixel is a point of background, otherwise the pixel
belongs to the prospect, which is the moving object.
Because of the interaction between moving objects and
background, noise would inevitably occur in the
abstracted moving objects, while there will be plots in
the binary image of moving objects. Thus, we filter the
noise in the image by morphology process, such as
erosion and dilation, and finally, when the area of
some connective region is larger than a given
threshold, the region is thought to be possessed by the
objects.

(5)

otherwise

Σij ,k ,t = (σij ,k ,t )2

(6)

From the formula (5) and (6), it can be easily
received that after the conversion to the Bayer array, X,
μ and Σ have been fallen down from two-dimension to
one dimension. It greatly reduces the calculation of
Gaussian mixture model.

2.3 Background
Acquiring

Modeling

and

Objects

The new observations of Xij,t in a descending order
by priority is matched with its k(1 ≤ k ≤K )Gaussian
distributions, whose condition is |Xij,t—Uij,k,t| < 2.5

3 Moving Objects Tracking

σij,k,t.If all is not matched, or k is less than K, add a

The tracking of the moving objects uses the
effective characteristics of the target and uses the
appropriate algorithm to look for the position of the
most similar candidate template to the target template
in the image sequence. Because the Camshift
algorithm can track the moving objects with
speediness and robustness using the color
characteristics, this paper uses the Camshift algorithm
to track the moving objects.

new Gaussian distribution; or k is K, replace the
smallest priority with a new Gaussian distribution. The
new Gaussian distribution considers X as mean and
initializes a larger variance and a smaller weight.The
updating of Gaussian distribution weights is :
ωij,k,t = (1−α)ωij,k,t −1 +αMij,k,t , k =1,..., K (7)

Mij,k,t is 1 for the matched models and 0 for the
remaining ones. The μ and σ parameters for
unmatched distributions remain the same. The
parameters of the distribution which matches the new
observation are updated as follows:

μ ij , k , t = (1 − ρ ) μ ij , k , t − 1 + ρ X ij , t

(8)

σ2ij,k,t =(1−ρ)σ2ij,k,t−1 +ρ(Xij,t −μij,k,t )T (Xij,t −μij,k,t )

(9)

ρ = αη ( X ij ,t , μij ,k ,t , σ ij ,k ,t )

(11)

k =1

3.1 Camshift Algorithm
The Camshift algorithm bases on the color
distribution information to track moving objects.
Because the histogram of the object image is a record
of the probability, the changes of the object shape can
not affect this method and can solve the problems of
object deformation and partly occlusion efficiently
with more efficient computing. From the literature [811] we can see its advantages. Its core algorithm is the
Meanshift [10] algorithm. Meanshift algorithm is a
method of probability density estimation based on
non-parametric. It looks for the peak point in the
probability distribution and makes every point "drift"

(10)

Where, α is the learning rate , ρ is the learning
factor for adapting current distributions.

319

to the local maximum point of the density function
through the iterative process. Camshift algorithm is the
expansion of Meanshift algorithm. It can implement
tracking moving objects in the continuous video frames
through adaptively adjusting the size and position of
search window. It is faster and easier to calculate and
has good ability to resist the noise. The flow of the
algorithm is as follows:
(1) Select the size of the search window(s) in the
color probability distribution.
(2) Calculate the zero moments:

M 00 = ∑

∑ I ( x, y )

(12)

M01 = ∑

∑ yI (x, y)

(13)

M10 = ∑

∑ xI ( x, y)

(14)

x

x

x

3.2 Improved Camshift Algorithm
The initial search window of the traditional
Camshift algorithm needs to be selected manually. In
response to this question, this paper uses the detected
moving objects to initialize search window
automatically. Firstly, initialize the Gaussian mixture
model to get the background image, and then using the
background differential with the current frame to
detect the moving objects. After 100 frames, we track
the objects using Camshift algorithm. In this process,
maybe only a small part of the targets can be detected
in some frames because of just entering, it is
impossible to track with this part to initialize the
search window. In order to solve the problem, in this
paper we add a test line in the image. When the
moving target arrives at the test line, we use the
detected moving object as the search window and
track it.
If the problems of occlusion or large-scale similar
color interference appear when tracking, the Camshift
algorithm will fail. With this problem, this paper
improves the Camshift algorithm with the kalman
filter. The kalman filter can predict the positions of k
(k>2) frames as the center position of the search
window in Camshift algorithm. Then Camshift will
find the optimal position in the field which can be used
as the observation value to modify the prediction value
of k frames. With the modified value, the possible
position of the next frame can be predicted. This will
speed up the convergence rate of the Camshift
algorithm. Furthermore, it can track when the
occlusion happens to the moving objects, so the
tracking robustness is enhanced.
In this paper, we set up a few Camshift trackers to
solve the problem that the original algorithm can not
track multiple objects simultaneously. In the stage of
moving objects detection, we could detect many
moving objects, so we define a chain of each target
tag. When tracking, each object is assigned a tracker,
which is responsible for its own object. If the search
window of the object is over the image border, the
tracking object disappears. In that case, we should
delete it from the target chain and the tracker no longer
works. About the new unmarked moving objects, add
it to the target chain, and increase Camshift tracker,
thus we achieve the tracking of multiple moving
objects.
The moving objects can be got from the
background subtraction using a frame of video image
and the background image which is generated from the
Gaussian mixture model based on bayer pattern, and
then use the mathematical morphology operation to
remove the noises. With the moving field, the search
window of Camshift algorithm can be initialized. Then

y

y

y

Where, I(x, y) is the image element value of
coordinates (x, y), and x and y change in the scope of
the search window.
(3) Calculate the center of mass for the search
window (Xc, Yc):

xc =

M
M

10
00

,

yc =

M 01
M 00

(15)

(4)The size of the search window that is the
function of a color probability distribution of the former
search window can be re-installed as s.
(5)Repeat steps (2), (3), (4) until they are
constringent (the change of the center of mass is less
than the threshold value).
When the video sequence changes frame by frame,
the Camshift algorithm manages frame by frame so that
the continuous follow-up tracking about the goal can be
achieved. But these problems will appear:
z Camshift algorithm is the semiautomatic
tracking algorithm. The location and size of the
moving objects need to be selected manually.
z Only single moving objects can be tracked.
z The tracking fails when occlusion problem or
color disturbing of big size appears.
In response to the questions, this paper presents an
improved Camshift tracking algorithm. It can
automatically initialize the search window and track
multiple objects at the same time. Additionally, it can
effectively overcome the occlusion problem in the
period of tracking. The details are shown in Chapter
3.2.

320

transform the image from RGB mode into HSV mode,
and set up the color probability distribution backprojection which is the base of the latter tracking
through the color histogram of the H-component. Use
the Camshift algorithm to track and set the center
position of the search window as the measured value of
the kalman filter to modify the position of the target.
The predicted value of the kalman filter can be used to
set as the center position of the search window in next
frame. With this cycling, the tracking of the moving
target can be achieved. The flow chart of the whole
tracking is as follows:

Figure 4 The Results of detected objects in Bayer
array modeling

(a)

(b)

(c)

Figure 5 The Results of detect objects in RGB
space modeling
Where, (a) is the binary image, (b) is the
processed binary image , (c) is arresting image based
on Bayer and RGB respectively. When the value of k is
3, the average processing time for each frame is 47ms
(about 21 frames/s) of Gaussian mixture background
modeling in Bayer array and the average processing
time for each frame is 78ms (about 12 frames/s) of
Gaussian Mixture background modeling in RGB space.
So the average processing time in Bayer array is on a
reduction of 40% than that in RGB space and the realtime detection can be achieved. From the comparison,
It can be seen that, the Gaussian mixture background
modeling in Bayer array can detect the moving objects
accurately and the effect is similar as that in RGB
space.
In order to verify the effectiveness of the
improved Camshift algorithm, the moving objects are
tracked in video sequence 2 of the similar color. Each
frame’s resolution is 320x240 and there are 85 frames
totally. The search window is initialized by the
detected moving objects automatically. The result is
shown in Figure 6:

Figure 3 Flow diagram of detecting and tracing

4 Experimental results
In order to verify the reliability of the background
modeling method using Gaussian mixture model based
on Bayer pattern, we detect the objects in Bayer array
modeling and RGB space modeling respectively in the
environment of P4/2.99GHz, 1G memory, VC + +6.0
with Intel OpenCV library. Each frame is the image of
320x240 with the total of 91 frames. Below is the result
of one frame shown in Figure 4 and Figure 5:

(a) 51st frame

(c) 67th frame

(b) 59th frame

(d) 75th frame

Figure 6 The Results of Moving Objects Tracking
under Occlusion
(a)

(b)

(c)
321

References:

There are two vehicles with similar color in the
51st frame, Figure 6(a) and there is the occlusion in the
59th frame, Figure 6(b) and there is the tracking result
after the separation in the 75th frame, Figure 6(c).
Because of the Kalman filter, this algorithm still can
track the target when facing with the occlusion. In
addition, it can reduce the iteration number of
Meanshift algorithm in each frame. The comparison
about the iteration number between the traditional
Camshift algorithm and improved Camshift algorithm is
as follows:

[1] Ridder C ， Munkeh O ， Kirchner H ． Adaptive
background estimation and foreground detection using
kalman filtering[C] Proc International Conference on
recentAdvances in Mechatronics,1995:193-199．
[2] Stauffer C, Grimson W.E.L. Adaptive Background
Mixture Models for Real-Time Tracking. Proceeding of
IEEE Conference on Computer Vision and Pattern
Recognition[C]. 1999: 246-252
[3] D.Comaniciu, V.Ramesh, and P.Meer, Kernel based
Object Tracking[J]. IEEE Trans, On Pattern Analysis
and Machine Intelligence, 2003, 25(5):564-575.
[4] C. Hue, J.P. Le Cadre, and P. Perez, “Tracking multiple
objects with particle Filtering,” IEEE Trans. On
Aerospace and Electronic Systems, Vol.38(3), pp.791812, 2002.
[5] Xuefeng Song, Ram Nevatia. A Model-based Vehicle
Segmentation Method for Tracking[J]. Proceedings of
tenth IEEE International Conference on Computer
Vision, 2005, 2:1124-1131.
[6] BRADSKI G. Computer vision face tracking for use in a
perceptual user interface. Intel Technology Journal,
1998.
[7] G. Bailo, M. Bariani, P. Ija, et al. Background Estimation
with Gaussian Distribution for Image Segmentation, a
fast approach. Proceedings of the 2005 IEEE
International Workshop on Measurement Systems for
Homeland Security, Contraband Detection and Personal
Safety Workshop[C]. 2005: 2-5
[8] LIU X, CHU H X, LI P J. Research of the Improved
Camshift
Tracking
Algorithm[C]//
International
Conference on Mechatronics and Automation. China,
2007: 968-972.
[9] DAI G J,ZHANG Y. A Novel Auto-Camshift Algorithm
Used in Object Tracking[C] // Proceedings of the 27th
Chinese Control Conference .China,2008:369-373
[10] CHU H X, YE S J. Object Tracking Algorithm Based
on Camshift Algorithm Combinating with Difference in
Frame[C]// Proceeding of the IEEE International
Conference on Automation and Logistics. China, 2007:
51-55.
[11] NOUAR O D, ALI G. Improved Object Tracking with
Camshift
Algorithm[C]//
IEEE
International
Conference on Acoustics, Speech and Signal
Processing. France, 2006:657-660.
[12] COMANICIU D,RAMESH V. Mean shift and optimal
prediction for efficient object tracking: IEEE int. Conf.
Image Processing[C]// Canada, 2000(3): 70-73.
[13] Lu Jun, Li Feng, Li Qinghua. A Detecting and Tracking
Method for Moving Objects under Occlusion. GESTS
International Transactions on Communication and
Signal Processing. 2007.7

Figure 7 Operation Speed Corrparative
Figure 7 shows the iteration number of Meanshift
algorithm in the process of tracking. It can be seen that,
from the figure, the iteration number is less than that of
the traditional algorithm and the efficiency is improved.

5 Conclusions
This paper presents a real-time moving objects
detecting and tracking method based on color video.
With the Gaussian mixture model based on Bayer
pattern we can complete the modeling of the color
video image and obtain the background image from the
image sequence and detect the prospect images. With
the prospect images, we present the multi-moving
objects method based on Camshift and Kalman.
Through actual moving objects detection and tracking
as examples are taken, this algorithm has advantages of
quick speed and good accuracy. Meanwhile, it can
realize multi-moving objects tracking and overcome
occlusion problem in the process of tracking.

322

