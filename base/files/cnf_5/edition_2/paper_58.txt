2009 Sixth International Conference on Computer Graphics, Imaging and Visualization

A Statistical Image Retrieval Method using Color Invariant
Cheng Jin
Department of Computer Science and Engineering, Shanghai Jiaotong University, P.R. China
cheng.jin.jinhua@gmail.com
searches for similar images in the presence of occlusion and
noise. It is fast to compute, which allows real time indexing
in a large database, and is robust to the small changes in the
viewpoint. Several successful retrieval systems have been
developed using the color histogram [10-14], taking
advantages of its robustness to various object pose and
shape.
While color histogram is perhaps one of the most widely
used tool for image retrieval, it is unsuitable for the
applications to retrieve similar scenes under different
illumination circumstances. Moreover, the spatial
information is not preserved in the color histogram, so
images with diverse contents may have almost the same
histogram. For example, image containing many scattered
red pixels has a similar histogram with the image containing
a single large red region. Researches in this area have been
carried out to compensate the missed spatial information in
color histogram. Color coherence vector [15] has been
proposed to classify the pixels with the same color as either
coherent or incoherent, based on whether or not they are
parts of a similar color region. Color correlogram [16]
describes spatial information by counting the correlation
between different colors. Spatiogram [17] is a generalization
of the color histogram, and captures spatial information by
constructing the higher order moments. The hidden Markov
chain model [18-20] is also employed to characterize spatial
information between colors.
However, there is still one main obstacle left behind.
Since the users usually do not provide the indication of
which portion of the query image is of interest, a CBIR
system often denote the images by generalized descriptors.
To fit different kinds of images, this global descriptor tends
to have high dimensions and therefore intense computation is
required during image comparison. For instance, a vector
with the dimension of 166 is used to describe the image in
[18], and a typical color histogram usually has a 1000
dimensional structure or more to capture image information.
Some methods have been proposed for matching high
dimensional histograms [21], but further improvements are
still expected.
We propose an adaptive image retrieval method, which
merges the color invariant with the Markov chain feature.
There, the difference between the new descriptor and the

Abstract
Content based image retrieval is an essential task in
many image processing applications, among which, color
based methods have been receiving constant attentions in
past years, because color information is a discriminative
descriptor for image retrieval, especially in case of large
database. A limitation of previous color based methods is
their unsuitability for retrieving similar scenes under
varying lighting conditions as color is sensitive to
illuminations. Besides image descriptors of some existing
methods are with large dimensionality and thus
computational expensive. As betterment, an adaptive method
is proposed in this paper, which integrates the color
invariant with some spatial information of images. Different
from previous work, the number of states during the
quantization of the color space is not manually determined.
Instead, it depends on the context of the image itself, using an
adaptive clustering technique: Firstly, feature map
consisting of color invariants is established for images.
Secondly, the Markov chain model is employed to capture
the image both color and spatial information. Thirdly, an
image descriptor is computed for each image, not under the
frame of the entire fixed color space. To practice our
method, similar images are retrieved with a similarity
measure based on a two-stage weighted distance.
Experiments show that, this method has improved simplicity
and compactness without the lost of efficiency and
robustness.

1. Introduction
Content based image retrieval (CBIR) has gained
significant attention in recent years [1-7]. A classic CBIR
system takes a query image and retrieves images with
specific content properties from the database, and evaluating
method for CBIR is proposed in [8]. Since color information
plays an important role in image retrieval because of its
distinguishing property, color based methods for this
purpose is widely adapted. In recent years, color histogram
has become popular among these methods. Color histogram
[9] captures the global color property of the image and
978-0-7695-3789-4/09 $25.00 © 2009 IEEE
DOI 10.1109/CGIV.2009.89

355

If the sum of RGB values at one point is less than the
threshold, its color invariants of three channels are all set to
zero respectively. Theoretically speaking, there are only two
independent parameters from the normalized color. However,
these three normalized colors are all employed to construct
the feature map, taking account of the block color affect.

color histogram descriptor is that the representative colors
are computed from each image instead of being fixed in the
color space, thus allowing the feature representation to be
accurate as well as compact. Accordingly, this method has
improved the simplicity and compactness of image retrieval,
without losing its efficiency and robustness.
The rest of the manuscript is organized as follows:
Section 2 describes the process to establish the feature map
consisting of color invariants. Section 3 presents how to
construct the image descriptor with the feature map. In
section 4, two weight similarity measurements have been
defined to retrieve the similar images based on the Markov
chain model. Experiments results and conclusion are given
in section 5 and 6.

3. Image description based on Markov model
Once the feature map is available, a proper descriptor for
image will be need. In general, typical CBIR system includes
two main steps: image description and similarity
measurement. For statistical methods, image usually has
been quantized into a set of states according to the color and
texture information and similarity measurement will be
carried out between these states. However, descriptors used
in many methods quantize images with fixed distance in the
whole color space, and a hard decision is made about the
number of states. Accordingly, these descriptors tend to have
very large size to deal with general images. The other
limitation of these methods is that, different states may
contain similar colors and distinct colors may appear in the
same states.
In this section, a new image descriptor has been
developed based on Markov chain model. Under the new
framework, the states are decided according to the image
contents, so the two aforementioned limitations may be
avoided. At the meanwhile, the spatial information of image
is preserved as well as the color information.
All the images used in this paper are considered to be
regular images with the size of 2M×2N, where M and N are
positive numbers. To reduce the computational cost, every
feature map has been segmented into blocks and these blocks
are grouped into states. Firstly, the feature maps of regular
images will be divided into 2K×2K blocks, where K is a
positive number. For a regular image with the size of
768×512, K is usually set to 5 or 6. Secondly, the mean
values of the normalized colors in these blocks are computed
to characterize these blocks. Then the Hierarchical
Agglomerative Clustering (HAC) theory is adapted to
classify these blocks into different states.
For many existing clustering algorithms, the number of
initial clusters should be predefined, such as K-means.
However, they are not suitable for general image retrieval,
because the actual number of clusters varies from image to
image, according to the image contents. In order to solve this
problem, the HAC is adopted in this paper. The HAC treats
every block as a potential cluster and then successively
agglomerate pairs of clusters, according to the similarity
level between clusters. The similarity level is measured as
following

2. Feature map consisting of color invariants
Color cue is important for computer vision applications,
since it provides informative features for high-level
reasoning, such as object recognition and image retrieval.
Several successful retrieval theories have been developed
over the past few years using color information. Among all
these methods, the robustness with respect to changing
illumination remains the biggest challenge. On the other
hand, even though color invariants are widely used to capture
image features it happens in practice that many kinds of
color invariants are meaningless in particular positions in the
color space. For example, according to [22], the normalized
color rgb, saturation S and c1c2c3 color invariants have no
physical meanings near the black point; the hue H and l1l2l3
color invariants are not stable along the achromatic axis
since the denominator equals zero there; the color invariants
proposed in [23] are also unstable in certain planes in color
space. In this paper, we take advantage of color invariants to
fulfill the image retrieval purpose by building up feature map.
The feature map has been introduced to capture image
features, which is constructed by the normalized color
integration with threshold.
The normalized colors are defined as follows:

R
R+G + B
G
g=
R+G+ B
B
b=
R+G + B
r=

(1)
(2)
(3)

According to [24], they are insensitive to viewpoint,
surface orientation, illumination direction, and illumination
intensity. In fact, the normalized colors are only dependent
on the sensor and the surface albedo.
It can be investigated that the normalized color are not
stable near the black point, where small perturbation of
image RGB values will cause large disruption in normalized
color values. To solve this problem, a threshold is predefined.

d = 1 − ∑ | c1 − c2 |
c

(4)

where c={r, g, b} and v=[r, g, b]T denotes the mean value of
the normalized color of the cluster. It is used to indicate how
356

Summarily speaking, images are represented by their
parameter sets Θ=(V,W,C), where V is the set of state feature
value, W is the set of state feature weight and C is the state
transition matrix. According to the experiments, less than 10
states usually provide a powerful characterization for the
images.

different clusters are similar with each other. If the similarity
level between two clusters is less than 0.85, they should be
classified into different states in this paper.
After the HAC process, the feature map is divided into a
set of states according to the image content, which is called
the state image. The main chromatic and spatial information
concerning the image is retained in the state image. The
mean value of the normalized color in every state is
computed as the state feature value to represent the state,
which also keep the color information about image. Let S={si}
(i=1,2,…,L) is the set of states, the state feature value
V=[V1,V2,…,VL] is defined as

Vi =

∑ v ( P ( x, y ) = s )
i

4. Similarity measurement
The states of images are decided according to the image
contents, so the number of states and state feature values may
vary from image to image. To match images with different
number of states and different state feature values, the
correspondences between image states are required.
Given two images represented by their parameter sets Θ1
and Θ2, the similarity measurement is performed as follows:
Step 1: The correspondences between the states of the
two images are set up. The states of the two images are
matched by the state feature values.

(5)

N ( P( x, y ) = si )

The state feature weight W=[W1,W2,…,WL]T is defined
as

Wi =

N ( P ( x, y ) = si )
2K × 2K

(6)

E =|| VAi − VBj ||

Where v(P(x,y)=si) denotes the mean value of the normalized
color of the blocks in state si, and N(P(x,y)=si) denotes the
number of blocks in state si.
To capture the spatial information between these states,
the Markov state transition matrix is defined. Let P(x,y) be a
block in image, and Q(x,y) be its neighboring block by
8-connectivity, the state transition matrix C=(cij)L×L is
defined as

⎧ N ( P ( x, y ) = si , Q( x, y ) = s j )
cij = ⎨
⎩ N ( P ( x, y ) = si , Q( x, y ) = s j ) / 2

(i ≠ j )
(i = j )

(8)

where VA and VB are the state feature values of the two
images. If E is less than 0.05, the i-th state of image A and
the j-th state of image B are considered to be matched.
Step 2: The cooccurrence matrices of the two images are
constructed. The cooccurrence matrix can be viewed as the
sub-division of state transition matrix, consisting of rows and
columns where the matched states lie. Given image A,
having m corresponding states with image B, the
cooccurrence matrix T=(tij)m×m is defined as follows

(7)

tij =

cij
m

∑c

(9)

ik

k =1

where C=(cij)L×L is the state transition matrix. The
cooccurrence matrix element tij denotes the probability that
the j-th state appears around the i-th state. Notice that the
cooccurrence matrix only focuses on spatial relation between
corresponding states, which is different from almost all other
CBIR methods.
Step 3: The stationary distribution Π about the
cooccurrence matrices of the two images are computed
according to [18].

1 m
(10)
∑ ai
m i =1
1
T
( I + T + T 2 + ... + T n ) .
where A = [ a1 ,..., am ] =
n +1
Π=

Figure 1: Color images and their state images
From a statistical view, the large element cij implies a
high possibility that the blocks in state si are connected with
the blocks in state sj. Notice that the state transition matrix
used in this paper only focuses on the blocks in
8-connectivity. Based on this enactment, the computational
cost can be efficiently reduced, compared with the color
correlogram [16].

Step 4: To compare images, the similarity measurement
has been defined, which contains two stage weighted
distances. Supposing there are two images A and B with m
corresponding states, they are compared with the parameter
sets θA and θB, where θ=(W, Π), W is a vector denoting state
feature weight of the corresponding states and Π is the
357

and they are divided into 26×26 blocks. Images best
satisfying the queries are retrieved. In the first example, the
last image is not similar with the query image, but it is seen
that the distance between the similar images and dissimilar
images are distinguishable enough.
The retrieval performance of the proposed method is
compared with the traditional color histogram descriptor. A
1000 dimensional color histogram vector is extracted from
images and five different kinds of images have been used for
test. The experimental results in table 1 exhibit that, our
method is comparable to the color histograms, but with the
smaller descriptor and lower computational load.

stationary distribution of the corresponding states. The
distance D is defined as

D=

D1 (WA , WB )
+ D3 (ΠA , ΠB )
D2 (WA , WB )

(WAi − WBi ) 2
WAi + WBi

(12)

D2 (WA , WB ) = ∑ min(WAi , WBi )

(13)

m

where

(11)

D1 (WA ,WB ) = ∑
i =1

m

i =1

(ΠAi − ΠBi )2
ΠAi + ΠBi
i =1
W=[W1,W2,…,Wm]T and Π=[Π1,Π2,…, Πm]T.
m

D3 (ΠA , ΠB ) = ∑

(14)

6. Conclusion
In this paper, a statistical image retrieval method is
proposed. Different from most existing CBIR methods, the
new image descriptor are with adaptive structures since
representative colors are computed from each image instead
of being fixed in the color space and accordingly, the image
descriptor usually has very small structure. To characterize
the images, the Markov chain model has been employed on
color invariants to capture both the color information and the
spatial information from images. In similarity measurement
process, a new two-stage weighted distance is defined, which
also can be used for partial image retrieval. Experiments
demonstrate that, the proposed method is comparable to the
color histograms, robust to the changing illumination
circumstances, and with the smaller descriptor and lower
computational load.

In some circumstances, users are only interested in a
portion of an image, regardless of the rest. The localized
CBIR systems retrieve only a portion of an image with the
help of the corresponding points and regions [2, 25].
However, the detection of corresponding points and regions
is time consuming and sensitive to image noise. To deal with
this problem, neural network is employed and the definition
of distance D is improved as follows

D =α ×

D1 (WA , WB )
+ β × D3 (ΠA , ΠB )
D2 (WA , WB )

(WAi − WBi ) 2
WAi + WBi

(16)

(ΠAi − ΠBi ) 2
D3 (ΠA , ΠB ) = ∑ γ i
ΠAi + ΠBi
i =1

(17)

m

where

(15)

D1 (WA ,WB ) = ∑ γ i
i =1
m

References

From the perspective of neural network training and
simulation mechanism, a set of images labeled with
user-specified portions is firstly directly for training to
determine the parameters of α, β, γ, and then the trained
networks can be used to retrieve interesting portion of
images.

[1] J. Shashank, P. Kowshik, K. Srinathan, and C. V. Jawahar,
"Private Content Based Image Retrieval," presented at
Computer Vision and Pattern Recognition, 2008. CVPR 2008.
IEEE Conference on, 2008.
[2] R. Rahmani, S. A. Goldman, Z. Hui, S. R. Cholleti, and J. E.
Fritts, "Localized Content-Based Image Retrieval," Pattern
Analysis and Machine Intelligence, IEEE Transactions on,
vol. 30, pp. 1902-1912, 2008.
[3] C. Yixin, J. Z. Wang, and R. Krovetz, "CLUE: cluster-based
retrieval of images by unsupervised learning," Image
Processing, IEEE Transactions on, vol. 14, pp. 1187-1201,
2005.
[4] Z. Ruofei and Z. Zhongfei, "Hidden semantic concept
discovery in region based image retrieval," presented at
Computer Vision and Pattern Recognition, 2004. CVPR 2004.
Proceedings of the 2004 IEEE Computer Society Conference
on, 2004.
[5] K. ByoungChul and B. Hyeran, "Integrated region-based
image retrieval using region's spatial relationships," presented
at Pattern Recognition, 2002. Proceedings. 16th International
Conference on, 2002.
[6] E. Loupias, N. Sebe, S. Bres, and J. M. Jolion, "Wavelet-based
salient points for image retrieval," presented at Image
Processing, 2000. Proceedings. 2000 International Conference
on, 2000.

5. Experiments
The proposed method is tested on a database of 530
color images from the Ground Truth Database [26] of
Department of Computer Science and Engineering,
University of Washington. Firstly feature maps for test
images in the database are constructed, and then the image
descriptors are modeled, which consist of the set of the state
feature value, the set of the state feature weight, and the state
transition matrix. In comparison purpose, the
correspondence between the states of query image and the
states of test images are built, and the cooccurrence matrices
are constructed and the stationary distributions are used for
comparison.
Two examples are displayed in Figure 2. All images in
these examples are regular images with resolution 768×512
358

[7] Y. Rui, T. S. Huang, and S. Mehrotra, "Content-based image
retrieval with relevance feedback in MARS," presented at
Image Processing, 1997. Proceedings., International
Conference on, 1997.
[8] N. V. Shirahatti and K. Barnard, "Evaluating image retrieval,"
presented at Computer Vision and Pattern Recognition, 2005.
CVPR 2005. IEEE Computer Society Conference on, 2005.
[9] M. J. Swain and D. H. Ballard, "Color Indexing," International
Journal of Computer Vision, vol. 7, pp. 11-32, 1991.
[10] S. Young-jun, P. Won-bae, K. Dong-woo, and A. Jae-hyeong,
"Content-based image retrieval using new color histogram,"
presented at Intelligent Signal Processing and Communication
Systems, 2004. ISPACS 2004. Proceedings of 2004
International Symposium on, 2004.
[11] H. Ju and M. Kai-Kuang, "Fuzzy color histogram and its use in
color image retrieval," Image Processing, IEEE Transactions
on, vol. 11, pp. 944-952, 2002.
[12] A. M. Ferman, A. M. Tekalp, and R. Mehrotra, "Robust color
histogram descriptors for video segment retrieval and
identification," Image Processing, IEEE Transactions on, vol.
11, pp. 497-508, 2002.
[13] J. Berens, G. D. Finlayson, and G. Qiu, "Image indexing using
compressed colour histograms," Vision, Image and Signal
Processing, IEE Proceedings -, vol. 147, pp. 349-355, 2000.
[14] R. Aibing, R. K. Srihari, and Z. Zhongfei, "Spatial color
histograms for content-based image retrieval," presented at
Tools with Artificial Intelligence, 1999. Proceedings. 11th
IEEE International Conference on, 1999.
[15] G. Pass, R. Zabih, and J. Miller, "Comparing images using
color coherence vectors," presented at ACM Multimedia 96,
Boston MA USA, 1996.
[16] H. Jing, S. R. Kumar, M. Mitra, Z. Wei-Jing, and R. Zabih,
"Image indexing using color correlograms," presented at
Computer Vision and Pattern Recognition, 1997.

[17]

[18]

[19]
[20]
[21]
[22]

[23]

[24]
[25]
[26]

Proceedings., 1997 IEEE Computer Society Conference on,
1997.
S. T. Birchfield and R. Sriram, "Spatiograms versus
histograms for region-based tracking," presented at Computer
Vision and Pattern Recognition, 2005. CVPR 2005. IEEE
Computer Society Conference on, 2005.
L. Jianguo, W. Weixin, W. Tao, and Z. Yimin, "One step
beyond histograms: Image representation using Markov
stationary features," presented at Computer Vision and Pattern
Recognition, 2008. CVPR 2008. IEEE Conference on, 2008.
L. Hsin-Chih, W. Ling-Ling, and Y. Shi-Nine, "Color image
retrieval based on hidden Markov models," Image Processing,
IEEE Transactions on, vol. 6, pp. 332-339, 1997.
L. Jia, A. Najmi, and R. M. Gray, "Image classification by a
two-dimensional hidden Markov model," Signal Processing,
IEEE Transactions on, vol. 48, pp. 517-533, 2000.
F.-D. Jou, K.-C. Fan, and Y.-L. Chang, "Efficient matching of
large-size histograms," Pattern Recognition Letters, vol. 25,
pp. 277-286, 2004.
T. Gevers and H. Stokman, "Robust histogram construction
from color invariants for object recognition," Pattern Analysis
and Machine Intelligence, IEEE Transactions on, vol. 26, pp.
113-118, 2004.
J. M. Geusebroek, R. van den Boomgaard, A. W. M.
Smeulders, and H. Geerts, "Color invariance," Pattern
Analysis and Machine Intelligence, IEEE Transactions on,
vol. 23, pp. 1338-1350, 2001.
T. Gevers and A. W. M. Smeulders, "Color-based object
recognition," Pattern Recognition, vol. 32, pp. 453-464, 1999.
J. Sivic, F. Schaffalitzky, and A. Zisserman, "Object Level
Grouping for Video Shots," International Journal of Computer
Vision, vol. 67, pp. 189-210, 2006.
L. Yi and L. G. Shapiro, "Consistent line clusters for building
recognition in CBIR," presented at Pattern Recognition, 2002.
Proceedings. 16th International Conference on, 2002.

Query

D=0.0226

D=0.0594

D=0.0809

D=0.0956

D=0.1014

D=0.1556

D=1.4809

359

Query

D=0.1005
D=0.1315
Figure 2.Some images of two query examples for retrieval in experiments

D=0.2073

I
II
III
IV
V
Color Histogram
71.43%
72.73%
83.34%
62.50%
76.92%
Our Method
85.72%
90.91%
83.34%
87.50%
84.61%
Table 1. The retrieval performance of the traditional color histogram descriptor and the proposed method. A 1000 dimensional
color histogram vector is extracted from images and 5 different kinds of images areb used for test.

360

