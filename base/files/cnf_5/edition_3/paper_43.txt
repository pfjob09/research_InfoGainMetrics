Fifth International Conference on Computer Graphics, Imaging and Visualization
Visualisation

LSP Trajectory Analysis for Speech Recognition
J. Onshaunjit, J. Srinonchat
Signal Processing Research Laboratory
Department of Electronics and Telecommunication Engineering
Faculty of Engineering
Rajamangala University of Technology Thanyaburi
Patumthani, Thailand, 12110
jakraj@hotmail.com, jakkree.s@en.rmutt.ac.th
Abstract

2. Speech feature

Speech signal is the continuous signal which has the
characteristics in its own. For recognizing the speech
signal, the system must be able to classify and recognize
the speech feature. Almost of this system is speakerindependent speech system. This paper presents
statistical methods for speech recognition by extracting
the features of the speech and analyzing their trajectory.
The speech feature has been extracted to Line Spectral
Pairs (LSP) coefficients and then uses the statistic model
to pattern the trajectory for recognizing the signal. The
result shows that the using technique usually works well
which the maximum accuracy of recognition is 99.67%
at number 1 of male speech and the minimum accuracy
of recognition is 82.33% at number 5 of female speech.

2.1. Line Spectral Pairs (LSP)
The Line Spectral Pairs (LSP) or Line Spectral
Frequencies (LSF) decomposition was first introduced
by Itakura in 1975 [2]. It is mainly used as a convenient
representation of Linear Prediction Coding (LPC). There
are also some other representations of LP parameters,
such as Reflection Coefficients (RC), Autocorrelations
(AC), Log Area Ratios (LAR), Arcsine of Reflection
Coefficients (ASRC), Impulse Response of LP synthesis
filter (IR). The Line Spectral Pairs (LSP) decomposition
has advantageous properties over others [3]. In this
technique, the minimum phase predictor polynomial
computed by the autocorrelation method of linear
prediction is split into a symmetric and an antisymmetric
polynomial. It has been proved that the roots of these
two polynomials, the LSP are located interlaced on the
unit circle, if the original LP predictor is minimum
phase. Furthermore, it has been show that LSP behave
well when interpolated. Due to these properties, the LSP
decomposition has become the major technique in
quantization of LP information and it is used in various
speech coding.
The Line Spectral Pairs are a representation of Linear
Prediction Coefficients that are commonly used for
coding. Consider the conventional LP polynomial with
order p,

Keywords --- Speech Recognition, Trajectory,
Line Spectral Pairs, Linear Predictive.

1. Introduction
Speech processing can be classified into three major
categories: speech coding, speech synthesis and speech
recognition [1]. A number of speech recognition systems
and applications can benefit from general function
enhancement capabilities, such as a monitoring function
of user utterance, car navigation system and cellular
phone system. Almost of this system is speakerindependent speech system. In speaker-independent
speech recognition system, training inter speaker
variability requires a broad population of speakers.
This paper presents statistical methods for speech
recognition by extracting the features of the speech and
analyzing their behavior. The analysis of speech
recognition based on feature speech trajectory. The Line
Spectral Pairs (LSP) coefficients are used to extract the
speech feature, and then the feature speech trajectory
pattern is investigated for each word.

978-0-7695-3359-9/08 $25.00 © 2008 IEEE
DOI 10.1109/CGIV.2008.59

p

Ap ( z ) = ∑ ai z −i

(1)

i=1

Where a0 =1 . Define two LSP polynomials Pp+1 ( z )
and Q p+1 ( z ) of order p + 1 as Figure 1.
From Fig. 1 white circles depict the zeroes of the
original LP polynomial A(z), squares and filled circles
are the zeroes of LSP polynomials P(z) and Q(z)
respectively.

276

Q ( z ) = A( z) − z − ( k +1) A( z −1 )

(6)

And related with A(z) by (7),

A( z ) =

P ( z ) + Q( z )
2

(7)

The roots of the polynomials P(z) and Q(z) are called
the LSPs. The polynomials P(z) and Q(z) have the
following two properties:
1) All zeros of P(z) and Q(z) lie on the unit circle.
2) Zeros of P(z) and Q(z) are interlaced with each
other; i.e., the LSP are in ascending order.

It can be shown that A(z) is minimum-phase
if its LSP satisfy these two properties. Thus,
the stability of LP synthesis filter (which is an
important pre-requirement for speech coding
applications) can be easily ensured by
quantizing the LP coefficients in LSP domain.

Figure 1 Demonstration of the unit circle property and the
intra-model interlacing property of LSP

The arrows show how the zeroes are transformed in
LSP decomposition [4].
p

A( z ) = 1 + ∑ ak z −k

(2)

2.2. Trajectory Speech

k =1

The filter A(z) is known as the “whitening” filter as it
removes the short-term correlation present in the speech
signal and, therefore, flattens the spectrum. Since E(z)
has an approximately flat spectrum, the short-time
power-spectral envelope of the speech signal is modeled
in LP analysis by an all-pole (or autoregressive) model,

H ( z) =

1
A( z )

The trajectory models for speech recognition is that
sequences of speech features are statistically dependent
and that the effective and efficient modeling of the
speech process will incorporate this dependency. The
class of trajectories that we have thus far considered has
been low degree polynomials, though our formulation
does permit other classes of trajectory models [7].
The trajectory model each feature dimension of a
speech segment is Estimation of the model means
estimation. First write the trajectory equation for each
feature as,
c( n ) = u( n ) β ( n ) + e( n ) ; n =1,..., D
(8)

(3)

The filter A(z) is also known as the “inverse” filters as
it is the inverse of the all-pole model H(z) of the speech
signal.
In LP analysis, the short-time power-spectral envelope
of speech is obtained by evaluating H(z) on the unit
circle. However, for this, the LP coefficients have to be
computed first from the speech signal. These are usually
determined by minimizing the total-squared LP error,

Where c(n) are the observed cepstral features in a
segment of length D, u(n) is the mean feature vector as a
function of frame number and represents the dynamics of
the features in the segment, and e(n) is the residual error
term which we assume to have a Gaussian distribution
and β ( n ) is a matrix of regression coefficients.

n2

E = ∑ en2

(4)

n= n1

Expanding out (8) for a quadratic trajectory model and
segment with N frames as,

Where the summation range [n1,n2] depends on which
of the two methods (the autocorrelation method and the
covariance method.) is used for LP analysis [5].
Unfortunately, LP coefficients are not themselves
suitable for speech processing as they are highly
sensitive to error. Small changes in the predictor
coefficients can lead to large changes in the spectral
properties of the synthesis filter, at worst leading to
instability. The LP coefficients must be transformed into
an equivalent coefficient set with more suitable
properties.
Line Spectral Pairs representation is an equivalent
coefficient set found to have excellent quantization and
interpolation properties for use in low bit rate coding of
speech [6].
To define the LSP, the inverse filter polynomial is
used to construct two polynomials,

P( z) = A( z ) + z − ( k +1) A( z −1 )

1
⎡c1,n ⎤ ⎡
⎢ ⎥ ⎢
⎢ c2 , n ⎥ = ⎢ 1
⎢⇓ ⎥ ⎢
⎢ ⎥ ⎢⇓
⎢
⎣⎢c3,n ⎦⎥ ⎣⎢ 1

0
1
N −1
⇓
1

0
⎤ ⎡ β ⎤ ⎡e ⎤
1, n
1,n
⎥ ⎢ ⎥
1 2 ⎥⎢
(
) ⎥ ⎢ β 2 , n ⎥ ⎢ e2 , n ⎥
N − 1 ⎥⎢
⎥+⎢ ⎥
⎥⎢ ⇓ ⎥ ⎢ ⇓ ⎥
⇓
⎥ ⎢ β ⎥ ⎢e ⎥
3, n ⎦ ⎣ 3, n ⎦
1
⎦⎥ ⎣

(9)

for n = 1,…,D
This work focused on the trajectory features of the
speech signal. The trajectory of speech has been
considered in the format LSP coefficients as explained in
previous section. The characteristics of the same word
should be similar to each other. In the other hand, the
different word should not be similar. By the reason, the
distance of the each trajectory can be applied to classify
and recognize the speech signal.

(5)

277

accuracy, the trajectory of one numeric was simulated to
all number. For example, the trajectory of number 0
were calculated the distance from average of number 0 to
number 9 as shown in Fig. 3 - 6

3. Experiments and Results

Distance from average (%)

Speech signal was collected from 200 speakers (100
males and 100 females), then were recorded in a
laboratory environment with a PC computer using
program “GoldWave v5.20” as PCM mono. The
numeric zero to nine had been selected to be signal input
which each speaker must speak three times. So there
were 300 utterances which separated male and female.
Firstly, all speech signals were adjusted to avoid the
noise and increase the maximum amplitude by (10), and
the End-point Detection technique was used to cut off the
new word and unwanted signal.
⎡1 − max( X )⎤
(10)
X ( new) = X (old ) + X (old ) × ⎢
⎥
⎣ max( X ) ⎦
Since X(old) is original data, and max(|X|) is the
maximum absolute amplitude.
Each speech signals were separated to 20 frames, and
then each frame calculated the LSP coefficients in order
10. Thus speech signal contained of male and female in
the format of LSP coefficients.
The percentage of distance had been used to searching
the signal which far from average value in each speech
signals by (11).
Average − Data
× 100%
Average

Figure 3 Compare feature trajectory of number 0 – 4 with all
number for male speech signal

Distance from average (%)

% Distance =

Number

(11)

Where Average is the average for all speech signal of
each coefficient, and Data is coefficients of each speech
signal.
This experiment focused on the 10%, 15%, 20% and
25% of the error distance to select the appropriate error
for consider the feature speech trajectory pattern.

Number

Figure 4 Compare feature trajectory of number 5 – 9 with all

Distance from average (%)

number for male speech signal

Figure 2 Comparison of distance from average
Number

Fig. 2 shows that LSP coefficients mapping with the
maximum range of 25% far away from the average
value. It can be seen that in the region of 20% can be
contained the most values of LSP coefficients more than
90%. Thus the 20 % distance measurement in LSP was
selected to be the major considering.
The experiment then exploited this technique to
recognize the speech signal by create statistic model
using the feature speech trajectory. To measurement the

Figure 5 Compare feature trajectory of number 0 – 4 with all
number for female speech signal

Fig. 3 - 6 show the feature trajectory of one number
compare with the other number. It can be seen that the
lowest percentage of distance is the comparison with the
same number.

278

Acknowledgements
Distance from average (%)

Thank you to Mr. Suwan Ruensukhon for data
collecting and all people in Signal Processing Research
Laboratory, Rajamangala University of Technology
Thanyaburi for the motivation in this research.
This work was supported in part by the National
Research Council of Thailand - Speech Control Dialed
Telephone for Disable People Project.

References
Number

[1]

Figure 6 Compare feature trajectory of number 5 – 9 with all

[2]

number for female speech signal
[3]

Last of all, for testing the accuracy of this research by
using 300 speech signals. The final result is shown in
Table 1.

[4]

Table 1 Accuracy of Recognition from Testing 300 Speech
Signals

[5]

Number

Male

Female

0

98.67 %

99.33 %

1

99.67 %

97.00 %

2

91.67 %

99.33 %

3

92.33 %

89.67 %

4

97.67 %

97.33 %

5

90.00 %

82.33 %

6

97.00 %

98.33 %

7

98.33 %

98.67 %

8

94.67 %

90.00 %

9

93.00 %

90.67 %

[6]

[7]

[8]
[9]

[10]

[11]

[12]

Conclusions

[13]

The work presents the statistic model of feature
speech trajectory to recognize the speech signal. This
can be seen that the 20 percents distance measurements
in LSP features are selected to be the major considering
of data recognition pattern.
This technique also
excellently recognizes the speech signal which shows in
Fig. 3 - 6. The maximum accuracy of recognition is
99.67 percents at number 1 of male speech and the
minimum accuracy of recognition is 82.33 percents at
number 5 of female speech as shown in Table 1. The
average accuracy of recognition is around 95 percents.

[14]

[15]

[16]

[17]

279

F.J. Owens, “Signal Processing of Speech”, The Macmillan Press
LTD, Hampshire, 1993.
F. Itakura, “Line spectrum representation of linear predictive
coefficients of speech signals”, Journal of Acoustic Society of
America, vol.57, pp. 535, April 1975.
F.K. Soong and B-H. Juang, “Linear spectrum Pair (LSP) and
speech data compression”, in Proc. IEEE Acoustics, Speech, and
Signal Proc. ICASSP’84, San diego,CA, March 1984, vol. 1, pp.
1.10.1-1.10.4.
Yuan, Z., Bäckström, T., and Alku, P., "All-pole Modelling of
Noisy Speech with the Weighted Sum of the Line Spectrum Pair,"
in the 5th Nordic Signal Processing Symposium (NORSIG-2002),
Hurtigruten, Norway, October 4-7, 2002.
K.K. Paliwal and W.B. Kleijn, “Quantization of LPC
Parameters”, Speech Coding and Synthesis, W. B. Kleijn and K.
K. Paliwal, Eds. Amsterdam, the Netherlands: Elsevier, pp. 443–
466, 1995.
G. C. Cawley, M. I. Heywood, and P. D. Noakes, “Weight zero
enhancement in speech synthesis using neural networks”, In
Proceedings the International Conference on Artificial Neural
Networks (ICANN-93), pp. 272, Amsterdam, September 1993.
Han, Y., de Veth, J., and Boves, L., “Trajectory Clustering for
Automatic Speech Recognition,” in Proc. EUSIPCO-2005,
Antalya, Turkey, 2005.
L.R. Rabiner and R.W. Schafer, “Digital Processing of Speech
Signal”, Prentice-Hall, 1978.
W. Goldenthal, “Statistical Trajectory Models for Phonetic
Recognition”, Ph.D Thesis Massachusetts Institute of Technology,
1994.
Nikil Jayant, “Signal Compression: Technology Targets and
Research Directions”, IEEE Journal on Selected Areas in
Communications, vol.10 No.5, pp. 796-818, June 1992.
Hasegawa-Johnson, M., "Line spectral frequencies are poles and
zeros ofthe glottal driving-pointimpedanceofa discretematchedimpedance vocal tract model," Journal of Acoustic Society of
America, pp. 457-460, 2000.
S. Limpanakorn, C. Tanprasert, “Voice articulator for Thai
speaker recognition system”, ICONIP'02 Proceedings of the 9th
International Conference, vol.5, pp. 2396-2400, Nov. 2002.
J. Srinonchat, S. Danaher, J. I. H. Allen and A. Murray, "New Bit
Rate CELP coder for Speaker Dependent Coding System",
IASTED International Conference on Artificial Intelligence and
Applications, pp. 432-435, 2004.
Li J., Yu Y. and Rui X., “A New Algorithm for Calculating LSP
Parameters of Speech Signal”, The 8th International Conference
on signal Processing, Volume 1, pp. 16-20, 2006.
J. Srinonchat, “New Technique to Reduce Bit Rate of LPC-10
Speech Coder”, TENCON 2006, 2006 IEEE Region 10
Conference, pp. 1-4, November 2006.
Bäckström T. and Magi C., "Properties of Line Spectrum Pair
Polynomials - A Review", Signal Processing, vol. 86, no. 11, pp.
3286-3298, November 2006.
S. Ruensukhon and J. Srinonchat, "An Efficient of LPC and LSP
Trajectory in Thai Speech Recognition", JCSSE2008 Conference
vol. 2, pp. 297-302, May 2008.

