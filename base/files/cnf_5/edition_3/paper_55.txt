Fifth International Conference on Computer Graphics, Imaging and Visualization
Visualisation

Automatic Signature Recognition And Verification Using Principal
Components Analysis
I . A. Ismail
Professor, Faculty of Computers and informatics ,
Zagazig University, Egypt

M . A. Ramadan
Professor, Department of Mathematics, Faculty of Science

Menofia University , Egypt

T. El danf

A. H. Samak

lecturer, Department of Mathematics, Faculty of Science

lecturer, Department of Computer science, College of Science
in Al-Kharj
king Saud University , Saudi Arabia
Email : Samak @ksu.edu.sa

Menofia University , Egypt

Abstract
The fact that the signature is widely used as a
means of personal verification emphasizes the need for
an automatic recognition system. Recognition can be
performed either Offline or Online based on the
application. Online systems use dynamic information of
a signature captured at the time the signature is made.
Offline systems work on the scanned image of a
signature. In this paper we present a method for Offline
recognition and verification signatures using Principal
components analysis. The proposed method consists of
image prepossessing , feature extraction , evaluate the
Principal components analysis for the extracted feature
and the identification step. The identification step
contain tow process recognition and verification. In the
recognition process we use the K nearest-neighbours
classifier and in the verification process we use the
neural network classifier.
Key words Pattern recognition , signature,
classifier , personal verification

be divided into on-line (or dynamic) and off-line (or
static) recognition. On-line recognition refers to a
process that the signer uses a special pen called a stylus
to create his or her signature, producing the pen
locations, speeds and pressures, while off-line
recognition just deals with signature images acquired
by a scanner or a digital camera. In general, off-line
signature recognition is a challenging problem. Unlike
the on-line signature, where dynamic aspects of the
signing action are captured directly as the handwriting
trajectory, the dynamic information contained in offline signature is highly degraded. Handwriting features,
such as the handwriting order, writing-speed variation,
and skillfulness, need to be recovered from the greylevel pixels. In this paper we present a new method
based on the Principal components analysis (PCA) .
The flow diagram for proposed method is shown in
figure 1 .
2.Database

1. Introduction
The signature database consists of 840 signature
images, scanned at a resolution of 300 dpi,8-bit grayscale. They are organized into 18 sets, and each set
corresponds to one signature enrollment. There are 24
genuine and 24 forgery signatures in a set. Each
volunteer was asked to sign his or her own signatures
on a white paper 24 times. After this process had been
done, we invited

Handwritten signature is one of the most widely
accepted personal attributes for identity verification. As
a symbol of consent and authorization, especially in the
prevalence of credit cards and bank cheques,
handwritten signature has long been the target of
fraudulence. Therefore, with the growing demand for
processing of individual identification faster and more
accurately, the design of an automatic signature
verification system faces a real challenge. Handwritten
signature recognition can

978-0-7695-3359-9/08 $25.00 © 2008 IEEE
DOI 10.1109/CGIV.2008.8

some people who are good at imitating other’s
handwritings. An examples of the database image are
shown in figure 2 .

356

figure 1 : The flow diagram for the proposed method

(a)

(b)
Figure 2 . ( a ) Genuine and ( b ) forgery signatures.
preprocessor is used to remove noise. Preprocessing
techniques eliminate much of the variability of
signature data.

3. Preprocessing
Any image-processing application suffers from
noise like touching line segments, isolated pixels and
smeared images. This noise may cause severe
distortions in the digital image and hence ambiguous
features and a correspondingly poor recognition and
verification rate. Therefore, a

3.1 Noise Reduction

Standard noise reduction and isolated peak noise
removal techniques, such as median-filtering and
average filtering [1], are used to clean the initial image.

357

3-2 Normalization

f1 =

The next step in the Signature recognition process
is image normalization .Normalization is used to
standardize the intensity values in an image by
adjusting the range of gray-level values so that it lies
within a desired range of values. Let I(i, j) represent the
gray-level value at pixel (i, j), and N(i, j ) represent the
normalized gray-level value at pixel (i, j ). The
normalized image is defined as:

v (I (i, j) − M)2
M0 + 0

v
N(i, j) = 
2
 M − v0 (I (i, j) − M)
0

v

θ
Π

2

2
2
where θ = tan −1 µ 02 − µ 20 + ( µ 02 − µ 20 ) + 4 µ 11
2 µ 11
Extension degree

f2 =

λ1 − λ 2
;
λ1 + λ 2

( µ 02 + µ 20 ) 2 + 4 µ 112
2

where λ1 = ( µ 02 + µ 20 ) +
Extension degree 2

if I (i, j) > M

(µ

otherwise

f3 =

where M and V are the estimated mean and variance
of I(i,j) , respectively , and M0 and V0 are the desired
mean and variance values, respectively.

+ µ

02

20

)
l 00

where

size

size= (xmax−xmin)(ymax− ymin)
M −1 N −1

l 00 =

∑∑
0

g (x, y)

0

4. Features extraction
4-2 Grey-scale co-occurrence matrices

In principle, any texture analysis technique can be
applied to extract features from Hand write signature.
In this work we use Moment , the gray-scale cooccurrence matrix (GSCM) and Chain code future.

GSCMs are also considered. Generally speaking,
GSCMs are expensive to compute. For an image
represented using N grey levels, each GSCM is of size
N × N . Binary handwrite signature images contain
only two grey levels. It is therefore reasonable to use
the GSCM technique. In this paper, GSCMs were
constructed for five distances (d = 1, 2, 3, 4, 5) and
direction θ = 0o This gives each input handwrite
signature image 5 matrices of dimension 2 × 2 . When
the size of the GSCM is too large to allow the direct
use of matrix elements, measurements such as energy,
entropy, contrast and homogentityare computed from
the matrix and used as features [2].
Let pθ , d is the co-occurrence matrix then

4.1. Moment features

The global shape characteristics can be described
by moment. Region moment representations interpret a
normalized gray level image function as a probability
density of a 2D random variable. Properties of this
random variable can be described using statistical

p+q

characteristics - moments. A moment of order (
)
is dependent on scaling, translation, rotation, and even
on gray level transformations and is given by
∞

∫ ∫

m pq =

∞

−∞ −∞

x p y q g ( x , y ) dxdy
central

µ pq = ∫

∫

∞

−∞ −∞

p

moments

Contrast

∑∑

c

(i − xc ) ( j − y c ) g (i , j )

f

0

=

20

−
+

a − b

Homogentit yare =

k

p θλ , d ( a , b )

∑

p θλ , d ( a , b )

a ,b , a ≠ b

m 10
m 01
, yc =
m 00
m 00
From above moments, we can derive such features:
Height to width ratio
20

∑

where k = 2 , λ = 1

=

µ
(
µ

=

q

i=0 j=0

x

pθ , d ( a , b )

a ,b

n

p

2

a ,b

all previous work [5,6] use riemain summation to
evaluate the moment as the next equation

µ pq =

p θ2 , d ( a , b )

Entropy = − ∑ p θ , d ( a , b ) log

q

( x − xc ) ( y − yc ) g( x, y)dxdy

m

∑
a ,b

the
∞

=

Energy

µ
µ

02

a−b

k

4.3. chain codes

chine code are used to represent a boundary by a
connected sequence of straight-line segment of
specified length and direction. Typically, this
representation is based on 8-connectivity of the
segment. The direction of each segment is coded by
using a scheme shown in figure 3. Chain codes based

+ 1)

02

2

Incline degree

358

on this scheme are referred to as Freeman chain code
[1] .

to one input. The vector mx in Eq. (1) is the vector of
mean values of all input variables defined by relation
1 K
(2)
m = E { x} =
x
x

K

∑

k

k =1

Matrix A in Eq. (1) is determined by the
covariance matrix Cx. Rows in the A matrix are formed
from the eigenvectors e of Cx ordered according to
corresponding eigenvalues in descending order. The
evaluation of the Cx matrix is possible according to
relation

figure 3 : Direction number for 8–directional chain
code
5. Previous Work Using Principal Component
Analysis (PCA)

mx = E{(x − mx )(x − mx )T } =

1 K
T
T
∑xk xk −mx mx
K k=1

(3)

As the vector x of input variables is n-dimensional
it is obvious that the size of Cx is
n x n. The elements Cx(i, i) lying in its main diagonal
are the variances of x and the other values Cx(i, j)
determine the covariance between input variables xi,
xj.
(4)
c ( i , i ) = E {( x i − m i ) 2 }

The Principal Component Analysis (PCA) is a
useful statistical technique that has found applications
in fields such as recognition, classification and image
data compression. It is also a common technique in
extracting features from data in a high dimensional
space. This quality makes it an interesting tool for our
study. It is a systematic method to reduce data
dimensionality of the input space by projecting the data
from a correlated high-dimensional space to an
uncorrelated low-dimensional space. Turk and Pentland
[3] applied PCA for faces recognition. Ji and Yang [4]
built an ‘eigeneye’ feature space using PCA that
captured relationship between 3D face pose and the
geometric properties of the pupils. The ‘eigeneye’
space is then used for 3D face pose classification.
Results [4] showed that the technique could estimate
face pose in real time and produce good results for
subjects closer to the camera. Ohba et al. [5] applied
PCA to classify several facial expressions such as
anger, normal, surprise and smile. Original image of
each category is projected onto a facial expression
space and only the first three eigenvectors are used for
classification of facial expression. The ability of PCA
is also employed by Algorri and Escobar [6] for facial
gesture recognition. They used the eigenspace method
to build the facial gesture space and later used it for
image reconstruction during video conferencing. Ozer
et al. [7] applied PCA to detect human activities,
namely walking, running and kicking.

c (i, j ) = E{( xi − mi )( x j − m j )} (5)
between input variables xi, xj . The rows of A in
Eq. (1) are orthonormal so the inversion of PCA is
possible according to relation

x = AT y + m x (6)
7.signature identification

Signature identification can be classified into two
different problems: recognition and verification.
Recognition selects the author of a sample from among
a group of writers, while verification confirms or
rejects a written sample, as shown in Figure1. So, the
question that a recognizer answers is: who is the
writer? While the question that the verifier answers is:
Is this the writer’s true signature?
7.1 Recognition process

In the recognition process we use the K nearestneighbours classifier. When using the K nearestneighbours classifier (K-NN), for each class V in the
training set, the ideal feature vectors are given as fv.
Then we detect and measure the features of the
unknown signature (represented as U). To determine
the class R of the signature we measure the similarity
with each class by computing the distance between the
feature vector fv and U The distance measure used here
is the Euclidean distance. Then the distance computed
dv of the unknown signature from class V is given by

6. The PCA Theory

Principal component analysis in signature
recognition can be described as a transform of a given
set of n input vectors (variables) with the same length
K formed in the n- dimensional vector x = [x1, x2,
...xn]T into a vector y according to
y = A (x −mx)
(1)
This point of view enables to form a simple
formula (1) but it is necessary to keep in the mind that
each row of the vector x consists of K values belonging

dv

359

 N
=  ∑ (U
 j =1


− f vj ) 

2

j

1
2

where j=1,2,… N ( N is the number of the features
considered). The signature is then assigned to the class
R such that:
d R = min( d v ) where (k=1,2, no of classes).

[3] Turk, M. and A. Pentland. 1991. Eigenfaces for
Recognition. Journal of Cognitive Neuroscience. 3(1):
71-86.
[4] Ji, Q. and X. Yang. 2002. Real Time 3D Face Pose
Discrimination Based on Active IR Illumination.
International Conference on Pattern Recognition.
Japan. 4: 310-313.

7.2 Verification process

We designed a multilayer feed forward artificial
neural network for verification of off-line digitized
signatures. The proposed ANN consists of 28 input
variables, 18 hidden neurons, and 2 output variables
and it is designed to verification one signature at a
time. Back propagation algorithm is used for training.

[5] Ohba, K., G. Clary, and T. Tsukada. 1998. Facial
Expression Communication with FES. International
Conference on Pattern Recognition. Japan. 1378-1381.
[6] Algorri, M. E. and A. Escobar. 2004. Facial
Gesture Recognition for Interactive Applications. IEEE
Proceedings of Fifth Mexican International Conference
in Computer Science. Mexico. 185-195.

8. Experimental Results

Table 1 present the results for the proposed method
using PCA and Without Using PCA
Using Features
Without using
PCA
FRR (false
recognition
rate)
FAR(false
accept rate)
Average
error rate

20%

[7] Ozer, B. and W. Wolf. 2002. Real Time Posture
and Activity Recognition. IEEE Proceedings on
Motion and Video Computing. 133-138.

Using
Features
with
PCA
15%

[7] Tobias Scheidat , Claus Vielhauer, Jana Dittman.
Handwriting verification – Comparison of a multialgorithmic and a multi-semantic approach Image Vis.
Comput. (2007), doi:10.1016/j.imavis.2007.03.006

IEEE COPYRIGHT FORM
18%

17%

19%

16%

To ensure uniformity of treatment among all
contributors, other forms may not be substituted for this
form, nor may any wording of the form be
changed. This form is intended for original material
submitted to the IEEE and must accompany any such
material in order to be published by the
IEEE.Please read the form carefully and keep a copy
for your files.

Table 1 :Results in terms of FRR and FAR

TITLE OF PAPER/ARTICLE/REPORT/
PRESENTATION/SPEECH INCLUDING ALL
CONTENT IN ANY FORM, FORMAT,
OR MEDIA (hereinafter, "the Work"): Automatic
Signature Recognition And Verification Using
Principal Components Analysis
COMPLETE LIST OF AUTHORS:I. A. Ismail , M.
A. Ramadan ,T . El danf, A. H. Samak
IEEE PUBLICATION TITLE (Journal, Magazine,
Conference, Book):Fifth International
Conference on Computer Graphics, Imaging
and Visualization
COPYRIGHT TRANSFER

9. Conclusion

In this study, we presented an off-line signature
recognition and verification system which is based on
extract some signature image feature as moment ,
GSCMs and chain code . The PCA compute to the
extract feature for the training database , also the same
feature extracted to the test image and project into the
evaluated PCA. Two separate process for signature
identification Recognition process and Verification
process. Recognition selects the author of a sample
from among a group of writers in this process we used
KNN classifier , while verification confirms or rejects a
written sample in this process we used ANN.

The undersigned hereby assigns to the Institute of
Electrical and Electronics Engineers, Incorporated (the
"IEEE") all rights under copyright that may
exist in and to the above Work, any revised or
expanded derivative works submitted to the IEEE by
the undersigned based on the Work, and any
associated written, audio and/or visual presentations or
other enhancements accompanying the Work. The
undersigned hereby warrants that the Work

10. REFERENCES
[1] Gonzalez, C., Wintz, P., 1987. Digital Image
Processing, second ed. Addison-Wesley, MA.

[2] R.M. Haralick, Statistical and structural approaches
to textures, Proc. IEEE, vol. 67, 1979, pp. 786 - 804.

360

is original and that he/she is the author of the Work; to
the extent the Work incorporates text passages,
figures, data or other material from
the works of others, the undersigned has obtained any
necessary permissions. See Retained Rights, below.
See Retained Rights ,below.
AUTHOR RESPONSIBILITIES
The IEEE distributes its technical publications
throughout the world and wants to ensure that the
material submitted to its publications is properly
available to the readership of those publications.
Authors must ensure that their Work meets the
requirements as stated in section 8.2.1 of the IEEE
PSPB Operations Manual, including provisions
covering originality, authorship, author responsibilities
and author misconduct. More information on
IEEE's publishing policies may be found at
http://www.ieee.org/web/publications/pubtoolsandpolicy
info/index.html. Authors are advised especially
of IEEE PSPB Operations Manual section 8.2.1.B12: "It
is the responsibility of the authors, not the IEEE, to
determine whether disclosure of their
material requires the prior consent of other parties and,
if so, to obtain it." Authors are also advised of IEEE
PSPB Operations Manual section
8.1.1B: "Statements and opinions given in work
published by the IEEE are the expression of the
authors."

6. Although authors are permitted to re-use all or
portions of the Work in other works, this does not
include granting third-party requests
for reprinting, republishing, or other types of re-use.
The IEEE Intellectual Property Rights office must
handle all such third-party
requests.

INFORMATION FOR AUTHORS
IEEE Copyright Ownership
It is the formal policy of the IEEE to own the copyrights
to all copyrightable material in its technical publications
and to the individual contributions
contained therein, in order to protect the interests of
the IEEE, its authors and their employers, and, at the
same time, to facilitate the appropriate
re-use of this material by others. The IEEE distributes
its technical publications throughout the world and
does so by various means such as hard
copy, microfiche, microfilm, and electronic media. It
also abstracts and may translate its publications, and
articles contained therein, for
inclusion in various compendiums, collective works,
databases and similar publications.
Author/Employer Rights
If you are employed and prepared the Work on a
subject within the scope of your employment, the
copyright in the Work belongs to your employer
as a work-for-hire. In that case, the IEEE assumes that
when you sign this Form, you are authorized to do so
by your employer and that your
employer has consented to the transfer of copyright, to
the representation and warranty of publication rights,
and to all other terms and
conditions of this Form. If such authorization and
consent has not been given to you, an authorized
representative of your employer should
sign this Form as the Author.
Reprint/Republication Policy
The IEEE requires that the consent of the first-named
author and employer be sought as a condition to
granting reprint or republication rights to
others or for permitting use of a Work for promotion or
marketing purposes.

RETAINED RIGHTS/TERMS AND CONDITIONS
1. Authors/employers retain all proprietary rights in any
process, procedure, or article of manufacture described
in the Work.
2. Authors/employers may reproduce or authorize
others to reproduce The Work, material extracted
verbatim from the Work, or derivative works
to the extent permissible under United States law for
works authored by U.S. Government employees, and
for the author's personal use or
for company or organizational use, provided that the
source and any IEEE copyright notice are indicated,
the copies are not used in any
way that implies IEEE endorsement of a product or
service of any employer, and the copies themselves
are not offered for sale.
3. Authors/employers may make limited distribution of
all or portions of the Work prior to publication if they
inform the IEEE in advance of
the nature and extent of such limited distribution.
4. In the case of a Work performed under a U.S.
Government contract or grant, the IEEE recognizes
that the U.S. Government has royalty-free
permission to reproduce all or portions of the Work,
and to authorize others to do so, for official U.S.
Government purposes only, if the
contract/grant so requires.
5. For all uses not covered by items 2, 3, and 4,
authors/employers must request permission from the
IEEE Intellectual Property Rights office
to reproduce or authorize the reproduction of the Work
or material extracted verbatim from the Work, including
figures and tables.

GENERAL TERMS
1. The undersigned represents that he/she has the
power and authority to make and execute this
assignment.
2. The undersigned agrees to indemnify and hold
harmless the IEEE from any damage or expense that
may arise in the event of a breach
of any of the warranties set forth above.
3. In the event the above work is not accepted and
published by the IEEE or is withdrawn by the author(s)
before acceptance by the IEEE,
the foregoing copyright transfer shall become null and
void and all materials embodying the Work submitted
to the IEEE will be destroyed.
4. For jointly authored Works, all joint authors should
sign, or one of the authors should sign as authorized
agent for the others.
I. A. Ismail , M. A. Ramadan ,T . El danf, A. H. Samak
31-05-2008

361

