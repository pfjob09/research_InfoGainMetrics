Fifth International Conference on Computer Graphics, Imaging and Visualization
Visualisation

Image Texture Classification using Combined Grey Level Co-occurrence Probabilities
and Support Vector Machines
1

Hee-Kooi Khoo, 2Hong-Choon Ong, 3Ya-Ping Wong
School of Mathematical Sciences, Universiti Sains Malaysia, 11800 Gelugor, Penang, Malaysia
3
Faculty of Information Technology, Multimedia University, 63100 Cyberjaya, Selangor, Malaysia
{1hkkhoo@gmail.com, 2hcong@cs.usm.my, 3 ypwong@mmu.edu.my}
1&2

can be created from the shift on statistical feature while
moving from one texture to another [3].
Support Vector Machine (SVM) is a type of training
method which is used to separate extracted features by
creating a separating hyperplane [4]. SVM have been
proven to overcome the local minimum that happens in
Neural Networks (NN) training algorithms. Thus, SVM
provides a better performance in terms of accuracy for
classification and regression [5]. In imaging, SVM is
modified to do several classification tasks, such as
pattern recognition in [6], edge detection in [1], texture
classification in [7] and video classification in [8]. SVM
serves as complement for image segmentation methods.

Abstract
Texture refers to properties that represent the
surface or structure of an object and is defined as
something consisting of mutually related elements. The
main focus in this study is to do texture segmentation and
classification for texture digital images. Grey Level Cooccurrence Probabilities (GLCP) method is being used
to extract features from texture image. Gaussian Support
Vector Machines (GSVM) have been proposed to do
classification on the extracted features. A popular
Brodatz texture album had been chosen to test out the
result. In this study, a combined GLCP-GSVM shows an
improvement over GLCP in terms of classification
accuracy.

2. Methodology

Keywords--- Support Vector Machines, Grey
Level Co-occurrence Probabilities, Texture Analysis,
Classification

2.1. Grey Level Co-occurrence Probabilities
Grey Level Co-occurrence Matrix (GLCM) is a
discrete function that represents joint probability, Cij, of
different sets of pixels having different grey levels.
Practically, the co-occurrence matrix can be constructed
by configuring a vector between two pixels. The setting
of distance between two relational pixels normally will
be equal to 1 for non-stationary texture image. The
common orientation is either 0°, 45°, 90° or 135°. The
combination for both directions can also be used for
isotropic texture image [3]. The co-occurrence matrix is
then divided by the total of all entries that give rise to the
joint probability density function as defined by,

1. Introduction
In digital imaging, to select the texture of interest
from an image in nature is not an easy task. For a highly
textured image, the arrangement of the set of pixels is
rather random or having several kinds of transformation.
Besides, a noisy image may affect implementation of the
manual segmentation methods. For example, grey-level
threshold method could easily miss out the related pixels
of a texture feature and only gives the brightness of an
image. A Sobel filter could result in a lot of noise on
certain texture features, which then decreases the
performance of the segmentation [1].
Grey Level Co-occurrence Probabilities (GLCP)
statistics are used to preserve the spatial characteristics
of a texture. The selection of certain texture is possible
based on the statistical features. The best statistical
features that are used for analysis are entropy, contrast,
and correlation [2]. However, further analysis in [3]
shows that correlation was not suitable for texture
segmentation. GLCP statistics can also be used to
discriminate between two different textures. Boundaries

978-0-7695-3359-9/08 $25.00 © 2008 IEEE
DOI 10.1109/CGIV.2008.47

Cij =

F

∑

ij
G −1
i , j =0

Fij

(1)

where Fij represents the frequency of occurrence between
grey levels, i and j. The grey level quantization, G,
recommended setting is 24 in [2]. However, an adequate
grey level setting is 64 in [3]. Different types of textures
carry different pattern information. The selection of
statistical features can be determined through artificial
bi-partite image sampling. In order for GLCP statistics to
properly detect certain natural texture, a reasonable
window size shall be set to extract features. More

180

analysis on co-occurrence matrix can be found in [9].
Some of the statistical features used are defined as shown
in Table 1,
Statistics

Several experiments had been tested using SVM.
For example the comparison performance between
boosted Artificial Neural Networks (ANN) and SVM for
classification done in [5]. The efficiency of SVM
algorithm is proved while comparing with other edge
detectors, such as Sobel and Canny filter in [1].

Formula

Uniformity

G −1

∑C

2

3. Experimental Design

ij

i , j =0

Contrast

G −1

∑C

ij

3.1. Test Images

(i − j ) 2

The Brodatz texture images are being used by Rishi
Jobanputra in [3] and Ibrahim Turkoglu in [7]. Some of
the Brodatz textures images are selected to test the
performance for both the GLCP and GLCP-GSVM
system. The first test image used is a bi-partite textured
image consisting of cork (D4) and wire (D6) from
Brodatz album in Figures 1, 2 and 3. The resolution of
the bi-partite image is being crop out into 200×200
pixels for GLCP testing. The second test image is
another Brodatz image consisting of oriental rattan (D64)
and handmade paper (D57). The D64-D57 bi-partite
image is also being crop out into 638×335 pixels for
GLCP testing. The third test image is a mosaic texture
consisting oriental rattan texture and handmade paper
texture with size 300×300.

i , j =0

Entropy

G −1

− ∑ Ci j log Cij
i , j =0

Table 1: Statistical features used in GLCP

2.2. Support Vector Machines Algorithm
In classification, the purpose of SVM is to map from
feature vectors into a higher dimensional feature space,
and then creating a separating hyperplane with maximum
margin to classify the features. Support Vectors (SVs)
are highlighted pixels that help to create the margins or
boundaries in an image. Higher dimensional space is
defined by a kernel function. Some of the popular
kernels are shown in Table 2. Other kernel also can be
found, such as Spline function in [10].
Kernels

Formula

Polynomial

k ( x, x ') = ( x, x ')d

Gaussian Radial Basis
Function (RBF)

k ( x, x ') = exp(−
where

Exponential

Radial

Basis Function (RBF)

For GLCP, quantization was set to 64 levels in order
to collect sufficient grey level co-occurring information.
The displacement vector was only set to current pixel
and the next pixel to the right, to decrease computational
complexity. All three statistical features have been taken
into account, while doing sampling, to determine the one
that is closest to the texture boundaries.

| x − x ' |2
)
2σ 2

σ >0.

k ( x, x ') = exp(
where

3.2 Parameters Settings

| x − x'|
)
2σ 2

σ >0.

Criteria

Value

Grey level quantization

64 levels

Distance

1 pixel

Orientation

0°

Statistical Features

Uniformity, contrast and
entropy

Table 2: Common Kernel functions for SVM

Table 3: GLCP parameters configuration

The construction of margin is done by training the
coordinates for each pixel with the corresponding class.
SVM algorithm actually does clustering and optimization
during the training by finding the support vectors without
explicitly defining a function that does it. The available
optimizers for SVM are LOQO [4] and MINOS [11]. For
an understanding of SVM algorithm, one can try out the
Matlab SVM toolbox from [12], developed by Steve
Gunn.

The LOQO software package developed by
Alexander J. Smola had been selected to do optimization.
Gaussian RBF was chosen because it could provide the
best optimal solution for both the non-linear case and
closed case. SVM also automatically helps RBF kernel to
define the centers during optimization.

181

Criteria

Value

Optimizer

LOQO

Kernel

Gaussian RBF

Standard deviation,

σ

1.0
1

Table 4: SVM parameters configuration

0.8
0.6
0.4
0.2

3.3 Procedures

0
0

3.3.1. Bi-partite textured image Co-occurrence
probabilities were generated for each column of the
image based on the parameters in Table 3. The statistical
features could be determined with the formula from
Table 1 for each co-occurrence probability. Then, all
statistical features were normalized into the range 0 to 1.
The graph of statistical features versus column of the
image is then plotted. Since the border of the first test
image is linear, so the boundary between the textures can
be easily obtained by finding the gradients among all
statistical features. The value of each texture feature also
could be determined by taking the average.
3.3.2. Mosaic texture image The features of
oriental rattan (D64) and handmade paper (D57) can be
retrieved by following the steps in Section 3.3.1.
Window size of 5×5 was selected to scan the image, thus
extracting the oriental rattan (D64) feature from
handmade paper (D57) feature. Large windows are
problematic to extract features for irregularly shaped
texture boundaries and in regions of high boundary
density because of overlapping.

50

100

150

200

Figure 1: Cork-wire image with white line as
boundary and the corresponding graph of GLCP
uniformity

1.2
1
0.8
0.6
0.4
0.2
0
0

50

100

150

200

Figure 2: Cork-wire image with white line as
boundary and the corresponding graph of GLCP
contrast

4. Result and Discussion
4.1. Cork-wire Image
Figures 1, 2 and 3 show the white line as
boundary obtained with the cork-wire image whereby the
cork texture is on the left side of the image, and the wire
texture is on the right side of the image. The graphs
below the images in Figures 1, 2 and 3 show the
corresponding statistical features of uniformity, contrast
and entropy respectively. GLCP uniformity performs the
best separation on the cork-wire image. The boundary
touched exactly between the two textures as shown in
Figure 1, as compared with entropy and contrast, in
Figure 2 and Figure 3 respectively.

1.02
1
0.98
0.96
0.94
0.92
0.9
0

50

100

150

200

Figure 3: Cork-wire image with white line as
boundary and the corresponding graph of GLCP
entropy

182

4.2. Oriental Rattan-Handmade Paper Image
Next, Figures 4, 5 and 6 also show the white
line as boundary obtained with the bi-partite image
where by the oriental rattan (D64) texture is on the left
side of the image, and the handmade paper (D57) texture
is on the right side of the image. The graph in Figures 4,
5 and 6 show the corresponding statistical features of
uniformity, contrast and entropy respectively.

1
0.98
0.96
0.94
0.92
0.9
0.88
0.86
0.84
0.82
0.8
0

100

200

300

400

500

600

Figure 6: D64-D57 image with white line as
boundary and the corresponding graph of GLCP
entropy

0.8
0.7
0.6
0.5
0.4
0.3

All GLCP uniformity, GLCP entropy and
GLCP contrast perform the good separation on the D64D57 bi-partite image. As shown in the Figures 4, 5 and 6,
the boundaries touched the exact border between the two
textures. Following the procedures in Section 3.3.1,
average measurements of each texture feature can be
obtained as shown in Table 5.

0.2
0.1
0
0

100

200

300

400

500

600

Figure 4: D64-D57 image with white line as
boundary and the corresponding graph of GLCP
uniformity

Image

Uniformity

Contrast

Entropy

Cork (D4)

0.410476

0.567811

0.991469

Wire (D6)

0.597513

0.206878

0.449321

Oriental

0.453334

0.11783

0.831089

0.207774

0.279775

0.941592

Rattan(D64)
Handmade
Paper(D57)

0.35
0.3

Table 5: Average measurements of each feature
in the test images

0.25
0.2
0.15
0.1
0.05

GLCP entropy could extract the oriental rattan
(D64) from handmade paper (D57) base on the average
features in Table 5. Because of the orientation stated in
Table 3 is only consider one direction (current pixel and
pixel to the right), the feature extraction could create
some noise for mosaic textures in Figure 7 below. Thus,
classification method is essential, in order to improve the
accuracy of the segmentation. SVM can classify Figure
7, base on the GLCP feature vector extracted.

0
0

100

200

300

400

500

600

Figure 5: D64-D57 image with white line as
boundary and the corresponding graph of GLCP
contrast

183

5. Conclusions
GLCP statistical features serves as a tool to separate
most of the texture images, since the manual methods are
found to be difficult to do segmentation and
classification tasks. Reclassification using GLCP-GSVM
thus improves the classification performance over GLCP
method.

Acknowledgements
The research is funded by the Malaysian Ministry of
Science, Technology and Innovation (MOSTI) under the
Grant Number 305/PMATHS/613122 of eScience Fund.

Figure 7: Mosaic texture image of oriental rattan
(D64) within handmade paper (D57)

References

Figure 7 is a mosaic image created from the
oriental rattan and handmade paper to test out the
performance for GLCP and GLCP-GSVM. The oriental
rattan and handmade paper textures are chosen because
their average grey level values are close. The
classification accuracy of GLCP and GLCP-GSVM can
be measured by comparing each method with the original
classification. The original classification was done using
the RGB color luminance threshold with manual edge
detection. The accuracy is defined by
Accuracy, A =

T −e
× 100%
T

[1]

Sheng Zheng, Jian Liu, Jin Wen Tian, A new efficient
SVM-based edge detection method, Pattern Recognition
Letters 25, p.1143-1154, 2004.
[2] David A. Clausi, An analysis of co-occurrence texture
statistics as a function of grey level quantization, Remote
Sensing, Vol. 28, No. 1, p.46-62, 2002.
[3] Rishi Jobanputra, David A. Clausi, Preserving
boundaries for image texture segmentation using grey
level co-occurring probabilities, Pattern Recognition 39,
p.234-245, 2006.
[4] R. J. Vanderbei. LOQO: An interior point code for
quadratic programming. Technical Report SOR-94-15,
Princeton University, Statistics and Operations Research,
1998. Code available at http://www.princeton.edu/~rvdb.
[5] Miguel Rocha, Paulo Cortez, Jose, Evolution of neural
networks
for
classification
and
regression,
Neurocomputing 70, p.234-245, 2007.
[6] Bernd Heisele (2005), Hierarchical classification and
feature reduction for fast face detection. Handbook of
Pattern Recognition and Computer Vision (CH Chen,
PSP Wang, ed.), p.481-495. World Scientific Publ.
[7] Ibrahim Turkoglu, Engin Avci, Comparison of waveletSVM and wavelet-adaptive network based fuzzy
inference system for texture classification, Digital Signal
Processing, Vol. 18, No. 1, 2008.
[8] D.K. Iakovidis a, Texture multichannel measurements
for cancer precursors identification using support vector
machines, Measurements 36, p.297-313, 2004.
[9] James R. Carr, Fernando Pellon de Miranda, The
semivariogram in comparison to the co-occurrence
matrix for classification of image texture, Geoscience
and Remote Sensing, Vol. 36, No. 6, 1998.
[10] YuBo Yuan, WeiGuo Fan, DongMei Pu, Spline function
smooth support vector machine for classification,
Industrial and Management Optimization, Vol. 3, No. 3,
2007.
[11] B. A. Murtagh and M.A. Saunders. MINOS 5.4 user’s
guide. Technical Report SOL 83.30, Stanford University,
1993.
[12] Steve Gunn (1998), Matlab Support Vector Machines
Toolbox [Online], [Accessed 2007]. Code available at
http://www.isis.ecs.soton.ac.uk/resources/svminfo.

(2)

where T is the total number of pixels on test image and
e is the number of pixels wrongly classified.
Image
Figure 7

Classification Accuracies (%)
GLCP

GLCP-GSVM

91.76

98.49

Table 6: Accuracies of each classification
methods
As shown in Table 6, experiment using GLCP and
GLCP-GSVM method were tested on the Figure 7. The
accuracy of GLCP-GSVM classification is increase
about 6.7% over GLCP classification.

4.3. Technical Description
The GLCP and SVM systems were developed in C
and C++ programming language. The programs were run
on Windows Vista operating system, with 2.0GHz Core
2 duo processor and 2GB of memory. During the
program execution, the programs occupied about a
quarter of the CPU and memory usage.

184

