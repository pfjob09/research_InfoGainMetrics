Environment Lighting for Point Sampled Geometry
Feng Liu, Sushil Bhakar, Thomas Fevens, Sudhir Mudur
Department of Computer Science and Software Engineering
Concordia University, Montreal, Quebec, H3G 1M8, Canada
william7ba@yahoo.com, {sushil, fevens, mudur}@cse.concordia.ca
Abstract
Point sampled geometry has recently gained
significant interest due to the tremendous advances in
the technology of 3D scanning and the representational
simplicity afforded by avoiding any need for explicit
connectivity information. Their use in creating highquality rendered images is however still limited. Till
date, most renderings of point sampled surfaces use the
Phong illumination model. In this paper we consider the
rendering of point sampled surfaces with both diffuse
and specular material properties under distant
illumination, as specified using an environment map. For
this, we have combined two of the earlier works for
continuous surfaces, spherical harmonic representations
of irradiance environment maps and glossy reflection,
and programmed it on the GPU using vertex and
fragment shaders. This hardware accelerated
implementation has been incorporated into a public
domain point based renderer enabling us to efficiently
produce high quality images of point sampled geometry.
Keywords: point based rendering, environment
lighting, spherical harmonics, irradiance, GPU
programming

1. Introduction
Recently point based graphics is emerging as an
alternative to triangle based graphics. In this, the shape
of objects is represented discretely in the form of
sampled surface points. Typically these sampled surface
points can be directly obtained using 3D scanners. Their
immediate application in the fast growing industries of
video gaming and 3D cinema has in turn fuelled a lot of
interest in investigating the use of 3D points as the
universal primitive in computer graphics, both for
representing 3D objects and for synthesizing (rendering)
color shaded images of such point sampled surface
representations. Traditionally, in computer graphics, the
geometry of the surfaces of 3D objects has been
represented using algebraic geometry techniques usually in the form of implicit algebraic equations
(example: polyhedral meshes, piece-wise quadrics) or as
parametric polynomial functions (example: Bezier or BSpline surfaces). Since surface topology information like

connectivity of vertices, edges and faces, that is typically
required in a triangle or polygonal mesh based surface
representation is not present, representation of point
sampled geometry is very much simpler. A surface is
merely stored as a large soup of 3D points. While the
move to point samples appears simple, there are a
number of issues primarily due to the discrete nature, and
the fact that there is not an explicit mathematical
definition for the continuous surface that can be
employed for geometric operations, say for zooming into
a small part of a surface to a level of detail in which that
part of the surface gets sparsely sampled. As a result,
apart from the major challenges of efficiently handling
and interactively rendering the large amount of point
geometry data, irregular spacing and noise in sampling,
problems due to the fact that a point has no spatial extent
also need to be addressed. Thus, the process of rendering
a point sampled surface in an efficient manner to yield
aesthetically pleasing and smooth images is currently a
hot research topic in the field of computer graphics.
Splatting is a standard technique which associates a
spatial extent of influence for a point in order to ensure
hole-free rendering. This could be a disk on the tangent
plane [18] or more elaborate differential geometric
information [19]. The point is then rendered either using
shading optionally followed by screen space filtering or
by choosing a suitably approximating shape in screen
space [20]. Splat based rendering gives reasonably
acceptable results in terms of rendering the discrete
representation as a continuous looking surface. However
even till today, most of the renderers for point sampled
geometry employ a very simple local illumination model.
Typically, this includes one or more distant point light
source and possible variation in the diffuse, specular and
shininess coefficients of the standard Phong illumination
model. This makes it very difficult to create high quality
images with point sampled surfaces. Also, because of the
discontinuous nature of the points and the splats, the
rendering results are even poorer under magnification.
This lack of effort in high quality rendering could be due
both to the infant nature of this field and also to the lack
of direct hardware support for rendering the spatial
extent of discrete 3D points making it inefficient to
produce high quality images. Clearly more complex
lighting models have to be considered. In this paper we
consider the rendering of point sampled surfaces with
both diffuse and specular material properties under
distant illumination, as specified using an environment

Proceedings of the International Conference on Computer Graphics, Imaging and Visualisation (CGIV'06)
0-7695-2606-3/06 $20.00 © 2006

map. We have combined two of the earlier works for
continuous
surfaces:
(1)
spherical
harmonic
representations of irradiance environment maps for
illumination of diffuse surfaces with light falling on the
objects from all the directions [8], and (2) glossy
reflection for illumination of surfaces with specular
behaviour [10]. We have adapted these formulations for
point based surface representations and for
computational efficiency programmed it on the GPU
using vertex and fragment shaders. This hardware
accelerated implementation has been incorporated into a
public domain point based renderer, namely
PointShop3D[16], enabling us to efficiently produce high
quality rendered images of point sampled geometry. The
rest of this paper is organized as follows. Section 2
provides a short review of other efforts at producing high
quality images for point sampled geometry. Section 3
provides a brief background on complex lighting models
used in high quality rendering. Section 4 provides the
two formulations for lighting diffuse and specular objects
using environment maps and describes our efforts at
supporting the combined illumination model into the
PointShop3D software package. Section 5 concludes
with an analysis of the results of our implementation and
potential for future work.

2. Related Work on High Quality Rendering
of Point Sampled Surfaces
Recent work on high quality rendering of point sampled
surfaces can be considered in three categories as
discussed below.

calculations [3]. Wald and Seidel[4] give another ray
tracing algorithm for interactive applications. They use a
combination of different techniques including an SIMD
accelerated intersection code, together with a highly
optimized specially built kd-tree data structure. They
report 7 – 30 frames for a 512 x 512 image of
sufficiently large point based model. A more recent
effort describes attempts on ray tracing deformable point
sampled surfaces. Once again the emphasis is on clever
update of the hierarchical data structure for
accommodating the deformation in each frame [5].

2.2 Radiosity:
Apart from ray-tracing, another powerful and
popular graphics method for achieving global effects is
the radiosity method. Dobashi et. al [6] describe a very
straight forward extension of the standard radiosity
technique based on finite elements and applying it to
compute radiosity based illumination for point sampled
geometric environments. For this they consider each
surfel (point with associated area) as a finite element and
calculate inter-reflections among the surfels.

2.3 Reproduction of Sharp Features
Since the surface reconstruction techniques as well
as splat based rendering technique assume smooth
surface geometry, it is difficult to reproduce sharp
features like edges and corners in rendered images of
point based models, say modeled as CSG tree [7]. There
have been a number of efforts to ensure correct rendering
of edges and corners. The solutions either suggest
resampling around the feature area [22], clipping of
surfel [17, 7], or special two normal surfel [24].

2.1 Ray Tracing:
Simulation of global illumination effects of shadows
and reflections, a few papers have applied ray tracing
techniques to point based models. Apart from the fact
that the number of points in a point sampled surface may
be very large, the main problem in comparison to ray
tracing of continuous surface models arises due to the
fact that both points and rays are singular geometric
entities having no spatial extent. At least one of these
should be augmented with some spatial entity. The
different methods vary in the way in which this problem
is solved and also correspondingly in the acceleration
data structures that are employed. Schaufler and Jensen
[1] were the first to propose ray-point-based surface
intersection algorithm. Here the authors propose to
intersect ray with point sampled surface by creating a
cylinder around the ray. Adamson and Alexa [2]
proposed a number of ray-surface algorithms based on
their moving least squares (MLS) implicit surface
definition. Since the surface calculation is expensive,
they initially create a sphere hierarchy and intersect the
rays with this hierarchy to find an approximate
intersection. Finally they apply surface-ray intersection
method inside the sphere. They followed up their work
by further improving efficiency of intersection

3. Complex Lighting Models
In most real situations lighting is quite complex as it
comes from a variety of sources such as area light
sources, bright reflecting surfaces, skylight, etc. The
simplest lighting model is an empirical approximation of
direct illumination by one or more distant point light
sources. This is the standard graphics direct illumination
model and is known as the Phong illumination model. In
the Phong model, there are three components in the light
reflected by a point on the surface; (i) diffuse lighting
which depends primarily on the surface normal,
(ii) specular lighting which depend on the angle between
the surface normal and the view direction and is modeled
using a reflection coefficient and a shininess factor and
(iii) indirect lighting due to interreflection which is
approximated using an ambient light component that is
independent of the surface and the view direction. Of
course; this does not model global interreflection effects
such as shadows, reflections refractions etc. For this, the
methods discussed earlier, namely ray tracing and
radiosity have to be used. The latter methods essentially
have to carry out a computationally expensive integration

Proceedings of the International Conference on Computer Graphics, Imaging and Visualisation (CGIV'06)
0-7695-2606-3/06 $20.00 © 2006

of the incoming light over the upper hemisphere of a
surface point.
The most general form of the illumination model is
the BRDF (Bi-directional Reflection Distribution
Function) which defines outgoing light in any direction
with respect in coming light in any direction [14].
Usually there is a lambertian component to account for
the diffuse reflection behaviour and a specular
component. There have been many proposals for
modeling of the specular reflection behaviour in a more
physically accurate manner than the Phong model. The
most known of these are the Torrance and Sparrow
model [10] and Cook and Torrance model [21]. The
Torrance-Sparrow model uses a Gaussian micro-facet
distribution function and a geometric attenuation factor
to account for self shadowing.
From the point of view of complex light sources, one
approach to modeling of more complex lighting is the
method of environment maps. An environment map is
the incident light at a point in all directions, usually
modeled as a spherical light field surrounding the point.
Blinn and Newell were the first to propose environment
maps to model perfect mirror like reflection of a small
surface illuminated by distant spherical illumination [13].
Wolfgang et. al [10][11] showed how to do prefiltering
and get view independent environment maps. They also
applied physically more accurate model than Phong
illumination for local lighting. For reflections they use
their view independent maps. Kautz et. al [12] extended
their technique to handle a more general class of
isotropic BRDFs.
Ramamoorthi et. al [8][9] have shown that for
diffuse lighting, irradiance can be calculated analytically
in terms of spherical harmonics. Spherical harmonic
coefficients [15] are similar to Fourier basis coefficients
but defined over sphere. This turns out to be a compact
and efficient representation of what has been termed as
irradiance environment map. Basically, in this
representation, diffuse environment lighting can be well
approximated using only 9 parameters. They
demonstrated results of their method applied to polygon
based representations very effectively.

4. Environment Lighting for Point Sampled
Surfaces
We have a simple straight forward implementation
for environment map based lighting of point sampled
surface models. Given an environment map, we compute
the diffuse and specular components separately and add
them to compute the colour to be assigned to the splat
associated with that point. We discuss the formulation
for these two components in a little more detail below.

4.1 Irradiance Environment Map for Diffuse
Lighting:

There are three benefits of using this technique of
spherical harmonic based irradiance environment map
introduced in [8]:
• people perceive materials more easily under
irradiance map than geometry lighting (point light
and directional light).
• The cost of evaluating the light condition is
independent of the number of light sources. Because
the lighting environment is represented as a whole,
and the integral is pre-computed.
• Since the first 9 coefficients approximate the
integrated result over the hemisphere very well, it is
computationally efficient even for real time
rendering of point based models.
For the benefit of the readers, we repeat parts of the
formulation given in [8] below as we use the same for
point based lighting as well. For a complete detailed
derivation, the reader is referred to the original paper [8].
After ignoring shadows and near-field illumination, the
irradiance E is a function of surface normal n only and is
given by an integral over the upper hemisphere
represented using spherical harmonics:

E (θ ,φ ) = ¦ Al LlmYlm (θ ,φ )

(1)

l,m

Where

Ylm denote spherical harmonic coefficients,

Llm denote the spherical harmonic coefficients of the
incident light in their expansion, and A denotes the dot
product of the normal and the direction vector for which
analytical formulae have been provided [1].
We can calculate Llm in a preprocessing operation:

Llm =

π

2π

³ ³
θ φ

L(θ , φ ) Ylm (θ , φ ) sin θ dθ dφ

(2)

=0 = 0

Just 9 coefficients ( l ≤ 2 ) are sufficient for a close
approximation. The average error is less than 1%.
With this we have everything for equation (1), so we can
calculate every point’s diffuse color just based on its
normal.
We first have to calculate spherical harmonic (SH)
coefficients. Given below are the spherical harmonic
basis functions that are used in the above. These are
defined in terms of the direction cosines in Cartesian
coordinate space:
Let us define normalization coefficients of the spherical
harmonic basis functions as follows:
1
3
15
5
15
n0 =
; n1 =
; n2 =
; n3 =
; n4 =
2 π
2 π
2 π
4 π
4 π
Then

Y00 = n0 ;

Proceedings of the International Conference on Computer Graphics, Imaging and Visualisation (CGIV'06)
0-7695-2606-3/06 $20.00 © 2006

( Y1−1 ; Y10 ; Y11 ) = n1 *(-x; -y; z);
( Y21 ; Y2−1 ; Y2− 2 ) = n2 *(xz ;yz ;xy) ;

Y20 = n3 *(3*z*z-1) ;

In our actual vertex shader implementation, we have
reused a clever trick introduced in “Efficient evaluation
of Irradiance Environment Maps” [23], which uses less
number of GPU registers. In what follows, Rlm , Glm ,

Blm are just Llm in RGB channel respectively.

Y22 = n4 *(x*x –y*y) ;
For an environment map (EMap), we precalculate the 9
spherical harmonic coefficients:

Llm (0  l  2, -l  m  l ).
These calculations are done separately for each of RGB
channels and stored in an array SH, which is then passed
on to the vertex shader.
for (i=0;i<EMapHeight;i++)
for (j=0;j<EMapWidth;j++)
for (col=0;col<3;col++)
{
index = l*(l+1)+m+1;
SH[col][index]+=
(-1)^index*EMap[i,j]*Ylm*dȦ;
}

Before we look at the actual vertex shader pseudocode,
we need to define a few parameters.
With

c0 = n0 ; c1 = h1n1; c2 = h2 n2 ; c3 = h2 n4 ;
Table 1 shows the formulation of these parameters

TABLE 1: Diffuse Lighting GPU Program Parameters

We are now ready to describe the vertex shader
implemented by us:

The pseudo code for this is given above.
float3 x1, x2, x3;
x1.r = dot(cAr,vNormal);
x1.g = dot(cAg,vNormal);
x1.b = dot(cAb,vNormal);

The computation of the diffuse lighting component for
each point is carried out in the vertex shader. For this, we
need to carry out the following calculations for each
point, say p and its given normal: N(x,y,z).

float4 vB = vNormal.xyzz * vNormal.yzzx;
x2.r = dot(cBr,vB);
x2.g = dot(cBg,vB);
x2.b = dot(cBb,vB);

Define:

2
1
h1 = ; h2 = ;
3
4

float vC =
vNormal.x*vNormal.x - vNormal.y*vNormal.y;
x3 = cC.rgb * vC;

where hi are the convolution coefficients divided by

π (irradiance is turned into exit radiance), and ni

are the
normalization coefficients of the SH basis functions
defined earlier.

E00 = L00 * n0
E1−1 = L1−1 * [ n1 * h1 * (-N.y)]
E10 = L10 * ( n1 * h1 * N.z)
E11 = L11 * [ n1 * h1 * (-N.x)]
E2 − 2 = L2 − 2 * [ n2 * h2 * (N.x * N.y)]
E2 −1 = L2 −1 * [ n2 * h2 * (-N.y * N.z)]
E20 = L20 * [ n3 * h2 * (3 * N.z * N.z - 1)]
E21 = L21 * [ n2 * h2 * (-N.x * N.z)]
E22 = L22 * { n4 * h2 * [(N.x * N.x) (N.y * N.y)]}
Then diffuse( p ) =

¦E

lm

( p)

float3 vDiffuse;
vDiffuse = x1+x2+x3;

4.2 Environment Map-based Specular Lighting
for adding :
This part of the calculation is also done in hardware.
For this, we get a vector from the eye position to each
point. From this vector, we compute a reflected vector.
This represents a perfect mirror reflection. In order to
simulate glossy reflection, rather than mirror reflection,
we also create another random vector within a cone
centered around the mirror reflection vector. Based on
this reflected vector, using the environment map as a
texture, we index into the texture map and get a color
value vSpecular as the incident light in that direction.
Then we calculate a fresnel term F to determine how
much light is reflected, assuming that the rest is absorbed
by the object (cf. Fig. 1)

F=

( g − c )2
( g + c) 2

ª (c( g + c ) − 1)2 º
«1 + (c( g − c) + 1)2 »
¬
¼

Proceedings of the International Conference on Computer Graphics, Imaging and Visualisation (CGIV'06)
0-7695-2606-3/06 $20.00 © 2006

Where c = ( E • H )

implemented our environment lighting computations
described above using vertex and fragment shaders for
efficiency. We have replaced PointShop3D’s EWAGLRenderer, a hardware renderer which uses the standard
Phong lighting model in its shader. Fig. 2 shows a
comparison of two images rendered using PointShop3D;
the first is by using the standard lighting model and the
second is by environment lighting.

g = n2 + c 2 − 1
n is the index of refraction.

Figure 1: Specular Reflection H = (L + E) / 2

Lastly we compute a value for the distribution term D3
given by:
2
ª
º
c3
D3 = « 2
»
2
¬ cos α (c3 − 1) + 1¼

2

where cos Į = dot(N, H), and c3 denotes shininess (0 for
perfect reflection and 1 for total diffuse reflection)
We are now ready to compose diffuse and specular
lighting components together. For example, using Kd =
0.8, Ks = 0.2.
Final_Color=Kd*vDiffuse + Ks*vSpecular*F*D3;
The GPU implementation of the specular lighting
component is distributed between the vertex shader and
the fragment shader programs as follows. First in vertex
shader, we connect camera position with each vertex to
form a view direction. From the view direction and the
vertex’s normal, we can get a mirror reflection direction
and perturb it randomly as described above to obtain the
reflected vector. Using this reflected vector, we get a
corresponding 2D texture coordinate. We then output
this 2D coordinate to fragment shader of the same
rendering pass. Secondly, in vertex shader, we also
calculate the fresnel term and distribution term based on
the 3 vectors (view direction, reflected vector, normal).
We save these F and D3 scalar values and output them to
fragment shader too.
In fragment shader, based on the 2D texture coordinate,
we do texture mapping to get a color, then multiply this
color by F and D3 in order to get the final value for the
specular lighting component. This is then composed with
the diffuse component to get the final color for the point.

5. Implementation Results
PointShop3D [16] is a public domain system for
interactive shape and appearance editing of 3D pointsampled geometry. PointShop3D encourages developer
to create their own plug-in components. We have

Figure 2: Standard Lighting (top), Environment Lighting (middle) and
the Environment Map used (bottom)

Figures 3-4 show two point models rendered using
environment lighting under different lighting conditions
and material property settings. We are able to render all
these models at interactive frames rates varying between
25 and 50 frames a second. As future work we are
working on animated lighting and on integrating textures
into this environment lighting.

Proceedings of the International Conference on Computer Graphics, Imaging and Visualisation (CGIV'06)
0-7695-2606-3/06 $20.00 © 2006

References:
[1] G. Schaufler and H. Jensen. Ray tracing point
sampled geometry. Rendering Techniques 2000.

Figure 3: Images rendered with increasing glossiness.

Figure 4: Model rendered with different environment.

Acknowledgements:
This work was supported in part by NSERC Discovery
Grant Program and ENCS Faculty Research Support
Grant, Concordia University. We thank Paul Debevec for
providing light probes. (http://www.debevec.org). 3D
models were downloaded from Stanford 3D Scanning
Repository. We gratefully acknowledge software source
from PointShop3D which was modified for our purposes.

[2] A. Adamson and M. Alexa. Ray tracing point set surfaces.
Proceedings of Shape Modeling International 2003
[3] A. Adamson, M. Alexa and Andrew Nealen. Adaptive
sampling of intersectable models exploiting image and objectspace coherence. SI3D 2005. pages 171-178
[4] I. Wald and H. Seidel. Interactive ray tracing of point based
models. Proceedings of 2005 symposium on Point Based
Graphics
[5] B. Adams, R. Keiser, M. Pauly, L. Guibas, M. Gross, and P.
Dutre. Efficient Raytracing of deforming point-sampled
surfaces. Proceedings of the 2005 Eurographics conference
[6] Y. Dobashi, T. Yamamoto and T. Nishita, T. Radiosity for
point-sampled geometry: 12th Pacific Conference on Computer
Graphics and Applications 2004.
[7] M. Wicke, M. Teschner and M. Gross CSG Tree Rendering
for Point-Sampled Objects. Proceedings of the Computer
Graphics and Applications 2004.
[8] R. Ramamoothi and P. Hanrahan. An efficient
representation for irradiance environment maps. SIGGRAPH
2001
[9] R. Ramamoorthi and P. Hanrahan. The relationship between
radiance and irradiance: Determining the illumination from
images of a convex lambertian object. Journal of the Optical
Society of America, 2001
[10] W. Heidrich and H. Seidel. View-independent
environment Proceedings of the 1998 workshop on Graphics
hardware
[11] W. Heidrich, and H. Seidel Realistic, Hardwareaccelerated Shading and Lighting. SIGGRAPH 1999
[12] J. Kautz and M. McCool. Approximation of Glossy
Reflection with Prefiltered Environment Maps. Graphics
Interface 2000
[13] J. Blinn and M. Newell. Texture and reflection in
computer generated images. Communications of the ACM
1976
[14 G. .Miller And C. Hoffman. Illumination and reflection
maps: Simulated objects in simulated and real environments.
SIGGRAPH 84
[15] T. MacRobert. Spherical harmonics. Dover publications.
[16] M. Zwicker, M. Pauly, O. Knoll, and M. Gross. Pointshop
3D: An interactive system for Point-based surface editing
SIGGRAPH 2002
[17] M. Zwicker, J. Räsänen, M. Botsch, C. Dachsbacher, M.
Pauly. Perspective accurate splatting. Graphics Interface 2004
[18] H. Pfister, M. Zwicker, J. van Baar, and M. Gross. Surfels:
Surface elements as rendering primitives. SIGGRAPH 2000
[19] A. Kalaiah and A. Varshney. Modeling and rendering
points with local geometry. IEEE Transactions on
Visualizaition and Computer Graphics 2002.
[20] M. Zwicker, H. Pfister, J. van Baar, and M. Gross. Surface
splatting. SIGGRAPH 2001
[21] R. Cook and K. Torrance. A reflectance model for
computer graphics ACM Transactions on Graphics 1982.
[22] S. Bhakar, L. Luo, and S. Mudur. View Dependent
Stochastic Sampling for Efficient Rendering of Point Sampled
Surfaces. Journal of WSCG 2004.
[23] P. Pike and J. Sloan. Efficient Evaluation of Irradiance
Environment Maps. In Book ShaderX2, shader programming
tips & tricks with DirectX 9
[24] M. Pauly, R. Keiser, L. Kobbelt, M. Gross. Shape
Modeling with Point-Sampled Geometry ACM SIGGRAPH
2003

Proceedings of the International Conference on Computer Graphics, Imaging and Visualisation (CGIV'06)
0-7695-2606-3/06 $20.00 © 2006

