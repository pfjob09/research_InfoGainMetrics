Elastic Local Reconstruction for Human Face Recognition
Xudong Xie and Kin-Man Lam
Centre for Multimedia Signal Processing, Department of Electronic and Information Engineering,
The Hong Kong Polytechnic University, Hong Kong
{enxdxie, enkmlam}@eie.polyu.edu.hk
Abstract

face recognition. ELR considers the human face
manifold structure, and is therefore robust to a number of
image variations. Compared to other methods, such as
LDA [3] or LPP [4], our method only requires one image
per subject in the database, which is very useful for real
applications, and it can tackle different kinds of image
variations at the same time. In addition, our algorithm
does not require building the face manifold, so it is timeefficient. We evaluate the performance of our proposed
algorithm for face recognition based on the different
databases. Consistent and promising experimental results
were obtained, which show that our method can greatly
improve the recognition performances under all
conditions.

In this paper, a new face recognition algorithm
based on a single frontal-view image for each face
subject is proposed, which considers the effect of the face
manifold structure. A human face is considered a
combination of a sequence of local image blocks. Then
an elastic local reconstruction (ELR) method is proposed
to measure the similarities between the image block
pairs in order to measure the difference between the two
face images. Our algorithm not only benefits from the
face manifold structure, in terms of being robust to
various image variations, but also is computationally
simple because there is no need to build the face
manifold. We evaluate the performance of our proposed
face recognition algorithm with the use of different
databases and consistent and promising experimental
results were obtained.

2. Face Recognition Using Elastic Local
Reconstruction

1. Introduction

2.1. The Manifold Structure of Human Faces

Over the last decade, human face recognition has
received significant attention, which has created a wide
range of commercial and law enforcement applications
[1], such as criminal identification, credit card
verification, security systems, scene surveillance, etc. A
practical face recognition algorithm should be robust to
the image variations caused by illumination conditions,
facial expressions, poses or perspectives, aging, and
some other factors such as make-up, hairstyles or glasses.
Because the variations caused by different conditions
disturb an image in different ways [2], most existing face
recognition methods encounter difficulties in cases of a
number of large variations, especially when only one
upright frontal image is available for each person in the
database and the training images are under even
illumination and a neutral facial expression.
In this paper, we aim to take the effect of face
manifold structure into account for face recognition.
Facial images can be considered a combination of a
sequence of local image blocks. The image blocks of an
image in the database are transformed according to the
corresponding image blocks of a query facial image. An
elastic local reconstruction (ELR) method is then
proposed to measure the similarities between a local
image block pair, and the reconstruction error is used for

In computer graphics applications, a human face is
treated as a combination of a sequence of small and flat
facets, which can be determined by important facial
feature points, i.e.
(1)
F
f ,



i

i 1,.., N

where F is a facial image, fi is a small, local image block
or a facet, and N is the number of blocks. These blocks
should satisfy the following condition:
(2)
fi  f j  ,
where i z j. Figure 1 shows a face image overlaid by an
updated version of the CANDIDE model [5], which is
composed of a sequence of triangular facets.

Figure 1 A human face image with its
corresponding CANDIDE-3 model overlaid.

This work was supported by a research grant from The Hong Kong
Polytechnic University, Hong Kong (Project No. A-PG61).

Proceedings of the International Conference on Computer Graphics, Imaging and Visualisation (CGIV'06)
0-7695-2606-3/06 $20.00 © 2006

Xie et al. [6] proved that, for each image block, the
effect of uneven lighting can be modeled by a first-order
function as follows:
(3)
fi1(x, y) = aifi(x, y) + bi,

where mi is the number of pixels within the image block
i. Let us denote
G c [ f ic( x0 , y 0 )  f ic( xk , y k )  f ic( xmi 1 , y mi 1 )]T , and

where fi(x, y)  fi, fi1(x, y)  fi1, fi is an image block
under normal lighting condition, fi1 is the corresponding
image block under a particular illumination, and ai and bi
denote the multiplicative noise and the additive noise,
respectively. The values of ai and bi are constant within
the image block under consideration, and are determined
only by the surface normal direction of the image block
and its illumination conditions. Considering that the
value of bi is very small (close to zero) [6], (3) can be
written as
(4)
fi1 = Li ( fi ), i = 1,…, N,
where Li is a linear operator with the coefficients ai and
bi.
Facial expressions are generated by contractions of
the facial muscles, which result in the deformation of
facial features such as the eyelids, eyebrows, nose and
lips, and also in changes to their relative positions.
Therefore, we can deform and move the image blocks at
different positions of a face image, which is under a
neutral facial expression, to construct a face image with
non-neutral expression. Suppose the block size is so
small that the image block can be considered a rigid
object. Therefore, only translation and rotation are to be
considered, i.e.
(5)
fi2 = Ti (Ri ( fi ) ), i = 1,…,N,

G

where Ti and Ri are a translation and a rotation operator,
respectively, for the ith image block, and fi2 represents an
image block of the image with a facial expression.
From (1), (4) and (5), we can see that the following
equation can be used to model the combined effect of
illumination and expression variations for the
construction of a face under an arbitrary lighting
condition and facial expression as follows:
(6)
Fc
fc ,



i

i 1,.., N

fic = Ti (Ri (Li ( fi ) ).

where

(7)

Different combinations of {Li, Ri, Ti}, where i = 1,…, N,
will result in different constructed face images.
Therefore, in our algorithm, an elastic local
reconstruction method is proposed to measure the
similarity between two image blocks without building
the face manifold so as to reduce the computational
complexity, and the reconstruction error is used as a
distance measure for face recognition.

2.2. Elastic Local Image Block Reconstruction
Firstly we consider only the effect of varying
illumination. From (3), we have
ª f ic x0 , y0 
«

«
« fic xk , yk 
«

«
« c
,y
x
¬« fi mi 1 mi 1





º
»
»
»
»
»
»
¼»

ª f i  x0 , y0 
«

«
« f i  xk , yk 
«

«
«
,y
f
x
¬« i mi 1 mi 1





1º
»
»
a
1» «ª i »º ,
» ¬ bi ¼
»
»
1»
¼

ª f i  x0 , y0  
«
«¬

1



1



T

a
then we have G c G ª i º .
(9)
«b »
¬ i¼
Therefore, the least-squared solution can give the
optimal values of ai and bi,

ª aˆi º
«ˆ»
¬« bi ¼»

G G 
T

1

GT Gc .

(10)

In order to satisfy the condition that G is of full rank, a
small perturbation is added to all the diagonal values of
G, i.e.
G = G + įI,
(11)
-3
where I is an identity matrix and į = 10 . From (3) and
(10), the reconstructed image block can be obtained as
follows:
fˆi c xk , yk  aˆi f i  xk , yk   bˆi , k 0, 1, .., mi  1 . (12)
Then we can compute the reconstruction mean-squared
error for the block i as follows:

¦

ei1

k 0,1,..mi 1

 f c x , y   fˆ c x , y 
i

k

k

i

k

2

k

.

(13)

mi

This error measures the efficiency of using fi to
reconstruct f ic under varying lighting conditions. The
smaller the value of ei1 is, the more similar the query
image block f ic and the reconstructed block fˆic is, and
the more possible it is that f ic can be derived from fi.
After this procedure, the effect of uneven illuminations
can be reduced.
Next, we consider the rotation operation. Because
the rotation angle is unknown, instead of rebuilding f ic
by rotating fi with different angles, which is very
computational, we directly compare their ranked pixel
values. For the image block fi, its pixel values gi(k) are
ranked in ascending (or descending) order, i.e.
gi = rank(fi) =[gi(0),···, gi(k), ···, gi(mi - 1)]T,

(14)

where gi(0)  ···  gi(k) ··· gi(mi 1). Similarly, pixels
of f ic are ranked in the same manner, i.e.
gi’ = rank( f ic ) =[gi’(0),···, gi’(k), ···, gi’(mi - 1)]T, (15)
where gi’(0)  ···  gi’(k) ··· gi’(mi 1). Then, we
define

¦  gc  k   g  k 
i

ei 2

(8)



f i xmi 1 , ymi 1 º
» ,
»¼
1

f i  xk , yk  

i

k 0,1,.. mi 1

2

.

(16)

mi

Because the ranked values do not contain any spatial
information, they are insensitive to the rotation
operations. ei2 can be considered a similarity measure of
two image blocks after eliminating the effect of rotation.

Proceedings of the International Conference on Computer Graphics, Imaging and Visualisation (CGIV'06)
0-7695-2606-3/06 $20.00 © 2006

Finally, we consider the fact that the two image
blocks to be compared may not be in exactly the same
position due to local distortions. In most cases, the shape
variations caused by expressions are not large, so we can
reduce the effect by translating the image blocks within
their neighborhoods when ei1 and ei2 are being measured.
For a real face recognition application, the
illumination variation and shape variation may occur at
the same time (as shown in (7)), and so are difficult to
separate. Combining (13) and (16), an elastic local
reconstruction (ELR) method is proposed for comparing
two image blocks. Define
(17)
ei = (1 – ȕ)· ei1 + ȕ· ei2,
where ei1 represents the reconstruction error after
eliminating the effect of illumination, ei2 denotes the
reconstruction error independent of rotation, and ȕ is a
weighting factor. In order to reduce the effect of local
translation, for each query image block f ic , the matching
is performed within its neighborhood in the target image,
and the minimum reconstruction error ei is then used for
face discrimination.

In Section 2.2, (17) provides a similarity measure for
comparing two image blocks. However, if the lighting
variations are large, ei2 will be large and unreliable. In
other words, when the variations are dominated by
varying lightings, we should not consider the effect of
rotation any more, and directly use ei1 instead of ei to
perform the elastic matching. Therefore, we should
evaluate the illumination condition of the query image
first and then judge how to compute the reconstruction
errors between two images.
Define

¦  f c x , y   f  x , y  
k

k

i

k

k

k 0,1,..mi 1

ei 3

2

.

(18)

mi

Comparing with (13), we can see that ei1 denotes the
reconstruction error after the effect of illuminations is
reduced, while ei3 represents the mean-squared error
based on two original image blocks. Therefore, the
difference between these two errors can be used to
evaluate the lighting conditions. Because the effect of
lighting varies with the position of the blocks considered,
a ratio is defined as follows:
K
e  ª1  D  m  x , y  º
e  ª1  D  m  x , y  º ,(19)

¦
i

i3

¬

i

¼

i

¦
i

i1

¬

i

i

¼

where (xi, yi) is the central point of the block i, and
m(xi,yi) is the corresponding eigenmask value [7], which
is used to represent the importance of different facial
positions, and D is a weighting factor.
If Ș>Ș0, we consider only the reconstruction error
caused by the illumination and translation, and the
average reconstruction error between two images is
computed by
(20)
E
min  e   ª1  D  m  x , y  º N ;

¦

i 1,.., N

'x , 'y

i1

¬

i

E

¦

i 1,.., N

min ¬ª1  E   ei1  E  ei 2 ¼º  ¬ª1  D  m  xi , yi ¼º N . (21)
'x , 'y

Therefore, E can be used to evaluate the similarity
between two images and search the best matching in a
face database.
In our algorithm, we consider a sequence of feature
points located at the nodes of a 21u21 grid with the
image size of 64u64. An image block of size aua
centered at each of the feature points is formed. When
performing elastic matching, the searching is within a
bub range. The values of the parameters a and b are
adapted to the local statistical property of the query
image block. For example, if the variance of the input
block is larger than İ, which means more textures exist,
we should consider a smaller image block and a larger
searching range, i.e. a=3 and b=5, otherwise, a=5 and
b=3. The optimal parameters are obtained based on the
Yale database, where Ș0 = 5.5, Į = 2, ȕ = 0.02 and İ = 25.
This set of parameters will then be applied to other
databases.

3. Experimental Results

2.3. Face Recognition Using ELR

i

otherwise,

i

¼

In this section, we will evaluate the performances of
the proposed elastic local reconstruction algorithm for
face recognition based on different face databases. The
databases used include the Yale database, the AR
database, the YaleB database, the PIE database, the
Caltech database and the JAFFE database. The number
of distinct subjects and the number of testing images in
the respective databases are tabulated in Table 1.
TABLE 1 THE TEST DATABASES USED IN THE EXPERIMENTS.
Yale

YaleB

AR

PIE Caltech JAFFE

Number of subjects

15

10

121

68

26

10

Number of test
images

150

640

605

1768

417

203

The face images in different databases are captured
under different conditions, as shown in Figure 2, such as
various lighting conditions, facial expressions,
perspectives, etc. In each database, one frontal image of
each subject with normal illumination and neutral
expression is selected as a training sample, and the rest
form the testing set. All images are cropped to a size of
64u64 based on the eye locations. To enhance the global
contrast of the images and reduce the effect of uneven
illuminations, histogram equalization is applied to all the
images.

Figure 2 Some cropped images in different databases.

Proceedings of the International Conference on Computer Graphics, Imaging and Visualisation (CGIV'06)
0-7695-2606-3/06 $20.00 © 2006

The performances of our proposed ELR algorithm
are evaluated and compared with the PCA, Gabor
wavelets (GW) [8], and elastic graph matching (EGM)
[9]. PCA can preserve the global structure of the image
space, while the GW and EGM adopt the local
information about images. For PCA, all the eigenfaces
available for each database are used, i.e. at most M1,
where M is the total number of training samples. In other
words, 100% of the variance is kept. The GW employs
two sets of parameters: GW3 denotes the use of three
center frequencies, i.e. ʌ/2, 2S 4 and ʌ/4, and eight
orientations, i.e. from 0 to 7ʌ/8 in steps of ʌ/8, while
GW5 represents the use of two additional center
frequencies
2S 8 and ʌ/8. The Gabor wavelets
representations are concatenated to form a highdimensional vector, which is used directly to compute
the distance between two images pixel by pixel.
Similarly, the number of center frequencies and
orientations of the Gabor wavelets used in EGM are five
and eight, respectively, while the dimension of the elastic
graph is 6u8.
The respective performances of the abovementioned
face recognition methods based on the different
databases are shown in Table 2. From the result, we can
see that our proposed ELR can always achieve optimal
results, and the performance is consistently higher than
97.1%. GW performs better than PCA and EGM for all
cases due to its characteristic of capturing salient visual
properties such as spatial localization, orientation
selectivity, and spatial frequency [10]. However, we
should notice that the performance of GW5 degrades
greatly compared with GW3 for the YaleB database. This
is because for a Gabor filter with a higher center
frequency (scale), the standard deviation of the Gaussian
function used, ı, is enlarged [8], which means the
extracted Gabor features are more easily disturbed by
large illumination variations, e.g. the unreliable edges or
shadows.
TABLE 2. FACE RECOGNITION RESULTS BASED ON DIFFERENT
DATABASES.
Recognition
Rate (%)

PCA

GW3

GW5

EGM

ELR

Yale

84.0

82.0

85.3

70.7

98.7

YaleB

65.0

94.1

89.2

73.4

99.7

AR

83.6

95.9

98.0

86.3

98.8

PIE

98.9

99.4

99.7

97.1

99.8

Caltech

77.9

92.3

92.6

89.2

97.1

JAFFE

93.1

94.6

97.0

87.7

97.5

4. Conclusions
In this paper, we consider the face manifold
structure when we compare face images captured under
arbitrary conditions. A human face can be considered a

combination of local image blocks. The illumination
effect based on each image block can be modeled by a
linear operation, while the expression variations are
described using translation and rotation operations.
Therefore, an elastic and local reconstruction method is
proposed for comparing image blocks, which can handle
a range of variations from different sources, especially
for the variations caused by illuminations and
expressions. Our method requires only a single face
image under frontal lighting and with neutral expression
for training. In addition, our algorithm does not have to
estimate the face surface normals and light source
directions, which is usually not an easy task; nor does it
have to assume that different people have the same
surface normal and different albedo, where this
assumption cannot be satisfied in cases of expression
variation. Furthermore, our method does not need to
perform image warping to obtain a shape-free image,
where the positions of the feature points are difficult to
detect accurately, especially when a face is under a poor
lighting condition and has various expressions.
The experimental results show that the ELR
algorithm not only achieves consistent and convincing
performances for cases of varying illumination or
expression, but also can improve the performance in
cases of perspective variations and with the existence of
spectacles and occlusions.

References
[1] W. Zhao, R. Chellappa, P.J. Phillips, and A. Rosenfeld,
Face Recognition: A Literature Survey, ACM Computing
Survey, vol. 35, no. 4, pp. 399-458, 2003.
[2] Y. Adini, Y. Moses, and S. Ullman, Face Recognition:
The Problem of Compensating for Changes in Illumination
Direction, IEEE Trans. Pattern Anal. Machine Intell., vol. 19,
no. 7, pp. 721-732, 1997.
[3] P.N. Belhumeur, J.P. Hespanha, and D.J. Kriegman,
Eigenfaces vs. Fisherfaces: Recognition Using Class Specific
Linear Projection, IEEE Trans. Pattern Anal. Machine Intell.,
vol. 19, no. 7, pp. 711-720, 1997.
[4] X. He, S. Yan, Y. Hu, P. Niyogi and H.-J. Zhang, Face
Recognition Using Laplacianfaces, IEEE Trans. Pattern Anal.
Machine Intell., vol. 27, no. 3, pp. 328-340, 2005.
[5] J. Ahlberg, CANDIDE-3 - Un Updated Parameterised
Face, Report No. LiTH-ISY-R-2326, 2001.
[6] X. Xie and K.M. Lam, An Efficient Illumination
Normalization Method for Face Recognition, Pattern
Recognition Letters, vol. 27, no. 6, pp. 609-617, 2006.
[7] K.H. Lin, K.M. Lam and W.C. Siu, Spatially EigenWeighted Hausdorff Distances for Human Face Recognition,
Pattern Recognition, vol. 36, no. 8, pp 1827-1834, 2003.
[8] D. Liu, K.M. Lam, and L.S. Shen, Optimal Sampling of
Gabor Features for Face Recognition, Pattern Recognition
Letters, vol. 25, no. 2, pp. 267-276, 2004.
[9] M. Lades, J.C. Vorbruggen, J. Buhmann, J. Lange, C.V.D.
Malsburg, R.P. Wurtz and W. Konen, Distortion Invariant
Object Recognition in the Dynamic Link Architecture, IEEE
Trans. Computers, vol. 42, no. 3, pp. 300-311, 1993.
[10] C. Liu and H. Wechsler, “Independent Component
Analysis of Gabor Features for Face Recognition,” IEEE
Trans. Neural Networks, vol. 14, no. 4, pp. 919-928, 2003.

Proceedings of the International Conference on Computer Graphics, Imaging and Visualisation (CGIV'06)
0-7695-2606-3/06 $20.00 © 2006

