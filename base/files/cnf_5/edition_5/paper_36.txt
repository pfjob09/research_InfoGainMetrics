A TWO-PASS IMPROVED ENCODING SCHEME FOR
FRACTAL IMAGE COMPRESSION
Kin-Wah Ching Eugene and Ghim-Hwee Ong
School of Computing, National University of Singapore
Republic of Singapore
onggh@comp.nus.edu.sg
Abstract
An improvement scheme, so named the Two-Pass Improved
Encoding Scheme (TIES), for the application to image compression
through the extension of the existing concept of Fractal Image
Compression (FIC), which capitalizes on the self-similarity within a
given image to be compressed, is proposed in this paper. We first
briefly explore the existing image compression technology based on
FIC, before proceeding to establish the concept behind the TIES
algorithm. We then devise an effective encoding and decoding
algorithm for the implementation of TIES through the consideration
of the domain pool of an image, domain block transformation,
scaling and intensity variation, range block approximation using
linear combinations, and finally the use of an arithmetic
compression algorithm to store the final data as close to source
entropy as possible. We then conclude by explicitly comparing the
performance of this implementation of the TIES algorithm against
that of FIC under the same conditions, in which the TIES algorithm
exhibits significantly better compression performance for large
images (1024x1024px) compared to the FIC algorithm.

1. Introduction
1.1. Fractal Image Compression (FIC)
Fractal image compression is a lossy compression technique
proposed in the 1980s by M. Barnsley [1-3]. The technique is based
on the observation that since fractals can generate relatively realistic
images, then, it should be possible to store a given image in the form
of just a few basic fractal patterns, coupled with the specification of
how to restore the image using those fractals. The FIC algorithm
starts from the complete image, and breaks down that image into a
number of partitions. For each given partition Pi, the algorithm then
searches the image for other sub-sections of the image, Sj, which are
relatively similar to Pi, and then maps Pi to Sj, until a mapping for
every sub-section of the image has been found. The compressed
image would then consist of all the partitions Pi, and their
corresponding mappings. In FIC terminology, Pi is called a domain
block, and the corresponding set of partitions is called the domain
pool, while Sj is called a range block, and the corresponding set of
sub-sections is called the range pool.

1.2. An Improvement Scheme to FIC
This paper proposes an improvement scheme which is based
in part on the earlier described FIC algorithm, which will reduce the

overall size of a compressed image as compared to that of FIC
under similar conditions [3]. This scheme will, in fact, make
extensive of use the FIC algorithm for partitioning a given image
into range blocks (sub-images of the original image) and extracting
the domain pool by finding a suitable mapping to approximate the
range blocks from the domain blocks. However, we note that FIC
searches for the best match between a range block and a domain
block, and then proceeds to store that mapping of the range block to
the domain block. In other words, FIC produces a one-to-one
mapping for every range block from a set of domain blocks. This
has two consequences. Firstly, the domain to range mapping is the
best for a one-to-one mapping, but would it be possible that a linear
combination of domain blocks might result in a better
approximation of that range block? If so, then image quality can be
increased without increasing the size of the domain pool. In
addition, by using linear combinations of domain blocks to
approximate the range blocks, it also becomes possible to reduce the
size of the domain pool should some of the domain blocks now be
made redundant. This is similar to the idea of using a resultant
vector to represent a linear combination of vectors in the technique
of matching pursuit [4]. Secondly, can the size of the domain pool
be reduced if we search for similar domain blocks within the
domain pool itself?
Indeed, both of these are possible, and this paper proposes an
extension and improvement to the original FIC algorithm by
capitalizing on these two observations to improve compression
performance. However, it is worthwhile to note that while the idea
behind searching for linear combinations of domain blocks instead
of simply using one-to-one mappings of domain blocks to range
blocks seems simple, determining what is considered the best linear
combination is extremely computationally expensive, as the
algorithm would have to search through all possible linear
combinations of varying sizes. Thus, this paper will also propose a
simple and effective algorithm to searching for such linear
combinations.

2. The Proposed Algorithm
2.1. Introduction
The proposed algorithm is a two-pass scheme, whereby the
first-pass involves extracting the domain pool (as in the original FIC
algorithm), and the second-pass involves utilizing that extracted
domain pool to achieve the maximum compression. Due to its twopass nature, the proposed algorithm is thus named as a “Two-Pass
Improvement Encoding Scheme” (TIES). The first-pass of the TIES

Proceedings of the International Conference on Computer Graphics, Imaging and Visualisation (CGIV'06)
0-7695-2606-3/06 $20.00 © 2006

algorithm is straight-forward as it derives directly from the FIC
algorithm. In the second-pass, the TIES algorithm performs:
1. Compression of the Domain Pool
2. Partitioning of the image
3. Searching for the best linear combinations
4. Storage of the results
In the presentation of the TIES algorithm in this paper, a square
grayscale image is assumed in order to provide a simple framework
for the description and implementation of the algorithm. The
algorithm can be extended easily to accommodate non-square
image by first dividing the non-square image into two parts, the
largest possible square Isq1, and the remaining part of the image Ir1,
and then applying the algorithm on Isq1. By recursively applying the
above steps of dividing Ir again into Isq2 and Ir2, it is clear that we
will finally be able to apply the compression algorithm on the entire
image. In addition, the algorithm can also be easily extended to
colour images. Colour images are simply 24-bit images consisting
of the layers: red, green and blue (for RGB images). As such, the
algorithm can be applied to each layer in succession without
modification. Hence, it suffices to describe the algorithm for a
square, grayscale image, for clarity.

2.2. Quad-Tree Partitioning
A simple way to partition an image is simply to break the given
image up into fixed-sized range blocks, Ri. However, such a method
of partitioning has a weakness – there are some parts of an image
where there is less detail (for example, a background scene). Hence,
larger range blocks will suffice to cover that area well. This will, in
turn, reduce the number of domain blocks needed to cover the
image as a whole, as well as the number of domain to range block
mappings, thus achieving better compression. Likewise, there are
also other regions of that same image which are difficult to cover
well using a range block of fixed size. Such regions usually require
smaller range blocks in order to capture the finer detail of that
portion of the image (for example, the eyes of a person).
Hence, to allow for varying range block sizes, quad-tree
partitioning is used in the implementation of the TIES algorithm. In
quad-tree partitioning, a square in the image is sub-divided into four
equally sized squares when it is not well-covered enough by a
domain. The measurement of well-coveredness is determined by the
tolerance factor of the TIES encoder, and will be fully detailed in
Section 3.3. This process repeats recursively starting from the
original image (assumed to be a square as explained above), and
continuing until a given square (the range block) is small enough to
be well-covered by domain block(s). Small squares can be covered
better than large ones because contiguous pixels in an image tend to
be highly correlated [2, 3].

3. The TIES Encoder
3.1. Extracting the Domain Pool
The extraction of the domain pool is similar to the inference
algorithm used by the FIC encoder. The original image is first
divided into a number of overlapping sub-squares called Di of size
2n by 2n, where n = 0, 1, … , log2(size of image). The collection D
of these sub-squares forms the initial set of domain blocks, or the

initial domain pool. Next, the original image is then partitioned,
using quad-tree partitioning, into four equally sized sub-sections Ri
called range blocks. For each Ri, the algorithm tries to find a best
match of Di from D, such that the tolerance criteria is met. If such a
match is found, then a mapping is made between Di and Ri, and Di is
placed into another collection D’, which contains the index of the
corresponding domain block in D chosen during the extraction
process. D’ thus is the set of indices representing the final domain
pool. If a match cannot be found, then Ri is again sub-divided using
quad-tree partitioning into Ri1, Ri2, Ri3 and Ri4, and for each Rij,
where j = 0, 1, 2, 3, the algorithm is again applied. This recursive
process finally terminates when all Ri have a mapping to a certain
Di, and the collection D is the final domain pool.

3.2. Compressing the Domain Pool
Once the domain pool D has been extracted, we then proceed
to compress the domain pool.
The key in this algorithm is to find all domain blocks which are
similar. Two domain blocks, Da and Db, are considered to be similar
if the sum of the square of the difference in pixel values between
corresponding pixels in Da and Db is less than a specified tolerance
T, for all possible 90o rotations and flips applied to Db. This means
that the comparison between Da and Db has to be applied a total of
eight times, four times for each 90o rotation of Db without flipping
Db, and another four times with a horizontal flip applied to Db.
Clearly, when making comparisons between Da and Db, we also
have to ensure that Da and Db are of the same size.

3.3. Searching for the Best Linear Combination
One of the issues in finding the best linear combination (LC) is
the fact that exhaustively searching through all possible
combinations for all possible sizes is computationally expensive,
and hence, doing such an exhaustive search would clearly make the
encoding process excessively long. Hence, this paper will propose
an algorithm that can be implemented simply and efficiently.
The proposed algorithm is implemented by restricting that the
reconstruction of the final range block R from its corresponding
linear combination of domain blocks L = {D1, D2 … Dn} is given by
taking the sum across all elements of L (i.e. R = D1 + D2 + … + Dn).
On each iteration, the algorithm then computes,
n

Remainder = R –

¦D

i

(1)

i 0

and continues to iterate infinitely, each time choosing another
domain block Di+1 from D to add to the previously computed sum
of domain blocks, but only if the addition of the next domain block
will bring the remainder closer to zero. If no such domain block Di+1
can be found, the algorithm terminates for this particular range
block R. In addition, the algorithm will also terminate when the
remainder is less than a tolerance value TLC. Thus, this tolerance
value represents whether a given range block is adequately
represented by its linear combination of domain blocks.
Finally, when performing the comparison between domain
blocks Di+1 to choose the best domain block, the algorithm also
applies two flip transformations, four rotation transformations, and a
number of intensity multipliers on each domain block. Visually, the

Proceedings of the International Conference on Computer Graphics, Imaging and Visualisation (CGIV'06)
0-7695-2606-3/06 $20.00 © 2006

intensity multiplier simply lightens the image associated with the
domain block, such that D’i+1 = I  Di+1, where I is the intensity
multiplier, and D’i+1 is the modified domain block.

3.4. Storage Format
Since the set of domain blocks D’ has been chosen, the original
domain pool D can be further reduced in size to contain only those
blocks which are elements of D’. In other words, we want D = D’.
Hence, we now perform a second level compression of the original
domain pool D to restrict D to elements of D’, and we also adjust
the pointers in D’ such that they point at the correct (changed)
element in D. This hence reduces the size of D. At this point, the
TIES encoder would have obtained:
D:
Compressed domain pool
D’: Set of chosen domain blocks (pointers to D)
F’: Set of corresponding flip transformations used
R’: Set of corresponding rotation transformations used
I’:
Set of corresponding intensity multipliers used
LC’: Set of corresponding number of LC elements
Thus, it is now necessary to obtain an efficient encoding of the
data to minimize the final output file size. First, a minimal bit coding
scheme will be used to pack the data efficiently by observing the
limits on the type of data stored. Secondly, the data will be further
compressed using an arithmetic encoder [5]. Sets F’ and R’ can be
combined into a single set T’ comprising of 3-bit elements. This
allows for more efficient compression during arithmetic coding.
We note that at this point there has been no effort made to store
the coordinates (location) of each range block in the original image.
This omission of the location of each range block is intentional for
the purposes of reducing the size of the compressed data. However,
the location of each range block can be determined, due to the way
in which the data blocks LC’, T’, I’ and D’ are arranged. The
sequence in which the data for LC’, T’, I’ and D’ is written into their
corresponding data blocks is such that they represent, sequentially,
the range blocks from top to bottom, left to right, regardless of the
size of the range block itself. This allows the decoder to correctly
retrieve the locations of each range block. The technique and
corresponding algorithm used in handling the varying sizes of the
range blocks will be described in Section 4.1.
Finally, after D, D’, T’, I’, LC’ have been constructed, a
(block-based) arithmetic coder is used to further compress each
individual data block to achieve maximum possible compression.
In addition, due to the highly independently nature of the
encoding algorithm, in particular the linear combination search
algorithm, it is also possible to construct a parallelized variation of
the algorithm in order to achieve improved performance [6-8].

4. The TIES Decoder
The implementation of the TIES decoder is fairly
straightforward as compared to the encoder, with the only slightly
more challenging task being the means to decode the range block
location based on the encoding format. Essentially, the decoder is
given the task of reading the encoded file, extracting from the five
encoded blocks the matrices (data blocks) and storing them back
into the sets D, D’, T’, I’ and LC’ by implementing an arithmetic
decoder, inferring the range block locations and storing them in sets

Rx and Ry, and finally reassembling the final image using the
information stored in the above seven matrices. The matrices are
identical to the ones obtained during the encoding process and are
given by D, D’, T’, I’ and LC’.
Once the decoder has obtained the final image in terms of raw
pixel values, the decoder then performs post-processing and
smoothing to remove any blocking artifacts found due to the
partitioning of the image into discrete range blocks during the
encoding phase, as well as to visually enhance the image. Upon
completion of the post-processing, the image is written to an output
file in BMP format.

4.1. Decoding the Encoded Data
Before the image can be restored, we first need to use an
arithmetic decoder to decode the data into the above-described 5
matrices. After which, we will be ready to fully decode the data.
However, before we describe the other aspects of the TIES decoder,
it is necessary to establish the algorithm for uniquely inferring the
location of each range block from the encoded file.
In general, the corresponding information for each range block
is stored in LC’, T’, I’ and D’ in a top to bottom, right to left
fashion, regardless of the size of the range block. However, we do
know the size of the particular range block since the size is stored in
LC’ as well. As such, an example of the decoding of range blocks
can be graphically represented as follows:

Figure 4.1 Example of range blocks of different sizes
In order to determine the location, given by (Ri,x, Ri,y), we first
start with a two-dimensional helper matrix, of size equal to the size
of the original image, and whose elements are all initialized to 0. We
denote this helper matrix as used. In addition, we need to know the
size of the smallest range block (stored in the header of the encoded
file).
When we decode a range block, we obtain the corresponding
size of that range block, and proceed to mark out all the pixels
“occupied” by that range block in the used matrix. We then proceed
to decode the next range block. The position of the next range block
will be to the immediate right of the previously decoded range
block. In other words, its horizontal position is the same as that of
the previous range block, while its vertical position is given by the
first unused pixel in the used matrix. If the rightmost end of the
matrix is reached, we then move the vertical pointer down by the
size of the smallest range block, and proceed to find the first unused
pixel in the used matrix. As such, we are able to obtain the location
of each range block (Ri,x, Ri,y).The positions of each range block are
stored in matrices Rx and Ry.

Proceedings of the International Conference on Computer Graphics, Imaging and Visualisation (CGIV'06)
0-7695-2606-3/06 $20.00 © 2006

4.2. Reconstructing the Image
With the seven matrices D, D’, T’, I’, LC’, Rx and Ry, the
decoder now has sufficient information to reconstruct the image.
For each range block, the decoder obtains:
1. The (x, y) location of the range block (from Rx, Ry)
2. The number of linear combination elements used for that
range block (from LC’)
3. The pointers to the domain blocks in D (from D’)
4. The transformations used on each domain block (from T’
and I’)
and regenerates each range block. Finally, with the reconstructed
image, the decoder writes the data out in BMP format. The
decoding is complete.

In this section, the compression performance of the TIES
encoder in comparison to the FIC encoder is examined. In Figure
6.1 below, the graph of compression performance vs. PSNR is
shown for the Lena image. The compression performance for the
remaining images are given in Tables 6.1(a) & (b), and 6.2. In this
analysis, compression is defined as percentage savings, given by:
Percentage Savings =
Size of original image - Size of compressed image

(3)

u 100%

Size of original image

Graph of Compression Performance (y-axis) vs. Image Size (x-axis)
for Lena Image
128 x 128 px
256 x 256 px
512 x 512 px
1024 x 1024 px
85

90

85

80

5. The PSNR Metric
In measuring the compression performance of the TIES
algorithm, as well as that of the FIC algorithm, it is useful of have a
precise and formal method of measuring image quality, rather than
relying purely of visual inspection of the final decoded image. The
ideal metric is certainly the one which can differentiate between
visible image impairment and negligible image impairment.
However, such a metric is hard to achieve. Hence, for the purpose
of measuring image quality vs. compression ratios, this paper makes
use of the peak signal-to-noise ratio (PSNR) as a representative of
image quality. The PSNR is defined as follows:

40
25

32

62
27

34

70
32

37

76
35

41

Figure 6.1 Compression Performance of TIES (thick) vs. FIC (thin)
Table 6.1(a) Compression: Size of large (1024x1024px) compressed file
using TIES and FIC encoders for remaining images
Images of Size 128 x 128 px (+: high PSNR, -: low PSNR)
Boat
Bike
Plant
Lady
Sky
–
+
–
+
–
+
–
+
–
+
PSNR
FIC
54 81.4 81.3 57.6 81.3 53.6 82.3 53.7 - 81.7
TIES 44.8 62 63.2 40.1 61 34.8 61.2 32.9 97.8 -

total pixels

¦
PSNR = – 20 log

imagea , p  imageb , p

p 0

total pixels u 255

dB. (2)

6. Results and Discussions
In evaluating the performance of the TIES encoder, an
empirical analysis was carried out on six grayscale test images.
These test images were chosen as representatives of certain broad
classifications of image types, which include human subjects, manmade objects, natural scenery and combinations of the above
mentioned types. During the empirical analysis, two separate
encodings, one by the TIES encoder, and the other by the FIC
encoder [3], were performed on a total of four different image sizes
– 128x128px, 256x256px, 512x512px and 1024x1024px – for each
of the six test images. In addition, the parameters used in the TIES
encoder are: minimum quad-tree depth of 2, maximum quad-tree
depth of 6 to 10, the tolerance value before requiring further quadtree partitioning as 30, maximum number of linear combination
elements as 4. The reason for this is that statistically, such settings
appear to produce a suitable balance between image quality and
image compression. The test images used are:

Lena (1)

Boat (2)

Bike (3)

Plant (4) Lady (5)

6.1. Compression Performance of TIES vs. FIC

Sky (6)

Table 6.1(b) Compression: Size of small (128x128px) compressed file
using TIES and FIC encoders for remaining images
Images of Size 1024 x 1024 px (+: high PSNR, -: low PSNR)
Boat
Bike
Plant
Lady
Sky
–
+
–
+
–
+
–
+
–
+
PSNR
FIC
76.6 76.5 76.9 74.4 76.6 75.1 74.6 72.2 - 81.0
TIES 89.7 82.1 88.1 76.1 87.5 77.9 87.7 78.9 91.4 -

From Figure 6.1 and Table 6.1, we observe that with small
images, the compression performance of the FIC encoder is better
than the TIES encoder regardless of image quality (PSNR).
However, when the size of the encoded image increases to
1024x1024px, the TIES encoder consistently produces better
compression ratios compared to the FIC encoder at equal or better
PSNR values. Table 6.2 below summarizes the specific
improvement in compression performance of TIES over FIC for
1024x1024px images.
Table 6.2 Compression Performance Gains for TIES over FIC
for large (1024 x 1024px) images
% Improvement in
PSNR
Compression over FIC
Image
Range, dB
Min
Max
Mean
Lena
37 – 41
6.0
12.5
9.3
Boat
37 – 40
5.5
13.0
6.8
Bike
35 – 37.5
2.5
6.0
5.5
Plant
33 – 37.5
2.5
11.0
8.4
Lady
33 – 37.5
7.0
13.0
10.0

From the table above, we observe that within a given
overlapping range of PSNR values produced by the TIES encoder
and the FIC encoder, the TIES encoder achieves greater savings in

Proceedings of the International Conference on Computer Graphics, Imaging and Visualisation (CGIV'06)
0-7695-2606-3/06 $20.00 © 2006

the range of 2.5 and 13.0% over the FIC encoder. As such, this
paper claims that while the TIES encoder produces smaller savings
on average when compared to FIC for small-sized images, TIES
will outperform FIC as image size is increased. The reason for this
is discussed in Section 6.2.
In the previous analysis, we have excluded a discussion on the
results of the sky image. The reason for this is that the encoding for
this image appears strange. In fact, the resultant encoding based on
the TIES encoder produces extremely high compression ratios (88
to 98%) but poor PSNR values (17 to 19 dB) across all image sizes.
Conversely, the FIC encoder produces high PSNR values (39 to 52
dB) but average compression (80 to 82%). As a result, the TIES
decoded image suffers from severe impairment after being decoded.
Thus, in this case, the TIES encoder failed to perform satisfactorily.
A possible reason for this is discussed in Section 6.2.

6.2. Savings due to Domain Compression (TIES)
In Table 6.3 below, the savings produced by the TIES encoder
due to domain compression (only) is shown for each of the six
individual test images. Mathematically:
Percentage Savings =
Original domain pool size - New domain pool size

(4)

u 100%

Original domain pool size

Table 6.3 Percentage Savings due to Domain Compression
Graph of Percentage Savings (y-axis) vs. Image Size (x-axis)
Lena

Boat

99

Bike

98

98

Plant

98

97

97

96

96

95

95

Lady

98

Sky

98

97

97

96

96

95

95

100

99.5

97

99

96

94
94

94

94
93

95
93

93
98.5

93
92

92

94
92

93

92
100

92

91

200

300

400

500

600

700

800

900

1000

1100

90
100

91

91

200

300

400

500

600

700

800

900

1000

1100

90
100

91

90

200

300

400

500

600

700

800

900

1000

1100

89
100

98

90

200

300

400

500

600

700

800

900

1000

1100

89
100

200

300

400

500

600

700

800

900

1000

1100

97.5
100

200

300

400

500

600

700

800

900

1000

1100

From the graphs above, two observations can be made. Firstly,
for all six images, a reduction in domain pool size is achieved by
compressing the domain pool. Furthermore, from the statistics
captured, it appears that the size of the compressed domain pool is
in the range of 1 to 11% of the size of the original domain pool.
Secondly, we observe that for the test images, generally the
percentage savings due to domain pool compression increases as the
size of the test image increases. As such, this paper suggests that
there is a positive, linear relationship between the size of the original
image and the percentage savings gained due to domain pool
compression. Indeed, an abnormality to this trend can be observed
in the boat image, where it appears that the 512x512px image
resulted in less savings as compared to the smaller 256x256px
image. However, since the domain pool extracted is dependent on
the nature of the image, and since the difference in percentage
savings between the 256x256px image and the 512x512px image is
less than 2%, it is likely that the abnormality is primarily due to
statistical fluctuations of the compressed domain pool, and that the
general trend of the savings due to domain compression is still
linear.
Finally, we observe that for the sky image (6), the percentage
savings achieved is extremely high. However, as described in the
previous section, the PSNR value for this image is extremely low.
Table 6.4 shows size of the original domain pool and the size of the
compressed domain pool for this image.

Table 6.4 Difference between Size of Original and Compressed
Domain Pools
Average Domain Pool Size of
Domain Pool Size of
Images (1) to (5)
Image (6)
Image
Size
Original
Compressed
Original Compressed
(pixels)
%
%
Size
Size
Size
Size
deviation
deviation
128x128 2322
7.81 202
13.09
1098
26
256x256 6742
8.81 488
8.75
4152
32
512x512 20451 6.23 1034 12.41
19389
30
1024x1024 70260 3.93 1204 16.46
65559
11

As can be seen from the table, the size of the compressed
domain pool of the final image is in the order of 10, while the
average size of the compressed domain pool for the first six images
is in the order of 102, one full difference in magnitude. The key
difference between this image and the first six images is the
homogenous nature of this image. This would mean that in the
extracted domain pool, a large number of blocks would be relatively
similar to each other, which causes the TIES encoder to decide that
a large proportion of domain blocks can be made redundant and
thus removed from the domain pool. However, due to this excessive
reduction of the domain pool, the TIES encoder is unable to obtain a
good linear combination from the extremely limited domain pool,
thus resulting in a poor approximation to the original image, hence
the poor PSNR.
In addition, Table 6.4 also illustrates the reason why the TIES
encoder produces significantly better compression ratios compared
to the FIC encoder for large image sizes. As can be seen from Table
6.4, a 128x128px image produces 202 domain blocks after
compression. However, when the image size is quadrupled to
256x256px, the number of domain blocks after compression is only
slightly more than 2.4 times the original number. Furthermore,
when the image is 16 times the size (512x512px), the number of
domain blocks is slightly more than 5 times the original number. As
such, we can see that the rate of growth of domain blocks (after
compression) is much lower than the rate of growth of the image
size. Thus, as image size increases, greater compression can be
achieved. Furthermore, with a larger domain pool (for the larger
image), better image quality (PSNR) can be achieved as the encoder
now has more domain blocks to choose from.

6.3. Savings due to Arithmetic Coding (TIES)
In Table 6.5 below, the savings produced by the TIES encoder
due to arithmetic coding (only) is now shown for each of the six test
images. Mathematically:
Percentage Savings =
(Original size - Compressed size) of data segments

(5)

u 100%

Original size of data segments

Table 6.5 Percentage Savings due to Arithmetic Coding
Graph of Percentage Savings (y-axis) vs. Image Size(x-axis)
Lena

Boat

26

Bike

25

25

Plant

24

Lady

21

21

20

20

19

19

18

18

17

17

16

16

15
100

15
100

Sky
75

23

24

70

22

24

65

23
21

23

60
22

20

22

55

19

21
21

50
18
20

20

45

17
19

19

18
100

200

300

400

500

600

700

800

900

1000

1100

18
100

40

16

200

300

400

500

600

700

800

900

1000

1100

15
100

200

300

400

500

600

700

800

900

1000

1100

200

300

400

500

600

700

800

900

1000

1100

200

300

400

500

600

700

800

900

1000

1100

35
100

200

300

400

500

600

700

800

900

1000

1100

Again, we observe that the empirical results suggest that
savings between the range of 15% to 26% can be achieved by

Proceedings of the International Conference on Computer Graphics, Imaging and Visualisation (CGIV'06)
0-7695-2606-3/06 $20.00 © 2006

encoding the data blocks using an arithmetic coder [5]. In addition,
this paper again suggests that the relationship between the size of the
image being encoded, and the percentage savings achievable due to
arithmetic coding is linear and positively correlated. Indeed, this is
in line with the results of the well-understood arithmetic encoding
algorithm, where data sets whose elements have asymmetric
frequencies can be compressed significantly.

6.4. Encoding and Decoding Times of TIES vs. FIC
In Figure 6.2, the average encoding and decoding time values
for each image size, across all six test images were taken for both
the TIES encoder and the FIC encoder are shown. The horizontal
axis of the graph represents the size of the image being encoded,
while the vertical axis represents the time taken in seconds for the
encoding process to complete.
Encoding Time

Decoding Time
Time (seconds)

Time (seconds)

25000

0
100

1100

7

1
100

1100

Image Size (pixels)
Image Size (pixels)
Figure 6.2 Encoding and Decoding Times of TIES (thick) and FIC (thin)

It can be observed from the figure above that for small images
(256x256px and below), TIES and FIC complete the encoding
process in approximately the same amount of time. However, as the
image size increases, the graph above suggests that the encoding
time for TIES increases much faster than that of FIC. However, this
is to be expected as there usually exists a trade-off between time and
space. Thus in the case of the TIES encoder, increased compression
is achieved at the expense of encoding time. The reason for the
exponential growth in encoding time for the TIES encoder is due to
the complexity of the domain compression linear combination
search algorithms.
In the case of decoding, it can be observed that the decoding
time for TIES is comparable to that of FIC. In this light, we note that
the TIES algorithm, similar to the FIC algorithm, is an asymmetric
encoding/decoding algorithm.

7. Conclusion
This paper has proposed an improvement scheme (Two-Pass
Improved Encoding Scheme) based on the concept of fractal image
compression. In describing the TIES encoder and decoder, three
algorithms are used, which forms to basis of the TIES encoding
algorithm – domain pool compression, best linear combination
search, and block-based arithmetic coding. To exemplify the
workability of TIES, and to demonstrate that under similar
conditions, the TIES algorithm does outperform its FIC counterpart
for large images of the size of 1024x1024 pixels and above, we
have derived a complete implementation of the TIES encoder and
decoder, and obtained empirical results based on six test images.
From the results of the empirical analysis carried out in Section
6, we observed that the TIES encoder produces good results in
terms of gaining additional compression over the FIC encoder for

large images of size 1024x1024px. In addition, there appears to be a
linear relationship between the size of the image encoded and the
savings due to domain pool compression and arithmetic coding.
Based on these observations, this paper thus suggests that there is
indeed a linear relationship between the size of the image encoded
and the overall compression performance of the TIES encoder. In
other words, as the image size increases, TIES out-performs the FIC
encoder by an increasing margin. In addition, we note that for the
sample images used in the empirical analysis and the results
obtained, the TIES encoder is able to achieve greater savings in the
compressed file size, from the range of 2.5 to 13.0% with respect to
the FIC encoder for large images. Furthermore, we note that the
TIES encoder is general enough to handle images of any size, such
as images of 1280x1280px, by either trimming the source image
separately encoding the trimmed image and its border, as described
in Section 2.1, or by setting the parameters of the TIES encoder
such that the maximum depth of quad-tree partitioning results in the
smallest range and domain block size being an integer.
Finally, we established that the current implementation of the
TIES encoder has a drawback – it is unable to handle largely
homogenous images – reason being that the domain compression
algorithm over-reduces the original domain pool extracted to the
point that it is inadequate for the linear combination search
algorithm to find a suitable linear combination of domain blocks to
represent each range block in the image.

8. Acknowledgements
This authors’ work was supported by the National University
of Singapore Academic Research Fund under grant R-252000-118-112.

9. References
[1]

[2]

[3]
[4]

[5]
[6]

[7]

[8]

A. E. Jacquin, Image Coding Based on a Fractal Theory of
Iterated Contractive Image Transformations, IEEE
Transactions on Image Processing, 18-30, 1992.
F. Yuval, Fractal Image Compression, SIGGRAPH ’92 Course
Notes, San Diego Super Computer Center, University of California,
San Diego, USA, 1992.
Y. Fisher (editor), Fractal Image Compression – Theory and
Applications. Springer-Verlag, New York, USA, 1995.
S.G. Mallet and Z. Zhang, Matching Pursuits with Time-Frequency
Dictionaries, Journal of IEEE Signal Processing, Vol.41, No.12,
December 1993.
I. H. Witten, R. M. Neal, J. G. Cleary, Arithmetic Coding for Data
Compression, Communications of the ACM, Vol. 30 No. 6, 1987.
J.Hammerle and A.Uhl. Fractal image compression on MIMD
architectures II: Classification based speed-up methods. Journal of
Computing and Information Technology (Special Issue on Parallel
Numerics and Parallel Computing in Image Processing, Video
Processing, and Multimedia), 8(1):71-82, 2000
Shinhaeng Lee, Shin'ichiro Omachi and Hirotomo Aso, A Parallel
Architecture for Quadtree-based Fractal Image Coding
Proceedings of the 2000 International Conference on Parallel
Processing (ICPP2000), 15-22, August 2000.
M. Wang, R. Liu, and C. H. Lai, Adaptive Partition and Hybrid
Method in Fractal Video Compression, To appear in a special issue
of Computers and Mathematics with Applications Distributed
Algorithms for Science and Business, 2006.

Proceedings of the International Conference on Computer Graphics, Imaging and Visualisation (CGIV'06)
0-7695-2606-3/06 $20.00 © 2006

