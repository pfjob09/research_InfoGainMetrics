Object Recognition using Fourier Descriptors: Some Experiments and
Observations
M. Sarfraz
Department of Information & Computer Science
King Fahd University of Petroleum and Minerals
KFUPM # 1510, Dhahran 31261, Saudi Arabia
E-mail: sarfraz@kfupm.edu.sa
Abstract
In many image analysis and computer vision applications,
object recognition is the ultimate goal. This work presents
study and experimentation for object recognition when
isolated objects are under discussion. The circumstances
of similarity transformations, presence of noise, and
occlusion have been included as the part of the study. For
simplicity, instead of objects, outline of the objects have
been used for the whole process of the recognition.
Fourier Descriptors have been used as features of the
objects. Various similarity measures have been used and
compared for recognition. The test objects are matched
with the model objects in database and the object with the
least similarity measure is taken as the recognized object.
A detailed experimental study has been made under
different conditions and circumstances.

1. Introduction
Fourier descriptors [1, 2], like Moment descriptors [9],
have been frequently used as features for image
processing, remote sensing, shape recognition and
classification.
Fourier
Descriptors
can
provide
characteristics of an object that uniquely represent its
shape. Several techniques have been developed that derive
invariant features from Fourier Descriptors for object
recognition and representation [1-5]. These techniques are
distinguished by their definition, such as the type of data
exploited and the method for deriving invariant values
from the image Fourier Descriptors.
Granlund [1] introduced Fourier descriptors using
complex representation in 1972. This method ensures that
a closed curve will correspond to any set of descriptors.
The Fourier descriptors have useful properties [3, 4]. They
are invariant under similarity transformations like
translation, scaling and rotation. The objects having these
kind of transformations can be easily recognized using
some recognition algorithms with Fourier descriptors as
invariant features. For example, the Fourier descriptors of
the boundary for recognizing closed contours is proposed
in [5]. However, despite its success in some applications,

it has certain limitations. Occlusion is the severe shape
distortion, when the shape gets distorted, the Fourier
descriptors don’t work well for recognition [6-8].
This paper has used these Fourier descriptors, with
different combinations, for the recognition of objects
captured by a non-ideal imaging system which may
transform, make noise or can have occlusion in the
images. An extensive experimental study, similar to the
moment invariants [9], has been made using various
similarity measures in the process of recognition. These
measures include Euclidean Measure, Log Sum Square
and Percentage error. A comparative study of various
scenarios has lead to very interesting observations which
may be quite useful for the researchers as well as
practitioners working for imaging and computer vision
problem solving. Although the whole study has been made
for bitmap images, but it can be easily extended to gray
level images.
The outline of the remainder of the paper is as
follows. Getting of bitmap images and their outline is
discussed in Sections 2. Section 3 deals with the study of
Fourier descriptors. The concept of similarity measures are
explained in Section 4. Algorithm for object recognition
problem has been devised in Section 5. Detailed
experimental study and analyses is made in Section 6
whereas Section 7 deals with interesting observations
during the experimental study. Finally, Section 8
concludes the paper as well as touches some future work.

2. Finding Boundary
In order to find boundary of bitmap image, first its chain
code is extracted [11, 12]. Chain codes are a notation for
recording the list of edge points along a contour. The chain
code specifies the direction of a contour at each edge in
the edge. From chain coded curve, boundary of the image
is found [13]. The selection of Boundary Points is based
on their corner strength and contour fluctuations. The
input to our boundary detection algorithm is a bitmap
image. The algorithm returns number of pieces in the
image and for each piece, number of Boundary Points and
values
of
these
Boundary
Points

Proceedings of the International Conference on Computer Graphics, Imaging and Visualisation (CGIV'06)
0-7695-2606-3/06 $20.00 © 2006

Pi x i , y i , i 1,2,..., N . Figure 1(b) shows detected
boundary of the image of Figure 1(a).
(a)

(b)

Figure 1. (a) Bitmap image, (b) Outline of the image.

3. Fourier Theory and Implementation
In the scope of this research, the Fourier transform
technique [2] is used for shape description in the form of
Fourier descriptors. The Fourier descriptor is a widely
used all-purpose shape description and recognition
technique. The shape descriptors generated from the
Fourier coefficients numerically describe shapes and are
normalized to make them independent of translation, scale
and rotation. These Fourier descriptor values produced by
the Fourier transformation of a given image represent the
shape of the object in the frequency domain. The lower
frequency descriptors store the general information of the
shape and the higher frequency the smaller details.
Therefore, the lower frequency components of the Fourier
descriptors define a rough shape of the original object

Input shape

F-16
B-747
M-52
……
…...
……

Database of
Fourier
Descriptors

complex numbers. In order to represent traversal at a
constant speed, it is necessary to interpolate equidistant
points around the boundary. Traversing the boundary more
than once results in a periodic function. When dealing
with discrete images, the Discrete Fourier Transform
(DFT) is used. The DFT of the sequence of complex
numbers, obtained by the traversal of the object contour,
gives the Fourier descriptor values of that shape. The
Fourier descriptor values can be normalized to make them
independent of translation, scale and rotation of the
original shape.

4. Similarity Measures
Given two sets of descriptors, how do we measure their
degree of similarity? An appropriate classification is
necessary if unknown shapes are to be compared to a
library of known shapes. If two shapes, A and B, produce a
set of values represented by a(i) and b(i) then the distance
between them can be given as c(i) = a(i) – b(i). If a(i) and
b(i) are identical then c(i) will be zero. If they are different
then the magnitudes of the components in c(i) will give a
reasonable measure of the difference. It proves more
convenient to have one value to represent this rather than
the set of values that make up c(i). The easiest way is to
treat c(i) as a vector in a multi-dimensional space, in
which case its length, which represents the distance
between the objects, is given by the square root of the sum
of the squares of the elements of c(i).
This paper implements a simple classifier that
calculates the similarity measure of the corresponding
Fourier descriptors of the input shape and each of the
shapes contained in the database as shown in Figure 2. The
similarity measures, attempted for experimental studies,
are as follows:
n

1.

¦ ci   bi 

2

(Euclidean Distance (ED))

i 1

n

2. log
Contour shape

Classifier

¦ ci   bi 

2

(log of ED (LED))

i 1

Answer

Figure 2. Pictorial Description of the method.

The Fourier transform theory can be applied in different
ways for shape description. One method works on the
change in orientation angle as the shape outline is
traversed. But in this study, the following procedure was
implemented. The boundary of the image is treated as
lying in the complex plane. So the row and column coordinates of each point on the boundary can be expressed
as a complex number, x + jy where j is sqrt (-1). Tracing
once around the boundary in the counter-clockwise
direction, at a constant speed, yields a sequence of

n

3.

c i 

¦ bi 

(Percentage Error (PE))

i 1

In this study, n is the number of FDs considered, a(i) is the
ith FD of the template image, and b(i) is the ith FD of the
test image. A tolerable threshold U is selected to decide a
test object recognized. This threshold is checked against
the least value of the selected similarity measure.

5. Algorithm
The outline of the algorithms is as follows:

Proceedings of the International Conference on Computer Graphics, Imaging and Visualisation (CGIV'06)
0-7695-2606-3/06 $20.00 © 2006

1. Clean up the image of noise by using a median filter and then
removing all but the largest of the objects in the scene.
2. Find the boundary of the image.
3. Convert the x, y coordinates in the contour to a onedimensional vector by treating them as a complex pair. That
is: U(n) = X(n) + i * Y(n).
4. Perform the Fast Fourier Transform on U and take the
absolute value to create a new vector A which is the
magnitude of the coefficients.
5. Throw away A(0) since it is the DC component; that is, it
represents only the translation of the contour.
6. Truncate A (>JX), for a pre-selected JX, since higher
frequency components don't add much to the shape and are
wildly affected by noise.
7. Normalize the remaining magnitudes by dividing each
element of A by A(0). Reason: when a shape is scaled by a
constant factor (alpha), the magnitude of each of the
coefficients in the resulting FFT is also multiplied by alpha.
To remove alpha from the equation we simply divide by a
number, A(0), which is known to be a product of alpha.
8. The result in A is the Fourier Descriptor.
9. For a given test silhouette, Its FD’s are compared with all the
model objects FD’s using the Euclidean distance (ED)
between them (or LED, or PE).
10. The model object with least Euclidean distance (ED) between
them (or LED, or PE) is a recognized object.

6.1. Experiments I
The first series of experiments has been made to view
results for different combinations of the Fourier
Descriptors. Various experiments can be seen presenting
different scenarios of the combination of Fourier
Descriptors, similarity measures and nature of data used.
The recognition system is tested by generating the test
objects by translating, rotating, and scaling and adding
noise to the model objects contained in a database of size
60. The test objects were randomly rotated and translated,
3
1
but scaled to factor of around th , 1 th and some
4
4
without scale of their model sizes. Sixty test objects were
used for each of the experiments for testing similarity
transformation, 16 test objects were used for noisy objects
with similarity transformations, and 60 test objects were
used for occluded objects. The salt & pepper noise of
density 10% is added to the objects for generating the
noisy test objects. Median filter was used in the
experiment to filter the noise, so that the noise remains on
the boundary of the object.

6. Results and Analysis
The recognition system is tested by generating the test
objects by translating, rotating, scaling, adding noise, and
adding occlusion to the model objects contained in a
database of different sizes. The test objects were randomly
rotated, translated, and scaled. Some were considered
without scale of their model sizes. Up to 100 test objects
were used for the experiments for testing similarity
transformation.
The salt & pepper noise [14-16] of different densities
is added to the objects for generating the noisy test objects.
Median filter was used in the experiment to filter the
noise, so that the noise remains on the boundary of the
object. Median filtering is a type of neighborhood
processing that is particularly useful for removing 'salt and
pepper' noise from an image. The median filter [14-17]
considers each pixel in the image and it looks at its nearby
neighbors to decide whether or not it is representative of
its surroundings. Instead of simply replacing the pixel
value with the mean of neighboring pixel values, it
replaces it with the median of those values. The median is
calculated by first sorting all the pixel values from the
surrounding neighborhood into numerical order and then
replacing the pixel being considered with the middle pixel
value. As would be seen in the experiments, FDs are not
promising for the recognition of occluded objects. Around
25% occlusion was added into the objects to make tests.
We split the experiments into different categories
explained in the following subsections.

Figure 3. FDs under different transformations

The procedures taken to analyze and test the system is as
follows:
6.1.1. The base case
That is, the Fourier descriptors FD 1-6 (highlighted in
Table 1) are used as features and the Euclidean distance is
considered for comparison. The percentage of recognition
recorded in case of just similarity transformations is
83.3%. In case of similarity transformations with noise, it
is about 93.75%. It is worth noting that in the latter, only
translation is considered as a similarity transformation,
i.e., the test images are not rotated or scaled. The
recognition rate of occluded objects is only 8.3%, which is
very low. The Fourier Descriptors for an object in case of
similarity transformations, noise and occlusion are shown
in Figure 3. One can see that the Fourier descriptors did
not change much in case of similarity transformations and
noise. However, in the last column of Figure 3, the
occlusion caused the change in the values of descriptors.
6.1.2. Fourier Descriptors and Euclidean distance
Experiments are made to obtain the recognition rates of
transformed, noisy, or occluded images considering

Proceedings of the International Conference on Computer Graphics, Imaging and Visualisation (CGIV'06)
0-7695-2606-3/06 $20.00 © 2006

different numbers of FDs using Euclidean distance. The
recognition rates for using different numbers of FDs,
ranging from 1 to 40, are performed. Some sample results
are tabulated in Table 1. For example, using 11 FDs
improves the recognition rate of transformed images to
93.33% and improves the recognition rate of occluded
images to 20%.

6.2. Experiments II
This series of experiments is related to various cases as
mentioned in Table 3. Different number of Fourier
Descriptors, with different nature of data, are tested. The
similarity measure used here was the ED. The Table 3
shows the details of the experiments that were run for
investigating the use of FDs:

Table 1: Recognition rates for different numbers of
Fourier descriptors using Euclidean distance.
No. of FDs
used
4
6
11
8
22
29
40

Transformations

Noise

Occlusion

71.67%
83.33%
93.33%
90%
93.33%
95%
95%

75%
93.75%
93.75%
93.75%
93.75%
93.75%
93.75%

5%
8.33%
20%
18.33%
23.33%
23.33%
23.33%

From these results, it can be concluded that a good
compromise between recognition performance and
computational cost is achieved using 11 FDs. That is,
increasing the number of FDs beyond 11 does not help
much as the maximum recognition rate obtained for
transformed images using up to 40 FDs is 95%. Another
observation is that the maximum recognition rate is
achieved by using 29 FDs. Thus, using more FDs does not
improve the recognition performance further.
6.1.3. Fourier Descriptors and percentage of errors
Similarly, the recognition rates of transformed, noisy, or
occluded images using the sum of percentage of error (PE)
have been obtained. The recognition rates for using
different numbers of FDs, ranging from 1 to 40, are
summarized. Sample results are tabulated in Table 2. It
can be seen that, using PE with FDs results in less efficient
performance than using ED. Moreover, increasing the
number of FDs does not necessarily guarantee a better
performance. It can be observed that the best recognition
rate of transformed images is achieved using 9 FDs.
However, larger number of FDs gives rise to a lower
performance.

Table 3. Experiments for the different cases.
No.
1

Experiment Details

2

Number of Test Images: 45
Number of FDs Used: 1 - 11
Number of Templates in Database: 45
Noise Used: No
Occlusion: No
Test Images had a mixture of Translated, Scaled and
Rotated Images

3

Number of Test Images: 15
Number of FDs Used: 1 - 11
Number of Templates in Database: 15
Noise Used: No
Occlusion: No
Test Images had a mixture of Translated, Scaled and
Rotated Images

4

Number of Test Images: 45
Number of FDs Used: 1 - 11
Number of Templates in Database: 45
Noise Used: YES ( 10% Salt and Pepper Noise)
Occlusion: No
Test Images had a mixture of Translated, Scaled and
Rotated Images

5

Number of Test Images: 45
Number of FDs Used: 1 - 11
Number of Templates in Database: 45
Noise Used: No
Occlusion: YES
Test Images had a mixture of Translated, Scaled and
Rotated Images

Table 2: Recognition rates for different numbers of
Fourier descriptors using percentage of errors.
No. of FDs
used
4
6
9
16
22
29
40

Transformations

Noise

Occlusion

70%
80%
86.67%
75%
68.33%
68.33%
62.25%

87.5%
81.25%
81.25%
81.25%
81.25%
81.25%
81.25%

8.33%
11.67%
13.33%
8.33%
6.67%
11.67%
11.33%

Number of Test Images: 75
Number of FDs Used: 1 - 11
Number of Templates in Database: 75
Noise Used: No
Occlusion: No
Test Images had a mixture of Translated, Scaled and
Rotated Images

6.2.1. Results
The results of the experiments are summarized in first five
graphs of Figure 4. These graphs show in details the
comparisons between:

x
x
x
x

Different number of FDs used,
Different sizes of databases used,
With Noise and without Noise,
With Occlusion and without occlusion

Proceedings of the International Conference on Computer Graphics, Imaging and Visualisation (CGIV'06)
0-7695-2606-3/06 $20.00 © 2006

Figure 4. (left to right row wise) Percent Accuracy in Recognition by FDs in a database of images 15, 45, 75 s, 45
Noisy, 45 Occluded; Images Successfully Recognized by number of FDs from a database of images15, 45, 75.

Graphs in Figure 4 also show the success rates of the FDs
in different settings as mentioned above. It should be
noted that these graphs demonstrate the data for Percent
Accuracy of each combination of the FDs or descriptors.
The percentage is computed in terms of the total images
recognized correctly by each combination of FDs or
descriptors out of the whole pool of test images.

6.3. Experiments III
In this category of experiments, just before examining the
test images, FD database is loaded and up to 20 FDs are
computed. The experiments are made over a mixture of
transformations and effects at a database of 60 objects.
The Euclidian distance between the templates’ FDs and
those of the targets is computed as a similarity measure.
The results achieved are quite reasonable. The experiment
results are mentioned in Table 4. It should be noted that
when the experiments were made for the template
directory images, the accuracy was 100%.
Table 4. Recognition rates for the different cases.

50%

78%

83%

58%
58%
58%

90%
92%
92%

87%
87%
87%

Arbitrary
(different type of
transformations)

82%
93%
95%
95%

10 noise 10degree
rotation 0.25scale

10% noise
10 degree rotation

20% noise 20 degree
rotation

Number of Fourier
Descriptors
6
10
15
20

6.4. Experiments IV
In this category of experiments, just before examining the
test images, FD database is loaded and up to 31 FDs are
computed. The similarity measure LED is used between
the templates’ FDs and those of the targets. The
experiment results are mentioned in Table 5. Various cases
of similarity transformations, noise and occlusion were
tested. It should be noted that when the experiments were
made for the template directory images, the accuracy was
100%. During the experimentation, the test images were
divided into three sets as follows:
1. transformed (without noise and occlusion) = 60
images
2. noisy (transformed and noisy) = 16 images
3. occluded (transformed and occluded) = 60 images
Table 5. Results with LED.
FDs
5
6
7
8
9
10
11
12
13
14
15
31

Transformed
60.00%
73.33%
75.00%
80.00%
80.00%
83.33%
83.33%
83.33%
85.00%
86.67%
86.67%
78.33%

Noisy
56.25%
56.25%
68.75%
81.25%
81.25%
87.50%
81.25%
81.25%
81.25%
81.25%
81.25%
87.50%

Occluded
1.67%
5.00%
6.67%
16.67%
15.00%
18.33%
15.00%
20.00%
16.67%
16.67%
18.33%
23.33%

From the experiments, it seems that ED is better as
compared to LED. Good results can be achieved with less
than 10 descriptors for the test images. However, occluded
objects recognition has improved with LED in some cases.

Proceedings of the International Conference on Computer Graphics, Imaging and Visualisation (CGIV'06)
0-7695-2606-3/06 $20.00 © 2006

7. Some Observations
Here are some observations for the whole discussion in the
paper. The recognition accuracy of Fourier descriptors is
decreased as the size of the database increases. Fourier
descriptors were found to be able to recognize at a higher
rate if we use nine or more Fourier descriptors. Most
cumulative combinations of Fourier descriptors are able to
recognize most of the images correctly for samples
without noise or occlusion. It is noted that if an image is
recognized, it is recognized by most cumulative
combinations of Fourier descriptors, and if it is not
recognized, then it is not recognized by almost all
cumulative combinations of Fourier descriptors. Noise
(salt and pepper) with density of up to 50% has a minimal
effect on the recognition ability of Fourier descriptors. The
Fourier descriptors show a steady increase in accuracy
level as the number of Fourier descriptors used increases.
It then stabilizes at same level for nine to eleven
descriptors.
Fourier descriptors perform very poorly in the
presence of occlusion in the image. The occlusion is a big
issue on recognition object, especially, when we use
Fourier descriptors. Since the method works on the
boundary of edge of objects, any distortion on the shape
will be affected to the recognition process.

8. Conclusion and Future Work
This work has been reported to make a practical study of
the Fourier descriptors to the application of Object
Recognition. The implementation was done on a P-IV PC
using MATLAB. The ultimate results have variations
depending upon the selection of number of FDs, similarity
transformations, noise, occlusion, and Data size. The
variety of similarity measures and different combinations
of FD features, used in the process, make a difference to
the recognition rate. The results have been tested using
three similarity measures and up to 40 FDs. Three
similarity measures, including ED, LED, and PE, provided
different recognition results. The images used are all
bitmapped images, further investigations are being done
with some more complex images.
It can be seen that, using PE with FDs results in less
efficient performance than using ED. Moreover,
increasing the number of FDs does not necessarily
guarantee a better performance.
Using ED took superiority over LED and produced
improved results in all cases of transformation and noise.
But, occlusion was observed to have better recognition
with LED in some cases.

The images that have to be recognized but failed to be
recognized by most of the FD combinations are to be
analyzed further. This might lead to another theory to find
out appropriate features or attributes in the image that
made it difficult to be recognized. A combination of FDs
and some other descriptors could also be studied to
increase an overall probable performance of the object
recognition system too.

References
[1] G. H. Granlund, Fourier Preprocessing for hand print
character recognition, IEEE Trans. Computers, Vol C-21,
Febr. 1972, pp. 195-201.
[2] A Project led by Julien Boeuf and Pascal Belin, and
supervised
by
Henri
Maître:
http://www.tsi.enst.fr/tsi/enseignement/ressources/mti/descri
pt_fourier/index.html.
[3] O. Betrand, R. Queval, H. Maître, Shape Interpolation by
Fourier Descriptors with Application to Animation
Graphics, Signal Processing, June 1981, 4:53-58.
[4] H. Maître, Le traitement des images, ENST, December
2000, pp. 70-72.
[5] C.T. Zahn, R.Z. Rhoskies, Fourier descriptors for plane
closed curves, IEEE trans. Compu. 21 (1972) 269-281.
[6] Thomas Bernier, Jacques-Andre landry, A new method for
representing and matching shapes of natural objects, Pattern
Recognition 36 (2003), 1711-1723.
[7] N. Ansari, E.J. Delp, Partial Shape Recognition: a landmark
based approach, IEEE Trans. PAMI 12 (1990), 470-183.
[8] J. Zhang, X. Zhang, H. Krim, G.G. Walter, Object
representation and recognition in shape spaces, Pattern
Recognition 36(5), 2003, pp. 1143-1154.
[9] M. Sarfraz, Object Recognition using Moments: Some
Experiments and Observations, Proceeding of the
International Conference on Geometric Modeling and
Imaging (GMAI), IEEE Computer Society Press, 2006.
[10] John W. Gorman, O Robert Mitchell, Frank P. Kuhl, Partial
shape recognition using dynamic programming, IEEE
Transactions on pattern analysis and machine intelligence,
Vol.10,No.2, March 1988.
[11] G. Avrahami and V. Pratt. Sub-pixel edge detection in
character digitization. Raster Imaging and Digital
Typography II, pp. 54-64, 1991.
[12] Hou Z. J., Wei G. W., A new approach to edge detection,
Pattern Recognition Vol. 35, pp. 1559-1570, 2002.
[13] N. Richard, T. Gilbert, Extraction of Dominant Points by
estimation of the contour fluctuations, Pattern Recognition
Vol. 35, pp. 1447-1462, 2002.
[14] Rafael C. Gonzalez and Richard E. Woods, Digital Image
Processing, Prentice Hall, 1992.
[15] Rafael Gonzalez, Richard Woods and Steven Eddins, Digital
Image Processing Using Matlab, Prentice Hall, 2003.
[16] R. Jain, R. Kasturi, B. Schunk, Machine Vision, McGraw
Hill, 1995.
[17] http://www.cee.hw.ac.uk/hipr/html/median.html.

Proceedings of the International Conference on Computer Graphics, Imaging and Visualisation (CGIV'06)
0-7695-2606-3/06 $20.00 © 2006

