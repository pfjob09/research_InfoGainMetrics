BRDF recovering and Scene re-lighting
using an environment map
Youngsup Park, Taiho Choi, Kyunghyun Yoon
221, HukSeok-Dong, DongJak-Gu, Seoul, Korea, 156-756
Computer Graphics Lab, CS&E, Chung-Ang University
{aupres98@hanmail.net, thchoi@cglab.cse.cau.ac.kr, khyoon@cau.ac.kr}
Abstract
A rendering algorithm based on physical
phenomenon and well-defined model data are needed to
generate a synthetic image realistically. In this paper,
inverse rendering based on an environment map is
proposed to obtain BRDF of objects. Many researchers
try to find BRDF by analyzing many pictures taken with
well-controlled camera and light position. But this
method is available at a laboratory environment. Limits
of previous works can be conquered by using Inverse
rendering based on an environment map and it is
possible to get BRDF of objects at a general environment.
Inputs are an image, an environment map and 3D
geometry data of models. Objects of an input image are
divided into three parts – diffuse reflection, glossy
reflection and diffuse texture – and BRDF of objects are
recovered. Using BRDF of objects, it is possible to add
virtual objects and to remove real objects from an input
image.
Keywords--- Image-Based
Environment Map

Lighting,

BRDF,

1. Introduction
To generate a realistic image is a traditional purpose
of computer graphics. Model data is important to make a
realistic image. In this paper, we propose an inverse
rendering algorithm 1 to find BRDF(Bi-directional
Reflection Distribution Function) of objects. By finding
BRDF of objects, many things - adding virtual objects,
removing real objects, changing a view point, changing
light conditions and etc. - can be done.
BRDF is important to render a realistic image and is
studied by many scientists. Phong-illumination model is
used widely although it cannot represent correct
phenomenon of light reflection because Phongillumination model can be generated realistic and
intuitive images. BRDF model of Ward[1] and Torrancesparrow model[2] which can represent phenomenon of
light more correctly is suggested. It is possible to obtain
BRDF of objects by analyzing many pictures that are
1

Type of input environment map and an image is HDRI[14].

Proceedings of the Computer Graphics, Imaging and Vision: New Trends (CGIV’05)
0-7695-2392-7/05 $20.00 © 2005 IEEE

taken with well-controlled
position[1,3,4].

light

and

camera

2. Related Work
A study to modify an image is continued for a long
time. There are some studies to express exchange of light
between real objects taken by photo and virtual objects
obtained by 3D engine such Maya and 3D MAX.
Devebec[1] divides a scene into three part – distant scene,
local scene and synthetic objects. A distant scene is a
HDRI(High Dynamic Range Image) environment map
based on light and a local scene is an image taken with
camera. A synthetic scene of local scene and virtual
objects are rendered. Using differential image, a
synthetic scene is composed into a real image.
Imari[4] suggests another method to add virtual
objects into a real scene. In Imari[4], 3D model of an
environment that is similar to a real environment is
generated by using two environment maps taken in
different positions. To add virtual objects into a real
scene, light effect is calculated by sampling 3D model of
the environment regularly. And shadowing effect is
generated realistically by diminishing amount of light
that is blocked by synthetic objects from a real image.
But the limitation of Imari[4] is that real objects that
exchange lights with virtual objects should be diffuse
objects and planar objects.
Imari[4] and Devebec[1] have some weak points
because they don’t know BRDF of real objects which
exchange light with virtual objects. Also there are some
studies to calculate BRDF of objects. Ward [9]
developed gonioreflectometer for measuring BRDF of
objects. Using this device it is possible to steer lights and
camera position very accurately. And this paper suggests
BRDF model which can represents anisotropic reflection
based on gaussian distribution. Sato [10] and
Devebec[11] also developed a device to measure BRDF
and by using the device, BRDF is obtained. But it is hard
to measure BRDF of various objects and in various
environments by using these methods because these
methods need laboratory-environment in which it is
possible to control position of light and camera.
Boivin[13] calculates BRDF of objects using
another method. The main purpose of Boivin[13] is to
add virtual objects into a real scene and to change light

condition of real scene. At first, many pictures of a room
are taken. Model data of the room is made by applying
Loscos[14] to these pictures. Using model data and
radiance data of the pictures, BRDF of objects in the
room are found. Using these data, it is possible to
generate realistic images that contain virtual objects or
virtual lights. Boivin[13] overcomes the weakness of
[1,4] – BRDF of a real object is unknown – and [9,10,11]
– position of light and camera should be steered very
accurately.
Cabral[15] recovers the BRDF of objects by using a
picture and using recovered BRDF, it is possible
relighting and adding virtual objects. Inputs of
Cabral[15] are model data of picture and information of
direct light source. Diffuse reflection, mirror reflection,
isotropic reflection and anisotropic reflection are
founded one by one. And reminders are treated as a
texture. Using BRDF and geometry data of model,
relighting and adding virtual objects are possible.
The purpose of this study is to find BRDF of objects
in a scene – similar to Boivin[13] and Cabral[15]. But
this paper suggests a new method to find BRDF, and this
method has some merits.

a glossy factor, n is a normal vector, l is a light vector

3. Environment Map Filtering

4.1. Diffuse Reflection

Devebec et al[1,4,5,6,7,8,12] are the papers about
rendering method using an environment map. Using an
environment map and monte-carlo ray tracing, it is
possible to render a realistic image. But monte-carlo ray
tracing is very slow. Environment map filtering[15] can
generate a realistic image and also reduce rendering time.
But it has some disadvantages. Those are environment
map filtering cannot represent shadowing and interreflection.
Environment map filtering is method for
improvement of rendering speed by calculating
complex part of lights integration and storing result of
calculations. Generally environment map filtering is
available to symmetric BRDF. In this paper,
normalized Phong BRDF is used. Equation (1) is
equation of normalized Phong BRDF.

I

U U
U Y U U
U U
K d ³ (n x l )Li (l )dl  K s ( N 1)³ (r x l ) N Li (l )dl
:

:

U

x l ) Li (l ) d l

(1)

U
Li (l )

,
can
advance. At first, case of :
be obtained from an environment map. Therefore
incident lights of each plane of which normal is n can
be pre-integrated. For each n , integration can be precomputed and stored. Also, case of

Figure 1 Filtering Result. (a) Input environment map
(b) diffuse filtered environment map (c) glossy factor
2 (d) glossy factor 4 (e) glossy factor 8 (f) glossy factor
16 (g) glossy factor 32 (h) glossy factor 64

4. Inverse Rendering based on Environment
map

In case of diffuse reflection, Because

Ks

Kd

of

K

d is
can be calculated
U U easily.
U Y
³ ( n x l ) L i (l ) d l
into a radiance
calculated by dividing : U U
U Y
³ ( n x l ) Li (l ) d l
can be obtained from a
of a surface. :
diffuse filtered environment map.

equation 1 is zero,

I

U Y U U
K d ³ (n x l ) Li (l )dl
:

Kd

U Y U U
I / ³ (n x l ) Li (l )dl

(2)

:

4.2. Mirror Reflection

Integral terms of above equation
canU be Ucalculated in
Y

³ (n

and r is a reflection vector of a viewing vector. Fig 1 is
results of environment map filtering.

U U
U U N
³ ( r x l ) L i (l ) d l ,

:

integral can be pre-computed for each r . In equation 1,

K d is a diffuse factor and K s is a specular factor. N is

Proceedings of the Computer Graphics, Imaging and Vision: New Trends (CGIV’05)
0-7695-2392-7/05 $20.00 © 2005 IEEE

In case of mirror reflection, objects can have
properties of diffuse reflection and mirror reflection. N
of Phong-illumination model (equation 1) is infinite
when objects are mirror reflection. In this case, light
information can be obtained from an environment map.
Because 3D position of objects is predefined, a normal

U

U

vector n and a reflection vector r of surfaces can be
obtained easily. Amount of light that comes into an eye
is calculated by a diffuse filtered environment map and a

U

naive environment map using a normal vector n and a

U
reflection vector r (equation 3).

I ( x, y )

K d * Ld  K s * LsN

I ( x , y ) is a radiance of pixel
U Y U U
Ld ³ (n x l ) Li (l )dl

(3)

:

U U
U U
LsN ( N  1) ³ (r x l ) N Li (l )dl
:

Kd

and

Ks

are an un-known value and Ld and

LsN are a known value. We want to know K d and K s .
Kd
Ks

It is possible to calculate
and
by sampling
more than two points and solving simultaneous equations
of the first degree.

Figure 2 (a) Input image and model data (b) rendered
image of model data using calculated BRDF

K d avg
Error

Kd

Ks

glossy factor,
and
are calculated using glossy
filtered environment map, error of each glossy factor is
calculated and N is selected by comparing error of each
case.

4.4. Algorithm
Inputs of algorithm are an image, an environment
map, model data and camera parameter. At first filtered
environment maps are generated. Those are
corresponded to their BRDFs by performing
environment map filtering. Then diffuse objects are
selected using a diffuse filtered environment map. Next,
glossy objects are founded. And reminded objects are
classified as diffuse texture. Explanation for each step is
followed.
A. Diffuse Reflection - An item buffer is rendered
using camera parameter and model data of objects. An
item buffer stores information about ID of objects
corresponding to a pixel. Using this item buffer, a normal
of pixel is obtained, and using this normal, we get light
information Ld from the diffuse filtered environment
map. A diffuse map is generated by dividing this value
into value of each pixel. Then average value of every
item is calculated. Using this average, the error is
calculated (equation 4). If this error of a face is smaller
then threshold, the face is assigned as diffuse reflection.

M 1

¦ (I

i

U
/ L d (n i ))

i 0

U
abs ( I i / Ld (n i )  K d avg )
¦
Ii
i 0

(4)

M 1

1
M

4.3. Glossy Reflection
In this paper, to calculate BRDF of glossy object,
filtered environment maps are generated using different

1
M

B. Glossy Reflection - Faces that are not classified
diffuse reflection are checked. When n points composed
of each face are sampled, a reflection vector of a eye
vector is calculated and checked whether the reflection
vector bumps into environment map or not. If the
reflection vector comes across environment map, the
sample point is selected; otherwise if the reflection
vector come across objects modeled, the sample point is

U

rejected. Using the normal vector n and reflection

U

vector r of the selected point, values of environment
maps are gathered. Then using SVD,
calculated (equation 5).

Kd

and

Ks

are

sample 3
ª Ld
«L
« d
«¬ Ld

Error

ªI0 º
«I »
« 1»
«¬ I 2 »¼

(5)

1
sample
sample 1

*

LS 0 º
ª Kd º
LS 1 »» « »
Ks
LS 2 »¼ ¬ ¼

¦
i 0

abs ( I i  ( Ldi * K d  Lsi * K s ))
Ii

K

(6)

K

d and
s ,
Using calculated
we gain
error(equation 6). To select glossy factor, error of each
filtered environment map is compared and glossy factor
of environment map that has minimum error is selected.
Then error of selected environment map is compared
with threshold. If the error is smaller than threshold, the
face is classified glossy object that has calculated BRDF.

C. Diffuse Texture - Faces that are classified are
treated as a diffuse texture.

Proceedings of the Computer Graphics, Imaging and Vision: New Trends (CGIV’05)
0-7695-2392-7/05 $20.00 © 2005 IEEE

5. Image based Lighting
In this paper, Image based lighting system is
developed to generate synthetic scene using finded
BRDF. Rendering algorithm of Image based Lighting
system is environment map and ray tracing. When
diffuse objects are rendered, diffuse filtered environment
map is used and when specular objects are rendered, a
naive environment map is used. Generally, radiosity or
monte-carlo ray tracing is used to render diffuse region.
But those methods need much time.

6. Experimental Result

Figure 3 Error curve of objects (a) Error curve of
plane, (b) Error curve of box

To test an algorithm of this paper, fig.2 is used.
Fig.2-(a) is generated by using a ray tracer and model
data is made by using 3DS Max. Fig.1-(a) is an input
environment map. And Fig.2-(b) is generated using
calculated BRDF of objects. Fig.3-(a) is an error curves
of the plane. While glossy factor increases, an error of
face decreases. Fig.3-(b) is the error curves of the box.
Because diffuse factor of box is much larger than
specular factor, the error curves of box are not affected
by glossy factor of filtered environment map. But the
error curve of box has minimum error when glossy factor
of filtered environment map is equal to real glossy factor
of box. Fig.4 is another experimental result. Input is
Fig.4-(a). Fig.4-(b) is re-rendered scene using BRDF
which is founded by inverse rendering algorithm of this
paper. Fig.4-(c) is re-rendered scene at a different
viewpoint. Color of some faces is gray because an
algorithm cannot find information of those faces. Real
objects are removed from image at Fig.4-(d) without
artifacts. It is possible to add virtual objects into the
image naturally in fig.4-(e). Fig.4-(f) shows that it is
possible to render properly in different environment.

7. Conclusion and Future Work
This paper suggests an algorithm to find BRDF of
objects by using an image, an environment map, model
data and camera parameter. Using this algorithm, to add
virtual objects into a real scene, to remove real objects
and change light condition of environment map are
possible. Previous works need too many pictures and
have limits of laboratory environment and objects to be
measured. Inverse rendering algorithm of this paper
overcomes these weak points of previous works.
Future works are followed. Weak point of
environment map filtering is that environment map
filtering cannot represent shadowing and inter-reflection.
Therefore, to consider shadowing and inter-reflection
effects of environment map filtering are needed. Also
environment map filtering need too much time. It should
be studied.
Environment map filtering is necessary to perform
inverse rendering. Environment map filtering for every
glossy factor needs too much time. So it will be possible
that glossy filtered environment map for some glossy
factor is generated and glossy filtered environment maps
for other glossy factor can be created by interpolating.
The correction of diffuse factor is needed[13]. It is
possible to generate more a realistic image by combine
objects that have similar BRDF, and finding BRDF
group by group. It is also a future work to applying other
BRDF model instead phong- BRDF.
Figure 4 (a) input image (b) re-rendered scene at
same viewpoint (c) re-rendered scene at different
viewpoint (d) pyramid is removed (e) virtual object is
add (f) re-rendered in different environment

Proceedings of the Computer Graphics, Imaging and Vision: New Trends (CGIV’05)
0-7695-2392-7/05 $20.00 © 2005 IEEE

References
[1]

Paul E. Debevec, "Rendering synthetic objects into real
scenes: bridging traditional and image-based graphics
with global illumination and high dynamic range
photography", Proceedings of the 25th annual conference
on Computer graphics and interactive techniques, p.189198, July 1998

[2]

[3]

[4]

[5]

[6]

[7]

[8]

[9]

[10]

[11]

[12]

[13]

[14]

[15]

Paul E. Debevec , Jitendra Malik, "Recovering high
dynamic range radiance maps from photographs",
Proceedings of the 24th annual conference on Computer
graphics and interactive techniques, p.369-378, August
1997
Ward, Gregory J., "The RADIANCE Lighting
Simulation and Rendering System," Computer Graphics
(Proceedings of '94 SIGGRAPH conference), July 1994,
pp. 459-72
Imari Sato, Yoichi Sato, Katsushi Ikeuchi, “Acquiring a
Radiance Distribution to Superimpose Virtual Objects
onto a Real Scene”. IEEE Transactions on Visualization
and Computer Graphics 5(1): 1-12 (1999)
Sameer Agarwal, Ravi Ramamoorthi, Serge Belongie,
and Henrik Wann Jensen "Structured Importance
Sampling of Environment Maps". Proceedings of
SIGGRAPH'2003
J. Kautz, P.-P. Vazquez, W. Heidrich, and H.-P. Seidel. "A
Unified Approach to Prefiltered Environment Maps".
Rendering Techniques '00 (Eurographics Workshop on
Rendering), pp. 185-196. Springer, 2000
R. Ramamoorthi and P. Hanrahan. “An efficient
representation for irradiance environment maps”. In
Proceedings of SIGGRAPH 2001, ACM Computer
Graphics Proceedings, Annual Conference Series, pages
497--500, August 2001.
P.-P. Sloan, J. Kautz, J. Snyder, “Precomputed Radiance
Transfer for Real-Time Rendering in Dynamic, LowFrequency Lighting Environments”, Proceedings
SIGGRAPH 2002, pages 527-536, July 2002
G. J. Ward, "Measuring and modeling anisotropic
reflection", Computer Graphics (SIGGRAPH'92
Proceedings), Vol. 26, No.3, July 1992, pp. 265-272
Y. Sato, M. D. Wheeler, and K. Ikeuchi, "Object shape
and reflectance modeling from observation", Proceedings
of ACM SIGGRAPH 97, In Computer Graphics
Proceedings, Annual Conference Series 1997, ACM
SIGGRAPH, pp. 379-387, August 1997
Y. Yu, P. Debevec, J. Malik, and T. Hawkins, "Inverse
Global Illumination: Recovering Reflectance Models of
Real Scenes from Photographs," Proc. SIGGRAPH, Los
Angeles, CA, July 1999.
Paul E. Debevec, Camillo J. Taylor, and Jitendra Malik.
“Modeling
and
Rendering
Architecture
from
Photographs: A Hybrid Geometry- and Image-Based
Approach”. In SIGGRAPH 96, August 1996
Samuel Boivin , Andre Gagalowicz, “Image-based
rendering of diffuse, specular and glossy surfaces from a
single image”, Proceedings of the 28th annual conference
on Computer graphics and interactive techniques, p.107116, August 2001
C. Loscos, G. Drettakis, and L. Robert. “Interactive
virtual relighting of real scenes”. IEEE Trans. on
Visualization and Computer Graphics, 6(3), 2000
Brian Cabral , Nelson Max , Rebecca Springmeyer,
“Bidirectional reflection functions from surface bump
maps”, Proceedings of the 14th annual conference on
Computer graphics and interactive techniques, p.273-281,
August 1987

Proceedings of the Computer Graphics, Imaging and Vision: New Trends (CGIV’05)
0-7695-2392-7/05 $20.00 © 2005 IEEE

