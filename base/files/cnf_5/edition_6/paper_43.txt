Perspective Correct Normal Vectors for Phong Shading
Hua Zhang1,2, Changqian Zhu1, Qiang Zhao2 and Hao Shen2
1
VR Center, Southwest Jiaotong University, P.R.China
2
Institute of Computer Applications, Chinese Academy of Engineering Physics, P.R.China
hzhang@caep.ac.cn cqzhu@home.swjtu.edu.cn zhaoq@caep.ac.cn shh@caep.ac.cn

Abstract
Linear shading interpolation is not physically
correct in perspective projection. We present a
perspective correct interpolation method. Our method
achieves the perspective correct interpolation in the
standard graphics pipeline in contrast to other’s that
are calculated in a nonstandard graphics pipeline or
by using similar triangles technology. We also show
how to use this perspective interpolation to get the
perspective correct normal vectors for applications
such as Phong shading.

1. Introduction
There are three widely used shading methods,
Gouraud Shading [2], Phong Shading [3], and spherical
linear interpolation shading [11]. In these shading
methods, linear interpolation along scanlines is used to
make image of polyhedral objects smoother. In
Gouraud shading, intermediate intensities are obtained
by interpolating the endpoint intensities of a scanline
linearly. In Phong shading, intermediate intensities are
calculated by the interpolated normal vectors. In
spherical linear interpolation, intermediate intensities
are obtained by interpolating the angle between two
normalized vectors. However, perspective distortion is
introduced because interpolation is performed after
perspective transformation [1], [4], [7], [8], and [9].
Foley et al. [4] suggested using a larger number of
smaller polygons to reduce the perspective distortion.
Blinn [7] presented a good detailed introduction of
perspective interpolation and an experiment of texture
mapping by using homogenous coordinates through a
new graphics pipeline. Heckbert and Morton [9]
presented a fast algorithm based on “rational linear
interpolation” technology. Low [1] presented a clear
algorithm of perspective correct interpolation based on
similar triangles, and how to get correct intensities for
Gouraud shading.

Proceedings of the Computer Graphics, Imaging and Vision: New Trends (CGIV’05)
0-7695-2392-7/05 $20.00 © 2005 IEEE

We derive a new perspective correct interpolation
method from eye space to screen space within the
standard OpenGL graphics pipeline, and will show that
our result is the same as that of [1], which emphasizes
the perspective projection stage instead.

2. Preparing works
2.1. Graphics pipeline
Fig. 1 is a revised graphics pipeline from [5], which
will be used in our derivation. We start derivation from
eye coordinates to window coordinates. We assume
that vertices are always in the viewing volume, and are
not be clipped against the perspective frustum.
In the viewport transformation stage, the aspect ratio
of the viewport is set to be the same as that of the
viewing volume to avoid image distortion [5].

2.2. Terminology and illumination
All symbols used here are defined in Table 1.
For simplicity, we use one of the simplest lighting
models, which is Lambert’s illumination model. The
illumination equation is as follows:

I = Kd V • Ld .

(1)

We assume that only one light source and Ld is
constant in the rest of this paper. For example, sun is a
parallel light source. Blinn [6] had a very good
introduction to several lighting models, including
Lambert’s model.
B

3. Deriving perspective correct normals

B

Table 1. Variables and Constants
eye
coordinates

Vertex 1,2,3...

clip
coordinates

Modelview
Matrix

Projection
Matrix

clip

2D Display
Device

Viewport
matrix

Perspective
division

window
coordinates

N
F
L
R
T
B
width
height
Vp
Vq
Vr
V

normalized
device coordinates

'

Figure 1. The graphics pipeline revised
far plane

near plane

v

P

P'

n

R

R'

eye

Q'
u

Q

( R,B,-N )

Figure 2. Perspective transformation of line
segment PQ
y (X+width,Y+height)
y
Maximum
range of
screen widow
coordinates.

(-1,1,1)
P

x

R
Q

T he distance from eye to the near-depth clipping plane.
T he distance from eye to the far-depth clipping plane.
T he coordinate for the left-vertical clipping plane.
T he coordinate for the right-vertical clipping plane.
T he coordinate for the top-Horizontal clipping plane.
T he coordinate for the bottom-horizontal clipping plane.
T he width of viewport.
T he height of viewport.
T he normalized normal vector of point P.
T he normalized normal vector of point Q .
T he normal vector of point R.
T he normalized normal vector of a vertex.
T he corrected normal vector of point R.
T he normalized normal vector o f point A.
T he normalized normal vector of point B.
T he normalized normal vector of point C.
A fourth component of homogeneous coordinates.
Represents the value of Zqe /Zpe in window coordinates.
T he minimum value of depth buffer.
T he maximum value of depth buffer.
A vector along a line segment.
Line segments length ratio [0 to 1] in eye coordinates.
Line segments length ratio [0 to 1] on screen window.
T o specify which point is used, i=p,q or r.
T he x coordinate for the origin of view port.
T he y coordinate for the origin of view port.
T he x coordinate of a point i in eye coordinates.
T he x coordinate of a point i in normalized coordinates.
T he x coordinate of a point i in screen window coordinates.
T he y coordinate of a point i in eye coordinates.
T he y coordinate of a point i in normalized device coordinates.
T he y coordinate of a point i in screen window coordinates.
T he z coordinate of a point i in eye coordinates.
T he z coordinate of a point i in normalized device coordinates.
T he depth value of a point i in screen window coordinates.
T he normalized vector pointing in the direction of light source.
A scalar that controls the diffuse reflectivity.

Vr
Va
Vb
Vc
u
λ
a
b
d
te
tw
i
X
Y
Xie
Xin
Xiw
Yie
Yin
Yiw
Zie
Zin
Ziw
Ld
Kd

(X,Y)

z

Let PQ be a line segment in the view volume (Fig.
2), R be a point on PQ, and te be the ratio of line
segment PR to the line segment PQ, where te =0 at P
and te=1 at Q. Suppose P, R, and Q in eye coordinates
are ( X pe , Ype , Z pe ) , ( X re , Yre , Z re ) , and ( X qe , Yqe , Z qe ) ,

x

(1,-1,1)

B

Figure 3. Viewport transformation

B

B

3.1. Perspective projection
After perspective projection, vertices are
transformed into normalized device coordinates. The
following is the perspective projection matrix [5]:
§ 2N
¨ R−L
¨
¨ 0
M=¨
¨
¨ 0
¨
¨ 0
©

0
2N
T −B
0
0

R+L
R−L
T +B
T −B
−( F + N )
F−N
−1

·
¸
¸
0 ¸
¸.
¸
−2 FN ¸
F−N ¸
0 ¸¹

B

0

(2)

Proceedings of the Computer Graphics, Imaging and Vision: New Trends (CGIV’05)
0-7695-2392-7/05 $20.00 © 2005 IEEE

B

B

respectively. The homogeneous coordinates of the
point P could be represented as follows:
§ uX pe ·
¨
¸
¨ uYpe ¸ ,
¨ uZ pe ¸
¨¨
¸¸
© u ¹

where u is a scalar value except 0. If u is equal to zero,
point P is at infinity. Now, multiplying it by projection

matrix M on the left for perspective transformation, we
obtain:

§ 2 NuX pe ( R + L)uZ pe ·
+
¨
¸
R−L
¨ R−L
¸
¨ 2 NuYpe (T + B )uZ pe ¸
+
¨
¸.
T −B
¨ T −B
¸
¨ −( F + N )uZ pe −2 FNu ¸
+
¨
¸
F−N
F−N ¸
¨
¨
¸
−uZ pe
©
¹

B

X iw = ( X in + 1)( width / 2) + X .

(12)

Yiw = (Yin + 1)(height / 2) + Y .

(13)

Z iw = ( Z in + 1)((b − a) / 2) + a.

(14)

Putting (3) into (12), (4) into (13), and (5) into (14),
respectively, the screen window coordinates of point P
can be obtained as follows:

X pw = (

Dividing this by scalar -uZpe (since u is not equal to
zero and Zpe<0) for perspective division, we obtain the
normalized device coordinates of point P as follows:
B

viewport transformation equations can be represented
as follows:

−2 NX pe
( R − L) Z pe

R+L
+ 1)( width / 2) + X .
R−L

(15)

T +B
+ 1)(height / 2) + Y .
T −B

(16)

−

B

B

§ −2 NX pe
−( R + L ) ·
+
¨
¸
−
(
R
L
)
Z
R−L ¸
pe
¨
§ X pn · ¨
−(T + B ) ¸¸
¨
¸ ¨ −2 NYpe
¨ Ypn ¸ = ¨ (T − B) Z + T − B ¸ .
pe
¨ Z pn ¸ ¨
¸
¨¨
¸¸ ¨ F + N
2 FN
¸
+
© 1 ¹ ¨
F − N ( F − N ) Z pe ¸
¨
¸
¨
¸
1
©
¹

Ypw = (

−2 NYpe
(T − B ) Z pe

Z pw = (

−

F+N
2 FN
+
+ 1)((b − a ) / 2) + a.
F − N ( F − N ) Z pe

(17)

Then (15), (16) and (17) could be represented as the
following by solving X pe , Ype , and Z pe , respectively:

The normalized device coordinates of point P can be written
in individual forms as follows:

2( X pw − X )

R+L
+
− 1)( R − L) Z pe /(−2 N ). (18)
width
R−L
2(Ypw − Y ) T + B
+
− 1)(T − B ) Z pe /(−2 N ). (19)
Ype = (
height
T −B
X pe = (

Z pe = 2 FN /((

X pn = −2 NX pe /(( R − L ) Z pe ) − ( R + L ) /( R − L ).

(3)

Y pn = −2 NY pe /((T − B ) Z pe ) − (T + B ) /(T − B ).

(4)

Z pn = ( F + N ) /( F − N ) + 2 FN /(( F − N ) Z pe ).

(5)

Similarly, the normalized device coordinates of point R
and Q can be obtained as follows, respectively:
X rn = −2 NX re /(( R − L) Z re ) − ( R + L) /( R − L).

(6)

Yrn = −2 NYre /((T − B) Z re ) − (T + B ) /(T − B ).

(7)

Z rn = ( F + N ) /( F − N ) + 2 FN /(( F − N ) Z re ).

(8)

X qn = −2 NX qe /(( R − L ) Z qe ) − ( R + L ) /( R − L ).

(9)

Yqn = −2 NYqe /((T − B ) Z qe ) − (T + B ) /(T − B ).

(10)

Z qn = ( F + N ) /( F − N ) + 2 FN /(( F − N ) Z qe ).

(11)

3.2. Viewport transformation
We assume that the viewport transformation (Fig. 3)
maps pseudodepth from range –1 to 1 into the range a
to b, where a and b are scalars, and b>a. Now, the

Proceedings of the Computer Graphics, Imaging and Vision: New Trends (CGIV’05)
0-7695-2392-7/05 $20.00 © 2005 IEEE

2( Z pw − a)
b−a

−

F+N
− 1)( F − N )).
F−N

(20)

Similarly, with regard to points R and Q, we can
obtain:
2( X rw − X ) R + L
+
− 1)( R − L) Z re /( −2 N ). (21)
width
R−L
2(Y − Y ) T + B
+
− 1)(T − B) Z re /(−2 N ). (22)
Yre = ( rw
height
T −B
X re = (

2( Z rw − a ) F + N
(23)
−
− 1)( F − N )).
b−a
F−N
2( X qw − X ) R + L
+
− 1)( R − L) Z qe /(−2 N ). (24)
X qe = (
width
R−L
2(Yqw − Y ) T + B
Yqe = (
+
− 1)(T − B ) Z qe /( −2 N ). (25)
height
T −B
Z re = 2 FN /((

Z qe = 2 FN /((

2( Z qw − a)
b−a

−

F+N
− 1)( F − N )).
F−N

(26)

Now, replacing (30) and (29) into (33)’s left side
and rearranging terms, we obtain:

3.3. Obtaining perspective normals
In the eye coordinates system, we assume a line
segment passes through points P(Xpe, Ype, Zpe) and
Q(Xqe, Yqe, Zqe), then the vector from P to Q can be
written as:
d = ( X qe − X pe , Yqe − Y pe , Z qe − Z pe ).

The parametric form of line segment PQ is
PQ(te)=P+dte, where te is the line segment length ratio
of PR to PQ in the eye coordinates, and has the range
of 0 to 1. So the eye coordinates of points P, R, and Q
in individual forms could be represented as follows:
B

B

B

B

B

(

X pw − X + ( X qw − X pw )tw

L
)(Z pe + (Zqe − Z pe )te ) =
+
width
R−L
X pw − X
L
.(
)Z pe +
+
width R − L
X qw − X
L
.((
)Zqe −
+
width R − L
X pw − X
L
.(
)Z pe )te .
+
width R − L

B

X re = X pe + ( X qe − X pe )te .

(27)

Yre = Y pe + (Yqe − Ype )te .

(28)

Z re = Z pe + ( Z qe − Z pe )te .

(29)

.

(30)

Yrw = Ypw + (Yqw − Y pw )tw .

(31)

Note that t w is the length ratio of line segments PR
to PQ on 2D display by discarding the depth value, and
also has a range of 0 to 1.
Submitting (18), (21) and (24) into (27), we obtain:
2( X rw − X ) R + L
+
− 1)( R − L) Z re /( −2 N ) =
width
R−L
2( X pw − X ) R + L
+
− 1)( R − L) Z pe /(−2 N ) +
.(
width
R−L
(32)
2( X qw − X ) R + L
+
− 1)( R − L) Z qe /( −2 N ) −
.((
width
R−L
2( X pw − X ) R + L
+
− 1)( R − L) Z pe /(−2 N ))te .
.(
width
R−L

Multiplying both sides of (32) by − N /( R − L), and
rearranging terms, we obtain:
(

X pw(Zqe − Z pe )te
width

X rw − X
L
) Z re =
+
width
R−L
X pw − X
L
.(
) Z pe +
+
width
R−L
X qw − X
L
.((
) Z qe −
+
width
R−L
X pw − X
L
.(
) Z pe )te .
+
width
R−L

Proceedings of the Computer Graphics, Imaging and Vision: New Trends (CGIV’05)
0-7695-2392-7/05 $20.00 © 2005 IEEE

−

L
R−L

L

Zqete −

R−L

X pw − X

+

Z pe +

+

width
L

Z pe

R−L

X pw − X

z pe +

width

Zqete +

width

width

Z pete.

Equation (34)'s right =
X qw − X

( Xqw − X pw)tw

X (Zqe − Z pe )te

( Xqw − X pw)(Zqe − Z pe )tetw

.

X rw = X pw + ( X qw − X pw )tw .

width

Z pe +

width
.

Similarly, with regard to the same points P, R, and
Q after being transformed into the window coordinates,
the window coordinates of points P, R, and Q can be
represented as follows:

X pw − X

Equation (34)' s left =
.

(

(34)

L
R−L

L
R−L

Z pe +

Zqete −

L

Z pete −

Z pete .
width
R−L
Discarding the same terms of both sides of (34), and
multiplying both sides of (34) by width, we obtain:
Equation (34)'s left = ( X qw − X pw )t w Z pe +
.

. X pw ( Z qe − Z pe )te +
.( X qw − X pw )( Z qe − Z pe )te t w .

Equation (34)'s right = ( X qw Z qe − X pw Z pe )te .
Let (34)’s right=left. Rearranging terms, we obtain:
( X qw − X pw )(Zqe − (Zqe − Z pe )tw )te = ( X qw − X pw )Z petw . (35)
Proposition. Z qe − ( Z qe − Z pe )tw ≠ 0.
Proof. Assume Zqe - (Zqe - Zpe)tw=0. Dividing both
sides by Zqe (since points P and Q are in the view
volume and Zqe<0), and rearranging terms, we obtain:
(36)
tw (1 − Z pe / Z qe ) = 1.
B

B

B

B

B

B

B

B

B

B

B

B

B

B

B

B

Since Zpe <0 and Zqe<0 in view volume, then Zpe/Zqe
>0.
If 0<Zpe/Zqe<1, then
0<(1-Zpe/Zqe )<1tw=1/(1-Zpe/Zq)>1.
This is in direct contradiction to tw in the range of 0
to 1.
B

B

B

B

B

B

B

B

B

B

B

B

B

B

B

B

B

B

B

B

B

B

If Zpe/Zqe =1 then tw(1- Zpe/Zqe)=0. This is in direct
contradiction to tw(1- Zpe/Zqe)=1.
If Zpe/Zqe>1 then
(1-Zpe/Zqe)<0tw=1/(1- Zpe/Zqe)<0.
This is also in direct contradiction to tw in the range
of 0 to 1.
Therefore: Z qe − ( Z qe − Z pe )tw ≠ 0. 
B

B

B

B

B

B

B

B

B

B

B

B

B

B

B

B

B

B

B

B

B

B

B

B

B

B

B

B

If Xqw ≠ Xpw, dividing both sides of (35) by
( X qw − X pw )( Z qe − ( Z qe − Z pe )tw ) , we obtain:
B

B

B

(a)

(b)

B

te = Z pe t w /( Z qe − ( Z qe − Z pe )tw ).

Dividing both the numerator and denominator by
Z pe (since point P is in the viewing volume and Zpe < 0
B

in the eye coordinates), we obtain:
tw
( X qw ≠ X pw ).
te =
Z qe / Z pe + (1 − Z qe / Z pe )tw

B

(37)

Similarly, submitting (19), (22) and (25) into (28), then
submitting (31) and (29) into the just obtained equation
and rearranging terms, we get:
tw
(38)
(Yqw ≠ Ypw ).
te =
Z qe / Z pe + (1 − Z qe / Z pe )tw
In (37) and (38), when Xpw=Xqw and Ypw=Yqw, we can not
use any one of these two equations to get the relations
of te and tw. However, when Xpw=Xqw and Ypw=Yqw, the
length of line segment PQ on the screen window is
zero (the depth value of points P and Q may or may not
be the same). That is to say that line segment PQ is just
a pixel on the screen window. In this case, we do not
perform interpolation.
So, after perspective projection and viewport
transformation, if line segment PQ on the screen is not
a point, we always have the following equation:
tw
(39)
.
te =
Z qe / Z pe + (1 − Z qe / Z pe )tw
B

B

B

B

B

B

B

B

B

B

B

B

B

B

B

B

B

B

B

B

B

B

We will use (39) to get perspective correct normal
vectors for Phong shading in the following content.
Note equation (39) is same as equation (10) in [1].
On the screen window, we assume that the
normalized vector of point P and Q are Vp and Vq. For
any point R at line segment PQ with line segment
length ratio of t w (tw=|PR|/|PQ|), we obtain the normal
vector Vr of point R by using Phong shading, as in
B

B

B

B

(c)
(d)
Figure 4. Phong shaded triangle using diffuse
component only: (a) without correct normal
vectors. (b) with correct normal vectors. (c)
intensity distribution of
(a). (d) intensity
distribution of (b)

B

B

B

(a)

(b)

(c)
(d)
Figure 5. Phong shaded cone (represented in
8192 triangles) using diffuse component of a
light source only: (a) without correct normal
vectors. (b) with correct normal vectors.(c) the
intensity distribution of (a). (d) the intensity
distribution of (b)

B

eye coordinates. Let V’r be the normal vector of point
R obtained by using te. Now the normal vector of point
R becomes
B

Vr = tw × Vq + (1 − tw ) × Vp .

(40)

tw is the 2D ratio on the screen window, not a ratio in
the eye coordinates. te is the line segment ratio in the
B

B

B

B

Proceedings of the Computer Graphics, Imaging and Vision: New Trends (CGIV’05)
0-7695-2392-7/05 $20.00 © 2005 IEEE

B

B

B

Vr' = te × Vq + (1 − te ) × Vp .

(41)

where te can be obtained from (39). The eye
coordinates Zqe and Zpe are used to get te from (39).
B

B

B

B

B

B

B

B

3.4. Interpolating using window coordinates
How do we interpolate line segment PQ on screen
using the window coordinates? If we know the depth
values of two end points P and Q, F, N, a, and b, we
can use (20) and (26) to obtain Z qe / Z pe :
Z qe / Z pe =

( Z pw − a)( F − N ) − N (b − a)
( Z qw − a)( F − N ) − N (b − a)

.

(42)
Figure 6.
(tw-te) as function of tw when
Zqe/Zpe=100, 10, 5, 1, 0.2, 0.1 and 0.01

Let (42)’s right=λ, Then we can use (39) to obtain te:
B

te =

tw
.
λ + (1 − λ )te

B

References

(43)

4. Results

[1] Kok-Lim Low, “Perspective-Correct Interpolation,”
http://www.cs.unc.edu/~lowk/research/writings/lowk_persp_i
nterp.pdf
[2] H. Gouraud, “Continuous Shading of Curved Surface,” IEEE
Trans. Computers, vol. 20, no. 6, June 1971
[3] B.T. Phong, “Illumination for Computer Generated
Pictures,” Comm. ACM, vol. 18, no. 6, June 1975
[4] J.D. Foley, A. van Dam, S.K. Feiner, and J.F. Hughes,
Computer Graphics: Principles and Practice, Second Edition
in C, pp. 735-740, Addison-Wesley, 1996
[5] F.S. Hill, Jr., Computer Graphics using OpenGL, Second
Edition, pp. 371-387, Science Press and Pearson Education
Asia Limited
[6] J.F. Blinn, "Models of Light Reflection for Computer
Synthesized Pictures," Proc. SIGGRAPH, pp. 192-198, 1977
[7] J.F. Blinn, “Hyperbolic Interpolation,” IEEE Computer
Graphics and Applications, vol. 12, no. 4, July, 1992, pp. 8994
[8] M. Feda, R.F. Tobler and L. Neumann, “Fast Perspective Zbuffer with reverse Depths,” http://www.cg.tuwien.ac.at/TR/94/TR186-2-94-16Paper.ps.gz
[9] P.S. Heckbert and H.P. Morton, “Interpolation for
Polygon
Texture
Mapping
and
Shading,”
http://citeseer.ist.psu.edu/cache/papers/cs/1774/http://zSzzSz
www.cs.cmu.eduzSz~phzSztextin.pdf/heckbert91interpolation
.pdf
[10] Jim X. Chen, Guide to Graphics Software Tools, pp. 64,
Springer, 2002
[11] A.A.M. Kuijk and E.H. Blake, “Faster Phong Shading via
Angular Interpolation,” Computer Graphics Forum, vol. 8, no.
4, pp. 315-324, 1989
T

T

For a triangle (Fig. 4), a different visual effect is
shown in (a) and (b). (c) and (d) are the intensity
distribution of (a) and (b), respectively. Similarly, for a
cone (approximated by triangles, which are introduced
in [3] and [10]), the visual effects are also different
with and without perspective correct normals.
More detailed information about how Z coordinates
ratio (in the eye coordinates) influences the length ratio
(in the window coordinates) of the line segments is
presented in Fig. 6, which is obtained from (39). From
Fig. 6, we can see that there is no change of (tw - te),
when the Z coordinates ratio of the two end points in
the eye coordinates is equal to 1. There is also no
change of (tw - te) at the two end points (tw=0 and tw=1).
From Fig. 6, when the Z coordinates in eye coordinates
ratio is 100, and tw is 0.9, we can see that (tw - te) is
about 0.8, which affects liner interpolation seriously.
B

B

B

B

B

B

B

B

B

B

B

B

B

B

B

B

B

B

T

T

T

5. Conclusions

T

We have derived perspective correct interpolation
directly from eye space to screen space within standard
graphics pipeline by using matrix technology. We also
presented how perspective correct interpolation is used
in Phong shading and how much the z coordinates ratio
in the eye space affects the perspective interpolation in
the device coordinates space. Experiments show that,
for Phong shading, exists a clear visual difference
between using it with perspective correct interpolation
and without it.

Proceedings of the Computer Graphics, Imaging and Vision: New Trends (CGIV’05)
0-7695-2392-7/05 $20.00 © 2005 IEEE

