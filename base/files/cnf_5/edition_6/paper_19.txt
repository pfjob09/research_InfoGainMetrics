Face Recognition base on Low Dimension Gabor Feature using Direct
Fractional-Step LDA
Zhang Yong Mei
Department of Computer
Engineering and Science of
South China University of
Technology
may1230@hotmail.com

ZhangXing Ming
Department of Computer
Engineering and Science of
South China University of
Technology
cszxm@scut.edu.cn

Abstract
A novel approach of Gabor feature based face
recognition approach is presented in this paper. Gabor
wavelet is a very powerful tool to analyze the texture of
an image. Due to its characteristic of being insensitive
to the varying illumination condition, it also has been
widely used in face recognition task. However, the
redundancy of Gabor feature limited its application. In
this paper, a feature mask is applied for the
sub-sampling of the original magnitude feature of
Gabor transform. What’s more, a lately algorithm of
discrimination, Direct Fractional-Step LDA, is adopted
instead of traditional method of PCA+LDA. It
preserved more important discriminate information
during reducing dimensions. The experiment results
indicate that the performance is superior to single
DF-LDA and the method based on low-dimensional
Gabor feature with PCA+LDA.

1.Introduction
Face recognition has drawn a lot of attention in
recent years. Gabor features please many scientists due
to its well performance in recognition. To overcome the
illumination varieties, which is considered as one of the
primary obstacles in face recognition system, many
works have been done in the past. Some general method
like histogram equalization and Affine Transform
(AT)[1] are in common use. Some image preprocess
approach have been tried to reduce the affection as
well. Such as Self Quotient Image(SQI) in [2], and QI
in[3]. It did enhance the shape and the detail of the dark
part of face image. However, it also blurs the whole
image as well. Those unexpected noise limited the
performances of them. Since Gabor features is

Proceedings of the Computer Graphics, Imaging and Vision: New Trends (CGIV’05)
0-7695-2392-7/05 $20.00 © 2005 IEEE

GuoYuCong
Department of Computer
Engineering and Science of
South China University of
Technology
yucong_guo@hotmail.com

insensitive to illumination, people have a great
expectation on Gabor feature based method [6][7][8].
Unfortunately, Gabor features have too much
redundancy. Pure Gabor features could cause a
disaster not only in storage but in training. To solve
this problem, a dimension reduce strategy should be
adopted. Few good methods have been presented.
Robert
Alterson
in
[9]
proposed
an
adaptive-sampling algorithm for special signature
generation. But it’s not fit for face recognition.
In [4], an optimal Gabor feature sampling
approach was proposed. A GGFM(Global Gabor
Feature Mask ) or IGFM(Individual Gabor Feature
Mask) was generated by means of Gabor transform
and Principal Component Analysis (PCA). And then
a slide window would scan the mask image and to
judge which points should stay to construct a low
dimension feature mask. At last, the original Gabor
features would be sub-sampled according to the low
dimension GGFM or IGFM. That’s how a low
dimension Gabor feature around 7 to 10 thousands
dims comes out. For further dimension reduce and
classes discriminate, PCA and Linear Discriminant
Analysis (LDA) were applied to finish the
recognition phase.
The approached mention above achieved a
satisfying recognition rate in small databases, such as
ORL face database with 40 persons. However, still
there are some shortages. The performance under
very terrible illumination is instable. And the time
and hardware cost of PCA training also annoy people
sometimes.
In this paper, Direct Fractional-Step LDA
(DF-LDA) is used for the task of FR. DF-LDA is
proposed in [5]. It is a combine of Direct LDA
(D-LDA) and fractional steps analysis (F-LDA). In

Ψ ( x , y , ω 0 ,θ )

DF-LDA framework, data are processed directly in the
original high-dimensional input space. So that, some
significant discriminatory information which might be
lost due to PCA process could be preserved.

=

1
2πσ

[

Mask training images

e −(( x cosθ + y sin θ )

2

+ ( − x sin θ + y cos θ ) 2 ) / 2σ 2

× e i (ω 0 x cosθ +ω 0 y sin θ ) − e −ω 0 σ

Gabor filter
Magnitude Gabor features
PCA

Face images

Gabor filter

2

2

/2

]

(1)
Here, x, y denotes the pixel in a face image, ω0 is
the radical center frequency, θ shows the
orientation of Gabor wavelet, and

σ

stands the

standard deviations of the Gaussian function.
The relationship between σ and ω0 can be derived to

σ = K / ω0

be

Gabor feature mask
GGFM or IGFM

2φ + 1
)
,Where K = 2 ln 2( φ
2 −1

(2).
Here

Sub-Sampling
paper,
Low-dimensional Gabor
feature mask

Sub-Sampli
Low-dimensional Gabor features
DF-LDA

Result

Fig.1. The framework of our approach

2.Low dimensional Gabor Feature
2.1Gabor Features
Gabor wavelets have both orientation and frequency
characteristics which are supposed to be similar to those
of the human visual system. Gabor filters have been
widely applied to texture representation and
segmentation.
In spatial domain, Gabor wavelets (kernels, filters) is
a complex exponential modulated by a Gaussian
function. Assume that σ x

2

= σ y = σ , It can be defined

as follows [4].

Proceedings of the Computer Graphics, Imaging and Vision: New Trends (CGIV’05)
0-7695-2392-7/05 $20.00 © 2005 IEEE

φ

φ

is the band with in octaves. In this

=1.Then

select

three

σ = K / ω0 ≈ π / ω0
center

. We

frequencies:

ω = π / 2 , ω0 = 2π / 4 , and ω = π / 2 .
2

1
0

1
0

Assume G(x,y) denotes the origin image, the
convolution of the image and the Gabor wavelet
should be:

CΨG ( x, y , ω0 ,θ ) = G ( x, y ) ∗ Ψ ( x, y , ω0 ,θ ) (3)
The convolution can be performed more efficient
by means of Fast Fourier Transform (FFT),
point-by-point multiplications, and Inverse Fast
Fourier Transform (IFFT). The result of (3) should be
a complex presentation of Gabor features. And the
magnitude of those complex vectors would be the
basic Gabor feature for texture segmentation and
recognition.
The magnitude of Gabor representation should be
normalized to zero mean and unit variance. The
concatenated form of those CΨG ( x , y , ω0 ,θ ) with
different scales and orientations is the final Gabor
feature. We name it vector C:

(

)

(

)

§ C ΨG x, y, ω 01 ,θ 1 , C ΨG x, y, ω 01 ,θ 2 ,....,
C =¨
¨ × C x, y, ω 1 ,θ m ,...., C x, y, ω n ,θ m
0
0
ΨG
© ΨG
(4)

(

)

(

·
¸
¸
¹

)

Γ

θ =0

π /8

π /4

3π / 8

π /2

5π / 8

3π / 4

7 π /8

7π / 8

ω01 = π / 2

ω02 = 2π /4

ω01 =π /2
Fig 2. Gabor wavelet representation of a sample image (size 64h64)
Take a image of 64h64 for example. Its Gabor
feature of 3 scales and 8 orientations would come out to
have 98,304(64h64h8h3) dimension. That’s a huge
number not only for calculation but memory storage.
To solve this problem, a sampling strategy is introduced
in section 2.2.

2.2Gabor Feature sub-Sampling
In [4]. The task of sub-sampling begins with the
generation of feature mask. And the brief steps of the
approach are described as follows:
1. A mask training set with about 21 randomly selected
subjects (12 male and 9 female) should be prepared.
2. Calculate its Gabor feature by form (1), (3) and (4).
3. PCA is performed on those Gabor feature vectors to
compute the eigenvectors, vi, where i=1,...,N,
corresponding to the N largest eigenvalues in
descending order. N satisfies.
N

( ¦ i =1 λi 2 ) / ¦ i λi 2 > 0.95
4. A summation vector V would be calculated as
follow:
i= N
i=N
ªi=N
º
V = « ¦ vi1 , ¦ vi 2 ,....,¦ vid »
¬ i =1
¼
i =1
i =1

(5)

5. A manually constructed elliptical mask (Fig.3) would
be used to remove the regions of background which
considered to be affecting the Gabor feature.

Fig.3 elliptical mask (64h64)

6. The largest 25% of the magnitudes are called
key points, where others called assistant points.
There are two ways to divide key points and
assistant points. In the first way we select the
largest 25% points beyond the whole Gabor
feature to be key points. The mask comes out
through this method is call GGFM (Global Gabor
Feature Mask). In the second way, we select the
largest 25% points from each component of the
Gabor feature to be key points. This mask is called
IGFM (Individual Gabor Feature Mask).
7. In order to reduce the dimensions of Gabor
feature. Sub-sampling based on feature mask is
required. I.e. not all points in GGFM or IGFM are
going to stay. We have to select some points of
them to construct a low-dimensional feature mask.
It’s easy to understand that key points carry more
important information than assistant point. So the
sampling intervals over these two different reigns
should be different. In this paper, we applied 4:6
sampling intervals over the key points and assistant
points. To determine whether a point is selected for
feature extraction, the point is considered to be the
center of a slide window whose size is dependent
on its type. In this paper, key points window is 4h
4 while assistant points window is 6h6. If there is
no selected point in the window, the point under

Proceedings of the Computer Graphics, Imaging and Vision: New Trends (CGIV’05)
0-7695-2392-7/05 $20.00 © 2005 IEEE

considered will be selected. All those selected together

at last construct a low-dimensional feature mask.

Fig.4 a)GGFM trained from IFACE database with selecting percentage of 30%

Fig.4 b)IGFM trained from IFACE database with selecting percentage of 30%
C

After all steps above have been done, a sub sampling
process could be achieved according to the
low-dimension feature mask. To an original Gabor
feature vector, we can drop or keep an element of the
vector refer to the low-dimensional feature mask. In
this way, a low-dimensional Gabor feature could be
easily and quickly computed.

3.Direct fractional-Step LDA (DF-LDA)
DF-LDA is a new enhanced algorithm for feature
representation and discriminatory. This method not
only helps to overcome the shortage and limitations of
D-LDA (direct LDA) and F-LDA (fractional steps
LDA) but also combine the advantage of them. More
detail should be referred to [5] and [10].Here a brief
algorithm flow is present.

Sˆ BTM =

C

¦φ φ

T

i i

i =1

(6)
is the expression of weighted between-classes scatter
matrix, where

φi = ( Li / L)1/ 2 ¦ j =1 (ω ( d ij ))1/ 2 ( zi − z j )

,
is the

zi is the mean of class

zi , Li
number of elements in zi ,and d ij = zi − z j is
the Euclidean distance between the means of class
i and class j. The weighting function

ω (d ij ) = (d ij ) −2 p with p=2,3....
The algorithm steps are as follows:
Input:

A

set

of

training

low-dimensional Gabor vector

N-dimensional

{zi }i =1 .
L

Output: A low-dimensional representation y of z
with enhanced discriminatory power, after a
transformation y = ϕ ( z )
.
Steps:

φbTφb with
non-zero eigenvalues: Em = [ e1...em ] , where
T
ˆ
m ≤ C − 1 and φb is from S BTM = φbφb

1. Calculate those eigenvectors of

Proceedings of the Computer Graphics, Imaging and Vision: New Trends (CGIV’05)
0-7695-2392-7/05 $20.00 © 2005 IEEE

.

xi = ΓT zi

2. Calculate the first m most significant eigenvectors

SˆBTM by

and their corresponding eigenvalues of

6. Further reduce the dimensionality of

V = φb Em and Λ b = V SˆBTMV .
−1/ 2
3. Let U = V Λ b
. Calculate eigenvectors of
T

to

U STOTU , P .
largest

eigenvalues.

M (≤ m)
'

Let

selected

and

M ' h M ) be the bases of the output space.

7. The optimal discriminant feature representation of
z can be obtained by y = ϕ ( z ) = ( ΓW )T z
.

the

PM ' and Λ ω be the

eigenvectors

'
xi from M

M by performing a F-LDA on {xi }iL=1 , and let W

(size

T

4. Optionally discard those eigenvectors in P with

.

their

4.Experiments

corresponding eigenvalues.
5.

Map

all

Gabor

vectors

{zi }i =1
L

to

Tow database, the ORL and IFACE, are used to
demonstrate the effectiveness of the proposed FR
strategy.

the

subspace
spanned
by
M ' demensional
−1/ 2
L
Γ = UPM ' Λω
and have {xi }i =1
where
,
,

A)

B)

C)
Fig.5. Some samples from ORL database.

Fig.6. Some samples under three different
illuminating conditions from IFACE database.

images would be divided to two part, one is probe
set, while another become gallery. GGFM is applied
to the sampling.
The comparison between three approaches would come
out the result as below:

ORL is a popular face database which contains 40
distinct persons with 10 images per person. 20 persons
with 3 images from ORL database are selected for
feature mask training. 4 images in 10 are used to train
PCA+LDA kernel or DF-LDA kernel, and the rest of the
Training
set
2 ,4, 8,
10
3, 4, 5, 9
1, 2, 8, 9

Gallery

3, 6, 7

Probe

1, 5, 9

PCA

Fisher

90.00ˁ

94.00%

DF-LDA Sampling
Gabor feature
with PCA+LDA
96.67%
98.33%

Sampling
Gabor feature
with DF-LDA
97.5%

1, 2, 6
7, 8, 10
96.67%
99.1%
90.00ˁ 93.33ˁ 97.50ˁ
7, 4, 3
5, 6, 10
97.50%
98.33%
89.17ˁ 90.00ˁ 94.17ˁ
Table 1. Recognition rate comparison between different approaches in ORL database.

IFACE is a database with 106 persons with more than
50 images per person. And those images are under three
different illuminating conditions, A, B, C, as shown in
Fig.6. In the experiment, we select 10 images for each

condition, as probe set A, B, C. And we also pick 21
persons with 5 images from A as a feature mask
training set. What’s more, a gallery which contains
106 persons with 10 images per subject from

Proceedings of the Computer Graphics, Imaging and Vision: New Trends (CGIV’05)
0-7695-2392-7/05 $20.00 © 2005 IEEE

conditions A, B is ready. And IGFM is applied to the

sampling.

Illuminating conditions

DF-LDA
Sampling Gabor feature Sampling Gabor feature
with AT
With PCA+LDA
with DF-LDA
A
98.11%
99.05%
100%
B
90.37%
91.51%
92.28%
C
80.18%
82.08%
85.63%
Table 2. Recognition rate comparison under varying illumination
between three different approaches in IFACE database.

Please notice that the results of PCA and Fisher
approach have not been put in the Fig.8, because,
without preprocess, PCA and Fisher have terrible
performances under B and C illuminating conditions.
There is no need of comparing. And the single DF-LDA
is also limited by terrible illuminating conditions. So we
add a preprocess with an enhanced AT [1] algorithm.

5.Conclusions
Refer
to
the
experiment
results
above,
low-dimensional Gabor features perform well under
varying illumination without image preprocessing.
Because the Gabor features are insensitive to the
illumination variety. And the power of DF-LDA has also
been proved. It does not only fit for the original image
but also improve the recognition rate in low-dimensional
Gabor feature. Considering time cost, DF-LDA also is a
better choice than PCA+LDA. In both experiments,
training a DF-LDA kernel is roughly two times faster
than calculate a PCA kernel.

6.Reference
[1] Juhua Zhu, Bede Liu and Stuart C.Schwartz: General
illumination correction and its application to face
normalization. Proceeding of AMFG, 2003.
[2]Haitao Wang, Stan Z Li, Yangsheng Wang: Face
Recognition under Varying Lighting Conditions Using Self
Quotient Image. Sixth IEEE International Conference on
Automatic Face and Gesture Recognition May 17 - 19, 2004.
[3]Amnon Shashua, and Tammy Riklin-Raiv: The quotient
image: Class-based re-rendering and recognition with varying

illuminations. IEEE transactions on Pattern Analysis and
Machine Intelligence, Vol. 23, No.2, pp129-139, 2001.
[4]Dang-Hui Liu, Kin-Man Lam, Lan-Sun Shen:
Optimal sampling of Gabor features for face recognition.
Pattern Recognition Letters 25 (2004) 267–276.
[5] Juwei Lu, Kostantinos N. Plataniotis, and Anastasios
N. Venetsanopoulos: Face Recognition Using
LDA-Based Algorithms. IEEE Transactions on neural
networks, vol. 14, NO. 1, January 2003.
[6] LinLin Shen and Li Bai: Gabor Feature Based Face
Recognition Using Kernel Methods. Proceedings of the
Sixth IEEE International Conference on Automatic Face
and Gesture Recognition (FGR’04).
[7] Chengjun Liu, Member: Gabor-Based Kernel PCA
with Fractional Power Polynomial Models for Face
Recognition. IEEE Transactions on Pattern Analysis and
Machine Intelligence, VOL. 26, NO. 5, MAY 2004.
[8] LinLin Shen and Li Bai: Gabor Wavelets and Kernel
Direct Discriminant Analysis for Face Recognition.
Proceedings of the 17th International Conference on
Pattern Recognition (ICPR’04).
[9] Robert Alterson, Minas Spetsakis: Object recognition
with adaptive Gabor features. Image and Vision
Computing 22 (2004) 1007–1014.
[10] Juwei Lu, K.N. Plataniotis, A.N. Venetsanopoulos:
Regularization Studies of Linear Discriminant Analysis
in Small Sample Size Scenarios with Application to Face
Recognition. Preprint submitted to Elsevier Science 17
August 2004.

Proceedings of the Computer Graphics, Imaging and Vision: New Trends (CGIV’05)
0-7695-2392-7/05 $20.00 © 2005 IEEE

