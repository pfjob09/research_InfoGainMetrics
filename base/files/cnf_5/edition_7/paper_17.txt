Features Extraction Based On Fuzzy Clustering and Segmentation onto
the Motion Region for Medium Field Surveillance Application
Mohamad Nansah Maliki1

Syed Abdul Rahman Abu Bakar Al-Attas2

Computer Vision, Video and Image Processing (CVVIP) Research Group,
Dept. of Microelectronic and Computer Engineering (MiCE),
Faculty of Electrical Engineering,
Universiti Teknologi Malaysia, 81310 Skudai, Johor, Malaysia
E-mail: 1mnansyah@hotmail.com , 2syed@suria.fke.utm.my

Abstract
Fuzzy-based clustering algorithm is becoming popular
in image processing, especially in image segmentation.
Based on the degree of the membership function, each pixel
can be grouped into “natural group” of pixels according to
the spatial coordinate using their values. In this work we
present features extraction based on fuzzy clustering and
segmentation onto the motion region for medium field
surveillance application. Instead of using blob analysis, we
believe that fuzzy based clustering algorithm, can also be
used to generate different clusters. Incorporating the
motion-based segmentation the complexity of the fuzzy
clustering will also be reduced because only the motion
region will be processed to the clustering algorithm.

1. Introduction
Fuzzy clustering organizes the original image into
several “natural groups” of pixels in a given observation
using fuzzy subset assumptions on clusters. From the fuzzy
clustering one will obtain the degree of membership of
certain pixels to a cluster, and the periphery of the cluster
will become uncertain [1, 2]. Fuzzy C-Mean (FCM)
clustering algorithm has a wide application especially in
control engineering. Due to its ability to represent linguistic
variables, fuzzy logic is a powerful tool in handling some
form of uncertainty and imprecision. Here we consider the
pixel value and its spatial location as the data to be analyzed.
Each pixel needs to be clustered based-on its pixel value and
spatial location, y-plane and x-plane to form a membership
function value i.e. U ik .
The aim of the paper is to simplify the data stream
containing n objects into K mutually disjoint clusters. The

state of the clustering is expressed by n u K matrix of U ik .
The criteria for this U ik are shown in equations (1), (2) and
(3) respectively. Each cluster is represented by its center
prototype cluster Vk . These prototype clusters will keep on
changing until they converge to a stable value.
K

¦U

ik

1; i 1,..., n.

(1)

¦U

ik

! 1; k 1,...K .

(2)

k 1
n
i 1

U ik  [0.1], i 1,..., n; k 1,..., K ;

(3)

The criterion used to cluster each data stream is basedon the membership function U ik that minimizes the total
mean square error as shown in equation (4). Equations (5)
and (6) show the criterion of U ik and criterion of Vk (center
of prototype cluster) respectively.
n

K

¦¦ (U

J (U ik ,Vk )

ik

) m || xi  Vk ||2

(4)

i 1 k 1

1

U ik

K

¦{d ( x ,V ) / d ( x ,V )}
i

k

i

2
m 1

(5)

j

j 1

n

¦ (U
Vk

ik

) m xi

i 1
n

¦ (U

(6)
ik

)

m

i 1

Proceedings of the International Conference on Computer Graphics, Imaging and Visualization (CGIV’04)
0-7695-2178-9/04 $20.00 © 2004 IEEE

frame differences between two consecutive frame without
any moving object.

where;

i 1,..., n; k 1,..., K .
m is the degree of fuzziness,
d is the distance between two points,

and xi is the input data.
In general, the object seen by the camera with respect to
the field of view can be classified into three types; near field,
medium field and far field [16]. The medium field is used
predominantly in surveillance applications. In this field,
most applications used blob analysis for segmentation [16].
In this paper we will show how fuzzy clustering algorithm
can be used to extract information such as the center of the
clusters and their respective location.
This paper is organized as follows; Section 2 describes
the detection of moving object. Section 3 describes the
clustering segmentation scheme and how features are
extracted based on the fuzzy membership function. The link
between section 2 and section 3 are related in reducing the
processing time when both techniques are combined
together. Section 4 provides the initial experimental result
and finally section 5 gives the conclusion of the work
presented.

1(a)

1(b)

1(c)

2. Detection of Moving Object
Since we are interested in the moving object region
only, we concentrate our algorithm technique in this region.
In addition, this will also overcome the computation
complexity of the FCM algorithm. To do this, motion object
detector has been applied. The detector consists of color
separation, frame differencing and projection histogram.

2.1. Color Separation
Video sequence captured from RGB format suffers from
blinking artifact. From the RGB format we separate the color
information into the YUV format because the sensitivity of
the luminance component is more stable compared to the
color component. The transformation from RGB to YUV
format is done through equations (7) where the details can be
found in [3].
ªY º
«U »
« »
«¬V »¼

0.587 0.114º ª R º
ª 0.299
« 0.147  0.589 0.436» «G »
«
»« »
«¬ 0.615  0.515  0.1 »¼ «¬ B »¼

(7)

Within the YUV format, the Y-luminance data has been
selected for motion detection module, while both
chrominance values U and V are kept to reconstruct color
video for displaying purpose. Figure 1 shows the result of

1(d)

1(e)

Figures 1. 1(a) Original live color captured at time t, 1(b), 1(c)
and 1(d) show the results of differencing consecutive frames
using the R, G, and B component respectively. Figure 1(e)
Result of frame differencing based on luminance- note the
absent of blinking artifacts.

2.2. Motion Detection
There are many existing motion detection algorithms
that are already established and some of them can be found
in [4, 5, 6, 7, 8, 9, 10, 11, 12, and 13]. Generally all of these
techniques can be divided into four categories, i.e. pixelbased, features-based, optical flow [14] and frequency
domain approach as mentioned in [4].
In this research work, the motion detection technique
employed is based on differencing between edges taken from
two consecutive frames. Features are taken from the edges of
the image. We employed the Hexagonal-Based Edge
Detector (HED) as was done in [15]. One superior advantage
of using HED is its speed performance which makes it
suitable for real-time application [15].

Proceedings of the International Conference on Computer Graphics, Imaging and Visualization (CGIV’04)
0-7695-2178-9/04 $20.00 © 2004 IEEE

example of a 5-dimensional FCM respectively. Figure 4
show the flowchart for the FCM algorithm .
Motion
Region



x1 x2 x3 x 4 x5 x6 x7 x8

Vertical
projection

x M 1 x M
y1 I11 I 12 I 13 I14 I15 I16 I17 I18 .. .. I1,M1 I 1, M
y 2 I 21 I 22 I 23 I 24 I 25 I 26 I 27 I 28 .. .. .. I2,M

Horizontal
projection

y3 I 31 I 32 I 33 I 34 I 35 I 36 I 37 I 38 .. ..
y 4 I 41 I 42
y 5 I 51 I 52



y 6 I 61 I 62 I 63

Figure 2. Motion region detection based on projection
histogram

:
:
y N 1 IN1,M

2.3. Projection histogram
Projection histogram technique is applied to the output
edge map from the motion detection module. We make use
of the histogram projection technique to encompass the
moving object within a box. Figure 2 shows the result of
motion region detector based on the projection histogram.
Based on the motion detection algorithm one can segment
the monitored area into motion region and static region as
was done in [15], using projection histograms. Unfortunately
this method fails when multiple moving objects in the
monitoring area are too closed to one another. Moreover the
technique works for stationary or mounted camera only. For
the pant and tilt camera, motion detection and segmentation
using image mosaic has been reported in [9] and noise
reduction using time-varying noise level technique has been
proposed in [8].

3. Clustering and Segmentation
For analysis purpose, redundancies information in
captured image should be eliminated as much as possible. In
clustering segmentation, redundancies in captured image are
manipulated so that the representation of the image is
simplified. Through segmentation, each pixel will be
grouped according to its homogeneity. We proposed FCM
algorithm in our segmentation algorithm. FCM uses
unsupervised segmentation scheme with supervised number
of clusters. With this procedure pixels will be clustered into
“natural group” relying on their spatial location and
similarity intensity value.
In the first stage, 2D image data need to be represented
by into 1D data. The way of doing this is by concatenating
the image into a column vector as shown in Figure 3(a) and
3(b). Each representation of data will form the M dimensional of FCM algorithm. Figure 3(b) shows an
example of a 3-dimensional FCM and Figure 3(c) shows an

..

:

I 43 I 44 I 45 I 46 I 47 I 48 .. ..
I 53 I 54 I 55 I 56 I 57 I 58 .. ..

:
:
:

:
:
:

.. :
.. :
I 64 I 65 I 66 I 67 I 68 .. .. .. :
: : : : : % .. .. :
: : : : : : % .. :
: : : : : .. .. % IN1,M1

y N I N ,1 I N , 2 I N ,3 I N , 4 I N ,5 I N , 6 I N , 7 I N ,8 .. .. INM1 I NM
3(a)

l

x

y

L

l

x

y

R

G

B

1

1

1

I11

1

1

1

R11 G11 B11

2

1

2

I 21

2

1

2

3

1

3

I 31

3

1

3

R21 G21 B21
R31 G31 B31

4

1

4

I 41

4

1

4

R41 G41 B41

5

1

5

I 51

5

1

5

R51 G51 B51

6

1

6

I 61

6

1

6

7

1

7

I 71

7

1

7

R61 G61 B61
R71 G71 B71

:

:

:

:

:

:

:

:

:

:

:

:

:

:

:

:

:

:

:

:

:

:

:

:

:

:

:

:

:

:

:

:

:

:

:

:

:

:

:

:

:

:

:

:

:

:

:

:

:

:

:

:

:

:

:

:

:

:

:

:

:

:

:

:

:

:

:

:

:

:

M

N-2

RN2,MGN2,M BN2,M

N*M2

M

N-2

I N  2, M

N*M2

N*M1

M

N-1 I N 1, M

N*M1

M

N-1

RN1,M GN1,M BN1,M

N*M

M

N*M

M

N

RNM GNM BNM

N

I NM

3(b)

3(c)

Figure 3. 3(a): 2D data for one frame. 3(b) 1D Data into 3D
FCM algorithm and correlated with same corresponding
level, l . 3(c) 1D Data into 5D FCM algorithm and correlated
with same corresponding level, l .

Proceedings of the International Conference on Computer Graphics, Imaging and Visualization (CGIV’04)
0-7695-2178-9/04 $20.00 © 2004 IEEE

Initialize weight
of prototype
Standardize initial
weight over K

Standardize cluster
weight over i

Uik

Compute new prototype
cluster center Vk

5(c)
Compute new
weight
I<Imax
yes
no
Assign feature vector according the
max. weight/membership function

Uik

Figure 4. General flowchart for the FCM algorithm.

4. Initial experimental results and discussion
As described before, we applied fuzzy clustering onto
the motion region to reduce complexity i.e. motion-based
segmentation. Figure 5 below shows the fuzzy clustering
algorithm onto the motion region. Figure 5(a) is the motion
region and figure 5(b), 5(c) and 5(d) show the result in
different view angle.

5(d)

Figure 5 – 5(a): Output from motion region detector. 5(b):
Output from clustering algorithm. 5(c) :Membership function
Uik plot with their corresponding spatial location (x,y). 5(d):
Same graph as 5(c) accept their view angle.

Conclusions
The aim of this work is to extract the moving feature
and enhance the feature in real-time live video frame rate.
Motion region is obtained using the projection histogram
applied on differenced edge-image. Once the motion region
is located then clustering algorithm is applied to extract the
center point of each cluster. The continuation of this research
is to use this simplification into feature trajectory module.
Figure 6 show the result of FCM algorithm on the motion
region for frame 29 to frame 34.
5(a)

5(b)

Proceedings of the International Conference on Computer Graphics, Imaging and Visualization (CGIV’04)
0-7695-2178-9/04 $20.00 © 2004 IEEE

Frame 29
Frame 33

Frame 34
Frame 30
Figures 6 – Sample of activities taken from frames 29-34.
Each frame is shown with its corresponding center each
cluster.

Acknowledgements
This research was supported by Malaysian Ministry of
Science, Technology and Environment (MOSTE) of
Malaysia under the Intensification of Research in Priority
Area (IRPA) grant scheme vote. No. 74072.
Frame 31

References

Frame 32

[1] Mika Sato-Ilic. “On Clustering based on
Homogeneity”
IFSA World Congress and 20th NAFIPS International
Conference pg. 2508-2510, July 2001.
[2] Mika Sato-Ilic. “On Evaluation of Clustering using
Homogeneity Analysis”, IEEE International Conference on
System, Man and Cybernetics vol.5, pg 3588-3593. Okt. 2000.
[3] Yao Wang, Jorn Ostermann, Ya-Qin. ”Video Processing and
communications”. Prentice Hall.2002.
[4] Syed Abdul Rahman Syed Abu Bakar, R.J. Green. “A SubEdge
Moving
Object
Detector:
Algorithm
and
Implementation”. 1st East Asian Conference on Light wave
System, Laser and
Optoelectronic. Kuala Lumpur. 1999
[5] Stefan Huwer, Heinrich Niemann. “Adaptive Change
Detection for Real-Time Surveillance Application”. Third

Proceedings of the International Conference on Computer Graphics, Imaging and Visualization (CGIV’04)
0-7695-2178-9/04 $20.00 © 2004 IEEE

[6]

[7]

[8]

[9]

[10]

[11]

[12]

[13]

[14]
[15]

[16]

IEEE International Workshop on Visual Surveillance. (VS2000). Pp. 37-45. July 2000.
Paul L. Rosin. “Thresholding for Change Detection”. The 6th
International Conference on Computer Vision (ICCV’98).
Bombay, India. Jan 1998.
Ismail Haritaoglu, Ross Cutler, David Harwood, Larry S.
Davis. “Backpack: Detection of People Carrying Objects
Using Silhouettes.” IEEE International Conference on
Computer Vision. Greece, vol.1. Sept. 1999
Antonio Albiol, Cristina Sandoval, et. el. “Robust motion
detector for Video Surveillance Application”. International
Conference on Image Processing (ICIP), 2003.
Kiran S. Bhat, Mahesh Saptharishi, Pradeep K. Khosla.
“Motion Detection and Segmentation Using Image Mosaics”
IEEE Transactions on Robotics and Automaation: Special
Issue on Multi-Robot System, vol 18, no.5, pp. 826-836.
October 2002.
Dieter Koller, Joseph Weber, Jitendra Malik. “Robust Multiple
Car Tracking with Occlusion Reasoning.” International Proc.
3th European Conference on Computer Vision. pp 189-196.
Sweden.1994.
Yu Zhong, Anil K. Jain, M.-P Dubuisson-Jolly. “Object
Tracking Using Deformable Templates.” IEEE Trans. On
Pattern Analysis and Machine Intelligence (PAMI) vol.22, No.
5 May, 2000.
Paul L. Rosin. “Thresholding for Change Detection”. The 6th
International Conference on Computer Vision (ICCV’98).
Bombay, India. Jan 1998.
Peter N. Prokopowicz, Michel J.Swain, Roger E. Kahn. “Task
and Environment-Sensitive Tracking.” IEEE Proc. of the
International Association for Pattern Recognition (IAPR)
workshop on Visual Behaviors. June 1994.
Tun-Yu Chiang, Wilson Lau. “Segmentation of Vehicle in
Traffic Video.” Project Report EE392j Stanford University.
P.Y Yeoh, S.A.R Abu Bakar. “Accurate Real-Time Object
Tracking with Linear Prediction Method”. IEEE International
Conference on Image Processing (ICIP), 2003.
Alexei A. Efros, Alexander C. Berg, Grey Mori, Jitendra
Malik. “Recognizing at a distance”. IEEE International
Conference on Computer Vision, Nice, France, Oct. 2003.

Proceedings of the International Conference on Computer Graphics, Imaging and Visualization (CGIV’04)
0-7695-2178-9/04 $20.00 © 2004 IEEE

