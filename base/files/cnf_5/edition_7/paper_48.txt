A New Perspective on Multiresolution Image Processing
Michel Bister
University of Nottingham, Malaysia Campus, Div. of Engineering, 50450 Kuala Lumpur, Malaysia
{michel.bister@nottingham.edu.my}
Abstract
This paper takes a Fourier perspective on the various
multiresolution approaches to digital image processing
such as Laplacian Pyramids, Gaussian Scale Space, and
wavelet transform (both discrete and continuous). From
this perspective, it is possible to highlight the strong
similarity between those different approaches. Dangers
or possible dangers of some approaches will be
highlighted, while at least one case of porting a
successful algorithms from one formalism to another one
will be presented, opening the perspective of more
transparence between the different approaches. The
successful porting of efficient feature detection and
tracking algorithms from one formalism to another opens
the perspective of benefiting from the advantages of
each, ad putting these strong points to the service of
image-based modeling and rendering.
Keywords --- Multiresolution, wavelets, Gaussian
scale space, image-based modeling and rendering

1. Introduction
Although Digital Image Processing (DIP) and
Computer Graphics (CG), in recent year the two fields
have come closer and benefited from each other [1]. On
one hand, techniques from Computer Graphics are used
more and more often to visualize the results from
medical imaging and the results of medical image
processing. On the other hand, to implement interactive
virtual campus tours, it will become more and more
important to modelise the buildings of a campus, which
could be done by DIP (automated detection of feature
points in stereo images and construct a model of the
building from those feature points).
Since the 1980’s, various multiresolution (MR)
approaches have become more and more popular in DIP,
culminating with more than 2000 peer-reviewed papers
last year alone. Different factors have motivated this

strong interest in MR. One is the mimicking of the
Human Visual System, which is still one of the best
examples of efficient image processing and recognition.
Another factor has been the pursuit of top-down
approaches in DIP – first detecting major features at a
low level of resolution, then refining their definition and
finding details at higher resolution without (too much)
noise disturbance. Finally, there also has been the factor
of processing time – low-resolution images being usually
analyzed at reduced resolution (as allowed by the
sampling theorem) and hence at reduced computational
time and computational complexity.
Over the years, different approaches to MR DIP have
been developed. After a brief attempt on Laplacian
Pyramids (LPy) in the 1980’s [2], an alternative
approach was developed by Daubechies [3] and Mallat
[4] at the end of the 1980’s, namely the Discrete Wavelet
Transform (DWT). Later an alternative was developed,
namely the Continuous Wavelet Transform (CWT). In
the meantime, another approach had grown from the
study of the Human Visual System [5], and came to be
called the Gaussian Scale Space (GSS). The LPy died
out, while the GSS approach received much less
publicity and popularity than the Wavelet approach,
although it has some very attractive properties. Usually
the Wavelet approaches and the GSS are in competition.
They follow very different mathematical formalisms.
The field of DIP originally grew from Digital Signal
Processing (DSP). However, DSP deals mainly with 1dimensional (1-D) signals (signals that vary with time),
which are usually destined for the human ear; while DIP
deals mainly with 2- (or higher-) dimensional signals
(images), which are usually destined for the human eye.
Since the two organs function very differently, the two
fields have evolved in very different ways. However,
since signals are signals, much benefit can be obtained
by taking a DSP approach to DIP – particularly to MR
DIP. This will enable us to see the common points
between the different approaches, and to apply concepts
developed in one technique using the other technique as
well.

Proceedings of the International Conference on Computer Graphics, Imaging and Visualization (CGIV’04)
0-7695-2178-9/04 $20.00 © 2004 IEEE

In this paper, we will first briefly review the four
basic algorithms, trying to emphasize the concepts more
than the mathematics. Next, we will introduce the DSP
approach to each to the algorithms. The following
section will introduce the comparison, and as an example
it will be shown how one typical feature detection
algorithm developed in the GSS literature can be applied
using the CWT formalism. The final section will draw a
number of conclusions.
Since we will talk about both 1-D signals and 2-D (or
multi-D) signals (images), we will use the word “signals”
to denote both 1-D signals and images.

things go well and detection of the black object in the 1D signal can easily be performed on the two-but-highest
level in the LPy. The computational efficiency is clear:
local operators at the right level in the LPy are sufficient
to detect a vast object in the original signal.

2. Basic Algorithms

However, the problems faced by LPy’s are clear when
considering a slightly shifted version of the signal of
Figure 2, as illustrated in Figure 3: no single reducedresolution pixel can represent the black object adequately
anymore. Although many adaptations of the algorithms
were proposed to try to overcome this problem, it was
shown in 1990 [8] that all algorithms following this
approach would suffer the same problem, namely not
being able to accurately represent a small change in the
high-resolution signal at reduced-resolution levels, and
hence major changes in the conclusions as a result of
small changes in the input signal – which engineers call
“instability”.

Although LPy have almost died out as DIP algorithm,
we will still briefly discuss them, as they help to
understand some of the basic concepts of MR DIP, and
help to point to some of the related dangers.

2.1. Laplacian Pyramids (LP)
The LPy was the first and hence the most simple of all
the MR approaches. It relied on a basic assumption from
the sampling theorem [6, 7]: if the number of frequencies
in a signal is reduced by a factor N, the sampling
frequency required to accurately represent the signal can
also be reduced by a factor N. In particular, a factor 2
was considered as being the smallest integer factor and
having strong IT support.
Based on the idea that the sampling frequency could
be reduced by a factor 2 if the signal was properly
processed (high frequencies removed), a structure was
considered whereby pixels in one layer had only half the
sampling rate of the pixels in the other layer, resulting
(after proper arrangement) in pyramid-like structure, as
show in Figure 1 for a 1-D signal.

Figure 1. Traditional arrangement of pixels in a
1-D LPy structure
The technique to reduce the higher frequencies was
quite crude: simple averaging of the 2x2 pixels
“underlying” one reduced-resolution pixel, or at best a
weighted averaging of the 4x4 “underlying” pixels –
which, as DSP-literate people know, is a very poor lowpass (LP) filter.
Next, objects were detected at the lowest resolution
(highest level in the LPy), and their borders refined from
one level to another, as illustrated in Figure 2, where

Figure 2. Detection of a massive dark object in a
1-D LPy structure

Figure 3. Inability to detect a poorly positioned
massive dark object in a 1-D LPy structure,
illustrating the shift-variance of the LPy

2.2. Discrete Wavelet Transform (DWT)
Although the DWT was developed on a completely
different basis than LPy and has much stronger
mathematical background, some points are in common:
again there is the basic idea of reducing the sampling rate
after removing half of the frequencies. However, in the
DWT, both a LP and a HP (high-pass) filtering are
applied to the signal, and half of the HP samples are kept
in addition to half of the LP pixels, such that the next
level has the same number of pixels as the previous one.
The LP and HP filters are designed with much more
care than in the LPy pyramid. They usually are designed
as Finite Impulse Response (FIR) filters with the
property that the reconstruction of the signal is possible
from the reduced-sampling versions of it – hence the
name of transform: the signal is transformed from one
representation to the other and can be transformed back
to the first representation.

Proceedings of the International Conference on Computer Graphics, Imaging and Visualization (CGIV’04)
0-7695-2178-9/04 $20.00 © 2004 IEEE

Another difference with the LPy is that the number of
levels in the DWT is not equal to log2 of the original
size, but can be chosen between one and log2 of the
original size (although that maximal value is rarely
used).
It is also to be noted that only the LP version of the
signal is again being subjected to filtering and subsampling at the next level(s).
The whole procedure is illustrated in Figure 4.
filter

sub-sample

re-arrange

re-filter

re-sub-

re-re-arrange

etc.

For signal analysis, the CWT has traditionally been
preferred over the DWT (because of similar but
unreported problems for the DWT as for the LPy ?).

2.3. Continuous Wavelet “Transform” (CWT)
The CWT is derived from the DWT by introducing
two modifications:
• the filtered signals are not sub-sampled
• the filters do not eliminate half of the frequencies but
select frequencies in a certain range.
As a result, the signal is filtered at different levels of
resolution, in order to extract a certain range of details or
features at each level. All the levels are stacked on top of
one another, resulting in a structure that has an additional
dimension, namely scale. This is not without similarity to
the Short Time Fourier Transform (STFT) or
Spectrogram [11] for 1-D signals, whereby the frequency
is determined as a new dimension to the signal. Hence,
the CWT cannot really be termed a “transform”, as it
generates much more samples than in the original
domain and hence introduces a vast redundancy.
However, this redundancy makes it possible to analyze
the signal at low resolution first and extract significant
features, which are then either refined or which guide the
analysis of the signal at higher resolution.
Since sub-sampling is avoided, any LPy-related
problems are also avoided, but computational complexity
is no longer an advantage in this approach.

2.4. Gaussian Scale Space (GSS)

Figure 4. Illustration of the building of a DWT –
darker gray values represent higher frequency
content and vice versa
The LP-filtered signal is termed “approximation”,
while the HP-filtered signal is termed “details”. Different
authors have proposed different filters. The steepness of
the filters depend on their order (order, length, size,
complexity are all related).
DWT are used for signal analysis in much the same
way as LPy (with the same problems? - this has never
been investigated) but their big success has been in
signal compression. They benefit from the information
compaction property of the Fourier Transform (to which
they are related, as we will show in the next section),
while having also a structural redundancy (structural
relationship between pixels at the same location in
different reduced-resolution sub-sections), which is
ingeniously applied in several DWT-based compression
algorithms [9, 10].

Gaussian Scale Space developed rapidly after the
seminal paper from J.J. Koenderink [5] in which he
started from the assumption that the blurring process
should reduce the features in the signal (in his case the
local extrema) as an expression for causality, added to
the requirements of linearity and isotropy. This brought
him to the linear isotropic diffusion equation or heat
equation – an equation dear to Engineers as it also results
from entropy maximization (another way to
axiomatically derive the GSS). The Green’s function of
this equation is the Gaussian kernel, as well as all its
derivatives.
In the GSS, versions of the signal with increased
blurring (increased values of σ in the Gaussian kernel)
are stacked on top of one another, and the evolution of
the features is followed along the stack until they vanish
– or they are detected at a certain level of blurring
(certain level of importance or energy) and then traced
back along the stack to find their precise location (“deep
structure”).
Another important result from the GSS theory is that
Gaussian derivatives are also solutions to the diffusion
equation, while the derivative of the convolution of a

Proceedings of the International Conference on Computer Graphics, Imaging and Visualization (CGIV’04)
0-7695-2178-9/04 $20.00 © 2004 IEEE

signal with a kernel is equal to the convolution of the
signal with the derivative of the kernel. Since the kernel
is arithmetically known, its derivatives are also. As a
result, the derivative operator – which is so important in
signal analysis but which is so difficult to calculate for
sampled signals - can now easily be calculated as a
convolution, i.e. an integral operator instead of a
differential operator. As a result, many features
(isophotes, flowlines, curvatures, ridges, corners, Tjunctions, intersections, etc.) which usually require the
calculation of a lot of derivatives (even of up to 4th
order) and hence usually cannot be implemented easily
in DIP, now suddenly can be successfully applied [12].
Since the GSS grew from the study of the Human
Visual System, it should come as no surprise that our
retina seem to calculate receptive fields that “look like”
Gaussian kernels and their derivatives – even time- and
color processing of images in the retina seem to be
related to the Gaussian kernel and its derivatives [12].
Texture is usually analyzed with Gabor filters, which
researchers have reported to have noticed in the receptive
fields of the retina. But Gaussian derivatives are indeed
arithmetically very close to Gabor filters and could be
another way of interpreting the patterns found in the
retina.
The GSS approach has been applied to fields as
diverse as denoising, segmentation, stereo vision, optical
flow, color imaging, differentiation, feature detection,
texture analysis, morphological analysis, registration,
time-series, 3-D analysis, etc. – making it a valid
candidate for a unifying framework for DIP.

level i-1). The frequency response of the actual filters
depends on the type of wavelet chosen and on its order –
higher orders giving sharper filters, as illustrated in
Figure 7.

Figure 5. Normalised frequency response of the
averaging filters applied in the LPy

3. DSP Description
Since most MR approaches at least occasionally refer
to filters, it is definitely interesting to take a DSP
approach to compare them.
The analysis of the LPy is quickly done: applying an
averaging operator over two samples to derive a reducedresolution sample is like convolving the signal with a [1
1]/2 kernel – or at best a [1 1 1 1]/4 kernel – to the
signal. The frequency-domain representation of these
kernels reveal a LP-filter indeed, but one of very low
quality, as shown in Figure 5. This only adds to the
previous criticism on the LPy.
The case of the DWT was already briefly exposed
from a filtering perspective in Figure 4. Figure 6
illustrates the approach in both time- and frequencydomain. It shows clearly that the application of HP-filters
on a LP-version of the signal results in a BP-version of
it. Hence, after applying N passes of this procedure, the
resulting N-level DWT contains one LP-version of the
signal (the approximation on the highest level), one HPversion of it (the details on the lowest level) and N-1 BPversions (the details at level i of the approximation at

Figure 6. The basic steps of the DWT illustrated
in both time- and frequency domain (from [13])

Figure 7. Normalised frequency representations
of Daubechies and Biorthogonal wavelet
decomposition filters of different order
The CWT is very similar to the DWT, except that
there is no sub-sampling, the scale can be chosen at wish,
with the HP corresponding to a scale 1 and all the other
scales corresponding to BP filters (the LP component is
not used in CWT). Since the same filters are used for
CWT as for DWT, the frequency response of the LP and

Proceedings of the International Conference on Computer Graphics, Imaging and Visualization (CGIV’04)
0-7695-2178-9/04 $20.00 © 2004 IEEE

HP filters (used in combination to produce the BP filter)
can also be seen in Figure 7.
Finally, the Gaussian kernel is clearly a LP filter, with
the cutoff frequency varying inversely proportionally to
σ. It seems difficult to relate this LP approach to the
typical BP approach of DWT and CWT. However, when
we look at the frequency response of the derivatives of
the Gaussian kernel – which are also solutions to the heat
equation proposed by Koenderink and which are also
used intensively in the GSS – we find again the BP
behavior, as illustrated in Figure 8.

in [14]. The author proposes an affine invariant corner
detector defined as follows over the 2-D image L(x, y):
2

Θ=2

∂ 2 L § ∂L ·
∂L ∂ 2 L ∂L ∂ 2 L § ∂L ·
− 2 ¨¨ ¸¸ − 2 ¨ ¸
∂x ∂x∂y ∂y ∂x © ∂y ¹
∂y © ∂x ¹

2

or, with simplified notations:

Θ = 2 Lx Lxy L y − Lxx L y − L yy Lx
2

2

As we saw before, the derivatives used in this
equation can be calculated by convolving the original
image L0(x, y) with the right derivative of the Gaussian
kernel G(x, y; σ):

∂ n + m L(x, y;σ ) ∂ n + m (L0 ( x, y ) ⊗ G (x, y;σ ))
=
∂x n ∂y m
∂x n ∂y m
= L0 ( x, y ) ⊗

Figure 8. Frequency representations of the
Gaussian and a number of its derivatives, for a
number of different values of σ
Hence, we see a common factor emerge from all these
different MR approaches to DIP: they work on stacked
versions of mainly BP but also LP and HP versions of
the original signal, and try to combine them in an
intelligent way. This is not without evoking the
filterbank approach – which was the predecessor of
wavelets and applied a series of BP filters to the original
signal – or even the Short Term Fourier Transform
(STFT) which calculates the frequency representation of
the signal at fixed time intervals, and hence can be
compared to a very large number of very narrow BP
filters put side by side.
The main issue seems to be the way to define the BP
filters – to make the implementation as simple as
possible (LPy), to make reconstruction possible (DWT),
or to ensure causality (GSS). Hence, our comparison
between the different MR approaches will be based on
comparing the frequency response of each class of filters.

4. Comparison
If the whole issue of MR DIP is just to define the
right type of LP, HP and derived BP filters, the different
approaches should be comparable. What is more,
techniques from one approach could be readily ported to
the other approach by applying the right type of filter in
the right context.
Since we are interested particularly in Computer
Graphics and the extraction of significant features from
an image in order to modelise it, we tried to apply the
CWT approach to the corner detection algorithm defined

∂ n + m G ( x, y ; σ )
∂x n ∂y m

Since the derivative of the Gaussian kernel is a BP
filter, we could approximate it with an appropriate
version of a CWT filter. To find the best approximation,
we minimized the difference between the nromalised
amplitude of the frequency response of the Gaussian
derivative and of the wavelet filter. When using the
Daubechies family, the 1st-order derivative of the
Gaussian kernel with standard deviation σ was found to
be best approximated with the Daubechies wavelet of
order 1 and scale 4.3 n. For higher-order derivatives,
similar results could be obtained. However, it was found
more expedient and easier to program to take the 2ndorder derivative as the 1st-order derivative of the 1st-order
derivative, etc., hence to calculate derivatives iteratively:

∂ 2 L( x, y;σ ) ∂ ∂L( x, y; σ )
=
∂x
∂x
∂x 2

Figure 9. Test image for the corner detection
algorithm
The result for the image of Figure 9 is illustrated in
Figure 10, where the corner detector was first applied
using the GSS for σ = 1.0 and σ = 3.0, and then using the
Daubechies-1 wavelet (which is also the Haar wavelet)
with scales 4.3 and 12.9 respectively. The similarity of
the results is striking.
At press time, experiments were going on to
determine the sensitivity of the transformed algorithm to
the exact wavelet, order and scale selection, and to
convert other GSS algorithms to the wavelet domain (in

Proceedings of the International Conference on Computer Graphics, Imaging and Visualization (CGIV’04)
0-7695-2178-9/04 $20.00 © 2004 IEEE

particular the T-junction and intersection detection
algorithms in [15] and [16], resp.

around from the DWT/CWT formalism to the GSS
approach.

References
[1]

[2]

[3]

[4]

Figure 10. Results of GSS (σ = 1.0 and σ = 3.0)
and CWT (Daubechies-1 scales 4.3 and 12.9)
corner detection algorithms applied on the test
image of figure 9

[5]
[6]

5. Conclusions
The DSP perspective on the various MR approaches
to DIP shows the strong similarity between those
different approaches – similarity which is not obvious
when sticking to the mathematical formalism used by
each approach.
The DSP comparison we performed here pointed to
the danger (instability) of the LPy approach and the risk
that the DWT – when used for image analysis – would
suffer a similar drawback (which would not be a
drawback in applications like compression and
denoising, which incidentally are the major application
areas of DWT).
It also highlighted the similarity between CWT and
GSS approaches, to the point of taking one successful
application of GSS and porting it directly in the CWT
formalism, with great similarity in the results.
This comparison might be an important breakthrough
in MR DIP, as it would mean that all the algorithms
developed in either approach could be ported to the other
formalism, benefiting from the strong points of any
approach chosen.
In particular, the optical flow algorithms developed
successfully in GSS could be adapted in CWT so as to
keep track of significant feature points in a video
sequence, as would have been detected using corner, Tjunction and intersection algorithms (also ported from
GSS to CWT), and hence stereo vision algorithms could
be applied on the points to derive first the camera
position, then the model of the objects (buildings) in the
scene.
Other successful algorithms, such as compression and
Denoising, could hopefully be ported the other way

[7]

[8]

[9]

[10]

[11]

[12]

[13]

[14]

[15]

T. Pun and E. Blake, "Relationships between image
synthesis and analysis: towards unification?", Computer
Graphics Forum, 9, 2, July 1990, 149-163.
P.J. Burt, T.H. Hong, A. Rosenfeld, “Segmentation and
Estimation of Image Region Properties Through
Cooperative Hierarchical Computation,” IEEE Trans.
Syst. Man Cyber., vol. 11, pp. 802-809, 1981.
I. Daubechies, "Orthogonal bases of compactly
supported wavelets," Comm. Pure Appl. Math., vol. 41,
pp. 909-996, 1988.
S. G. Mallat, "A theory of multiresolution signal
decomposition: the wavelet representation," IEEE Trans.
Pattern Anal. Machine Intell., vol. PAMI-11, pp. 674693, 1989.
J.J. Koenderink, “The Structure of Images,” Biol.
Cybern., vol 50, pp. 363-370, 1984.
H. Nyquist, "Certain topics in telegraph transmission
theory," Trans. AIEE, vol. 47, pp. 617-644, Apr. 1928.
C. E. Shannon, "Communication in the presence of
noise," Proc. Institute of Radio Engineers, vol. 37, no.1,
pp. 10-21, Jan. 1949.
M. Bister, J. Cornelis, A. Rosenfeld, "A Critical view on
Pyramid Segmentation Algorithms," Pattern Recognition
Letters, vol. 11, pp. 605-617, 1990.
J. M. Shapiro, “Embedded Image Coding Using
Zerotrees of Wavelet Coefficients,” IEEE Transactions
on Signal Processing, Vol. 41, No. 12, p. 3445-3462,
1993.
A.Said, W.A.Pearlman, "A New Fast and Efficient
Implementation of an Image Codec Based on Set
Partitioning in Hierarchical Trees", IEEE Transactions
on Circuits and Systems for Video Technology, Volume
6, pp. 243-250, June 1996.
L.R. Rabiner and R.W. Schafer, "Digital Processing of
Speech Signals," Prentice-Hall, Englewood Cliffs, NJ
1978.
B. M. ter Haar Romeny, “Front-End Vision and
Multiscale Image Analysis,” Kluwer Academic
Publishers, 2003.
S. Mansor, “Modality- and Region-Oriented Medical
Image Compression Using Wavelets,” M.Eng. Thesis,
Multimedia University, Malaysia, 2003.
J. Blom, "Affine Invariant Corner Detection", in: PhD
Thesis, Utrecht University, NL Utrecht, 1991.
B. M. ter Haar Romeny, L. M. J. Florack, A. H. Salden,
and M. A. Viergever, "Higher order geometrical image
structure", in Proc. Information Processing in Medical
Imaging '93, Flagstaff AZ (H. Barrett, ed.), (Berlin),

pp. 77-93, Springer-Verlag, 1993.
[16] A. H. Salden, B. M. ter Haar Romeny, and M. A.
Viergever, "Algebraic invariants of linear scale spaces."
Journal of Mathematical Imaging and Vision, March
1999

Proceedings of the International Conference on Computer Graphics, Imaging and Visualization (CGIV’04)
0-7695-2178-9/04 $20.00 © 2004 IEEE

