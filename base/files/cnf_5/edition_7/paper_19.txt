Visual Inventory Inspection Using Optical Character Recognition
Chong Kuan Meng
Department of Industrial Computing
Faculty Technology & Information Science
National University of Malaysia
P28105@mail2.ukm.my

Abstract
This paper presents a research on developing a visual
inspection of character base image for automatic
inventory control system by using an optical image
processing method. Usually, bar code method has been
used as an input device for inventory control system.
However, data or information that included in a bar code
may not sufficient for the purpose of inventory controlling.
Therefore, for the purpose of efficiency, character
recognition for label stock in inventory controlling system
will be an advantage in providing extra information
regarding stock in industrial computing. This system
derives from 2 major parts. The first part is used to
extract the area of stock label in a grayscale picture, and
then try to recognize the text inside a label. Whereas the
second part, it record the in-out activities of an inventory
using the information from the first part. Research for the
recognition system is concentrate on the capital letters
and the numbers only.

1. Introduction
This research is concentrate on the character
recognition or in common, called OCR (Optical Character
Recognition). OCR is a process that converts an image of
a printed material or a handwritten material to a form that
can be understood or process by computer, for an example
in ASCII (American Standard Code for Information
Interchange) form.
The new technology of OCR was started in 1950’s
when a robot that can read and write – GISMO, was
created by M. Sheppars. Whereas, in the year 1956, J.
Rainbow has created a prototype machine that can
recognize all the capital letters from a typing machine.
The machine that created by J. Rainbow has the ability to
recognize 1 character a minute. Start from the year 1960’s,

Yuwaldi Away
Department of Industrial Computing
Faculty Technology & Information Science
National University of Malaysia
yuwaldi@ftsm.ukm.my

some companies like IBM, Recognition Equipment Inc.,
have started to market OCR system.
At the beginning state of the development of OCR
system, a few standards have been created. Some
examples of these standards are list below:
x
x
x

Character Set for Optical Character Recognition
(OCR-A).ANSI X3.17-81
Character Set for Optical Character Recognition
(OCR-B). ANSI X3.49-75
Optical Character Recognition (OCR) Character
Position. ANSI X3.93-81

Generally, commercial system OCR can be divided
into two major groups. The first group, is specialist task
reader, and the second group, is general purpose reader.
The system with specialist task reader is used on specific
document only, whereas the general purpose reader is
used on more variety of document type for example, letter,
news paper, etc.
Research has been done to develop a visual inspection
of character base image for automatic inventory control
system by using optical image processing method. This
system act as a specialist task reader using a normal USB
digital camera that can recognize the contents of a stock’s
label.

2. System Architectures
As show in figure 1, our system records the in-out
activities of an inventory. Upon receiving of new
inventory, an item with a stock label that consists of the
name, serial number of stock, will be scan using a digital
camera. The image will then go through a series of image
processing module where the data from the label will be
extracted for recording purpose. The same process repeat
when a item is being move out from the stock.

Proceedings of the International Conference on Computer Graphics, Imaging and Visualization (CGIV’04)
0-7695-2178-9/04 $20.00 © 2004 IEEE

I t e m m o v e in
to In v e n to ry

Ite m m o v e
o u t fro m
In v e n to ry

In v e n to ry

R e c e iv in g I t e m

D e liv e r y I t e m
S canner

S canner

I m a g e o f t h e it e m

I n v e n t o r y C o n t r o l U n it
I n b o u n d I n v e n t o r y C o n t r o l M o d u le

O u t b o u n d I n v e n t o r y C o n t r o l M o d u le

C h a r a c t e r R e c o g n it io n U n it
I m a g e M a n ip u la t io n

L o c a t e L a b e l P o s it io n
L o c a t e T e x t L in e P o s it io n
S e p a ra te C h a ra c te r F ro m T e x t
C o m p a r is o n W it h T e m p la t e

C o n t e x t u a l C h e c k in g

P r o d u c t I n f o r m a t io n

Figure 1 : System Architectures

3. Method
Several methods are being used when developing the
system. To extract text from the image, an scanned image
must first be enhance to increase the contrast level. Then
the position of the label is located in the image before the
area of the label can be extract. Further more, the position
of each line of text are being determine. Then each
character must be extract from the line of text. For further
processing, the image must be binarized. Lastly, each

character from a line are being determine to form an input
to the system. To enhance the result of the recognition,
result from the recognition will go thru a conceptual
processing.

3.1 Image Enhancement
Image enhancement process will determine the pixel
with the highest brightness level in the image. This pixel
is then adjusted to the highest brightness level with the

Proceedings of the International Conference on Computer Graphics, Imaging and Visualization (CGIV’04)
0-7695-2178-9/04 $20.00 © 2004 IEEE

value 255. Using the variant between the original value,
with the enhanced brightness value, the brightness value
of all the others pixel are been calculate and updated.

3.2 Locate Label Position
The system will scan each pixel in the enhanced image
from top to bottom, from left to right, to locate a row of
continuous pixels that pass the threshold value. The first
row of continuous pixels that pass the threshold value will
be the starting y position for the label, whereas the last
row of continuous pixels that pass the threshold value will
be the ending y position for the label. The same apply for
the starting and ending x position for the label. Thus, the
position of the label can be determined, with the
assumption that the label has a bright background color.

3.6 Contextual Processing
To enhance the accuracy, the scanned result, for
example the name of a item, are being compare with the
pre-safe database to match to the proper item.

4. Experiment
The system has been tested with 12 label samples that
consist of 2-3 lines of characters. Figure 3 has shown the
system interface and Figure 4 has show a sample label for
scanning. Table 1 has shown the result and the
performance of the recognition.

3.3 Locate Text Position
Using the same method in scanning the position of
label, the text position in the label can be determined. An
assumption has been made that the text from 2 different
lines is separated clearly.

3.4 Locate Character
Using the same method in scanning the position of
label, the character from a line of text can be extracted.
An assumption has been made that the characters are
separate clearly with each other.

3.5 Binarization
Figure 3 : System Interface
As shown in Figure 2, each pixel in a extracted
character are binarize for comparison process with a set of
pre-safe template.

Figure 4 : Sample Label for Scanning
Figure 2 : Binarization

Proceedings of the International Conference on Computer Graphics, Imaging and Visualization (CGIV’04)
0-7695-2178-9/04 $20.00 © 2004 IEEE

Table 1 : System Performance Test Result
Data
1
2
3

4

5

Lines’ Contents (Printed)
2D CODE READER
432645756123
CC SELF-POWER
062125156821
E3X-NM/NT
532453456453
013103
CANONBJC210SP
08852341124
110704
LEXMARKZ13
213265934531
103103

Lines’ Contents (Result)
1. 2DCODEPEADEP
2. 432645756123
1. CCSELFIPOWER
2. 062125156821
1. E3XINM7NT
2. 532453456453
3. 013103
1. CANONBJC210SP
2. 086532341124
3. 110704
1. LEXMARKZ13
2. 213265984531
3. 103103
Average

5. Conclusion
The research of the system has built a fundamental
understanding for computer vision system that can be
used in the field of industrial computing. It gives a
concept and eases the process of varying the use of
computer vision system, for example in quality control,
and to manipulate geometric data of an object. Referring
to the experiment’s results, it shown that the system has
the ability to achieve a average accuracy of 95.08% with
an average speed of 6.15 seconds a character. This system
is yet to be enhanced to overcome all the limitation.

6. References
[1] Batchelor, B.G., Hill, D.A. and Hodgson, D.C. Automated
Visual Inspection. UK: IFS (Publications) Ltd, 1985.
[2] Bowyer, K.W. and Phillips, P.J. “Overview of Work in
Empirical Evaluation of Computer Vision Algorithm. In:
Bowyer & Phillips (ed) Empirical Evaluation Techniques
in Computer Vision”, IEEE Computer Society Press, Los
Alamitos, California, 1998, 1-11.
[3] Davies, E.R., “IEE Colloquium on Industrial Inspection”,
1997, 6/1-6/5.
[4] Haralick, R., “Performance Characterization in Image
Analysis: thinning, a case in point.” Pattern Recognition
Letters 13, 1992, 5-12.
[5] Haralick, R. and Shapiro, L., Computer and Robot Vision,
vol. 1. Addison-Wesley, 1992.
[6] Kauppinen, H. , Development of a Color Machine Vision
Method for Wood Surface Inspection. Ph.D. Dissertation.
University of Oulu, 1997.

Accuracy
83.33%
100%
91.67%
100%
77.78%
100%
100%
100%
91.67%
100%
100%
91.67%
100%
95.08%

Time (s)
8
6
8
6
6
6
4
7
6
5
7
6
5
6.15

[7] Newman, T.S. and Jain, A.K. , “A Survey of Automated
Visual Inspection. Computer Vision and Image
Understanding “, 1997, 231-262.
[8] Serena, F. and Vidal, L., “Using National Instruments
LabVIEW and IMAQ for Visual Quality Control of a
Filling Line”, http://digital.ni.com/csma.nsf/, 2003.
[9] Jean Duong, Myriam Cote, Hubert Emptoz, Ching Y. Suen.,
“Extraction of Text Areas in Printed Document Images”,
2001.
[10] Victor Wu, R. Manmatha, Edward M. Riseman.,
“TextFinder: An Automatic System To Detect And
Recognize Text In Images”, IEEE Transactions on Pattern
Analysis and Machine Intelligence, 1997.
[11] Anto Satriyo Nugroho, Susumu Kuroyanagi and Akira
Iwata. “An Algorithm For Locating Characters In Color
Image Using Stroke Analysis Neural Network”.
[12] V. Wu and R. Manmatha and E. Riseman., “Automatic
Text Detection and Recognition”, 1997.
[13] Toshio Sato, Takeo Kanade, Ellen K. Hughes and Michael
A. Smith. ,”Video {OCR} for Digital News Archive”, 1998.
[14] J.R. Parker., Chichester, John Wiley and Sons, “Algorithms
for Image Processing and Computer Vision”, New York,
Brisbane, Toronto, Singapore, Weinheim, design and
measurement in electronic engineering edition, 1997.
[15] Ramesh Jain, Rangachar Kasturi, and Brian G. Schunck..
Machiine Vision. McGraw-Hill Inc., mcgraw-hill series in
computer science edition, 1995.
[16] Victor Wu , R. Manmatha and Edward M. Riseman. ,
“Finding Text in Images”, 1997.
[17] Huiping Li , David Doermann and Omid Kia. “Text
Extraction, Enhancement and OCR in Digital Video.”
[18] H. Li , D. Doermann and O. Kia, “ Automatic text detection
and tracking in digital videos.”, IEEE Transactions on
Image Processing, 2000, 147—156.

Proceedings of the International Conference on Computer Graphics, Imaging and Visualization (CGIV’04)
0-7695-2178-9/04 $20.00 © 2004 IEEE

