Volume 27 (2008), Number 2

EUROGRAPHICS 2008 / G. Drettakis and R. Scopigno
(Guest Editors)

Apparent Greyscale: A Simple and Fast Conversion to
Perceptually Accurate Images and Video
Kaleigh Smith1
1 MPI

Pierre-Edouard Landes2

Informatik, Saarbrücken, Germany

Joëlle Thollot2
2 Grenoble

Karol Myszkowski1

Universities, INRIA, France

Abstract
This paper presents a quick and simple method for converting complex images and video to perceptually accurate
greyscale versions. We use a two-step approach first to globally assign grey values and determine colour ordering,
then second, to locally enhance the greyscale to reproduce the original contrast. Our global mapping is image
independent and incorporates the Helmholtz-Kohlrausch colour appearance effect for predicting differences between isoluminant colours. Our multiscale local contrast enhancement reintroduces lost discontinuities only in
regions that insufficiently represent original chromatic contrast. All operations are restricted so that they preserve
the overall image appearance, lightness range and differences, colour ordering, and spatial details, resulting in
perceptually accurate achromatic reproductions of the colour original.
Categories and Subject Descriptors (according to ACM CCS): I.3.3 [Computer Graphics]: Display Algorithms

1. Introduction
The basic problem of greyscale transformation is to reproduce the intent of the colour original, its contrasts and salient
features, while preserving the perceived magnitude and direction of its gradients. The transformation consists of two
interdependent tasks: a mapping that assigns a grey value to
each pixel or colour, and a discriminability constraint so that
the achromatic differences match their corresponding original colour differences. Recent approaches solve discriminability constraints to determine the grey values, producing images in which the original colour contrasts are highly
discriminable. However, the greyscale images may exhibit
exaggerated dynamic range, an arbitrary achromatic order
that differs among colour palettes, and a smoothing or masking of details. These modifications all contribute to make the
grey version appear dissimilar from its original and create
inconsistency among like images and video frames.
The goal of this work is to create a perceptually accurate version of the colour image that represents its psychophysical
effect on a viewer. Such greyscale imagery is important for
printed textbooks and catalogues, the stylization of videos
and for display on monochromatic medical displays. A perceptually accurate image is one that emulates both global
and local impressions: it matches the original values’ range
and average luminance, its local contrasts are neither exc 2008 The Author(s)
Journal compilation c 2008 The Eurographics Association and Blackwell Publishing Ltd.
Published by Blackwell Publishing, 9600 Garsington Road, Oxford OX4 2DQ, UK and
350 Main Street, Malden, MA 02148, USA.

aggerated nor understated, its grey values are ordered according to colour appearance and differences in spatial details are imperceptible. Strong perceptual similarity is particularly important for consistency over varying palettes and
temporal coherence for animations.
We present a new two-step greyscale transformation that
combines a global mapping based on perceived lightness
with a local chromatic contrast enhancement. Our simple
algorithm yields comparable images to more complex approaches, and its linear runtime makes it suited to video
processing and accelerated graphics hardware implementations. First, the grey values are mapped pixelwise from
each colour’s apparent lightness, resulting in the reproduction of the original contrast and gradients. Second, the gradient magnitudes are measured in perceptual difference ∆E
and adjusted to maintain or improve discriminability with
our multiscale chromatic contrast enhancement filter. This
twofold approach mimics aspects of the human visual system, which processes global attributes while simultaneously
depending on local contrasts such as edges and surrounds.
We choose lightness as the quantity for the grey values (and
thus their ordering) because it is the achromatic response to
a colour stimulus, measuring how bright a colour appears
compared to an equally bright white. Colour studies show
that lightness depends largely on luminance, but that colour-

194

K. Smith et al. / Apparent Lightness Greyscale

fulness also contributes, as characterized by the HelmholtzKohlrausch effect (H-K); a colourful stimulus appears more
light than a similar less colourful sample. The H-K effect has
been identified as an important factor in greyscale mapping,
and although it has been used for clipart greyscale mapping [BB04], no existing greyscale conversion for complex
images explicitly takes it into account. Our global apparent lightness mapping is independent of the original colour
palette, incorporates the H-K effect so is sensitive to small
differences even between isoluminant colours, and yields
perceptually accurate gradient directions and an appropriate
dynamic range.
The mapping from a 3D to 1D colour space reduces the overall difference between colours, jeopardizing discriminability. We are not too sensitive to this loss when it occurs between spatially distant colours, but with adjacent colours it
is immediately apparent, especially if an original contrast
becomes imperceptible. To solve this problem, we enhance
local contrast until its magnitude emulates that in the original. The enhancement restores chromatic differences without overemphasizing luminance differences by adaptively
increasing weak contrasts. Furthermore, the process is restricted so that the polarity over edges, overall lightness and
colour ordering are preserved, thus maintaining perceptual
accuracy.
We begin by describing other greyscale conversion techniques and highlighting their effects on perceptual accuracy.
Then, in Section 3, we give a background on colour appearance models, compare H-K predictors and determine the
best suited to greyscale conversion. In Sections 4 and 5, we
present our global-local technique to solve greyscale conversion. In Section 6, we compare the results of our technique to other standard results to accentuate the perceptual
aspects that are more accurately preserved, and demonstrate
our technique’s ability on various input types. Finally, we
conclude by discussing the implications of our findings, future work and other possible applications.
2. Related Work
There are a variety of printing and display solutions catered
to the conversion of images from colour to greyscale. The
most straightforward conversion maps a colour to an equiluminant grey value, by desaturation or by picking a single
colour channel to mimic the effect of a colour filter.
In their short paper studying chromatic contrast for greyscale
conversion, Bala et al. [BE04] take a spatial approach
and introduce color contrasts in CIELAB LCH (lightness,
chroma, hue angle) by adding the high-pass filtered chroma
channel to the lightness channel. To prevent overshooting
in already bright areas, this correction signal is locally adjusted and its sign is taken from the lightness contrast. The
algorithm is susceptible to problems in chroma and lightness misalignment. Taking a local adaptive approach, Bala et

al. [BB04] propose a mapping method for business graphics. The distinct colours of the image are sorted according
to a simplified lightness predictor that incorporates the H-K
effect. To maximize discriminability, adjacent pairs of lightness values are then respaced according to their relative color
differences. The approach is uniquely for graphics with up to
10 colours, and is not applicable to complex images.
Gooch et al. [GOTG05] find grey values that best match the
original color differences through an objective function minimization process. Original contrast between each pixel and
its neighbours is measured by a signed distance, whose magnitude accounts for luminance and chroma difference and
whose sign represents the hue shift with respect to a userdefined hue angle. It has O(N 2 ) to O(N 4 ) complexity, but
a recent extension to a multiresolution framework by Mantiuk et al. improves the algorithm’s performance [MMS06].
Rasche et al. [RGW05] propose a similar approach that finds
the linear transform matching pairwise grey differences to
corresponding color differences. The best transform is found
by minimizing an error function that can be evaluated over a
smaller set of colors to alleviate computation costs.
In recent work, Grundland et al. [GD07] find a global continuous mapping that adds lost chromatic information to
the luminance channel. Their algorithm achieves linear-time
performance thanks to Gaussian pairing sampling which
limits the amount of processed color differences. In Y PQ
color space, the color differences are projected onto the two
predominant chromatic contrast axes and are then added to
the luminance image. A saturation-controlled adjustment of
the output dynamic range is adaptively performed to balance
between the original range and the desired amount of enhancement. Recently, Neumann et al. [NCN07] present a
technique with linear complexity that requires no user intervention. It stresses perceptual loyalty by measuring the image’s gradient field by colour differences in their Coloroid
color space. After discarding all gradient field inconsistencies, fast 2D integration determines the final grayscale image.
In [CF03], Calabria and Fairchild find that image lightness
strongly affects perceived contrast, meaning techniques that
can arbitrarily modify lightness, like approaches by Rasche
and Grundland, may affect image appearance in an adverse
way. A greyscale ordering that contradicts the colours’ luminance ordering also strongly impacts image appearance, yet
in several approaches, ordering is subjective and arbitrary:
the choice of hue angle in Gooch’s Color2Gray can change
all gradient directions, in Rasche’s approach a user-defined
threshold controls whether a colour is mapped to a darker
or lighter value (see Figure 7), and in Grundland’s approach
ordering depends on the image and parameter choice of the
color sampling method. Lastly, image details and salient features may be lost by the choice of neighbourhood size in
Gooch’s Color2Gray or by unpredictable behavior in inconsistent regions of the gradient field in Neumann’s approach
c 2008 The Author(s)
Journal compilation c 2008 The Eurographics Association and Blackwell Publishing Ltd.

195

K. Smith et al. / Apparent Lightness Greyscale

(see Figure 9). Since the discussed colour to grey methods
depend strongly on local image content, colour palettes and
user parameters, they are hindered in their perceptual accuracy and are not directly applicable to animation where the
colour palette is frequently modified and pixel correlations
change quickly due to occlusion and disocclusion. With this
as motivation, we attempt a different approach where perceptual accuracy and consistency is paramount.

3. Apparent Lightness
In order to discuss colour, we must move into the realm
where colour exists - that is, in the observer’s mind. A
physical stimulus produces a perceptual response that we
name ‘colour’, or alternately, an achromatic response we
name ‘brightness’ or ‘perceived lightness’. Colour appearance models take on the complex task of predicting a human
viewer’s perceptual response to colour stimulus - thus defining measures of colour. Throughout this paper, we work in
the CIELAB and CIELUV colour spaces, whose three axes
approximate perceived lightness L∗ , chroma C∗ and hue angle H ∗ . The first component, L∗ , quantifies the perceptual
response of a human viewer to luminance and is defined
by Hunt as “the brightness of objects relative to that of a
similarly illuminated white”. Mathematically, it is defined
as L∗ = 116(Y /Y0 )1/3 − 16 for luminance Y and reference
white luminance Y0 .
While luminance is the dominant contributor to lightness
perception, the chromatic component also contributes, and
this contribution varies according to both hue and luminance. For example, cornflower blue seems brighter than a
dull golden yellow of equal luminance. This phenomenon
is characterized by the Helmholtz-Kohlrausch effect, where
given two isoluminant colours, the more colourful sample
appears brighter.
Helmholtz-Kohlrausch Effect A chromatic stimulus with
the same luminance as a white reference stimulus will appear brighter than the reference [Nay97].
There are two experimental approaches for measuring the HK effect: the Variable-Achromatic-Colour (VAC) approach,
in which an achromatic sample’s luminance is adjusted to
match a colour stimulus; and the Variable-Chromatic-Colour
(VCC) approach, in which the chromatic content of a colour
stimulus is adjusted until its brightness matches a given
grey stimulus [Nay98]. VAC is more common and was used
in the seminal 1954 Sanders-Wyszecki study, and again in
Wyszecki’s later 1964 and 1967 studies [Wys67].

3.1. Helmoltz-Kohlrausch Lightness Predictors
The H-K phenomenon is predicted by a chromatic lightness term that corrects L∗ based on the colour’s chromatic
component. We examine three such predictors published by
c 2008 The Author(s)
Journal compilation c 2008 The Eurographics Association and Blackwell Publishing Ltd.

Fairchild and Nayatani for suitability to the greyscale problem. Existing models, like CIECAM02, account for many
more complex colour appearance aspects, like surrounding
colours, but are less suited to greyscale conversion due to
their complexity and because most disregard the HelmholtzKohlrausch effect (the reader may refer to Table 17.1 in
[Fai05]).
Fairchild’s CIELAB chromatic lightness metric L∗∗ is fit to
Wyszecki 1967 data and is defined as [FP91]:
L∗∗ = L∗ + (2.5 − 0.025L∗ ) 0.116 sin

H ∗ − 90
2

+ 0.085 C∗
(1)

Chroma C∗ measures colourfulness and a sinusoidal curve
predicts the H-K effect’s decreased impact at yellow hues
and its strongest effect at blues.
∗
Nayatani defines chromatic lightness metrics LN
and
VAC
∗
LNVCC , for each experimental approach, based in CIELUV
[Nay97]. † A quantitative difference between them is that
∗
∗
LN
is twice as strong LN
(in log space). For each
VCC
VAC
method, chromatic object lightness is predicted by the following equations (see Appendix for more details):
∗
LN
= L∗ + [−0.1340 q(θ) + 0.0872 KBr ] suv L∗
VAC

(2)

∗
LN
= L∗ + [−0.8660 q(θ) + 0.0872 KBr ] suv L∗
VCC

(3)

suv is the chromatic saturation in terms of u ,v which predicts the effect’s strength according to colourfulness. The
quadrant metric q(θ) predicts the change of the H-K effect
for varying hues, and constant KBr expresses the H-K effect’s
dependance on the adapting luminance La . These chromatic
85

CIELAB L*
Fairchild L**
Nayatani VCC
Nayatani VAC

80

75

70

65

Figure 1: Lightness values from various H-K effect predictors applied to a spectrum of isoluminant colours, compared
to CIE L∗ .
lightness metrics solve a key challenge in greyscale conversion because they predict differences between isoluminant
† For readability, we have used the notation from [Nay98].

196

K. Smith et al. / Apparent Lightness Greyscale

colours. Figure 1 plots the lightness measured by each metric on a nearly equiluminant colour ramp. It can be seen that
more variation occurs when the H-K is being predicted, compared to luminance-based L∗ which predicts nearly equal
lightness for all colours. Note that other colour pairs will
map to the same greyscale value, but that these are predicted
to be more similar than the isoluminant colours.
We now decide which predictor is best suited to greyscale
∗
conversion. We prefer L∗∗ or LN
, because the gathering of
VAC
VAC data on which they are modeled seems more akin to
the goal as it finds a grey that matches a colour. Moreover,
∗
in testing LN
, we observe that its stronger effect maps
VCC
many bright colours to white, making it impossible to distinguish between very bright isoluminant colours. For that
∗
reason, and by heeding Nayatani’s advice that LN
, instead
VAC
∗
of LNVCC , should be used for predicting differences between
∗
isoluminant colours, we decide not to use LN
[Nay98].
VCC
100

4. Global Apparent Lightness Mapping
We now describe our global mapping according to apparent
∗
lightness using the Nayatani model L∗N = LN
described in
VAC
the previous section. The mapping process is as follows:
IRGB → ILUV → IL∗N → G

(4)

We first convert the colour image to linear RGB by inverse
gamma mapping, then transform to CIELUV colour space.
Its apparent chromatic object lightness channel L∗N is calculated according to Equation 2. We map L∗N to greyscale
Y values using reference white chromatic values for u∗ and
v∗ . Finally, we apply gamma mapping to move from linear
Y space back to a gamma-corrected greyscale image G. As
shown in Figure 3 for several colour ramps, the mapping is
continuous, there is no colour reordering, no lost discrimination and the dynamic range is preserved.

CIELAB L*
Fairchild L**
Nayatani VCC
Nayatani VAC

90

80

70

60

Figure 3: On a colour test (left), G (right) preserves overall
appearance and lightness ordering.

50

40

Figure 2: Lightness values from various H-K effect predictors applied over a full spectrum. L∗∗ exhibits a small range
and at blue hues differs from L∗ .
Because they are both fit to VAC data, the behaviours of L∗∗
∗
and LN
are very similar. Their differences stem from the
VAC
data on which they are based, and the flexibility of the mod∗
els. LN
is based on both Wyszecki 1964 and 1967 data,
VAC
theoretical arguments about H-K, and the effect of adapting
luminance. The L∗∗ model is based only on Wyszecki 1967
data and has a simpler treatment of hue which we expect is
responsible for the following: we observed L∗∗ of blue hues
is much higher than L∗ , which reduces its range and makes
∗
its ordering differ significantly from both LN
and L∗ , see
VAC
Figure 2. While the model fits the H-K effect perceptual data,
this range reduction is problematic for greyscale conversion
because colours with different L∗ become less discriminable,
an observation shared by Bala [BB04].‡ We therefore con∗
clude that LN
is the most suitable H-K predictor to use in
VAC
our global colour to greyscale mapping.

‡ Bala uses L∗∗ = L∗ + 0.143C∗ .
1

Figure 4: Our approach maps isoluminant colours to
unique, properly ordered greyvalues.
∗ may map
Due to the compression of a 3D gamut to 1D, LN
two different colours to a similar lightness, which then are
quantized to the same grey value. This occurs only when
colours differ uniquely by hue, which is very uncommon
in natural images and well-designed graphics. Even for a
very challenging image that comprises equiluminant colours
sampled from Neumann et. al’s paper [NCN07], our global
mapping discriminates appropriately, predicting the H-K effect that makes a more colourful blue appear lighter than the
duller yellow, as shown in Figure 4 (view original colours
on a calibrated screen). Recall that our goal is perceptual
accuracy: the resulting low contrast properly represents the
low contrast of the colour image, and each unique colour is
mapped to a unique greyvalue. By incorporating the H-K effect, our global mapping partially solves the problem of grey
value assignment and appropriately orders colours that normal luminance mapping can not discriminate.

c 2008 The Author(s)
Journal compilation c 2008 The Eurographics Association and Blackwell Publishing Ltd.

197

K. Smith et al. / Apparent Lightness Greyscale

5. Local Chromatic Contrast Adjustment
The mapping described in the previous section captures
some chromatic content in the greyscale image G according
to the H-K effect. However, because of dimension reduction
and unaccounted for hue differences, chromatic contrast may
be reduced. Humans are most sensitive to these losses at local contrasts, regions where there is a visible discontinuity.
To counter the reduction, we increase local contrast in the
greyscale image G to better represent the local contrast of
original I. The technique is adapted according to the ratio
between colour and greyscale contrast, so that increases occur at underrepresented colour edges without unnecessarily
enhancing edges that already represent the original. We cater
the general adaptively-weigthed multiscale unsharp masking technique [NB98] to our goal of reintroducing chromatic
contrast. Recently, this general tool has been used to good effect for adjusting contrast of tone mapped images [KMS07]
and to restore contrast from depth perception [LCD06].
We perform contrast adjustments using the Laplacian pyramid that decomposes an image into n bandpass images hi
and a single lowpass image l [BA83]. Laplacian pyramids
are built for I and G in CIELAB using a binomial coefficient filter of order 4. The hi of each channel measures its
local contrast, but as G contains no chromatic information,
its local contrasts are contained entirely in its L∗ channel. At
each scale in the Laplacian pyramid, we adaptively increase
local contrast hi (GL∗ ) by a perceptually-based amount λi ,
which measures the amount of contrast needed to match
colour contrast hi (I). The enhanced greyscale image G is
computed by modifying GL∗ as follows:
n−1

GL∗ = GL∗ +

∑ ki λi hi (GL )
∗

(5)

i=0

where parameters k1 , . . . , kn−1 , ki ≤ 1 exist so that the spatial effect can be controlled according to amount of discriminability desired and the intended viewing conditions (image
size and viewing distance).
The goal of gain factor λi is to measure the remaining chromatic contrast to be restored during the enhancement. We
define it as:
λi =

∆E(hi (I))
|hi (GL∗ )|

p

(6)

∆E(hi (I)) is the colour contrast between a pixel and
its neighbourhood which we measure by ∆E(hi (I)) =
1
(hi (IL∗ )2 + hi (Ia∗ )2 + hi (Ib∗ )2 ) 2 . Since the chromatic channels of G contain no contrast information, |hi (GL∗ )| ∼
=
∆E(hi (G)). The ∆E colour difference is used so that both
colour and grey contrasts are expressed in units of perceptual lightness. The parameter 0 ≤ p ≤ 1 is used to remap
the λ values to a non-linear scale so that weaker contrasts,
like those from isoluminant colours, can be enhanced without over emphasizing stronger contrasts.
c 2008 The Author(s)
Journal compilation c 2008 The Eurographics Association and Blackwell Publishing Ltd.

The parameters introduced exist to provide flexibility, allowing users to tweak according to their preference for desired
discriminability. We criticize other approaches for being ad
hoc, so have ensured that the parameters provide flexibility without allowing uncontrolled changes to the image. The
overall lightness is not altered because we limit the number
of subbands that may be enhanced, preventing changes from
having too large an impact (in practice n ≤ 4 levels). Most
importantly, by definition of λ, edge polarity can not flip,
meaning the lightness order of adjacent regions can not be
changed.

Original I and G

Basic Unsharp

G’

Figure 5: Compared to the basic unsharp mask (middle),
our chromatic enhancement (right) gains contrast where it
is low in G and high in I. In the gain images, green values
represent negative gain; p = 0.25 k = {2, 1, 1, 0.6}.
We illustrate the effect of our local chromatic contrast adjustment in Figure 5. Contrast is nearly below threshold between
isoluminant regions, especially among the bottom row of
colours. A basic sharpening of all contrast (middle) does little to discriminate along that bottom row because the bandpass contains next to no signal. With our chromatic adjustment (right) it is possible to lift these contrasts above threshold without over emphasizing existing contrasts, so the resulting image better represents the original contrast.
6. Results and Discussion
The results presented here strive for perceptual accuracy, and
do not attempt to increase or exaggerate discriminability.
Therefore, the effects are apparent, but subtle. For comparison, we present either the CIE Y channel or Gimp greyscale
with a basic unsharp enhancement, so that the reader is able
to compare between images with matching overall sharpness. Additionally, the images presented here are for viewing
on a calibrated colour screen (sRGB); for print, our resulting greyscale images should be mapped to the appropriate
printer gamut.
We begin by showing that we discriminate between isoluminant colours by applying our approach to two images from
Gooch et al. [GOTG05] in Figure 6. In both images, nearly

198

K. Smith et al. / Apparent Lightness Greyscale

isoluminant regions are distinguishable (parameters p and k,
and thus n, are given with each image). We now compare to
previous work to support our claims of better perceptual accuracy. We illustrate the consistency problem of local adaptive approaches in Figure 7 with Rasche’s result using default parameters (top row) on similar images with varying
colours (bottom row). While our results (middle row) also
use default parameters p = 0.5, k = {0.5, 0.5, 0, 0}, the correct flower brightness ordering is preserved and the greyvalues of leaves and backrounds are identical, and the lightness
range is not exaggerated. Because we maintain consistency,
we are able to apply our approach to video, as shown for a
single frame in Figure 8 with constant parameters p = 0.8,
k = {0.2, 0.8, 0, 0}. The red flowers become more visible and
bright without changing the overall video appearance and
maintaining temporal coherence. Please see our project website for examples of our approach applied over time § .
Figure 7: Rasche (top), and our colour ordered conversion
(middle), original colour (bottom).
Original Video Frame

Figure 6: Our conversions discriminate between colours
even with similar luminance. Car p = 0.5 k = {0.5, 0.5, 0.5};
Island p = 0.8 k = {0.4, 0}.
We consider changes to spatial content, as illustrated by
greyscale versions of Monet’s Impression Sunrise shown in
Figure 9. Gooch’s Color2Gray approach (bottom left) dilates
the sun and reflection and has a strong blurring effect. Neumann et al. (bottom middle) masks details of the background
structures, and alters the water’s brightness, giving the impression of another light source. Our approach preserves the
lightness of regions, the brightness of the sun, keeps all paint
strokes visible, and when visually compared to original contains fewer spatial modifications (bottom right).
Finally, we show results on highly complex images that are
more perceptually accurate than similarly sharpened Gimp
greyscale. In Figure 10, the hats are more bright and the furthest two are distinguished more easily. In Figure 11, the red
fish and stone advance and the two orange fish reappear.

Frame from our G

Gimp greyscale

Frame from our G’ p=0.8,k={0.2,0.8,0,0}

Figure 8: A frame from our hummingbird video. Source:
www.naturelibrary.com.

Engineering Toolbox and a Matlab toolbox for Laplacian
pyramids. Our runtime depends on image resolution and
the speed of colour mapping and pyramid construction. We
specify times for both 1 and 4 storey pyramids, computed
on an Intel4 3 GHz CPU. The Impression Sunrise image
(311×223 pixels) takes 1.8 or 3.2 seconds; the Impatiens image (570×593) takes 6.7 or 10.8 seconds; and the Hummingbird video (192×144) single scale conversion takes 136.3
seconds with 0.96 seconds for each of the 142 frames.
7. Conclusions and Future Work

We implemented our conversion in Octave using the Colour
§ http://www.mpi-inf.mpg.de/resources/ApparentGreyscale

In this paper, we have presented a new approach to color
to grey conversion. Our approach offers a more perceptually accurate appearance than standard luminance mapping
c 2008 The Author(s)
Journal compilation c 2008 The Eurographics Association and Blackwell Publishing Ltd.

K. Smith et al. / Apparent Lightness Greyscale

and generates a closer response to the original than other
approaches. In particular, we have incorporated the H-K effect which we consider fundamental to obtaining faithful
greyscale reproductions. Our two-step approach is a good
compromise between a fully automatic technique (first step)
and user control (second step) making this approach well
suited for natural images, photographs, artistic reproductions
as well as business graphics. Finally a major benefit is the
consistency we ensure by avoiding changes in color ordering. This makes this technique well adapted to the treatment
of videos and image sets.
The main limitation of our approach is the locality of the
second step, since it can not enhance non-adjacent regions.
In future work, we plan to predict image appearance with
respect to its color and spatial surrounding by incorporating
the masking effect of colour patterns and measuring the visibility of the original contrasts using the contrast sensitivity
function (CSF) for chromatic channels as a function of spatial frequency. We also plan to investigate methods for modifying enhancement parameters over time while maintaining
temporal coherence. Further investigation into the problem
of converting video to greyscale or to a reduced colour set
is important for video stylization, processing and display on
limited devices. We hope our work has fostered new ideas in
this direction.
Acknowledgements
We thank Rafal Mantiuk, Hendrik Lensch, Andrei Lintu and
the anonymous reviewers for their valuable comments.
Appendix A: Nayatani Chromatic Lightness Model
In CIELUV colour space u ,v are CIE 1976 chromaticity
of test stimulus and uc ,vc are chromaticities of the reference
white and La adapting luminance, set by default to 20 as suggested by Nayatani. The following are equations for L∗NVAC
and L∗NVCC [Nay97, Nay98].
6.469 + 6.362La0.4495
KBr = 0.2717
6.469 + La0.4495
1

suv = 13[(u − uc )2 + (v − vc )2 ] 2 , θ = tan−1

(7)
v − vc
(8)
u − uc

q(θ) = −0.01585 − 0.03017cosθ − 0.04556cos2θ
−0.02667cos3θ − 0.00295cos4θ + 0.14592sinθ
+0.05084sin2θ − 0.01900sin3θ − 0.00764sin4θ
References
[BA83] B URT P. J., A DELSON E. H.: The Laplacian
Pyramid as a compact image code. IEEE Trans. on Comm.
(1983), 532–540.
[BB04] BALA R., B RAUN K.: Color-to-grayscale conversion to maintain discriminability. Proc. SPIE 5293 (2004),
196–202.
c 2008 The Author(s)
Journal compilation c 2008 The Eurographics Association and Blackwell Publishing Ltd.

199

[BE04] BALA R., E SCHBACH R.:
Spatial color-tograyscale transformation preserving chrominance edge
information. Proc. IS&T/SID’s 12th Color Imaging Conference (2004), 82–86.
[CF03] C ALABRIA A., FAIRCHILD M.: Perceived image
contrast and observer preference i & ii: The effects of
lightness, chroma, and sharpness manipulations on contrast perception. Journal of Imaging Science & Technology, 47 (2003), 479–493.
[Fai05] FAIRCHILD M.: Color Appearance Models, 2nd
Ed. Wiley-IS and T, Chichester, UK, 2005.
[FP91] FAIRCHILD M., P IRROTTA E.: Predicting the
lightness of chromatic object colors using CIELAB.
Color Research and Application 16, 6 (1991), 385–393.
[GD07] G RUNDLAND M., D ODGSON N. A.: Decolorize:
Fast, contrast enhancing, color to grayscale conversion.
Pattern Recogn. 40, 11 (2007), 2891–2896.
[GOTG05] G OOCH A. A., O LSEN S. C., T UMBLIN J.,
G OOCH B.: Color2gray: salience-preserving color removal. ACM Trans. Graph. 24, 3 (2005), 634–639.
[KMS07] K RAWCZYK G., M YSZKOWSKI K., S EIDEL
H.-P.: Contrast restoration by adaptive countershading.
In Computer Graphics Forum (Proc. Eurographics 2007)
(2007), vol. 26.
[LCD06] L UFT T., C OLDITZ C., D EUSSEN O.: Image
enhancement by unsharp masking the depth buffer. ACM
Trans. Graph. 25, 3 (2006), 1206–1213.
[MMS06] M ANTIUK R., M YSZKOWSKI K., S EIDEL H.P.: A perceptual framework for contrast processing of
high dynamic range images. ACM Transactions on Applied Perception 3, 3 (July 2006), 286–308.
[Nay97] NAYATANI Y.: Simple estimation methods for the
Helmholtz-Kohlrausch effect. Color Res. Appl. 22 (1997),
385–401.
[Nay98] NAYATANI Y.: Relations between the two kinds
of representation methods in the Helmholtz-Kohlrausch
effect. Color Res. Appl. 23 (1998), 288–301.
[NB98] N OWAK R. D., BARANIUK R. G.: Adaptive
weighted highpass filters using multiscale analysis. IEEE
Transactions on Image Processing 7, 7 (1998), 1068 –
1074.
[NCN07] N EUMANN L., C ADIK M., N EMCSICS A.: An
efficient perception-based adaptive color to gray transformation. In Proc. of Computational Aesthetics 2007
(2007), pp. 73– 80.
[RGW05] R ASCHE K., G EIST R., W ESTALL J.: Recoloring images for gamuts of lower dimension. Computer Graphics Forum 24 (2005), 423–432.
[Wys67] W YSZECKI G.:
Correlate for lightness in
terms of CIE chromaticity coordinates and luminous reflectance. Journal of the Optical Society of America
(1917-1983) 57 (Feb. 1967).

200

K. Smith et al. / Apparent Lightness Greyscale
Original

GIMP greyscale

Gooch Color2Gray

Neumann et al.

Our G

Our G’ p=0.75 k=[0.2,0.6,0.4,0.4]

Figure 9: Our impression is more like the original because it preserves the paint strokes especially in the sky and background.
Gooch’s image is strongly blurred with a dilated sun and Neumann masks the background and lightens the water.

Original

Unsharp masked GIMP greyscale

Our G’ p=0.75 k={0.4,0.4,0.3,0.2}

Difference between G’ and Gimp version
Our G’ p=0.8 k={0.2,0.5,0.5,0.5}

Unsharp masked GIMP greyscale

Original

Figure 10: The extreme brightness of the hats is more apparent in our image than Gimp’s greyscale which highlights the
differences between the furthest two hats. Source: www.vischeck.com.

Figure 11: Our approach accentuates the red fish and stone, and restores salience to the two orange fish. Source: Getty Images.
c 2008 The Author(s)
Journal compilation c 2008 The Eurographics Association and Blackwell Publishing Ltd.

