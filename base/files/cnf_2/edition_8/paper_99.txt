Eurographics/ IEEE-VGTC Symposium on Visualization 2008
A. Vilanova, A. Telea, G. Scheuermann, and T. Möller
(Guest Editors)

Volume 27 (2008), Number 3

Sound Tracing: Rendering Listener Specific Acoustic Room
Properties
Jens Bellmann1 , Frank Michel2 , Eduard Deines2 , Martin Hering-Bertram3 , Jan Mohring3 , and Hans Hagen1
1 Computer

Science Department, University of Kaiserslautern, Germany
Research Training Group (IRTG), Kaiserslautern, Germany
3 Fraunhofer Institut Techno- und Wirtschaftsmathematik (ITWM)

2 International

Abstract
We present an acoustic rendering approach visualizing the listener-specific contribution of frequency-dependent
pressure fields on a scene geometry with acoustic reflection and scattering properties. Our method facilitates
the evaluation of simulated acoustics showing the effect of simulation parameters like absorption and scattering. The image-based spatial localization of acoustic properties is complementary to the auditive evaluation by
means of auralization. Our core contribution is a pressure-based acoustic rendering equation and a corresponding
raytracing method applying techniques from photorealistic rendering to the field of simulated room acoustics. Applications are directed at the visualization of interference patterns and analyzing the impact of acoustic reflection
parameters.
Categories and Subject Descriptors (according to ACM CCS): I.3.7 [Computer Graphics]: Three-Dimensional
Graphics and RealismRaytracing; I.6.8 [Simulation and Modeling]: Types of Simulation Monte Carlo; J.2 [Computer Applications]: Physical Sciences and EngineeringPhysics

1. Motivation
Understanding the results of numerical simulation is a primary goal of scientific visualization. In the scope of simulated acoustics, the most general concept is a virtual-reality
(VR) based combination of visualization and auralization
methods [FCE+ 98, BDM+ 05, LSVA07]. This means that
stereoscopic viewing of three-dimensional geometry and simultaneous display of acoustic signals within an immersive
VR-environment is feasible. Auralization systems provide a
realistic auditive environment, either using a great number of
speakers for sound field synthesis or based on head-related
transfer functions providing stereo signals perceived by a human.
The core contribution of the present work to this process
is the adaption of photo-realistic rendering techniques to the
visualization of acoustic simulation results. Therefore, we
establish a pressure based acoustic rendering equation which
is applied to an array of frequencies. Since the auditive environment of a scene is by far more complex than its visual

c 2008 The Author(s)
Journal compilation c 2008 The Eurographics Association and Blackwell Publishing Ltd.
Published by Blackwell Publishing, 9600 Garsington Road, Oxford OX4 2DQ, UK and
350 Main Street, Malden, MA 02148, USA.

environment regarding the number of base frequencies that
can be distinguished, our method produces a set of images in
each rendering pass. For each frequency, the corresponding
image conveys the pressure amplitude (mapped to brightness) and its phase shift (mapped to color). From this visual representation, local details of the directional impulse
response are conveyed spatially much sharper than possible
with auditive methods, complementing the valuable analysis
by means of auralization.
While methods inspired by photo-realistic rendering
[JC98] have already been used for acoustic simulation
[KJM04, BDM+ 05], to our knowledge there exists no approach of this kind for visualization purposes. Instead, previous work on acoustic visualization is mostly based on
graphical primitives like spheres, arrows and (iso-)surfaces,
whereas rendering plays an inferior role. Theoretical approaches well known from photo-realistic image synthesis,
e.g. approaches based on a rendering equation [Kaj86], have
not yet been used for the visual evaluation of acoustic simulation results. The present work is meant to close this gap,

Jens Bellmann et al. / Sound Tracing: Rendering Listener Specific Acoustic Room Properties
944
showing that acoustic environments provide a “nice and colmapping [KJM04] is a particle based Monte Carlo method
orful view” when seen with the eyes. This enables us to unfor geometric acoustics also inspired by photon mapping
derstand the contribution of reflected and direct sound to the
[JC98]. It is a two stage sound particle based method modelaudible result at a special position in an intuitive way, being specular and diffuse reflections, as well as diffraction of
cause humans are able to distinguish between the exact dithe sound wave.
rection of light sources in contrast to sound sources.
Visual representation of sound propagation as well as repFurthermore, we illustrate how important details regardresentation of the sound received at a listener position can
ing variations of the simulation method can be viewed,
help in understanding this complex process. The existing viwhich may be much harder to perceive from audio signals.
sualization techniques can be classified into two groups. The
Our rendering method is based on the phonon map, but it is
first group considers the propagation of the sound waves or
generally applicable to results obtained from other simularays inside the room independent of the listener position.
tion methods capable of calculating pressure fields.
[YST02] and [PR05] visualized 2-dimensional sound wave
The remainder of our work is structured as follows: Secpropagation. [PL03,FCE+ 98,LCM07] use 3 dimensional visualization for the evaluation of their results. The second
tion 2 provides a review of related work, including the difgroup is based on the measured or simulated room impulse
ferent approaches to simulated acoustics, visualization and
response for individual listeners. [KFW98] used colormaps
auralization, as well as photo-realistic rendering. In section
for the visualization of pressure levels, [MLPK01] employed
3 our previous work is summarized. Section 4 contains the
2D plots to visualize the impulse response. Stettner et. al.
core contribution of our work, the pressure based acoustic
[SG89] and Monks et al. [MOD00] visualized several acousrendering equation and its use in a raytracing-based visutic parameters by using specific icons. A couple of commeralization algorithm. This method is tested and evaluated in
cial systems, e.g. odeon (www.odeon.dk), catt (www.catt.se),
section 5.
bose (www.bose.com), provide several tools for visualizing
measured or computed acoustic quantities.
2. Related Work
In our previous work we have introduced the phonon tracing algorithm for the simulation of room acoustics based
In room acoustic design and especially in virtual and acouson particles. Furthermore we developed several visualizatic reality applications mostly methods based on geometric
tion techniques utilizing the results of the simulation. The
acoustics are applied. They are based on optical fundamenalgorithm and the visualization approaches are briefly sumtals and make use of approaches developed there. The image
marized in the next section.
source method [AB79,Bor84] models specular reflections by
In this paper we present a pressure based sound renderinserting new sound sources, which are obtained by mirroring equation for room acoustic simulation. Our backward
ing the location of audio source on polygonal surfaces inside
ray tracing approach facilitates a listener based visualization
the scene. In the ray tracing method [Kro68, Kul84, Vor88]
of pressure amplitude as well as pressure phase for middle
several rays are traced from the sound source to receivers,
frequencies of 22 frequency bands. The method shows the
which are typically represented as spheres. The reflections
unfold of the overall sound at a specified listener position.
on the surfaces in the scene take place according to Snell’s
Due to consideration of the sound pressure instead of energy
law of specular reflection and Lambert’s law for diffuse rewe are able to simulate and visualize interference effects.
flection calculation.
Another widely used technique in acoustic computation is
the beam tracing method. Beam tracing overcomes the alias3. Previous Work
ing problem of classical ray tracing by recursively tracing
beams (i.e. sets of rays) of polyhedral [FCE+ 98, FTC+ 04],
3.1. Phonon Tracing
conic [Ama84, MM93, Dal96], triangular [Lew93, Far95], or
rectangular (frustum tracing) [LCM07] cross-sections. Ray
The improved phonon tracing approach, introduced in
tracing and image source methods depend on the receiver
[DBM+ 06] computes the pressure level of a propagating
wave front in contrast to most geometric approaches which
position. Changing the listener position implies a recalculaare energy based. Given a scene with defined absorption
tion of the room impulse response. In contrast beam tracing
properties of the objects, position and emmision probability
and radiosity methods [SZ93,NMI04] are view independent.
distribution Ψ of a source S, one ore more listener positions
Siltanen et al. [SLS07] derived an energy based acoustic renLk an impulse response filter gk for each Lk is computed. The
dering equation which is used to solve a global sound energy
algorithm consists of two steps: the phonon emission step
transport problem for auralization purposes. The computaconstructs the phonon map, and the phonon collection and
tion complexity of all these methods does not seem practical
filtering step collects the phonon’s contribution to gk . The
for large environments.
phonon map contains for each phonon j the pressure specDue to the shortcomings of the approaches described
trum p j , the phonon’s position Pj on the surface, the image
above, continuative approaches have been developed e.g.
source V j from which we can calculate the phonons outgoing
[Vor89, Hei93, Nay93, Lew93]. They mostly employ parts
direction o j , the traversed distance d j , number of reflections
of the classical schemes or a combination of them. Sonel

c 2008 The Author(s)
Journal compilation c 2008 The Eurographics Association and Blackwell Publishing Ltd.

945
All previous visualization approaches are based on graphical primitives (spheres, arrows, surfaces, etc.) and do not
make use of an acoustic rendering equation.

Jens Bellmann et al. / Sound Tracing: Rendering Listener Specific Acoustic Room Properties

nr j , and the material m j at the current reflection.
In the emission stage, η phonons are ent out from the
source S according to the emission probability distribution Ψ. At the intersection of the phonon ray with the
scene, a virtual source V j with pressure reduced by materialdependent absorption is placed behind the reflecting surface.
The phonon is stored at the intersection point, contributing to
a global phonon map. In the collecting stage of the algorithm the phonon’s contribution to the impulse response filter
gk for every listener position Lk is determined. In the case of
a point source and uniform absorption for all frequencies, the
contribution of a phonon visible from the listener is a scaled,
translated unit pulse (Dirac). The Dirac is shifted by the time
elapsed between emission and reception of a phonon. The
scaling decreases with the accumulated length and wall absorption along the phonon path and depends on the angle
between the phonon direction and the direction from the virtual source to the listening position k:
p(t, L) =

χtot pre f
w ∠ o j , L −V j
dj

· δ fs t −

dj
c

(1)

where pre f is a reference pressure at 1m from the source,
χtot is the product of the reflection coefficients along the
phonon path and w is a Gaussian weighting function chosing
σ such that the associated Gaussians approximate a partition
of unity on the unit sphere:
w(ϕ ) =

2 − ϕ 22
e 2σ
ησ 2

(2)

In the more general case of frequency-dependent absorption, the unit impulse is subdivided into wavelets representing the individual frequency bands. The Dirac becomes
then a sum of these wavelets scaled and shifted as described above. The filter design, especially the corresponding band pass filters (wavelets), is described in full detail
in [BDM+ 05].

4. Visualization Algorithm
To vizualize phase and pressure of sound arriving through
the individual pixels of the viewing window, we establish a
pressure-based sound-rendering equation. The corresponding relation between the sound-pressure p(S,t) at a source
at position S and the sound-pressure p(L,t) at a listenerposition L is computed by convolution with a proper impulse
response g,
p(L,t) = g(t) ∗ p(S,t) =

Our phonon tracing approach precomputes particle traces
and records them in the phonon map which we used for
sound visualization. In [BDM+ 05] we visualized the sound
wave propagation by use of color coded spheres representing particular phonons. The color of these spheres corresponds to the energy decomposition of the phonons. In another work [DMB+ 06] we presented additional techniques
using the phonon map to visualize wave fronts on the scene
surfaces using geometric primitives, triangulated surfaces
and scattered data interpolation. Additionally we visualized
the results at a listener position using a color coded sphere
which is deformed according to the direction and amount of
the received energy. In [MDHB+ 07] we introduced a visual
analysis approach of acoustic quality at listener positions utilizing acoustic parameters (metrics) and gave an example of
improvement of speech comprehensibility inside a lecture
room.
c 2008 The Author(s)
Journal compilation c 2008 The Eurographics Association and Blackwell Publishing Ltd.

p(S, τ )g(t − τ )d τ .

(3)

4.1. Adaption of the Ray Tracing Approach
Based on the local pressure representation at scene surfaces
obtained from simulation and our rendering equation, a pressure signal is calculated for every pixel. Therefore, we make
the following assumptions of linear geometric acoustics:
• linear spread of a wave front with sound speed c = 343 ms
• linear attenuation of sound pressure p ∼ d1
• the total pressure is the sum of all reflected pressure fields
Linear acoustics is only applicable to wavelenght λ << ξ ,
with ξ as a measure for the dimensions of the simulated environment. The second assumption of linear attenuation with
the traversed distance d is valid for pressure, whereas energy
is subject to quadratic attenuation.
To calculate equation (3) by ray tracing the pressure response needs to be forumulated geometrically. This is done
by our sound rendering equation
p(L,t) = limρ →0

3.2. Visualization Approaches

τ

1
4 π ρ2

Sρ

PE (B,t) dB ,

(4)

calculating the pressure on an infinitesimal sphere with radius ρ around L by integrating the incomming pressure
PE (B) on its surface. As illustraded in figure 1, B is a point
on Sρ and r denotes the ray from L through B to its intersection point E with the scene. Based on Huygens’ principle,
the pressure field on a reflecting surface can be represented
by an infinite set of infinitesimal spherical sources, see figure 2. The incoming pressure at L may thus be represented
by integrating the pressure contributions of all reflecting surfaces E.
When considering a specific frequency ω , the incomming
pressure PE (B,t) can be represented by a complex function
pE (B,t)dB = g(B, E) · pout (E),

(5)

where g(B, E) denotes the complex transfer function of the
direct transmission line between B and E, given by equation
(6). The harmonic pressure wave and the complex description reduce the convolution with g to a simple multiplication

Jens Bellmann et al. / Sound Tracing: Rendering Listener Specific Acoustic Room Properties

946

=

=

1
4π

i: ψi ∈Ψ

1
4π

i: ψi ∈Ψ

∑

g(L, Ei ) · pout (Ei )ψi

(10)

∑

Pre f l,ψi (L)

(11)

4.2. Recursive Ray Tracing
(b)

(a)

Figure 1: The pressure at the point L can be calculated
by the pressure on the surface of an infinitesimal sphere S
around L with diameter d = 2ρ (a). In analogy, the pressure
at the surface point E can be calculated by the pressure on
an infinit small hemisphere H around E with diameter d (b).

In geometric acoustics reflection of sound is considered
more specular than reflection of light. Diffuse reflections
are mainly due to simplifications in the geometric model,
for example representing a book shelf by a planar surface.
Hence, recursive ray tracing provides a good approximation.
The total outgoing pressure pout at each intersection point is
the weighted sum of specularly and diffusely reflected and
emitted sound pressure.
For an intersection point X k and an incident ray rk during
the recursion, the pressure pout , which is emitted in reverse
direction of rk , can be written as:

pout (X k ,rk )=

Figure 2: Huygens’ principle: A reflected sound wave corresponds to an infinite set of point sources. When adding the
individual pressure fields, shape and direction of the wave
front are preserved.
with g. The phase α and amplitude A of the pressure p(X)
are expressed by a complex number p(X).

1
eiα (||L−E||)
||L − E||

(6)

p(X,t) = A · cos(ω t + α ) = Re(Aeiα eiω t )

(7)

g(L, E) =

= Re( p(X)e

iω t

)

Inserting this into equation (4) provides our frequencyspecific sound rendering equation

Pre f l(L) =

1
4 π ρ2

S

g(B, E) · pout (E, r) dB

ρ →0

, (8)

calculating the total incomming reflected sound pressure. We
note that the direct response from the point source S is not
represented here, since it corresponds only to one point in
the image. The outgoing pressure pout (E, r) at E with respect to the ray direction r is calculated by a simple acoustic
bi-directional reflection distribution function (BRDF), as described below.
The discretization of equation (8) is provided in equation
(9), where ψi is the solid angle covered by the pixel wi .
The infinitesimal radius ρ is eliminated when considering
only the pressure reflected through the viewing window Ψ
towards L:

Pre f l,Ψ (L) ≈

1
4πρ 2

∑

i: ψi ∈Ψ

g(B, Ei ) · pout (Ei )ρ 2 ψi

(9)
ρ →0


 pout,di f f (X k )
p (X k , rk )
 emis
pout,re f l (X k , rk )

i f rd = rdmax
i f rk hits a source
otherwise

(a)
(b)
(c)

(12)

with rd being the current and rdmax maximum recursion
depth. If the maximum recursion depth rdmax is reached only
diffuse reflection is used for the last intersection point (12,a).
The calculation of the diffusely reflected outgoing sound
pressure pout,di f f from simulation data is shown in the next
paragraph. The case that a ray hits a point source (12,b) is
very unlikely, as a point source has no area. Therfore, it will
be neglected. pout,re f l (12,c) is calculated by (13) which describes the outgoing pressure for the first n − 1 reflections
of a ray with rd intersection points. To ensure the correct
reproduction of direct sound in case of specular reflection a
shadow ray is traced for each source Si .

pout,re f l (X k , rk )
= pout,spec (X k , rk ) + pout,emis (X k , rk ) + pout,di f f (X k )
pout,spec (X k , rk )
(13)
= Rspec (X k , rk ) · g(X k , X k+1 ) · pout (X k+1 , rk+1 )
pout,emis (X k , rk ) = ∑∀Si ∈V k Rspec (X k , rk ) · g(X k , Si ) · pemis (Si )

pout,re f l is the sum of the perfectly specular reflected pressure pout,spec (X k , rk ), the specular reflected direct incoming sound pout,emis (X k , rk ) and the diffusely reflected sound
pout,di f f (X k ). V k is the set of direct visible sources S j from
X k , rk+1 is the perfectly specular reflected ray and X k+1
its next intersection point with the scene. Rspec (X k , rk ) is
the specular part of the Bidirectional Reflection Distribution
Function (BRDF). It calculates the sound pressure reflected
by X k in one meter distance. This enables us to approximate
the reflected sound pressure by that of a point source at E.
Figure 3 shows the impact of the recursion depth rd. In
Figure 3(a) the recursion depth rd = 1 is used. Thus, it shows
c 2008 The Author(s)
Journal compilation c 2008 The Eurographics Association and Blackwell Publishing Ltd.

Jens Bellmann et al. / Sound Tracing: Rendering Listener Specific Acoustic Room Properties

947

Figure 3: The same setup traced with recursion depth rd=1, rd=3 and rd=20 @640Hz. The floor has 1% and the other surfaces
90% scattering. The impact of the recursion dept is obvious.
only the information of the phonon map, interpreted as diffusely reflected sound. Figures 3(b) and (c) show the same
setup, traced with rd = 3 and rd = 20. A high recursion
depth increases the effect of specular reflection and overweights the diffuse part. Pre f l,ψi (L) in equation (9) can be
calculated by:
Pre f l,wi (L) = g(L, Xi1 ) · pout (Xi1 , r1 )

(14)

4.3. Local Evaluation of the Phonon Map for diffuse
Reflection
In contrast to previous work in [BDM+ 05] and [DMB+ 06]
we also want to visualize frequency-dependent effects like
inteference. Therefore we need some additional information,
like phase of the reflected sound, to calculate Pemis . As explained in section 4.1, this is done by expressing the phase
and pressure spectrum for each phonon by a complex pressure spectrum.
Each intersection point E can be considered as a point
source, as described in section 4.1. For diffuse reflection the
sound-pressure and phase of this source is determined by
interpolating the phonon map. This is done by a gaussian
weighted sum, equation (15), as proposed in section 3, or
standard Shepard interpolation. A comparison is depicted in
Figure 4. As in this case the reflection is assumed as perfect
diffuse, each p j is weighted by Rdi f f (β ) = cos(β ) for lambertian reflection. β is the angle between surface-normal and
incident direction of the Phonon j.
m

pout (E,t) =

∑ w(γ (Pj , E))Rdi f f (β ) p j

(15)

(a)

(b)

Figure 4: (a) Phonon map of simple wall with point source
in front of it. The left half is interpolated with Shepard, the
right half with gauss interpolation. (b) Legend for minampl =
10−4
the overall error is negligible. Therefore gaussian interpolation is preferred.
4.4. Color Mapping
Phase and amplitude convey the most important information
in our approach. Therefore the phase is mapped on discrete
color intervals in order to display the isolines of the phase
shift. The amplitude is logarithmically mapped on the value
channel of the HSV color model. As in most simulations the
amplitude values are concentrated on a small interval, therefore a lower clipping level minampl is defined. For values below minampl the amplitude is set to zero. Figure 4 (b) shows
the legend for minampl = 10−4 . As the ray tracer creates a
complex pressure spectrum for each pixel in one run, also
the color mapping is done in a single run. For each middle
frequency of a frequency band a single picture is mapped.
5. Examples and Results

j=0

For correct interpolation of the pressure at E we need to distinguish between the phonons on different surfaces. Therefore, for each phonon, the normal and material-index of the
corresponding surface is added to the map.
In Figure 4 (a) the left half of the image is rendered using
Shepard and the right half using equation (15). Even if the
results obtained by gauss interpolation are more blurry than
those by Shepard interpolation, the error can be accepted as a
trade off between quality of the results and physical correctness. As contribution of diffuse reflected sound pressure is
much smaller than that of specular reflected sound pressure,
c 2008 The Author(s)
Journal compilation c 2008 The Eurographics Association and Blackwell Publishing Ltd.

(a)

(b)

Figure 5: Configuration of the simulation scenario in two
different lecture rooms. Orange spheres mark the sources
and blue sphere marks the listener position.

948

Jens Bellmann et al. / Sound Tracing: Rendering Listener Specific Acoustic Room Properties

(a)

(b)

(c)

(d)

Figure 6: The visualization of the phonon map using the described approach (a,b) and the phonon visualization described
in [DMB+ 06] (c,d) for the second reflection showing the global (a,b) and local (c,d) influence of scattering. Pictures (a,c) are
traced with a scattering coefficient of 1% and (b,d) with a scattering coefficient of 50%
5.1. Comparison of Different Visualization Methods
In virtual acoustics scattering is used to model diffuse reflection of structured surfaces. In order to show the scatering effect we visualize the phonon map with our approach
and by use of the method described in [DMB+ 06]. We build
the phonon map for scattering of 1% and 50%, respectively.
For the rendering we consider only phonons which are reflected two times at the scene surfaces. The virtual scene is
depicted in figure 5 (a). The visual results achieved by use
of the sound rendering equation show the global influence of
the scattering coefficient at 320Hz (see 6 (a+b)). The resulting phase pattern becomes more blurry with increased scattering coefficient, recognizable in figure 6 (b) as distorted
phase color borders. The more blurry the total phase of a
surface is the more uncorrelated is the reflected sound wave
front. This global influence of the scattering coefficient can
not be seen in figure 6 (c,d), which shows single particles
on room surfaces [DMB+ 06]. Nevertheless it gives a good
local insight into the scattering effect.
5.2. Interference pattern visualization
Interference is a disturbing effect of standard speaker setup.
While the interference pattern of the first reflection at scene
surfaces can be easily calculated, the determination of the
pattern after several reflections is not that trivial. In order
to visualize the interference phenomenon we have simulated the following scenario (see Figure 5(a)). Inside the
virtual model of a university lecture room (13 × 6 × 3 m),
we have placed two sources in a distance of approximately

three meters between each other (orange spheres). The listener (blue sphere) is positioned centered to the sources at
the same height several meters away. Using this setup interference patterns should be visible, at least for the early reflections. We have calculated the sound pressure and phase
using our sound tracing algorithm for different frequencies
without scattering. The used phonon map contains about 2M
phonons. Figure 7 shows the occuring interference patterns
on the scene surfaces for 452Hz (a,d), 640Hz (b,e), and
1280Hz (c,f) considering only the first reflection (a-c) and
the early six reflections (d-f). The interference patterns due
to the constructive interference (full color intensity) and the
destructive interference (zero color intensity) are clearly recognizable.

5.3. Application Examples
Figures 5 (b) shows a model of a lecture room at our University. The shape and the materials inside this room are
chosen in order to satisfy its usage for speech. We have
calculated the pressure amplitude and phase approximating
the real absorption coefficients. We have traced the rays until the recursion depth of twenty using a phonon map with
2.5M phonons. Figure 8 depicts the resulting visualization
at 452Hz frequency, corresponding to a low frequency of
speech. As expected our visualization shows that the lecture
room is suitable for speech presentations. The side walls on
both sides of the blackboard are mainly responsible for this
fact. The big green spots in the figure show that a large surface of them reflects sound with equal phase as that reflected

c 2008 The Author(s)
Journal compilation c 2008 The Eurographics Association and Blackwell Publishing Ltd.

949

Jens Bellmann et al. / Sound Tracing: Rendering Listener Specific Acoustic Room Properties

(a)

(b)

(c)

(d)

(e)

(f)

Figure 7: Phase visualization of sound received at one listener position for the frequencies 452Hz (a,d), 640Hz (b,e), and
1280Hz (c,f) for the first reflection and after six reflections (d-f) for the scenarion shown in Figure 5 (a).
off the middle of the blackboard. Therefore sound at this frequency will be amplified by these reflections.

Figure 8: Room HS46-110 at the university @452Hz

Our rendering method provides an array of images representing the frequency-specific pressure fields generated by
sound sources inside a room geometry with associated reflection distribution functions. In this representation, color
is used to convey the pressure phase and amplitude contributions of the scene elements visible from a listener position.
We used our method to visualize acoustic patterns like interference and to study the effects of modifications in the
simulation algorithm, such as the introduction and weighting of scattering coefficients.
Our work is a first step combining geometric acoustics
with wave-based methods (like finite and boundary element methods), where continuous complex-valued pressure
fields are computed with tremendous computational efforts.
Since our visualization method can be combined with any
pressure-based simulation method (it is not restricted to
phonon mapping), we want to visualize the results of wavebased simulation methods, as well.
Acknowledgements

6. Conclusions and future work
We presented a pressure based acoustic rendering equation
and a raytracing approach visualizing the results of simulated acoustics. Using complex numbers for pressure fields
at fixed frequencies has the great advantage that annihilation for interference patterns can be modeled, which is not
possible with energy-based approaches (since energy is nonnegative).
c 2008 The Author(s)
Journal compilation c 2008 The Eurographics Association and Blackwell Publishing Ltd.

This work was supported by the German Research Foundation (DFG) through the International Research Training
Group (IRTG 1131) and by the Rhineland Palatine Cluster of
Excellence on Dependable and Adaptive Systems and Mathematical Modeling (DASMOD).
References
[AB79] J.B. Allen and A. Berkeley. Image method for efficiently simulating small-room acoustics. J. Acoust. So. Amer.,

950

Jens Bellmann et al. / Sound Tracing: Rendering Listener Specific Acoustic Room Properties

65(4):943–950, Apr. 1979.
[Ama84] J. Amanatides. Ray tracing with cones. ACM Siggraph,
18(3):129–135, 1984.
[BDM+ 05] M. Bertram, E. Deines, J. Mohring, J. Jegorovs, and
H. Hagen. Phonon tracing for auralization and visualization of
sound. In IEEE Visualization, pages 151–158, 2005.
[Bor84] J. Borish. Extension of the image model to arbitrary polyhedra. J. Acoust. So. Amer., 75(6):1827–1836, 1984.
[Dal96] B.-I. Dalenbäck. Room acoustic prediction based on a
unified treatment of diffuse and specular reflection. Journal of
the Acoustical Society of America, 100(2):899–909, 1996.
[DBM+ 06] E. Deines, M. Bertram, J. Mohring, J. Jegorovs,
F. Michel, H. Hagen, and G.M. Nielson. Comparative visualization for wave-based and geometric acoustics. In IEEE Visualization, pages 1173–1179, 2006.
[DMB+ 06] E. Deines, F. Michel, M. Bertram, H. Hagen, and
G. Nielson. Visualizing the phonon map. In EuroVis, pages 291–
298, 2006.
[Far95] A. Farina. Ramsete - a new pyramid tracer for medium
and large scale acoustic problems. In Euro Noise 95 Conference,
pages 55–60, 1995.
[FCE+ 98]

T. A. Funkhouser, I. Carlbom, G. Elko, G. P. M.
Sondhi, and J. West. A beam tracing approach to acoustic modeling for interactive virtual environments. In ACM Siggraph, pages
21–32, 1998.

[FTC+ 04] T. Funkhouser, N. Tsingos, I. Carlbom, G. Elko,
M. Sondhi, J. E. West, G. Pingali, P. Min, and A. Ngan. A beam
tracing method for interactive architectural acoustics. Journal of
the Acoustical Society of America, 115(2):739–756, 2004.
[Hei93] R. Heinz. Binaural room simulation based on an image
source model with addition of statistical methods to include the
diffuse sound scattering of walls and to predict the raverberant
tail. Applied Acoustics, 38:145–159, 1993.
[JC98] H.W. Jensen and P.H. Christensen. Efficient simulation
of light transport in scene with participating media using photon
maps. In ACM Siggraph, pages 311–320, 1998.

[Lew93] T. Lewers. A combined beam tracing and radiant exchange computer model of room acoustics. Applied Acoustics,
38:161–178, 1993.
[LSVA07] T. Lentz, D. Schröder, M. Vorländer, and I. Assenmacher. Virtual reality system with integrated sound field
simulation and reproduction. EURASIP Journal on Advances
in Signal Processing, 2007:Article ID 70540, 19 pages, 2007.
doi:10.1155/2007/70540.
[MDHB+ 07] F. Michel, E. Deines, M. Hering-Bertram, C. Garth,
and H. Hagen. Listener-based analysis of surface importance for
acoustic metrics. In IEEE Visualization, pages 1680–1687, 2007.
[MLPK01] J. Merimaa, T. Lokki, T. Peltonen, and M. Karjalainen. Measurements, analysis, and visualization of directional
room responses. In 111th Audio Engineering Society (AES) Convention, New York, NY, USA, 2001. preprint nr. 5449.
[MM93] D. van Maercke and J. Martin. The prediction of
echograms and impulse responses within the epidaure software.
Applied Acoustics, 38:93–114, 1993.
[MOD00] M. Monks, B.M. Oh, and J. Dorsey. Audioptimization:
Goal-based acoustic design. IEEE Computer Graphics and Applications, 20(3):76–91, 2000.
[Nay93] G. M. Naylor. Odeon – another hybrid room acoustical
model. Applied Acoustics, 38:131–143, 1993.
[NMI04] E.M. Nosal, Hodgson M., and Ashdown I. Improved algorithms and methods for room sound-field prediction by acoustical radiosity in arbitrary polyhedral rooms. Journal of the
Acoustical Society of America, 116(2):970–980, 2004.
[PL03] V. Pulkki and T. Lokki. Visualization of edge diffraction.
Acoustics Research Letters Online (ARLO), 4(4):118–123, 2003.
[PR05] S. Petrausch and R. Rabenstein. Highly efficient simulation and visualization of acoustic wave fields with the functional
transformation method. In Simulation and Visualization, pages
279–290, Otto von Guericke Universität, Magdeburg, 2005.
[SG89] A Stettner and D. P. Greenberg. Computer graphics visualization for acoustic simulation. In International Conference on
Computer Graphics and Interactive Techniques, pages 195–206.
ACM, 1989.

[Kaj86] J. T. Kajiya. The rendering equation. ACM Siggraph,
pages 143–150, 1986.

[SLS07] S. Siltanen, T. Lokki, and L. Savioja. The room acoustic
rendering equation. Journal of the Acoustical Society of America,
122(3):1624–1635, 2007.

[KFW98] S. Khoury, A. Freed, and D. Wessel. Volumetric visualization of acoustic fields in cnmat’s sound spatialization theatre.
In IEEE Visualization, pages 439–442 & 562, 1998.

[SZ93] J. Shi and A. Zhang. A modified radiosity algorithm for
integrated visual and auditory rendering. Computer & Graphics,
17(6):633–642, 1993.

[KJM04] B. Kapralos, M. Jenkin, and E. Millios. Sonel mapping:
Acoustic modeling utilizing an acoustic version of photon mapping. In IEEE International Workshop on Haptics Audio Visual
Environments and their Applications (HAVE), pages 1–6, 2004.

[Vor88] M. Vorländer. Ein strahlenverfolgungs-verfahren zur
berechnung von schallfeldern in räumen. Acusica, 65:138–148,
1988.

[Kro68] U. Krockstadt. Calculating the acoustical room response
by the use of a ray tracing technique. Journal of Sound and Vibrations, 8(18):118–125, 1968.
[Kul84] U. Kulowski. Algorithmic representation of the ray tracing technique. Applied Acoustics, 18:449–469, 1984.
[LCM07] C. Lauterbach, A. Chandak, and D. Manocha. Interactive sound propagation in dynamic scenes using frustum tracing.
In IEEE Visualization, pages 1672–1679, 2007.

[Vor89] M. Vorländer. Simulation of the transient and steadystate sound propagation in rooms using a new combined raytracing/image-source algorithm. J. Acoust. So. Amer., 86(1):172–
178, 1989.
[YST02] T. Yokota, S. Sakamoto, and H. Tachibana. Visualization
of sound propagation and scattering in rooms. Acoust. Sci. &
Tech., 23(1):40–46, 2002.

c 2008 The Author(s)
Journal compilation c 2008 The Eurographics Association and Blackwell Publishing Ltd.

