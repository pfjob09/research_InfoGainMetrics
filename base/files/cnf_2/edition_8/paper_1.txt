DOI: 10.1111/j.1467-8659.2007.01037.x

COMPUTER GRAPHICS

forum

Volume 27 (2008), number 1 pp. 13–23

Occlusion Textures for Plausible Soft Shadows∗
E. Eisemann and X. D´ecoret
ARTIS-GRAVIR/IMAG-INRIA†
{Elmar.Eisemann@imag.fr}

Abstract
This paper presents a new approach to compute plausible soft shadows for complex dynamic scenes and rectangular
light sources. We estimate the occlusion at each point of the scene using prefiltered occlusion textures, which
dynamically approximate the scene geometry. The algorithm is fast and its performance independent of the light’s
size. Being image-based, it is mostly independent of the scene complexity and type. No a priori information is
needed, and there is no caster/receiver separation. This makes the method appealing and easy to use.
Keywords: soft shadows, image-based, real-time
ACM CCS: I.3.7 Three Dimensional Graphics

1. Introduction

This paper presents a new way to estimate this visibility
function with the following properties:

Shadows are important visual cues to estimate spatial relationships of objects and are a necessity for realistic images.
Point lights have been in focus for several years. The resulting
hard shadows are not very realistic, as in the real world, most
light sources are usually not punctual. Instead of a binary output (lit/unlit), soft shadows consist of umbra and penumbra
regions. The penumbra is the transitional region between the
umbra region (where the light source is fully hidden) and the
region where the light is completely visible.

r
r
r

r

Physically, the incoming light on a small surface is given
by a double integral over this surface and the light source
involving energy, visibility and orientation. Visibility represents the main factor for convincing shadows, and orientation can be mostly neglected inside the integral [AAM02,
AAM03, ADMAM03]. Still, the determination of the light’s
visible portion is not trivial.

Speed independent of the light’s size and penumbrae.
Almost independent of scene complexity, no scene information required, and integrates well with various rendering paradigms (e.g. vertex shaders, point and imagebased rendering).
There is no shadow caster/receiver distinction.

Our approach is inspired by previous work [KM99, SS98]
and obtains real-time performance for highly complex scenes
using off-the-shelf graphics hardware. In general, our solution is not physically correct, as is no current realtime method, but it often compares well to the reference
solution.

∗

Based on “Plausible Image-Based Soft Shadows Using Occlusion Textures”, by Elmar Eisemann and Xavier D´ecoret,
which appeared in Proceedings of SIGRAPI 2006: XIX Brazilian Symposium on Computer Graphics and Image Processing,
Manuel M. Oliveira and Rodrigo L. Carceroni (Eds.), Manaus,
AM, Brazil, 8–11 October 2006, IEEE Computer Society Press.
c 2006 IEEE.
† ARTIS is a team of the GRAVIR / IMAG laboratory, a joint
effort of CNRS, INRIA, INPG and UJF
c 2007 The Authors
Journal compilation c 2007 The Eurographics Association and
Blackwell Publishing Ltd., 9600 Garsington Road, Oxford
OX4 2DQ, UK and 350 Main Street, Malden, MA 02148, USA.

Shadows are plausible, smooth, continuous, and account
for real penumbrae (not just extended umbrae).

The basic method described in this paper was originally
published in [ED06b]. This extended version presents important implementation details, new extensions and not previously described optimizations (Section 3.6), along with additional comparison and deeper analysis (Sections 4.1 and
4.2).

13

14

E. Eisemann & X. D´ecoret / Occlusion Textures for Plausible Soft Shadows

2. Previous Work
Lots of shadow algorithms exist and here, an exhaustive presentation is impossible. We refer to [WPF90, HLHS03] forsurveys.
Point light sources do not create penumbrae because it is
equivalent to point-point visibility. Image-based techniques
such as shadow mapping [Wil78] are based on this observation leading to performance quasi independent of the scene’s
complexity. This makes the method suitable for complicated
objects, but the discrete nature of images leads to aliasing.
Several approaches try to remedy this shortcoming creating
soft-shadow-like effects to hide the jaggy boundaries. Several
shadow samples are evaluated in percentage closer filtering
[RSC87, BS01, Ura05]. In [DL06], statistics are used which
might lead to light leaks. Shadow volumes [Cro77] present an
object-based approach that gives higher quality. Potentially
this is costly for complex scenes (e.g. for vegetation, almost
all edges are silhouettes, yielding shadow quad overdraw and
expensive silhouette detection).
In principle, soft shadows could be sampled using several
point lights. On the one hand, if the rate is too coarse, banding occurs. On the other hand too many samples are costly
[Ura05]. This lead to approximate methods. In [BS02] and
[KD03] unoccluded radii/widths are calculated on a depth
map to estimate the light’s occlusion. Other approaches rely
on a costly precomputation. In [SAPP05] a special deep
shadow map for a static light source is created based on
several standard shadow maps. The resulting map encodes
occlusion for each point of a static scene. It is thus possible
to insert dynamic objects even though those objects cannot
cast soft shadows. Zhou et al. [ZHL∗ 05] follow a very different strategy; occlusion is precalculated per object, and then
used dynamically. To gain storage, the result is compressed
on basis functions which are evaluated, involving sorting,
at run-time at each scene vertex. Agrawala et al. [ARHM00]
create layered attenuation maps by warping several depth images. The evaluation is quick, but the preprocess costly. Light
source and scene thus need to be considered static. Arvo et al.
[AHT04] present an approach where the camera view is processed to add soft shadows. This entirely image-based approach detects hard shadow boundaries and adds (in flood fill
steps) penumbrae regions based on depth map information.
The cost is directly related to the size of the penumbra on the
screen. Depending on the viewpoint and the light’s position,
this area can be very large and the flood fill is not well supported by current graphics hardware. Temporal incoherence
can result from missed penumbra boundaries, for example,
where distinct umbras overlap. Atty et al. [AHL∗ 06] also use
a single depth map. They project depth map texels on the
receiving ground and evaluate the percentage of the source
that is hidden. Occluders and receivers need to be separated
to make this approach work. The algorithm gives convincing results at high frame rates even though CPU usage limits texture resolution. Related techniques were presented in

Figure 1: Visibility as a box-filter response.
[GBP06, BS06, ASK06] where a more expensive fragment
shader projects texels directly from the depth map onto the
source. The run-time complexity becomes highly dependent
on the source’s size. Large sources do not allow real-time
performance and can induce noticeable incoherences.
In [KM99], the scene is replaced by a Multiple Depth Image obtained on the CPU, and ray-tracing is performed against
this alternative representation. There are several similarities
with our method, that we discuss in Section 4. Our work also
relates to Soler et al. [SS98] who introduced convolution for
approximate soft shadows.
Adaptations of shadow volumes for soft shadows are presented in [AAM02, AAM03, ADMAM03]. The result are
high quality shadows, but these approaches are unsuitable for
highly complex models due to the geometry-based wedges.
Sampling artifacts are avoided and light sources can be textured [AAM03], but shadows remain approximative. Only silhouettes from the center of the source are considered and the
contribution accumulation of distinct occluders is additive.
Hybrid approaches like [CD03] add supplementary primitives to silhouettes to describe the blocking influence of an
edge, an idea that is somewhat similar to [WH03]. Both relate
to [PSS98] and lead to alias free, but not soft shadows.
3. Our Approach
We approximate the shadow intensity at a point P for a rectangular light S and an occluder O by:
I (P) :=
S

v P (S) d S,

(1)

where v P is the visibility function defined by:
v P : S ∈ S → 1 if [P, S] ∩ O = ∅ else 0.

(2)

In other words, we count the unblocked rays from P to S.
This function is generally complex and three dimensional.
A GPU friendly approximation is presented in the following
sections.
3.1. Planar occluder
First we consider a single planar occluder parallel to a rectangular light source. It is fully described by a supporting plane
O and a characteristic function δ in that plane:
δ:

O

→ {0, 1}, Q → 1 if Q ∈ O else 0.

(3)

c 2007 The Authors
Journal compilation c 2007 The Eurographics Association and Blackwell Publishing Ltd.

E. Eisemann & X. D´ecoret / Occlusion Textures for Plausible Soft Shadows

15

at very high levels in the mipmap pyramid can lead to large
variations of the filtered function if a slight shift is applied.
To alleviate this problem, D´ecoret introduced the NBuffers
[D’05]. These make prefiltering with continuously placed
kernels possible. Originally they were used with a max filter
and applied in the context of geometry culling. We use them
to compute the mean of neighboring pixels. Each texel, of a
level l, holds the normalized response of a box filter with a
kernel size of 2l × 2l . Intermediate kernel sizes are approximated via linear interpolation. This does not lead to the exact
filtered function, but it significantly reduces the blocky artifacts (Figure 2, bottom). The dyadic construction (using four
lookups per level) is very efficient.

Figure 2: Comparison of different filtering methods.
Consider the frustum of a point P and the light. There is a
bijection between the region where the frustum intersects the
occluder plane and the light rays passing through P. The integral of 1 − δ over this region, normalized by the regions’s
size, thus gives the shadow intensity at P (Figure 1). This
region is a rectangle because the light is rectangular and parallel to the occluder. Its size depends on the ratio of distances
of P to the light and the occluder plane:
s(P) :=

d(P,
d(P,

O)
S)

× si ze(S).

(4)

This derivation presents a particular case of the result by
Soler et al. [SS98], who showed that for an aligned planar
light source, planar occluder and planar receiver, visibility
corresponds to a convolution with an appropriately scaled
source. In our special case the integral can be computed by
filtering 1 − δ with a box filter of size s(P). We encode
1 − δ as a an occlusion texture and process it, as described
in the next section. We can then shade a point P by simply
computing s(P) using Equation (4) and performing a lookup
of the appropriately filtered result.
3.2. Accelerated box filtering
We investigated three approaches to filter an occlusion texture with a rectangular kernel: Mipmapping, NBuffers and
Summed Area Tables.
Mipmapping was originally introduced to reduce aliasing of minified textures [Wil83]. It linearly interpolates between dyadically downsampled versions of a texture. It was
a natural candidate because it is widely supported by GPUs.
Anisotropic filtering even allows rectangular kernels. Shadows vary smoothly thanks to linear interpolation (Figure 2,
top). However, it suffers from blocky artifacts that become
particularly noticeable when the scene is animated. The
dyadic downsampling that may combine adjacent texels only

Summed Area Tables (SAT) [Cro84] allow to compute the
exact filter response for a rectangular kernel. Although an
efficient GPU implementation exist [HSC∗ 05], this approach
still suffers from several limitations. To avoid precision artifacts 32 bit textures are required (shifting the values, as
suggested by the authors, is not useful in our context, due
to the binary nature of occlusion textures). Also linear interpolation for such textures is currently not supported (this is
why texels are noticeable on the close-up of Figure 2). Moreover, creation and transfer increases the bandwidth. The four
texture lookups, needed to get the filter’s response, further
slow down the approach, when NBuffers require only one.
Finally, extra computations are required because the normalization by the kernel size cannot be embedded, contrary to
NBuffers. However, the filtering is exact.
We tried the three approaches (Figure 2). It seems that the
best trade-off between performance and quality are NBuffers.
SAT may become the preferred solution on future hardware.
In particular, a single texture is more cache friendly than multiple textures as is the case for NBuffers. Currently, SATs are
too slow for our purposes, even though our implementation
leads to approximately the same timings as in [HSC∗ 05].

3.3. Several planar occluders
We now consider multiple planar occluders. The shadows
caused by each occluder can be computed independently as
before. However, it is difficult to combine these shadows.
The truth lies between the sum and the maximum of the occluders’ contributions (as pointed out in [SS98]). Intuitively,
two occluders can cover disjoint or overlapping parts of the
source.
Several attempts to solve this problem have been proposed.
In [SS98], the use of the mean value between these two
extremal situations is suggested. Assarson et al. [AAM02,
AAM03, ADMAM03] are inherently bound to combine contributions additively because they constantly add and subtract
occlusion contributions based on edges. A different combination method (still not exact) implies a costly clearing step
after accumulating the contribution of a single silhouette loop

c 2007 The Authors
Journal compilation c 2007 The Eurographics Association and Blackwell Publishing Ltd.

16

E. Eisemann & X. D´ecoret / Occlusion Textures for Plausible Soft Shadows

Figure 3: Comparison of maximum, sum and our probabilistic approach with the reference solution.
(see [ADMAM03]). Detecting these loops loads more work
on the CPU. Arvo et al. [AHT04] need to keep track of the
texel in a shadow map responsible for occlusion during the
flood fill process. It is necessary to make a choice when combining the occlusion for two such texels, and they select the
one with maximum occlusion.
Additive approaches tend to saturate quickly (occlusion
values exceed 100%). The umbra is thus overestimated: shadows look too dark and create unrealistic shadow gradients.
Taking maximum values gives visually more appealing results, but it tends to create gradient reversals and lead to
shadows that seem too bright (in particular if the occluders
are rather unstructured, like the foliage of a tree). The average does not seem to be a good choice, because the maximum
only takes a single occluder into account, whereas the sum
involves all occluders. The ranges of these two values differ
too much to be meaningfully combinable.
Our suggestion is based on the observation that the probability for a ray, from P to S, to be blocked by the considered
planar occluder is exactly 1 − V(P). V denoting the shadow
intensity function given by Equation (1). For several occluders with a uniform distribution of occlusion, the probability
that a ray is not blocked by the union of the occluders is the
product of the probabilities. We suggest to accumulate the
shadow intensities of several occluders using:
n

[1 − Ik (P)].

I1,...,n (P) :=

(5)

k=1

This formula inherits the advantages of the sum; If an occluder does not block any ray [I k (P) = 0], the result is not
modified. If it blocks all rays [I k (P) = 1], the source is declared invisible. In contrast to the maximum (Figure 3), it
does combine all contributions instead of selecting just one.
3.4. General case
In the general case, we approximate the caused occlusion
with several occlusion textures. We slice a scene parallel to
the light source, and project everything inside a slice on its

Figure 4: Orthogonal projections (left) are more prone to
light leaks than perspective ones (right).

bottom plane (the one furthest from the light source). The
binary nature of this information allows the use of approaches
like [DCB∗ 04; ED06a] to recover many layers at the cost of
a single rendering step.
However, more slices imply more texture lookups to compute the combined shadow. The cost of prefiltering can mostly
be neglected (see table in Figure 2).Currently, four to 16 slices
represent a good trade-off between speed and accuracy. To
calculate the occlusion texture representation, each slice is
represented by one color channel. Multiple render targets
(MRT) give the possibility to write into several buffers at
the same time and we can directly associate the slices to the
correct color channel. This also accelerates the computation
of mipmapping, NBuffers or SAT because four slices can be
treated in parallel. This relates to lightweight methods such
as [ND05].
The occlusion texture creation is fast and does not interfere
with any CPU or GPU based animation. Furthermore, it is
compatible with any representation that produces a depth,
such as point-based rendering, impostors or ray-tracing on
GPU.
The view during this rendering pass is very important as it
controls the scene slicing. An orthogonal projection is disadvantageous. First, for an acceptable quality a higher texture
resolution is required because it is more difficult to fit the
scene into the camera’s frustum. Second, the projection onto
slices breaks continuous surfaces into pieces along lines not

c 2007 The Authors
Journal compilation c 2007 The Eurographics Association and Blackwell Publishing Ltd.

E. Eisemann & X. D´ecoret / Occlusion Textures for Plausible Soft Shadows

17

Shadows are affected by this step; umbrae are slightly
overestimated and the shadow gradient differs a little. Consequently, this correction could be applied uniquely for thin
objects. Where light leaks are unlikely, it can be deactivated.
Figure 5: Offsetting the COP simplifies filtering.

Figure 6: Light leaks for thin occluders can be fixed.

oriented towards the light’s center. Light can easily shine
through, where it would actually be blocked by the real surface, causing light leaks (Figure 4). Perspective projection
suffers less from light leaks. Figure 4 illustrates this. Nevertheless, if the center of projection (COP) is placed on the light
source two problems arise. First, to encompass the scene a
large field of view is necessary, increasing texture distortion.
Second, during the shadow computations kernels are large
and can even jut out of the occlusion textures (Figure 5). Interpolation as well as precision issues arise. Placing the COP
slightly behind the light (as seen on Figure 4) at a distance
sufficient to englobe the scene, and fitting the near plane to
the source leads to a much better behavior. Using a projection from a particular COP only affects the way we ‘X-ray’
the scene to approximate occlusion, not the areas where
shadows are computed. There is no relation with the recovery of a depth map (which would only contain the first surfaces of a scene), nor the approximation to detect silhouette edges from the center of the light source as in other
methods.

3.4.1 Light leaks
Perspective projection already limits leaks, but some may
still occur. It will become particularly visible in the case of
thin geometry, such as wings of a butterfly (Figure 6). For
such geometry, we decided to project each occlusion texture
on its successor further away from the source. This helps
‘closing’ the discontinuities. This projection is possible at
almost no cost: It is sufficient to fill two instead of a single
color channel during the slice creation. Figure 6 shows the
effect of the projection. In practice, we did not encounter
any leaks using this method although it does probably not
handle all situations. It is also useful for animation of thin
objects as it improves coherence when geometry changes the
slice.

3.4.2 Self shadowing
There is no shadow caster/receiver distinction in our method.
For every point in the scene the shading is computed based
on the occlusion textures between it and the light source. The
occlusion texture corresponding to the slice that contains the
point needs to be omitted. Otherwise the point would be shadowed by its own projection in the occlusion texture. Simply
ignoring a slice may cause discontinuities where geometry
crosses the clipping planes. Instead, we linearly fade out the
slice’s contribution based on the distance of the shaded point
to the slice’s lower clipping plane.
This is a very coarse approximation. In practice it still often
works well for the following reasons. The occlusion texture
actually provides a good approximation for far away geometry. For nearby elements it is more problematic. Interestingly
diffuse illumination often helps correcting this shortcoming.
Consider a watertight object. The front-facing faces block
light from the back-facing ones. If both fall in the same slice,
this effect is missed. However, the diffuse illumination of
the back-facing faces is zero and makes them appear dark as
they should. For nonwatertight chaotic objects like trees, the
diffuse illumination has high frequencies which potentially
hide incorrect shadowing. Again, the discussed problem only
concerns nearby slices.

3.5. Putting everything together
The algorithm is summarized in Figure 7. Occlusion textures
are obtained by cutting the scene in slices. This involves one
rendering of the scene from the light’s point of view (Section 3.4). These occlusion textures are processed to allow
recovering filtered responses for different kernel sizes (Section 3.2). In a second step, the scene is rendered from the
observer’s point of view. At each point P of the scene, the
shadow caused by each slice between it and the source is computed. This involves a texture lookup according to the size of
the light’s projection from P onto the slice. Using formula (5),
the shadow contributions are combined. This leads to better
results than the maximum or additive approach (Section 3.3).
The contribution of the slice s i closest to P is weighted depending on the distance between P and s i . This results in
a smooth interslice variation. Finally, illumination based on
the material (phong, texture) is combined with the shadow
intensity.
A modification of our algorithm allows sunlight-like shadows (see Figure 8). We suppose that the source is at infinity
and consider a constant frustum from each scene point. To
capture the spherical shape we use a Gaussian instead of a

c 2007 The Authors
Journal compilation c 2007 The Eurographics Association and Blackwell Publishing Ltd.

18

E. Eisemann & X. D´ecoret / Occlusion Textures for Plausible Soft Shadows

Figure 7: Overview of our algorithm.

Algorithm 1 ideal computation of visibility V

Figure 8: Sunlight: simulating a spherical source.

1:
2:
3:
4:
5:
6:
7:
8:
9:
10:

V =0
W = world coordinate(fragment)
for i in occlusion textures do
p, s = kernel pos and level for(W, Light, i)
l= s
vlo = lookup(p,nbuffers[l])
v hi = lookup(p,nbuffers[l+1])
v = (1 − (s − l))vlo + (s − l)v hi
V = accumulate(v, V)
end for

box-filter. The nondyadic nature limits the maximum frustum
size. In the case of sunlight this is unproblematic as the sun’s
solid angle is small in reality too.
NBuffer levels, thus still fitting the 16 textures limitation
(and in particular leaving five textures usable for conventional
shading).

3.6. Implementation details
Conceptually, the algorithm is simple (see alg. 1). To shade a
fragment, we retrieve the corresponding world point W. Then,
for each occlusion texture, we find the kernel position p and
size s (implied by W and the light). We deduce the surrounding NBuffer levels l and l + 1 and lookup the filtered occlusion
in these levels. These are then linearly interpolated and accumulated. The problem is that this approach is currently not
implementable for two reasons. First, shaders do not allow
dynamic access of an array of textures. Line 6 and 7 thus cannot be translated to shader instructions. The second problem
is that shaders can only access a fixed number of textures,
typically 16. If we use four occlusion textures of 256 × 256
(thus encoding 16 slices in the RGBA channels), we need 8 =
log2 (256) levels of NBuffers. Even on a simple configuration
like this, 4 × 8 = 24 different textures are used. We get around
these two problems by using texture packing, and sequencing the algorithm in a way that texture arrays are accessed
statically.
Lets start with packing. Our 16 slices are encoded in four
occlusion textures. Instead of generating eight NBuffers for
each, we generate eight textures and pack in texture i the
NBuffer level i of each occlusion texture (resulting in eight
textures of 4 × 256 × 256, instead of 24.). With a resolution of 2048 × 2048, we would only need three more

Lets now see how we re-order the algorithm. Each slice
i should be filtered with a different kernel of size s i . The
key observation is that this s i is strictly increasing from the
slice closest to the shaded point to the slice closest to the
light. Thus, we can loop over the NBuffer levels l in order
of increasing kernel size s l , and increment a current slice index i. This index is initialized with the slice closest to the
point and is increased every time s i < s l . Because of packing, this index is a shift of the horizontal texture coordinate
used to access the current NBuffer level. This second version (see alg. 2) works because the loop at line 5 is a static
one, completely determined by the resolution of the occlusion
textures.
Line 8 requires a comment. Because we encode four slices
in the RGBA channels of each occlusion texture, increasing
the current slice index is a bit more tricky than using i =
i + 1. Luckily, this can be done efficiently using the swizzle operator of shading languages, and other tricks. We use
a float4 for slice index and implement line 8 and 9 with
i=i.yzwx and delta +=i.w∗packing offset. Then, in
line 12 and 13, when we do the lookup, we get back four
slices as one RGBA color, and we extract the relevant one by
doing a dot product with i. Note that this approach is purely
arithmetic and no branching is used (although conceptually it

c 2007 The Authors
Journal compilation c 2007 The Eurographics Association and Blackwell Publishing Ltd.

E. Eisemann & X. D´ecoret / Occlusion Textures for Plausible Soft Shadows

19

Algorighm 2 practical computation of visibility
1:
2:
3:
4:
5:
6:
7:
8:
9:
10:
11:
12:
13:
14:
15:
16:

V =0
W = world coordinate(fragment)
i = index slice closest to(W)
p, s = kernel pos and level for(W, Light, i)
δ = i∗packing offset
for l in nbuffers levels do
while s<kernel size for level(l)
i =i +1
δ += packing offset
p, s = kernel pos and level for(W, L, i)
end while
vlo = lookup(p + δ,nbuffers[l])
v hi = lookup(p + δ,nbuffers[l+1])
v = (1 − (s − l))vlo + (s − l)v hi
V = accumulate(v, V)
end for

Figure 10: Comparison between our approach and a reference solution for a nonplanar ground.

will be based on scalar rather than vector processors, which
is perfect for our algorithm.

4. Results and Discussion
amounts to tests and can also be implemented using if/then
constructs).
A couple of other optimization can be done, but are not
presented here for conciseness. In particular, packing offset
and kernel position/size actually only depend on the distance
from the shaded point to the COP. This simplifies and factors
several computations. Deferred shading is used to avoid doing computations on hidden fragments. This works because
the algorithm only needs the world position of the fragment,
which can be output in a texture in a first pass. In this section,
we focused on describing the nifty parts of the algorithm.
Additional details are on the paper’s website.

3.7. Anticipating future hardware
There is another way to work around dynamic access of texture arrays. In theory, NBuffer levels could be arranged in
a 3D texture. This would also make the linear interpolation
of line 12–14 immediate and hardware supported. This approach would need to build the slices by rendering into a 3D
texture. Although this is a documented functionality, it seems
drivers do not implement it yet. In the future, this may however prove a possible alternative. Also, the upcoming DirectX
10 introduces texture stacks that would completely address
this indexing problem.
As mentioned before, more than 16 slices could be generated from the scene using techniques as in [DCB∗ 04, ED06a].
Redistributing the slices into color channels can be done independently of the scene geometry. This would also allow to
do a first scene analysis to better fit slices to the objects.
Currently, we simply use a uniform distribution. Another
interesting aspect is the fact that 32 bit textures are fully
supported. Several occlusion layers could thus be packed in
one color channel. This would make the lookups more cache
friendly and improve performance. Finally, new hardware

Our work is similar in spirit to that of Keating and Max
[KM99] but the field of application is completely different. Their approach does not aim at real time and targets
ray-tracing. It introduces the idea of decomposing the scene
into layers but even without averaging several rays, it is still
presented in a form that would not allow real-time performance. It uses a convolution with small kernels mostly to
avoid noise and applies it similarly to percentage closer filtering [RSC87]. Instead, we use convolution for acceleration
purposes. We presented several solutions to approximate filtering efficiently. Our method thus treats large light sources
without penalty. Occlusion textures are efficiently created on
the GPU and we avoid any CPU interaction. We combine
contributions differently, based on probability, and obtain
convincing results without evaluating several sample rays.
Of course, ray-tracing produces more realistic images.
We believe that the introduction of occlusion textures for
shadows is very beneficial. Depth map based approaches can
suffer from visible temporal incoherences for large sources,
even in simple situations. Consider a small occluder close
to the light. It might not even create an umbra region, but
all objects that are hidden in the depth map will not cast
any shadow at all. Therefore, whenever an object passes over
another one, there artifacts appear in the penumbra region.
Atty et al. [AHL∗ 06] rely on two shadow maps to overcome
this problem. Guennebaud et al. [GBP06] do not have this
option, because they would need to separate occluder and
receiver. Thus they are restricted to small sources, not only
for performance but also for quality concerns. For small light
sources, due to a smaller overhead, the technique is preferable, although in this case percentage closer filtering also
works well. Our method has less problems with occlusion
because we rely on slicing. Nevertheless, slicing might miss
nearby occlusions, thus flickering and oscillations may still
appear for vertical movements and grazing angles as shown
in the accompanying video.

c 2007 The Authors
Journal compilation c 2007 The Eurographics Association and Blackwell Publishing Ltd.

20

E. Eisemann & X. D´ecoret / Occlusion Textures for Plausible Soft Shadows

Figure 9: Distant objects are well represented by few slices. Nearby shading benefits from more (e.g. branches).
We implemented our method using Cg 1.5 shading language and OpenGL. To make it possible to compare our algorithm to others we used the same test system as in [AHL∗ 06]
(a 2,4 Ghz Pentium 4 with a GeForce 6800 Ultra). Both the
scene slicing and the computations of NBuffers are very fast,
thus the rendering cost of our method is dominated by the
final render pass. Most of the images we show are levels of
gray. This is to emphasize the shadows. Our method works
seamlessly with textures and would even benefit from their
presence, since texture maps would mask minor shadowing
artifacts. Similarly, most of our examples show cast shadows
on a flat ground to ease the perception. An arbitrary ground
is possible and we want to emphasize again that there is no
caster/receiver distinction in our method.

4.1. Qualitative analysis
Although our approach is based on a very coarse assumption, the results are surprisingly convincing and correct. We
tried different test scenarios to study how well slices capture
occlusion, and the influence of texture resolution. For each,
we compared our technique to a reference solution based on
sampling and show deviations in false colors.
The tree scene of Figure 9 indicates that, even with four
slices, we capture important effects. In particular, the shadows
cast by the big tree are very accurate on the ground because
the further a caster is from a receiving point, the smaller
is the error caused by approximation. In other words, the
further away objects are, the more aggressively they could
be simplified. This means that if shadows on ground are the
focus, a good choice would be to place more slices close
to the ground. Our implementation however uses uniformly
placed slices, because we wanted to make no assumption
about the scenes. The overlapping of branches in the tree
scene would severely challenge depth map based methods.
We added a weak ambient light to show missed shadows
where geometry is close. Diffuse lighting for the tummy of
the buddha is completely black. Figure 10 shows a nonplanar
ground.

Even for extreme low resolution occlusion textures, our
shadows are plausible and smooth. Although each single texture is piecewise linear and can look blocky, combining nonaligned textures increases resolution artificially. One can interprete this in terms of frequencies [DHS∗ 05]. Slices can be
considered as a decomposition of the shadow on basis functions. The lookup into each slice is done with a distinct filter
size and thus represents a separate frequency range. Consequently, low resolutions seem to be sufficient for big lights.
Figure 11 illustrates this. The quality often beats sampling
with many samples, because the light source is huge (the size
of the whole scene) and thus branches add a random noise.
Due to filtering, our result is smooth, as expected. In general
it is not possible to use low resolution textures. Because the
smallest entity is a pixel, the blocking contribution of very
fine objects can be overestimated or missed. This problem is
common to all image-based methods. Noticeable artifacts can
occur during animation (still images are deceiving to judge a
method).

4.2. Timings
We compared the performance of our algorithm with the Soft
Shadow Volume (SSV) algorithm of Assarson et al. [ADMAM03], and with the Soft Shadow Texture (SST) algorithm of Atty et al. [AHL∗ 06]. We used the jeep scene from
[AHL∗ 06] with a varying number of cars (each is 2032 polygons). Figure 12 presents the results. Our method outperforms
both competitors. In particular, the rendering time is almost
independent of the geometry. For SSV, it is clear that adding
more geometry increases the amount of work. For SST, the
slow-down is caused by the increasing number of shadowmap fragments that need to be reprojected. Thus, although
image-based, it is not independent of the scene configuration as is our method. Note that our tests use 16 slices and
high resolution occlusion textures. Here, only four slices and
a low resolution still produces nice results and would yield
even better comparisons. So we largely outperform state-ofthe art image-based soft-shadows algorithms, and we lift the
caster/receivers separation limitation. To emphasize that our
method scales well with the number of polygons, we tested a

c 2007 The Authors
Journal compilation c 2007 The Eurographics Association and Blackwell Publishing Ltd.

E. Eisemann & X. D´ecoret / Occlusion Textures for Plausible Soft Shadows

21

Figure 11: Low resolution is visible for small lights(left) but acceptable for large ones(right), where sampling might be noisy.

Figure 12: Comparison of our method to Soft Shadow Textures (SST) and Soft Shadow Volumes (SSV). We used textures more
than four times larger than SST and 16 slices, whereas four slices of 128 × 128 resolution would be enough (right).

Figure 13: Our method scales well with complexity (each
bunny has 69,451 triangles).

brae are handled; complex interobject shading is treated
through a novel way of combining caster contributions. Although the method is image-based, shadows are smooth, even
at low texture resolution. The method is output sensitive, depending only on the amount of shaded points rather than on
type or size of the shadows. In particular, very large light
sources are naturally treated and it outperforms current stateof-the art algorithms. To our best knowledge, it is the only
approach that possesses all these properties. Some artifacts
can occur, due to the limited number of slices/resolution and
approximated filtering; self-occlusion might fail locally and
shadows can flicker for vertical movements as the weighting
for the closest slice changes.

scene with multiple bunnies, each approximately 69k polygons. Figure 13 shows that we achieve real-time even for
challenging scenes of almost 500k polygons, and 16 slices
(with four slices it runs approximately four times faster).

Slice placement should be investigated further. Litmaps
[D’05], or CC Shadow volumes [LWGM04] might be used
to guide a non uniform placement. Per object slicing could
address the discontinuities inherent to a scene-based slicing,
enforcing ‘continuous’ evolution during animation.

5. Conclusion and Future Work

Reparameterizations [LTYM06] to increase texture resolution locally are a challenging topic, but methods like [GW07]
should integrate smoothly.

We presented a novel image-based soft shadow algorithm,
that is fast and especially well-adapted to GPU. It requires
no precalculation, integrates smoothly with animated scenes,
and does not distinguish casters and receivers. Although not
physically correct, the resulting shadows are convincing and
relatively close to the ground truth: inner and outer penum-

Acknowledgments
We thank the reviewers for their insightful comments, S.
Lefebvre for helpful suggestions and early input. C. Soler

c 2007 The Authors
Journal compilation c 2007 The Eurographics Association and Blackwell Publishing Ltd.

22

E. Eisemann & X. D´ecoret / Occlusion Textures for Plausible Soft Shadows

and H. Bezerra for helpful discussions. U. Assarson, L. Atty,
N. Holzschuch, M. Lapierre, J.-M. Hasenfratz, C. Hansen
and F. Sillion for their support concerning the comparison.
We thank Stanford and Espona for the models.

References
¨
T.: Approx[AAM02] ASSARSON U., AKENINE-MOLLER
imate soft shadows on arbitrary surfaces using penumbra wedges. In Proc. of Workshop on Rendering’02
(2002).
¨
[AAM03] ASSARSON U., AKENINE-MOLLER
T.: A
geometry-based soft shadow volume algorithm
using graphics hardware. In Proc. of Siggraph’03
(2003).
[ADMAM03] ASSARSON U., DOUGHERTY M., MOUNIER
¨
T.: An optimized soft shadow volM., AKENINE-MOLLER
ume algorithm with real-time performance. In Proc. of
Workshop on Graphics Hardware’03 (2003).
[AHL∗06] ATTY L., HOLZSCHUCH N., LAPIERRE M.,
HASENFRATZ J.-M., HANSEN C., SILLION F.: Soft shadow
maps: Efficient sampling of light source visibility. Computer Graphics Forum (2006).
¨
[AHT04] ARVO J., HIKORPI M., TYYSTJARVI
J.: Approximate soft shadows with an imag-space flood-fillalgorithm. In Proc. of Eurographics’04 (2004).
[ARHM00] AGRAWALA M., RAMAMOORTHI R., HEIRICH
A., MOLL L.: Efficient image-based methods for rendering
soft shadows. In Proc. of Siggraph’00 (2000).
[ASK06] ASZODI B., SZIRMAY-KALOS L.: Real-time soft
shadows with shadow accumulation. In Short Paper Eurographics (2006).
[BS01] BRABEC S., SEIDEL H. P.: Hardware-accelerated
rendering of antialiased shadows with shadow maps. In
Proc. of CGI’01 (2001).
[BS02] BRABEC S., SEIDEL H.: Single sample soft shadows using depth maps. In Proc. of Graphics Interface’02
(2002).
[BS06] BAVOIL L., SILVA C. T.: Real-time soft shadows
with cone culling. In Technical Sketch at SIGGRAPH
(2006).

[Cro84] CROW F. C.: Summed-area tables for texture mapping. In Proc. of Siggraph’84 (1984).
[D’05] DE´ CORET X.: N-buffers for efficient depth map
query. In Proc. of Eurographics’05 (2005).
[DCB∗04] DONG Z., CHEN W., BAO H., ZHANG H., PENG
Q.: Real-time voxelization for complex polygonal models.
In Proc. of Pacific Graphics’04 (2004).
[DHS∗05] DURAND F., HOLZSCHUCH N., SOLER C., CHAN
E., SILLION F.: A frequency analysis of light transport.
ACM Transactions on Graphics (Proceedings of SIGGRAPH 2005) 24, 3 (aug. 2005).
[DL06] DONNELLY W., LAURITZEN A.: Variance shadow
maps. In Proc. of I3D’06 (2006).
[ED06a] EISEMANN E., DE´ CORET X.: Fast scene voxelization and applications. In Proc. of I3D’06 (2006).
[ED06b] EISEMANN E., DE´ CORET X.: Plausible image
based soft shadows using occlusion textures. In Proc. of
SIBGRAPI’06 (2006).
[GBP06] GUENNEBAUD G., BARTHE L., PAULIN M.: Realtime soft shadow mapping by backprojection. In Proc. of
Eurographics Symposium on Rendering (2006).
[GW07] GIEGL M., WIMMER M.: Queried virtual shadow
maps. In ShaderX 5 - Advanced Rendering Techniques,ENGEL W., (Ed.). Charles River Media, Inc., 2007.
[HLHS03] HASENFRATZ
J.-M.,
LAPIERRE
M.,
HOLZSCHUCH N., SILLION F.: A survey of real-time
soft shadows algorithms. Computer Graphics Forum 22,
4 (Dec. 2003).
[HSC∗ 05] HENSLEY J., SCHEUERMANN T., COOMBE G.,
LASTRA A., SINGH M.: Fast summed-area table generation and its applications. In Proc. of Eurographics’05
(2005).
[KD03] KIRSCH F., DOELLNER J.: Real-time soft shadows
using a single light sample. Journal of WSCG (2003).
[KM99] KEATING B., MAX N.: Shadow penumbras for
complex objects by depth-dependent filtering of multilayer depth images. In Proc. of Workshop on Rendering’99
(1999).

[CD03] CHAN E., DURAND F.: Rendering fake soft shadows
with smoothies. In Proc. of Symposium on Rendering’03
(2003).

[LTYM06] LLOYD B., TUFT D., YOON S., MANOCHA D.:
Warping and partitioning for low error shadow maps. In
Proceedings of the Eurographics Symposium on Rendering 2006 (2006), Eurographics Association.

[Cro77] CROW F.: Shadow algorithms for computer graphics.in computer graphics. In Proc. of Siggraph’77
(1977).

[LWGM04] LLOYD B., WENDT J., GOVINDARAJU N. K.,
MANOCHA D.: Cc shadow volumes. In Proc. of EG Symposium on Rendering’04 (2004).

c 2007 The Authors
Journal compilation c 2007 The Eurographics Association and Blackwell Publishing Ltd.

E. Eisemann & X. D´ecoret / Occlusion Textures for Plausible Soft Shadows

23

[ND05] NGUYEN H., DONNELLY W.: Hair Animation and
Rendering in the Nalu Demo. In GPU Gems 2. Addison
Wesley, 2005.

[Ura05] URALSKY Y.: Efficient soft-edged shadows using
pixel shader branching. In GPU Gems 2 (2005), Addison
Wesley.

[PSS98] PARKER S., SHIRLEY P., SMITS B.: Single sample soft shadows. Tech. Rep. UUCS-98-019, University of
Utah, 1998.

[Wil78] WILLIAMS L.: Casting curved shadows on curved
surfaces. In Proc. of Siggraph’78 (1978).

[RSC87] REEVES W. T., SALESIN D. H., COOK R. L.: Rendering antialiased shadows with depth maps. In Proc. of
Siggraph’87 (1987).

[Wil83] WILLIAMS L.: Pyramidal parametrics. In Proc. of
Siggraph’83 (1983).
[WPF90] WOO A., POULIN P., FOURNIER A.: A survey of
shadow algorithms. IEEE Comput. Graph. Appl. 10, 6
(1990).

[SAPP05] ST-AMOUR J.-F., PAQUETTE E., POULIN P.: Soft
shadows from extended light sources with penumbra
deep shadow maps. In Proc. of Graphics Interface’05
(2005).

[WH03] WYMAN C., HANSEN C.: Penumbra maps: Approximate soft shadows in real-time. In Proc. of Symposium on Rendering’03 (2003).

[SS98] SOLER C., SILLION F.: Fast calculation of soft
shadow textures using convolution. In Proc. of Siggraph
’98 (1998).

[ZHL∗ 05] ZHOU K., HU Y., LIN S., GUO B., SHUM H.-Y.:
Precomputed shadow fields for dynamic scenes. In Proc.
of Siggraph’05 (2005).

c 2007 The Authors
Journal compilation c 2007 The Eurographics Association and Blackwell Publishing Ltd.

