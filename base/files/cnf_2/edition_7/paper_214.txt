DOI: 10.1111/j.1467-8659.2009.01422.x

COMPUTER GRAPHICS

forum

Volume 28 (2009), number 8 pp. 2151–2164

Fast Isosurface Rendering on a GPU by Cell Rasterization
B. Liu, G. J. Clapworthy and F. Dong
Department of Computing and Information Systems, University of Bedfordshire, UK
{Baoquan.Liu, Gordon.Clapworthy, Feng.Dong}@beds.ac.uk

Abstract
This paper presents a fast, high-quality, GPU-based isosurface rendering pipeline for implicit surfaces defined
by a regular volumetric grid. GPUs are designed primarily for use with polygonal primitives, rather than volume
primitives, but here we directly treat each volume cell as a single rendering primitive by designing a vertex
program and fragment program on a commodity GPU. Compared with previous raycasting methods, ours has a
more effective memory footprint (cache locality) and better coherence between multiple parallel SIMD processors.
Furthermore, we extend and speed up our approach by introducing a new view-dependent sorting algorithm to
take advantage of the early-z-culling feature of the GPU to gain significant performance speed-up. As another
advantage, this sorting algorithm makes multiple transparent isosurfaces rendering available almost for free.
Finally, we demonstrate the effectiveness and quality of our techniques in several real-time rendering scenarios
and include analysis and comparisons with previous work.
Keywords: isosurface, graphics hardware, raycasting, marching cubes
ACM CCS: I.3.3 [Computer Graphics]: Isosurface Computation and Rendering

1. Introduction
Isosurface rendering is one of the most important techniques
for visualizing volume data; it displays a surface representing the locus of a collection of points in the volume that
correspond to a given isovalue. It is applied widely in medical visualization, where volume data are acquired by CT
or MRI scanners and presented as regular volumetric scalar
grids. Isosurface rendering provides a means for visualizing
the boundaries of some materials with complex shapes, for
example, the skin, a specific bone or organ or a tumour.
In recent years, the programmability, and thus the versatility, of consumer-level graphics hardware has evolved at an
increasing pace. Further, the performance of modern GPUs
now exceeds that of CPUs in terms of both the raw computational power provided and the speed at which it continues to
develop. This has led to the GPU becoming the ideal platform
for efficient volume data processing and rendering.
In this paper, we propose a new pipeline for rendering isosurfaces on a GPU by rasterizing only the so-called ‘active’
cells (i.e. those through which the isosurface passes), which
are extracted by GPU stream reduction. We achieved the desc 2009 The Authors
Journal compilation c 2009 The Eurographics Association and
Blackwell Publishing Ltd. Published by Blackwell Publishing,
9600 Garsington Road, Oxford OX4 2DQ, UK and 350 Main
Street, Malden, MA 02148, USA.

ignated isosurface rendering effects by rasterizing each active
cell as a point primitive. In our vertex shader, we compute an
accurate screen-space bounding circle (for the cell to be rasterized), which covers all the pixels on to which the cell will
project. In the pixel shader, we discard unwanted fragments,
and for those remaining, we compute the ray intersections
and shading.
This new pipeline is motivated by the features of volume
data for isosurface extraction and rendering. Normally, a volume data set is rather coarse, as the active cells will occupy
only a small percentage of the total volume. The new pipeline
allows us to skip the large majority of the cells by rapidly
extracting the active cells on the GPU and then rasterizing
them directly on to the screen space. Our result demonstrates
a significant improvement in performance as a result of employing this new pipeline.
To further speed up our algorithm, we propose an efficient view-dependent sorting algorithm, which can effectively drive the hardware early-z-culling feature of the
GPU to achieve significant performance gains. Since correct
transparent rendering requires the geometry to be rendered in a view-dependent order, another advantage of this

2151

2152

B. Liu et al. / Fast Isosurface Rendering on a GPU by Cell Rasterization

sorting algorithm is that it provides the possibility of rendering multiple transparent isosurfaces at virtually no extra
cost. In summary, our technique provides the following major
contributions:
• A new, fast isosurface rendering pipeline, which treats
each volume cell directly as a single rendering primitive on a GPU.
• An accurate and easy-to-implement algorithm to compute the perspective projection of a sphere.
• A new view-dependent sorting algorithm, which provides a further improvement in the speed.
• A transparent-rendering method for multiple isosurfaces with different isovalues.
As far as we know, we are the first to propose a rendering pipeline that treats each active volume cell (a cube with
eight corner voxels) as a single GPU-rendering primitive (a
GL POINT with only one vertex operation), as opposed to
the 12 triangle primitives used in previous bricking-based
raycasting techniques [HQK05], which require many more
vertex-operations and rendering passes for each brick.
The remainder of the paper is structured as follows. In
the next section, we briefly review previous, related work
and indicate how our approach addresses issues associated
with the various algorithms mentioned. In Section 3, we describe the details of our rendering pipeline. In Section 4, we
present a view-dependent cell-sorting algorithm to further
speed up our technique and in Section 5, we demonstrate
its application in the transparent rendering of multiple isosurfaces. The implementation and results are discussed in
Section 6, including comparisons with previous work. The
paper concludes in Section 7 with some ideas for future
work.

2. Previous and Related Work
Hadwiger et al. [HSS∗ 05] use raycasting in the fragment
program of a GPU to traverse the volume data. While this
method uses the CPU to cull some empty blocks for simplification, the fragment program may still need to traverse
many cells along the ray path. The lengths of the ray paths
may differ considerably between neighbouring fragments,
especially for isosurfaces that have many complex silhouettes, such as a network of blood vessels. This implies that,
in the pixel shader, some rays will traverse few cells and
thus have very short paths, while other rays will have longer
paths and run for a much longer time. In the native SIMD
programming model of the GPU, the slowest ray determines
the overall running speed of the fragments that are ‘in flight’
(i.e. the group of fragments being processed by different
parallel processors at a given time), as explained by Leung
et al. [LNM06]. From this point of view, our method is more

suitable for parallel implementation than the raycasting algorithm [HSS∗ 05] [SSKE05], since each of our fragment
programs traverses exactly one cell, which means that there
is better local coherence between neighbouring fragments,
and the amount of texture access is greatly reduced (better
cache locality).
Marching Cubes [LC87] is a well-known algorithm for extracting isosurfaces (contours). It yields a triangular approximation of the contour for an assumed trilinear interpolation of
the scalar field between the discrete grid points. This planar
triangular approximation produces a faceted appearance (diamond artefacts) on the resulting surface [The02], especially
when the viewpoint is very near. Under the assumption of a
trilinear interpolated implicit surface, the contour should be a
cubic polynomial function along any straight line or ray passing through the cell [MKW∗ 04]. In this sense, our approach
uses a more accurate method for finding the intersection
of the ray with the isosurface, and its results thus produce
much smoother images than those generated by Marching
Cubes.
Dyken et al. [DZTS08] ran Marching Cubes on a GPU
by using an efficient stream compaction and expansion algorithm, called HistoPyramid [ZTTS06]. From the tests they
performed, the authors proved that their algorithm outperformed all other known state-of-the-art GPU-based isosurface extraction algorithms. Our algorithm is based on the
assumption that, rather than extracting and rendering all the
Marching Cube triangles individually, it would be more efficient to extract and render all the active cells directly.
Our rendering pipeline is also different from previous
cube-based cell-projection methods. For example, Hong et al.
[HQK05] used object-order raycasting in which all the front
and back faces of the cubic cells are projected on to the image
plane to launch raycasting. However, such techniques require
four rendering passes for each cell, so the rendering contexts
are switched three times during the cell projection, which
will probably result in performance loss on current GPUs. In
contrast, our method needs only one pass for the cell rasterization. Furthermore, the previous methods handle each cell
as a cube with 12 triangle primitives, which involves many
more vertex operations than ours, since we need to handle
only one vertex (a proxy point) for each cell.
Kloetzli et al. [KOR08] rendered isosurfaces at interactive
speed on a GPU using Bezier Tetrahedrons. This method
used a combination of tetrahedron splatting and ray intersection but, like all tetrahedron-based methods, it has to
split each cubic 3D cell into several tetrahedron primitives
during pre-processing. At runtime it also needs to expand
each tetrahedron into several screen-space triangle primitives in the geometry shader. The overhead of this additional stage in the GPU pipeline has proved expensive on
current hardware [DZTS08]. Other tetrahedron-based algorithms may need pre-computation on the CPU to build

c 2009 The Authors
Journal compilation c 2009 The Eurographics Association and Blackwell Publishing Ltd.

B. Liu et al. / Fast Isosurface Rendering on a GPU by Cell Rasterization

2153

some form of accelerating structure for a particular isovalue,
such as interval-tree, k-d tree or octree, but all such precomputations may be a limiting factor (in [KW05] it needs
about 5 s), so extending these approaches to the exploration
of dynamic volume data has proved to be a major challenge.
In contrast, our method needs fewer primitives (for each cell)
than tetrahedron-based methods and is much more suitable
for processing dynamic volume data.
Our rendering pipeline also differs from previous pointbased rendering methods [ZK06] [CHJ03]. These usually use
surface splatting for point rendering, and elliptical weighted
averaging for blending the footprints from neighbouring
point primitives to produce a hole-free surface.
3. Our New Algorithm
In this section, we first give an overview of the flowchart of
our algorithm; the later subsections then provide more details
for the rendering parts of the algorithm: a vertex shader and
a pixel shader.
Our algorithm involves two stages: active cells extracting stage and rendering stage. In the first stage, we build a
HistoPyramid texture [ZTTS06] in order to extract all the
active cells and skip all the inactive cells. HistoPyramid is
an efficient GPU stream-reduction technique, which reduces
a highly sparse matrix with N elements to a list of its M
active entries in O(N + M (log N)) steps, so this technique
fits well with our goal of extracting the active cells from
the coarse volume data. Note that if the isovalue does not
change, our method does not need to rebuild the HistoPyramid for every frame, as the active cells do not change as
long as the underlying scalar field and the isovalue do not
change. A simple review of the HistoPyramid technique is
provided in the Appendix, and further details can be found in
[ZTTS06].
In the second stage, we design a new isosurface rendering
pipeline to render each extracted active cell as a single rendering primitive, rasterize it and finally shade it as an isosurface. Generally, one cannot treat a volume cell as a rendering
primitive, since GPUs are designed mainly for polygon primitives rather than volume primitives. We have overcome this
difficulty by treating each volume cell as a point primitive,
and the desired isosurface rendering effects are produced by
use of a vertex program and fragment program, which are
described in Sections 3.1 and 3.2.
The pipeline is further accelerated by exploiting the hardware early-z-culling feature, thanks to a sorting algorithm;
this is presented in Section 4.
3.1. Vertex program
For each active cell, the vertex program only needs to compute a proper disk in screen-space for hardware rasterization

Figure 1: Left: A top view showing a cell, the red square (a
cube in 3D), and its bounding sphere (in blue) with radius R
and centre O. R has the same length for all the cells and can
be pre-computed. Right: In this context, the intersection of a
cone with a plane is an ellipse, the centre of which does not
lie on the axis of the cone.
as a single rendering primitive (GL POINT), which covers
all the pixels on to which the cell will project.
The only inputs to the vertex program are the indices of
the active cells, which are streamed off a vertex buffer object
(VBO). The vertex program first traverses the HistoPyramid in order to retrieve the object-space position of the cell,
then, from the object-space cell position, it computes the
size (gl PointSize) and the centre for the cell’s projection in
screen-space. To achieve this with a low computing overhead, we use the bounding sphere of each cell to compute
this projection in screen-space.
Due to perspective distortion, the projection of a sphere
is normally an ellipse rather than a circle, unless the centre
−−−−→
of the sphere lies on the optical axis Axiscam of the camera,
which is perpendicular to the image plane. Moreover, the
centre of the ellipse is normally not at the projection of the
centre of the sphere.
In the computer graphics literature, it is difficult to find an
explicit description about how to compute a sphere’s projection under perspective projection, so we provide an explicit
algorithm, which is both accurate and easy to implement, for
solving this problem.
Perspective projection of a sphere. We compute a sphere’s
perspective projection using the concept of conic section, as
shown on the right of Figure 1. From the projection centre,
a sphere will subtend a cone (a solid figure), which touches,
but does not intersect, the sphere. The apex P of the cone
is at the camera position. The sphere’s projection on to the
image plane is an ellipse, which is the intersection of the
cone with the image plane. Here, we derive some equations
to compute the centre of the ellipse and its major axis in our
scenario.
−
→
Figure 2 shows the plane, which is determined by PO (the
−−−−→
axis of the cone) and Axiscam . We call this the CrossPlane,
−−−−→ −
→
and its normal can be calculated as Ncross = Axiscam × PO.

c 2009 The Authors
Journal compilation c 2009 The Eurographics Association and Blackwell Publishing Ltd.

2154

B. Liu et al. / Fast Isosurface Rendering on a GPU by Cell Rasterization

Figure 3: Intermediate and final results of cell rasterization.
The left image shows that the cells are rasterized as round
disks; the middle and right images show the final result after
fragment discarding and ray-intersection (the middle corresponds to intersection with the bounding sphere, while the
right corresponds to intersection with the cell cube). The resolution of this volume data set is set very low (16 × 16 ×
16), for illustration.
Figure 2: The computation of a sphere’s perspective projection on the CrossPlane. The green circle is the intersection of
the CrossPlane and the bounding sphere with centre O and
→
→
radius R = | OA| = | OB|.

On this CrossPlane the sphere touches the cone at two tangent points: A and B, whose projections produce exactly
−−→
the ellipse’s major axis A B , since the major axis lies on
the intersection line of two planes: the image plane and the
−−→
CrossPlane. We shall calculate |A B | as the size of the proxy
point and use its midpoint M = (A + B )/2 as the centre
of the proxy point for hardware rasterization (note that M
is not equal to O , the projection of O). So we need only
to find A and B, and then project them into screen space
(by a matrix) to obtain A and B . That is all we need to
compute.
−
→
We first calculate: sin(α) = R/|PO|, where α is the semi−
→
angle of the cone, then find H (the intersection of AB and
−
→
PO) from:
−
→
H = O − R ∗ sin(α) ∗ normalize(PO)

(1)

Finally, we obtain
−→
A = H + HA
−→
B = H − HA

(2)

−
→
−
→
where HA = R ∗ cos(α) ∗ normalize(Ncross × PO).
As a result, the cell will be rasterized in screen space as a
round disk (anti-aliased point) with centre at M and diameter
d equal to |A B |. The round disk can guarantee to cover
all the pixels on to which the cell can be projected in the
screen, because the disk is exactly the bounding circle of
the projected ellipse in the image plane. An intermediate
rendering result of our cell rasterization approach is shown
on the left of Figure 3.

3.2. Fragment program
In the fragment program, we compute the ray-isosurface intersection for only one cell, which is rasterized to produce
the fragment.
From the fragment position and camera position, we can
generate a ray, which will have at most two intersection points
with the cell. To find the intersections, there are two alternative methods: ray-intersection with the bounding sphere of
the cell, or ray-intersection with the exact cell (a cube with
eight corner voxels). We introduce each of them separately.
• Ray-cell intersection using a bounding sphere. This
can be computed easily by substituting the ray equation into the equation of the sphere, which results in
a quadratic equation that can be solved easily by the
standard formula.
• Ray-cell intersection using a cube. There are many
methods for computing ray intersection with an axisaligned box. We adopt [GM03] because it exploits the
properties of the IEEE floating-point standard and the
SIMD instruction set to produce a branchless, SIMDfriendly variation of the intersection algorithm that is
efficient on GPUs.
Both of the above methods can produce two intersection
points of the ray with the cell if it has intersections, otherwise the fragment is simply discarded. The former method is
slightly faster, so we use it for all the opaque isosurface rendering in this paper, while the latter produces ray segments
with no overlap between neighbouring cells, so it is used only
in the particular case of transparent isosurface rendering (see
Section 5).
After finding the two end points of the ray segment, we
calculate the exact intersection of the ray segment with the
isosurface by using uniform stepping combined with a binary

c 2009 The Authors
Journal compilation c 2009 The Eurographics Association and Blackwell Publishing Ltd.

B. Liu et al. / Fast Isosurface Rendering on a GPU by Cell Rasterization

Figure 4: Firstly uniform stepping (left) finds the first sign
change along the ray, where P1, P2, P3 and P4 have the
same sign (opposite to P5’s sign), and then the binary search
(right) refines the result between P4 and P5 (P6, P7 and
P are intermediate and final results, respectively). Here we
assume ray-sphere intersection is used.

search [POC05], as shown in Figure 4. Hardware trilinear reconstruction filtering is exploited for each texture sampling
of the scalar density function f (x), and the isosurface is defined as F (x) = f (x) − isovalue = 0.
The uniform stepping searches for the first sign change of
F(x) along the ray segment at each pair of two neighbouring
uniform sample points. Once the first sign change has been
identified as lying between x i and x i+1 , the binary search is
used to refine the result between x i and x i+1 . The number of
iteration steps for uniform stepping is computed adaptively
according to the projection diameter, d, of the cell using a
simple linear relationship—a larger d means that the cell
is nearer to the camera and, thus, more steps are required
for accuracy. The number of iteration steps for the binary
search is normally small (2 or 3 generally suffice). Because
neighbouring cells produce similar values for d, the number
of iterations for neighbouring cells is, if not exactly the same,
at least very similar, so coherence between neighbouring
pixel shaders is preserved, thus assisting effective parallel
implementation.
If higher quality is desired, an analytic cubic polynomial
root solution [MKW∗ 04] can be applied, which will result
in more accurate intersections, though with a much greater
computational overhead. Marmitt et al. [MKW∗ 04] proved
that iterative solution is much faster than analytical solution
for cubic polynomials, even under Parallel SIMD Implementation, so we use the iterative solution for all the rendering in
this paper.
If no intersection is found between the ray segment and
the isosurface, the current fragment is discarded immediately. If there is an intersection, we perform Phong shading
for the fragment, based on the normal at the intersection.
The normal can be computed on the fly, or pre-computed, as
the normalized gradient of the volume. Finally the z-value

2155

of the intersection is output to the z-buffer by the fragment
program. Note that for ray-sphere intersection, the ray sampling points may end up being slightly outside the bounds
of the cell, but since we use hardware trilinear sampling to
access the 3D texture, so the isosurface being traced will exactly match the isosurfaces traced in the same pixel position
for the neighbouring cells, since the trilinear reconstructed
isosurface (a cubic polynomial) is C 0 continuous cross the
cell boundaries, so no artefacts are introduced here. Two
results, corresponding to the two methods for ray-cell intersection above (after fragment discarding, ray intersection
and shading) are shown in the middle and right of Figure 3,
respectively.
Note that only one cell is involved in the above rayintersection investigation, so all the parallel pixel shaders
have a similar program length (thus ensuring better coherence between multiple SIMD processors); the texture access
is also limited only to the local neighbouring voxels around
one cell (better cache locality and smaller memory footprint).
These two aspects are very important for effective parallel
implementation on the GPU.
Overall, our rendering pipeline is a hybrid of forward (cell
rasterization) and backward (ray intersection) methods.

4. Accelerating the Algorithm by Sorting
Although our rendering pipeline can already achieve realtime speed, we can make further performance improvements
by effectively exploiting the hardware early-z-culling feature,
which is driven by a CPU-based sorting.
Hardware early-z-culling works on the GPU [SI05] as follows. Prior to the execution of a pixel shader, the graphics
hardware performs a check to see if the interpolated z-value
of the fragment is less than the z-value in the z-buffer. If the
check fails, the pixel shader will be skipped without executing. We exploit this hardware feature to avoid execution of
the pixel shader for all the occluded fragments. However, it
works well only if all the cells are rendered in a front-to-back
order as, in this way, there will be many occluded fragments
after the front-most cells are rendered.
Unfortunately, the sequence of the extracted cells by the
original HistoPyramid algorithm [ZTTS06] is in a quad-tree
order (shown on the left of Figure 5), which is not viewdependent and cannot effectively exploit the hardware earlyz-culling feature. So, in the following three subsections, we
present a new view-dependent rendering algorithm to overcome this problem.
In Section 4.1, we make sure that all the slices are taken
from the 3D volume data along the viewing direction; in
Section 4.2, we sort the slices from quad-tree order into
sequential order; in Section 4.3, we render all the slices in a
front-to-back order, according to the camera position.

c 2009 The Authors
Journal compilation c 2009 The Eurographics Association and Blackwell Publishing Ltd.

2156

B. Liu et al. / Fast Isosurface Rendering on a GPU by Cell Rasterization

As noted earlier, the HistoPyramid texture was originally
organized in a quad-tree order, and for the sake of economy,
we need to change this into a slice-based sequential order,
based on the read-back texture. The example in Figure 5
shows this sorting process.

Figure 5: Sorting from the original quad-tree order to a
slice-based sequential order. The texture that we read back
is in quad-tree structure (left), which amounts to a 1D
array in this order: (0,1,4,5,2,3,6,7,8,9,12,13,10,11,14,15).
After sorting, the slice-based sequential order (right)
amounts to a 1D array in view-dependent order:
(0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15). The value in each element represents the order for the corresponding slice.
4.1. View-dependent tiling layout
When we create the tiled 2D texture (as the base texture of the
HistoPyramid) from the 3D volume data, we always set the
tiling direction along the major axis of the viewing direction.
In this way, each tile corresponds to a 2D slice perpendicular
to the major axis of the viewing direction, where the major
axis is selected as the axis (X, Y or Z) for which the angle
between the axis and the viewing direction is smallest. This
tiling layout ensures that all the slices are handled in a strictly
view-dependent order.

Note that the resolution of the texture that we read back is
very low, hence the total amount of data for CPU sorting is
small. Because of this and the fact that the CPU-sorting algorithm is simple, the sorting time can, effectively, be ignored.
Consequently, the bottleneck of the system still lies with the
GPU, rather than the CPU.
4.3. Slice-based rendering order
The output of our CPU sorting is two 1D arrays, each of
length L. Each element in the first array (num cell [i]) contains
the number of active cells for the ith slice, while each element
in the second array (num offset [i]) contains the number of
active cells in all previous slices (from 0 to i − 1), which is
the offset (in the output-stream sequence) for the ith slice.
After the CPU sorting, all the active cells in one slice are
rendered in a batch, and all the slices are rendered one by
one in view-dependent order. For clarity, we summarize the
rendering algorithm in Algorithm 1, which renders all slices
in front-to-back order, based on the camera position (the sign
of the MajorAxis direction).

Algorithm 1 Rendering All Cells in Front2BackOrder

4.2. CPU sorting
We assume that the resolution of the 3D volume data (N ×
M × L) is a power of two in each of the axial directions
(arbitrary sizes can be accommodated by the use of suitable
padding).
After we build the HistoPyramid texture on the GPU, we
need to read back a single particular texture level from the
pyramid to main memory to perform the sorting on the CPU.
The particular pyramid level l r depends upon the number of
slices along the viewing direction. For example, if the main
axis is Z, then the number of slices is L.
At this particular level of the pyramid texture, there is only
one element for each slice, so at this pyramid level all the
slices are tiled into a 2D texture with a side of length (2lr −1 ).
In this, each of the texels has four channels (R,G,B,A), and
each channel has an integer value for a slice representing the
number of active
√ cells in the slice; l r can be computed as:
lr = 1 + log L/4 .
For example, if the volume data resolution is 256 × 256 ×
256, then L = 256 and l r = 4. This means that we only need
to read back the fourth level from the pyramid (the first level
is the pyramid top with side length equal to 1), for which
the resolution is 8 × 8. This small texture contains all of the
information needed for sorting.

1: if SignOfMajorAxis > 0 then
2:
for i = (L − 1) to 0 do
3:
offset ⇐ num offset [i];
4:
N cells ⇐ num cell [i];
5:
glDrawArrays(GL POINTS, offset, N cells );
6:
end for
7: else // negative major axis points to the camera
8:
for i = 0 to (L − 1) do
9:
offset ⇐ num offset [i];
10:
N cells ⇐ num cell [i];
11:
glDrawArrays(GL POINTS, offset, N cells );
12:
end for
13: end if

In this view-dependent ordering, the hardware program
flow will focus on the front-most cells (first depth layer)
only, and the occluded layers and cells can be skipped effectively. Detailed measurements of the speed-up achieved by
our sorting algorithm can be seen in Section 6.1.
5. Transparent Rendering of Multiple Isosurfaces
Another advantage provided by our sorting algorithm is that
we can render multiple layers of isosurfaces transparently in
the same frame, and this comes almost for free.

c 2009 The Authors
Journal compilation c 2009 The Eurographics Association and Blackwell Publishing Ltd.

B. Liu et al. / Fast Isosurface Rendering on a GPU by Cell Rasterization

2157

Correct transparent rendering requires that the geometry
should be rendered in a view-dependent order (back-to-front
or front-to-back) so that all the surfaces can be blended correctly. Previous approaches have needed to read back the
geometry (the output from Marching Cubes) for sorting on
the CPU, which may dominate the total rendering time due
to the large number of triangles, or have employed hardware depth-peeling, which requires the same geometry to
be rendered several passes [Eve01]. Our approach allows
straightforward transparent rendering by taking advantage
of the slice-based rendering order, so that all the slices are
blended correctly by the hardware alpha-blending feature.
Further, multiple isosurfaces with different isovalues can
be transparently rendered without the need for multiple rendering passes, since all the active cells (for several different
isovalues) can be rasterized by only one pass.
When we build the base texture of the HistoPyramid, the
integer part of each texel (in float32 format) is still 1 or
0 to represent whether the cell is active or not, while the
fractional part of the float32 value is used to identify the
different isovalues for which the cell is active. When the ray
intersects the cell, we check the fractional part of the float32
value to identify the isovalues for which this cell is active.
We then find the ray intersections with the corresponding
isosurfaces and render each surface using the corresponding
colour and alpha values.
If the fractional part indicates that a cell is active for more
than one isovalue, we blend the colours at the intersection
points (which will be at different depths) before outputting
the final colour in the fragment program. When we render
transparent isosurfaces, we disable the OpenGL depth testing
so that these multiple layers can be blended together.
As a result, several different isosurfaces can be rendered
correctly, each with a different colour and alpha value. Further, all of their isovalues, colours and alpha-values can be
changed interactively at runtime. Some results of transparent
rendering are shown in Figure 6.

Figure 6: Transparent rendering result; two isosurfaces
with isovalues corresponding to skin and skull, respectively,
are rendered by only one pass; the framerate is around 30fps;
the resolution of this data set is 256 × 256 × 256.
the various algorithms all refer to their performance on this
computer and that comparisons for the various test cases were
rendered under the same view configurations.

6.1. Comparison with marching cubes
We compare the rendering quality of our algorithm with
that of Dyken et al. [DZTS08], by a zoomed-in image in
Figure 7. Marching Cubes produces a faceted appearance
(diamond artefacts), which is caused by the planar triangles,
while our method uses ray-isosurface intersection to produce
a smoother result.

In this section, results concerning the performance and quality of our technique are presented, and the advantages of
our approach, as compared to previous work, are discussed.
Comparisons are made against the latest GPU-based Marching Cubes method (Section 6.1) and a representative GPUbased raycasting method (Section 6.2). Some discussion is
carried out in Section 6.3, and Section 6.4 indicates some
limitations.

We also compare the speed with that of Dyken et al.
[DZTS08], who proved that their algorithm outperformed
all the latest GPU-based isosurface rendering algorithms (including some CUDA-based implementations), so it is an appropriate yardstick against which to test the performance of
our algorithm. To make the comparison as exacting as possible, their fastest rendering mode, GLHP-VS, is used. Table 1
shows the results of the comparison in terms of the frame rate
achieved across a variety of models and data resolutions. To
assist with repeatability, we also give the isovalue for the isosurface, and the number of active cells that were identified.
The test scenes used here are shown in Figure 8.

The experiments were performed on an AMD 3.01 GHz
PC with an NVIDIA GeForce 8800GTX graphics card using
OpenGL/GLSL. All images were rendered at 800 × 800
screen resolution. We emphasize that the results quoted for

An advantage of our method over [DZTS08] is our inclusion of the view-dependent sorting algorithm which helps us
to avoid rendering occluded cells. Although many cells will
be hidden due to occlusion (especially when the isosurface

6. Results and Discussion

c 2009 The Authors
Journal compilation c 2009 The Eurographics Association and Blackwell Publishing Ltd.

2158

B. Liu et al. / Fast Isosurface Rendering on a GPU by Cell Rasterization

Figure 8: Rendering results (by our method) used in the
performance analysis of Table 1.
Figure 7: Quality comparison with Marching Cubes. Closeups of the upper two images are shown in the respective lower
images.

646). The occluded active cells form a large proportion of
the total and can be culled efficiently as a result of our sorting
algorithm.

is very complex and has many layers occluding each other),
methods based on Marching Cubes simply extract and render all of these triangles, whether they are occluded or not.
We propose the view-dependent sorting algorithm to avoid
rendering these occluded cells. By use of this sorting, our
rendering procedure focuses on the front-most layers of cells
and subsequently discards the occluded ones.

Using this data set, we performed the following 3 experiments for our approach to prove the speed-up that the sorting
can achieve:

It is evident from Table 1 that the greater the complexity
of the surface, the greater are the benefits of our method.
When there are more active cells, the amount of occlusion
increases, so our front-to-back rendering order makes better
use of hardware early-z-culling for greater speed. Our best
speed-up in the table is achieved for the MRhead data set,
which is an MR-scanned head data set with a resolution of
256 × 256 × 256. The isosurface for this data set has many
complex layers with a huge number of active cells (2341,

3. after sorting, rendered from front to back, 34.9fps.

1. without sorting, rendered in original quad-tree order,
16.5fps;
2. after sorting, rendered from back to front, 15.1fps;

We can see that it is only the last of these that makes efficient use of hardware early-z-culling (almost four times
faster than [DZTS08]); the second case is the worst as
rendering takes place in the inverse order to how early-zculling works. The first case shows that having no sorting is
little better than the worst case. Even so, it is still faster than
the fastest mode (GLHP-VS) of [DZTS08], which uses the

Table 1: The performance of full extraction and rendering of isosurfaces from scratch for each frame, measured in frames per second (fps), and
comparison with GPU-based Marching Cubes [DZTS08] on the same hardware platform and all with the same view configuration. # represents
the number of active cells. Test scenes are shown in Figure 8.

Model
name
CThead
MRbrain
Bonsai
Aneurism
MRhead
Cayley

Cell
dimension

#

Isovalue

[DZTS08]

Our
method

255 × 255 × 127
255 × 255 × 127
255 × 255 × 255
255 × 255 × 255
255 × 255 × 255
255 × 255 × 255

308787
551630
508145
119478
2341646
155317

32.0
103.4
37.75
55.59
127.0
0.0

53.2
33.9
34.2
77.8
9.1
67.9

79.7
76.8
59.1
76.8
34.9
73.9

c 2009 The Authors
Journal compilation c 2009 The Eurographics Association and Blackwell Publishing Ltd.

B. Liu et al. / Fast Isosurface Rendering on a GPU by Cell Rasterization

2159

vertex shader to perform the expansion of the geometry by
traversing the HistoPyramid textures once per vertex of each
isosurface triangle produced by the cell. In contrast, our vertex shader traverses the HistoPyramid textures only once per
cell. For example, if a cell produces five triangles, their vertex shader has to be run 15 times for the cell, whereas our
traversal is run only once. Since HistoPyramid traversal is the
bottleneck of the isosurface extraction process, this provides
considerable computational savings.
If there are not many occlusions to be exploited in the data
set, the benefits from our sorting are limited, because in such
cases, we cannot make much use of hardware early-z-culling.
Hence, the worst speed-up is for the Aneurism data set, which
is a scan of the arteries in a human head. The isosurface in
this data set is very sparse, so little occlusion occurs between
the active cells. For this data set, our frame rate is marginally
worse than that of [DZTS08], this is because our pixel shader
is more complex in relation to the intersection computing
introduced to improve image quality.
In summary, our method provides both better image quality than the algorithm of [DZTS08] by reducing the diamond
artefacts, and major performance gains, apart from in scenes
of low complexity. Previous tests had shown that the algorithm of [DZTS08] outperforms other methods, but for the
MRhead data set, our frame rate is almost 4 times faster than
theirs.

6.2. Comparison with GPU-based raycasting
Here we compare our results with those produced by raycasting in relation to performance and quality. To represent
GPU-based raycasting techniques, we selected [SSKE05] because this seems to be the only recent GPU-based raycasting
technique for which the code is available and thus for which
we could make direct comparisons (using the same data set on
the same hardware and with identical view configurations).
Adaptive sampling may cause some fine details in the data
set to be missed, resulting in an inaccurate image, which
is unacceptable to clinical users. Therefore uniform sampling should be used by raycasting with a sufficiently small
sampling distance S dist to provide the required accuracy and
quality.
The only expensive stage of the raycasting algorithm is
the actual ray-marching loop. The calculation time of raycasting for each fragment is mainly influenced by the ray
length, as this controls the number of marching steps. From
Figure 9, it is obvious that the ray length of our method is
shorter than in raycasting, especially for transparent rendering, as in raycasting, many fragments that do not accumulate
sufficient alpha components to reach the opacity threshold
will continue executing until they reach the volume bounds,
whereas our method ensures that ray segments are associated
only with the active cells (the two red squares in Figure 9).

Figure 9: For opaque isosurface rendering (early ray exiting due to first-hit can be applied), the ray length of our
→
→
method is | BC|, while the ray length of raycasting is AC. For
transparent rendering (early ray exiting can not be applied),
→
→
the ray length of our method is | BC| + | DE|, while the ray
→
length of raycasting is | AF|. In this illustration, ray-cube
intersection is being used by our method.
Since the quality and performance of a raycasting algorithm depends heavily upon the numbers of sampling steps
along the ray, which is determined by the uniform sampling
distance S dist and the ray length, various cases with different
S dist were compared with our method in the following two
subsections.
6.2.1. Using pre-computed normals
Please note that in order to perform a true comparison with
[SSKE05], which used only pre-computed normals, all the
experiments in this subsection used pre-computed normals
for both our method and raycasting, whereas in all of the
other experiments in this paper, normals were computed onthe-fly. The raycasting code used here is from [SSKE05]
without any changes, we simply ran it on our computer to
find the results.
From the two results shown in Figures 10 and 11, we can
see that when raycasting uses a shorter sampling distance
S dist , its rendering quality becomes closer to ours, but at the
same time, its rendering performance becomes much slower.
This is because we focus all our sampling only inside the
active cells, while raycasting has to sample uniformly along
the ray to avoid missing some small features. GPU-based
empty-space skipping could be considered to ameliorate this
by using an interval-tree (computed by the CPU and transferred to the GPU), but this would impose pre-computation
and data-transfer burdens for dynamic volume data, furthermore such image-order empty space skipping must perform
checks on essentially a per-sample basis and thus is much
more expensive. Note that Stegmaier et al. [SSKE05] did use
some performance optimizations, such as ‘early ray termination’ and ‘inside-test checking’, but as the authors indicated,
the performance gains expected by these optimizations were
often negated by the overheads introduced by the poor local
coherence.

c 2009 The Authors
Journal compilation c 2009 The Eurographics Association and Blackwell Publishing Ltd.

2160

B. Liu et al. / Fast Isosurface Rendering on a GPU by Cell Rasterization

cache locality (many fewer texture accesses in each pixel
shader) and better local coherence between multiple parallel
SIMD processors (we have similar ray lengths for all fragments, while raycasting may have very different ray lengths
for neighbouring fragments, especially when the isosurfaces
have many complex silhouettes).

6.2.2. Using on-the-fly normals
Figure 10: Comparison with GPU-based raycasting. The
3 rendered results are shown at the top, with their respective
close-up views below. The left and middle columns show the
results of raycasting with different sampling distance: 2 ×
S dist and S dist , respectively; our result is shown on the right.
The frame rates for the 3 images are 28.2fps, 14.3fps and
64.0fps, respectively. The data set used here is Vertebra, a
scan of arteries with a resolution of 2563 .
Our quality gain was achieved by using a sufficiently small
S dist , which is adaptively computed according to the projection diameter of the cell, and we can guarantee that all the
active cells are visited by the rays, so that no fine details
are missed. Our performance gain was achieved by a better

In this subsection, we amended the raycasting code from
[SSKE05] a little in order to use normals that are computed
on-the-fly by both our method and raycasting. We also applied the same binary search as ours to refine the raycasting
results after the first sign change (between two neighbouring
sampling points along the ray) has been found by raycasting.
The results are shown in Figure 12. Again, we can see that
when raycasting uses a shorter sampling distance S dist , its
rendering quality becomes closer to ours, but at the same
time, its rendering performance becomes much slower.

6.3. Discussion about z-buffer
An important issue in our accelerated rendering mode
(Section 4) is the z-values. Current graphics hardware will

Figure 11: Comparison with GPU-based raycasting. Left: Our results (whole image); Right: Close up views, in order from top
to bottom: raycasting with different sampling distance: 4 × S dist , 2 × S dist and S dist , respectively, and our method (the frame
rates are 22.8fps, 12.1fps, 6.22fps and 19.7fps, respectively). The data set used here is Angiography 512 which has resolution
512 × 512 × 256.
c 2009 The Authors
Journal compilation c 2009 The Eurographics Association and Blackwell Publishing Ltd.

B. Liu et al. / Fast Isosurface Rendering on a GPU by Cell Rasterization

2161

Figure 12: Comparison with GPU-based raycasting. The three rendered results are shown at the top, with their respective
close-up views below. The left and middle columns show the results of raycasting with different sampling distance: 5 × S dist
and S dist , respectively; our result is shown on the right. The frame rates for the three images are 20.1fps, 4.3fps and 72.8fps,
respectively. Note that our method missed fewest fine details (the very thin sheets behind the human head) but had the fastest
rendering speed. The data set used here is CTHead (with resolution resampled to 2563 ).
disable the early-z-culling feature when the rasterized z-value
is changed by the pixel shader, so in our accelerated rendering mode, the pixel shader does not output any z-values for
the fragment, hence the actual z-value in the final z-buffer is
obtained from the cell centre (via rasterization) rather than
from the actual intersection, as shown in Figure 13.
This presents no problem for rendering volume isosurfaces, and the images produced are identical with versions
in which the correct z-values are output in the pixel shader,
because the shading is always computed at the exact intersection rather than at the cell centre.
However, for applications such as hybrid rendering of volumetric isosurfaces with other polygonal geometries, where
exact z-values are needed in the z-buffer to achieve correct
surface interpenetrations, we shall output the actual z-values
of the intersection in the pixel shader (as in Section 3.2). To
do this, the early-z-culling feature will be disabled automatically by current hardware, and thus the rendering time will
be increased a little. One would hope that future graphics
hardware will overcome this constraint.

6.4. Limitations
The memory requirements of our method are the same as in
[DZTS08]: we need to store a 2D HistoPyramid texture and a
3D volume data texture. However, our current GPU (NVIDIA
8800 GTX) has only 768M bytes of video memory, which
is not enough to load very large volume data (currently, the
highest resolution our GPU can support is 512 × 512 × 512
if normals are computed on the fly; if we need to store the precomputed normals, the highest resolution will be 512 × 512
× 256, as shown in Figure 11). One solution to this limitation
would be to divide the larger data into bricks, and then handle
them separately. An alternative would be to adopt Multi-GPU
techniques [MMD08] [MO08], in which multiple GPUs and
one CPU are set up on a single system that allows texture
memory on multiple GPUs to be virtualized in a manner that
is both scalable and transparent to the programmer. Another
good news is that the latest GPUs already provide much
more video memory. For example, ATI Radeon HD4870X2,
NVIDIA Quadro FX5800 and NVIDIA Tesla S1070 already
provide 2, 4 and 16 GB video memory, respectively.

c 2009 The Authors
Journal compilation c 2009 The Eurographics Association and Blackwell Publishing Ltd.

2162

B. Liu et al. / Fast Isosurface Rendering on a GPU by Cell Rasterization

to gain a significant performance speed-up for complex isosurfaces. This sorting algorithm also achieves the rendering
of multiple transparent isosurfaces almost for free. Our algorithm does not require any geometry shaders and can be
implemented on DX9-compatible GPUs, and is suitable for
any graphics hardware with at least Shader Model 3 (SM3)
capabilities.
A very attractive feature of our algorithm is that it allows the rapid extraction and rendering of isosurfaces from
scratch, without the need for any pre-processing. The isovalues can also be changed interactively at runtime. Given
these benefits, the algorithm has great potential for use in the
exploration of fully dynamic volume data.
Figure 13: The z-value in the z-buffer. For a ray (in red)
originating from the camera P , P 1 and P2 are the calculated intersections between the ray and the blue coloured
isosurface, and C1 and C2 are the results of the rasterization (the z values that will be output into the z-buffer) for
cells A and B, respectively. This presents no problem for rendering the correct final image as shading is calculated at
the exact intersection, and correct hardware depth testing
between cells will ensure that C1 will be in front of C2. So
the z-buffer will finally store the z-value at C1, while the corresponding colour-buffer will store the shading result from
P1.
We only sort the cells in a slice-based order, but we do not
perform any sorting on cells in the same slice. For transparent
rendering, this is satisfactory when the volume resolution
is sufficiently high (relative to screen resolution) to avoid
much isosurface occlusion between the neighbouring cells
in the same slice. Otherwise, if the volume resolution is
low (that is, the part of the isosurface within a cell will be
projected on to a large screen area containing many pixels),
our transparent rendering will not be very accurate due to
some incorrect isosurface ordering within the same cell-slice.
This presents no problem for opaque isosurface rendering
since hardware depth testing can correctly handle this. For
transparent rendering, the solution would be to recursively
subdivide each low-resolution cell into eight subcells (by
trilinear interpolation) in order to produce a higher resolution
volume for improved rendering quality.
7. Conclusion and Future Work
We have presented a fast and high-quality isosurface rendering pipeline running on the GPU. The pipeline treats
each extracted active cell as a single rendering primitive,
and exploits our vertex program and fragment program to
achieve isosurface rendering. The pipeline has a better local
coherence than previous raycasting methods and can produce
smoother images than both Marching Cubes and raycasting
techniques.
We have also proposed a new view-dependent sorting algorithm, so that hardware early-z-culling can be exploited

However, our method does have the limitation that it requires the volume data set to be retained in video memory.
Some recent methods have adopted a multiresolution LOD
approach [GMI08] [Lju06], which adaptively selects some
coarser levels of the original out-of-core data so that it can
be loaded entirely into video memory (depending upon the
GPU memory limit) for approximate rendering. For large
data sets, this can utilize the speed of GPU processing to
deliver lower-resolution rendering much more rapidly than
CPU-based full-resolution processing, which is useful in
some contexts. However, pre-processing is required to build
the LOD structures, which makes it unsuitable for use with
dynamic volume data.
In future work, we shall consider the application of the
cell-rasterizing pipeline to direct volume rendering and outof-core data visualization. We shall also consider how to
implement and accelerate the analytic cubic polynomial root
solution to provide higher quality ray-cell intersection.

Acknowledgements
We would like to thank Dr. Christopher Dyken for the valuable discussion and for generously providing us with his
code and data. We would also like to thank Stegmaier et al.
[SSKE05] for making their raycasting code available. Both
of these were instrumental in enabling us to perform comparisons under the same conditions as for our algorithm.
We thank the anonymous reviewers for their help, suggestions and review of this work.
In addition, we thank those scientists who provide and curate data on which researchers can experiment. We greatly
appreciate the valuable service that this renders to the
community. In this paper, in addition to the above, we
used data from the Stanford volume data archive and from
http://www.volvis.org/.
This work was partially supported by the Aneurist project
(IST-2004-027703), funded by the European Commission
under the IST Programme of FP6.

c 2009 The Authors
Journal compilation c 2009 The Eurographics Association and Blackwell Publishing Ltd.

B. Liu et al. / Fast Isosurface Rendering on a GPU by Cell Rasterization

2163

techniques for iso-surface ray tracing. In VMV04 (2004),
pp. 429–435.

References
[CHJ03] CO C., HAMANN B., JOY K.: Iso-splatting: A
point-based alternative to isosurface visualization. In Proceedings of the 11th Pacific Conf. on Computer Graphics and Applications—Pacific Graphics 2003 (2003),
pp. 325–334.

[MMD08] MARCHESIN S., MONGENET C., DISCHLER J.-M.:
Multi-GPU sort-last volume visualization. In EG Symposium on Parallel Graphics and Visualization (EGPGV’08)
(2008), pp. 1–8.

[DZTS08] DYKEN C., ZIEGLER G., THEOBALT C., SEIDEL
H.-P.: High-speed marching cubes using histopyramids.
Computer Graphics Forum 27, 8 (Dec. 2008), 2028–2039.

[MO08] MOERSCHELL A., OWENS J. D.: Distributed texture
memory in a multi-GPU environment. Computer Graphics
Forum 27, 1 (Mar. 2008), 130–151.

[Eve01] EVERITT C.: Interactive Order-Independent
Transparency. Research report, NVIDIA Corporation,
2001.

[POC05] POLICARPO F., OLIVEIRA M., COMBA J.: Realtime relief mapping on arbitrary polygonal surfaces.
ACM Transactions on Graphics 24, 3 (2005),
935–935.

[GM03] GEIMER M., MULLER S.: A cross-platform framework for interactive ray tracing. In Tagungsband Graphiktag der Gesellschaft f¨ur Informatik (2003), pp. 25–34.
[GMI08] GOBBETTI E., MARTON F., IGLESIAS GUITIA´ N J.: A
single-pass GPU raycasting framework for interactive outof-core rendering of massive volumetric datasets. The Visual Computer 24, 7–9 (2008), 797–806.
[HQK05]
HONG W., QIU F., KAUFMAN A.: GPU-based
object-order ray-casting for large datasets. In Volume
Graphics 2005 (2005), pp. 177–185.
[HSS∗ 05] HADWIGER M., SIGG C., SCHARSACH H., BUHLER
K., GROSS M.: Real-time ray-casting and advanced shading
of discrete isosurfaces. Computer Graphics Forum 24, 3
(2005), 303–312.
[KOR08] KLOETZLI J., OLANO M., RHEINGANS P.: Interactive volume isosurface rendering using BT volumes. In
SIGGRAPH I3D 2008 (2008), pp. 45–52.
[KW05]
KIPFER P., WESTERMANN R.: GPU construction and transparent rendering of iso-surfaces. In
VMV05 (2005), Greiner G., Hornegger J., Niemann H.,
Stamminger M. (Eds.), IOS Press, infix, pp. 241–248.

[SI05] SANDER P. V., ISIDORO J.: Explicit early-z culling
and dynamic flow control on graphics hardware. In ACM
SIGGRAPH 2005 Course 37 Notes, GPU Shading and
Rendering. 2005.
[SSKE05] STEGMAIER S., STRENGERT M., KLEIN T., ERTL
T.: A simple and flexible volume rendering framework for
graphics-hardware-based raycasting. In Volume Graphics
2005 (2005), pp. 187–195.
[The02] THEISEL H.: Exact isosurfaces for marching
cubes. Computer Graphics Forum 21, 1 (2002), 19–
31.
[ZK06] ZHANG H., KAUFMAN A.: Interactive point-based
isosurface exploration and high-quality rendering. IEEE
Transactions on Visualization and Computer Graphics 12,
5 (2006), 1267–1274.
[ZTTS06] ZIEGLER G., TEVS A., THEOBALT C., SEIDEL H.P.: On-the-fly point clouds through histogram pyramids.
In VMV06 (2006), pp. 137–144.

Appendix: The HistoPyramid Algorithm
[LC87] LORENSEN W. E., CLINE H. E.: Marching cubes:
A high resolution 3d surface construction algorithm.
SIGGRAPH Computer Graphics 21, 4 (1987), 163–
169.
[Lju06] LJUNG P.: Adaptive sampling in single pass GPUbased raycasting of multiresolution volumes. In Volume
Graphics 2006 (2006), pp. 39–46.
[LNM06] LEUNG W., NEOPHYTOU N., MUELLER K.: SIMDaware raycasting. In Volume Graphics 2006 (2006),
pp. 59–62.
MARMITT G., KLEER A., WALD I., FRIEDRICH
[MKW∗ 04]
H., SLUSALLEK P.: Fast and accurate ray-voxel intersection

Since we use the HistoPyramid algorithm [ZTTS06] to extract all the active cells, here we make a simple review of
this algorithm and its data structure. The basic input for this
algorithm is regularly sampled scalar volume data, and the
output is a list of all the active cells, in quad-tree order.
This algorithm first creates, as input, a large tiled 2D texture in which each tile corresponds to a slice of the 3D volume
data. This structure is known as a Flat 3D layout. From this
it builds the HistoPyramid texture, a pyramid-like data structure very similar to a texture MipMap (a stack of 2D textures).
The pyramid-like 2D texture stack is built in a bottom-up,
layer-by-layer fashion. Each texel in the bottom level has a
bool value (0 or 1) representing whether the cell is active

c 2009 The Authors
Journal compilation c 2009 The Eurographics Association and Blackwell Publishing Ltd.

2164

B. Liu et al. / Fast Isosurface Rendering on a GPU by Cell Rasterization

Figure A1: HistoPyramid building process (image courtesy
of Ziegler et al. [ZTTS06]). While generating the next pyramid level, the GPU sums four adjacent cells into one, thereby
halving resolution, until only one cell remains.

or not (depending upon a comparison of the isovalue with
the scalar values associated with each of its eight corners).
Each texel in an upper level is assigned the sum of the four
corresponding elements in the level immediately below. The
example in Figure A1 shows this building process.
After the HistoPyramid is built, all the active cells can be
retrieved by traversing the HistoPyramid using the index of
each cell, as we did in Section 3.1. If there are N active cells,

Figure A2: HistoPyramid traversal process for an example
key index (image courtesy of Ziegler et al. [ZTTS06]).
their indices will be a list of integer values [0, 1, 2, . . . , N-1],
which will be used as vertex attribute to trigger the GPU
rendering. The example in Figure A2 shows this traversal
process.

c 2009 The Authors
Journal compilation c 2009 The Eurographics Association and Blackwell Publishing Ltd.

