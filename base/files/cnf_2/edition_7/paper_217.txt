DOI: 10.1111/j.1467-8659.2009.01432.x

COMPUTER GRAPHICS

forum

Volume 28 (2009), number 8 pp. 2189–2200

g-BRDFs: An Intuitive and Editable BTF Representation
N. Menzel and M. Guthe
FB Grafikprogrammierung und Multimedia, Fachbereich Mathematik & Informatik, Philipps-Universit¨at Marburg,
Marburg, Germany

Abstract
Measured reflection data such as the bidirectional texture function (BTF) represent spatial variation under the full
hemisphere of view and light directions and offer a very realistic visual appearance. Despite its high-dimensional
nature, recent compression techniques allow rendering of BTFs in real time. Nevertheless, a still unsolved problem
is that there is no representation suited for real-time rendering that can be used by designers to modify the BTF’s
appearance. For intuitive editing, a set of low-dimensional comprehensible parameters, stored as scalars, colour
values or texture maps, is required. In this paper we present a novel way to represent BTF data by introducing
the geometric BRDF (g-BRDF), which describes both the underlying meso- and micro-scale structure in a very
compact way. Both are stored in texture maps with only a few additional scalar parameters that can all be
modified at runtime and thus give the designer full control over the material’s appearance in the final real-time
application. The g-BRDF does not only allow intuitive editing, but also reduces the measured data into a small set
of textures, yielding a very effective compression method. In contrast to common material representation combining
heightfields and BRDFs, our g-BRDF is physically based and derived from direct measurement, thus representing
real-world surface appearance. In addition, we propose an algorithm for fully automatic decomposition of a given
measured BTF into the g-BRDF representation.
Keywords: editable BTF, BRDF acquisition, material representation, real-time BTF rendering, BTF
decomposition
ACM CCS: Categories and Subject Descriptors (according to ACM CCS): I.3.7 [Computer Graphics]: Colour,
Shading, Shadowing, and Texture I.4.8 [Computer Vision]: Shading.

1. Introduction
In general, surface appearance is determined by either reflectance (coarse-scale) or texture (fine-scale). When view
and light directions vary, the equivalent descriptions are the
BRDF and the BTF. At a given point on a surface the 4D
(four-dimensional) BRDF is a function of light and view direction whose characteristics determine the appearance of
the surface and are defined either empirically or by direct
measurement. In the latter case, it is necessary to tabulate
the BRDF into a discrete set of samples. In this process high
frequency details are often neglected due to poor sampling
and/or compression.
The 6D BTF as introduced by Dana et al. [DvGNK99]
captures the variance of textures with view and light direction and is able to provide photo-realistic surfaces. The BTF
can be understood as a simultaneous measurement of perpixel BRDFs, called apparent BRDFs (ABRDFs) as they
c 2009 The Authors
Journal compilation c 2009 The Eurographics Association and
Blackwell Publishing Ltd. Published by Blackwell Publishing,
9600 Garsington Road, Oxford OX4 2DQ, UK and 350 Main
Street, Malden, MA 02148, USA.

also contain effects of the underlying meso-scale geometry
and represent the reflectance fields of single pixel. As such, a
BTF accommodates self-shadowing, inter-reflection, masking and parallax effects of a complex material without explicit
representation of the small-scale geometry. Currently, there
are two major reasons speaking against BTFs as a common
modelling resource: first, acquisition systems are expensive
and the measurement process lasts from several hours to
days, and second, the size of a BTF is in the range of several gigabytes, so effective compression methods have to be
applied before synthesis or rendering [MMS∗ 05].
Recently, much effort was spent on developing efficient
compression methods for BRDFs and BTFs. With these at
hand, sample databases containing gigabytes of input images
can be reduced to a fraction of their original size, preserving
most of the original visual appearance. Many of these methods follow a similar approach. They reduce high-dimensional
input data to low-dimensional subspaces containing most of

2189

2190

N. Menzel and M. Guthe / g-BRDFs

and BRDFs is not new to artists, our particular contribution
is that we propose an algorithm to extract the meso-scale
structure and analytical BRDFs from measured BTFs. This
means that we describe physical properties of a real-world
surface instead of a hand-generated texture. This does not
only allow to efficiently compress a BTF and render it in
real-time, but also to use measured data as basis for artistic
editing of a real-world material.
2. Related Work

Figure 1: Rendering of a BTF from its g-BRDF
representation.
the variation. Resulting eigenvectors can be stored in ordinary texture maps and the BTF can be rendered in real time.
Nevertheless, BTFs are still far from being used as common modelling resource like texture maps, one reason being
that compressed data offers very little expressiveness to designers. Although user-guided modification and editing of
raw BTFs have become possible, in existing systems a BTF
needs to be compressed for real-time rendering, which again
requires several hours The solution to this problem would
be a method that breaks a BTF down into comprehensible
properties and then use these for rendering as well as for
editing. This would not only enable designers to modify or
combine BTFs to create novel materials, but also yield a
very efficient compression, as some properties have little
contribution to the final appearance and only the most visible ones are required to describe a BTF’s appearance under
varying light and view directions. The reason why we need
all the BTF information is that real-world surfaces comprise
extremely complex light interaction which physically based
BRDFs describe at micro-scale without considering geometric variations at meso-scale. Because these are contained
in almost every BTF, a BTF cannot be treated as spatially
varying BRDF, because light interaction is closely related to
geometry and thus not locally bound.
The contribution of this paper is hence an intuitive representation for both meso- and micro-scale properties of a
BTF as shown in Figure 1. By separating these two scales, an
artist can use BRDF-editing techniques together with geometric editing to modify an existing BTF or to create a novel
one from scratch. Whereas the combination of heightfield

In rendering, there are many types of BRDF models, which
can be categorized into three classes: empirical models, datadriven models and physical models. One of the first empirical but physically not plausible BRDF models was introduced by Phong [Pho75]. Later a physically correct model
was introduced by Ward [War92]. Data-driven models are
based on real-world measurements and construct a representation using orthogonal basis functions. Kautz and McCool
[KM99] represent a BRDF as sum of separable functions
where each of the functions can be stored as texture map and
rendered in real time. The focus of this paper lies on physically based BRDF models as introduced by Torrance and
Sparrow [TS67]. Approaches of micro-facet-based models
have been generalized to arbitrary facet distribution by the
micro-facet BRDF generator [APS00] that was used to approximate measured BRDFs [NDM05]. Later, Ashikhmin
proposed the d-BRDF model [Ash06] which has a simplified
shadowing and masking term and was used for BRDF acquisition by Ghosh and Heidrich [GH07]. Instead of discrete
functions, Lafortune et al. [LFTG97] fit measured BRDFs
analytically using multiple cosine-lobes, resulting in a very
compact representation.
BTFs were introduced by Dana et al. [DvGNK99] and a
comprehensive overview of acquisition, synthesis and rendering is given by M¨uller et al. [MMS∗ 05]. Much effort has
been spent in the field of BTF compression, mostly based
on statistical compression. Suykens et al. [SvBLD03] treat a
BTF as a set of spatially varying apparent BRDFs and introduce the chained matrix factorization. Resulting factors can
be stored as ordinary texture maps and rendered on consumer
hardware. M¨uller et al. [MMK03] took a similar approach
but used local principal component analysis to compress
the apparent BRDFs, whereas Liu et al. [LHZ∗ 04] perform
singular-value decomposition of the whole BTF dataset.
In addition to compression, some work has been conducted
on measuring or extracting the meso-scale geometry of BTFs.
Lensch et al. [LKG∗ 01] present a robust fitting algorithm of
BRDFs to spatially varying materials, which does not include
inter-reflections or self-shadowing.
Magda and Kriegman proposed to decompose a BTF into
a set of semitransparent layers [MK06] to encode the mesostructure. While this approach has the advantage that complex structure can be modelled, the micro-structure is stored

c 2009 The Authors
Journal compilation c 2009 The Eurographics Association and Blackwell Publishing Ltd.

N. Menzel and M. Guthe / g-BRDFs

volumetrically and thus can hardly be edited intuitively. Another drawback is the limited depth resolution resulting in
rather strong shearing artefacts at grazing angles. Wang et al.
[WTS∗ 05] proposed a method to directly capture the mesogeometry of a BTF and store it as 4D distance field, allowing
for correctly shaped silhouettes. M¨uller et al. [MSK06] extract a normal and tangent map and use them to better align
the ABRDFs with a data-driven local coordinate system.
The Meso-structure can also be obtained from specularity
maps [CGS06] or using the so-called Helmhotz stereopsis
[ZBK02] where the structure and normals are estimated by
exploiting the Helmholtz reciprocity. Pairs of light source
and camera positions are chosen that guarantee that the ratio
of the emitted radiance to the incident irradiance is the same
for corresponding points in two images. The advantage is
that no assumptions about the underlying BRDF have to be
made, but the resulting depth maps show strong artefacts for
uniform materials.
None of the methods discussed so far consider the aspect
of editing BTF data. The non-parametric inverse shade tree
[LBAD∗ 06] contains one- or two-dimensional material representation at leaf level. These low-dimensional materials
can be edited, but the method is restricted to flat materials that can be described by a few BRDFs only. Pellacini
et al. [PL07] present an approach for editing spatially- and
temporally-varying BRDFs that adopt a stroke-based workflow. Efficient solvers are used to allow interactive refinement of this appearance-driven optimization, but there is
no straightforward extension to BTF editing. Kautz et al.
[KBD07] proposed an out-of-core data management for editing raw data of an entire BTF. They developed sophisticated
operators to edit shadows, specularity, meso-structure and a
method to build a selection tree in order to represent distinct
materials. The main drawback of this approach is that if the
meso-geometry is changed, affected features – for example
shadows – do not change accordingly. While interactive editing of a BTF is possible and took about 10–15 minutes for
the examples they used, the compression required for realtime rendering takes several hours. M¨uller et al. [MSK07]
developed a technique for procedural editing of BTFs. They
are able to alter or replace the original meso-structure using
procedural models and generate a new BTF using constraint
synthesis. Their main benefit is that the whole complexity
of shadowing and light transport is preserved. Unfortunately,
the system is restricted to previously acquired materials and
the BTF has to be recompressed before rendering.
The idea of representing materials as combination of
heightfield and BRDFs is not novel: one of the first approaches to model meso-scale geometry was bump mapping
[Bli78], which simulates small-scale variation of surfaces by
shifting normals into tangent and bitangent directions. Normal maps can also be directly created from meshes and stored
per pixel [COM98] to improve the visual quality of a simplified mesh. Parallax mapping is an enhancement of bump
mapping where per-pixel depth information is stored in a

2191

Figure 2: Meso-structure maps: depth (left) and orientation
(right).
texture. The surface is displaced accordingly per pixel which
provides more realism for bumpy surfaces and can further be
improved by adding soft shadows in real time [Tat06].
3. The g-BRDF Representation
To ensure both compression and editability, a BTF is best represented by a set of 2D images describing either light interaction or the geometric structure of the underlying surface. We
therefore define two distinct classes: light interaction maps
and geometry maps.
The meso-scale geometry is represented by a depth map
and two scalar values, defining minimum and maximum
depth offsets. In this form, the geometry can easily be modified by just increasing or decreasing pixels or whole areas.
For more complicated operations up to generating a complete
depth map from scratch, a variety of existing tools that have
been developed to create depth maps for 3D computer games
can be used. These tools range from procedural texture generation to modelling systems that can output the depth map
from a 3D model instead of a rendered image. An additional
normal map is not required, because it can be derived from
the depth map with the advantage that a designer does not
need to take care of consistency between the two. The only
remaining degree of freedom for the local coordinate system
is a rotation about the normal which is encoded in the orientation (or tangent) map, which is required for anisotropic
BRDFs. There, each pixel stores the direction of the tangent
vector encoded as hue of the HLS colour model, although
any other coding would be possible as well. While this second texture map might not seem very intuitive at first sight,
designers quickly get used to it and are able to achieve the
desired results. Figure 2 shows an example of depth and
orientation maps.
While the meso-scale geometry is completely represented
by these two images, the number of parameters required to
describe the micro-structure is significantly higher in order
to preserve the visual appearance. Because it is impossible
to completely define the light interaction for each texel, both
from a designers point of view, as well as considering the
required storage amount, we divide the BTF into a set of

c 2009 The Authors
Journal compilation c 2009 The Eurographics Association and Blackwell Publishing Ltd.

2192

N. Menzel and M. Guthe / g-BRDFs

Figure 3: Micro-structure maps (from left to right): diffuse,
Fresnel, cluster and NDF maps.

a few distinct basis materials. Each basis material can be
represented by an arbitrary BRDF model, where some lowdimensional parameters – such as the diffuse colour – are
stored per texel to allow for more variation.

Figure 4: Rendering workflow: (a) the parallax occlusion
mapping determines (u, v) texture coordinates; (b) (u, v) are
used to index the rotation map and (c) local light and view
are used to calculate the BRDF.

4. Rendering
3.1. BRDF model
So far, we have separated geometry from light interaction
and thus each material can be represented by a BRDF ρ
(k 1 , k 2 ) that describes what fraction of light coming from a
given direction k 1 is reflected into another direction k 2 . The
choice of an appropriate BRDF model is important because
the complexity of the underlying model determines how easily each basis material can be edited. The more accurate (and
thus more complex) a BRDF model is, the harder it becomes
to achieve a desired appearance by changing its properties.
Therefore, we chose Ashikhmin’s distribution-based BRDF
[Ash06] as it is an excellent trade-off between accuracy and
intuition. There the BRDF is defined as follows:
ρ(k1 , k2 ) =

cd
cs p(h)F (k1 h)
+
,
π
k1 n + k2 n − (k1 n)(k2 n)

(1)

where the normal distribution function (NDF) p(h) is an arbitrary anisotropic function that describes the normal distribution of the BRDFs underlying micro-structure and the halfvector h is the normalized average of k 1 and k 2 . The NDF is
stored in a texture using the parabolic maps parametrization
[HS98] which is simple to calculate and has a relatively uniform sampling of the hemisphere, but any other parametrization could be used as well.
For the Fresnel term, Schlick’s approximation is used:
F (k1 h) ≈ r0 + (1 − r0 )(1 − k1 h)5 ,

(2)

where the only free parameter, the reflectance at normal incidence r 0 , depends on the refraction index of the material.
Due to the complexity of the NDF, only a single one is
stored per basis material. The other two parameters cd and
r 0 are low-dimensional and thus allowed to change per texel.
This way, a compact editable representation is combined with
the possibility to introduce per-texel variation by modulating
the diffuse colour and the specular reflection. Figure 3 shows
an example of the complete set of images defining the microstructure of a BTF.

Although it is possible to use the proposed g-BRDF representation directly for rendering, a few modifications can improve
the performance. Grouping of textures can save texture units
and texture fetches; preprocessing is applied if possible in
order to save shader instructions. The grouping and preprocessing require a few milliseconds per BTF only and could
even be integrated as additional shader pass operating on
intermediate textures. The surface normals are precomputed
by discrete derivation of the depth map using the 2D Sobelfilter [GW87]. The x- and y-components of the normals are
stored in the red and blue colour channels of a 2D texture.
The z-component is redundant as it can be calculated with
√
z = 1 − x − y. To rotate k 1 and k 2 into the local coordinate system, the sine and cosine of the tangent angles are
precomputed and stored in the remaining two components of
the rotation texture. This saves their costly computation at
run-time and avoids discontinuities between 0 and 2π during
interpolation. The cluster indices are originally stored in an
indexed colour map, which has the drawback of not being
suited for bilinear interpolation. For this reason, we combine
every four materials into a weight texture where each channel contains the weight for one material. The monochrome
Fresnel map is combined with the diffuse map into a single
RGBA texture and finally, all NDFs are aggregated into a 3D
texture, where the third dimension is equal to the number of
distinct materials. This does not only reduce the number of
required texture units, but also the number of texture fetches
since the interpolated probability between two adjacent
NDFs can be obtained with a single texture fetch. Figure 4
shows an overview of the textures and the overall workflow
of the rendering algorithm.
The most time-consuming part of the rendering algorithm
is the mapping of screen pixels onto the meso-geometry.
For this step, we use the parallax occlusion mapping (POM)
[Tat06] which essentially is a per-pixel ray-tracing algorithm
that is able to resolve inter-penetrations and self-occlusion in
real time. In addition to the view ray, a shadow ray is traced
toward the light source to generate self-shadowing effects.

c 2009 The Authors
Journal compilation c 2009 The Eurographics Association and Blackwell Publishing Ltd.

2193

N. Menzel and M. Guthe / g-BRDFs

can produce reasonable reconstructions. Assuming that the
meso-structure is locally planar, the cosine factor can be cancelled out by matching the local neighbourhood of a point
with the normalized cross-correlation of the log-scale radiance between Lr (k 1 , k 2 ) and Lr (k 2 , k 1 ). The similarity S at
point x is then
S(x) =
k1 ,k2

u(x, k1 , k2 ) · u(x, k2 , k1 )
,
u(x, k1 , k2 ) u(x, k2 , k1 )

(5)

Figure 5: Basic structure of g-BRDF pixel shader.
Finally, the BRDF can be evaluated using the local coordinate
system (Figure 5).
5. BTF Decomposition
Because there is already a substantial amount of measured
BTF data available, an algorithm to decompose these measured BTFs into a corresponding g-BRDF is desirable to use
them as basis for editing and combine them with other gBRDFs in a real-time application. This decomposition needs
to be split into two phases because before each texel of the
BTF can be approximated with the BRDF model, the mesostructure has to be recovered in order to establish correct
surface point correspondences.
5.1. Meso-structure reconstruction
A surface to be generated by a 3D reconstruction algorithm
is typically defined to minimize some error functional. For
a measured BTF, we can derive such functionals from the
physical properties of BRDFs, namely Helmholtz reciprocity
and lambertian law of cosines:
ρ(k1 , k2 ) = ρ(k2 , k1 ),

where u (x, k 1 , k 2 ) is the log-mapped and mean-removed
neighbourhood of x projected into the input image (k 1 , k 2 )
written as a column vector:
ui (x, k1 , k2 ) = log L(pi (x), k1 , k2 ) − L¯ log (x, k1 , k2 ), (6)
with L¯ log (x, k1 , k2 ) being the mean log-radiance of the neighbourhood p i (x) of x in input image (k 1 , k 2 ).
A consistent depth reconstruction for the whole BTF is
obtained using graph-cut stereo [RC98]. For a set of discrete
depth values, the similarity is calculated per texel and a 3D
graph is constructed where each texel in every layer is connected to its eight neighbours and to itself in the next and
previous layer. The weight of the edges corresponds to the
sum of the similarity of both nodes, where vertical connections are weighted with a smoothness factor k. The minimal
cut separating top and bottom layers then yields a reasonable
approximation of the parallax and approximately solves the
point correspondence problem.
The local normal at x now minimizes the difference between ρ(k 1 , k 2 ) and ρ(k 2 , k 1 ). Because radiance values are
exponentially distributed, ρ is again transformed into logspace:
E(x) =

(3)

v(x, k1 , k2 ) log
k1 ,k2

Lr (k1 , k2 ) = ρ(k1 , k2 )(k1 n)Li ,

(4)

where Li is the irradiance which is constant for all k 1 , k 2 .
Note, that most BTFs that are stored as regular images in a
database also do not contain linear luminance so these have
to be converted into linear values with an inverse gamma
correction before a reconstruction.
In addition to parallax effects, the meso-structure also influences the local surface normal. Therefore, the BRDFs cannot be directly extracted from the input images that only
contain the reflected radiance Lr (k 1 , k 2 ), nor can the reciprocity be used as error functional alone. These properties are
also the basis for the Helmholtz stereopsis [ZBK02] where
the depth is defined such that the difference to a reciprocal
BRDF with unknown normal is minimized. While this works
well for materials with texture – that is, per pixel colour variation – no depth values can be reconstructed for uniform
materials. For such surfaces only global optimization methods taking into account the local neighbourhood of the point

ρ(x, k1 , k2 )
ρ(x, k2 , k1 )

2

,

(7)

with
ρ(x, ki , kj ) =

L(x, ki , kj )
,
ki n(x)

(8)

where v(x, k 1 , k 2 ) is one if x is visible from both k 1 and k 2 ,
and zero otherwise. The optimal local normal n at x is found
using Levenberg-Marquardt optimization [Lou04]. Convergence to a local minimum – a common problem when solving
nonlinear equation systems – cannot occur because the error functional has only a single minimum. Also, LevenbergMarquardt has the fastest convergence rate. Finally, depth
values and normals are combined using the method of Nehab
et al. [NRDR05]. Due to the normal reconstruction from the
reciprocity, a global normal shift cannot occur and thus we
skip the normal correction and only optimize the depth values with the extracted normals. However, as the normal map
is not an integral part of the representation, new normals are
calculated from the depth map as described in Section 4 for
the subsequent decomposition steps.

c 2009 The Authors
Journal compilation c 2009 The Eurographics Association and Blackwell Publishing Ltd.

2194

N. Menzel and M. Guthe / g-BRDFs

where

5.2. Estimation of the BRDF parameters
When the meso-structure is fixed, the micro-structure can be
reconstructed per surface point by mapping the input images
onto the generated heightfield and transforming the light and
view directions into the local coordinate systems. Note that
this transformation also includes the removal of occluded
and shadowed samples because they are specifically handled
within the parallax occlusion mapping algorithm. Using the
d-BRDF model with Schlick’s Fresnel approximation, three
parameters need to be determined: the diffuse colour cd , the
NDF p(h) and the reflectance at normal incidence r 0 . As each
of these can be calculated analytically if the other two are
known, we use the alternating least squares method, starting
with cd , to find all of them.
Solving Equation 1 for the diffuse colour yields the following equation for a least square fit of the RGB-colour cd :

λs (k1 , k2 ) =

cd =

(9)

where

k1 ,k2

(λf (k1 , k2 ))2

,

(18)

k1 ,k2

δf (k1 , k2 ) =
Lr (k1 , k2 )
cs p(h)F (kh)(k1 n)
−
Li
k1 n + k2 n − (k1 n)(k2 n)

(10)

Lr (k1 , k2 )
cd
+ cs p(h)(1 − kh)5 ins,
−
Li
π
(19)

λf (k1 , k2 ) = (1 − (1 − kh)5 )cs p(h(k1 n)),

k1 n
,
λd (k1 , k2 ) =
π

(20)

(11)

with the constraint that no colour channel can be below zero
or above one due to energy conservation. The normal distribution p(h) is extracted similar to [NDM05] where the least
squares fit is
λp (k1 , k2 )δp (k1 , k2 )
p(hi ) =

(17)

where

k1 ,k2

δd (k1 , k2 ) =

p(h)F (kh)(k1 n)
.
k1 n + k2 n − (k1 n)(k2 n)

λf (k1 , k2 )δf (k1 , k2 )
r0 =

,

λd (k1 , k2 )2

(16)

Energy conservation is enforced for the NDF in three steps:
first, the probability for any halfway vector cannot be larger
than the reciprocal of its differential area; second, the sum of
all probabilities (i.e. the integral over the hemisphere) cannot
exceed one; and third, cs is restricted to at most 1 − cd .
Finally, the reflectance at normal incidence r 0 (Equation 2)
is calculated based on the current estimates for cd and p(h):

λd (k1 , k2 )δd (k1 , k2 )
k1 ,k2

Lr (k1 , k2 ) cd
− ,
Li
π

δs (k1 , k2 ) =

k1 +k2 =hi

,

(λp (k1 , k2 ))2

(12)

Up to now, the BRDF approximation process minimizes
the root mean square error, whereas radiance values are exponentially distributed and thus the logarithmic error needs
to be minimized. This can be accomplished by weighting
the contribution of each radiance value Lr (k 1 , k 2 ) with the
derivative of the logarithmic mapping function during summation of the λ’s and δ’s, which simply is the reciprocal of
the radiance.

k1 +k2 =hi

with

5.3. Clustering
Lr (k1 , k2 ) cd
−
Li
π

(13)

cs F (kh)(k1 n)
k1 n + k2 n − (k1 n)(k2 n)

(14)

δp (k1 , k2 ) =

λp (k1 , k2 ) =

From the probability for discrete halfway vectors h i , the
parabolic map over the upper hemisphere is calculated using the push-pull algorithm [GGSC96]. Then, the specular
intensity is extracted with
λs (k1 , k2 )δs (k1 , k2 )
cs =

k1 ,k2

λs (k1 , k2 )2
k1 ,k2

,

(15)

To combine the independent per-texel BRDFs into n basis materials, we need to find those texels that have similar
micro-facet distributions. As the local normal is fixed, the
only remaining degree of freedom is the rotation about the
normal. When the NDF is parameterized over spherical coordinates (θ, φ), the rotation becomes a shift in φ and the offset
can efficiently be found utilizing the Fourier shift theorem:
let F and G be the Fourier transformations of the NDFs f and
g. Then, the maximum of the inversely transformed function
¯ lies at (0, φ 0 ) with φ 0 being the rotation beh of H = F G
tween f and g. Based on this pairwise alignment, a k-means
clustering of NDFs is performed by aligning each NDF to
the cluster centre before distance calculation and summation.
The rotation about the normals to the cluster centres is then
equivalent to the orientation map of the g-BRDF.

c 2009 The Authors
Journal compilation c 2009 The Eurographics Association and Blackwell Publishing Ltd.

2195

N. Menzel and M. Guthe / g-BRDFs

As the clustering operates on each texel independently,
the boundaries between different base material tend to become noisy. To reduce this boundary noise, an additional
relaxation labelling [Gen89] is performed after clustering.
We define the probability of an NDF to belong to a cluster
as the reciprocal of the distance between the two and normalize the total probability of each NDF to one. Then, we
perform the relaxation labelling that pulls the probabilities of
each NDF into the direction of those of its neighbours. The
required number of clusters is automatically determined by
calculating the separation index SI(n) for all possible number
of clusters n up to a given maximum and choosing the one
for which SI(n) is minimal. The separation index is defined
as the ratio of the root mean square difference between the
per-texel NDFs and their corresponding cluster centres to the
minimum difference between two cluster centres. Finally,
the BRDF parameters are estimated for the complete BTF
as described above, where the NDF pi (h) is calculated per
cluster i and cd (x) and r 0 (x) per texel.

Table 1: Root mean square CIELab E 00 colour difference in JND
for different BTFs.

Material
Corduroy
Impalla
Proposte
Wallpaper
Wool

g-BRDF (1.5 MB)

[MMK03] (17MB)

10.09 JND
12.24 JND
12.41 JND
5.87 JND
8.94 JND

5.98 JND
6.70 JND
7.06 JND
5.02 JND
5.36 JND

6. Results
For the BTF decomposition we used several BTFs from a
publicly available database [SSK03]. These measured BTFs
have the advantage that the sample set is dense and spatially registered, that is. the directions of incoming and outgoing light as well as camera parameters are known for
each image. Other measured BTFs, such as the pioneering
CUReT database [DvGNK99], are unfortunately very sparse
and not spatially registered such that they cannot be used
without prior resampling. Another drawback of the CUReT
database is that it contains some graphical errors, caused by
frame-grabber artefacts or reflections of the robot sample
holder plate visible in the raw data. Similarly, the database
of Koudelka et al. [KMBK03] lacks reciprocal image pairs
and would also require resampling.
The decomposition process needs approximately 3 hours
for a 2562 × 812 BTF on an Intel Core 2 Duo running at
2.4 GHz and the runtime is linear in the number of pixels
contained in the dataset. We achieved the best results using
the following constants for decomposition: irradiance Li = 3,
cross-correlation window size 5 × 5, graph-cut smoothness
k = 0.1 and depth weight λ = 0.2. The root mean square
(RMS) difference of the decomposed BTF to the original one
is six to twelve times the just noticeable difference (JND) in
the CIELab colour space according to the E 00 difference
formula. This is slightly higher than for the currently best
compression algorithm [MMK03] with an error of 5–7 JND
(see Table 1), but they need 17 MB texture memory while
the g-BRDF requires 1.5 MB only.
For comparison of depth map reconstruction quality, we
implemented the algorithms of [RC98] and [ZBK02] as
shown in Figure 6. The NCC does not clearly separate between the two different height layers of the shown BTF.

Figure 6: Depth maps created with normalized crosscorrelation, Helmholtz stereopsis and our approach (left to
right); depth maps after global optimization (bottom row).

Helmholtz stereopsis performs better, but still produces some
artefacts and lack of detail without optimization.
The resulting g-BRDF textures for the six 2562 × 812 BTFs
from the database are shown in Figures 7–9 along with renderings from the compressed representation. Approximately,
90% of the total rendering time is required for the two trace
functions of the parallax occlusion mapping [Tat06]. Therefore, the overall performance is similar to parallax occlusion
mapping rendering alone which achieves about 200 fps on
current graphics hardware at full screen coverage on a 1280 ×
1024 display. In addition, we visually compare the results
with images generated from the uncompressed BTF data. On
the right side of Figures 7–9 a closeup is shown (top) in comparison to using the original BTF data. Below, a difference
image calculated in CIELab colour space and exaggerated
by a factor of two is shown to depict the visual difference.
The main difference to the captured BTF data lies in
shadow regions, especially for the impalla BTF (Figure 7
bottom) due to the missing scattering. However, the image
generated from the uncompressed impalla BTF exhibits significant blurring due to the naive image-based interpolation.
For almost all BTFs, there is some chromatic difference –
especially for corduroy (Figure 7 top) and wool (Figure 9
bottom) – because micro-facet models cannot model colour

c 2009 The Authors
Journal compilation c 2009 The Eurographics Association and Blackwell Publishing Ltd.

2196

N. Menzel and M. Guthe / g-BRDFs

Figure 7: Rendering of the corduroy (top) and impalla (bottom) BTFs from their g-BRDF representation shown on the
insets. On the right a closeup is compared to renderings from
the original BTF data together with the CIELab difference.

changes when the halfway vector is constant. Altogether, the
comparisons suggest that a more complex BRDF representation, which includes scattering, is required to accurately
describe all effects of a BTF. Nevertheless, the rather simple
d-BRDF model still produces convincing results.
To show how intuitively the g-BRDF representation can
be edited, we performed four different tasks (Figures 10–13).
In Figure 10 the orientation of the fibres of the corduroy material is inverted. For this purpose the logo is pasted into the
orientation map. Then, the fibres below the logo are rotated
by 180◦ .

Figure 8: Rendering of the proposte (top) and pulli (bottom)
BTFs from their g-BRDF representation shown on the insets.
On the right a closeup is compared to renderings from the
original BTF data together with the CIELab difference.
NDF is created by adding some lint and a minor specular
highlight. The rotation map is set to 45◦ . The depth map is
created by grayscaling the diffuse texture.
Each of these tasks was performed within less than 4 minutes and the complete editing process can be seen in the
accompanying video. A detailed list of the editing times is
shown in Table 2.
7. Discussion and Limitations

In Figure 12 the first the logo is copied into the diffuse
texture. Then, the depth map is changed so that the logo is
engraved into the surface. Finally, a new BRDF for the paint
of the logo is added. For this purpose, a synthetic specular
NDF is added. The index map is then altered accordingly in
order to address the new NDF. Finally, colour and Fresnel
map are modified to change reflection behaviour.

The proposed texture maps for meso-geometry and light interaction can easily be edited with standard image operations.
While previous approaches require special software to modify raw BTF input data, our representation allows a designer
to use his favourite image-editing tool and thus remain in a
working environment he is accommodated to. Another advantage is that every change of the maps directly affects the
BTF’s appearance and can be reviewed in a shader editor
without latency, as no further compression is required. This
way, a designer has full control over the final result at any
time. We have also shown that measured data can be seamlessly combined with user-generated BRDFs and even the
construction of a BTF from a single image is possible. Furthermore, our representation is able to represent a measured
BTF with about 1.5 MB only.

In the last example, we create a BTF from a single image.
First, we copy the image into the diffuse texture. Then, the

The main limitation of our approach clearly lies in
the choice of the d-BRDF model which totally neglects

In Figure 11 the colour of the wool is changed to red. For
this we simply exchange the colour channels of the NDFs and
the diffuse texture. To add some additional lint, the grazing
angles of the NDF are selected and a light-pink reflection is
added.

c 2009 The Authors
Journal compilation c 2009 The Eurographics Association and Blackwell Publishing Ltd.

N. Menzel and M. Guthe / g-BRDFs

2197

Figure 11: Editing the BRDF of the wool BTF.

Figure 9: Rendering of the wallpaper (top) and wool (bottom) BTFs from their g-BRDF representation shown on the
insets. On the right a closeup is compared to renderings from
the original BTF data together with the CIELab difference.

Figure 12: Adding a synthetic material to the impalla BTF.

Figure 10: Editing the meso-structure of the corduroy BTF.

surface is lost. A solution to this would be to store a set of the
most distinct NDFs for each material. Also, the use of a single
depth map implies the assumption that the surface is opaque.
This limitation could be lifted by using a multilayer model or
a volumetric representation similar to [MK06]. Such representations however significantly increase the complexity and
thus hinder intuitive editing.

subsurface-scattering and inter-reflections. With our method,
shadows are stored only implicitly and reconstructed using depth map and parallax occlusion mapping. The resulting harsh look could be compensated by simulating light
transport on the surface, a task that has been done on meshes
in real time in [Bun05, HJ07]. Another limitation is that we
only use a single normal distribution function for each material. This way much of the original variation and realism of a

The realism could be further improved by using an appropriate BSSRDF model [JMLH01], but then the fitting of the
parameters would become more difficult. An open question
is however how scattering can be extracted from the input
images as most acquisition systems do not even use backlighting, although Lensch et al. [LGB∗ 02] proposed one that
uses laser beams to capture subsurface-scattering BTF data.
Once its parameters are found, real-time rendering is possible
using a screen-space approximation [BC06].

c 2009 The Authors
Journal compilation c 2009 The Eurographics Association and Blackwell Publishing Ltd.

2198

N. Menzel and M. Guthe / g-BRDFs

[Ash06] ASHIKHMIN M.: Distribution-based BRDFs.
http://jesper.kalliope.org/blog/library/dbrdfs.pdf, 2006.
Stony Brook University.
[BC06] BANTERLE F., CHALMERS A.: A fast translucency
appearance model for real-time applications. In SCCG
2006 – Spring Conference on Computer Graphics (2006).
[Bli78] BLINN J. F.: Simulation of wrinkled surfaces. In
SIGGRAPH ’78: Proceedings of the 5th Annual Conference on Computer Graphics and Interactive Techniques
(1978), pp. 286–292.
[Bun05] BUNNELL M.: Dynamic ambient occlusion and
indirect lighting. In GPU Gems II (2005), pp. 223–233.

Figure 13: Creating a BTF from a diffuse texture.
Table 2: Editing times for example tasks.

Task
Meso-structure editing
BRDF editing
Adding synthetic material
Creating a complete g-BRDF

Time (mm:ss)
0:39
1:32
2:52
3:51

8. Conclusion
We proposed a novel BTF representation suited for both
editing and rendering at the same time by splitting the BTF
into texture maps describing meso-scale geometry and textures describing light interaction. The main advantage of this
representation is that changing the textures directly affects
the BTF rendering because no further compression is required. For designers, these textures are comprehensive and
intuitive and do not require much knowledge of the underlying physics. We further presented a shader based on parallax occlusion mapping to render g-BRDFs in real time on
current graphics hardware. In addition to generating a BTF
from scratch, the proposed decomposition process partitions
a measured BTF into its g-BRDF representation and thus allows editing of real-world materials. While the quality of the
compressed BTF is comparable to state-of-the-art statistical
compression algorithm, the g-BRDF requires significantly
less texture memory.

[CGS06] CHEN T., GOESELE M., SEIDEL H.-P.: Mesostructure from specularity. In CVPR ’06: Proceedings of the
2006 IEEE Computer Society Conference on Computer
Vision and Pattern Recognition (2006), pp. 1825–1832.
[COM98] COHEN J., OLANO M., MANOCHA D.:
Appearance-preserving simplification. In SIGGRAPH
’98: Proceedings of the 25th Annual Conference on
Computer Graphics and Interactive Techniques (1998),
pp. 115–122.
[DvGNK99]
DANA K. J., vAN GINNEKEN B., NAYAR S. K.,
KOENDERINK J. J.: Reflectance and texture of real-world
surfaces. ACM Transactions on Graphics 18, 1 (1999),
1–34.
[Gen89]
GEN´IS C. T.: Relaxation and neural learning:
Points of convergence and divergence. Journal of Parallel
and Distributed Computing 6, 2 (1989), 217–244.
[GGSC96]
GORTLER S. J., GRZESZCZUK R., SZELISKI R.,
COHEN M. F.: The lumigraph. In SIGGRAPH ’96: Proceedings of the 23rd Annual Conference on Computer
Graphics and Interactive Techniques (1996), pp. 43–54.
[GH07]
GHOSH A., HEIDRICH W.: The d-BRDF model as
a basis for BRDF acquisition. In SIGGRAPH ’07: ACM
SIGGRAPH 2007 Posters (2007), p. 40.
[GW87]
GONZALEZ R. C., WINTZ P.: Digital Image Processing. Addison-Wesley, 1987.
[HJ07] HOBEROCK J., JIA Y.: High-quality ambient occlusion. In GPU Gems III (2007), pp. 257–274.
[HS98]
HEIDRICH W., SEIDEL H.-P.: View-independent environment maps. In HWWS ’98: Proceedings of the ACM
SIGGRAPH/EUROGRAPHICS Workshop on Graphics
Hardware (1998), pp. 39–44.

References
[APS00]
ASHIKMIN M., PREMOZˇ E S., SHIRLEY P.: A
microfacet-based BRDF generator. In SIGGRAPH ’00:
Proceedings of the 27th Annual Conference on Computer
Graphics and Interactive Techniques (2000), pp. 65–74.

[JMLH01] JENSEN H. W., MARSCHNER S. R., LEVOY M.,
HANRAHAN P.: A practical model for subsurface light transport. In SIGGRAPH ’01: Proceedings of the 28th Annual

c 2009 The Authors
Journal compilation c 2009 The Eurographics Association and Blackwell Publishing Ltd.

N. Menzel and M. Guthe / g-BRDFs

Conference on Computer Graphics and Interactive Techniques (2001), pp. 511–518.
[KBD07] KAUTZ J., BOULOS S., DURAND F.: Interactive
editing and modeling of bidirectional texture functions. In
SIGGRAPH ’07: ACM SIGGRAPH 2007 Papers (2007),
pp. 53–62.
[KM99] KAUTZ J., MCCOOL M. D.: Interactive rendering
with arbitrary BRDFs using separable approximations. In
SIGGRAPH ’99: ACM SIGGRAPH 99 Conference Abstracts and Applications (1999), p. 253.
[KMBK03] KOUDELKA M. L., MAGDA S., BELHUMEUR P. N.,
KRIEGMAN D. J.: Acquisition, compression and synthesis of
bidirectional texture functions. In 3rd International Workshop on Texture Analysis and Synthesis (Texture 2003)
(2003).
[LBAD∗ 06] LAWRENCE J., BEN-ARTZI A., DECORO C.,
MATUSIK W., PFISTER H., RAMAMOORTHI R., RUSINKIEWICZ
S.: Inverse shade trees for non-parametric material representation and editing. In SIGGRAPH ’06: ACM SIGGRAPH 2006 Papers (2006), pp. 735–745.
[LFTG97] LAFORTUNE E. P. F., FOO S.-C., TORRANCE K. E.,
GREENBERG D. P.: Non-linear approximation of reflectance
functions. In SIGGRAPH ’97: Proceedings of the 24th
Annual Conference on Computer Graphics and Interactive
Techniques (1997), pp. 117–126.
LENSCH H. P. A., GOESELE M., BEKAERT P.,
[LGB∗ 02]
KAUTZ J., MAGNOR M. A., LANG J., SEIDEL H.-P.: Interactive
rendering of translucent objects. In PG ’02: Proceedings
of the 10th Pacific Conference on Computer Graphics and
Applications (2002), p. 214.
[LHZ∗ 04] LIU X., HU Y., ZHANG J., TONG X., GUO B.,
SHUM H.-Y.: Synthesis and rendering of bidirectional texture functions on arbitrary surfaces. IEEE Transactions
on Visualization and Computer Graphics 10, 3 (2004),
278–289.
LENSCH H. P. A., KAUTZ J., GOESELE M.,
[LKG∗ 01]
HEIDRICH W., SEIDEL H.-P.: Image-based reconstruction of
spatially varying materials. In In Rendering Techniques
’01 (Proceedings of Eurographics Rendering Workshop)
(2001), pp. 104–115.

2199

[MMK03] M¨ULLER G., MESETH J., KLEIN R.: Compression
and real-time rendering of measured BTFs using local
PCA. In Vision, Modeling and Visualisation 2003 (2003),
pp. 271–280.
M¨ULLER G., MESETH J., SATTLER M., SARLETTE
[MMS∗ 05]
R., KLEIN R.: Acquisition, synthesis and rendering of bidirectional texture functions. Computer Graphics Forum 24,
1 (2005), 83–109.
[MSK06] M¨ULLER G., SARLETTE R., KLEIN R.: Data-driven
local coordinate systems for image-based rendering. Computer Graphics Forum 25, 3 (2006), 369–378.
[MSK07] M¨ULLER G., SARLETTE R., KLEIN R.: Procedural
editing of bidirectional texture functions. In Eurographics
Symposium on Rendering 2007. Kautz J., Pattanaik S.,
(Eds.), 2007, pp. 219–230.
[NDM05] NGAN A., DURAND F., MATUSIK W.: Experimental analysis of brdf models. In Proceedings of the Eurographics Symposium on Rendering (2005), pp. 117–226.
[NRDR05] NEHAB D., RUSINKIEWICZ S., DAVIS J.,
RAMAMOORTHI R.: Efficiently combining positions and normals for precise 3rd geometry. ACM Transactions on
Graphics 24, 3 (2005), 536–543.
[Pho75] PHONG B. T.: Illumination for computer generated
pictures. Communication of ACM 18, 6 (1975), 311–317.
[PL07] PELLACINI F., LAWRENCE J.: Appwand: editing measured materials using appearance-driven optimization.
ACM Transactions of Graphics 26, 3 (2007), 54.
[RC98] ROY S., COX I. J.: A maximum-flow formulation
of the n-camera stereo correspondence problem. In ICCV
’98: Proceedings of the Sixth International Conference on
Computer Vision (1998), p. 492.
[SSK03] SATTLER M., SARLETTE R., KLEIN R.: Efficient and
realistic visualization of cloth. In EGSR ’03: Proceedings of the 14th Eurographics Symposium on Rendering
(2003), Eurographics Association, pp. 167–177.
[SvBLD03] SUYKENS F., vOM BERGE K., LAGAE A., DUTRE
P.: Interactive rendering with bidirectional texture functions. Computer Graphics Forum 22, 3 (2003), 463–472.

[Lou04] LOURAKIS M. I. A.: Levmar: LevenbergMarquardt nonlinear least squares algorithms in C/C++.
http://www.ics.forth.gr/∼lourakis/levmar/, 2004.

[Tat06] TATARCHUK N.: Dynamic parallax occlusion mapping with approximate soft shadows. In I3D ’06: Proceedings of the 2006 Symposium on Interactive 3D Graphics
and Games (2006), pp. 63–69.

[MK06] MAGDA S., KRIEGMAN D.: Reconstruction of volumetric surface textures for real-time rendering. In Proceedings of the Eurographics Symposium on Rendering
(2006), pp. 19–29.

[TS67] TORRANCE K. E., SPARROW E. M.: Theory for offspecular reflection from roughened surfaces. Journal of
the Optical Society of America 57, 9 (1967), 1105–1114.

c 2009 The Authors
Journal compilation c 2009 The Eurographics Association and Blackwell Publishing Ltd.

2200

N. Menzel and M. Guthe / g-BRDFs

[War92]
WARD G. J.: Measuring and modeling anisotropic
reflection. In SIGGRAPH ’92: Proceedings of the 19th
Annual Conference on Computer Graphics and Interactive
Techniques (1992), pp. 265–272.
[WTS∗ 05] WANG J., TONG X., SNYDER J., CHEN Y., GUO
B., SHUM H.-Y.: Capturing and rendering geometry details

for btf-mapped surfaces. The Visual Computer 21, 8–10
(2005), 559–568.
[ZBK02] ZICKLER T., BELHUMEUR P. N., KRIEGMAN D. J.:
Helmholtz stereopsis: Exploiting reciprocity for surface
reconstruction. International Journal of Computer Vision
49, 2/3 (2002), 215–227.

c 2009 The Authors
Journal compilation c 2009 The Eurographics Association and Blackwell Publishing Ltd.

