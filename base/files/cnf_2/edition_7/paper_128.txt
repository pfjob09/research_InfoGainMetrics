Eurographics Symposium on Rendering 2009
Hendrik P. A. Lensch and Peter-Pike Sloan
(Guest Editors)

Volume 28 (2009), Number 4

Motion based Painterly Rendering
H. Lee, C. H. Lee, and K. Yoon
Chung-Ang University, Korea

Abstract
Previous painterly rendering techniques normally use image gradients for deciding stroke orientations. Image
gradients are good for expressing object shapes, but difficult to express the flow or movements of objects. In real
painting, the use of brush strokes corresponding to the actual movement of objects allows viewers to recognize
objects’ motion better and thus to have an impression of the dynamic. In this paper, we propose a novel painterly
rendering algorithm to express dynamic objects based on their motion information. We first extract motion information (magnitude, direction, standard deviation) of a scene from a set of consecutive image sequences from the
same view. Then the motion directions are used for determining stroke orientations in the regions with significant motions, and image gradients determine stroke orientations where little motion is observed. Our algorithm is
useful for realistically and dynamically representing moving objects. We have applied our algorithm for rendering landscapes. We could segment a scene into dynamic and static regions, and express the actual movement of
dynamic objects using motion based strokes.
Categories and Subject Descriptors (according to ACM CCS): Computer Graphics [I.3.3]: Picture/Image Generation
Display algorithms—

1. Introduction
A painting is an artist’s interpretation of a scene onto a twodimensional canvas. The artist recognizes patterns and flows
about a target scene, and expresses them. However, no matter how successful artists were in representing movements
and flows, their work within the canvas frame has limitations
of being static [ADG∗ 02]. In order to overcome such limitations, they use strokes’ orientation corresponding to the
actual movement. For example of Van Gogh’s painting in
figure 1, brush strokes are oriented towards the direction of
the water stream in (a); and a horizontally-oriented strokes
were used to depict drifting clouds in (b). Through actual
brush stroke orientation, the artist can not only express the
real movement, but also provide rhythm and energy that help
the viewer’s perception.
Painterly rendering is a Non-photorealistic rendering(NPR) method based on brushstrokes. It uses the stroke
rather than the pixel as a basic unit of which an image is
composed [Her03]. In previous 2D painterly rendering techniques [Lit97] [Her98] [GCS02], strokes’ orientations are
normally determined by image gradients. Those techniques
are good for representing object shapes, and thus they are
c 2009 The Author(s)
Journal compilation c 2009 The Eurographics Association and Blackwell Publishing Ltd.
Published by Blackwell Publishing, 9600 Garsington Road, Oxford OX4 2DQ, UK and
350 Main Street, Malden, MA 02148, USA.

(a)

(b)

Figure 1: Vincent Van Gogh’s "Canal with Women Washing"(1888) and "The Poplars at Saint-Remy"(1889).

suitable for rendering still-life or static scenes. However,
they have weakness in expressing scenes with objects that
flow or move, typically appearing in landscapes.
In this paper, we propose a painterly rendering algorithm
based on motion information for expressing a natural flow in

1208

H. Lee , C. H. Lee , K. Yoon / Motion based Painterly Rendering

a scene. To express the flow in a scene, we use a set of consecutive image frames from the same view as input, from
which motion information between the frames is extracted.
By accumulating the extracted motion information between
the frames, the motion information (magnitude, direction,
and standard deviation) for the scene is derived. Then the
motion directions are used for determining stroke orientations in the regions with significant motions. And we add
randomness based on motion’s standard deviation. Optionally, we propose a technique to determine stroke color using
the derived motion information to mimic a motion blur effect.
The main contribution of our paper is to provide realistic
and dynamic 2D representations of moving objects, such as
in landscapes (sky, waterfall, brook) or scenes with dynamic
backgrounds. Secondly, using the stroke’s attribute derived
from motion information rather than from conventional gradient information is a novel approach. It is expected that this
approach will be further extended to other Stroke-based rendering(SBR) research. Thirdly, we can segment a scene into
dynamic regions and static regions, witch will be useful for
other rendering or vision techniques.
2. Related Work
The proposed rendering algorithm is related to two areas of
previous work, painterly rendering and motion information
based rendering techniques. Firstly, a review of painterly
rendering techniques is presented according to the method
of determining stroke orientation.
The painterly rendering approach was firstly introduced
in Haeberli’s work [Hae90]. In Haeberli’s system, a user
determines brush strokes attributes such as position, color,
size, and orientation manually. From the late 90s, painterly
rendering techniques that use image gradient information to
determine strokes orientation were proposed. In Litwinowicz [Lit97] and Hertzmann [Her98], an image gradient is
used to orientate brush strokes. That is, the computation
of an appropriate angle for each stroke is accomplished
by using the image gradient. Stroke orientation derived
from an image gradient is good for representing object
shape along edges, but this approach cannot obtain a coherent direction for nearby strokes. To solve this problem,
Hertzmann [Her02] and Hays [HE04] used an interpolation method based on image gradient. By preserving strong
edge directions while directing weak edges to follow the
neighboring dominant ones, a consistent direction in the rendered image can be achieved. In Olsen [OMG05], brush
strokes orientation based on fluid simulation is used to create the sorts of turbulent brush stroke patterns that Van Gogh
is known for. This method creates Van Gogh-like renderings of images, but generates conflicting strokes orientation that does not take the neighborhood objects into account. Park [PKB∗ 06] and Seo [SPY09] applied the best
matching technique based on a photomosaic algorithm to

painterly rendering. This method chooses the best matching brush stroke from a database storing a number of brush
stroke templates. This algorithm is appropriate for generating real painting effect, but it cannot provide coherent directions for brush strokes. Unlike the previous work, our algorithm derives stroke orientation from motion information.
We can control the region where motion direction is used
based on the motion magnitude.
In the existing research field of 2D rendering, there are
mainly three research areas using motion information painterly animation, motion display and image editing. In
painterly animation research [Lit97] [HP00] [HE04] [PY08],
the motion information is extracted and used only to determine the strokes’ position in the next frame, but it does not
influence other stroke attributes such as orientation, color,
etc. In motion display research, Freeman [FAH91], Collomosse [Col03] and Kim [KE05] analyzed motion from video
and added flow lines to enhance visualization so that object movement can be expressed effectively. Brostow [BE01]
propose motion blur effects based motion information. Nienhaus [NWG08] analyzed motion in several frames with the
same view and applied rendering by warping object shape
portrayed in the image along the directions of its motion. In
image editing, Chuang [CGZ∗ 05], a user divides an input
image of real artistic picture into regions with multi-layers.
The user generates the effect of moving painting by interactively assigning motion information to each layer. In this paper, we use motion information to produce a painterly effect.
We generates stroke direction based on motion information,
it can capture and express realistic motion directions of objects.

3. Motion Based Stroke Generation
Figure 2 presents the overall system flow of the proposed
motion-based painterly rendering algorithm. We use a set of
consecutive frames 1 to n as input image sequences. For rendering, Motion Analysis and Image Analysis are performed.
In Motion Analysis, the given input image sequences are analyzed to derive motion information - i.e., magnitude, direction, and standard deviation at each pixel. In Image Analysis,
the last(nth ) frame in the input image sequences is analyzed
to obtain image gradients, edges, an edge distance map. In
the Stroke synthesis phase, we divide the scene, based on the
motion magnitude, into the dynamic region where motions
are big and the static region where motions are small. Then
we synthesize the stroke orientations by applying the motion directions in dynamic regions and the image gradients
in static regions. In the Rendering stage, we generate brush
strokes based on the synthesized stroke orientations and the
stroke positions based on the edges and the edge distance
map, and applies the generated strokes upon the 2D canvas.
More details of each phase in the algorithm are presented in
the following subsections.
c 2009 The Author(s)
Journal compilation c 2009 The Eurographics Association and Blackwell Publishing Ltd.

1209

H. Lee , C. H. Lee , K. Yoon / Motion based Painterly Rendering

Figure 3: Part of input frames

˜
3.1.2. Motion Magnitude(Q)
The motion magnitude of each pixel is obtained by averaging the magnitudes of the motion between frames and then
normalizing it. Equation (4) shows how to calculate the motion magnitude Q of pixel i. In the equation (4), N[·] indicates
a normalization ranged from 0 to 1. From Q, we compute a
smoothed motion magnitude Q˜ i by applying a Gaussian filter
to each pixel i.
Figure 2: System flow.
Qi = N[
3.1. Motion Analysis
We use the optical flow technique [BA91] to extract motion
information from input frames. Let mi be the motion vectors
between ith and (i + 1)th frames. mi is a two-dimensional
array where the motion vector between two frames at each
pixel. In addition, let qi a two-dimensional array that stores
the magnitude of the motion at each pixel. From the n input frames, overall n − 1 motion vectors and magnitudes are
computed:
m = [m1 , m2 , m3 , ...mn−1 ]

(1)

q = [q1 , q2 , q3 , ...qn−1 ]

(2)

Then we compute the average motion direction and magnitude and standard deviation of motion as described in the
following sections.
3.1.1. Motion Direction(M)

(4)

Additionally, the standard deviation of the motion direction Si is computed at each pixel i. The calculated standard
deviation influences random factors that are added to stroke
orientations.
Figure 3 shows some frames from the input image sequences. In the images, the cactus has no motion while the
clouds in the sky are sweeping from the left to the right.
Figure 4 shows the motion information derived from the input frames. Figure 4(a) adapts LIC [CL93] to depict motion
direction(M). Figure 4(b) and figure 4(c) represent pixel’s information in numeric values ranged between 0 and 255. The
brighter pixel indicates the greater value. Because the clouds
are sweeping fast from the left to the right in the scene, vector lines in the sky modeling the movement towards the right
side can be observed in figure 4(a). On the other hand, the
cactus is a static object, so there is no observed direction and
magnitude.
3.2. Image Analysis

The motion direction of each pixel is calculated by averaging the directions in m. Equation (3) shows how to calculate the motion direction of pixel i. The function avg
is used to average directions, taking care of singularities
around zero(0=2π) based on Perona’s continuous space concept [Per98].

Mi = avg({mki }),

1 n−1
( ∑ qki )]
n − 1 k=1

1 ≤ k ≤ n−1

(3)

c 2009 The Author(s)
Journal compilation c 2009 The Eurographics Association and Blackwell Publishing Ltd.

For strokes attributes, edges and an edge distance map are
extracted from nth input frame. The normal of the image
gradients are used for deciding stroke directions, in static
regions. And edge and edge distance map are used for positioning and clipping the stroke, in both static and dynamic
regions. The extracted normal of image gradient is defined
as (G ). Figure 5 shows the image information (i.e., gradient, edges, and edge distance map) resulting from the Image
Analysis process.

1210

H. Lee , C. H. Lee , K. Yoon / Motion based Painterly Rendering

value(equation (8)). Let wr be a parameter to adjust the
amount of randomness ranged between 0 and 1. Then the
final stroke direction D˜ i at pixel i is defined as in equation
(7). For example, the flower nodding in the wind have a bigger random value than the flower stood still so that irregular
motions can be expressed more naturally.

(a) Motion Direction

D˜ i = ET F(Di ) + wr R(Si )

(7)

R(λ) = Rand(| −λ, λ |)

(8)

Figure 6 shows the stroke directions on varying static and
dynamic regions according to the user-defined parameter r.

(b) Motion Magnitude

(c) Standard deviation

Figure 4: Motion Information
(a) r = 0

(b) r = 0.3

(c) r = 0.9

(d) r = 1.0

Figure 5: Image Gradient, Edges, and Edge Distance Map

3.3. Stroke synthesis
In a real painting, artists emphasize the shapes by aligning brush stroke with the object silhouettes or focus on the
movements by brushing along the object motions. So, we
provides a user-controllable variable r to leave the aesthetic
decisions about brush stroke characteristics to the user. r is a
threshold value ranged between 0 and 1 that decides whether
the motion direction is used for rendering or not .

Figure 6: Information synthesis result with various r. (Red
area: use gradients, Blue area: use motions)

In pixel i, stroke direction(Di ) is determined based on
equation (5) and (6). Stroke direction is derived from normalized motion magnitude(Q˜ i ). If Q˜ i is greater than (1 − r),
motion direction is used. If not, image gradient direction is
used.

For rendering, we apply the hays [HE04]’s multi-layered
rendering technique which determine stroke attributes based
on edges. On the first layer, large and big strokes are distributed by random position for filling canvas. On the higher
layers, smaller and shorter strokes are applied and placed
around the edges. The edges and the edge distance map derived in the Image Analysis stage are used for this purpose.
In the previous painterly rendering techniques, a stroke color
takes the pixel value in the input image to which the stroke
is applied. In this paper, an additional option is provided to
use the cumulative sum of the color values is provided to
mimic a motion blur effect. The stroke color of pixel i is determined based on equation (9). Let C(ni ) be the color of
pixel i on frame n. In general, the color in the last frame is
used by setting wc = 1.

Di = α · Mi + (1 − α) · Gi
α=

1
0

if Q˜ i ≥ (1 − r)
otherwise

(5)
(6)

After determining the region of using motion directions
or gradient directions based on the motion magnitude, the
ETF interpolation [KLC07] is performed. It prevents breaks
in the boundaries between dynamic and static regions as well
as generates coherent directions.
Using randomness is also important in achieving a handcrafted look. So we apply random factor based on S

4. Rendering

Colori = wc ·C(ni ) + (1 − wc )(

1 n−1
∑ C(ki ))
n − 1 k=1

(9)

c 2009 The Author(s)
Journal compilation c 2009 The Eurographics Association and Blackwell Publishing Ltd.

H. Lee , C. H. Lee , K. Yoon / Motion based Painterly Rendering

5. Experimental Results
We experimented on different brush stroke parameter values to examine different results. The result images generated
using our algorithm is compared with the images produced
using the conventional gradient-based directions. The total
time to get the final rendered images depends on the image
size and the number of the input frames. It takes about 30
seconds for processing 70 image frames, when each frame
size is 900x500. We used a Pentium 2.4GHz quad core PC
with 2GB memory for the results in this paper.
Figure 7 shows the final result of our algorithm with the
corresponding images. The top of three images show the motion magnitude, segmented region and the stroke direction
synthesized the r = 0.9. The bottom of figure 7 shows the
final result. The given parameter values are denoted under
the images. Figure 8 shows the different rendered images
according to the r value. Each image is produced based on
the stroke directions in figure 6. Where r = 0, the gradient
direction is used in all areas, which gives the same result
with the classical gradient-based interpolation. As the value
of the r variable increases, the motion direction begins to be
used in addition to the gradient direction where motion magnitude is greater than (1 − r). Only motion direction is used
when r = 1. In this case, static object such as the cactus in
figure 8 shows coarse boundaries. In general, r = 0.9 was
the most appropriate value to combine the motion and gradient directions, which produces the painterly rendered images
with aesthetically pleasing looks. Figure 9 shows the results
jittered according to standard deviation values. We control
the randomness with wr . It shows that even if the same motion information is used, more various stoke directions can
be represented by adjusting weights for the pixels where the
standard deviations turn out big. We can see that the right
part of white flowers are more affected than yellow flower
by wr . Figure 10 shows the effects resulting from adjusting
the stroke color considering all the image frames. Using the
parameter wc value close to 0 gives the image a motion blur
effect because the frame color values are accumulated. This
scheme can be useful for representing the rigid objects with
a clear color contrast. However, w=1 is generally used for
the scenes having the similar color values such as the clouds
and the water. Figure 11 compares another result using the
existing gradient-based rendering techniques and using the
motion directions. We can see that our algorithm can express
realistic and dynamic effects on the water stream.
6. Conclusions And Future Works
In this paper, we propose a new algorithm for painterly rendering using motion information. The motion information
is derived from a set of consecutive images from the same
view, and motion’s magnitudes, directions, and standard deviation are calculated. Strokes’ orientation and color are then
determined based on the calculated motion information. The
proposed algorithm is capable of producing painterly renc 2009 The Author(s)
Journal compilation c 2009 The Eurographics Association and Blackwell Publishing Ltd.

1211

dered results which can effectively represent the movements
in a scene. The proposed technique is suitable for landscape
rendering, especially for expressing the ’natural’ look of
moving objects such as the cloud, waterfalls, brook, and etc.
The proposed algorithm contributes in several parts. We can
segment a scene into dynamic and static regions based motion information, and it allows a more effective way of representing objects containing flow or movement. The derivation
of stroke attributes from the motion information is a novel
approach in the field of SBR (Stroke-Based Rendering). We
expect that the proposed motion-based approach can be extended to other research areas in SBR.
We are planning a few future works. According to the
characteristic of input image sequences, adequate boundaries between static and dynamic regions could be different.
So, it would be useful to automatically determine the parameter r for deciding static and dynamic boundaries. Secondly,
the algorithm considers only line strokes with the same texture. The scene might be segmented into more fine classes
according to motion magnitude and standard deviation, and
the stroke styles and the texture suitable for each class can
be distinctively applied. This scheme is expected to enhance
the natural look of the moving objects and thereby give more
realistic sense of motion. In addition, the computational performance can be critical as the algorithm needs to process a
large number of image frames. Therefore it would be helpful to use GPU programming or any other algorithms for improving the performance. Finally, we have a plane to extend
this algorithm to other SBR research, for example, painterly
animation.
ACKNOWLEDGMENTS
This research was partially supported by the Chung-Ang
University Excellent Research Grant in 2007. This work
was also supported by the Korea Science and Engineering
Foundation (KOSEF) grant funded by the Korea government(MEST) (No. R0A-2008-000-20060-0).
References
[ADG∗ 02]

AGRAWALA M., D URAND F., G OOCH B., I NTER V., O STROMOUKHOV V., Z ORIN D.: Perceptual and
artistic principles for effective computer depiction. In ACM SIGGRAPH 2002 Course Notes (2002), p. "".
RANTE

[BA91] B LACK M., A NANDAN P.: Robust dynamic motion estimation over time. In Proc. computer Vision and Pattern Recognition (1991), pp. "296–302".
[BE01] B ROSTOW G., E SSA I.: Image-based motion blur for stop
motion animation. In ACM SIGGRAPH 2001 Proceeding (2001),
pp. "561–566".
[CGZ∗ 05] C HUANG Y., G OLDMAN D., Z HENG K., C URLESS
B., S ALESIN D., R ICHARD S.: Animating pictures with stochastic motion textures. In ACM SIGGRAPH 2005 Proceding (2005),
pp. "853–860".
[CL93] C ABRAL B., L EEDON L.: Imaging vector fields using
line integral convolution. In ACM SIGGRAPH 1993 Proceeding
(1993), pp. "296–302".

1212

H. Lee , C. H. Lee , K. Yoon / Motion based Painterly Rendering

[Col03] C OLLOMOSSE J. P.: Cartoon-style rendering of motion
from video. In Intl. Conf on Video, Vision and Graphics (VVG),
July 2003. Eurographics Assoc (2003), pp. "117–124".
[FAH91] F REEMAN W. T., A DELSON E. H., H EEGER D. J.:
Motion without movement. In ACM SIGGRAPH 1991 Proceeding (1991), pp. "27–30".
[GCS02] G OOCH B., C OOMBE G., S HIRLEY P.: Artistic vision:
Painterly rendering using computer vision techniques. In 2nd
Ann. Symp. Non-Photorealistic Animation and Rendering (NPAR
2002) (2002), pp. "83–90".
[Hae90] H AEBERLI P. E.: Paint by numbers: Abstract image representations. In SIGGRAPH 90 Proceedings (1990), pp. "207–
214".
[HE04] H AYS J., E SSA I.: Image and video based painterly animation. In Third International Symposium on Non-Photorealistic
Animation and Rendering (NPAR2004) (2004), pp. "120–133".
[Her98] H ERTZMANN A.: Painterly rendering with curved brush
strokes of multiple sizes. In SIGGRAPH 98 Proceeding (1998),
pp. "453–460".
[Her02] H ERTZMANN A.: Fast paint texture. In In Second International Symposium on Non-Photorealistic Animation and Rendering (NPAR 2002) (2002), pp. "91–96".
[Her03] H ERTZMANN A.: Tutorial: A survey of stroke-based rendering. In IEEE Computer Graphics and Applications (2003),
pp. "70–81".
[HP00] H ERTZMANN A., P ERLIN K.: Painterly rendering for
video and interaction. In 1nd Ann. Symp. Non-Photorealistic Animation and Rendering (NPAR 2000) (2000), pp. "7–12".
[KE05] K IM B., E SSA I.: Video-based nonphotorealistic and expressive illustration of motion. In Proc. Computer Graphics International (2005), pp. "32–35".
[KLC07] K ANG H., L EE S., C HUI C.: Coherent line drawing.
In Symp. Non-Photorealistic Animation and Rendering (NPAR
2007) (2007), pp. "43–50".
[Lit97] L ITWINOWICZ P.: Images and video for an impressionist
effect. In SIGGRAPH 97 Proceeding (1997), pp. "407–414".
[NWG08] N IENHAUS M., W INNEMOELLER H., G OOCH B.:
Forward lean - deriving motion illustrations from video. In ACM
SIGGRAPH Asia 2008 Sketch Program (2008), pp. " – ".
[OMG05] O LSEN S. C., M AXWELL B. A., G OOCH B.: Interactive vector fields for painterly rendering. In Graphics Interface
2005 (2005), pp. "241–247".
[Per98] P ERONA P.: Orientation diffusions. In IEEE Transactions
on image precessing, Vol 7, No 3, March 1998 (1998), pp. "457–
467".
[PKB∗ 06] PARK J., KOO B., BARRY R., H ONG S., YOON K.:
Painterly rendering with designed imperfection. In SIGGRAPH
2006 Sketches (2006), p. "99".
[PY08] PARK Y., YOOM K.: Painterly animation using motion
maps. In Graphical Models, Vol 70,Jan. 2008 (2008), pp. "1–
15".
[SPY09] S EO S., PARK J., YOON K.: A painterly rendering on
stroke profile and database. In Proc. Computationl Aesthetics
2009 (2009), p. "accepted".

c 2009 The Author(s)
Journal compilation c 2009 The Eurographics Association and Blackwell Publishing Ltd.

H. Lee , C. H. Lee , K. Yoon / Motion based Painterly Rendering

1213

Figure 7: Final result. Top:motion magnitude(left),segmented region from r=0.9(middle), result direction(right), bottom: final
result. n = 46, wr = 0.0, wc = 1

Figure 8: Result according to r value. (top left:r=0.0, top right:r=0.3, bottom left:r=0.9, bottom right: r=1.0)

c 2009 The Author(s)
Journal compilation c 2009 The Eurographics Association and Blackwell Publishing Ltd.

1214

H. Lee , C. H. Lee , K. Yoon / Motion based Painterly Rendering

(a) wr = 0.0

(b) wr = 0.3

(c) wr = 0.6

(d) wr = 1.0

Figure 9: Result according to wr (n = 60, r = 0.9, wc = 1), top left: standard deviation image

Figure 10: Result according to wc (top:wc = 1,bottom:wc = 0.3)n = 60, r = 0.9, wr = 0

c 2009 The Author(s)
Journal compilation c 2009 The Eurographics Association and Blackwell Publishing Ltd.

H. Lee , C. H. Lee , K. Yoon / Motion based Painterly Rendering

(a) Direction from r = 0

(b) Direction from r = 0.9

(c) Rendering result from (a)

(d) Rendering result from (b)

Figure 11: Another results(n
c 2009 The Author(s)
Journal compilation c 2009 The Eurographics Association and Blackwell Publishing Ltd.

= 70, wr = 0.2, wc = 1)

1215

