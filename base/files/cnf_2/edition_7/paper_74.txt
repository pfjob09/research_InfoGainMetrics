Eurographics/ IEEE-VGTC Symposium on Visualization 2009
H.-C. Hege, I. Hotz, and T. Munzner
(Guest Editors)

Volume 28 (2009), Number 3

Illuminated 3D Scatterplots
Harald Sanftmann and Daniel Weiskopf
VISUS, Universität Stuttgart, Germany

Abstract
In contrast to 2D scatterplots, the existing 3D variants have the advantage of showing one additional data dimension, but suffer from inadequate spatial and shape perception and therefore are not well suited to display
structures of the underlying data. We improve shape perception by applying a new illumination technique to
the pointcloud representation of 3D scatterplots. Points are classified as locally linear, planar, and volumetric
structures—according to the eigenvalues of the inverse distance-weighted covariance matrix at each data element.
Based on this classification, different lighting models are applied: codimension-2 illumination, surface illumination, and emissive volumetric illumination. Our technique lends itself to efficient GPU point rendering and can be
combined with existing methods like semi-transparent rendering, halos, and depth or attribute based color coding. The user can interactively navigate in the dataset and manipulate the classification and other visualization
parameters. We demonstrate our visualization technique by showing examples of multi-dimensional data and of
generic pointcloud data.
Categories and Subject Descriptors (according to ACM CCS): I.3.7 [Computer Graphics]: Three-Dimensional
Graphics and Realism—Color, shading, shadowing, and texture

1. Introduction
Traditional 3D scatterplots suffer from suboptimal spatial
perception and occlusion. In our work we address the issue of shape perception of 3D scatterplots. If some structures are present in the data, we aim at supporting the user
in identifying those structures and recognizing the relation
of points in 3-space. In 3-space there are 1-manifolds, 2manifolds, and 3-manifolds, which can be recognized based
on a local principal component analysis. In contrast to traditional point-based rendering techniques, which focus only
on the extraction of surfaces, our approach classifies each
data point according to linearity, planarity, and sphericity by
performing an eigenvalue decomposition of the covariance
matrix in the local neighborhood of each sample. Different lighting models are applied based on the classification
of each point. Since the classification and the eigenvectors
at close samples are correlated, the resulting illumination is
smooth, and gives the user the ability to recognize the shape
by examining a shaded image. The novelty of our approach
is the flexible dimension/codimension rendering of pointclouds. Our improvement of the shape perception is complementary to cues for depth perception, such as motion parc 2009 The Author(s)
Journal compilation c 2009 The Eurographics Association and Blackwell Publishing Ltd.
Published by Blackwell Publishing, 9600 Garsington Road, Oxford OX4 2DQ, UK and
350 Main Street, Malden, MA 02148, USA.

allax, halo rendering, depth-based color mapping, or relative
object size [KSH04] [PKH04].
We do not target to represent individual points with our
technique; our goal is to present structures in dense scatterplots. Without lighting the 3D shape of the structures is hard
to recognize (Figure 1, left), whereas the 3D structure becomes visible by illuminating the points (Figure 1, middle
and right). Figure 1 shows a dataset obtained by integrating over the Lorenz attractor. This dataset is used throughout this paper to illustrate several effects of illuminated scatterplots. Illumination also guides exploratory analysis since
the 3D shape can be tracked by the eyes much better than
uniformly colored samples. In Figure 1, specular highlights
resulting from the illumination of planar structures are visible in the center of the image. There are also specular highlights that result from linear structures (e.g. the one from the
right “hole” to the origin of the coordinate system), which
would not be present without considering linear structures.
In this way, we enhance 3D occlusion management by improved shape perception. According to the taxonomy by
Elmqvist and Tsigas [ET08], we are improving the “depth
cues”, which we generalize to cues for spatial perception.

752

H. Sanftmann & D. Weiskopf / Illuminated 3D Scatterplots

Figure 1: A Lorenz attractor. Left: traditional 3D scatterplot; middle: illuminated scatterplot; right: linear, planar, and spherical structures highlighted through mapping to green, red, and blue colors respectively. The base colors are chosen to have
equal intensity.

2. Related Work
In this section, we first cover previous work related to 3D
scatterplots and then continue with topics related to pointbased rendering, illumination, and blending.
Donoho et al. [DDG88] present a system that uses 3D
scatterplots for multivariate data exploration. Pointclouds up
to 5000 points could be rotated interactively. Becker [Bec97]
apply volume rendering to display dense 3D scatterplots.
Points are packed into corresponding voxels that are rendered with splatting. The number of samples in a voxel is
mapped to opacity; the average value of one data variable in
each bin is mapped to color. We perform a similar densitybased rendering in Section 3.7, but use a point representation insted of a scalar field. Their system was capable of
displaying 2500 voxels (1/3 of them holding data) at interactive rates. The system by Kosara et al. [KSH04] simultaneously shows several 3D scatterplots with different axis
mappings. The views are linked through color mapping. This
concept is orthogonal to, and could be combined with, our
method. The depth perception of 3D scatterplots is improved
by Piringer et al. [PKH04] by mapping distance to color,
which is adopted in our technique. They additional employ
halos and a mapping of distance to point size to support
the identification of individual sample points. While their
method is suited for sparse scatterplots (see Section 3.6), our
technique aims to improving the perception in dense regions.
With a combination of dense and sparse scatterplot rendering techniques, Reina and Ertl [RE04] employ texture-based
volume rendering for getting an overview of large datasets
and rendering of individual values to interact with subregions of the dataset. We also support volume blending, but
we directly work with the point representation without the
need for resampling on a regular grid.
Typically, point-based rendering focuses on representing
2D surfaces in 3-space. A survey of point-based rendering
techniques can be found in [KB04]. As one example Schall
et al. [SBS05] perform a principal component analysis of
scattered points representing a smooth surface to filter out-

liers; they use point-based rendering to render the illuminated surface. We extend the principal component analysis to
allow for linear and spherical structures as well. The pointbased rendering technique by Hopf et al. [HLE04] is suitable for large 3D scattered point datasets, but is restricted to
showing spherical structures.
Banks [Ban94] studies illumination in different codimensions. The special case of codimension-2 in 3-space is applied to streamlines by Zöckler et al. [ZSH96]; we employ
this illumination model for linear structures in pointclouds.
The covariance matrix is similar to a diffusion tensor: it
is symmetric and positive semi-definite. Based on the eigenvalues a diffusion tensor can be classified in a space where
linear, planar, and spherical structures act as spanning vectors of that space [WPG∗ 97]. We adopt this classification
scheme in our work. Kindlmann and Weinstein [KW99] also
use this classification to illuminate diffusion tensors, differentiating between linear and planar structures. In contrast to
our method they do not blend between three separate illumination methods for the three basis structures, and they do
not support the assignment of different material properties to
them.

3. Flexible Codimension Rendering
Our goal is to illuminate 3D scatterplots. Differently classified structures should be assigned different material properties, and we need to use different illumination models for
them. In this section we will explain how we can classify
scattered points, how the tangent and normal vectors can be
calculated for them (which are needed for lighting), and how
the lighting calculations are performed.

3.1. Eigenvector and Eigenvalue Calculation
A 3D scatterplot is given as a set of points P = pi ∈ R3
in 3-space. Illumination requires additional information on
c 2009 The Author(s)
Journal compilation c 2009 The Eurographics Association and Blackwell Publishing Ltd.

H. Sanftmann & D. Weiskopf / Illuminated 3D Scatterplots

753

top of point positions. We need normal vectors to illuminate planar surfaces, and tangent vectors to illuminate lines.
Principal component analysis allows us to estimate normal
and tangent directions of scattered data points. The principal
components are derived by calculating the eigenvalues and
eigenvectors of the covariance matrix.
We use the weighted covariance matrix according
to [SBS05]:
N

Ci =

∑ (p j − ci )(p j − ci )T χ

j=1

p j − pi
h

where h is the kernel size, χ is a monotonically decreasing
weight function, and ci is the weighted average of all samples inside the kernel.
To account for varying point density, we adjust the kernel
size to cover a certain number of points instead of covering
a constant volume. For each point we define the local neighborhood Nin of pi as the n closest points to pi . The distance
to the farthest point defines the kernel size hni for pi :
Ni (d) = p j | p j − pi < d

(1)

hni = max {d | |Ni (d)| ≤ n}

(2)

Nin = Ni (hni )

(3)

We use the following weight function χ, which is the triangle
function applied to the squared normalized distance:
χ(x) =

1 − x2
0

if |x| < 1
else

3.2. Classification
The final color C of a sample is calculated by applying different lighting models for 1-manifolds, 2-manifolds, and 3manifolds and weighting the results based on the classification of the sample:

Figure 2: Scatterplot showing the effect of modifying the
weight factors for the linear, planar, and spherical cases.
The triangle in the lower left corner of each plot shows the
user input. Starting from the upper left, clockwise: a) emphasizing spherical structures, b) emphasizing linear structures,
c) emphasizing planar structures, d) suppressing spherical
structures. The color coding is as follows: red corresponds
to planar, green to linear, and blue to spherical.

The values cl , c p , and cs sum up to one, i.e. they can be
interpreted as barycentric coordinates.
The user can adjust the classification through a transfer
function by manipulating the weight coefficients wX . The
values cX are multiplied with wX and re-normalized (summing up to 1), resulting in the values dX , which are taken for
rendering instead of cX :
cX wX
dX =
∑ cX˜ wX˜
all X˜

C = dl Cl + d p C p + ds Cs
where CX is the color resulting from the illumination model
and dX the classification weight for the respective manifold
type. Now we will derive the classification of a sample.
Similar to diffusion tensor imaging [WPG∗ 97], we can
perform the classification based on the properties of the
covariance matrix. Let λ0 ≤ λ1 ≤ λ2 be the eigenvalues
and v0 , v1 , v2 the corresponding normalized eigenvectors
of the covariance matrix. The point pi can be classified
based on the eigenvalues in the linear, planar, and spherical
cases [WPG∗ 97]:
λ2 − λ1
cl =
λ0 + λ 1 + λ 2
2(λ1 − λ0 )
cp =
λ0 + λ 1 + λ 2
3λ0
cs =
λ0 + λ 1 + λ 2
c 2009 The Author(s)
Journal compilation c 2009 The Eurographics Association and Blackwell Publishing Ltd.

To emphasize or suppress linear, planar, or spherical structures the user can modify the classification. The weight coefficients wX can be adjusted by selecting a position in a
triangle. The barycentric coordinates of the position define
the weight coefficients. The triangle widget and the effect of
different weight vectors can be seen in Figure 2.
3.3. Lighting
The color of the three manifold types is obtained by:
A
D D D
S S S
CX = MD
X F + KX MX F + KX MX F

where F is the light color, MX is the material color, and KX
the shading contribution; the superscripts A , D , and S denote
ambient, diffuse, and specular components respectively.
In the planar case, the eigenvector corresponding to the
smallest eigenvalue, v0 , is normal to the planar surface. The

H. Sanftmann & D. Weiskopf / Illuminated 3D Scatterplots

754

sign of the eigenvector is not determined. We choose the normal vector to show in the direction of the viewing vector:
n = sign(v0 · V)v0
where V is the viewing vector.
With the derived normal vector we can perform a normal
vector based illumination model. In our system we use the
Blinn-Phong lighting model [Bli77]:
K pD = n · L
kp = n · H
(k p )q
0

K pS =

if k p > 0
else

where L is the light vector, H the halfway vector, and q the
specular exponent.
For the linear case, setting the eigenvector corresponding
to the largest eigenvalue v2 as the tangent vector, the diffuse and specular components can be calculated according
to Zöckler et al. [ZSH96]:
KlD =

1 − (L · v2 )2

kl =

1 − (L · v2 )2

KlS =

(kl )q
0

1 − (V · v2 )2 − (L · v2 )(V · v2 )

if kl > 0
else

For the spherical case no surface can be determined, and
just a constant term is applied to achieve a global intensity
comparable to diffuse shaded linear or planar structures. The
contribution is user-specified and constant over the image:

Figure 3: Scatterplot with different kernel sizes. n =
20 , 21 , 22 , 23 , 24 , 25 , 212 , 213 from top to bottom, left to right.

KsD = const.
KsS = 0
3.4. Kernel Size
The number of neighbor samples for the covariance computation affects the eigenvalues and the eigenvectors. The size
of the kernel hni (see Equations (2) and (3)) acts as the support size of a lowpass filter. The effect of using different kernel sizes can be seen in Figure 3. Starting with one sample
the eigenvectors/eigenvalues are undefined, resulting in the
upper left plot. Here equal eigenvalues are assumed, leading to the spherical classification shaded with ambient blue.
With two samples the largest eigenvector is defined resulting in the linear case, which is shaded in green color. With
four and more samples all eigenvalues and eigenvectors are
defined resulting in a combination of the three cases. With
increasing kernel size the eigenvalues and eigenvectors are
lowpass filtered with decreasing frequency spectrum, reducing noise but at the cost of blurring over the samples (see the
last plot with n = 213 = 8192 samples). In our application
the neighborhood size is interactively specified by the user.

3.5. Boundaries
Boundaries can be of special interest in many situations.
In this section we will discuss how our method behaves at
manifold boundaries.
To analyze the behavior at boundaries of volumetric distributions we consider a box-shaped volume with uniform
volumetric sample distribution. Inside the volume all three
eigenvalues are similar in size, which results in the volumetric classification cl ≈ 0, c p ≈ 0, cs ≈ 1. As we move toward
one face of the volume the kernel covers a growing region
outside the volume, where there are no samples to contribute
to the covariance matrix. At the boundary the classification
will be cl ≈ 0, c p ≈ 0.5, cs ≈ 0.5, which is half volumetric
and half planar.
When moving toward an edge of the box the classification
tends toward the linear case. Both cases can be illuminated
according to the light direction in contrast to the volumetric
case, which helps to recognize the boundary of the volume
(see Figure 4).
c 2009 The Author(s)
Journal compilation c 2009 The Eurographics Association and Blackwell Publishing Ltd.

H. Sanftmann & D. Weiskopf / Illuminated 3D Scatterplots

755

Figure 4: Scatterplot showing samples uniformly distributed
in a cube (left) and on 2D surfaces of a cube (right). The
edges of the box as well as the faces are distinguishable and
illuminated by the algorithm (left). Similarly, the boundaries
of the 2D surfaces are distinguishable as well (right). An
oblique clip plane is applied to show the interior of both
images.

A similar effect occurs in edge areas for points distributed
uniformly on a plane. When approaching the edge, the eigenvalues that are orthogonal to the edge diminish, which results
in the linear case.
3.6. Color Mapping
In general, color mapping can be used to encode additional
data or information. In the previous examples color was used
to highlight the differently classified structures in the data,
D
by assigning green, red, and blue colors to MD
l , M p , and
D
Ms respectively. We choose the three material colors to have
equal intensity and to result in gray if mixed in equal parts.
In this way, manipulating the weights wX does not affect the
brightness substantially.
Illumination provides the visual cues to recognize the
shape of the data through the luminance channel. Therefore the two chromatic channels can be used to display additional data dimensions xi . We map the diffuse components for the three cases to the same value depending on xi :
D
D
MD
l = M p = Ms = m(xi ), where m should map to isoluminant colors, not to change the illumination. The motivation for this design choice is that the chromatic channels are
suitable for visual grouping, whereas the achromatic channel serves to facilitate shape perception [War04] [KSJ95].
For example, we apply visual grouping with color mapping
in Section 5 to the covtype dataset.
The color selection presented here is just an estimate since
the perceived brightness also depends on the environment
and the calibration of the display device, and also varies between users. An approach to derive completely isoluminant
colors based on user perception on a specific device can be
found in [KRC02].
The quantity which we map color to can also be a view dec 2009 The Author(s)
Journal compilation c 2009 The Eurographics Association and Blackwell Publishing Ltd.

Figure 5: Mapping depth to color: near to red, far to blue.
Point size is adjusted according to depth. Halos are drawn
around individual samples in the foreground. Upper image:
without illumination; lower: with illumination.

pendent attribute, like depth. The application of color mapping to depth is shown in Figure 5, which helps to distinguish points having substantially different depth. Color mapping is effective even in the case of unconnected regions.
Additionally point size can also be adjusted depending on
the depth values, supporting point identification in the foreground. Drawing halos around points helps to identify individual points in low point density regions which partially
overlap. In contrast, illumination is well suited to support
shape perception in high-density regions. As stated earlier
we are focusing on improving shape perception, which can
be combined with complementary techniques like depthbased color coding.
3.7. Rendering
The data is rendered as points. We propose to use two rendering variants. The first variant uses opaque points. With depth
test enabled, just the nearest sample is visible at each sample

756

H. Sanftmann & D. Weiskopf / Illuminated 3D Scatterplots

4. Implementation
The application is implemented in C++ and uses OpenGL.
The test platform was a PC with Core 2 Quad Q6600 CPU,
4 GB DDR2 main memory, and GeForce 8800GTX GPU.
Since the calculation of the covariance matrix at each
point is computationally demanding with growing neighborhood, the application is separated into a pre-processing part
and a real-time part.
In the pre-processing step the weighted covariance matrix
is calculated for different neighborhood sizes. As neighborhood size we use powers of 2 up to 213 = 8192 samples. To
efficiently perform searching for the n nearest neighbors we
need a spatial data structure. We use an octree for its simplicity. Alternatively, a k-d tree [Ben75] could be used, as done
by Camamarano and Jensen [CJ02] for a related point search
problem in photon mapping. The algorithm has asymptotic
complexity O(Nn log(N)), where n is the neighborhood size
and N the number of samples. In our implementation preprocessing takes 52 seconds for the 800K points Lorenz attractor shown in Figures 1 and 2 with n ∈ {2i |i ∈ [0..6]}
neighborhood size.
During runtime, the system is capable of interactively
changing the size of the kernel n in Equations (2) and (3) by
selecting from the pre-calculated neighborhood sizes. Our
system also supports interactivity by efficient point rendering; for example, the rendering part constantly runs over
100 FPS with 4x multisampling enabled on a 1600×1200
viewport with data sizes up to 800K points.
Figure 6: Visualization of the Lorenz attractor with additive
blending. Upper: without illumination; lower: with illumination.

location, providing an easy to understand image. Sometimes
structures need to be examined which are occluded by other
opaque points. One way of exploring the interior is by removing occluders. Typical approaches include clipping or
cutaways [DWE03]. In Figure 4 a planar clipping geometry
is used.
The second variant renders the data as a volume with
the emission-absorption model, which is widely applied in
direct volume rendering [EHK∗ 06]. Blending is in general not commutative, therefore spatial sorting of the data
would be necessary. However, there are order-independent
blending methods that are effective for volume visualization
(see Mora and Evert [ME04]). We have chosen the additive blending model, drawing the points semitransparent and
blending all samples rasterized to the same location. Figure 6
shows the results of additive blending. The density of the
samples is clearly shown, and additional illumination provides further shape cues.

5. Examples
We have applied our visualization methods to several examples of multi-dimensional data and even example applications beyond 3D scatterplots.
The first example shows the covtype dataset from the UCI
Machine Learning repository, which is a 55-dimensional
dataset of forest cover. We use the FastMap algorithm to map
the dataset to 3-space. FastMap [FL95] maps points from
n-dimensional space to k-dimensional space (k ≤ n) with
the focus on preserving distances between points. Figure 7
shows examples of the 3D scatterplot visualization, where
the four wilderness areas are mapped to different colors.
The two images in Figure 7 compare scatterplot visualization with and without illumination. This comparison demonstrates that illumination substantially improves the perception of the surface shapes surrounding the different clusters.
The animation in the accompanying video further improves
spatial perception by adding motion parallax.
The next example illustrates 3D scatterplots that can be
used for the design of 3D transfer functions in direct volume visualization. According to Kniss et al. [KKH02], the
first and second derivatives of 3D scalar fields allow for a
better design of transfer functions. However, in their paper,
c 2009 The Author(s)
Journal compilation c 2009 The Eurographics Association and Blackwell Publishing Ltd.

H. Sanftmann & D. Weiskopf / Illuminated 3D Scatterplots

757

Figure 7: Scatterplot showing the covtype dataset mapped to
3-space by the FastMap algorithm. Colors represent different wilderness areas. Left: without illumination; right: with
illumination.

Figure 8: Bucky-ball dataset, showing the first and second
derivatives over the scalar values (green, blue, and red axes
respectively).

they only show 2D scatterplots (in fact, 2D histograms), but
not the full 3D structure of the data distribution. Figure 8
and the accompanying video illustrates the 3D scatterplot of
the “bucky-ball” dataset, a typical test dataset in volume visualization with some 2M voxels. With illuminated 3D scatterplots the three quantities can be displayed simultaneously.
In particular, the two “branches” of the data distribution with
different signs of the second derivative become visible only
in the 3D scatterplot.
Another application of 3D scatterplots has recently been
published by Elmqvist et al. [EDF08]. They use 3D scatterplots to animate between 2D scatterplots and navigate
through a scatterplot matrix. This approach could also benefit from illuminated 3D scatterplots by better spatial and
shape perception, as illustrated in Figure 9 and in the accompanying video.
Finally, we provide another example that shows that our
technique can be applied to point data that does not originate from a scatterplot. Figure 10 depicts a subset of the
astrophysical Virgo dataset consisting of 925K points. The
dataset was rendered with additive blending. The dataset has
c 2009 The Author(s)
Journal compilation c 2009 The Eurographics Association and Blackwell Publishing Ltd.

Figure 9: Several time steps from an animation displaying
the transition between two scatterplot displays. The buckyball dataset is visualized without illumination (left) and with
illumination (right). The top image shows the first derivative
and the scalar value. The bottom image shows the second
derivative and the scalar value.

no large structures where lighting would be beneficial. Regions where stars are linearly or planarly structured can be
distinguished based on color corresponding to the classification.
6. Conclusions and Future Work
We have shown how 3D scatterplots can be improved by the
extraction and illumination of linear, planar, and volumetric
structures. Our technique is suitable for highlighting structures in dense scattered data. It relies on the presence of
structures and on a sufficiently high density of samples to
display smoothly shaded structures, which supports the user
in inferring shape from shading. We have shown how our
technique can be combined with existing ones, like blending, color mapping, halo rendering, linked views, or scatterplot matrix navigation.

H. Sanftmann & D. Weiskopf / Illuminated 3D Scatterplots

758

Rolling the dice: Multidimensional visual exploration using scatterplot matrix navigation. IEEE Transactions on Visualization
and Computer Graphics 14, 6 (2008), 1141–1148.
[EHK∗ 06] E NGEL K., H ADWIGER M., K NISS J. M., R EZK S ALAMA C., W EISKOPF D.: Real-Time Volume Graphics. A K
Peters, Ltd., 2006.
[ET08] E LMQVIST N., T SIGAS P.: A taxonomy of 3D occlusion
management for visualization. IEEE Transactions on Visualization and Computer Graphics 14, 5 (2008), 1095–1109.
[FL95] FALOUTSOS C., L IN K.-I.: Fastmap: A fast algorithm for
indexing, data-mining and visualization of traditional and multimedia datasets. In Proceedings of the ACM SIGMOD Conference
(1995), pp. 163–174.
[HLE04] H OPF M., L UTTENBERGER M., E RTL T.: Hierarchical
splatting of scattered 4D data. IEEE Computer Graphics and
Applications 24, 4 (2004), 64–72.

Figure 10: Virgo dataset, rendered with additive blending.
Green, red, and blue colors are used for linear, planar, and
spherical structures respectively. Lighting is disabled.

In future work, a user study could be conducted to quantify the effectiveness of illuminated 3D scatterplots for typical applications. Another area of future work could investigate techniques for the automatic neighborhood size estimation, which is strongly dependent on which structures the
users want to be highlighted. Furthermore, the actual rendering process could be improved. While rendering with blending the opacity of the samples plays an important role; different structures could be highlighted by weighting samples according to their category. Finally, different blending modes,
known from volume rendering, could also be investigated.
References
[Ban94] BANKS D. C.: Illumination in diverse codimensions.
In Proceedings of the ACM SIGGRAPH Conference (1994),
pp. 327–334.
[Bec97] B ECKER B. G.: Volume rendering for relational data. In
Proceedings of the IEEE Symposium on Information Visualization (1997), pp. 87–90.
[Ben75] B ENTLEY J. L.: Multidimensional binary search trees
used for associative searching. Communications of the ACM 18,
9 (1975), 509–517.
[Bli77] B LINN J. F.: Models of light reflection for computer synthesized pictures. In Proceedings of the ACM SIGGRAPH Conference (1977), pp. 192–198.
[CJ02] C AMMARANO M., J ENSEN H. W.: Time dependent photon mapping. In Proceedings of the Eurographics Workshop on
Rendering (2002), pp. 135–144.
[DDG88] D ONOHO A. W., D ONOHO D. L., G ASKO M.: MacSpin: dynamic graphics on a desktop computer. IEEE Computer
Graphics and Applications 8, 4 (1988), 51–58.
[DWE03] D IEPSTRATEN J., W EISKOPF D., E RTL T.: Interactive cutaway illustrations. Computer Graphics Forum 22 (2003),
523–532.
[EDF08]

E LMQVIST N., D RAGICEVIC P., F EKETE J.-D.:

[KB04] KOBBELT L., B OTSCH M.: A survey of point-based techniques in computer graphics. Computers & Graphics 28 (2004),
801–814.
[KKH02] K NISS J., K INDLMANN G., H ANSEN C.: Multidimensional transfer functions for interactive volume rendering.
IEEE Transactions on Visualization and Computer Graphics 8,
3 (2002), 270–285.
[KRC02] K INDLMANN G., R EINHARD E., C REEM S.: Facebased luminance matching for perceptual colormap generation.
In Proceedings of the IEEE Conference on Visualization (2002),
pp. 299–306.
[KSH04] KOSARA R., S AHLING G. N., H AUSER H.: Linking
scientific and information visualization with interactive 3D scatterplots. In Proceedings of WSCG (2004), pp. 133–140.
[KSJ95] K ANDEL E. R., S CHWARTZ J. H., J ESSELL T. M.: Essentials of Neural Science and Behavior. Appleton & Lange,
1995.
[KW99] K INDLMANN G., W EINSTEIN D.: Hue-balls and littensors for direct volume rendering of diffusion tensor fields.
In Proceedings of the IEEE Conference on Visualization (1999),
pp. 183–189.
[ME04] M ORA B., E BERT D. S.: Instant volumetric understanding with order-independent volume rendering. Computer Graphics Forum 23, 3 (2004), 489–497.
[PKH04] P IRINGER H., KOSARA R., H AUSER H.: Interactive
focus+context visualization with linked 2D/3D scatterplots. In
International Conference on Coordinated and Multiple Views in
Exploratory Visualization (2004), pp. 49–60.
[RE04] R EINA G., E RTL T.: Volume visualization and visual
queries for large high-dimensional datasets. In Proceedings of the
Eurographics/IEEE VGTC Symposium on Visualization (2004),
pp. 255–260.
[SBS05] S CHALL O., B ELYAEV A., S EIDEL H.-P.: Robust filtering of noisy scattered point data. In Proceedings of the
Eurographics/IEEE VGTC Symposium of Point-Based Graphics
(2005), pp. 71–144.
[War04] WARE C.: Information Visualization: Perception for Design, 2nd ed. Morgan Kaufmann, 2004.
[WPG∗ 97] W ESTIN C.-F., P ELED S., G UDBJARTSSON H.,
K IKINIS R., J OLESZ F. A.: Geometrical diffusion measures
for MRI from tensor basis analysis. In Proceedings of ISMRM
(1997), p. 1742.
[ZSH96] Z ÖCKLER M., S TALLING D., H EGE H.-C.: Interactive
visualization of 3D-vector fields using illuminated stream lines.
In Proceedings of the IEEE Conference on Visualization (1996),
pp. 107–113.

c 2009 The Author(s)
Journal compilation c 2009 The Eurographics Association and Blackwell Publishing Ltd.

