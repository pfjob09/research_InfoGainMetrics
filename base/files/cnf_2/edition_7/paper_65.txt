Volume 28 (2009), Number 2

EUROGRAPHICS 2009 / P. Dutré and M. Stamminger
(Guest Editors)

Dominant Texture and Diffusion Distance Manifolds
Jianye Lu

Julie Dorsey

Holly Rushmeier

Computer Graphics Group, Yale University

Abstract
Texture synthesis techniques require nearly uniform texture samples, however identifying suitable texture samples
in an image requires significant data preprocessing. To eliminate this work, we introduce a fully automatic pipeline
to detect dominant texture samples based on a manifold generated using the diffusion distance. We define the
characteristics of dominant texture and three different types of outliers that allow us to efficiently identify dominant
texture in feature space. We demonstrate how this method enables the analysis/synthesis of a wide range of natural
textures. We compare textures synthesized from a sample image, with and without dominant texture detection. We
also compare our approach to that of using a texture segmentation technique alone, and to using Euclidean, rather
than diffusion, distances between texture features.
Categories and Subject Descriptors (according to ACM CCS): I.3.7 [Computer Graphics]: Computing
Methodologies—Three-dimensional graphics and realism Color, shading, shadowing, and texture

1. Introduction
Texture describes appearance that looks homogeneous at
large scales but random at small scales and has the commonly accepted characteristics of locality, repetition, and
randomness. Texture has found widespread use in realistic
appearance modeling and synthesis in computer graphics
[DRS08]. However, not all images are suitable as a source
for texture samples: some input images have extraneous elements that are not a part of target textures or that have very
distracting features; some input images have variations that
depend on the environment or that are designed by a user.
A uniform texture is desired especially when texturing 3D
objects. Spatial variations in the object texture should be under the designer’s control (e.g. spelling out the word “I3D”
with flowers in the grass in Fig. 10 of [Ash01]), or should
be computed to be consistent with variations in shading and
shadowing, when the object is illuminated. All these issues
can be summarized into one key problem: given a source image, how can we identify patches that are suitable as texture
samples?
In previous work, users were required to carefully prepare the texture sample image. This can be a tedious trialand-error process, and requires insight into the texture synthesis process to identify an appropriate texture sample size
[KW07], as well as to eliminate areas not suitable for use.
c 2008 The Author(s)
Journal compilation c 2008 The Eurographics Association and Blackwell Publishing Ltd.
Published by Blackwell Publishing, 9600 Garsington Road, Oxford OX4 2DQ, UK and
350 Main Street, Malden, MA 02148, USA.

To address this problem, we extract the dominant texture,
a large group of homogeneous texture elements, from the
input image. We use pixels grouped in small patches as texture elements (referred to as “texels” hereafter) and study
their distribution in feature space based on a simple observation: variations within dominant texels are much smaller
than those between a dominant texel and an outlier; in other
words, elements of dominant texture are relatively much
closer to each other. When a single texture image contains
myriad observations of such texture elements, we can detect dominant texture by a data-driven approach without any
prior knowledge. Moreover, we note that dominant texture
elements are easily identified by humans despite their complicated patterns. We conjecture that such texel points of interest lie on a low-dimensional manifold within the original
high-dimensional space, similar to many other perceptionrelated applications. Therefore, we suggest the diffusion distance, a non-linear approach in manifold construction, to
better detect such geometric structure.
In this paper, we propose a pipeline that automatically
determines texture patch size and the collection of texture
patches for any given source image. Referring to Figure 1,
starting from a texture image, we construct a binary mask
of dominant texture using manifold analysis based on diffusion distance. Comparing texture synthesis results with and

668

J. Lu, J. Dorsey, H. Rushmeier / Dominant Texture and Diffusion Distance Manifolds

(a) source image (b) dominant texture mask (c) synthesis with full image (d) synthesis with dominant texture

Figure 1: Given a texture image (a), we construct a binary image that masks dominant texture based on manifold density
and diffusion distance to the kernel texel (b). Compared to texture synthesis with full source image in (c), synthesis only with
dominant texture in (d) gives us more homogeneous appearance and less distraction.

without such a mask side-by-side, we can see that dominant texture masks greatly improve the synthesis quality. Our
method eliminates the need for client-side parameter tweaking and input image editing, both of which are essential in
order for most current techniques to achieve the desired results. We make the following key contributions:
• apply diffusion distance manifolds to natural texture analysis and propose practical implementations to enable their
full potential;
• detect texture patch sizes and extract the collection
of texture patches used for conventional texture analysis/synthesis approaches;
• present a pipeline that is fully automatic and robust for a
wide range of natural texture images that previous work
has failed to address.
The rest of this paper is organized as follows: first,
we review related work in texture analysis/synthesis and
manifold-based analysis in Section 2; next, we detail our
manifold construction with diffusion distance in Section 3,
and formally define the dominant texture extraction problem in Section 4; then, we detail our pipeline in Section 5,
introduce a practical implementation in Section 6; then, we
demonstrate and compare experimental results using wide
range of natural texture samples with other methods in Section 7; finally, we conclude with a summary and future work
in Section 8.
2. Related Work
Our work is related to previous research in texture analysis/synthesis and manifold-based data analysis.
2.1. Texture Analysis and Synthesis
Considerable work has been devoted to texture-related research, including texture classification, which retrieves similar samples in the training set given any texture image, texture segmentation, which identifies differently textured areas
in one image, and example-based texture synthesis, which

generates a large patch of texture similar to a small input
sample. Much of this work adopted parametric texture models and considered either global or local similarity for texture
clustering [HB95, Bon97, LM01, FB03]. These approaches
rely on predefined texture features, about which we have
limited knowledge, and can only be applied to certain types
of textures. Later, non-parametric methods were proposed
for texture synthesis: a partially synthesized neighborhood
is compared to given examples based on the Markov Random Field (MRF) assumption, and the best match is used
as new synthesis pixel [EL99]. Combined with subsequent
improvements, such methods have proven well suited for efficient and high-quality texture synthesis (see [KW07] for a
comprehensive overview). However, these methods do not
validate MRF properties of the input samples before synthesis, and thus fail on images with complicated natural patterns
without careful preparation.
Our system combines the advantages of parametric and
non-parametric methods by inserting dominant texture extraction before MRF-based synthesis. Unlike previous parametric texture models, we use raw color pixel values of texture patches as our texture feature, and construct diffusiondistance-based manifolds to better examine texture homogeneity, which has proven to work well for a wide range of
natural textures without a priori knowledge. Detected dominant textures are fed to conventional non-parametric synthesis methods, such as Image Quilting [EF01], which we apply
in this paper. Dominant textures can also be used by other
texture analysis frameworks, such as Near-Regular Textures
analysis [LLH04]. We show that dominant texture detection
improves texture synthesis quality in 2D and on 3D objects.
Previous work also used masks to avoid mixing unrelated
textures. For example, Hertzmann et al. [HJO∗ 01] proposed
“texture-by-numbers” to synthesize new images based on
manually assigned labels; Zalesny et al. [ZFCG05] automatically segmented the input image into homogeneous regions with traditional gray-level co-occurrence methods before synthesis. In our work we automatically generate a dominant texture mask using raw texture patch pixel values on a
c 2008 The Author(s)
Journal compilation c 2008 The Eurographics Association and Blackwell Publishing Ltd.

669

J. Lu, J. Dorsey, H. Rushmeier / Dominant Texture and Diffusion Distance Manifolds

manifold based on diffusion distance. Other work has developed specific models to account for or to correct certain
types of texture variations. For example, Liu et al. [LLH04]
modeled geometric variations due to non-planar surfaces or
perspective viewing; Xue et al. [XWT∗ 08] modeled shading
variations as the product of reflectance and illuminance. Our
work does not rely on any prior knowledge.
2.2. Manifold-based Analysis
Manifold-based analysis considers only short-distance relationships between data points and reconstructs the global
structure by “stitching” such small pieces. Manifold models are considered more suitable for perception-related applications, where observations commonly lie only on a lowdimensional manifold in the original high-dimensional feature space [SL00]. Related approaches have been revived in
the past few years, including isometric mapping (Isomap)
[TdSL00], locally linear embedding (LLE) [RS00], diffusion maps based on diffusion distance [Laf04], and others.
These methods have been applied widely in graphics, such as
in charting in BRDF modeling [MPBM03], simplicial complexes for texture modeling [MZD05], Isomap and LLE in
appearance-space texture synthesis [LH06], and an Isomaplike approach in estimating weathering degree maps from a
single image [WTL∗ 06]. In our previous work [LGG∗ 07],
we applied diffusion maps to analyze correlation between
appearance patches and environmental contexts on a weathered surface. In this work we extend the application of diffusion maps to the identification of similar textures.
Coifman et al. showed the diffusion-maps-based methods
to be more reliable for recovering the smooth data structure
and more robust to data noise [CLL∗ 05, LKC06]. In this paper, we demonstrate their advantage in texture element modeling by showing an actual distribution of our data points,
and by comparing our dominant texture detection results
with Euclidean-distance-based analysis. This general idea is
similar to the appearance manifold described in [WTL∗ 06],
however the authors did not consider outliers in input samples. In subsequent work by Xue et al., they dealt primarily
with shading variations [XWT∗ 08]. In our approach, we apply diffusion distance instead of geodesic distance for manifold construction, use image patches as elements to better
characterize textures, and propose a fully automatic pipeline.
Pavan and Pelillo studied dominant sets in a graph using
pairwise clustering and introduced a similar algorithm to
ours [PP07]. However, their approach has a different mathematical starting point. In addition, we provide intuitive reasoning, a practical implementation, including key parameter
selection, and demonstrate results on a wide range of input
images.
3. Manifold Construction based on Diffusion Distance
To quantify how close two texels are in feature space, we
need a dissimilarity measurement. Euclidean distance, while
c 2008 The Author(s)
Journal compilation c 2008 The Eurographics Association and Blackwell Publishing Ltd.

Figure 2: Comparison between Euclidean and diffusion distances: point B and point C are equally distant from point
A in terms of Euclidean distance (highlighted in solid green
lines). Heat starting from point A reaches point B faster because of more paths connecting them (highlighted in dashed
blue lines); hence, in terms of the diffusion distance, point B
is considered “closer” to point A compared to point C.
X ⊂ RD
M ⊂ Rd
X′ ⊂ X
′
′
M ⊂ Rd
xi − x j
ε
δ(xi , x j )
wi, j
W
µ(xi )
A
hk (xi )

source patches, with cardinality N
embedded manifold
subsampled patches, with cardinality N ′ ≪ N
subsampled manifold from X ′
Euclidean distance
Gaussian kernel size
diffusion distance ∗
kernel function ∗
kernel matrix ∗
manifold density ∗
normalized heat diffusion matrix
dominant heat distribution from xk

Table 1: Summary of notation ( ∗ A superscript of (ε) is used
when the Gaussian kernel size is explicitly specified).

simple, fails to recover the geometric structure of lowdimensional manifolds embedded in high-dimensional feature space, where perception-related data usually lie [SL00].
Instead, we use diffusion distance, a non-linear distance
measurement, which computes the distance between two
points by simulating heat diffusion and recording the time
of traversal based on random diffusion. Figure 2 compares
Euclidean distance and diffusion distance measurements on
a “dumbbell-shaped” data set. The diffusion distance considers the width of the region connecting two points, in a
sense the number of paths connecting the two points. The
diffusion distance is demonstrated to better preserve structure smoothness and is more robust to both outliers and small
disturbances within the graph structure [CLL∗ 05].
A formal definition of the diffusion distance is as follows
(see Table 1 for a summary of math notation): given data set
X ⊂ RD with N points, we define its N × N kernel matrix
W (ε) with entries of pairwise heat conduction function (or,
kernel function) values as
(ε)

wi, j = e−

xi −x j

2

/2ε

,

(1)

670

J. Lu, J. Dorsey, H. Rushmeier / Dominant Texture and Diffusion Distance Manifolds

where xi − x j = (∑l (xi,l − x j,l )2 )1/2 is the Euclidean distance between xi and x j , and ε is some Gaussian kernel
width. When xi and x j are far away from each other, their
heat conduction rate decreases quickly to zero, which means
heat can only diffuse between two near points. Then we normalize the kernel matrix to factor out sampling density and
apply singular vector decomposition (SVD) to project original data xi to a point yi in a new feature space RN , where the
Euclidean distance of yi − y j approximates the diffusion
distance δ(ε) (xi , x j ) in the original feature space [LKC06].
Selecting an appropriate Gaussian kernel size ε is critical to reveal geometric structure using the diffusion distance.
Coifman et al. proposed an automatic way to select ε: when
we sum up both sides of Equation 1 with respect to all i’s and
j’s, then approximate the right side with its mean value integral and with the integral in the manifold’s tangent space,
we have

log

(ε)

∑ ∑ wi j
i

j

≈

N 2 (2π)d/2
vol(M )

d
log ε +
2

,

(2)

where d is the dimension of the manifold, N is the number of
total observations on the manifold, and vol(M ) is the volume of the manifold (see [CSSS08] for details). Since ε from
(ε)
the linearity region of the curve between log(∑i ∑ j wi, j )
and log(ε) introduces the least error among approximations,
such ε best reveals the manifold structure based on diffusion distances (see Figure 3 for an example). This guideline
makes selecting ε more efficient since we do not rely on prior
knowledge of our data set or brute-force trials. Moreover, we
estimate the manifold dimension d based on the slope of that
linearity region.
8

10

7

sum( W )

10

6

←ε

10

max

←ε

5

min

= 10^(−2.0) = 0.0100

4

−6

−4

10

−2

10
ε

(3)

where A’s entries are defined as ai, j = wi, j / ∑ j wi, j to normalize the outgoing degrees for heat transition, and (·)i is
the i-th component of a vector. This value measures the heat
accumulation at point xi coming from xk through all possible connections and thus qualitatively approximates the
diffusion distance δ(xi , xk ): the higher the value of hk (xi ),
the closer these two points are. For τ selection, we use
dN (1/d) , which is large enough to propagate heat to neighboring points but not to reach the heat equilibrium (where
all texels hold the same amount of heat). In this paper, we
use this measure to simplify our diffusion distance estimation without explicitly computing the manifold.
4. Dominant Texture and the Texel Manifold
To build up texels for manifold construction, we first apply
the 2D Fourier transform to the image and detect periodicity
along every 45 degrees in frequency domain. The strongest
periodicity response is used to estimate the texture patch
size. This scheme is particularly important for regularly
structured patterns. Unlike some previous work, we split the
source image into overlapping patches with step size 1 along
each direction, providing dense samples that are critical for
non-linear manifold reconstruction, and partly compensating for possible inaccuracy in patch size estimation usually found in images of natural textures. Such patches are
then expanded into high-dimensional feature vectors with
all pixel values. We construct a graph using texel vectors
as nodes and kernel function values as weights over edges
between each pair of texels.
Explicit computation of diffusion distances between
dense samples is impracticable in our pipeline. Instead, we
use two attributes of texels on the manifold to identify texels
of interest:

10

10

hk (xi ) = Aτ χk i ,

= 10^(−1.6) = 0.0251

slope = d/2 = 2.3974 ( d ≈ 5 )
10

Explicit construction of the manifold requires expensive
computation, including SVD on a large kernel matrix. If we
are only interested in diffusion distances among certain data
points, the diffusion framework provides an alternative measure by a Markov random walk [CLL∗ 05]: Suppose one unit
of heat starts diffusing from data point xk at time 0. In order to represent the heat distribution, we use a vector χk of
length N whose element is 1 only at the k-th component and
0 everywhere else. After time τ, the heat distribution at point
xi is defined as

0

10

2

10

Density µ(xi ): measures local compactness of a texel xi on
the manifold and can be estimated using the sum of weights
over all edges connecting xi
(ε)

Figure 3: Gaussian kernel size selection from the linearity
(ε)
region on a curve between log(∑i ∑ j wi, j ) and log(ε). See
Figure 1(a) for input texture image.

µ(ε) (xi ) = ∑ wi, j .

(4)

j

Dominant heat distribution hk (xi ): as defined in Equation 3, approximates the diffusion distance δ(xi , xk ). When
c 2008 The Author(s)
Journal compilation c 2008 The Eurographics Association and Blackwell Publishing Ltd.

J. Lu, J. Dorsey, H. Rushmeier / Dominant Texture and Diffusion Distance Manifolds

(a) Abstract graph showing texels in feature space.

(c) Texels in feature space from real data.

671

(b) Abstract illustration of texel classification.

(d) Texel classification based on real data.

Figure 4: Texel classification: (a) and (b) show abstracted graphs of the texel distribution in feature space and classification in
a space spanned by density and dominant heat distribution; (c) and (d) show corresponding graphs from real data (See Figure 1
for the source image). To visualize texels in high-dimensional space in (c), we project them onto a subspace spanned by the first
three principal components using PCA; the color bar on the right shows the data density: red for high densities, blue for low
densities; see http://graphics.cs.yale.edu/DominantTexture/ for animated 3-D view. We can see a large dense group
on the right (corresponding to the brick wall, later classified as Type 0), a small dense group on the left (corresponding to part
of the pipe, later classified as Type I), a few points connecting these two groups with medium densities (later classified as Type
II), and many sparse points with low densities scattered around (later classified as Type III).

xk is selected from the dominant texture set, this value also
implies how probable it is that xi belongs to the same set.
Based on these two attributes, we classify texels into four
different types, as follows (see Figure 4):
• Texel Type 0 (Dominant Texels): texels that form the
dominant texture. These texels have high densities with
support from near neighbors, cover the main region in the
image, and have high dominant heat distributions;
• Texel Type I (Small-Group Outliers): texels that form
some other texture groups covering relatively small regions in the image. These texels might still have high
densities if their internal variations are sufficiently small.
However, their dominant heat distributions would be significantly lower than those of texel type 0;
• Texel Type II (Bridging Outliers): texels connecting
Type 0 and Type I groups. Such “texel bridges” are usually
very narrow compared to the size of other texel groups,
hence densities are low. On the other hand, they are closer
c 2008 The Author(s)
Journal compilation c 2008 The Eurographics Association and Blackwell Publishing Ltd.

to the main texel group and have higher dominant heat
distributions compared to texel type I;
• Texel Type III (Scattered Outliers): noise scattered
throughout the feature space, far from other texels. These
have low densities and dominant heat distribution.
Although only dominant texels (Type 0) are explicitly detected and used in our pipeline, texel classification as outlined above provides a complete picture of texel characteristics from natural texture images for further study.
5. Pipeline
With the diffusion distance manifold we built in Section 4,
we propose the following pipeline for dominant texture detection, with the data flow shown in Figure 5.
Step 1: Texture granularity detection: Given a source image I , we apply the 2-D Fourier transform and estimate the
proper patch size n p in frequency domain.

672

J. Lu, J. Dorsey, H. Rushmeier / Dominant Texture and Diffusion Distance Manifolds








source image

granularity detection

texture patches

texels in feature space

O

 
 OO
  
  OO
  
 
O
O
  
 
O
O
 
O   
O
  
 
O
O  
 
O
O


kernel matrices

log-log curve
for ¦-selection

repeat until main texels found

O


O




O


O 


O

dominant texture
mask

texel
types/labels

texel
classification

dominant heat
distribution

texel density

kernel matrix

Figure 5: Flow chart of dominant texture detection.

Step 2: Texel vectors preparation: We split I into N
overlapping patches of size n p × n p centered around each
pixel, then expand such patches into D-dimensional vectors
{xi } ⊂ RD , where D = 3n2p for a color texture image.
Step 3: Kernel matrices computation: We estimate pair(ε)
wise kernel function values wi, j between texels using a series of predefined ε candidates (see Equation 1), then con(ε)
struct a series of kernel matrices WN×N .
Step 4: Kernel size selection: We plot a curve between
(ε)
log(∑i ∑ j wi, j ) and log(ε), then select ε around the linearity region and estimate the manifold dimension d based on
the slope of that linearity region.
Step 5: Texel density estimation: We estimate the density
µ(xi ) for each texel based on the kernel size ε (see Equation 4).
Step 6: Dominant Texels Detection: We first select xk with
the highest density as our “seed” texel, then scatter all texels
in a 2-D plane spanned by their densities µ(xi ) and dominant heat distribution values hk (xi ) with respect to xk (see
Figure 4(d)). If texels with high densities and high dominant
heat distribution values (those in the top right quadrant) consist of more than 40% of all texels, they are considered as
dominant texels (Type 0). Otherwise, they are considered as
small-group outliers (Type I), and are removed along with
texels with high heat distribution values but low densities
(those in the top left quadrant, as bridging texels, Type II).
We will re-run this step with all remaining texels until we
detect the dominant texel group.
In this step, thresholds for density and dominant heat diffusion are estimated automatically (see the vertical and horizontal red lines in Figure 4(d)): we order density values from
low to high, then select the valley between the first and sec-

ond peaks on the smoothed histogram as density threshold;
if no second peak is detected, we use the value of the 0.2quantile point instead. For the heat value threshold, we build
the smooth histogram in a similar way, then select the first
valley beyond the 0.4-quantile point as the threshold, making sure the size of main texel group is at least 40% of the
image; if no such valley is found, we simply consider all remaining texels as scattered outliers (Type 0).
Step 7: Dominant texture mask: If no dominant texels are
detected, we will reject the source image. Otherwise, we create a binary dominant texture mask Imask by first placing
1’s at the centers of dominant texels on the source image
and 0’s elsewhere, then applying a convolution of this binary image with a n p × n p square block of 1’s. Imask masks
“good pixels” that compose the dominant texture and is used
along with source image I in conventional texture synthesis
schemes.
6. Practical Implementation
Similar to other data-driven approaches, we need a large
amount of data to construct a reliable estimate about the data
distribution without prior knowledge. However, direct application of the pipeline above is still limited by computational
resources. We use several techniques to make our pipeline
practical in terms of space and time complexity.
6.1. Linear Dimensionality Reduction
We notice from Equation 1 that diffusion distances depend
only on the estimation of Euclidean distances, which can
be well approximated with linear dimensionality reduction.
We first apply principal component analysis (PCA) on our
source texel set to reduce its dimension to D′ ≪ D, where
c 2008 The Author(s)
Journal compilation c 2008 The Eurographics Association and Blackwell Publishing Ltd.

J. Lu, J. Dorsey, H. Rushmeier / Dominant Texture and Diffusion Distance Manifolds

99.9% of the energy is still preserved. Thus, diffusion distances in Equation 1 can be estimated in a significantly
lower-dimensional space without losing much accuracy.

6.2. Data Subsampling
Suppose our original data set X with N points is oversampled from a d-dimensional manifold M , and a subset
X ′ ⊂ X with N ′ points (N ′ ≪ N) is still sufficient to cover
M . We have the following equation for the Gaussian kernel
sizes ε for the original data set and ε′ for the simplified data
set,
N ′ /N = ε/ε′
′

d

.

(5)

′

If we approximate d by d based on X (see Equation 2), then
we have an approximation of ε for M
εapprox = ε′ N ′ /N

1/d ′

.

(6)

In our pipeline, we randomly select a small subset X ′ ⊂ X
with cardinal number N ′ ≪ N, estimate ε′ and d ′ based
on Equation 2, then estimate the manifold density of X
based on diffusion distances with respect to the subset X ′
based on εapprox in Equation 6. Similar ideas can be found
in [dST04], where landmark points are used to accelerate
multi-dimensional scaling. A small subset X ′ can greatly accelerate the computation but tends to over-simplify M ; thus,
d cannot be well approximated by d ′ , and we have only a
poor estimation of ε for M . For our test data, an empirical
number N ′ ∼ N 0.7 balances accuracy and acceleration very
well; we only need to estimate N × N ′ pairs of diffusion distances instead of N 2 pairs.

6.3. Graph Sparsification
During heat diffusion simulation, we need to maintain a matrix A of size N × N (see Equation 3), which is too large for
memory. In fact, a texel will only have a few neighbors with
non-negligible connection in terms of the kernel function
defined in Equation 1. Therefore, we consider only k nearest neighbors (k ≪ N) for each texel based on approximate
nearest neighbor searching (ANN) [AMN∗ 98], resulting in a
sparse diffusion matrix A with k × N non-zero entries. After
graph sparsification, the right hand side of Equation 3 can be
rewritten as (A · · · (A(Aχk )))i and computed efficiently as a
series of multiplications between a sparse matrix and a vector. In our implementation, a conservative k = log2 N balances efficiency and accuracy very well.

7. Results
We built our pipeline on a Windows platform with a
2.80GHz CPU and 2GB memory. We implemented steps
2 and 3 in C++ because these steps involve large amounts
c 2008 The Author(s)
Journal compilation c 2008 The Eurographics Association and Blackwell Publishing Ltd.

673

of simple data processing and we were concerned with efficiency. We implemented other steps in Matlab for better module flexibility and result visualization. For a general
color image of size 125 × 94 and patch size 11, it takes approximately 3 minutes for image patch preprocessing, 15
minutes for kernel matrix computation, and less than 10 seconds on dominant texture detection based on density and
dominant heat distribution.
7.1. Dominant Texture Detection Results
We apply our pipeline to a wide range of natural textures
that contain different extraneous elements, including artificial objects, deterioration patterns like scratches and cracks,
flow patterns, shadows, rust, dirt, biological growth, and others (see Figure 6) . All these examples are taken from natural scenes with rich texture information, but are difficult
to use as texture samples without some preprocessing. Our
pipeline detects dominant textures in most of these cases
without prior knowledge.
7.2. Comparison of Texture Synthesis with and without
Dominant Texture Detection
We generate binary masks for dominant textures based on
the detection results in Section 7.1, then synthesize large 2-D
texture patches from these input images using Image Quilting [EF01]. We compare synthesis results with and without
such a mask side-by-side in the first two columns in Figure 6.
Our masks remove outliers while still preserving rich variations of the dominant texture. In other words, our pipeline
automatically builds up a “clean” texture sample image for
synthesis purposes, a step which is missing in all previous
non-parametric synthesis approaches.
One might argue that those outliers sometimes enrich texture variations and can be viewed as part of the texture pattern. However, there are two important reasons that necessitate dominant texture detection: first, structured elements in
the input image (such as pipes and windows in the first two
examples in Figure 6) do not follow MRF-assumption and
cannot be repeated randomly; second, global texture variations are highly correlated to the environment and cannot be
synthesized with local neighborhoods. Simple repetition of
such patterns is very distracting (see the last two examples
in Figure 6). Our approach can be viewed as a form of preprocessing for other synthesis approaches oriented toward
global variations [WTL∗ 06, LGG∗ 07], where global variations over uniform textures under user control are possible.
To validate the second point, we synthesize textures from
2-D images onto 3-D surfaces by first splitting and flattening
3-D meshes into 2-D patches then synthesizing on the texture atlas. We compare synthesis results with and without the
dominant texture mask in Figure 7. When using full source
images, we cannot guarantee consistency between appearance and geometry, or object shadow directions with scene

674

J. Lu, J. Dorsey, H. Rushmeier / Dominant Texture and Diffusion Distance Manifolds

(a) source image

(b) diffusion distances

(c) inverse Euclidean distances

(d) nCut

Figure 6: We compare dominant texture detection and corresponding texture synthesis results of four image samples. From left
to right are synthesis with (a) full source image, (b) dominant texture based on diffusion distances, (c) dominant texture based
on inverse Euclidean distances (see Section 7.3), and (d) the largest texture segment from nCut (see Section 7.4).
c 2008 The Author(s)
Journal compilation c 2008 The Eurographics Association and Blackwell Publishing Ltd.

J. Lu, J. Dorsey, H. Rushmeier / Dominant Texture and Diffusion Distance Manifolds

675

Figure 7: Texture synthesis on 3D objects. From top to bottom: source texture image and dominant texture mask, synthesis with
full source texture image (note the inconsistency between texture and geometry, and between shadows from the texture map and
those from scene relighting), and synthesis with only dominant texture.

illumination. Realistic renderings can only be achieved by
post-processing scenes with “clean” textures as shown at the
bottom of Figure 7.
7.3. Comparison with Euclidean-Distance-based
Methods
To examine the value of using diffusion distances, we replace the kernel function in Equation 1 with the inverse of
Euclidean distance, as follows

wi, j =

1
.
xi − x j

(7)

We compare both detection results side-by-side in the second and the third columns in Figure 6. In most cases, diffusion distance manifolds provide more accurate detection results with more good texel candidates for texture synthesis.
7.4. Comparison with Texture Segmentation
To examine the value of building the texel manifold, we also
compare our dominant texture detection results with image
segmentation results from Multiscale Normalized Cuts Segmentation [CBS05] with two segments in the rightmost column in Figure 6. We note that unlike our approach, nCut is
c 2008 The Author(s)
Journal compilation c 2008 The Eurographics Association and Blackwell Publishing Ltd.

not completely automatic: the user must specify the number
of texture segments. In general, their results tend to preserve
large areas of uniform texture, usually missing small isolated outliers or further splitting uniform areas into smaller
patches. Again, our pipeline gives us more accurate detection results.
7.5. Failure Cases
Our pipeline gives poor results for two types of cases (see
Figure 8). Diffusion distance manifolds tend to connect texel
groups with smooth and broad transitions and therefore cannot correctly respond to such images; our pipeline also fails
for complicated crack patterns that have rich variations in
scale, orientation, and gap sizes. To our knowledge, such
patterns have not yet been well addressed by any data-driven
approach.
8. Conclusion and Future Work
In this paper, we address the problem of dominant texture
detection in texture modeling and synthesis. We construct
a graph with texture elements and a kernel function, then
propose an automatic pipeline to detect the dominant texture using diffusion distance with acceleration techniques.
Experimental results show that our system covers a wide
range of natural texture samples without domain knowledge.

676

J. Lu, J. Dorsey, H. Rushmeier / Dominant Texture and Diffusion Distance Manifolds
[EL99] E FROS A. A., L EUNG T. K.: Texture synthesis by nonparametric sampling. In ICCV ’99: Proceedings of the International Conference on Computer Vision - Vol 2 (1999), IEEE Computer Society, pp. 1033–1038.

Figure 8: Failure samples with dominant texture masks embedded: image with smooth transition between solid and
spotted paint textures; cracks of different orientation and
gap sizes.

All source data and additional examples can be found at
http://graphics.cs.yale.edu/DominantTexture/. In
future work, we will study the explicit shapes of texture manifolds, and apply state-of-the-art numerical methods to accommodate even larger data sets to cover more complicated
and generalized texture samples.
Acknowledgement The authors would like to thank Steven
Gortler for commenting on an early version of the paper and
Franco Woolfe for invaluable discussions. This material is
based upon work supported by the National Science Foundation under Grant No. 0528204.
References
[AMN∗ 98]

A RYA S., M OUNT D. M., N ETANYAHU N. S., S IL R., W U A. Y.: An optimal algorithm for approximate nearest neighbor searching fixed dimensions. J. ACM 45,
6 (1998), 891–923.
VERMAN

[FB03] F ISCHER B., B UHMANN J. M.: Path-based clustering
for grouping of smooth curves and texture segmentation. IEEE
Trans. Pattern Anal. Mach. Intell. 25, 4 (2003), 513–518.
[HB95] H EEGER D. J., B ERGEN J. R.: Pyramid-based texture
analysis/synthesis. In SIGGRAPH ’95: Proceedings of the 22nd
annual conference on Computer graphics and interactive techniques (1995), ACM Press, pp. 229–238.
[HJO∗ 01] H ERTZMANN A., JACOBS C. E., O LIVER N., C UR LESS B., S ALESIN D. H.: Image analogies. In SIGGRAPH ’01:
Proceedings of the 28th annual conference on Computer graphics and interactive techniques (2001), ACM Press, pp. 327–340.
[KW07] K WATRA V., W EI L.-Y.: Example-based texture synthesis. Course in SIGGRAPH, 2007.
[Laf04] L AFON S. S.: Diffusion maps and geometric harmonics.
PhD thesis, Yale University, May 2004.
[LGG∗ 07] L U J., G EORGHIADES A. S., G LASER A., W U H.,
W EI L.-Y., G UO B., D ORSEY J., RUSHMEIER H.: Contextaware textures. ACM Trans. Graph. 26, 1 (2007), 3.
[LH06] L EFEBVRE S., H OPPE H.: Appearance-space texture
synthesis. In SIGGRAPH ’06: ACM SIGGRAPH 2006 Papers
(New York, NY, USA, 2006), ACM Press, pp. 541–548.
[LKC06] L AFON S., K ELLER Y., C OIFMAN R. R.: Data fusion
and multicue data matching by diffusion maps. IEEE Trans. Pattern Anal. Mach. Intell. 28, 11 (2006), 1784–1797.
[LLH04] L IU Y., L IN W.-C., H AYS J. H.: Near regular texture
analysis and manipulation. ACM Transactions on Graphics (SIGGRAPH 2004) 23, 3 (August 2004), 368 – 376.

[Ash01] A SHIKHMIN M.: Synthesizing natural textures. In
I3D ’01: Proceedings of the 2001 symposium on Interactive 3D
graphics (2001), pp. 217–226.

[LM01] L EUNG T., M ALIK J.: Representing and recognizing the
visual appearance of materials using three-dimensional textons.
Int. J. Comput. Vision 43, 1 (2001), 29–44.

[Bon97] B ONET J. S. D.: Multiresolution sampling procedure
for analysis and synthesis of texture images. In SIGGRAPH ’97:
Proceedings of the 24th annual conference on Computer graphics and interactive techniques (1997), pp. 361–368.

[MPBM03] M ATUSIK W., P FISTER H., B RAND M., M C M IL LAN L.: A data-driven reflectance model. ACM Trans. Graph.
22, 3 (2003), 759–769.

[CBS05] C OUR T., B ENEZIT F., S HI J.: Spectral segmentation
with multiscale graph decomposition. In CVPR ’05: Proceedings
of the 2005 IEEE Computer Society Conference on Computer Vision and Pattern Recognition - Vol 2 (2005), IEEE Computer Society, pp. 1124–1131.

[MZD05] M ATUSIK W., Z WICKER M., D URAND F.: Texture
design using a simplicial complex of morphable textures. ACM
Trans. Graph. 24, 3 (2005), 787–794.
[PP07] PAVAN M., P ELILLO M.: Dominant sets and pairwise
clustering. IEEE Transactions on Pattern Analysis and Machine
Intelligence 29, 1 (2007), 167–172.

[CLL∗ 05] C OIFMAN R. R., L AFON S., L EE A. B., M AGGIONI
M., NADLER B., WARNER F., Z UCKER S. W.: Geometric diffusions as a tool for harmonic analysis and structure definition of
data: Diffusion maps. Proceedings of the National Academy of
Science 102 (May 2005), 7426–7431.

[RS00] ROWEIS S. T., S AUL L. K.: Nonlinear dimensionality
reduction by locally linear embedding. Science 290, 5500 (Dec
2000), 2323–2326.

[CSSS08] C OIFMAN R., S HKOLNISKY Y., S IGWORTH F.,
S INGER A.: Graph laplacian tomography from unknown random projections. IEEE Transactions on Image Processing 17, 10
(2008), 1891–1899.

[TdSL00] T ENENBAUM J. B., DE S ILVA V., L ANGFORD J. C.:
A global geometric framework for nonlinear dimensionality reduction. Science 290, 5500 (Dec 2000), 2319–2323.

[DRS08] D ORSEY J., RUSHMEIER H., S ILLION F.: Digital Modeling of Material Appearance. The Morgan Kaufmann Series
in Computer Graphics. Boston: Morgan Kaufmann / Elsevier,
2008.

[WTL∗ 06] WANG J., T ONG X., L IN S., PAN M., WANG C.,
BAO H., G UO B., S HUM H.-Y.: Appearance manifolds for modeling time-variant appearance of materials. ACM Trans. Graph.
25, 3 (2006), 754–761.

[dST04] DE S ILVA V., T ENENBAUM J. B.: Sparse multidimensional scaling using landmark points, 2004. Manuscript.

[XWT∗ 08] X UE S., WANG J., T ONG X., DAI Q., G UO B.:
Image-based material weathering. Computer Graphics Forum 27,
2 (Apr. 2008), 617–626.

[EF01] E FROS A. A., F REEMAN W. T.: Image quilting for texture synthesis and transfer. In SIGGRAPH ’01: Proceedings of
the 28th annual conference on Computer graphics and interactive techniques (2001), ACM Press, pp. 341–346.

[SL00] S EUNG H. S., L EE D. D.: The manifold ways of perception. Science 290, 5500 (Dec 2000), 2268–2269.

[ZFCG05] Z ALESNY A., F ERRARI V., C AENEN G., G OOL
L. V.: Composite texture synthesis. Int. J. Comput. Vision 62,
1-2 (2005), 161–176.

c 2008 The Author(s)
Journal compilation c 2008 The Eurographics Association and Blackwell Publishing Ltd.

