DOI: 10.1111/j.1467-8659.2011.01969.x

COMPUTER GRAPHICS

forum

Volume 30 (2011), number 8 pp. 2194–2207

Stroke Correspondence Construction Using Manifold Learning
Dongquan Liu1 , Quan Chen1 , Jun Yu2 , Huiqin Gu1 , Dacheng Tao3 and Hock Soon Seah1

1 Nanyang

Technological University, Singapore
University, China
3 University of Technology, Sydney, Australia
DQLIU@ntu.edu.sg, yujun@xmu.edu.cn
2 Xiamen

Abstract
Stroke correspondence construction is a precondition for generating inbetween frames from a set of key frames. In
our case, each stroke in a key frame is a vector represented as a Disk B-Spline Curve (DBSC) which is a flexible
and compact vector format. However, it is not easy to construct correspondences between multiple DBSC strokes
effectively because of the following points: (1) with the use of shape descriptors, the dimensionality of the feature
space is high; (2) the number of strokes in different key frames is usually large and different from each other and
(3) the length of corresponding strokes can be very different. The first point makes matching difficult. The other
two points imply ‘many to many’ and ‘part to whole’ correspondences between strokes. To solve these problems,
this paper presents a DBSC stroke correspondence construction approach, which introduces a manifold learning
technique to the matching process. Moreover, in order to handle the mapping between unequal numbers of strokes
with different lengths, a stroke reconstruction algorithm is developed to convert the ‘many to many’ and ‘part to
whole’ stroke correspondences to ‘one to one’ compound stroke correspondence.
Keywords: correspondence construction, inbetweening, manifold learning
ACM CCS: I.3.3 [Computer Graphics]: Picture/Image Generation—Line and curve generation; I.2.10 [Artificial
Intelligence]: Vision and Scene Understanding—Shape; I.3.4 [Computer Graphics] Graphics Utilities—Graphics
editors

1. Introduction
Today, facing challenges from being marginalized by threedimensional (3D) animation, the traditional 2D animation
industry is seeking effective ways to increase productivity.
Automatic inbetweening is regarded as one of the most important techniques to achieve this goal. However, automatic
inbetweening, which is generally composed of correspondence construction and interpolation, is still an open problem.
This is mainly because correspondence construction is difficult especially when objects in the key frames are complex
and hand-drawn. As vector-based graphics becomes more
popular, our objects are represented as vectors rather than
raster images. Hence, the correspondence construction problem for automatic inbetweening needs to correctly match
vector-based strokes which represent the corresponding
c 2011 The Authors
Computer Graphics Forum c 2011 The Eurographics
Association and Blackwell Publishing Ltd. Published by
Blackwell Publishing, 9600 Garsington Road, Oxford OX4
2DQ, UK and 350 Main Street, Malden, MA 02148, USA.

objects from the given key frames. Because the objects in
the key frames are usually complex in a real world production and we do not want to set up constraints for artists when
they draw the key frames, this stroke correspondence construction task is challenging. In Figure 1, Step 1 gives an
example of the key frames to be matched. In particular, first,
the number of strokes for the same object can be different
because artists may not use the same number of strokes to
draw the object in the different key frames. Secondly, as a
consequence of the first point, the lengths and directions of
corresponding strokes can be quite different as well. For these
two points, there exist ‘many to many’ and ‘part to whole’
mappings between strokes from different key frames. These
kinds of complicated stroke correspondences will adversely
impact the robustness and effectiveness of the subsequent interpolation process. Finally, because the objects are complex,

2194

D. Liu et al. / Stroke Correspondence Construction

2195

Figure 1: Illustration of our stroke correspondence construction method. One example of an input is given in Step 1; the data
after sampling is shown in Step 2; results of the point correspondences and stroke correspondences with highlighted lines are
shown in Step 3 and Step 4, respectively; one clustering result is given in Step 3.2 and the point correspondence within this
cluster is shown by connected lines in Step 3.3.

the number of strokes composing them is large, the relation
between strokes is complicated, for example the strokes may
be very close to each other which makes it hard to distinguish
them or there are a lot of intersections between them.
Up till now, there are several works targeting at the correspondence construction problem. First, works on animation inbetweening invariably face this problem. Some previous inbetweening approaches [CTS*06, Ree81] focus on
interpolation rather than correspondence construction, thus,
leaving this problem to the users. Approaches similar to 2D
blending [SG95, SG92] match feature points within strokes
instead of matching multiple strokes which also leave our
problem unsolved. Works such as [Kor02] proposed an automatic correspondence construction method. But the performance of these methods is not robust due to their reliance on
heuristic rules. Another group of works on correspondence
construction comes from the image processing domain. But
a large number of them [SL01, SDC09, dJB06, Low04] focus on raster images and use pure raster features which are
not applicable to our vector-based application. In the context
of 2D animation inbetweening, these methods cannot solve
the multiple stroke mapping problem. But the shape descriptors, such as shape context [BMP02, MBM05], introduced
in these methods are useful.

Targeting at the multiple stroke correspondence construction problem, in this paper, we propose a stroke correspondence construction method to deal with the matching of unequal number of DBSC [WST*04] strokes effectively. In
our method, first, feature points on the original strokes from
two key frames are generated by sampling. Then, the correspondence between feature points is built by matching them
using our DBSC shape context descriptor. Finally, the compound stroke correspondence between the two key frames
is obtained based on the feature point correspondence. In
particular, for the feature point correspondence construction,
we applied the state of art manifold learning framework—the
‘patch alignment framework’ [ZTLY09] to develop our unsupervised dimensionality reduction method. In this regard,
the original high dimensional DBSC shape context feature
space is projected to a compact subspace where similar feature points are grouped together by clustering. The final point
correspondence is built within these clusters. For the stroke
correspondence construction, we proposed a stroke reconstruction algorithm to convert ‘many to many’ and ‘part to
whole’ original stroke mapping to a ‘one to one’ compound
stroke correspondence. Thus, the interpolation quality and
robustness will be improved by this formulation of the stroke
correspondence. The main contributions of this work are
summarized later:

c 2011 The Authors
Computer Graphics Forum c 2011 The Eurographics Association and Blackwell Publishing Ltd.

2196

D. Liu et al. / Stroke Correspondence Construction

1. For feature point correspondence construction, an unsupervised dimensionality reduction method was developed
based on the manifold learning framework—the ‘patch
alignment framework’ to reduce the dimensionality of
our DBSC shape context feature space. Together with
clustering, the effectiveness of the matching is improved
because of the following reasons:
a. Via our unsupervised dimensionality reduction
method, a new low dimensional feature space, which
exploits the dimensional redundancy of original data
distribution, is obtained. This reduces computational
cost and noisy information.
b. By clustering in the new feature space, similar feature points are grouped into clusters before the final
point correspondence is built within each cluster. This
hierarchical strategy improves matching accuracy.
2. By introducing compound strokes, a new stroke reconstruction algorithm was developed to solve the matching problem between unequal numbers of strokes with
different length from two key frames. After the reconstruction, compound strokes are obtained by combining
or separating the original strokes. Therefore, the ‘many to
many’ and ‘part to whole’ mapping of original strokes are
converted to simple ‘one to one’ mapping of compound
strokes.
With the above contributions, our multiple DBSC stroke
correspondence construction method is able to effectively
match strokes from two key frames on which the artists can
draw without any constraints. Thus, together with the subsequent interpolation process, automatic inbetweening for 2D
vector based animation is handled elegantly.
The outline of the rest of this paper is as follows. In Section 2, related works on correspondence construction are
reviewed. After that, our method is introduced in detail in
Section 3. Comparisons and results are provided in Section 4.
Finally, Section 5 provides the conclusions.
2. Related Work
Research works on correspondence construction have been
published in both computer graphics and image processing
domains.
In computer graphics, besides the previously mentioned
works, such as [Kor02, SG92, SG95], on correspondence
construction for vector-based 2D animation inbetweening,
other important approaches are reviewed here. One early
work was proposed in [FBC*95], where correspondence is
manually built for a vector-based animation system.
Seah et al. [SL01] proposed a modified feature based algorithm which utilizes the optical flow method to establish
pixel correspondence between key frames. Not only has this
region-based method difficulty in maintaining the shapes of

characters, its raster representation is also not suitable for
vector-based animation. Similarly, the region-based search
method of the latest work by S´ykora [SDC09] is not applicable to our vector-based matching problem. Fiore [DFSEVR01, DFVR02] tried to use supplementary 3D information to facilitate 2D inbetweening. But these methods
only work when key frames are generated by a copy-paste
way which means artists can only create new key frames
by editing existing ones. As this constraint is too restrictive for real world production, this method is only applicable
to simple cut-out like animation. The same problem also
exists in [DF06]. Similar approaches to 2D blending, including [CTS*06] and [YF09, BBA09], are good for interpolation but not for correspondence construction. They share the
same nature of matching boundaries or inner stroke feature
points, so the multiple stroke matching problem remains unsolved. The recent work in [WNS*10] while focuses more on
the interpolation method also proposed an interactive semiautomatic matching approach targeting at very similar key
frames. Drawings are represented as graphs and matched
based on graph topology where the matching needs to be
manually initialized. As the differences in topology are not
handled, it cannot handle ‘many to many’ or ‘part to whole’
matching without considerable user interaction.
Besides the correspondence construction techniques proposed in computer animation field, works such as shape
matching, shape registration, shape alignment and shape retrieval, can be found in the image processing area [ZL04,
MCH*06]. In these approaches, correspondence construction
is regarded as a step for the subsequent matching or retrieval.
Generally, correspondence construction methods from the
image processing domain can be classified into region-based
algorithms [ZL04] and contour-based algorithms [ZL04].
Methods falling into the first category are usually designed
only for raster images to generate pixel to pixel mapping
which is not suitable for vector-based applications. The second class of methods always target at a single closed contour
which is used to describe one shape. Thus, when multiple
strokes exist, these methods cannot match them separately.
But shape descriptors such as the shape context [BMP02,
MBM05] proposed in contour-based approaches can be generalized and has been widely used in both image processing
and computer graphics areas.

3. Stroke Correspondence Construction
We formulated our multiple stroke correspondence construction solution as a four-step method: First, vectorized strokes
of two key frames are imported. Secondly, the vectorized
strokes are sampled into feature points according to their
curvature and stroke length. Thirdly, the correspondences between feature points from the two key frames are built within
clusters which are generated in a new low-dimensional feature space. In detail, every feature point is represented by a
DBSC shape context descriptor (which will be explained in

c 2011 The Authors
Computer Graphics Forum c 2011 The Eurographics Association and Blackwell Publishing Ltd.

D. Liu et al. / Stroke Correspondence Construction

Section 3.1) in the feature space. Then, our unsupervised dimensionality reduction method is utilized to generate a new
feature space with much lower dimensionality than the original feature space while preserving the relationship between
the feature points (more explanation of our ‘patch alignment framework’ based unsupervised dimensionality reduction method will be given in Section 3.2). In the new feature
space, feature points are grouped into clusters according to
similarity by the KMEANS [HK00] method. The final feature point correspondence will be built within each cluster
via the Hungarian method [PS82]. Finally, according to the
feature point correspondence, compound stroke correspondence is achieved by our stroke reconstruction algorithm
(which will be introduced in Section 3.3). In Figure 1, our
stroke correspondence construction method is illustrated.
3.1. DBSC shape context descriptor
A Disk B-Spline Curve (DBSC) [WST*04] defines the region
within a variable width curve by adding radii to the control
points in the traditional B-Spline representation. It provides
a concise and flexible way to describe a stroke with variable
width. The definition of a Disk B-Spline Curve is given in
(1) [WST*04].
n

D (t) =

Ni,p (t) Pi ; ri ,

(1)

i=0

where N i,p (t) is the ith B-Spline basis of degree
p with knot vector: [u0 , . . . , us ] = {a, . . . , a , up+1 , . . . ,
p+1

us−p−1 , b, . . . , b}, and a disk Pi ; ri is defined as: Pi ; ri

2197

Figure 2: DBSC shape context descriptor. Coloured points
represent the feature points on the DBSC strokes with variable radii.

of feature points are considered during matching. Thus, it
provides an elegant and effective descriptor for strokes with
variable widths. On the other hand, the dimensionality of the
DBSC shape context descriptor is higher than the original
shape context because its histogram is 3D. In practice, for
distance, angle and radius, the number of bins are set to 5, 12
and 3, respectively. Hence, the total dimension of the DBSC
shape context descriptor is 180.
To handle large rotation between drawings in key frames,
we introduced users’ interaction rather than applying the
solution proposed in [BMP02], which is not applicable for
our multiple stroke correspondence construction task. Based
on the users’ feedback, it is convenient and easier for them
to control their work in this manner than using complicated
rotation invariant techniques.

p+1

= {x ∈ R2 x − c ≤ ri , c ∈ R2 , ri ∈ R+ }, Pi is the control
point and ri is the control radius. More detailed explanation
of DBSC can be found in [WST*04].
The shape context [BMP02, MBM05] descriptor has been
widely used in many applications for its robustness and effectiveness. For each feature point of an object, the shape context
builds a spatial histogram which describes the distribution of
the relative positions of all the other feature points of this
object. By ordering this histogram into a vector, the feature
space where each feature vector represents one point is constructed. Because we use the DBSC representation for our
strokes, we modified the original shape context by adding the
difference in radii as one additional dimension to the original
log-polar space. Thus, this DBSC shape context becomes a
3D histogram which is illustrated in Figure 2. The distance
between two feature points P, Q from two objects is defined
as in [BMP02]
DP Q =

1
2

m

k=1

[hP (k) − hQ (k)]2
,
hP (k) + hQ (k)

(2)

where m is the number of bins and also the dimensionality
of the feature space. With the DBSC shape context, radii

3.2. Point correspondence construction via ‘Patch
Alignment Framework’ based unsupervised
dimensionality reduction
Higher dimensionality of the feature space produces more
dimensional redundancy. Therefore, for our DBSC Shape
Context feature space, an appropriate dimensionality reduction algorithm is important. Let us consider one object X
consisting of N feature points xi (1 ≤ i ≤ N) in m dimensional feature space. That is, X = [x1 , . . . , xN ] ∈ Rm×N . In
our dimensionality reduction method, the objective is to find
a mapping X → Y, which can generate a new representation Y = [y1 , . . . , yN ] ∈ Rd×N of X in the new low d dimensional feature space. The subsequent clustering step will
then perform on this new low-dimensional representation Y.
In Figure 3, an illustration of the ‘patch alignment framework’ based unsupervised dimensionality reduction method
for feature point correspondence construction is provided.
Representative dimensionality reduction algorithms can be
classified into two groups: (i) conventional linear dimensionality reduction algorithms (e.g. PCA [BHK97]), and (ii) manifold learning based algorithms (e.g. ISOMAP [TSL00], LE

c 2011 The Authors
Computer Graphics Forum c 2011 The Eurographics Association and Blackwell Publishing Ltd.

2198

D. Liu et al. / Stroke Correspondence Construction

can be found in the following way: xij can be added into xi ’s
patch, if xij is one of the k1 nearest neighbors of xi in key
frame 1, or xij is one of the k2 nearest neighbors of xi in
key frame 2. The value of k equals to k1 + k2 . The values of
k1 and k2 indicate the number of possible matching feature
points in each frame. Because these values only serve as an
initial guess for the subsequent optimization process, the performance of the whole matching algorithm is not sensitive to
their variation. Our local patch construction is illustrated in
Step 3.1 of Figures 1–3.

Figure 3: Illustration of the subspace construction via
‘patch alignment framework’.

The optimization processes of the local patch construction
and the whole alignment are given as follows. The optimization over each local patch is defined by
k

yi − yij

arg min
yi

[BN01] and LLE [RS00]). Recently, Zhang et al. [ZTLY09]
unified these popular algorithms into the ‘patch alignment
framework’, which consists of two stages: local patch construction and whole alignment. In the local patch construction
stage, different algorithms have specific optimization criteria. Each patch is built by one feature point and its related
neighbors according to the characteristics of the data and the
objective of the algorithm. In the whole alignment stage,
all part optimizations are integrated to form a consistent
global coordinate for all independent patches to achieve the
local dimensional sub-feature-space. In detail, feature point
xi and its k related feature points xi1 , . . . , xik form the local
patch Xi = [xi , xi1 , . . . , xik ] ∈ Rm×(k+1) for xi . In the local
patch construction stage, the local dimensional representation Yi = [yi , yi1 , . . . , yik ] ∈ Rd×(k+1) for each local patch Xi
is obtained. After that, all local patches are aligned together
to generate the final low-dimensional data representation via
whole alignment.
According to our requirement, we customized the ‘patch
alignment framework’ to achieve our unsupervised dimensionality reduction method by estimating all the feature
points from two given key frames and imposing discriminative information when building local patches. By combining
all the data of the two key frames, we achieve a uniform
low dimensional feature space which effectively describes
all the feature points of the two frames. By adding discriminative information, data on possible correspondence between
the feature points from different key frames are utilized to
enhance construction of local patches. This discriminative
information can be preserved during the whole optimization
process. Thus, the distribution of data in the resulting low dimensional feature space will be easier to analyse than in the
original feature space. This causes the corresponding feature
points from the two key frames to be projected closer to each
other and thus facilitating subsequent clustering. In detail,
because the local patch Xi is built by the feature point xi and
its related neighbors xi1 , . . . , xik , the discriminative information is imposed in the local patch construction by selecting
the k neighbouring feature points. The k related feature points

2

(wi )j ,

(3)

j =1

where yij , j = 1 , . . . , k, are the k connected low dimensional
data of the given xij , j = 1 , . . . , k. wi is the k dimension
column vector calculated by
(wi )j = exp(− xi − xij

2

/t),

(4)

in which xi − xij 2 is calculated as the Euclidean distance.
The optimization in Equation (3) means that points gathered
in one patch will be projected closely together in the lowdimensional feature space, so in subsequent clustering, the
points in the patch will be grouped into one cluster. Equation (3) can be rewritten as
arg min tr Yi Li YiT ,

(5)

yi

where Yi = [yi , yi1 , . . . , yik ], tr(.) is the trace operator. The
Li for each patch in our application is formulated as:
Li =

−ekT
⎡

Ik

diag(wi ) −ekT

Ik

⎤

k

⎢ (wi )j
=⎢
⎣ j =1
−wi

−wiT

⎥
⎥,
⎦
diag(wi )

(6)

in which eTk = [1 , . . . , 1]T ; and Ik is an k × k identity matrix.
After building the local patches, the global alignment can
be conducted by integrating the N patches as:
N

tr Yi Li YiT .

arg min
yi

(7)

i=1

According to the global alignment tricks in [ZTLY09], it
can be assumed that the components of the ith patch Yi =
[yi , yi1 , . . . , yik ] are selected from the global coordinates
Y = [y1 , . . . , yN ], such that Yi = YSi . Si is the selection
matrix, and (Si )pq = 1, if p = vi {q}, otherwise, (Si )pq = 0,
where vi = {i, i1 , i2 , . . . , ik } denotes a set comprising the

c 2011 The Authors
Computer Graphics Forum c 2011 The Eurographics Association and Blackwell Publishing Ltd.

2199

D. Liu et al. / Stroke Correspondence Construction

indices of the components in each patch. Then, Equation (7)
becomes
N

tr Yi Li YiT = arg min tr(Y LY T ).

arg min
Yi

i=1

Y

(8)

in which L = Ni=1 Si Li STi is the alignment matrix obtained
by an iterative procedure
L(vi , vi ) ← L(vi , vi ) + Li ,

(9)

in which i = 1 , . . . , N and the initialization is L = 0. L(vi , vi )
is the sub-matrix constructed by selecting certain rows and
columns from L according to the index set vi .
To uniquely determine Y, the constraint YY T = Id is imposed on Equation (8), where Id is a d × d identity matrix.
This optimization can be solved by using the Lagrangian
multiplier method [I.T02] and the solution can be obtained
by eigenvalue decomposition on L.
After the new representation Y in the low dimensional subfeature-space is obtained, the feature points are grouped into
clusters by the KMEANS method [HK00]. The final correspondences between the feature points are constructed within
these clusters by using the Hungarian algorithm [PS82] using
the distance given in Equation (2).
3.3. Stroke correspondence construction via
stroke reconstruction
Next, based on the obtained feature point correspondence,
our stroke reconstruction algorithm builds correspondence
of strokes which are of different number and length in two
key frames. The algorithm aims to minimize the sensitivity of point matching accuracy and establish correct stroke
matching for inbetween generation.
In practice, inbetween generation should be based on accurate matching of the strokes which describe the shapes of
objects in the drawings. Strokes representing the same part of
corresponding objects from two key frames must be matched
in order to preserve the shape of the object during inbetweening. But when artists draw key frames freely, the same part of
the corresponding objects may be composed different number of strokes with different lengths. Thus, there are ‘many
to many’ and ‘part to whole’ stroke mappings that will cause
robustness problems if they are not handled properly. As
our solution, we proposed the compound strokes to realize
optimal stroke correspondence where only ‘one to one’ mapping exists. A compound stroke consists of a list of segments
from the original strokes. Figure 4 illustrates an example
of compound stroke reconstruction. We name one key frame
as the source frame and the other as the target frame. C1s is
the original stroke in the source frame and C1t , Ct 2 , C3t are
the original strokes in the target frame. In our stroke reconstruction algorithm, the original strokes in the source frame
are checked one by one. For each original source stroke, we

Figure 4: Illustration of compound stroke reconstruction.
Cs and Ct denote source and target original strokes, Ss and
St denote source and target segments, CSs and CSt denote
source and target compound strokes.
find the best matching stroke from the target frame. Based
on this mapping, one source segment of the source stroke is
created. For example, a source segment S1s and a target segment S1t form a best match. Recursively, we can find the best
matching target segments for all the remaining segments of
the source stroke. After searching for all the source strokes,
the matching segments are grouped into a list according to
the connectivity between each other. The segments which
are of approximate G1 continuity between each other and
matched to the same original stroke are put into the same list,
for example segment S1t and S2t . Finally, we obtain a list of
matching segments that makes a compound stroke, for example segments S1t and S2t making a compound stroke CS1t . In
Figure 4, the arrows show the directions in which the strokes
were drawn. The direction of the generated compound stroke
is determined based on parameter changes along the source
stroke. For instance, when going through the points along
the source segment S3s , the parameters increase while those
of the matched points decrease on the corresponding target
segment S3t . Thus, the directions of S3t and CS2t are set to the
same as S3s .
The evaluation of a match is defined as follows:
rate =

Nt
Ns
s +
NC
NCt

· α1 +

min(Ls , Lt )
· α2 . (10)
max(Ls , Lt )

The first and the second parts are the ratio of matching
point number and the ratio of the matching segment lengths,
with respective weights α 1 and α 2 . N is the numbers of matching points, NC is the total number of feature points and L is the
length of a matching segment. s and t denote the source and
the target respectively. With this condition, segments with
relatively more matched points and of similar lengths tend to
be evaluated as a better match.
In some situation, a few segments may be partially
matched but are not evaluated as the best match. Thus,
they do not constitute any of the compound strokes. After all the strokes are processed, post processing is applied
to the remaining unmatched segments. An unmatched segment is appended to a matched segment if they meet an

c 2011 The Authors
Computer Graphics Forum c 2011 The Eurographics Association and Blackwell Publishing Ltd.

2200

D. Liu et al. / Stroke Correspondence Construction

approximate G1 continuity. Otherwise, its point correspondence is re-examined. For this unmatched segment, our
method will search all the strokes in the target key frame
for the best matching segment using the criteria in (10).
Once it is found, a new compound stroke is generated and, in
the source frame, its corresponding compound stroke is built
from the previous unmatched segment. For example, take the
monkey’s right ear in the target key frame, as shown at the
bottom of Figure 6. From the point correspondence result,
the points on the ear are matched from part of the points on
the right body contour in the source key frame. Although
the contour is already correctly matched, to allow matching
of the ear, a new pair of matched segments comprising part
of the contour in the source frame and the ear in the target
frame is set up. This handles the situation when some strokes
appear or disappear from one key frame to the other.
Our stroke reconstruction algorithm can be described by
the pseudo codes given in Algorithm 1.
Algorithm 1: Stroke reconstruction algorithm
1: for each original stroke in the source frame do
2: Get feature points on the stroke
3: Get matched points in the target frame based on point
correspondence
4: while number of unmatched source points > 0 do
5:
Find matched points with consecutive index to form
candidate matched segments
6:
Find the best matched source and target segments by
Equation (10)
7:
Record matched segments
8:
Remove matched feature points
9: end while
10: end for
11: Post-process unmatched segments
12: Construct compound strokes from segment lists

The proposed stroke reconstruction algorithm successfully
handles the problem of ‘many to many’ and ‘part to whole’
mapping of original strokes and obtains ‘one to one’ correspondence of compound strokes. Each compound stroke
is in fact a piecewise disk B´ezier curve. Inbetweens of two
piecewise disk B´ezier curves are generated using the method
by [SG95].
4. Comparisons and Results
In this section, comparisons and results on our test data and
data from real world animation are provided.
4.1. Stroke correspondence construction results
From Figures 5 to 7, stroke correspondence results on
three sets of data are given. In each figure, the upper picture

Figure 5: Stroke correspondence construction for DBSC
strokes with variable width. The upper picture shows the original strokes. The middle picture shows the feature point correspondence construction result. The bottom picture shows
the final compound stroke correspondence and user input
points.

shows the original strokes from two key frames. The middle picture shows the feature point correspondence built by
our method. The bottom picture shows the final compound
stroke correspondence. The correspondences of several pairs
of feature points are highlighted by small circles and straight
lines with arrows. Several compound stroke correspondences
are also highlighted by straight lines with arrows. In our test,
we set the dimensionality of the low feature space at 30,
the number of clusters at 10, and t = 10 000; α 1 = 0.3;
α 2 = 0.4; k1 = 5; k2 = 5. The settings of dimensionality
and cluster number are related to the complexity of the drawings in the key frames. As mentioned before, the values of
k1 and k2 serve as an initial guess for subsequent optimization. The performance of the whole matching algorithm is
not sensitive to their variation. We tested our method on a
number of real world data and it shows that the values work
for most cases except for special situations such as when
there are a lot of overlapping strokes. The setting of these parameters will need to be tuned based on multiple algorithm
running.

c 2011 The Authors
Computer Graphics Forum c 2011 The Eurographics Association and Blackwell Publishing Ltd.

D. Liu et al. / Stroke Correspondence Construction

2201

Figure 6: Stroke correspondence construction for real world
example 1. The upper picture shows the original strokes. The
middle picture shows the feature point correspondence construction result. The bottom picture shows the final compound
stroke correspondence.

In Figure 5, different numbers of strokes with variable
widths form three letters in each key frame. There are both
global transformation and local deformation between the letters in the two key frames. We handled the global transformation by letting the user indicate three points in one key frame
and the corresponding three points in the other key frame.
These three points cannot be collinear for us to recover the
global transformation. From the results, we can see that the
DBSC shape descriptor is robust to local deformation, such
as the relative height changes between the letters and the
relative location changes of stokes in letter ‘B’. The bottom
picture shows the final correspondence between compound
strokes. It can be seen that all complex correspondences between the original strokes are converted to simple ‘one to
one’ mappings of compound strokes.
In Figure 6, the correspondence construction result of one
set of data from a real world production is provided. In this
example, the number of strokes between the two key frames
is different and there is a complex correspondence between
the original strokes, for example those between the strokes
forming the main body contour, the right hand and the tail.
Moreover, the left ear of the character is not seen in the left
key frame but appears in the right key frame. Our method not
only converted all original complex correspondences to simple ‘one to one’ compound stroke mappings, but also matched

Figure 7: Stroke correspondence construction for real world
example 2. The upper picture shows the original strokes. The
middle picture shows the feature point correspondence construction result. The bottom picture shows the final compound
stroke correspondence.

the left ear in the right frame with one automatically generated compound stroke in the left frame, which is a segment of
the body contour. The advantage of this will be demonstrated
by the inbetweening result given in Figure 12(b), where the
left ear can appear automatically.
Figure 7 shows the results of a more complex real world
example where the anime character was drawn in two layers:
face layer and hair layer. The motion between these two key
frames involves 3D rotations as the character turns to its right
and a little downwards. We built the stroke correspondence
for these two layers separately. In Figure 7, the results of the
two layers are combined to save space. We can see all parts
of the character are matched correctly and the complicated
correspondences between the original strokes such as the
strokes of the strip of hair and the face contour on the right
are simplified to ‘one to one’ mapping between compound
strokes.

c 2011 The Authors
Computer Graphics Forum c 2011 The Eurographics Association and Blackwell Publishing Ltd.

2202

D. Liu et al. / Stroke Correspondence Construction

Figure 8: Stroke correspondence construction for real world
example 3. The upper picture shows the original strokes. The
middle picture shows the feature point correspondence construction result. The bottom picture shows the final compound
stroke correspondence.
Two more real world examples are given in Figures 8 and
9. These examples are also processed with the layering structure and all the strokes are correctly matched. In Figure 9,
one additional stroke in the first key frame is automatically
generated to match the right ear of the character in the second
key frame so that ‘one to one’ compound stroke mapping is
achieved as in Figure 6.
4.2. Comparisons
To demonstrate the effectiveness of our unsupervised ‘patch
alignment framework’ in subspace construction, we compared the clustering results with PCA, ISOMAP and LE.
PCA is the most widely used linear dimensionality reduction method while LE and ISOMAP are a classical manifold
learning methods. The data we used for comparison is the
face layer of our second real world example in Figure 7 where
one key frame is the front view and the other is the half-side-

Figure 9: Stroke correspondence construction for real world
example 4. The upper picture shows the original strokes. The
middle picture shows the feature point correspondence construction result. The bottom picture shows the final compound
stroke correspondence.

view of the girl character. It is a challenging example because
of the 3D rotation which causes big local changes especially
in her right eye and her nose areas.
The clustering results of our method, PCA, ISOMAP and
LE are given in Figure 10, where feature points grouped into
one cluster are highlighted with red circles. For each algorithm, three obtained clusters around the nose and the right
eye areas are shown. The setting for all the methods are as
follows: the number of clusters is 10; the dimension of the
sub-feature-space is 20. It can be seen that for the character’s right eye, PCA cluster is composed of the points in the
middle part of her eye in the front view key frame and the
points in the upper part of her right eye in the side view
key frame, as shown in Figure 10(a). ISOMAP grouped part
of her right eye into her right eyebrow cluster, as shown in
Figure 10(d). The other two clusters found by PCA show
that the corresponding points of the nose area from the two

c 2011 The Authors
Computer Graphics Forum c 2011 The Eurographics Association and Blackwell Publishing Ltd.

D. Liu et al. / Stroke Correspondence Construction

2203

Figure 10: Clustering results comparison. Each sub-figure shows one clustering result where the cluster is composed of
feature points (labelled with red circles) from both frames. From (a) to (c), the clusters are found by PCA. From (d) to (f),
the clusters are found by ISOMAP. From (g) to (i), the clusters are found by LE. From (j) to (l), the clusters are found by our
method.

key frames are not grouped correctly into one cluster, but
are glued to the character’s left eye or her left eyebrow. For
ISOMAP, it grouped several nose points with the right eye or
the face contour. As shown in Figure 10(i), LE also wrongly
grouped some nose points with the character’s right eye and
the face contour. Only our method achieved clusters which
are formed by the points from the corresponding parts of the
two key frames. The reason why PCA cannot perform well
on this data is that its linear projection is not able to find
the manifold subspace. For ISOMAP, it does not consider local information when building sub-feature-space. Comparing
our method with LE, although LE builds neighbourhood for
each point in a similar way, the discriminative information
we used is not considered in its optimization process.
Another major contribution of our work is to improve feature point matching accuracy by clustering in the obtained

low-dimensional feature space before the final point correspondence is built within clusters. Thus, in Figure 11, we
compared our point correspondence construction results with
those from matching directly in the original feature space via
the Hungarian method given in [BMP02].
In Figure 11(a)–(c), the correspondences of feature points
within the clusters built by our method are given. For comparison, the correspondence of the feature points in each front
view frame from the same clusters given in Figure 11(a)–(c)
are built again using the Hungarian method in the original feature space. The results are given in Figure 11(d)–(f).
Because of dimensional redundancy, a number of wrong correspondences were constructed by the Hungarian method. In
contrast, benefiting from prior dimensionality reduction and
clustering, the correspondences built within the clusters are
almost all perfectly matched.

c 2011 The Authors
Computer Graphics Forum c 2011 The Eurographics Association and Blackwell Publishing Ltd.

2204

D. Liu et al. / Stroke Correspondence Construction

Figure 11: Correspondence construction comparison. From (a) to (c), the feature point correspondences are built within the
clusters which are found in the low-dimensional feature space. From (d) to (f), the feature point correspondences are built in
the original feature space.

Figure 12: Generated inbetweens based on compound stroke correspondence. The first and the last pictures of each row are
key frames, and those between them are generated inbetweens.
c 2011 The Authors
Computer Graphics Forum c 2011 The Eurographics Association and Blackwell Publishing Ltd.

2205

D. Liu et al. / Stroke Correspondence Construction

Table 1: Matching accuracy of our proposed methods on some
examples.

Figure
Figure 5
Figure 6
Figure 7
Figure 8
Figure 9
Figure 13
Figure 14

No. of strokes
in Frame 1

No. of strokes
in Frame 2

% Accuracy

7
35
51
87
63
87
81

12
39
50
90
65
90
76

100
100
100
100
100
59
67

Table 2: Matching accuracy of the comparison methods on the face
layer of Figure 7.

Figure 13: Stroke correspondence construction for real
world example 3 without layering. The upper picture shows
the feature point correspondence construction result. The
bottom picture shows the final compound stroke correspondence.
4.3. Inbetweening results
Based on the obtained compound stroke correspondences,
inbetweens can be easily generated by interpolating the coordinates and radii of the DBSC control points. In Figure 12,
inbetweening results are given, where the colours are filled
after inbetweening. Benefiting from the simple ‘one to one’
compound stroke correspondence, the inbetweening results
are all correct in shape and smooth in motion. Otherwise,
the original ‘many to many’ and ‘whole to part’ stroke mappings due to the unequal number of strokes and different
stroke length will cause difficulties in interpolation, for example it will be hard to decide which pair of strokes should
be interpolated when a ‘many to one’ stroke correspondence
exists. Moreover, as shown in Figure 12(b), our method can
automatically make the left ear appear when there is no corresponding drawing in the left key frame.

4.4. Discussion
In animation production, different parts of a character are
usually separated into layers to simplify the drawing and
handle the relative movements between parts. For the examples shown previously, we also followed this practice. To
discuss the layering effect on our method, the same example
as in Figure 8 was used in Figure 13 . Here, the character is
drawn and matched in a single layer, while it is done in separate layers in Figure 8. It can be seen that are mismatches,

% Accuracy

Hungarian

PCA

ISOMAP

LE

23

47

75

67

such as in the eyes’ areas, while our method can achieve a
perfect match with layering in Figure 8. The reason is mainly
that the movements of different parts of the character are not
consistent between the key frames. The hair moves to the left
more than the eyes, the nose and the mouth. It causes a distribution change in our descriptor which affects the matching
accuracy. In Table 1, the matching accuracy of our method
on all examples is summarized. Based on the results given in
Section 4.2, we also calculated the stroke matching accuracy
for all comparison methods. In Table 2, the accuracy of the
Hungarian method, PCA, IOMAP and LE on the same data
using in Section 4.2 is provided. Here, the ground truth is the
correct correspondences set by artists.
Besides inconsistent movements of parts of a character,
sometimes the corresponding parts between the key frames
can differ quite significantly. An example is given in Figure 14 to demonstrate a limitation of our method. In the
figure, besides inconsistent movements between the hair and
the face, the structure of the hair also changed through the
two key frames as highlighted. Comparing with the results
given in Figure 6 where the missing left ear of the monkey
is mapped to a new generated stroke in another frame, the
highlighted parts here are very different in stroke number and
shape. Although we separated the character into two layers,
our method still has difficulty building correspondences between the highlighted strokes. In practice, there is actually
no ideal solution for such case. Different artists will create
different inbetweens based on their individual imagination.
Except for the highlighted parts, our method works fine for
all the other parts of this example.

c 2011 The Authors
Computer Graphics Forum c 2011 The Eurographics Association and Blackwell Publishing Ltd.

2206

D. Liu et al. / Stroke Correspondence Construction

construction, customized clustering algorithm will also be
developed instead of using the KMEANS algorithm.
Acknowledgments
The authors thank Mrs. Cao Youfang, Mr. Pham Quoc Anh
and the other members of our Computational Arts Group
for their help. This work has been supported by the National Research Foundation grant, which is administered by
the Media Development Authority Interactive Digital Media
Programme Office, MDA (IDMPO).
References
[BBA09] BAXTER W., BARLA P., ANJYO K. I.: N-way morphing for 2d animation. The Journal of Computer Animation
and Virtual World (CASA 2009), 20 (June 2009), 79–87.
[BHK97] BELHUMEUR P. N., HESPANHA Jo A. P., KRIEGMAN
D. J.: Eigenfaces vs. fisherfaces: recognition using class
specific linear projection. IEEE Transactions on Pattern
Analysis and Machine Intelligence, 19, 7 (1997), 711–720.
[BMP02] BELONGIE S., MALIK J., PUZICHA J.: Shape matching
and object recognition using shape contexts. IEEE Transactions on Pattern Analysis and Machine Intelligence, 24,
4 (2002), 509–522.

Figure 14: Stroke correspondence construction for real
world example 5. The upper picture shows the original
strokes, where the corresponding parts with big difference are
highlighted. The middle picture shows the feature point correspondence construction result. The bottom picture shows
the final compound stroke correspondence.

5. Conclusion
In this paper, a new stroke correspondence construction
method is proposed for 2D vector-based animation inbetweening. This method effectively matches DBSC strokes
under the DBSC shape context descriptor. Test results and
comparisons show that clustering in the subspace obtained
by the ‘patch alignment framework’ based unsupervised dimensionality reduction method enables our correspondence
construction method to deliver good matching performance.
Moreover, we developed the stroke reconstruction algorithm
to simplify the final stroke correspondence so that both robustness and quality of the subsequent inbetweening process
can be enhanced.
In the future, more complicated matching situations such
as strokes with overlapping parts will be investigated. To
further improve the result of the feature point correspondence

[BN01] BELKIN M., NIYOGI P.: Laplacian eigenmaps and
spectral techniques for embedding and clustering. In Advances in Neural Information Processing Systems, vol. 14.
T. G. Dietterich, S. Becker and Z. Ghahramani (Eds.). MIT
Press, Cambridge, MA, USA (2001), pp. 585–591.
[CTS*06] CHEN Q., TIAN F., SEAH H., WU Z., QIU J.,
KONSTANTIN M.: DBSC-based animation enhanced with
feature and motion: Research articles. Computer Animation and Virtual Worlds, 17, 3–4 (2006), 189–198.
[DF06] DI FIORE F., VAN REETH F. J. P.: Highly stylized
drawn animation. In Proceedings of Computer Graphics
International 2006 (Hangzhou, China, 2006), Springer,
Berlin, Heidelberg, Germany, pp. 36–53.
[DFSEVR01] DI FIORE F., SCHAEKEN P., ELENS K., VAN REETH
F.: Automatic in-betweening in computer assisted animation by exploiting 2.5d modelling techniques. In Proceedings of Computer Animation (CA2001) (Seoul, Korea,
2001), pp. 192–200.
[DFVR02] DI FIORE F., VAN REETH F.: Employing approximate 3d models to enrich traditional computer assisted
animation. In CA ’02: Proceedings of the Computer Animation (Washington, DC, USA, 2002), IEEE Computer
Society, p. 183.
[dJB06] DE JUAN C. N., BODENHEIMER B.: Re-using traditional
animation: methods for semi-automatic segmentation and

c 2011 The Authors
Computer Graphics Forum c 2011 The Eurographics Association and Blackwell Publishing Ltd.

D. Liu et al. / Stroke Correspondence Construction

inbetweening. In SCA ’06: Proceedings of the 2006 ACM
SIGGRAPH/Eurographics Symposium on Computer Animation (Aire-la Ville, Switzerland, Switzerland, 2006),
pp. 223–232.

2207

[SDC09] S´YKORA D., DINGLIANA J., COLLINS S.: As-rigid-aspossible image registration for hand-drawn cartoon animations. In NPAR ’09: Proceedings of the 7th International Symposium on Non-Photorealistic Animation and
Rendering (New York, NY, USA, 2009), pp. 25–33.

[FBC*95] FEKETE J.-D., BIZOUARN E., COURNARIE E., GALAS
T., TAILLEFER F.: Tictactoon: a paperless system for professional 2d animation. In SIGGRAPH ’95: Proceedings
of the 22nd Annual Conference on Computer Graphics
and Interactive Techniques (New York, NY, USA, 1995),
pp. 79–90.

[SG92] SEDERBERG T. W., GREENWOOD E.: A physically based
approach to 2-d shape blending. In SIGGRAPH ’92: Proceedings of the 19th Annual Conference on Computer
Graphics and Interactive Techniques. J. J. Thomas (Eds.).
ACM Press, New York, NY, USA (1992), pp. 25–34.

[HK00] HAN J., KAMBER M.: Data Mining: Concepts and
Techniques (1st edition). Morgan Kaufmann, Waltham,
MA, USA, 2000.

[SG95] SEDERBERG T. W., GREENWOOD E.: Shape blending
of 2-d piecewise curves. In Mathematical Methods for
Curves and Surfaces (1995), pp. 497–506.

[I.T02] JOLLIFFE I. T.: Principal Component Analysis (2nd
edition). Springer, Berlin, Heidelberg, Germany, 2002.

[SL01] SEAH H. S., LU J.: Computer-assisted inbetweening
of line drawings: image matching. In Proceedings of the
IEEE International Conference on Computer Aided Design and Computer Graphics (Kunming, China, 2001), pp.
193–200.

[Kor02] KORT A.: Computer aided inbetweening. In NPAR
’02: Proceedings of the 2nd International Symposium on
Non-Photorealistic Animation and Rendering (New York,
NY, USA, 2002), pp. 125–132.
[Low04] LOWE D. G.: Distinctive image features from scaleinvariant keypoints. International Journal of Computer
Vision, 60, 2 (2004), 91–110.
[MBM05] MORI G., BELONGIE S., MALIK J.: Efficient shape
matching using shape contexts. IEEE Transactions on Pattern Analysis and Machine Intelligence, 27, 11 (2005),
1832–1837.
[MCH*06] MANAY S., CREMERS D., HONG B.-W., YEZZI A. J.,
SOATTO S.: Integral invariants for shape matching. IEEE
Transactions on Pattern Analysis and Machine Intelligence, 28, 10 (2006), 1602–1618.
[PS82] PAPADIMITRIOU C. H., STEIGLITZ K.: Combinatorial
Optimization: Algorithms and Complexity. Prentice-Hall,
Inc., Upper Saddle River, NJ, USA, 1982.
[Ree81] REEVES W. T.: Inbetweening for computer animation utilizing moving point constraints. SIGGRAPH Computer Graphics, 15, 3 (1981), 263–269.
[RS00] ROWEIS S. T., SAUL L. K.: Nonlinear dimensionality
reduction by locally linear embedding. Science, 290, 5500
(2000), 2323–2326.

[TSL00] TENENBAUM J. B., SILVA V. D., LANGFORD J. C.:
A global geometric framework for nonlinear dimensionality reduction. Science, 290, 5500 (2000), 2319–
2323.
[WNS*10] WHITED B., NORIS G., SIMMONS M., SUMNER R.,
GROSS M., ROSSIGNAK J.: Betweenit: An interactive tool
for tight inbetweening. Computer Graphics Forum (Proc.
Eurographics), 29, 2 (2010), 605–614.
[WST*04] WU Z., SEAH H. S., TIAN F., XIAO X., XIE X.: Simulating artistic brushstrokes using disk b-spline curves. In
Proceedings of Conference on Multimedia Arts Asia Pacific, MAAP (Singapore, 2004).
[YF09] YANG W., FENG J.: Technical section: 2d shape morphing via automatic feature matching and hierarchical interpolation. Computer Graphics, 33, 3 (2009), 414–423.
[ZL04] ZHANG D., LU G.: Review of shape representation
and description techniques. Pattern Recognition, 37, 1
(2004), 1–19.
[ZTLY09] ZHANG T., TAO D., LI X., YANG J.: Patch alignment for dimensionality reduction. IEEE Transactions
on Knowledge and Data Engineering, 21, 9 (2009),
1299–1313.

c 2011 The Authors
Computer Graphics Forum c 2011 The Eurographics Association and Blackwell Publishing Ltd.

