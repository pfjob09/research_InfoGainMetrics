DOI: 10.1111/j.1467-8659.2011.01851.x

COMPUTER GRAPHICS

forum

Volume 30 (2011), number 6 pp. 1643–1654

General Spectral Camera Lens Simulation
B. Steinert, H. Dammertz, J. Hanika and H. P. A. Lensch

Ulm University, Germany

Abstract
We present a camera lens simulation model capable of producing advanced photographic phenomena in a general
spectral Monte Carlo image rendering system. Our approach incorporates insights from geometrical diffraction
theory, from optical engineering and from glass science. We show how to efficiently simulate all five monochromatic aberrations, spherical and coma aberration, astigmatism, field curvature and distortion. We also consider
chromatic aberration, lateral colour and aperture diffraction. The inclusion of Fresnel reflection generates correct
lens flares and we present an optimized sampling method for path generation.
Keywords: spectral light transport, diffraction, lens aberrations
ACM CCS: I.3.7 [Computer Graphics]: Three-Dimensional Graphics and Realism—Color, shading, shadowing,
and texture

1. Introduction
The synthesis of photo-realistic images with today’s techniques delivers high-quality pictures with an outstanding
degree of scene realism. However, some real-world photographic effects such as realistic depth of field, vignetting or
distortion are often neglected. To include these effects realistically in computer graphics, light transport has to be simulated as if there was a real camera lens forming the image.
To search for new realistic approximations or to validate existing ones, a reference simulation is needed which behaves
like a real optical device. Our approach is able to reproduce
all relevant optical monochromatic aberrations, and, in addition, chromatic aberrations due to full continuous spectral
simulation. Accounting for the Fresnel equations at every
single lens surface, lens flares can be formed. The inclusion
of the geometrical theory of diffraction [Kel62] allows for
the extension to simulate glare streaks caused by diffraction
at the aperture blades.
To summarize, we present

• a survey of aberration effects, their causes and appearance
in computer graphics.
c 2011 The Authors
Computer Graphics Forum c 2011 The Eurographics
Association and Blackwell Publishing Ltd. Published by
Blackwell Publishing, 9600 Garsington Road, Oxford OX4
2DQ, UK and 350 Main Street, Malden, MA 02148, USA.

• a unified framework including insights from computer
graphics, optical engineering, glass science and geometrical diffraction theory to render full spectral global
illumination including complex lens designs with all
aberrations and aperture diffraction (i.e. we do not
present a visualization of these effects).
• a highly efficient sampling method for path generation
through a lens.

2. Related Work
2.1. Camera models
One of the primary goals of computer graphics is to produce realistic images by modelling reality. The camera model
plays an important role in how the final image is produced.
This becomes especially important in movie production
where synthetic images are combined with real images in
which for example the depth of field is used as a storytelling
tool. Thus, depth of field simulation [CPC84] and fast approximations [MK06] have been studied in great detail. The
pinhole camera model commonly used in computer graphics
for its simplicity and ease of evaluation does not even support depth of field. It renders sharp, distortion free images

1643

1644

B. Steinert et al. / General Spectral Camera Lens Simulation

with an infinite depth of field [Shi00]. The thick lens model
[KMH95] provides a linear approximation with regard to the
lens thickness, causing significant visual influence by optical
path length manipulation [PP06]. It originates from optical
design analysis [Smi07]. The linear transformation based on
paraxial optics allows to express the imaging process of a
whole system of lenses in a single transformation matrix.
The thin lens model can be directly derived from the thick
lens approximation by reducing lens thickness to zero. In
contrast, we directly simulate the whole lens system and thus
include more optical effects.

2.2. Physically based light transport simulation
In photo-realistic image synthesis one generally solves the
rendering equation[Kaj86] to produce an image. Algorithms
to solve this equation have been discussed in detail [PH04]
and one common solution is to use Monte Carlo light transport simulation as described by Veach [Vea97]. As our goal
is to capture as many optical effects as possible, we need to
account for the wavelength of light as another dimension in
Monte Carlo integration. The actual image is formed by sampling a sensor plane and starting paths traversing an optical
device.

2.3. Full lens systems
Established models like the thin and thick lens model are
not able to simulate sophisticated optical effects like lens
aberrations of higher order, or flare effects inside the system.
In [KMH95], a complete realistic simulation of the imaging process was suggested first in a distribution ray tracing
setting. Our approach based on Monte Carlo path generation
methods extends the proposals by certain important methods:
wavelength dependent events, the use of real glass data and
consideration of dielectric Fresnel interaction at every glass
surface.
Moreover, we propose a sampling method to overcome the
problem of non-linear distortion of the exit pupil to efficiently
sample the cone of illumination formed by the lens and the
aperture gate. For the latter element, we extend the model
by simulating diffraction events by the geometrical theory of
diffraction.

2.4. Diffraction
The complex wave property of light causes diffraction effects,
not explainable with classic geometrical optics. Approaches
by Joseph B. Keller [Kel62] adopted the wave behaviour
of light to a modified Fermat setting, enabling us to make
statements on diffraction in a ray-based simulation setting.
Aveneau and M´eriaux proposed using this theory in an image rendering setting [AM99]. As we only want to simulate
diffraction at the aperture gate, we can significantly reduce

the complexity of this procedure. Glare effects have been
modelled by image-based approaches [SSZG95], but mainly
considered the human visual system so far. In [DK01], the
authors simulate camera bloom and corona using a physically
based model.
2.5. Commercial engineering software
The design and construction of lens system is a very important part in optical engineering and several commercial
tools are available that aid the engineer in analysing and constructing such systems. The field of application ranges from
medical imaging systems over photography to the design of
telescope lenses. One large software tool in this area is TracePro from Lambda Research1 . Other products are OpTaliX2
and zemax3 . These programs (and several others) are targeted
towards generating engineering information and analysis of
individual effects and mainly visualize them in data plots. All
these systems contain rendering software to visualize the lens
geometry but none of them is directly coupled with a global
illumination renderer. The ray tracing is usually restricted to
only inside of the lens system. The only visual feedback that
might resemble a real scene operates on a two-dimensional
image and distorts colour values in OpTaliX. In contrast, we
approach the simulation from the opposite side. Instead of
constructing an engineering application to analyse low-level
phenomena, we build an integrated system that tries to model
the full image formation process as closely as possible.
3. Optical Fundamentals
3.1. Geometrical theory of diffraction
The geometrical theory of diffraction [Kel62, MPM90] is
a simulation approach based on Fermat’s law with the following modification: ‘An edge-diffracted ray from a point P
to a point R is a curve which has stationary optical length
among all curves from P to R with one point Q on the edge.’
This allows for a direct usage in a ray-based image generation setting. Avenau and Meriaux [AM99] already introduced
the model by Keller to Computer Graphics for scene-based
diffraction account of direct light. Light is diffracted near
edges of obstacles. The diffraction event is determined by
the geometry of the occluder. For our purposes, it is sufficient to look at diffraction on straight edges lying on a wedge
with opening angle α.
The explicit direction for one ray in a simulation step is
determined by the Keller cone (shown in Figure 1) opening

1

www.lambdares.com.

2

www.optenso.com.

3

www.zemax.com.

c 2011 The Authors
Computer Graphics Forum c 2011 The Eurographics Association and Blackwell Publishing Ltd.

1645

B. Steinert et al. / General Spectral Camera Lens Simulation

Figure 1: Three images created with our lens simulation model. From left to right: realistic depth of field and Bokeh, fisheye
distortion, lens flare artefacts and glare streaks.

Q

R

β

sd

P

β

si
si

e

n

γ

Rm2

u

δ

Rm1

Q

hm1
sd

α
α

Om1

paraxial
region
Om2 O p

Figure 2: The cone of diffracted rays with the diffraction
edge as axis and opening angle β = β stated by Keller. The
edge is settled on a wedge (left, with the side shaded blue)
with inner angle α. By projecting into the plane perpendicular to the diffraction edge (right) γ and δ are introduced,
which lie between the normal of the hit wedge plane and the
projected vectors si and sd . Direction u completes the edge
coordinate system with e and n.

angle β equal to the angle of incidence β. It describes the
set of all valid diffraction directions for a diffraction location
Q. For perpendicular incidence on the edge with β = 90◦ ,
the cone degenerates to a disk around Q.
Diffracted radiance at a location R can be evaluated by
a diffraction coefficient for a known diffraction point and
geometry. With given projected angles in Figure 2, the
diffracted radiance from P to R over Q on the wedge with
α = π (2 − n) is [AM99]:
⎛

π
π
sin
⎜
4
n
⎜
Ld = Li λ ⎝
δ−γ
π
nπ sin β cos − cos
n
n
cos

⎞2
⎟
⎟ .
⎠

Figure 3: Comparison of Gaussian refraction (dashed) and
Snell’s refraction (solid) of marginal region rays.

3.2. Glass interaction
The correct simulation of light interacting with glass surfaces is of paramount importance for the following suggestions. [DCWP02] provides an overview over all necessary
formulas. Based on this, we use Sellmaier definitions of typical optical glass types that can be found in the Schott glass
catalogue [Sch09].
3.3. Aberrations
In the lens, the varying thickness and incident angle due to
the spherical surface causes a changing optical path length
with varying ray height h (see Figure 3), that is distance of
the ray to the optical axis. Consequently, the image suffers
from so-called Seidel aberrations [Ray02, Smi07]. Tracing
rays through an optical system means applying Snell’s law
[DCWP02] repeatedly:
η(λ) sin θ = η (λ) sin θ .

(2)

(1)

This formula is valid for unpolarized spherical wavefronts
hitting a straight edge, neglecting interference. It is important
to note that the contribution of diffracted rays and the rest
of the image, created with standard geometrical optics, can
simply be summed up to obtain the final image.

The Taylor expansion of sin θ reveals that the incident angle
appears in different orders.
∞

sin θ =

(−1)n
n=0

θ 2n+1
θ3
θ5
=θ−
+
± · · · . (3)
(2n + 1)!
3!
5!

Discarding all terms of higher order than the first yields the
paraxial approximation

c 2011 The Authors
Computer Graphics Forum c 2011 The Eurographics Association and Blackwell Publishing Ltd.

1646
radius[mm]
42.970
-115.33
306.840
aperture
-59.060
40.930
183.920
-48.910

B. Steinert et al. / General Spectral Camera Lens Simulation
thick.[mm]
9.8
2.1
4.16
4.0
1.870
10.640
7.050
79.831

material
LAK9
LLF7
air
air
SF7
air
LAK9
air

rad.[mm]
19.2
19.2
19.2
15.0
17.3
17.3
16.5
16.5

entrance
pupil

Figure 4: Tessar Design by Brendel (USP 2854889)
[Smi05], f /2.8, 100 mm effective focal length (EFL).
sin θ ≈ θ,

aperture stop

exit pupil

Figure 5: Adopted from [gSmi07]. The green, dashed principal ray defines pupil locations, the axial ray fan determines
the radii. The aperture stop is also treated as a pupil.

(4)

which is valid for small angles θ . This linear approximation
of Equation (3) is the central basis of all linear lens models like the thin or thick lens description [PP06, Smi07]. By
truncating the higher order terms, aberrations for a larger ray
height with increasing θ cannot be simulated anymore. In
contrast, we use Snell’s law [Equation (2)] for our computations and therefore the ray height is not limited. Figure 4
depicts the difference between linear Gaussian optics and
reality for marginal rays with large height h. Seidel [vS57]
classified five different forms of monochromatic aberrations
introduced with the third order. The effect that paraxial rays
with large height are focused closer to the lens is called spherical aberration. For oblique rays, coma aberration causes
comet-like tails to points. Astigmatism is caused by the fact
that the ray height can vary in two directions, resulting in
different image planes. Field curvature is the obvious consequence of using spherical surfaces. The image is not formed
on a real plane, but on a curved surface. Distortion arises
with marginal rays, becoming more or less magnified, and
thus introducing either inward pincushion distortion or outward barrel distortion. Chromatic aberrations are caused by
dispersion during transmission. Shorter wavelengths are focused closer to the lens because of stronger refraction compared to longer wavelengths.

3.4. Lens design
Optical instruments usually consist of one or more spherically curved, axially symmetric glass surfaces [Ray02]. Using lenses in tandem, either cemented or with a gap in between, offers possibilities for aberration correction, imaging
distance or effective focal length manipulation. A typical
description of a lens design is outlined in Figure 5.
Each row describes one spherical surface inside the device. The curvature follows a fundamental rule: A positive
radius stands for a surface with centre of curvature on the
right side, and negative sign means that the centre is on the
left side [Smi07]. The thickness applies to the transmission
distance along the optical axis. The material name is a code
referencing an entry in the Schott glass catalogue [Sch09].

The last column represents the semi-diameter of the element.
The aperture stop position and radius are defined in row 4. It
is important to note that all values are scaled with the same
factor when using the same lens design for a different focal
length [Smi05].

3.4.1. Aperture stop
Irradiance transport in an optical system is controlled by
a resizable diaphragm called aperture stop [PP06, Smi07,
Ray02]. As outlined before, aberration critical rays near the
margin can be blocked here. The entrance and exit pupils
depend on aperture size and position. They can be regarded
as images of the aperture on both sides of the lens system.
The light forming character of a lens system can therefore be
reduced to the two pupil disks, which allows concatenation
of lens systems.
The size of the aperture is expressed by the photographic
f -number (normally written as f /N )
N=

f
dentr

(5)

with entrance pupil diameter dentr and effective focal length
of the lens system f . The latter corresponds to the focal
length of one single lens approximating the whole system.

3.4.2. Material coatings
Ideally, an optical system delivers all incident light to the image plane. Light travelling from one medium to another will,
however, be partially reflected. The amount of reflected light
depends on the index difference. Thin film lens coatings are
used to reduce reflection by intermediate layers. Example relations between different coatings and wavelengths are given
in Figure 6. A rendering of a glass sphere with a specific
coating can be found in Figure 19.

c 2011 The Authors
Computer Graphics Forum c 2011 The Eurographics Association and Blackwell Publishing Ltd.

1647

B. Steinert et al. / General Spectral Camera Lens Simulation

8

aperture

Uncoated glass
Single layer coating
Double layer V coating
Multiple layer coating

7
6
R(%)

5
4

O

O

3
2

Figure 8: Optical vignetting is caused by the lens design.
The aperture cannot be completely imaged because of the
limited diameter of the lens in front and behind it.

1
0
400 450 500 550 600 650 700 750 800
λ

Figure 6: Comparison of reflectivity under normal incidence for different coatings [Ray02]. Coating stops a considerable amount of light from being reflected, allowing it to
contribute to the image.

Besides natural vignetting, caused by the varying angles of
incidence and the projected pupil area for different sensor
locations, mechanical vignetting is caused by obstacles like
lens hoods.
Optical vignetting is a consequence of off-axis rays having
another effective aperture, because not all elements of the
system can receive the full cone of illumination formed by
the aperture [Smi07]. Figure 8 drafts two different cases.
The reduced aperture area of oblique rays causes a respective
decrease of irradiance at the image plane.

4. Full Lens System for Realistic Image Synthesis
4.1. Implementation
Figure 7: Secondary reflections inside the lens barrel can
arise due to extreme angles of incidence, which cause internal
reflections inside the elements, as seen on the left. The right
schematic shows that stray light occurs when the barrel has
a certain reflectance.
3.5. Secondary effects
In the following section, we will look at secondary effects
that arise as soon as a lens design is used beyond its limits or
is not sufficiently refined with coatings.
3.5.1. Flare effects
Light in a lens housing is not only refracted towards the
sensor. Internal reflection cannot be completely eliminated
and becomes clearly visible in certain situations. A typical
flare effect is oblique incoming light, that gets reflected at a
surface and then reaches the image plane as can be seen in
Figure 7.
3.5.2. Vignetting
Inhomogeneous illumination of the imaging area is called vignetting and consists of three independent subtypes [Ray02].

The new setting presented in this paper combines several
well-understood concepts to yield a rendering system capable of accepting a real lens design. Basic implementation
ideas are adopted from [KMH95]. Continuous spectral path
evaluation was added to obtain chromatic artefacts. Spherical caps were chosen as analytic description for the lens
design. All ray generation is isolated in a lens tracing kernel
which is just used when trigger surfaces in front or in the end
are hit. Direct light estimation [Shi00] is done by sampling
these surfaces. Our system features flexible scales and precision to overcome numerical flaws. Scenes are represented
in units of metres whereas millimetres are used for the lens
tracing. This avoids the resolution problems of floating point
arithmetic (to handle self-intersection, an offset of 0.001f is
common). The aperture is described by the geometry of the
opening. Scaling allows for setting any desired f -number.

4.2. Pupil sampling
As can be seen in Figure 8, only paths passing through the
effective aperture contribute to the image. Ideally, in a backward path tracing setting starting on the sensor, we only want
to sample paths which pass through this aperture. This can
be done by sampling the image of the effective aperture on
a virtual plane between the image plane and the back lens,

c 2011 The Authors
Computer Graphics Forum c 2011 The Eurographics Association and Blackwell Publishing Ltd.

1648

B. Steinert et al. / General Spectral Camera Lens Simulation

Figure 9: Sampling the image of the effective aperture for
different pixel locations. The pixel pupils show large distortion. The first four images show the positive sample locations
in the pupil plane for pixel locations on the mid pixel row,
starting at the fisheye characteristic illumination border ending at the centre pixel of the sensor. The last image depicts the
shape for a central pixel in the first quadrant of the sensor.
y
global pupil

disc approximated
global pupil
back lens

x

y
image plane

pupil plane

z

pixel pupil

Figure 10: Samples of ray directions on the global pupil are
stored if the constructed path reaches the other side. The average of the transmitted path samples yields the centre for a
pixel pupil. Because the circle is a rather coarse approximation, there is still a region off the pupil border which causes
a small but acceptable amount of zero-contribution rays.

which we call pixel pupil. As the name indicates, this pupil
depends on the pixel on the image plane.
The pixel pupil can be approximated by a circle, which is
stored per pixel. The diameter and centre are evaluated by a
number of sample paths that are traced through the system.
The mean of all intersections with the pupil plane yields the
centre, and the radius is chosen to include all points plus an
optional, small offset. This approximation is used for all paths
starting from somewhere inside the pixel. Figure 9 shows a
few example pupils, Figure 10 illustrates the geometry of
the pixel pupil. and Figure 11 visualizes the procedure. A
nice side-effect can be observed for this fisheye lens: not
all pixels on the image plane are illuminated. Using pixel
pupil sampling, no paths are created for these pixels, as the
aperture is completely occluded.
Further optimizations to the method can be easily added.
For radially symmetric lenses, it is possible to exploit the
symmetry and sample only one quadrant. Furthermore, as
the number and order of spherical caps to intersect is given
in advance, the pixel pupil data could be pre-computed on
the GPU for a high number of samples in very short time.

Figure 11: Lens tracing plot for comparison between global
pupil sampling (left) and pixel pupil sampling (right) using
the same number of initial rays, for a 10 mm Muller Fisheye lens at f /8. In numbers, the ray passage rate is 10.2%.
By pixel pupil sampling, the number increases to averaged
79.7% per frame. By choosing an even more precise pupil representation this number could be optimized to nearly 100%.
An exactly computed pupil could indeed save the intersection
test with the aperture stop.

To extend the proposed algorithm to a forward path tracing
approach starting at light sources, a virtual image plane on
the object side of the lens system is needed to discretize the
field of view. To keep the area small it should be almost right
in front of the lens. The computation of the pupils is now
almost the same, except for one additional test if the sample
reaches the image plane inside valid bounds. The presented
method does of course only apply to a setting where inner lens
reflection is completely ignored. These effects are calculated
by another method and added to the final result.
An alternative to using our specialized pupil sampling
optimization would be general metropolis sampling. But it
has to be considered that the position of the pupil changes
with each pixel. Once a metropolis sampler has found valid
contributing path small permutations are still likely to find
another contributing path but because for many cases the
pupil is quite small, this process is not very efficient. The best
solution would be to use our conservative pupil sampling in
addition to a metropolis sampler.

4.3. Lens flare simulation
Because a single ray-based rendering technique cannot sufficiently cover all possible effects, a progressive rendering
method that combines several techniques is required. The
most common is to use forward and backward ray tracing together in a bi-directional fashion using multiple importance
sampling [Vea97]. For the specific phenomenon of lens flares,
we only need to consider direct light from the scene to obtain the light paths for reflection artefacts. Lens flares are
best found by starting samples at light sources and deterministically connecting them to the lens. The resulting image
delivers an independently viewable solution of the lens flare
as shown in Figure 12 (left). The results are only correct for

c 2011 The Authors
Computer Graphics Forum c 2011 The Eurographics Association and Blackwell Publishing Ltd.

1649

B. Steinert et al. / General Spectral Camera Lens Simulation

direct
light

image
plane

y
z

(a) Here, a 33mm wide-angle lens by Mori [Smi05] at f/ 2.8
was used for the left flare images. A lens surface was equipped
with a modified reflection spectrum resembling a thin layer Vcoating [Smi07] (lower left). For the coating see also Figure 6.
The right images show the lens flare result of Kimura wide-angle
with f/ 5.6 clearly reproducing aperture ghosts. The combined image gives an impression of the resulting impact.

(b) Left: Reference photograph of a typical flare light situation with
the source beeing outside the field of view. Right: Features different
optical artifacts. First, noticeable distortion, glare streaks and halo
around the sun, and outshining lens flares over the image. By courtesy of Paul van Walree [vW].

Figure 12: Inner reflections in lenses can be reduced by
thin layer coating and thus introduce colour artefacts by the
absorption characteristic.
the predetermined setting of direct light. Mirror interactions
are not accounted for in the light tracing pass but could be
easily included by extending the light paths and filtering out
appropriately in the backward stage. Neglecting direct light
in the backwards path tracing stage allows both results to be
summed up to the final image in Figure 12(right). The lens
tracing plot in Figure 13 clearly shows regions on the sensor,
where reflected light arrives.
To model the typical colour variations of lens flares, absorption characteristics of material coatings have to be simulated. We approximate thin film interference by including
a lookup step right after Fresnel computation. This lookup
depends on the incident angle on the lens surface and on
the wavelength. This evaluation is done as in the commonly
used multilayered BRDF models. The degree of transmission
is altered according to the desired coating with data from
Figure 6 for specific surfaces.

Figure 13: Lens tracing plot for an aperture-less Momiyama
wide-angle [Smi05] at 36 mm with fix f /2.8, simulating lens
flare. either directly at the first surface or later. The image of
the light source itself is not in the field of view. The reflected
rays reaching the sensor create the flare effects.

4.4. Aperture diffraction
Diffraction at the aperture causes significant glare streaks
crossing the image when looking into bright lights. The
geometrical theory of diffraction allows to introduce paths
into the rendering setting which produce these effects. The
diffraction direction must fulfil the Keller cone rules and has
to start on the edge of the aperture, or at least very near to it, to
be able to use the diffraction coefficient proposed in [AM99].
During lens tracing and aperture testing, we are able to check
whether the ray almost hits the edge for example by testing
the barycentric coordinates when using triangles. By choosing a certain interval around the edge, we can accept paths to
be diffracted according to the rules stated earlier. The diffraction direction has to be sampled randomly on the Keller cone
surface. By sampling a point on the base circle as direction
from the edge hitpoint, we receive a valid diffraction direction with probability π1r 2 . After that, the diffracted radiance
can be computed using Equation (1). For simplicity reasons,
we assume to have an infinitely thin aperture by applying
α = 0. Diffraction in the aperture corners has not been accounted for in this work, but could be added by specific coefficient and direction calculations. Note that the diffraction
process generally resembles a surface material interaction.
Thus we implemented the process as diffraction BRDF.

5. Results
In the following, we present renderings of individual effects.
Note that all effects could be present and correctly rendered
in a single image with our system.

5.1. Aberration simulation
To simulate photorealistic aberration, our system applies
Snell’s law according to the continuous spectrum. Figure 14
outlines various aberrations of a single spherical lens. The
scene is moved in and out of focus. Chromatic artefacts are

c 2011 The Authors
Computer Graphics Forum c 2011 The Eurographics Association and Blackwell Publishing Ltd.

1650

B. Steinert et al. / General Spectral Camera Lens Simulation

5.4. Lens flares
As already demonstrated in Figure 4.3, our system renders
lens flares due to inter-reflections. By saving the result of
the forward light tracing pass, the lens flare can be examined
separately from other effects. The example in Figure 4.3
clearly shows how a lens coating can suppress lens flare.
(a) Back wall in focus. Unequal
focus near the border is caused
by spherical aberration and field
curvature. The comet-like tail
at the marginal points is coma
aberration.

(b) Focus shifted a bit. The color
shift of the marginal circles is
called lateral color originating
from varying magnification of
all wavelengths.

Figure 14: These two images show the lower left of a shot
through a single biconvex lens, which suffer all aberrations
uncorrected. The small upper right point is the actual image
centre. Both images show significant distortion.

introduced by the specific dispersion properties of real glass.
These are clearly visible in the lower left corner of the images.
In Figure 15, a Petzval portrait lens design at aperture
f /3.5 is used. The design is well corrected for aberrations
except for curvature of field and astigmatism. The resulting
effects are shown for different image distances. Curvature
of field is caused by the spherical surface of lenses. Thus,
the real image surface is not planar but curved. Furthermore,
due to the astigmatism, there is no image distance for which
tangential and sagittal image features are in focus at the same
time. In Figure 15 the same pattern is photographed with a
real camera showing astigmatism.

5.2. Fisheye distortion
To be able to build lenses with a field of view of 180◦ , lens
designers deliberately introduce distortions. Such designs are
called Fisheye lenses and are among the most complex designs. Figure 16 shows two results, shot with different designs. Note the distortion of the window row near the ceiling,
which is actually straight. This is impossible to achieve with
a pinhole camera or thick lens model.

5.3. Depth of field and Bokeh
One obvious consequence of using a real lens design is a limited depth of field, especially for high-speed lenses. Bokeh
is the term for the visual appeal of the out-of-focus region.
Here, the size and shape of the aperture is an important factor, as it influences the appearance of out-of-focus features.
The effect is particularly noticeable in Figure 17 around the
highlights in the back.

5.5. Diffraction simulation
Diffraction of incoming light at the aperture blades forms
streaks perpendicular to the edges as can be seen in
Figure 18. As noted earlier, diffraction effects can be simulated separately and simply added to the rest of the light
transport. The resulting light streaks have a significant impact on the brightness perception of light sources.

5.6. Efficiency discussion
We benchmarked the lens stage of the rendering system and
give values in 1. The eye path generation with a thin lens approximation took less than 2% for a regular scene. Because of
the missing depth dimension of a thin lens and the possibility
to sample, the aperture area directly for path generation, there
is no loss of rays during the passage. The Armadillo in our
test setting has no environment geometry, which means most
of the rays leaving the lens have no contribution, because
they do not hit any surface at all. The thin lens computation
time fraction increases by a factor of six, because no indepth tree traversal and shading is done for most of the scene
rays.
In a real lens scenario, these aspects are considerably different. The ray passage rate depends on all variables changing the optical path length and space of valid paths of the
lens, among them focal length, sensor distance, glass properties, f -number and sensor dimensions. The numbers in the
table are averaged values observed during our tests. The relation between the ray passage and the f -number can be
observed in all test cases. In combination with our simple
pupil sampling method, this shortcoming can be completely
eliminated. In addition, the black pixels in the marginal region of a fish-eye shot can be identified, because their pupil
has zero diameter. Of course, rendering time increases with
higher ray passage, that is the main reason why the percentage of lens tracing time fraction decreases. In contrast
to the global pupil sampling approach, the path computation fraction stays constant over all stop settings for one
lens.
A fair comparison between thin lens and real lens is only
meaningful for the pixel pupil sampling approach, where
the ray passage rate gets optimized to a constant value
within some limits. Two instances influence the passage
rate in extreme conditions. A large distortion of the exit
pupil makes the circle a rather bad approximation, which

c 2011 The Authors
Computer Graphics Forum c 2011 The Eurographics Association and Blackwell Publishing Ltd.

B. Steinert et al. / General Spectral Camera Lens Simulation

1651

(a) In the rendering scenario observed for a Petzval lens at different image distances. Left: Visual evidence for field curvature. While
the margins are sharp, the center is defocussed because the image plane is placed before the actual focal plane. Middle: Setting with
the image plane moved towards the focal plane. The center gets focussed, but the margins lose sharpness. Right: This image made in
the focal plane clearly reveals astigmatism. While the tangential structures in the marginal regions are rather focussed, the sagittal lines
towards the center are blurred.

(b) Comparison photographs clearly showing the behaviour of astigmatism. Shot with a Zeiss Planar lens. By courtesy of Paul van
Walree [vW].

Figure 15: Astigmatism and field curvature.

(a) Natural History scene [ALB], illuminated with a daylight environment. Rendered through a 14mm Muller fisheye lens at f /5.6 with 144◦ field of view (left)
and with a 12mm Mitsuaki fisheye lens with 179◦ (right).

(b) Comparison panorama photograph
of the Muensterplatz in Ulm.

Figure 16: Fisheye lenses produce characteristic panoramic images with 180◦ field of view and above [Smi05].

c 2011 The Authors
Computer Graphics Forum c 2011 The Eurographics Association and Blackwell Publishing Ltd.

1652

B. Steinert et al. / General Spectral Camera Lens Simulation

(a) These images were rendered through a Double Gauss lens by Rosier [Smi05] at speed f /1. From top
to bottom with 4,6 and 12 diaphragm blades. Besides becoming brighter by enlarging the aperture area
the out-of-focus region of the image seems to become drawn much softer.

(b) The out of focus
structures in a reference
photograph taken with a
7-blade aperture.

Figure 17: Depth of field and influence of the aperture shape on out-focus-regions are clearly visible for high-speed lenses.

(a) Diffraction at the aperture simulated
in a forward path tracing stage. Rendering
took approximately 30 minutes.

(b) The flare image with inner lens reflection consideration, slightly brightened.
With forward path tracing, this result took
130 minutes to render.

(c) Armadillo in the dark. Combined image
by just summing up all previous images.
Scene rendering without streaks or flares
took 180 minutes.

Figure 18: An 800×600 sized example image stack of the proposed progressive approach with given absolute rendering times
on the CPU. The multithreaded Monte Carlo ray tracer works with a simple mono-ray SAH bounding volume hierarchy without
any handmade optimizations. Direct light estimation was used for the backward as well as the forward path tracing stage. We
used the GNU compiler collection gcc-4.4 and the machine was an 8-Core 2.5 GHz Intel Xeon E5420.

(a) L-CAF2:Low
Abbe-Value.

IOR,

high (b) N-LAK12: Mid IOR, mid (c) N-SF66: high IOR, low Abbe- (d) N-SF66, with double layer VAbbe-Value.
Value.
Coating

Figure 19: Different types of glass. Specifications taken from[Sch09]. The coating reduces reflection around 550 nm beyond
1% but has almost no effect to the lower and upper end of the visible spectrum.
causes more wrong samples when using the pixel pupil,
for example Rosier Gauss at f /1. This circumstance was
already mentioned in Figure 9 for fish-eye lenses was already explained. Secondly, as soon as the aperture is too
narrow, the exit pupil image is no longer able to illumi-

nate the whole sensor and produces pixels with zero diameter pupils, happening for Rosier Gauss at f /8. Another
issue is the number of used samples for the pupil construction itself. The smaller the chosen aperture, the more
samples are needed in theory to correctly determine the

c 2011 The Authors
Computer Graphics Forum c 2011 The Eurographics Association and Blackwell Publishing Ltd.

B. Steinert et al. / General Spectral Camera Lens Simulation

1653

Table 1: Presentation of rendering costs in relative numbers.

Eye path generation time
Lens
Thin lens
Tessar
Brendel
4 elements in
3 groups

Kimura
wide-angle
7 elements in
6 groups

Rosier Gauss
8 elements in
5 groups

Setting

Passage Rate

MeshBox

Armadillo

f/2.8, GPS

100%
64.4%

1.3%
20.7%

8.9%
60.8%

f/2.8, PPS

87.6%

17.8%

55.7%

f/8, GPS
f/8, PPS
f/2, GPS

10.7%
85.7%
53.9%

52.4%
17.7%
29.3%

81.1%
55.7%
70.5%

f/2, PPS

81.8%

26.4%

67.0%

f/5.6, GPS
f/5.6, PPS
f/16, GPS
f/16, PPS
f/1, GPS
f/1, PPS

18.0%
84.9%
4.3%
86.1%
40.7%
68.9%

50.7%
26.9%
76.9%
27.0%
34.9%
27.1%

83.8%
66.8%
92.5%
67.2%
76.3%
72.0%

f/2.8, GPS
f/2.8, PPS
f/8, GPS
f/8, PPS

6.1%
85.2%
0.9%
58.5%

73.4%
27.0%
93.0%
26.9%

91.5%
68.7%
96.1%
67.4%

(a) MeshBox (approx 1.9M
triangles) with Rosier Double
Gauss lens.

(b) Armadillo (approx. 350K
triangles) in the dark with
Kimura wide-angle lens.

Note: GPS marks global pupil sampling settings, and PPS settings with our pixel pupil sampling approach. The values represent the part of
rendering time needed for eye path generation per frame. Lens designs taken from [Smi05, Smi07]. We used approximately the same focal
length of 55 mm for all setups to have similar fields of view.

pixel pupil. Adaptive methods help to keep this problem
small.
These numbers only consider pure image generation. Effects such as diffraction or inner reflection cannot be combined with pixel pupil sampling, because the space of valid
paths is much larger in these cases.
The lens simulation alone offers several opportunities to
source the whole computation out to the GPU for example.
The small number of analytic primitives makes an acceleration structure obsolete. Ray computation through the lens
could massively benefit from parallel stream computation.
This eliminates any CPU cycle costs for eye path generation
from and to the sensor. The progressive rendering approach
for including diffraction and flare effects only adds small
extra rendering costs. The Armadillo example from the title
page is given with absolute time numbers in Figure 19.
6. Conclusion
The correct optical simulation of all types of aberrations was
introduced by the combination of spectral Monte Carlo light
transport, real lens design data and the consideration of appropriate physical laws. These were additionally augmented
by diffraction effects using the geometrical theory of diffraction.

The model could be generalized to other fields such as
astronomy or microscopy and be used to simulate novel optical elements such as lenslet arrays, liquid lenses or phase
plates. It is also possible to include polarization, interference and more general diffraction effects. This work can be
seen as first step on the way to derive simplified models for
fast evaluation, which can be verified against the reference
output of our simulation, and will benefit the field of believable rendering.

References
[ALB] ALVARO LUNA BAUTISTA J. A.: http://www.3drender.
com/challenges - Lighting Challenge #17 - Natural History. Accessed on 14 October 2009.
[AM99] AVENEAU L., M´ERIAUX M.: Rendering polygonal
scenes with diffraction account. In WSCG ’99: Seventh
International Conference in Central Europe on Computer
Graphics, Visualization and Interactive Digital Media
(Plzen-Borey, Czech Republic, 1999), University of West
Bohemia, pp. 353–360.
[CPC84] COOK R. L., PORTER T., CARPENTER L.: Distributed
ray tracing. Computer Graphics (Proc. SIGGRAPH’84)
18, 3 (1984), 137–145.

c 2011 The Authors
Computer Graphics Forum c 2011 The Eurographics Association and Blackwell Publishing Ltd.

1654

B. Steinert et al. / General Spectral Camera Lens Simulation

[DCWP02] DEVLIN K., CHALMERS A., WILKIE A.,
PURGATHOFER W.: Star: Tone reproduction and physically
based spectral rendering. In Proceedings of the State
of the Art Reports, Eurographics 2002 (Saarbruecken,
Germany, 2002), pp. 101–123.
[DK01] DURIKOVIC R., KOLCHI K.: Physically-based model
of photographic effects for night and day scenes. Journal
of Three Dimensional Images 15 (2001), 119–124.

[Ray02] RAY S. F.: Applied Photographic Optics, 3rd edition. Focal Press, 2002.
[Sch09] SCHOTT AG: Optical Glass - Data Sheets (Mainz,
2009), http://www.schott.com/advanced_optics/english/
download/schott optical glass jan 2011 en.pdf. Accessed on 7 February 2011.
[Shi00] SHIRLEY P.: Realistic Ray Tracing. AK Peters Ltd.,
Natick, MA, 2000.

[Kaj86] KAJIYA J. T.: The rendering equation. Computer
Graphics (Proc. SIGGRAPH ’86) 20, 4 (1986). doi:
http://doi.acm.org/10.1145/15886.15902

[Smi05] SMITH W. J.: Modern Lens Design, 2nd edition.
McGraw-Hill, Maidenhead, Berkshire, England, 2005.

[Kel62] KELLER J. B.: Geometrical theory of diffraction.
Journal of the Optical Society of America 52, 2 (1962),
116–130.

[Smi07] SMITH W. J.: Modern Optical Engineering,
4th edition. McGraw-Hill Professional, New York,
2007.

[KMH95] KOLB C., MITCHELL D., HANRAHAN P.: A realistic camera model for computer graphics. In Proceedings of SIGGRAPH ’ 95 (Los Angeles, CA, USA, 1995),
pp. 317–324.

[SSZG95] SPENCER G., SHIRLEY P., ZIMMERMAN K.,
GREENBERG D. P.: Physically-based glare effects for digital
images. Computer Graphics 29, (1995), 325–334 [Annual
Conference Series].

[MK06] MICHAEL KASS AARON LEFOHN J. O.: Interactive
Depth of Field Using Simulated Diffusion on a GPU. Tech.
Rep., Pixar Animation Studios, 2006.

[Vea97] VEACH E.: Robust Monte Carlo Methods for Light
Transport Simulation. PhD thesis, Stanford University,
1997.

[MPM90] MCNAMARA D. A., PISTORIUS C. W. I., MALHERBE
J. A. G.: Introduction to the Uniform Geometrical Theory
of Diffraction. Artech House, Boston, 1990.
[PH04] PHARR M., HUMPHREYS G.: Physically Based Rendering: From Theory to Implementation, 2nd edition. Morgan
Kaufmann, San Francisco, CA, 2004.

¨
die Theorie der Fehler,
[vS57] vON SEIDEL P. L.: Uber
mit welchen die durch optische Instrumente gesehenen Bilder behaftet sind, und u¨ ber die mathematischen Bedingungen ihrer Aufhebung. Abhandlungen der
naturwissenschaftlich-technischen Commission bei der
K¨oniglichen Bayerischen Akademie der Wissenschaften
in M¨unchen 1 (1857), 227–267.

[PP06] PEDROTTI F. L., PEDROTTI L. S.: Introduction to Optics.
Pearson Education (US), Zug, Switzerland, 2006.

[vW] vAN WALREE P.: http://www.toothwalker.org/optics.html
- Photographic Optics. Accessed on 14 October 2009.

c 2011 The Authors
Computer Graphics Forum c 2011 The Eurographics Association and Blackwell Publishing Ltd.

