DOI: 10.1111/j.1467-8659.2011.01900.x

COMPUTER GRAPHICS

forum

Volume 30 (2011), number 6 pp. 1761–1788

A Survey of Image Statistics Relevant to Computer Graphics
Tania Pouli1 , Douglas W. Cunningham2 and Erik Reinhard1

1 Department

of Computer Science, University of Bristol, UK
Technical University Cottbus, Cottbus, Germany
pouli@cs.bris.ac.uk, Reinhard.erik@googlemail.com

2 Brandenburg

Abstract
The statistics of natural images have attracted the attention of researchers in a variety of fields and have been used
as a means to better understand the human visual system and its processes. A number of algorithms in computer
graphics, vision and image processing take advantage of such statistical findings to create visually more plausible
results. With this report we aim to review the state of the art in image statistics and discuss existing and potential
applications within computer graphics and related areas.
Keywords: image statistics, natural images, power spectra, phase spectra, wavelets, gradients, moments,
principal/independent components analysis, sparse coding
ACM CCS: I.4.10 [Image Representation]: Statistical; I.5.1 [Models]: Statistical

1. Introduction
The field of natural image statistics studies images and their
statistical regularities [Gei08, HHH09, PRC10]. The human
visual system (HVS) has evolved in natural environments,
that is those without man-made structures. Human vision,
it is argued, has therefore evolved to be particularly good
at observing natural scenes, as opposed to random images
[van98]. By studying the input to the human visual system,
it is thought that the human visual system can be understood
better [BD61, Fie87, Rud94, HM99, Bar01].
The typical process by which natural image statistics are
computed, involves collecting statistics of ensembles of images after passing each image through a particular transform.
The transforms typically employed tend to correspond to a
component of human vision. It is, for instance, possible to
compute the wavelets for each image, and from these calculate aggregate statistics on wavelet coefficients for the whole
set. This state-of-the-art report reviews this and many other
transforms and statistics.
Aside from learning about human vision and the implications for perception, many of these statistical regularities have
c 2011 The Authors
Computer Graphics Forum c 2011 The Eurographics
Association and Blackwell Publishing Ltd. Published by
Blackwell Publishing, 9600 Garsington Road, Oxford OX4
2DQ, UK and 350 Main Street, Malden, MA 02148, USA.

transferred to computer graphics and adjacent areas: several
applications now successfully employ statistics of natural
images to help solve engineering problems. This generally
takes two forms. First, statistical regularities of a particular
ensemble can be used to ensure that the solution produced
by an algorithm will approach that ensemble.
Secondly, statistical properties of single images are computed and manipulated to achieve certain effects. As an example, deblurring algorithms exist that rely on optimization
involving priors that help push candidate images towards visually plausible solutions [SJA08]. Of course, visually plausible solutions are those that appear to humans in some
sense natural. Image priors have therefore been designed
with the aid of specific knowledge of natural image statistics, in this case regarding the average distribution of image
gradients.
We think that the use of natural image statistics has so far
shown great promise, with interesting applications making
use of some of the available statistical regularities. We also
see excellent scope for further future developments. In this
report, we review the current state of natural image statistics, and give an overview of how statistics have been used

1761

1762

T. Pouli et al. / A Survey of Image Statistics Relevant to Computer Graphics

in computer graphics, computational photography, visualization and image processing so far.
For the purpose of classifying different types of natural
image statistics, we follow van der Schaaf [van98] and equate
the order of a statistic to the number of pixels that it considers.
Thus, single-pixel statistics are first order, whereas statistics
that consider pairs of pixels are second order. Any statistics
that involve three or more pixels are deemed higher-order.
First-order statistics, as well as their relevant findings and
applications are discussed in Section 2, whereas second- and
higher-order statistics are shown in Sections 3 and 4. Colourrelated statistics are presented separately in Section 5. Finally, we summarize the findings in Section 6.

The simplest regularities in images that can be explored
through statistical analysis are properties of single pixels.
The distribution of pixel values in images is typically represented with histograms. For a given image I, we define its
histogram H with B bins of width V as follows:
H = {(h(1), v(1)), . . . , (h(B), v(B))},

(1)

max(I ) − min(I )
,
V

(2)

P (I (p), i), i ∈ [1, B],

(3)

N

h(i) =
p=1

v(i) = min(I ) + (i − 1)V ,

P (I (p), i) =

of a distribution can be computed as follows:
N

mk =
p=1

2. First-Order Statistics

B=

Figure 1: The right image was created by randomly permuting the pixels of the image on the left, resulting in identical
first-order statistics.

⎧
⎪
⎨1

i=

⎪
⎩0

otherwise,

I (p) − min(I )
+1 ,
V

(4)

(5)

where H is the set of all pairs (h(i), v(i)) for all i ∈ [1, B]
corresponding to the number of elements and value of the
ith bin of the histogram. I(p) is the value of the pth pixel
of image I which contains a total of N pixels and P (I (p), i)
represents the probability of a pixel I(p) belonging to a bin i.
By definition, first-order statistics do not capture relationships between pixels and as such are not suitable for studying
spatial regularities within images. Figure 1 shows an example of two very different images that would result in identical
first-order statistics. The right image is constructed by randomly permuting the pixels of the left image, yet it appears
unnatural. Statistical analysis of the distribution of pixel intensities can however lead to interesting insights.
Statistical moments are commonly employed to quantitatively describe the shape of a distribution. The kth moment

(I (p) − c)k
,
N

(6)

where c can be any constant. Generally, if c = 0 then the
above equation computes the raw moments of the distribution, whereas setting c to the mean μ gives us the central
moments (i.e. centred at the mean). The first raw moment is
the mean μ of the distribution and the second is the variance
σ 2.
The skewness S and kurtosis κ of a distribution relate to
the third and fourth moments, respectively. More specifically,
the skewness and the kurtosis can be defined as
m3
(7)
S = 3,
σ
m4
(8)
κ = 4,
σ
respectively, where m3 and m4 are the third and fourth central moments, respectively. The skewness is a measure of
lopsidedness of a distribution, whereas kurtosis is a measure
how long the tails of a distribution are. A normal distribution
has a kurtosis of 3 under the above definition of κ, which is
why sometimes 3 is subtracted. The physical interpretation
of higher order moments is less clear.
Huang and Mumford analysed more than 4000 grayscale
images of natural scenes (taken from the database created by
J. H. van Hateren [vv98]) by computing central moments of
the log histograms [HM99b]. The values found for the mean,
standard deviation, skewness and kurtosis were respectively
μ = 0, σ = 0.79, S = 0.22 and κ = 4.56. The value of
the skewness shows that the distribution is not symmetrical,
which can be attributed, at least partly, to the presence of
sky in many of the images, resulting in a bias towards higher
intensities. In addition to that, the values of both the skewness
and the kurtosis show that the distribution is non-Gaussian.
A less skewed distribution was found by Brady and Field
[BF00] in their analysis of 46 logarithmically transformed
natural images, whereas the linear images resulted in a distribution skewed towards darker values. Although no exact
values were provided for the moments of the distributions,
Figure 2 shows the resulting histograms for both cases.

c 2011 The Authors
Computer Graphics Forum c 2011 The Eurographics Association and Blackwell Publishing Ltd.

1763

T. Pouli et al. / A Survey of Image Statistics Relevant to Computer Graphics

Figure 2: The linear and log intensity histograms found
by Brady et al. from their analysis of 46 natural images.
(Adapted from [BF00].)

Figure 3: The log luminance histograms for corresponding
high and low dynamic range image ensembles [PRC10].
As can be seen from the above examples, although in both
cases natural images were used and analysed, the results vary.
Generally, the distribution of log intensities for natural images does not deviate far from symmetric. Results do depend
however on the choice of images.
Marked differences are found between high dynamic range
(HDR) and low dynamic range (LDR) ensembles, as shown
in Figure 3 [PRC10]. In particular, the quantization seen
toward the left of the LDR ensemble is absent in the HDR
natural image ensemble. The long tails due to the presence of
illumination sources can be captured with HDR techniques,
so that HDR image ensembles have much higher skew and
kurtosis than their LDR equivalents [DLAW01, PRC10].
The shape of a histogram can also be associated with particular qualities of the depicted surface. Motoyoshi et al.
[MNSA07] studied the perceived surface qualities of various materials and analysed their relation to the associated
histograms. They found that materials that are perceived as
glossier tend to have a positively skewed distribution while
matte surfaces result in a negatively skewed distribution.
The correlation found between the surface properties and
the skewness of the histograms is shown in Figure 4.

Figure 4: As the diffuse reflectance of the surface increases,
the lightness rating as perceived by the observers also increases while the corresponding histogram skewness decreases(left). An increase in specular intensity also results
in an increased rating of glossiness as well as higher skewness value (right). (Adapted from [MNSA07].)
correlations between first-order statistical regularities in images and properties of the illuminant [RKAJ08a, APS98]
which have proven useful in areas such as white balancing.
Moreover, transferring statistical moments between images
in appropriate colour spaces has been demonstrated in what
is now known as colour transfer [RAGS01]. These colourrelated application are discussed in detail in Section 5.
First-order statistics can also be computed on a single image basis. By manipulating the distribution of values of a
single image, a variety of effects can be achieved. For instance, the contrast of an image that only covers a small portion of the available range of intensities can be increased by
adjusting the pixel values such that the full range of intensities is more equally represented. This is known as histogram
equalization and an example can be seen in Figure 5.
A more general version of histogram equalization is known
as histogram matching and it allows the histogram of a source
image (Is ) to be matched to that of a given target (It ).
First, the cumulative histograms of the source and target are
computed:
B

Cs (i) =

hs (i)

(9)

ht (i)

(10)

i=1

B

Ct (i) =
i=1

after which an image is matched to another according to these
two cumulative histograms
I0 (p) = vt Ct−1 Cs

I (p) − min(I ) + 1
V

.
(11)

2.1. Histogram adjustments
Despite their simplicity, first-order statistics have now found
several applications in image processing. Studies have shown

Here, a cumulative histogram C is defined as a function mapping a bin index to a cumulative count. The inverse function
C −1 acts as a reverse lookup on the histogram, returning the

c 2011 The Authors
Computer Graphics Forum c 2011 The Eurographics Association and Blackwell Publishing Ltd.

1764

T. Pouli et al. / A Survey of Image Statistics Relevant to Computer Graphics

images resemble a distribution that more or less follows
p(x) = 1/x [AS05]. For such images Benford’s law holds
[AS05]. This law states that for some scale-invariant processes, the distribution of values of the most significant digit d
is not uniform, but rather follows a logarithmic behaviour. In
essence [Hil96],
P (x) = log10 1 +

1
x

,

(12)

where x ∈ [0, 9]. This curious law has applications in imaging, for instance in the detection of JPEG image compression
and in image forensics [FSS07].

2.3. Summary

Figure 5: Histogram equalization can increase the contrast
of a low contrast image (top left) by reshaping the intensity
distribution more equally. The equalized resulting image is
shown at the bottom left.

Because of their limitations to single pixel properties, firstorder statistics are the simplest to compute and interpret.
To further explore the relations between pixels, their spatial
configurations and their associations with aspects of human
vision more complex transforms are necessary. Second- and
higher-order statistics as well as their applications in computer graphics, image processing and other relevant areas are
presented in Sections 3 and 4, respectively.

3. Second-Order Statistics

Figure 6: The source image is matched to the target using histogram matching in the CIELAB colour space. The
resulting image as well as the histograms for all three are
shown.
bin index corresponding to a given count. An example of this
technique applied on a source–target pair of colour images is
shown in Figure 6.
2.2. Benford’s law
Intensity histograms can be seen as probability distribution functions. It can be argued that histograms of certain

Although the first-order statistics of an image provide considerable information, their focus on individual pixels restricts
them to the ‘unstructured’ aspects of the image—equivalent
to an investigation of individual rays of light. As James J.
Gibson [Gib79] famously pointed out, because the interaction of light rays with an object systematically alters light
according to the surface properties of the object, the pattern
of change across a set of light rays—which he referred to
as the structured optic array—provides direct, reliable information about the object. As is demonstrated in Figure 1,
this higher-order structure is of central interest to the human
visual system. It should not be surprising, then, that considerable attention has been directed towards investigating
second and even higher-order statistics. It has been shown,
for example, that people can discriminate almost without effort between images that differ in the second-order statistics
[JC79, Cae81]. This is the basis for the well-known ‘pop-out’
phenomenon.
The first and most obvious way to look at image structure is
to examine the relationship between pairs of pixels. This is the
core of second-order statistics. There are two main secondorder statistics: The power spectrum (3.1) and gradients (3.2).
Note that image contrast (e.g. the standard deviation of all
pixel intensities divided by the mean intensity) is also often
calculated. Image contrast can be derived from the power
spectrum[van98], and will not be discussed here.

c 2011 The Authors
Computer Graphics Forum c 2011 The Eurographics Association and Blackwell Publishing Ltd.

T. Pouli et al. / A Survey of Image Statistics Relevant to Computer Graphics

1765

Figure 7: The average power spectra for 133 natural images. Reused by permission from [RSAT04].
3.1. Power spectra
Images contain information at different spatial scales, from
the large (e.g. the presence of a tree trunk on the right in
Figure 1) to very small (e.g. the pattern of colour change on
the bird’s feathers). As is well known from Fourier analysis,
sharp edges, such as at the silhouette of the tree trunk, can
be described by a weighted sum of sinusoids, with higher
frequencies being weighted less. An examination of the relative power of the different spatial frequencies reveals several interesting trends, which are so prominent that most
work on image statistics provides an analysis of the power
spectrum.
The power spectrum S(u, v) of an N × N image is given
by
S(u, v) =

|F (u, v)|2
,
N2

(13)

where F is the Fourier transform of the image, and (u, v) are
pixel indices in Fourier space. Two-dimensional frequencies
can also be represented with polar coordinates (f , θ ), using
u = f cos(θ ) and v = f sin(θ ). Although the spectra of individual images vary considerably (which may play a role
in the rapid detection of certain scenes or objects [BCT09]),
when averaging over a sufficiently large number of images
(and across orientation), a clear pattern arises: the lower frequencies contain the most power, with power decreasing as a
function of frequency. In fact, on a log–log scale, amplitude
as function of frequency lies approximately on a straight line.
That is, the averaged spectrum tends to follow a power law,
which can be well modelled with P = 1/f β , where P is the
power as function of frequency f and β is spectral slope (see,
e.g. Figure 7).
Increasingly, the spectral slope is being used as a lowdimensional descriptor of texture [BCHT01, CG87, KP88,
RV90, TSW∗ 05]. Perceptually, the primary effect of increasing the spectral slope is to increase the coarseness

Figure 8: Static, random phase patches produced by 1/f β
spatial-frequency filtering of random white noise. From top
to bottom, the values of the spectral slope are 0.8, 1.6, 2,4
and 3.2 for the top left, top right, bottom left and bottom
right, respectively.

of the texture [BCHT01] (Figure 8). Several studies have
reported values for the spectral slope for different image
ensembles. Although the particulars of the image ensembles vary considerably, they tend to focus on natural scenes
(which usually means simply eliminating carpentered environments). The average spectral slope varies from 1.8 to
2.4, with most values clustering around 2.0 (Table 1) [BM87,
DA95, DWA04, Fie87, Fie93, FB97, van92, HLM00, PBT98,
RST01, RSAT04, RB94, Rud94, vv96, TF97, TTC92, TO03,
WM97]. One of the most prominent facets of such a power
law is that these images tend to be scale invariant. That is,
they share features at every scale, which is also a hallmark
of fractal images (note that a simple linear transform of the
spectral slope yields the image’s fractal dimension [CG87]).
In practice, this means that we should be able to zoom in and
out of an image, or travel through a natural scene, and expect that the statistics will remain roughly constant. It is also
worth noting that according to the Wiener–Kintchine theorem, the power spectrum and the auto-correlation function
form a Fourier transform pair. This means that the spectral
slope of image ensembles can be interpreted as describing
relations between pairs of pixels. Intuitively, the means that
since the surface of a given object tends to be rather homogeneous, it is expected that neighbouring pixels will be similar
and that the farther apart two pixels are, the less similar they
will be.

c 2011 The Authors
Computer Graphics Forum c 2011 The Eurographics Association and Blackwell Publishing Ltd.

1766

T. Pouli et al. / A Survey of Image Statistics Relevant to Computer Graphics

Table 1: Spectral slopes for natural image ensembles.

Study
[BM87]
[DA95]
[DWA04]a
[Fie87]
[Fie93]
[FB97]
[van92]
[HM99a]
[PBT98]
[PRC10]
[PRC10]a
[RST01]
[RB94, Rud94]
[vv96]
[TF97]
[TTC92]
[TO03]
[WM97]
a Studies

No. images

β ± 1 SD

19
320
95
6
85
20
117
216
29
95
95
133
45
276
82
135
12,000
48

2.1 ± 0.24
2.30
2.29
2.0
2.20
2.20 ± 0.28
2.13 ± 0.36
1.96
2.22 ± 0.26
2.22 ± 0.24
2.24 ± 0.14
1.88 ± 0.42
1.81
1.88 ± 0.42
2.38
2.4. ± 0.26
2.08
2.26

were carried out on high dynamic range data.

The 1/f property of images seems to arise from several
sources. Edges, for example, show 1/f spectra [SMS78].
Similarly, foliage and landscapes tend to exhibit fractal properties [Man83]. The clustering of independent objects is also
such that the distribution of sizes in many scenes also tends
to follow a power law [FB97, Rud97].
There is also some emerging evidence that the slope of
the power spectrum is distinct for different scenes or objects
[HM99b, TO03, WM97, PRC10]. For example, Huang and
Mumford [HM99a] examined 216 images which had been
painstakingly segmented into pixels representing 11 different
categories and found that although the image ensemble had
an average slope of 1.96, there were systematic differences
in the slopes across categories. Specifically, the slopes were
2.3, 1.8, 1.4 and 1.0 for man-made, vegetation, road and
sky pixels, respectively. Similarly, Webster and Miyahara
[WM97] analysed the power spectra and RMS-contrast of
48 natural scenes. They found significant differences in both
spectral slope and contrast across the three scene types (2.15,
2.23 and 2.4 for the forest, close-up, and distant meadow
scenes, respectively).
Pouli et al. examined the differences that one might expect
between LDR and HDR image ensembles, and furthermore
collected ensembles consisting of natural scenes, manmade
scenes, indoors and night-time scenes [PRC10]. Especially
for the latter two, they found spectral slopes that were significantly higher than for natural scenes. The HDR ensembles
show particularly steep slopes for these categories (2.61 and
2.68), whereas natural day-time scenes produced a slope of
2.24.

Furthermore, when the power spectra are not averaged
over all orientations, it is clear that there is some variation as
a function of angle: natural images tend to concentrate their
power in horizontal and vertical angles [BAM∗ 97, OT01,
Rud97, SMS78, vv96]. For example, in examining over 6000
man-made and 6000 natural scenes, [TO03] found that the
slope varied as a function of both scene type and orientation
(with slopes of 1.98, 2.02 and 2.22 for horizontal, oblique and
vertical angles in natural scenes and 1.83, 2.37 and 2.07 for
man-made scenes). Thus, the spectral slope may be useful
in object or scene discrimination [BCT09]. It is critical to
mention that if two images have similar spectral slopes, then
swapping their power spectra will not affect recognition as
long as phase information is preserved [TTC92, TT93].
It has also been shown that the pattern of change over time
follows a power law. That is, if the contrast modulation over
time for a given pixel is examined, the power spectra can also
be modelled with P = 1/f α , where P is the power as function
of frequency f , and α is temporal spectral slope [BGK01,
DA95, EBW92]. Temporal spectral slopes between 1.2 and
2.0 have been reported for natural image sequences. The
temporal spectral slope relates, perceptually, to the apparent
speed and jitter of the scene and to some degree with the
apparent purposefulness of the motion (the higher the slope
is, the more persistent the motion will be).

3.1.1. Human perception
There is an extremely large body of work examining the
relationship between natural image statistics and human perception. At the simplest level, our ability to discriminate two
random phase textures based solely on changes in the spectral slope has been examined [BCHT01, BCT09, KFK90,
TT94]. Humans are most sensitive to slopes around 2.8–3.2,
which would represent an image with much less high spatial
frequency content than natural images. There is some evidence (albeit controversial) for a second minimum near 1.2.
Rainville and Kingdom examined the ability to detect symmetry for white noise images with different spectral slopes
and found that one participant was best for slopes near 2.8,
consistent with the image discrimination data. The other participant was best for slopes between 1 and 2, consistent with
the potential second minima [RK99].
Regardless, it is clear that humans are not maximally sensitive to changes in spectral slopes representing natural images. The reasons for this are still unclear, although several
hypotheses have been forwarded including that the shift from
2 to 2.8 reflects blur perception [Bil00].
Instead of attempting to determine the tuning of the visual
system by measuring discrimination, one can approach the
problem more indirectly: one can estimate the sensitivity of
the spatial perception mechanisms from an auto-correlation
analysis of contrast sensitivity function (which has been

c 2011 The Authors
Computer Graphics Forum c 2011 The Eurographics Association and Blackwell Publishing Ltd.

T. Pouli et al. / A Survey of Image Statistics Relevant to Computer Graphics

1767

referred to as a modulation transfer function of the human
visual system).

most famous of these synthetic scenes are the eerily familiar
landscapes produced in Voss’s “fractal forgeries” [Vos85].

It is generally accepted that human spatial perception is
mediated by several, partially overlapping spatial frequency
channels (at least 7 at each orientation: see, e.g. [Bil00]).
Because similar frequencies are likely to be processed by the
same channel, the sensitivity to similar frequencies should
be similar. The less similar the frequencies are, the less correlated their sensitivity thresholds should be [BH96, OSS83,
PWK95, SWO84].

In the class of landscape synthesis, a white noise field is
filtered in Fourier space with the desired spectral slope to
produce the terrain texture of the field [PS88]. In such methods, the role of natural image spectra is obvious. In a second class of approaches, the midpoint displacement method
[FFC82], the role of power spectra is perhaps less obvious. In
this approach, terrain is essentially generated by iteratively
decreasing the spatial scale and (random) displacement. In
general, the procedure is capable of producing a wide range
of results, some of which look realistic and others which do
not. A closer examination of the method shows that changing the size of the displacement decrement effectively allows
one to control the coarseness of the texture. Because the
coarseness of a texture is directly related to its spectral slope,
it should be possible to automatically determine which displacement decrements produce natural terrain. The results of
a simple perceptual study support this, showing that people
felt that synthetic terrains that had a spectral slope of near
1.8 appeared to be the most natural [RSAT04].

Billock [Bil00] examined the correlation between contrast
sensitivity thresholds as a function of the spatial frequency
separation, and found that (for up to 5 octaves) the correlation functions were power laws with slopes ranging from
2.1 to 2.4. This held not only for static stimuli, but also
for slowly flickering stimuli (up to 1 Hz). These slopes are
much more in line with the slopes found in natural images,
suggesting that human spatial frequency mechanisms may
be optimized for natural images. Interestingly, more rapid
flicker yielded higher slopes (around 2.6). As mentioned earlier, higher slopes reflects an attenuation of the higher spatial frequencies. Billock suggested that the higher slopes for
rapidly flickering images may represent motion deblurring.
In contrast, the discrimination of temporal spectral slopes
appears to be more straight forward. Humans are most sensitive to differences in temporal spectral slope for slopes
between 1.8 and 2.0, which is very similar to the range of
slopes in natural image sequences.
The existence of spatial frequency channels in the human
visual system are also implicated in lightness perception.
Dakin and Bex have shown that if the amplitude of the response of these channels to natural stimuli is weighted according to their scale, that is with weights ws proportional
to 1/f −s , their combined response correlates well with the
perception of lightness [DB03]. In particular, it can explain
the Cornsweet-Craig-O’Brien [Cor70] and White’s illusions
[Whi79].

3.1.2. Fractal forgeries
Thanks in large part to the seminal work of Mandelbrot
[Man83], many areas of computer graphics use fractals to
synthesize textures, surfaces, objects or even whole scenes
(see, e.g. [DCCH05, DL05, PS88]). A subset of this work
focuses on fractal Brownian motion in general and fractal
Brownian textures in specific, which bear striking resemblance to real surfaces and textures. Because the fractal dimension of such a fractal texture is a linear transform of
the spectral slope, these works are essentially relying on the
regularities in power spectra. Many of these techniques either explicitly or implicitly choose parameters so that the
spectral slope will be similar to natural images. Perhaps the

Perhaps the second most common application of power
spectra, again through the use of fractal dimensions, is the
automatic generation of plants. Considerable literature has
been written on plant synthesis (see, e.g. [DL05] for a review). Overall, it is well known that plants tend to exhibit a
strong degree of self-similarity, and many descriptive systems
have been developed to taker advantage of this characteristic. The most prominent of these are L-systems. Just as with
fractal terrains, the system allows one to generate a wide variety or results, some of which are perceptually plausible and
some of which are not.
3.1.3. Image processing and categorization
Although a power law description clearly captures the regularities in large collections of images, individual images
tend not to be 1/f . It has been suggested that differences in
the spectral slope between parts of an image allow people
to rapidly make some simple discriminations (e.g. ‘pop-out’
effect, see [BCT09, Cae81, JC79]). Others have speculated
on the evolutionary advantage of being able to detect spectral
slope [Bil00, BCT09, CHJ78, HB96, RV90]. Just as knowing
about the statistics of natural images in general can inform us
about how the human visual system works, and how we might
build more efficient computer vision and computer graphics
algorithms, so too will an understanding of the cause of
variations in the statistics provide insights.
A number of potential sources for 1/f patterns and their
variations have been identified [Man83, FB97, HM99b,
Rud97, SMS78, TO03, WM97]. For example, [HM99b] and
[WM97] found different average spectral slopes for different scene categories (both within as well as between images): at the very least, there seem to be differences between

c 2011 The Authors
Computer Graphics Forum c 2011 The Eurographics Association and Blackwell Publishing Ltd.

1768

T. Pouli et al. / A Survey of Image Statistics Relevant to Computer Graphics

man-made, general vegetation, forest, meadow, road, and
sky elements. It has also been shown that underwater scenes
have different spectral slopes [BG03]. To help further distinguish between object or scene categories, one can look at
the interaction between power spectra and other characteristics [BAM∗ 97, OT01, Rud97, SMS78, vv96]. For example,
[OT01] suggested that a ‘spatial envelope’ of a scene can be
constructed from the interaction between power spectra and
orientation combined with some information from principal
components analysis (PCA). This envelope yields perceptual dimensions such as naturalness, roughness, expansion
and similar categories tend to cluster together in this scene
space. In [TO03], the approach was extended to estimate absolute depth using the relationship between power spectra
and orientation and some information from wavelets.
In a related line of work, Dror et al. used a variety of natural
image statistics to estimate the reflectance of an object (e.g.
metal vs. plastic) under conditions where the illumination
is unknown [DAW01]. They employ a wide range of image
statistics from simple intensity distributions through oriented
power spectra to wavelet coefficient distributions.
It has been suggested that the differences between the average spectral slope of 2.0 and the peak of human sensitivity to
changes in slope (at 2.8) is due to deblurring. Furthermore,
it has been suggested that the higher slopes for an autocorrelation analysis of human contrast sensitivity is due to
motion deblurring. In an indirect examination of this claim,
Dror and colleagues examined the properties of Reichardt
correlator motion detections [DOL00, DOL01]. Although
there is considerable evidence that the human visual system
uses such correlators for the low-level detection of motion, it
has also been shown using typical moving gratings that they
signal temporal frequency and not velocity. Dror demonstrated that when stimuli that have natural image statistics
are used, the response properties of Reichardt detectors is
better correlated with velocity and suggest that they make a
much better basis for the synthetic processing of motion than
previously assumed.

3.2. Gradients
Perhaps the simplest way to examine information contained
in more than a single pixel, however, is to look at the relationship between pairs of pixels. This is a discrete approximation
of the first derivative or gradient of the intensity function of
an image. There are three different discrete approximations:
forward/backward differences, central differences, and the
Sobel operator. The most straightforward is the forward difference method. Here, the gradient at a pixel (i, j) is calculated
from the difference between it and the next pixel forwards
Dx (i, j ) = ln(I (i + 1, j ) − ln(I (i, j ))),

(14)

Dy (i, j ) = ln(I (i, j + 1)) − ln(I (i, j )),

(15)

Figure 9: Gradient distributions for a collection of natural
images. Dx and Dy are the horizontal and vertical gradients
(first derivative of the intensity function), respectively. Dxx
and Dyy are the horizontal and vertical second derivatives.
where I (i, j ) is the luminance for pixel i, j , Dx is the horizontal gradient and Dy the vertical gradient. Computing gradients
in log space has the advantage that they represent contrasts,
as pixel ratios become pixel differences in log space.
An obvious variant on this, referred to as the backward
difference method, is to use the previous pixel [e.g. I (i − 1,
j )] rather than the next one. In both cases, it is common to
calculate the mean gradient magnitude at a given location
from the horizontal and vertical components
D(i, j ) =
=

Dx (i, j )

(16)

Dy (i, j )
Dx (i, j )2 + Dy (i, j )2 ,

(17)

although one may choose to keep the horizontal and vertical gradients separate (as for instance in Levin’s motion
deblurring technique [Lev07]). An example of the gradient
distribution for an image ensemble can be seen in Figure 9.
A somewhat more robust method is to calculate the central
differences:
Dx (i, j ) = 1/2(ln(I (i − 1, j )) − ln(I (i + 1, j ))),
(18)
Dy (i, j ) = 1/2(ln(I (i, j − 1)) − ln(I (i, j + 1))).
(19)
Finally, one can convolve an image with the Sobel operator, which also considers the diagonal neighbours
⎡
⎤
1 0 −1
⎢
⎥
(20)
Sx = ⎣ 2 0 −2 ⎦ ,
1

0

−1

c 2011 The Authors
Computer Graphics Forum c 2011 The Eurographics Association and Blackwell Publishing Ltd.

T. Pouli et al. / A Survey of Image Statistics Relevant to Computer Graphics

⎡

1
⎢
Sy = ⎣ 0

2

−1

−2

1

⎤

⎥
0⎦.

0

(21)

−1

Just as was the case for power spectra, image gradients
have been extensively investigated (see, e.g. [RB94, Rud94,
HM99b, HLM00, DLAW01, DWA04, PRC10]). It has been
repeatedly found that the gradient histogram has a very sharp
peak at zero (Figure 9) and then falls off very rapidly, with
long tails at the higher gradients. The distribution can be
α
modelled as e−x with α < 1 [LZW02, Sim05]. The reason for
the specific shape of the gradient distribution seems to be that
images contain many large surfaces, which tend to be smooth
and somewhat homogeneous (so that the gradients tend to be
near zero) along with a few high contrast edges (which will
yield very sharp gradients) [BG00]. An object often finds
itself over a consistent background, which means that the
transition from the object’s surface to the background will be
similar all along the object’s silhouette. This is reflected in
the symmetry of the gradient distribution around the central
peak.
Applications of knowledge of gradient distributions include image deblurring, image inpainting (both discussed in
the following sections) as well as the removal of vignetting
from photographs ZYK∗ 08.
3.2.1. Edge orientation histograms
Edge histograms encode the occurrence of edges at different
angles. It is for instance possible to compute horizontal, vertical and diagonal edges (at 45◦ and 135◦ ), as well as isotropic
and non-edge categories. Histograms of each category then
form a feature descriptor known as the edge histogram descriptor (EHD), that is for instance used in the MPEG-7 XM
model [MOVY01], as well as in image retrieval and scene
classification [SBM∗ 05]. This technique forms one of the
components of an algorithm to differentiate natural images
from man-made scenes, where in particular the standard deviation edge orientation histograms is indicative of naturalness, both for conventional and HDR images [DBO08]. Note
that edge orientations encode information similar to oriented
power-spectra, as discussed in Section 3.1.
3.2.2. Image deblurring
When taking a photograph of a scene, it is not uncommon
that either the camera or an object in the scene moves. The
longer the aperture is open, the more likely this is to be the
case. As a result, all or part of the image will be blurred.
A number of approaches for sharpening an image have been
proposed. One type of approach, blind motion deconvolution,
essentially treats the photograph as the result of a convolution
between an unknown sharp image and an equally unknown
blurring kernel. The goal is to estimate the blur kernel so that
it can be deconvolved with the blurred image to yield the

1769

sharp image. Naturally, this is an underspecified problem, so
additional constraints are needed and recently, a number of
researchers have employed natural image statistics to provide them. For example, Caron et al. assume that the sharp
image’s power spectrum follows a power law distribution
[CNR02], whereas Jalobeanu et al. and Neelamani et al. use
an interaction between power spectra and wavelets [JBFZ02,
NCB04]. Fergus et al. estimate the blur kernel by optimizing for the gradient distributions using priors derived from
natural images [FSH∗ 06].
All of these approaches assume camera motion. This implies that there is a single blur kernel for the entire image.
In an alternate approach, Levin uses the gradient structure to
find those pixels that are blurred and segment them from the
rest of the image [Lev07]. In addition, rather than use statistics of sharp images, they include statistics of the blurring
process. Specifically, they model how the gradient distribution changes as a function of blurring to discover the blurring
kernel for a given image. One primary feature of motion blurring is the attenuation of higher frequencies. This shows in
the slope of the power spectra (by increasing β) as well as
in the gradient histogram (e.g. in particular by removing the
longer tails at the higher gradients). Levin attempts to recover
the blur kernel by applying different blurs to the image to find
the one that produces a gradient histogram that matches the
blurred one. This requires a non-blurred image or image region. Using a completely different image tends not to produce
reliable results (due to differences in the underlying gradient histogram). Because much terrestrial motion tends to be
horizontal, the majority of the effects of motion blurring are
also horizontal. Thus, the vertical gradients can under some
circumstances be used to calculate the blur of the horizontal
components.
In a further refinement, Shan et al. employ an iterative
alternation between optimizing the blur kernel and the sharp
image using priors from natural image statistics [SJA08].
In related work, [MFTF03] use the gradient distribution to
fill in the holes produced when a high-resolution image is
produced from a low resolution image (a process called super
resolution). They also apply the same procedure to yield a
full colour image from a achromatic image.
Similarly, there are many approaches for removing the
noise in an image. Recently, several researchers have had
considerable success using gradient distributions (and occasionally other natural image statistics) to denoise images
[RB05, RB09, Sim05].
3.2.3. Image inpainting
One image processing application area where image statistics
have been used successfully is known as image inpainting.
To remove an unwanted object from an image, the texture
that would otherwise be behind that object needs to be recreated, a task that can be particularly difficult if the holes
are large.

c 2011 The Authors
Computer Graphics Forum c 2011 The Eurographics Association and Blackwell Publishing Ltd.

1770

T. Pouli et al. / A Survey of Image Statistics Relevant to Computer Graphics

Among the various approaches, several have used image
statistics to find optimal replacements for the missing texture and structure, usually by assuming that a patch similar to the missing portion can be found somewhere in the
remaining image. For example, Hirani et al. use a combination of spectral and spatial information to find the replacement patch [HT96]. Levin et al. select the missing region
that best matches the gradients at the boundary region and
also maximises the match of the global gradient histogram
[LZW03]. Finally, Shen et al. fill in the missing region by
completing the gradient maps and then reconstructing the
image by solving a Poisson equation [SJZW07].
4. Higher-Order Statistics
Whereas second-order statistics take into account pairs of
pixels through various transformations (in particular gradients and the amplitude spectrum), it is possible to find statistical regularities in larger groups of pixels using suitable
image manipulations. In particular, gradient statistics can be
extended in a hierarchical fashion to consider blocks of pixels by means of wavelet transforms. Further, it can be shown
that much of the structure of images is located in the phase
spectrum, as opposed to the power spectrum.
PCA can be used to capture structure in images. It effectively allows the most important sources of commonality between images or within a single image to be assessed. Each
principal component represents a dimension along which
variability can be measured. They are typically ordered so
that the first principal component accounts for most of the
data, whereas each subsequent component accounts for progressively less of the structure in the data. Each of the components are orthogonal with respect to each other.
The orthogonality of the axes can be seen as a limitation. A
better, albeit computationally much more involved technique
is independent components analysis (ICA). Rather than producing decorrelated axes that are orthogonal as achieved with
PCA, ICA finds axes that are more or less independent, but
which are not necessarily orthogonal.
In the following sections, each of these approaches is outlined in more detail, as well as more recent approaches to
characterize higher-order statistics. These include a full characterization of image patches, fields of experts and sparse
coding.
4.1. Phase structure
It can be argued that although statistical regularities are
present in power spectra of natural images, much of the perceptually relevant information is encoded in phase spectra
[Tho99]. As an example, we have swapped the phase spectrum of two images, shown in Figure 10. As can be seen,
much of the image structure has swapped. Thus, the image structure is largely encoded into the phase spectrum.
Second-order statistics such as the auto-correlation function

Figure 10: In this demonstration, the phases of the top two
images are swapped to produce the bottom to images. The
amplitude spectra are retained. Note that much of the image
structure is located in the phase spectrum, and has therefore
been swapped.
(and therefore power spectra in Fourier space) and variance
are insensitive to signal phase. They therefore do not adequately measure image structure.
To gain access to phase information without polluting
the results with first- and second-order information, we can
whiten the images first [Tho99, Tho01]. This amounts to adjusting the spectral slope to become flat. The auto-correlation
function will therefore be zero everywhere, except at the origin. Alternatively, PCA can be applied to whiten a signal
(Section 4.3). By removing the second moment from consideration, it is now possible to compute skewness and kurtosis
on the whitened signal. The whitened skew Sw and whitened
kurtosis κw are thus a measure of variations in the phase
spectra.
The results of applying this procedure to a set of natural
images, leads to the conclusion that the whitened images are
almost always positively skewed and are always positively
kurtosed. In contrast, if the phase spectrum is randomized

c 2011 The Authors
Computer Graphics Forum c 2011 The Eurographics Association and Blackwell Publishing Ltd.

1771

T. Pouli et al. / A Survey of Image Statistics Relevant to Computer Graphics

on the same images, the whitened skewness and kurtosis are
close to zero.
Although positive skewness and kurtosis of phase spectra
points in the direction of the presence of statistical regularities in the phase spectrum, these results are relatively
weak and do not easily explain aspects of human vision. Furthermore, they do not appear to have found employ in any
graphics-related applications that we are aware of (although
it may lead to higher-order constraints in texture synthesis
algorithms). In the following section, however, we will discuss how extending the present analysis to be localized in
space leads to further and stronger insights.

4.2. Wavelets
In the preceding section, we have seen that second-order
statistics, and in particular the amplitude spectrum of image
ensembles, show striking statistical regularities. The amplitude spectrum can be analysed for different orientations, but
as it is computed in Fourier space, it provides information of
whole images rather than regions of images.
In this section we study transforms that allow us to analyse images in local regions of space, as well as for different orientations and spatial frequencies. Such models and
transforms started with Gabor who introduced the notion
of time–frequency representations [Gab46]. It is noted that
these systems are in some sense similar to how images are
analysed by portions of the human visual system.
Wavelet transforms are self-similar, consisting of spatially
localized band-pass basis functions which vary only by a
dilation, translation or rotation [Fie93]. The basis functions
applied to a signal x thus derive from a prototype function
φ(x) which can be applied at different scales s and locations
l, leading to a set of basis functions φ s,l (x) [HHH09]:
φs,l (x) = 2−s/2 φ(2−s x − l).

(22)

Wavelets have found many direct applications in image
analysis and image processing. In particular, they have been
successfully used for the transmission of the chromatic components of HDTV signals [Wat90, Wat91], texture segregation [BCG90], compact coding [Wat87, Dau88, ASF91],
image de-noising [DJ95] and in identification systems
[Dau91].
Wavelet transforms using a variety of basis functions have
also been used to model the spatial response properties of
cells in the mammalian visual system [Fie93]. In particular,
Gabor functions—sinusoids weighted by a Gaussian—are
one of the more popular transforms. Nonetheless, these particular bases are non-orthogonal, making them difficult to
invert and use in modelling [Fie93]. As a result, orthogonal
bases were developed [ASH87, WA89, ASF91].

Cells in the visual system respond to certain patterns of
light and dark, with each cell responding optimally to a specific pattern. It has been demonstrated that groups of cells
in the visual cortex of several different species of mammal
respond to wavelet-like structures, in particular the Gabor
function [Mar80]
φ(x, y) = sin(2π kx +

) exp

−y 2
−x 2
+
2
2σx
2σy2

. (23)

A Gabor filter and an image processed with it are shown in
Figure 11. As can be seen, the local oriented structure in the
image is analysed at the specific frequency determined by
the sinusoidal component of the filter.
It is possible to extend this description by making the
bandwidth proportional to the frequency, so that the variances
σ x , σ y in the above equation are related to frequency band k
σx,y (k) = βk −α .

(24)

This allows us to build a stack of filters, each level in the
stack tuned to a different set of frequencies, in proportion to
the position in the stack. Each level in the stack is also known
as the scale.
Although the amplitude spectrum has shown scale invariance (Section 3.1), the phase structure revealed by Fourier
space analysis remains somewhat of a mystery (Section 3.1).
However, by analysing wavelets, which are simultaneously
localized both in space and frequency, it can be shown that
natural images are scale in variant in both phase and amplitude [Fie93].
This means that in local image regions, the locations of
edges are correlated across scales. At higher frequencies
neighbours in frequency become more highly correlated,
whereas neighbours in space become less correlated. In other
words, phases in natural images contain alignment that extend over greater ranges at higher frequencies [Fie93]. Phase
structures tend to change somewhat in orientation as well as
position when moving across scales. Such behaviour can be
analysed with wavelets. It is therefore possible that this may
help explain why mammalian visual systems use wavelet-like
structures in the visual cortex. It may well be that this is why
wavelets are useful in a range of applications, as outlined
above.
It was found that the distributions of histograms of wavelet
coefficients are highly non-Gaussian [Fie87, Mal89], showing in particular long tails, that is having high kurtosis. In
particular, these histogram distributions can be modelled by
a generalized Laplacian [Mal89, SA96, Sim99b]:
P (x) =

exp(−|c/s|p )
,
(2s/p) (1/p)

(25)

where is the gamma function and the parameters s and p
can be used to fit the model to a specific image or image
ensemble.

c 2011 The Authors
Computer Graphics Forum c 2011 The Eurographics Association and Blackwell Publishing Ltd.

1772

T. Pouli et al. / A Survey of Image Statistics Relevant to Computer Graphics

Figure 11: Examples of Gabor filters and an image processed with them.
If the bandwidths of the wavelet filters are chosen to be
around 1–2 octaves, that the kurtosis of the histograms of
wavelet transforms is maximal. This means that under these
conditions the resulting transform is maximally sparse. In
clusters of neurons, sparsity is an important feature. It means
that much of the variability in the input signal is explained
by a small number of neurons [Fie94]. Such neuronal activity is metabolically efficient [Bad96], minimizes wiring
length [Fol95], and increases capacity in associative memory [BMW88].
Similarly, in a wavelet transform, sparsity means that most
coefficients are small, with only a few coefficients having
larger values. This is for instance the basis for image compression algorithms [BS99]. By replacing small coefficients
with zero coefficients a lossy image compression algorithm
can be constructed. This approach is used for instance in
the JPEG2000 image compression standard [TM01]. Furthermore, wavelet-like receptive fields are discovered when
training a neural network for sparseness [OF96].
Of course, we are still free to choose the basis functions.
In many applications, for reasons of computability a much
simpler set of basis functions are used. In particular, the Haar
bases are used. In a Haar decomposition, an image is split into
averages and differences with those averages. The averages
are computed by a set of scaling functions [SDS95, SDS96]:
k
i

= φ(2k x − i) i = 0, . . . 2k − 1,

(x) =

1

for 0 ≤ x < 1,

0

otherwise.

(26)

(27)

The differences are computed with the mother wavelet
function:
ψik = φ(2k x − i)

i = 0, . . . 2k − 1

(28)

Figure 12: Left: Original image. Right: An example of a
Haar wavelet decomposition with three scales. The top left
image in the decomposition represents averages, whereas the
remaining panels indicate differences in horizontal, vertical
and diagonal directions.
⎧
1
⎪
⎨
ψ(x) = −1
⎪
⎩
0

for 0 ≤ x < 1/2,
for 1/2 ≤ x < 1,

(29)

otherwise.

An example of a Haar wavelet decomposition with three
scales is shown in Figure 12.

4.2.1. Image denoizing
An example application of wavelet statistics is image denoizing [Sim99a, PS00, PSWS03], where a Bayesian approach
is employed to remove noise. Assuming that the wavelet coefficients of natural images follow a generalized Laplacian
distribution, as outlined earlier, Gaussian image noise translates into Gaussian pollution of wavelet coefficients. Each
coefficient can therefore be written as y = x + n, with x
drawn from the density given by Equation (25) [Sim99a].
The noise n is Gaussian. A standard estimator for x given
the corrupted image y is the maximum a posteriori (MAP)

c 2011 The Authors
Computer Graphics Forum c 2011 The Eurographics Association and Blackwell Publishing Ltd.

1773

T. Pouli et al. / A Survey of Image Statistics Relevant to Computer Graphics

estimator
ˆ
x(y)
= arg max P (x|y),
c

(30)

= arg max P (y|x)P (x),

(31)

= arg max Pn (y − x)P (x).

(32)

c

c

Thus, by applying Bayes rule, the estimator is rewritten
as the product of the Gaussian noise density Pn (y − x) and
the prior density of the signal coefficient P(x). If we assume
that the parameter p in Equation (25) is set to 2 the estimator
becomes linear
ˆ
x(y)
=

σx2
y.
σx2 + σn2

(33)

For other values of p the estimator is non-linear. For instance
p = 0.5 and p = 1 lead to hard thresholding and soft thresholding, respectively. In television and video engineering such
thresholding is known as coring [BP86].
This approach assumes that wavelet coefficients are independent. Although wavelet coefficients are on average zero,
showing that their values are decorrelated, they are not independent. Although beyond the scope of this report, it can be
shown that correlations between x and p can be accounted
for using a joint statistical model for the purpose of denoizing [Sim99a], image compression [Sim97], as well as texture
synthesis [SP98].
An alternative approach to denoizing begins by applying
a discrete wavelet transform to the noisy image [DJ95]. At
each level, coefficients below a threshold ts are set to 0, while
supra-threshold values are pulled towards 0, thus making
the thresholding operation gentler. Such soft-thresholding is
also known as shrinkage. A smoothed image is reconstructed
by applying the inverse wavelet transform. At each wavelet
level s the threshold ts is chosen according to a risk estimate,
allowing the smoothing operator to adapt to the data.

In particular, wavelet pyramids have been used to assess
these differences based on a model of natural image statistics
[LF05]. At each level of the pyramid, histograms are built for
the horizontal, vertical and diagonal coefficients. These histograms are then characterized by their first four moments. In
addition, correlations between neighbouring pixels in space,
orientation, colour and scale are characterized by means of
a linear predictor. The first four moments of the weights
estimated for each of these neighbours are also collected.
These moments are subsequently encoded into a feature
vector for each image. By training a support vector machine
(SVM), photographs can be classified with an accuracy of
66.8%, whereas photorealistic renderings can be classified
with an accuracy of 98.8%.
This technique has also been used for steganalysis [LF06].
A different statistical approach with reportedly better classification accuracy is briefly described in Section 4.5.

4.3. Principal components analysis
One of the main properties of natural images is that pixel values are correlated. Nearby pixels tend to have similar values
while these correlations tend to be less strong as the distance
between pixels increases [HBS92]. One way to analyse these
correlations is by decomposing the image data into a set of
components that are as decorrelated as possible (Section 5.2).
Simultaneously, it allows as much of the variance in the data
to be described by as few components as possible [HHH09].
Each of these components will then capture some particular
mode of variation within the data.
PCA (also known as the Karhunen-Lo´eve transform) is
a solution commonly employed to that end. By computing
the eigenvectors and corresponding eigenvalues of the covariance matrix of the image collection, a set of orthogonal,
decorrelated components can be derived. The covariance between two variables X and Y, each consisting of n samples,
is defined as

Soft-thresholding has also been applied in the context of
sparse coding, leading to a scheme that is even better adapted
to the signal that is being de-noised [Hyv99b].
4.2.2. Differentiating between renderings
and photographs
The field of computer graphics has matured significantly in
the last 30 years or so. The consequence of this is that the
visual quality of computer generated imagery has in many
instances become good enough to be difficult to distinguish
from real photographs. This has given rise to an emerging
field which aims to create detection algorithms to assess
whether an image is a photograph or a computer generated
forgery. It turns out that there are still subtle but measurable
differences between these two classes of image.

¯ i − Y¯ )
ni=1 (Xi − X)(Y
,
n−1

cov(X, Y ) =

(34)

where n is the number of elements in X, Y. Note that
cov(X, X) gives the variance of X. To capture the covariance between more than two variables, a covariance matrix
C can be computed. For m variables {I 1 , I 2 , . . . , Im }, each
consisting of n samples, the covariance matrix C is given by
⎡

cov(I1 , I1 )

⎢
⎢ cov(I2 , I1 )
⎢
C = ⎢.
⎢.
⎣.
cov(Im , I1 )

cov(I1 , I2 )

···

cov(I2 , I2 )

···

..
.

..

cov(Im , I2 )

···

.

cov(I1 , Im )

⎤

⎥
cov(I2 , Im ) ⎥
⎥
⎥.
..
⎥
.
⎦
cov(Im , Im )
(35)

c 2011 The Authors
Computer Graphics Forum c 2011 The Eurographics Association and Blackwell Publishing Ltd.

1774

T. Pouli et al. / A Survey of Image Statistics Relevant to Computer Graphics

The matrix of eigenvectors V of C and the diagonal matrix
of corresponding eigenvalues D can then be computed such
that C = VDV−1 .
Components with a larger eigenvalue correspond to more
important features whereas lower eigenvalues signify less important components. This representation offers the advantage
that a relatively small number of components is sufficient to
encode most of the information in the images.
Finally, note that whitening, as discussed in Section 3.1
can also be achieved by applying PCA. A whitened signal has unit variance and is uncorrelated. PCA creates an
uncorrelated signal. By dividing the principal components
by their variance, we create whitened components. This
is used for instance as a pre-processing technique to ICA
(Section 4.4).
4.4. Independent components analysis
Although PCA measures covariances of pixels separated by
varying distances, the components that are found constitute
a linear transform. This means that although the data may
be decorrelated, there is no guarantee that the resulting components are in any way independent. In particular, only if
the input data happens to have a Gaussian distribution, then
the resulting principal components are both decorrelated and
independent.
As we have seen, many of the statistics of natural images
that are currently known point in the direction of high kurtosis, that is they are highly non-Gaussian. This has given rise
to the use of ICA [Com94, HKO01], which is a technique
to separate a multivariate signal into a set of components
that are likely to have produced the original signal under the
assumption that the input is non-Gaussian. ICA is a special
case of blind source separation, which is a general collection
of techniques that try to separate a set of signals from a mixed
signal without prior knowledge of the source signals or the
mixing process [Ach08].
ICA algorithms tend to require a set of pre-processing
steps to make the problem more tractable. In particular, the
data need to be centred and whitened. Also, data reduction is
often applied. The whitening can be achieved by running the
PCA algorithm first. By keeping only the first n components,
data reduction is achieved. It ensures that only those components are used that are meaningful to the problem being
solved. Moreover, it speeds-up the computations required to
determine independent components.
Several algorithms are known, including infomax [BS95],
extended infomax [LGS99], fastICA [Hyv99], Jade [Car99],
kernel ICA [BJ02] and RADICAL [LMF03]. Although the
implementations vary, their goals are the same: represent
multivariate data as a sum of components in such a way that
the components reveal the underlying structure that gave rise
to the observed signal.

The number of ICA algorithms available, and their computational and algorithmic complexity make an in-depth discussion of this class of algorithms beyond the scope of this
report. However, we will discuss some of their implications
for natural image statistics as well as human vision.
One could ask what are the independent components in the
context of natural images. It could be argued that these are
the objects that comprise a scene [OF97]. It is exactly these
that provide the structure that gives rise to the pixel array that
is analysed by computer algorithms as well as by the human
visual system. Both PCA and ICA, however, are generative
models which are based on linear superposition. Thus, they
cannot take into account translation and rotation of objects
[OF97].
However, it has been found that small image patches of
natural image ensembles can be analysed using ICA, revealing structures that resemble those found in the human
visual system [BS97]. In particular, this technique yields
Gabor-like patches—elongated structures that are localized
in space, orientation and frequency. Their size, aspect ratio, spatial frequency bandwidth, receptive field length and
orientation tuning bandwidth are similar to those measured
in cortical cells [vv98]. These results lend credence to the
argument that the human visual system appears to represent natural images with independent variables, each having
a highly kurtotic distribution that leads to a metabolically
efficient sparse coding.
Although linear transformations such as PCA and ICA
attempt to decompose an image into decorrelated or independent components, this works under the assumption that
the image is composed of a linear combination of Gaussian
or non-Gaussian sources. If the composition is non-linear,
which appears to be the case for natural images, dependencies
may be removed by a non-linear transform [LS09b, LS09a].

4.5. Full characterization of image patches
PCA and ICA make certain limiting assumption on the images by finding in some sense optimal linear projections or
basis functions. On the other hand, it is possible to attempt a
characterization of the full probability distribution of image
patches directly [LPM03].
To achieve this, Lee et al. select high-contrast patches of
3 × 3 pixels, which are then pre-processed by subtracting the
mean and normalizing their contrast [LPM03]. The resulting
data can be shown to lie on a seven-dimensional ellipsoid in
R9 . A change of bases is then used to make the points lie on
a Euclidian sphere.
To analyse the distribution of patches over the highdimensional sphere, the sphere is first tessellated according
to a Voronoi decomposition. The set of Voronoi cells are then
used as histogram bins, populated by a set of high-contrast

c 2011 The Authors
Computer Graphics Forum c 2011 The Eurographics Association and Blackwell Publishing Ltd.

T. Pouli et al. / A Survey of Image Statistics Relevant to Computer Graphics

patches of a large number of images. It turns out that the
distribution over Voronoi cells is extremely sparse: half the
patches project to less than 6% of the Voronoi cells.
Examining the small set of most highly populated cells,
it is found that for high-contrast patches of natural scenes,
these predominantly correspond to blurred step edges at various orientations. Lee et al. repeated this analysis on range
data, and found that most of the 3 × 3 range patches with high
contrast resemble binary patches [LPM03], indicating a qualitative statistical difference between images and depth maps.
Similarly, Ng et al. found that they could predict whether
an image was a computer-generated rendering or a photograph with this technique, allowing them to assess whether a
photograph is genuine or a forgery [NCH∗ 05].
4.6. Fields of experts
PCA and ICA are techniques that allow image patches to be
represented as a linear combination of bases. In ICA, these
components are assumed to be independent. This makes it
possible to multiply their marginal distributions to obtain a
prior model [RB05]. Such prior models are important for
instance in optimization algorithms which have many possible solutions. These prior models drive the solution towards
those solutions that are plausible in the sense of natural image
statistics.
However, as the components found by ICA are not necessarily truly independent, the model only affords an approximation. To overcome this limitation, it is possible to view
high-dimensional probability distributions as a product of
several lower-dimensional probability distributions (a product of experts). These lower-dimensional distributions, or
experts, are often relatively easy to model. If they are defined
on linear one-dimensional subspaces, projecting an image
patch onto a linear component is equivalent to applying a
linear filter to the patch [RB05]. However, it can be observed
that the responses of linear filters to natural images often
lead to highly kurtotic marginal distributions which can be
modelled with Student’s t distributions [WHO03].
The advantage of this approach over ICA is that the number of experts does not need to equal the number of pixels. It
is an interesting approach to learning prior models on image
patches. However, it cannot be trivially extended to work on
whole images as the number of parameters to learn would
be prohibitive. In addition, the model would be specific to
one given image size and it would not be translation invariant. To this end, the fields of experts model is proposed,
which incorporates Markov random fields into the above approach, learning filters from the image data itself [RB05].
The effectiveness of this method was demonstrated in image
denoizing and image inpainting applications [RB05]. In a different setting, Markov random fields were also used to infer
super-resolution and to distinguish shading from reflectance
variations [FPC00]. More recently, this method was refined

1775

to include score matching, allowing the low-level structure
from images to be learned in terms of filters of 12 × 12 elements, which is larger than can be achieved with preceding
methods [KLH09].

4.7. Sparse coding to distinguish original paintings
from imitators
In ICA, the statistical independence of the outputs is maximized. Related to this technique, and mathematically equivalent in some cases, is an approach called sparse coding, in
which the kurtosis of the output distribution is maximized.
If natural images are represented by training a sparse coding
model, the basis functions that emerge tend to resemble the
receptive fields encountered in mammalian vision [OF96].
Sparse coding was recently successfully applied to distinguish the paintings from Pieter Bruegel the Elder from
his imitators [HGR10]. Here, the coding learns the properties particular to the artist’s style. Projecting the image
of a painting onto the learned basis functions then leads to
a distribution that is sparse for original paintings, whereas
paintings produced by imitators yield a less sparse distribution. This allows paintings to be classified as either originals
or imitations.
The relationship between statistical regularities and art has
recently received much attention [GFRF10, GR10, OD10], as
it appears to be a particularly useful means to help understand
human visual coding and perception.
Finally, note that other statistical methods have also revealed differences between photographs and paintings. For
instance, it was discovered that paintings on average have
significantly more chromatic-only edges than photographs
[LC03], and that paintings from different periods can be
clustered on the basis of natural image statistics [SWF09].

5. Colour Statistics
We have so far considered statistical regularities in images
either without specifically including the notion of colour,
or deliberately ignoring colour and assuming a single luminance channel. The reason is that colour properties of images
have their own peculiarities, warranting a separate treatment
[BM87, PBTM98, CCO00, COVC00].
In general, images are formed as light is transduced to
electric signals. This happens both in the retina as well as
in electronic image sensors. Before that, light is emitted and
usually reflected several times off different surfaces before it
reaches a sensor. This process is modelled by the rendering
equation, given by
Lo (λ) = Le (λ) +

Li (λ)fr (λ) cos( ) dω.

(36)

c 2011 The Authors
Computer Graphics Forum c 2011 The Eurographics Association and Blackwell Publishing Ltd.

1776

T. Pouli et al. / A Survey of Image Statistics Relevant to Computer Graphics

This equation models the behaviour of light at a surface: an
amount of light Li impinging on a surface point from all
directions
is reflected into an outgoing direction of interest, weighted by the bi-directional reflectance distribution
function (BRDF) fr and a cosine term which depends on the
angle between the surface normal and the direction of Li .
The amount of light Lo going into that direction is then the
sum of the reflected light and the light Le emitted by the surface point (which is zero unless the surface is a light source).
Here, we have specifically made all relevant terms dependent
on wavelength λ to indicate that this behaviour happens at all
wavelengths, including all visible wavelengths. This means
that Lo (λ) can be seen as a spectral distribution.

constructed, which have applications in for instance colour
difference metrics as well as colour transfer algorithms.

Under photopic lighting conditions, the human visual system contains three cone types, each with a different peak
sensitivity. Thus, each cone-type integrates the incident light
according to a different weight function
L=

Humans tend to effortlessly discount the illumination of their
environments. In other words, the colour of the light sources
in a particular viewing environment are to a large extent
ignored, so that human vision is fairly good at detecting
surface colours. This phenomenon is known as colour constancy. Computational models that aim to achieve the same
are known as white balancing algorithms. They intend to
remove colour casts from images due to illumination.

¯ dλ,
Lo (λ)l(λ)

(37a)

As light is reflected off surfaces according to the rendering equation, reconstructing either surface reflectance and/or
illumination is an under-constrained problem. This means
that white balancing can only be achieved by means of statistical assumptions. These are discussed in the following
sections.

¯
Lo (λ)m(λ)
dλ,

(37b)

5.1.1. The grey world assumption

λ

M=

5.1. Colour constancy and white balancing

λ

S=

Lo (λ)¯s (λ)dλ,

(37c)

λ

¯
¯
where l(λ),
m(λ)
and s¯ (λ) are the weight functions (responsivities) which peak at wavelengths that are perceived
roughly as red, green, and blue. The letters L, M and S stand
for ‘long’, ‘medium’ and ‘short’ wavelengths.
A spectral distribution Lo (λ) therefore gives rise to a triple
of numbers (L, M, S) which represent the signal that is passed
on from the photoreceptors to the remainder of the human
visual system. Such triples are called tristimulus values. An
important implication of this behaviour is that different spectral distributions can integrate to the same tristimulus values.
Such spectral distributions are then necessarily perceived
to be identical, which is known as metamerism. It is the
reason that we are able to build display devices with three
primaries that are not the same as the responsivities of the
cones: tristimulus values in one colour space can be converted
to tristimulus values in another colour space, and although
they do not represent the same spectral distributions, through
metamerism they lead to the same percept. Further, rather
than study spectral distributions, we can limit ourselves to
the study of tristimulus values.
There are two interesting and relevant findings in natural
image statistics that pertain to colour. Both of these relate
to the relationships of values between the components of
tristimulus values. In other words, there exist statistical relationships between the three axes of colour spaces. Essentially, correlations between colour channels can be exploited
in colour constancy/white balancing algorithms. By decorrelating images or image ensembles, new colour spaces can be

In colour spaces such as the aforementioned LMS space,
equal values of the three components denote achromatic
colours. One way to achieve such neutral colours is to start
with an equal energy spectrum, that is a spectral distribution which has the same value Lo for each wavelength λ.
This could happen if a scene is illuminated by an equalenergy light source, a source that emits the same energy at all
wavelengths. If the BRDF then also reflects all wavelengths
equally, a neutral colour would be achieved.
In practice, a scene is illuminated by only one or at most a
few light sources, with an emission spectrum that is off-white.
The BRDFs in a scene are much more variable. However, a
surprising finding is that when a collection of BRDFs are
averaged, the result ends up being a distribution function that
is close to grey. This is known as the grey-world assumption
[RKAJ08a].
The implication of this finding is that if we were to average
the colours of all pixels in an image, and the grey-world
¯ M,
¯ S)
¯
assumption holds, the average tristimulus value (L,
is a good indicator of the colour of the light source. Of
course, when averaged over natural image ensembles, the
grey world assumption does tend to hold. In single images
this assumption may or may not hold. In particular, if the
surface colours in the scene are biased towards some specific
saturated colour, the average reflectance will not tend towards
grey.
The grey world assumption is often used to aid white
balancing. After all, if we know the colour of the illuminant,
then we can correct all pixels by simply dividing all pixels
by the average image value. Moreover, if we know that the
display has a different white point (i.e. the colour emitted

c 2011 The Authors
Computer Graphics Forum c 2011 The Eurographics Association and Blackwell Publishing Ltd.

1777

T. Pouli et al. / A Survey of Image Statistics Relevant to Computer Graphics

when the three colour channels are set to maximum), say
(Ld,w , Md,w , Sd,w ), white balancing can be implemented as
follows:
Ld,w
,
Lwb = L
L¯
Mwb = M

Md,w
,
M¯

Sd,w
.
Swb = S
S¯

(38b)

It was found that although grey-world algorithms work well
on some images, alternate solutions such as the white-patch
algorithm [Lan77] perform better on texture-rich images. The
white-patch algorithm assumes that the lightest pixels in an
image depict a surface with neutral reflectance, so that its
colour represents the illuminant.

(38c)

Both the grey-world and white patch algorithms are special
instances of the Minkowski norm [FT04]:

(38a)

The grey-world assumption is a statistical argument that
is necessary to perform white balancing on images in the
absence of further information about the illuminant, given
that white balancing is by itself an under-constrained problem
[FBM98].
Note that we have glossed over the fact that this procedure
is best applied in a perceptual colour space, such as LMS,
thereby mimicking chromatic adaptation processes that occur
in the human visual system. If an image is given in a different
colour space, most likely the sRGB space, the image should
first be converted to LMS.
The approximation of the illuminant can be improved
by excluding the most saturated pixels from the estimation
[APS98]. Alternatively, the image can be subjected to further statistical analysis to determine if the colour distribution
is due coloured surfaces or due to a coloured light source
[GS04]. Here the image is first converted to the CIELAB
colour opponent space. Ignoring the lightest and darkest
pixels as they do not contribute to a reliable estimate, the
remaining pixels are used to computed a two-dimensional
histogram F (a, b) on the two chromatic channels a and b. In
each channel, the chromatic distributions are modelled with
μk =

kF (a, b) dk,

(39)

(μk − k) F (a, b) dk,

(40)

k

σk2 =

k

where k = a, b. These are the mean and variances of the
histogram projections onto the a and b axes. In CIELAB
neutral colours lie around the (a, b) = (0, 0) point. To assess
how far the histogram lies from this point, the normalized
distance D σ can be computed
Dσ =

μ−σ
,
σ

5.1.2. Generalized grey-world and white patch
assumptions

(41)

where μ = μ2a + μ2b and σ = σa2 + σb2 . This measure
can be used to assess the strength of the cast. If the spread of
the histogram is small, and lies far away from the origin, the
image is likely to be dominated by strong reflectances rather
than illumination.

Lp =

f p (x)dx
dx

1/p

(42)

,

where f (x) denotes the image at pixel x. The average of the
image is computed for p = 1, thereby implementing the
grey-world assumption. The maximum value of the image
is computed by substituting p = ∞, which represents the
white-patch algorithm.
A further generalized assumption can be made about images, which is that the average difference between two pixels
evaluates to grey. This is known as the grey-edge assumption
[vG05], and can be formulated as follows [GG07]:
∂ n f σ (x)
∂x n

1/p

p

dx

(43)

.

Here, n is the order of the derivative, p is the Minkowski-norm
and f σ (x) = f ⊗ Gσ is the Gaussian blurred image where the
size of the filter kernel is given by σ . With this formulation
several colour constancy algorithms can be constructed:
n = 0, p = 1, σ = 0] This implements the grey-world
algorithm.
n = 0, p = ∞, σ = 0] This is the white-patch algorithm.
n ≥ 0, 1 < p < ∞, σ > 0] This is known as the general
grey-world algorithm. The value of n indicates the order
of the statistics. It is typically 0, 1 or 2.
5.1.3. White balance algorithm selection
Having noted that many colour constancy and white balancing algorithms exist, with none of them universally applicable, Gijsenij and Gevers use natural image statistics to
classify an image, and then use this classification to select
the most appropriate white balancing algorithm for the image
at hand [GG07]. In particular, they use the finding that the
distribution of edge responses in an image can be modelled
by means of a Weibull distribution [GS05]
f (x) =

γ
β

x
β

γ −1

exp

x
β

γ

.

(44)

The parameters β and γ have meaning in this context. The
contrast of an image (or image ensemble) is given by β
whereas γ is an indicator of grain size (i.e. the peakedness

c 2011 The Authors
Computer Graphics Forum c 2011 The Eurographics Association and Blackwell Publishing Ltd.

1778

T. Pouli et al. / A Survey of Image Statistics Relevant to Computer Graphics

of the distribution). This means that higher values for β
represent images with more contrast. Higher values for γ
indicate finer textures.

have green and red hues. Although we may describe objects
as reddish-blue or yellowish-green, we never describe them
as reddish-green. The same holds for yellow and blue.

Fitting a Weibull distribution involves computing a Gaussian derivative filter in both x and y directions. This results in
the (β x , β y , γ x , γ y ) set of parameters for each colour channel.
The Gaussian derivative filter can be first, second or third order. However, it was found that the order of the chosen filter
is relatively unimportant: high correlations exist between the
fitted parameters [GS05].

Colour spaces are defined with respect to CIE XYZ, a
colour space that is defined in terms of human visual perception [RKAJ08b]. The conversion from CIE XYZ to LMS, and
then from LMS to the aforementioned decorrelated opponent
colour space Lαβ is given by
⎡ ⎤ ⎡
⎤⎡ ⎤
X
L
0.3897 0.6890 −0.0787
⎢ ⎥ ⎢
⎥⎢ ⎥
0.0464 ⎦ ⎣ Y ⎦
⎣ M ⎦ = ⎣ −0.2298 1.1834

It is now possible to fit Weibull parameters to the derivatives of a large number of images, and correlate their values with the white balancing algorithm that performs best
for each image. The parameter space tends to form clusters
where a specific algorithm tends to produce the most accurate
result. This means that the Weibull distribution can be used
to select the most appropriate white balancing algorithm for
each image individually [GG07].

S

0.0000

0.0000

1.0000

Z
(45)

and the inverse conversion from LMS to XYZ is given by
⎤⎡ ⎤
⎡ ⎤ ⎡
L
1.9102 −1.1121 0.2019
X
⎥⎢ ⎥
⎢ ⎥ ⎢
0.6291 0.0000 ⎦ ⎣ M ⎦ .
⎣ Y ⎦ = ⎣ 0.3710
Z

0.0000

0.0000

1.0000

S
(46)

5.2. Statistical decorrelation
The success of the grey-world assumption has a second implication. If the average surface reflectance is grey, and light
sources tend towards white, then in the LMS colour space
and similar RGB-like spaces, values in one colour channel
tend to be good predictors of values in the other two colour
channels. In other words, if we find a high value for a red
pixel, then chances are that the green and blue values are high
as well. This means that the colour channels in such colour
spaces are highly correlated.
An interesting experiment was conducted whereby a set
of spectral images was converted to log LMS space, before
being subjected to PCA [RCC98]. The logarithm was taken
as a data-conditioning measure. Applied in this manner, PCA
rotates the axes to the point where they are maximally decorrelated. The resulting colour space is termed Lαβ where L is
a lightness channel, and α and β are colour opponent channels. By starting in LMS cone space, the rotation yields a
new colour space which surprisingly corresponds closely to
the colour opponent space found in the ganglion cells (these
are the cells that transport the visual signal from the retina
through the optic nerve to the lateral geniculate nucleus,
thought to be a relay station in the brain).
Colour opponent spaces are characterized by a single
achromatic channel, typically encoding luminance or lightness, and two chromatic axes which can be thought of as
spanning red-green and yellow-blue (although the axes do
not precisely correspond to these perceptual hues). The chromatic axes can have positive and negative values; a positive
value can for instance denote the degree of redness, whereas
a negative value in the same channel would denote the degree of greenness. A consequence of colour opponency is
that we are not able to simultaneously perceive an object to

Converting from LMS to Lαβ involves a further matrix
multiplication
⎡
⎤
1
0
0
√
⎥⎡
⎡ ⎤ ⎢ 3
⎤⎡
⎤
⎢
⎥ 1
L
1
1
log L
⎢
⎥
1
⎢ ⎥ ⎢
⎥⎢
⎥
⎥⎢
0 ⎥⎣ 1
√
1 −2 ⎦⎣ log M ⎦ ,
⎣α ⎦ =⎢0
⎢
⎥
6
⎢
⎥
β
0
log S
⎣
1 ⎦ 1 −1
0
0
√
2
(47)
whereas the inverse transform is given by
⎡√
3
0
⎡
⎤ ⎡
⎤⎢ 3
log L
1
1
1 ⎢
√
⎢
⎢
⎥ ⎢
⎥⎢
6
1 −1 ⎦⎢ 0
⎣ log M ⎦ = ⎣ 1
⎢
6
log S
1 −2
0 ⎢
⎣
0
0

⎤
⎥⎡ ⎤
⎥ L
⎥
⎥⎢ ⎥
⎣α ⎦.
0 ⎥
⎥
√ ⎥
β
2⎦
2
(48)
0

For 2000 random samples drawn from each of the images
shown in Figure 13, their distribution is plotted in Figure 14.
The point clouds form more or less diagonal lines in RGB
space when pairs of channels are plotted against each other,
showing that the three colour channels in RGB space are
almost completely correlated for these images. This is not
the case for the same pixels plotted in Lαβ space.
The colour opponency of the Lαβ space is demonstrated
in Figure 15, where the image is decomposed into its separate channels. The image representing the α channel has the
β channel reset to 0 and vice versa. We have retained the luminance variation here for the purpose of visualization. The
image showing the luminance channel only was created by
setting both the α and β channels to zero.

c 2011 The Authors
Computer Graphics Forum c 2011 The Eurographics Association and Blackwell Publishing Ltd.

T. Pouli et al. / A Survey of Image Statistics Relevant to Computer Graphics

1779

Figure 13: Examples images used to demonstrate the correlation between channels. The first two images are reasonable
examples of natural images, whereas the third image is an example of an image taken in a built-up area. Built environments
tend to have somewhat different natural image statistics compared with natural scenes [ZL98]. Figure taken from [RKAJ08a],
courtesy AK Peters, Ltd.

Figure 14: Random samples plotted in RGB colour space (top) and Lαβ colour space (bottom). The top to bottom order of the
plots is the same as the order of the images in Figure 13. Figure taken from [RKAJ08a], courtesy AK Peters, Ltd.
The fact that natural images can be transformed to a decorrelated colour space, which coincides with a colour decomposition occurring in the human visual system, points to a
beautiful adaptation of human vision to its natural input.

Section 5.1.1 yields meaningful results as the CIELAB space
used here is an example of a colour opponent space.

It also points to several applications that are possible due
to the fact that opponent spaces are decorrelated. In particular, we highlight colour transfer, an algorithm that attempts
to transfer the look and feel of one image to another on the
basis of its colour content. Because of the three-dimensional
nature of colour spaces, this is in the general sense a complicated three-dimensional problem. However, by converting
to a colour opponent space, the data in each channel will
be decorrelated from the other channels. As a first example,
the histogram projection onto the a and b axes as outlined in

5.2.1. Spatial colour processing
PCA and ICA algorithms, if applied to grey-scale images,
yield filters that resemble the receptive fields discovered in
human vision. Extending this analysis to colour images, it
was found that the ICA filters continue to resemble Gabor
patches, many of which are achromatic [WLS01, HH00].
There is a smaller number of chromatic patches, which show
either red-green or yellow-blue opponency. They are also
oriented, and exhibit low spatial frequencies.

c 2011 The Authors
Computer Graphics Forum c 2011 The Eurographics Association and Blackwell Publishing Ltd.

1780

T. Pouli et al. / A Survey of Image Statistics Relevant to Computer Graphics

Figure 16: Example of colour transfer [PR10].

Figure 15: The top-left image is decomposed into the L
channel of the Lαβ colour space, as well as L + α and L + β
channels in the bottom-left and bottom-right images. Figure
from [RKAJ08a], courtesy AK Peters, Ltd.

5.2.2. Colour transfer
Perhaps one of the most direct applications of the use of
decorrelated colour spaces is colour transfer between images. The aim is to transfer some statistical properties of one
image to another. To make this process straightforward, images can be converted to a decorrelated colour space, such
as the Lαβ space proposed by Ruderman [RCC98]. In this
space, the means and standard deviations of all the pixels can
be computed separately in each of the three axis. Doing this
for both a source and a target image yields a set of factors
and terms that can be used to shift and scale the pixel data
in one image to match the means and standard deviations of
the other image [RAGS01].
Alternatively it would be possible to use histogram matching in each of these three channels to transfer the appearance
of one image to another. However, this may lead to harshlooking results. Recently, a more sophisticated method was
proposed, which sits inbetween these two extremes [PR10]. It

uses a scale-space approach on histograms to gently reshape a
source histogram to a given target histogram. Results of this
procedure are shown in Figure 16. Its robustness allows a
wider variety of source and target images to be matched, and
can also be used for tone reproduction, by simply matching
a HDR image to an LDR target.
Applications of colour transfer, aside from producing aesthetically pleasing images, include creating night-time images from day-time images, as well as augmented reality
applications, where colour transfer provides an inexpensive
way to make rendered objects fit into a captured environment
[RAC∗ 04].
Although the Lαβ space is on average decorrelated, individual images may deviate arbitrarily from this ideal. As
such, many images may still show significant correlations
between the axis, even in a colour opponent space. It would
be possible to individually subject images to PCA to find
the most decorrelated axes for each specific image. Such a
technique may provide plausible results for a wider range of
inputs [AK04, AK07].

6. Conclusions
Natural images are not random. They contain striking statistical regularities, which are surveyed in this report. The

c 2011 The Authors
Computer Graphics Forum c 2011 The Eurographics Association and Blackwell Publishing Ltd.

T. Pouli et al. / A Survey of Image Statistics Relevant to Computer Graphics

human visual system has evolved to observe natural images
and therefore contains neural circuitry that is specifically
adapted to analyse natural images. Thus, the field that studies natural image statistics has emerged to understand the
input to the human visual system first, for the purpose of
gaining a better understanding of the inner workings of the
human visual system itself.
The discovery of natural image statistics follows several
steps. First, an ensemble of natural images is collected. Second, the images are transformed into a specific domain. Examples include the computation of power spectra, phase spectra or wavelets, although many more are known and listed
in this report. Finally, statistical regularities are computed in
this domain.
There are a couple of important observations to make about
human visual processing of natural images. For metabolic
reasons, the HVS appears to have evolved to use a sparse
coding. In essence, this means that most cells in the visual
cortex lie dormant most of the time, while for each input only
a few cells are active. This helps minimize energy consumption.
Thus, the HVS also applies several transforms to its input so as to induce a sparse coding. In the statistical sense,
sparse coding is often associated with probability density distributions that have a high kurtosis. Indeed, we have shown
several transforms that result in highly kurtotic signals, and
which approximate human visual processes. In particular, it
can be shown that wavelets that analyse regions locally in
space, orientation as well as frequency induce high kurtosis.
Moreover, such analysers are thought to operate in the visual
cortex.
Further, the human visual system appears to reduce redundancy in its input. The photoreceptors transduce a signal
which is recombined several times in the retina, producing a
spatial centre-surround mechanism as well as colour opponency. It has been shown in particular that opponent colour
spaces tend to be decorrelated. For natural images, the opponent signals tend to be close to independent. As a result, the
information carried in its three channels is stripped of much
of its redundancy.
Thus, the importance of discovering natural image statistics for understanding the human visual system is undeniable.
However, the use of natural image statistics is not limited to
the study of human vision. Particularly, in application areas such as computer graphics, machine vision as well as
image processing, images are synthesized or analysed. By
observing the aforementioned image statistics, we are able
to produce more plausible images, enable new applications,
or detect objects in images with higher success rates. Examples of these are given throughout this report.
Here, we highlight some of the more salient applications
that employ some form of natural image statistics. Of these,

1781

wavelets are particularly useful for many tasks. They are used
for instance in denoizing algorithms as well as for object
detection. However, perhaps its greatest success story lies in
its use in lossy compression algorithms. As wavelets induce a
sparse coding: histograms of wavelet coefficients are highly
kurtotic so that most coefficients are small. Clamping these
coefficients to zero means that an image can be reconstructed
from a very small set of non-zero coefficients, leading to good
opportunities of encoding only a small set of coefficients and
thereby obtaining high compression factors.
A second example is found in the use of the sparseness
of the distribution of gradients. Modelling the distribution
of gradients of image ensembles has resulted in a simple
functional form that can be used in optimization problems
as priors. This has been demonstrated in blind deconvolution
algorithms which aim to remove blur from images due to
camera shake. As an infinite number of solutions exist, these
algorithms require additional constraints. In particular, they
can drive the solution towards some measure of naturalness,
such as the aforementioned distribution of gradients.
Finally, the decorrelation afforded by opponent colour
spaces has been used directly in colour transfer algorithms.
Here, the plausible transfer of colour palettes is made simpler
by treating each channel independently.
We hope that this overview of the field of natural image
statistics, and its link with graphics-related applications may
help in the development of further applications in graphics.

References
[Ach08] ACHARYYA R.: A New Approach for Blind Source
Separation of Convolutive Sources: Wavelet Based Separation Using Shrinkage Function. VDM Verlag Dr. M¨uller
Aktiengesellschaft & Co. KG, Saarbr¨ucken, Germany,
2008.
[AK04] ABADPOUR A., KASAEI S.: A fast and efficient fuzzy
color transfer method. In Proceedings of the 4th IEEE
International Symposium on Signal Processing and Information Technology (2004), pp. 491–494.
[AK07] ABADPOUR A., KASAEI S.: An efficient PCA-based
color transfer method. Journal of Visual Communication
and Image Representation, 18, 1 (2007), 15–34.
[APS98] ADAMS J., PARULSKI K., SPAULDING K.: Color processing in digital cameras. IEEE Micro, 18, 6 (1998),
20–30.
[AS05] ACEBO E., SBERT M.: Benford’s law for natural and synthetic images. In Proceedings of Computational Aesthetics in Graphics, Visualization and Images
(Girona, Spain, 2005).

c 2011 The Authors
Computer Graphics Forum c 2011 The Eurographics Association and Blackwell Publishing Ltd.

1782

T. Pouli et al. / A Survey of Image Statistics Relevant to Computer Graphics

[ASF91] ADELSON E., SIMONCELLI E., FREEMAN W. T.: Pyramids and multiscale representations. In Representations
and Vision, A. Gorea (Ed.). Cambridge University Press,
Cambridge (1991), pp. 3–16.
[ASH87] ADELSON E., SIMONCELLI E., HINGORANI R.: Orthogonal pyramid transforms for image coding. In SPIE Visual Communications and Image Processing (Bellingham,
WA, 1987), SPIE, vol. II, p. 845.
[Bad96] BADDELEY R. J.: An efficient code in V1? Nature,
381 (1996), 560–561.
[BAM*97] BADDELEY R. J., ABBOTT L. F., MICHAEL C. A.,
BOOTH C. A., SENGPIEL F., FREEMAN T., WAKEMAN E. A.,
ROLLS E. T.: Responses of neurons in primary and inferior
temporal visual cortices to natural scenes. Proceedings
of the Royal Society B: Biological Sciences, 264, 1389
(1997), 1775–1783.
[Bar01] BARLOW H.: The exploitation of regularities in the
environment by the brain. Behaviors and Brain Sciences,
24 (2001), 602–607.
[BCG90] BOVIK A. C., CLARK M., GEISLER W.: Multichannel texture analysis using localized spatial filters. IEEE
Pattern Analysis and Machine Intelligence, 12, 1 (1990),
55–73.
[BCHT01] BILLOCK V. A., CUNNINGHAM D. W., HAVIG P. R.,
TSOU B. H.: Perception of spatiotemporal random fractals:
an extension of colorimetric methods to the study of dynamic texture. Journal of the Optical Society of America
A, 18, 10 (2001), 2404–2413.
[BCT09] BILLOCK V. A., CUNNINGHAM D. W., TSOU B. H.:
What visual discrimination of fractal textures can tell us
about discrimination of camouflaged targets. In Human
Factors Issues in Combat Identification, D. H. Andrews,
R. P. Herz, M. B. Wolf (Eds.), Ashgate, Surrey, England
(2009), pp. 99–112.
[BD61] BARLOW H. B., DONALDSON P. E. K.: Possible principles underlying the transformations of sensory messages.
In Sensory Communication, W. Rosenblith (Ed.). MIT
Press, Cambridge, MA (1961), ch. 13, pp. 217–234.
[BF00] BRADY M., FIELD D. J.: Local contrast in natural
images: normalisation and coding efficiency. Perception,
29 (2000), 1041–1055.

[BGK01] BILLOCK V. A., GUZMAN G. C. D., KELSO J. A. S.:
Fractal time and 1/f spectra in dynamic images and human
vision. Physica D, 148 (2001), 136–146.
[BH96] BILLOCK V. A., HARDING T. H.: Evidence of the spatial and temporal channels in the correlational structure
of human spatiotemporal contrast sensitivity. Journal of
Physiology, 490, 2 (1996), 509–517.
[Bil00] BILLOCK V. A.: Neural acclimation to 1/f spatial frequency spectra in natural images transduced by the human
visual system. Physica D, 137 (2000), 379–391.
[BJ02] BACH F. R., JORDAN M. I.: Kernel independent component analysis. Journal of Machine Learning Research,
3 (2002), 1–48.
[BM87] BURTON G. J., MOORHEAD I. R.: Color and spatial
structure in natural scenes. Applied Optics, 26, 1 (1987),
157–170.
[BMW88] BAUM E. B., MOODY J., WILCZEK F.: Internal representations for associative memory. Biological Cybernetics, 59 (1988), 217–228.
[BP86] BAYER B. E., POWELL P. G.: A method for the digital
enhancement of unsharp grainy photographs. Advances in
Computer Vision and Image Processing, 2 (1986), 31–88.
[BS95] BELL A. J., SEJNOWSKI T. J.: An informationmaximization approach to blind separation and blind deconvolution. Neural Computation, 7, 6 (1995), 217–234.
[BS97] BELL A. J., SEJNOWSKI T. J.: ‘The independent components’ of natural scenes are edge filters. Vision Research,
37 (1997), 3327–3338.
[BS99] BUCCIGROSSI R. W., SIMONCELLI E. P.: Image compression via joint statistical characterization in the wavelet
domain. IEEE Transactions on Image Processing, 8, 12
(1999), 1688–1701.
[Cae81] CAELLI T.: Visual Perception: Theory and Practice.
Pergamon Press, Oxford, 1981.
[Car99] CARDOSO J. F.: High-order contrasts for independent
component analysis. Neural Computation, 11, 1 (1999),
157–192.

[BG00] BALBOA R. M., GRZYWACZ N. M.: Occlusions and
their relationship with the distribution of contrasts in natural images. Vision Research, 40, 19 (2000), 2661–2669.

[CCO00] CHIAO C.-C., CRONIN T. W., OSORIO D.: Color
signals in natural scenes: characteristics of reflectance
spectra and the effects of natural illuminants. Journal of
the Optical Society of America A, 17, 2 (2000), 218–
224.

[BG03] BALBOA R. M., GRZYWACZ N. M.: Power spectra and
distribution of contrasts of natural images from different
habitats. Vision Research, 43, 24 (2003), 2527–2537.

[CG87] CUTTING J., GARVIN J.: Fractal curves and complexity. Perception and Psychophysics, 42 (1987), 365–
370.

c 2011 The Authors
Computer Graphics Forum c 2011 The Eurographics Association and Blackwell Publishing Ltd.

T. Pouli et al. / A Survey of Image Statistics Relevant to Computer Graphics

[CHJ78] CAMPBELL F. W., HOWELL E. R., JOHNSON J. R.: A
comparison of threshold and suprathreshold appearance
of gratings with components in the low and high spatial frequency range. Journal of Physiology, 284 (1978),
193–201.
[CNR02] CARON J. N., NAMAZI N. M., ROLLINS C. J.: Noniterative blind data restoration by use of an extracted
filter function. Applied Optics, 41, 32 (2002), 6884–
6889.
[Com94] COMON P.: Independent component analysis: a new
concept. Signal Processing, 36, 3 (1994), 287–314.
[Cor70] CORNSWEET T.: Visual Perception. Academic Press,
New York, 1970.
[COVC00] CHIAO C.-C., OSORIO D., VOROBYEV M., CRONIN
T. W.: Characterization of natural illuminants in forests
and the use of digital video data to reconstruct illuminant
spectra. Journal of the Optical Society of America A, 17,
10 (2000), 1713–1721.
[DA95] DONG D., ATICK J.: Statistics of time-varying images. Network: Computation in Neural Systems, 6 (1995),
345–358.

1783

[DJ95] DONOHO D. L., JOHNSTONE I. M.: Adapting to unknown smoothness via wavelet shrinkage. Journal of the
American Statistical Society 90 (1995), 1200–1224.
[DL05] DEUSSEN O., LINTERMANN B.: Digital Design of Nature: Computer Generated Plants and Organics. SpringerVerlag, New York, 2005.
[DLAW01] DROR R., LEUNG T., ADELSON E., WILLSKY A.:
Statistics of real-world illumination. In Proceedings of
the IEEE Conference on Computer Vision and Pattern
Recognition (Kauai, HI, 2001), vol. 2, pp. 164–171.
[DOL00] DROR R. O., O’CARROLL D. C., LAUGHLIN S. B.: The
role of natural image statistics in biological motion estimation. In Proceedings of the IEEE International Workshop on Biologically Motivated Computer Vision (Seoul,
Korea, May 2000), pp. 492–501.
[DOL01] DROR R. O., O’CARROLL D. C., LAUGHLIN S. B.:
Accuracy of velocity estimation by Reichardt correlators.
Journal of the Optical Society of America A 18, 2 (2001),
241–252.
[DWA04] DROR R. O., WILLSKY A. S., ADELSON E. H.: Statistical characterization of real-world illumination. Journal
of Vision 4 (2004), 821–837.

[Dau88] DAUGMAN J. G.: Complete discrete 2D gabor transforms by neural networks for image analysis and compression. IEEE Transactions on Acoustics,
Speech and Signal Processing, 36, 7 (1988), 1169–
1179.

[EBW92] ECKERT M. P., BUCHSBAUM G., WATSON A. B.: Separability of spatiotemporal spectra of image sequences.
IEEE Transactions on Pattern Analysis and Machine Intelligence 14, 12 (1992), 1210–1213.

[Dau91] DAUGMAN J. G.: Self-similar oriented wavelet pyramids: conjectures about neural non-orthogonality. In Representations and Vision, A. Gorea (Ed.). Cambridge University Press, Cambridge, 1991.

[FB97] FIELD D. J., BRADY N.: Visual sensitivity, blur
and the sources of variability in the amplitude spectra
of natural images. Vision Research 37 (1997), 3367–
3383.

[DAW01] DROR R. O., ADELSON E. H., WILLSKY A. S.: Surface reflectance estimation and natural illumination statistics. In Proceedings of the IEEE Workshop on Statistical
and Computational Theories of Vision (2001).

[FBM98] FUNT B., BARNARD K., MARTIN L.: Is machine
colour constancy good enough? In Proceedings of the 5th
European Conference on Computer Vision (Freiburg, Germany, 1998), pp. 445–459.

[DB03] DAKIN S. C., BEX P. J.: Natural image statistics mediate brightness filling in. Proceedings of the Royal Society of London, B 270 (Vancouver, Canada, 2003), 2341–
2348.

[FFC82] FOURNIER A., FUSSELL D., CARPENTER L.: Computer
rendering of stochastic models. Communications of the
ACM 25, 6 (1982), 371–384.

[DBO08] DENG J. D., BRINKWORTH R., O’CARROL D.: Assessing the naturalness of scenes: An approach using statistics
of local features. In Proceedings of the Image and Vision
Computing New Zealand (IVCNZ) (Christchurch, New
Zealand, 2008).
[DCCH05] DEUSSEN O., COLDITZ C., COCONU L., HEGE H.:
Efficient Modeling and Rendering of Landscapes Visualization in Landscape and Environmental Planning. Taylor
& Francis, Oxon, England, 2005.

[Fie87] FIELD D. J.: Relations between the statistics of natural images and the response properties of cortical cells.
Journal of the Optical Society of America A 4, 12 (1987),
2379–2394.
[Fie93] FIELD D. J.: Scale-invariance and self-similar
‘wavelet’ transforms: an analysis of natural scenes and
mammalian visual systems. In Wavelets, fractals and
Fourier transforms, M. Farge, J. C. R. Hunt, J. C. Vassilicos (Eds.). Clarendon Press, Oxford (1993), pp. 151–
193.

c 2011 The Authors
Computer Graphics Forum c 2011 The Eurographics Association and Blackwell Publishing Ltd.

1784

T. Pouli et al. / A Survey of Image Statistics Relevant to Computer Graphics

[Fie94] FIELD D. J.: What is the role of sensory coding?
Neural Computation, 6 (1994), 559–601.
[Fol95] FOLDIAK P.: Sparse coding in the primate cortex. In
The Handbook of Brain Theory and Neural Networks,
M. A. Arbib (Ed.). MIT Press, Cambridge, MA (1995),
pp. 895–989.
[FPC00] FREEMAN W. T., PASZTOR E. C., CARMICHAEL O. T.:
Learning low-level vision. International Journal of Computer Vision, 40, 1 (2000), 25–47.
[FSH*06] FERGUS R., SINGH B., HERTZMANN A., ROWEIS
S., FREEMAN W.: Removing camera shake from a single
photograph. ACM Transactions on Graphics, 25 (2006),
787–794.
[FSS07] FU D., SHI Y. Q., SU W.: A generalized Benford’s
law for JPEG coefficients and its applications in image
forensics. In Proceedings of the SPIE (San Jose, CA,
2007), vol. 6505.
[FT04] FINLAYSON G., TREZZI E.: Shades of gray and colour
constancy. In Proceedings of the Twelfth Color Imaging
Conference (Scottsdale, AZ, 2004), pp. 37–41.
[Gab46] GABOR D.: Theory of communication. JIEE London, 93, III (1946), 429–457.
[Gei08] GEISLER W. S.: Visual perception and the statistical
properties of natural scenes. Annual Reviews in Psychology, 59 (2008), 167–192.
[GFRF10] GRAHAM D. J., FRIEDENBERG J. D., ROCKMORE D.
N., FIELD D. J.: Mapping the similarity space of paintings:
Image statistics and visual perception. Visual Cognition,
18, 4 (2010), 559–573.
[GG07] GIJSENIJ A., GEVERS T.: Color constancy using natural image statistics. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (Minneapolis, MN, 2007), pp. 1–8.
[Gib79] GIBSON J. J.: The Ecological Approach to Visual Perception. Lawrence Erlbaum, Hillsdale, NJ,
1979.

[HB96] HAMMETT S. T., BEX P. J.: Motion sharpening: Evidence for the addition of high spatial frequencies to the
effective neural image. Vision Research, 36, 17 (1996),
2729–2733.
[HBS92] HANCOCK P., BADDELEY R. J., SMITH L.: The principal components of natural images. Network: Computation
in Neural Systems, 3, 1 (1992), 61–70.
[HGR10] HUGHES J. M., GRAHAM D. J., ROCKMORE D. N.:
Quantifiction of artistic style through sparse coding analysis in the drawings of Pieter Bruegel the elder. Proceedings of the National Academy of Sciences, 107, 4 (2010),
1279–1283.
[HH00] HOYER P. O., HYVA¨ RINEN A.: Independent components analysis applied to feature extraction from colour
and stereo images. Network: Computation in Neural Systems, 11 (2000), 191–210.
[HHH09] HYVA¨ RINEN A., HURRI J., HOYER P. O.: Natural Image Statistics: A Probabilistic Approach to Early Computational Vision. Springer, Dordrecht, The Netherlands,
2009.
[Hil96] HILL T. P.: A statistical derivation of the significantdigit law. Statistical Science, 10, 4 (1996), 354–363.
[HKO01] HYVA¨ RINEN A., KARHUNEN J., OJA E.: Independent
Component Analysis. John Wiley & Sons, Canada, 2001.
[HLM00] HUANG J., LEE A., MUMFORD D.: Statistics of range
images. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (Hilton Head, SC,
2000), vol. 1, pp. 324–331.
[HM99a] HUANG J., MUMFORD D.: Image Statistics for the
British Aerospace Segmented Database. Tech. Rep., Division of Applied Math, Brown University, 1999.
[HM99b] HUANG J., MUMFORD D.: Statistics of natural images and models. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (Fort
Collins, CO, 1999), vol. 1, pp. 541–547.

[GR10] GRAHAM D. J., REDIES C.: Statistical regularities in
art: relations with visual coding and perception. Vision
Research, 50, 16 (2010), 1503–1509.

[HT96] HIRANI A. N., TOTSUKA T.: Combining frequency and
spatial domain information for fast interactive image noise
removal. In SIGGRAPH ’96: Proceedings of the 23rd Annual Conference on Computer Graphics and Interactive
Techniques (New Orleans, LA, 1996), pp. 269–276.

[GS04] GASPARINI F., SCHETTINI R.: Color balancing of digital
photos using simple image statistics. Pattern Recognition,
37 (2004), 1201–1217.

[Hyv99a] HYVA¨ RINEN A.: Fast and robust fixed-point algorithms for independent component analysis. IEEE Transactions on Neural Networks, 10, 3 (1999), 626–634.

[GS05] GEUSEBROEK J., SMEULDERS A.: A six-stimulus theory
for stochastic texture. International Journal of Computer
Vision, 62, 1–2 (2005), 7–16.

[Hyv99b] HYVA¨ RINEN A.: Sparse code shrinkage: denoising
of non-Gaussian data by maximum likelihood estimation.
Neural Computation, 11, 7 (1999), 1739–1768.

c 2011 The Authors
Computer Graphics Forum c 2011 The Eurographics Association and Blackwell Publishing Ltd.

T. Pouli et al. / A Survey of Image Statistics Relevant to Computer Graphics

[JBFZ02] JALOBEANU A., BLANC-F´ERAUD L., ZERUBIA J.: Estimation of blur and noise parameters in remote sensing.
In Proceedings of International Conference on Acoustics,
Speech and Signal Processing (Orlando, FL, 2002), pp.
249–256.
[JC79] JULESZ B., CAELLI T.: Perception. On the Limits of
Fourier Decompositions in Visual Texture Perception, 8
(1979), 69–73.
[KFK90] KNILL D. C., FIELD D., KERSTEN D.: Human discrimination of fractal images. Journal of the Optical Society of America A, 7, 6 (1990), 1113–1123.
[KLH09] K¨OSTER U., LINDGREN J. T., HYVA¨ RINEN A.: Estimating Markov random field potentials for natural images. In
Proceedings of the International Conference on Independent Component Analysis and Blind Source Separation
(ICA, Paraty, Brazil, 2009), pp. 515–522.
[KP88] KUBE P., PENTLAND A.: On the imaging of fractal
surfaces. IEEE Transactions on Pattern Analysis and Machine Intelligence, 10 (1988), 704–707.
[Lan77] LAND E.: The retinex theory of color vision. Scientific American, 237, 6 (1977), 108–128.
[LC03] LEYKIN A., CUTZU F.: Differences of edge properties in photographs and paintings. In Proceedings of
the IEEE International Conference on Image Processing
(Barcelona, Spain, 2003), vol. 2, pp. III 541–544.
[Lev07] LEVIN A.: Blind motion deblurring using image
statistics. Advances in Neural Information Processing
Systems. J. C. Platt, D. Koller, Y. Singer and S. Roweis
(Eds.). MIT Press (2007), vol. 19, pp. 841–848.
[LF05] LYU S., FARID H.: How realistic is photorealistic?
IEEE Transactions on Signal Processing, 53, 2 (2005),
845–850.
[LF06] LYU S., FARID H.: Steganalysis using higher-order
image statistics. IEEE Transactions on Information Forensics and Security, 1, 1 (2006), 111–119.
[LGS99] LEE T.-W., GIROLAMI M., SEJNOWSKI T. J.: Independent component analysis using an extended infomax
algorithm for mixed sub-Gaussian and super-Gaussian
sources. Neural Computation, 11, 2 (1999), 417–441.
[LMF03] LEARNED-MILLER E. G., FISHER III J. W.: ICA using
spacings estimates of entropy. Journal of Machine Learning Research, 4 (2003), 1271–1295.
[LPM03] LEE A. B., PEDERSEN K. S., MUMFORD D.: The nonlinear statistics of high contrast patches in natural images.
The International Journal of Computer Vision, 54, 1/2/3
(2003), 83–103.

1785

[LS09a] LYU S., SIMONCELLI E. P.: Nonlinear extraction
of independent components of natural images using radial gaussianization. Neural Computation, 21 (2009),
1485–1519.
[LS09b] LYU S., SIMONCELLI E. P.: Reducing statistical dependencies in natural signals using radial gaussianization.
In Advances in Neural Information Processing Systems,
D. Koller, D. Schuurmans, Y. Bengio, L. Bottou (Eds.),
vol. 21. MIT Press, Cambridge, MA, 2009.
[LZW02] LEVIN A., ZOMET A., WEISS Y.: Learning to perceive transparency from the statistics of natural scenes.
In NIPS-15; The 2002 Conference on Advances in Neural Information Processing Systems (Vancouver, Canada,
2002), MIT Press.
[LZW03] LEVIN A., ZOMET A., WEISS Y.: Learning how to
inpaint from global image statistics. In Proceedings of the
Ninth IEEE International Conference on Computer Vision
(Nice, France, 2003), pp. 305–312.
[Mal89] MALLAT S. G.: A theory for multiresolution signal
decomposition: the wavelet representation. IEEE Pattern
Analysis and Machine Intelligence, 11 (1989), 674–693.
[Man83] MANDELBROT B. B.: The Fractal Geometry of Nature. Freeman, New York, 1983.
[Mar80] MARCELJA S.: Mathematical description of the responses of simple cortical cells. Journal of the Optical
Society of America, 70 (1980), 1297–1300.
[MFTF03] TAPPEN M. F. B. C. R., FREEMAN W. T.: Exploiting
the sparse derivative prior for super-resolution and image
demosaicing. In Proceedings of the Third International
Workshop on Statistical and Computational Theories of
Vision at ICCV (Nice, France, 2003).
[MNSA07] MOTOYOSHI I., NISHIDA S., SHARAN L., ADELSON E.
H.: Image statistics and the perception of surface qualities.
Nature, 447, 7141 (2007), 206–209.
[MOVY01] MANJUNATH B. S., OHM J. R., VINOD V. V.,
YAMADA A.: Color and texture descriptors. IEEE Transactions on Circuits and Systems for Video Technology, 11, 6
(2001), 703–715.
[NCB04] NEELAMANI R., CHOI H., BARANIUK R.: ForWaRD: Fourier-wavelet regularized deconvolution for illconditioned systems. IEEE Transactions on Signal Processing, 52, 2 (2004), 418–433.
[NCH*05] NG T.-T., CHANG S.-F., HSU J., XIE L., TSUI M.P.: Physics-motivated features for distinguishing photographic images and computer graphics. In Proceedings of
the ACM International Conference on Multimedia (Singapore, 2005), pp. 239–248.

c 2011 The Authors
Computer Graphics Forum c 2011 The Eurographics Association and Blackwell Publishing Ltd.

1786

T. Pouli et al. / A Survey of Image Statistics Relevant to Computer Graphics

[OD10] OLSHAUSEN B. A., DEWEESE M. R.: The statistics of
style. Nature, 463 (2010), 1027–1028.
[OF96] OLSHAUSEN B. A., FIELD D. J.: Emergence of simplecell receptive field properties by learning a sparse code for
natural images. Nature, 381 (1996), 607–609.
[OF97] OLSHAUSEN B. A., FIELD D. J.: Sparse coding with
an overcomplete basis set: A strategy employed by V1?
Vision Research, 37 (1997), 3311–3325.
[OSS83] OWSLEY C., SEKULAR R., SIEMSEN D.: Contrast sensitivity throughout adulthood. Vision Research, 23 (1983),
689–699.
[OT01] OLIVA A., TORRALBA A.: Modeling the shape of the
scene: a holistic representation of the spatial envelope.
International Journal of Computer Vision, 42, 3 (2001),
145–175.
[PBT98] P´ARRAGA C. A., BRELSTAFF G., TROSCIANKO T.: Color
and luminance information in natural scenes. Journal of
the Optical Society of America A, 15, 3 (1998), 563–569.
[PBTM98] P´ARRAGA C. A., BRELSTAFF G., TROSCIANKO T.,
MOOREHEAD I. R.: Color and luminance information in
natural scenes. Journal of the Optical Society of America
A, 15, 3 (1998), 563–569.
[PR10] POULI T., REINHARD E.: Progressive histogram reshaping for creative color transfer and tone reproduction. In Proceedings of the ACM Symposium on NonPhotorealistic Animation and Rendering (Annecy, France,
June 2010), pp. 81–90.
[PRC10] POULI T., REINHARD E., CUNNINGHAM D.: Statistical
regularities in low and high dynamic range images. In Proceedings of the ACM Symposium on Applied Perception
in Graphics and Visualization (Los Angeles, 2010).
[PS88] PEITGEN H.-O., SAUPE D.: The Science of Fractal Images. Springer-Verlag, New York, 1988.
[PS00] PORTILLA J., SIMONCELLI E. P.: Image denoising via
adjustment of wavelet coefficient magnitude correlation.
In Proceedings of the 7th International Conference on Image Processing (Vancouver, Canada, 2000), pp. 277–280.
[PSWS03] PORTILLA J., STRELA V., WAINWRIGHT M. J.,
SIMONCELLI E. P.: Image denoising using scale mixtures
of Gaussians in the wavelet domain. IEEE Transactions
on Image Processing, 12, 11 (2003), 1338–1351.
[PWK95] PETERZELL D. H., WERNER J. S., KAPLAN P. S.: Individual differences in contrast sensitivity functions: Longitudinal study of 4-, 6- and 8-month-old human infants.
Vision Research, 35, 7 (1995), 9651–979.

[RAC*04] REINHARD E., AKYU¨ Z A. O., COLBERT M., HUGHES
C. E., O’CONNOR M.: Real-time color blending of rendered and captured video. In Proceedings of the Interservice/Industry Training, Simulation and Education Conference (Orlando, FL, December 2004).
[RAGS01] REINHARD E., ASHIKHMIN M., GOOCH B., SHIRLEY
P.: Color transfer between images. IEEE Computer Graphics and Applications, 21 (2001), 34–41.
[RB94] RUDERMAN D., BIALEK W.: Statistics of natural images: scaling in the woods. Physical Review Letters 73, 6
(1994), 814–817.
[RB05] ROTH S., BLACK M. J.: Fields of experts: a framework
for learning image priors. In Proceedings of the IEEE
Conference on Computer Vision and Pattern Recognition
(San Diego, CA, 2005), pp. 860–867.
[RB09] ROTH S., BLACK M. J.: Fields of experts. International Journal of Computer Vision, 82, 2 (2009), 205–
229.
[RCC98] RUDERMAN D. L., CRONIN T. W., CHIAO C.: Statistics of cone responses to natural images: implications for
visual coding. Journal of the Optical Society of America
A, 15, 8 (1998), 2036–2045.
[RK99] RAINVILLE S. J. M., KINGDOM F. A. A.: Spatial-scale
contribution to the detection of mirror symmetry in fractal
noise. Journal of the Optical Society of America A, 16, 9
(1999), 2112–2123.
[RKAJ08a] REINHARD E., KHAN E. A., AKYU¨ Z A. O., JOHNSON
G. M.: Color Imaging: Fundamentals and Applications.
A K Peters, Wellesley, 2008.
[RKAJ08b] REINHARD E., KHAN E. A., AKYU¨ Z A. O., JOHNSON
G. M.: Color Imaging: Fundamentals and Applications.
AK Peters, Wellesley, MA, 2008.
[RSAT04] REINHARD E., SHIRLEY P., ASHIKHMIN M.,
TROSCIANKO T.: Second order image statistics in computer
graphics. In Proceedings of the 1st Symposium on Applied
Perception in Graphics and Visualization (Los Angeles,
CA, 2004), pp. 99–106.
[RST01] REINHARD E., SHIRLEY P., TROSCIANKO T.: Natural Image Statistics for Computer Graphics. Tech. Rep.
UUCS01-002, University of Utah, 2001.
[Rud94] RUDERMAN D. L.: The statistics of natural images. Network: Computation in Neural Systems, 5 (1994),
517–548.
[Rud97] RUDERMAN D. L.: Origins of scaling in natural images. Vision Research, 37 (1997), 3385–3398.

c 2011 The Authors
Computer Graphics Forum c 2011 The Eurographics Association and Blackwell Publishing Ltd.

T. Pouli et al. / A Survey of Image Statistics Relevant to Computer Graphics

[RV90] ROGOWITZ B., VOSS R.: Shape perception and lowdimension fractal boundaries. Proceedings of the SPIE
1249 (1990), 387–394.
[SA96] SIMONCELLI E. P., ADELSON E. H.: Noise removal via
bayesian wavelet coring. In Proceedings of the Third International Conference on Image Processing (Lausanne,
France, 1996), vol. I, pp. 379–392.
[SBM*05] SPYROU E., BORGNE H. L., MAILIS T., COOKE
E., AVRITHIS Y., O’CONNOR N.: Fusing MPEG-7 descriptors for image classification. In Proceedings of ICANN
(Warsaw, Poland, 2005), vol. LNCS 3697, pp. 847–
852.
[SDS95] STOLLNITZ E. J., DEROSE T. D., SALESIN D. H.:
Wavelets for computer graphics: a primer. IEEE Computer Graphics and Applications, 15, 3 (1995), 76–84.
[SDS96] STOLLNITZ E. J., DEROSE T. D., SALESIN D. H.:
Wavelets for Computer Graphics: Theory and Applications. Morgan Kaufmann, San Francisco, 1996.
[Sim97] SIMONCELLI E. P.: Statistical models for images:
compression, restoration and synthesis. In Proceeding of
the 31st Asilomar Conference on Signals, Systems and
Computers (Pacific Grove, CA, 1997), pp. 673–678.

1787

In Proceedings of the 5th International Conference of Image Processing (Chicago, IL, 1998), vol. I, pp. 62–66.
[SWF09] SPEHR M., WALLRAVEN C., FLEMING R. W.: Image
statistics for clustering paintings according to their visual
appearance. In Computational Aesthetics, Eurographics,
Switzerland (2009), pp. 1–8.
[SWO84] SEKULER R., WILSON H. R., OWSLEY C.: Structural
modeling of spatial vision. Vision Research, 24, 7 (1984),
689–700.
[TF97] THOMSON M., FOSTER D.: Role of second- and thirdorder statistics in the discriminability of natural images.
Journal of the Optical Society of America A, 14 (1997),
2081–2090.
[Tho99] THOMSON M. G. A.: Visual coding and the phase
structure of natural scenes. Network: Computation in Neural Systems, 10 (1999), 123–132.
[Tho01] THOMSON M. G. A.: Beats, kurtosis and visual coding. Network: Computation in Neural Systems, 12 (2001),
271–287.
[TM01] TAUBMAN D., MARCELLIN M.: JPEG 2000: Image Compression Fundamentals, Standards and Practice.
Springer, Dordrecht, The Netherlands, 2001.

[Sim99a] SIMONCELLI E. P.: Bayesian denoising of visual images in the wavelet domain. In Bayesian Inference in
Wavelet Based Models, P. M¨uller, B. Vidakovic (Eds.).
Springer-Verlag, New York, 1999.

[TO03] TORRALBA A., OLIVA A.: Statistics of natural image
categories. Network: Computation in Neural Systems, 14
(2003), 391–412.

[Sim99b] SIMONCELLI E. P.: Modeling the joint statistics of
images in the wavelet domain. In Proceedings of the SPIE
44th Annual Meeting (Denver, CO, 1999), vol. 3813, pp.
188–195.

[TSW*05] TAYLOR R., SPEHAR B., WISE J., CLIFFORD C.,
NEWELL B., HAGERHALL C., PURCELL T., MARTIN T.: Perceptual and physiological responses to the visual complexity of fractal patterns. Nonlinear Dynamics Psychol
Life Science, 9 (2005), 89–114.

[Sim05] SIMONCELLI E.: Statistical modeling of photographic
images. In Handbook of Image and Video Processing, A.
Bovik (Ed.). Elsevier Academic Press, Burlington, MA
(2005), ch. 4. 7, pp. 431–441.

[TT93] TADMOR Y., TOLHURST D. J.: Both the phase and the
amplitude spectrum may determine the appearance of natural images. Vision Research, 33, 1 (1993), 141–145.

[SJA08] SHAN Q., JIA J., AGARWALA A.: High-quality motion
deblurring from a single image. ACM Transactions on
Graphics, 27, 3 (2008), 1–10.

[TT94] TADMOR Y., TOLHURST D.: Discrimination of changes
in the second order statistics of natural and synthetic images. Vision Research, 34 (1994), 541–554.

[SJZW07] SHEN J., JIN X., ZHOU C., WANG C. C. L.: Gradient based image completion by solving Poisson equation.
Computers and Graphics, 31 (2007), 119–126.

[TTC92] TOLHURST D. J., TADMOR Y., CHIAO T.: Amplitude
spectra of natural images. Ophthalmic and Physiological
Optics 12 (1992), 229–232.

[SMS78] SWITKES E., MAYER M. J., SLOAN J. A.: Spatial frequency analysis of the visual environment: Anisotropy and
the carpentered environment hypothesis. Vision Research,
18, 10 (1978), 1393–1399.

[van92] VAN HATEREN J.: Theoretical predictions of spatiotemporal receptive fields. Journal of Comparative
Physiology A, 171 (1992), 151–170.

[SP98] SIMONCELLI E. P., PORTILLA J.: Texture characterization via joint statistics of wavelet coefficient magnitudes.

[van98] VAN DER SCHAAF A.: Natural Image Statistics and Visual Processing. PhD thesis, Rijksuniversiteit Groningen,
The Netherlands, 1998.

c 2011 The Authors
Computer Graphics Forum c 2011 The Eurographics Association and Blackwell Publishing Ltd.

1788

T. Pouli et al. / A Survey of Image Statistics Relevant to Computer Graphics

[vG05] VAN DE WEIJER J., GEVERS T.: Color constancy based
on the grey-edge hypothesis. In Proceedings of the International Conference on Image Processing (Genoa, Italy,
2005).

[Wat91] WATSON A. B.: Multidimensional pyramids in vision and video. In Representations of Vision, A. Gorea
(Ed.). Cambridge University Press, Cambridge (1991),
pp. 17–26.

[Vos85] VOSS R.: Random fractal forgeries. In Fundamental
Algorithms for Computer Graphics, R. A. Earnshaw (Ed.).
Springer, Berlin (1985), pp. 805–835.

[Whi79] WHITE M.: A new effect of pattern on perceived
lightness. Perception, 8 (1979), 413–416.

[vv96] VAN DER SCHAAF A., VAN HATEREN J.: Modelling the
power spectra of natural images: statistics and information. Vision Research, 36, 17 (1996), 2759–2770.
[vv98] VAN HATEREN J., VAN DER SCHAAF A.: Independent
component filters of natural images compared with simple
cells in primary visual cortex. Proceedings of the Royal
Society of London B, 265 (1998), 359–366.
[WA89] WATSON A. B., AHUMADA JR. A. J.: A hexagonal orthogonal oriented pyramid as a model of image representation in visual cortext. IEEE Transactions on Biomedical
Engineering, 36, 1 (1989), 97–106.
[Wat87] WATSON A. B.: Efficiency of an image code based on
human vision. Journal of the Optical Society of America
A, 4, 12 (1987), 2401–2417.
[Wat90] WATSON A. B.: Perceptual components architecture
for digital video. Journal of the Optical Society of America, 7 (1990), 1943–1954.

[WHO03] WELLING M., HINTON G., OSINDERO S.: Learning sparse topographic representations with products of
student-t distributions. In Proceedings of the NIPS (Cambridge, MA 2003), MIT Press, vol. 15, pp. 1359–1366.
[WLS01] WACHTLER T., LEE T.-W., SEJNOWSKI T. J.: Chromatic structure of natural scenes. Journal of the Optical
Society of America A, 18, 1 (2001), 65–77.
[WM97] WEBSTER M., MIYAHARA E.: Contrast adaptation
and the spatial structure of natural images. Journal of the
Optical Society of America A, 14 (1997), 2355–2366.
[ZL98] ZIEGAUS C., LANG E. W.: Statistical invariances in
artificial, natural and urban images. Z. Naturforsch, 53a
(1998), 1009–1021.
[ZYK*08] ZHENG Y., YU J., KANG S.-B., LIN S.,
KAMBHAMETTU C.: Single-image vignetting correction using radial gradient symmetry. In Proceedings of the IEEE
Conference on Computer Vision and Pattern Recognition
(Anchorage, Alaska, 2008).

c 2011 The Authors
Computer Graphics Forum c 2011 The Eurographics Association and Blackwell Publishing Ltd.

