DOI: 10.1111/j.1467-8659.2011.02059.x
Pacific Graphics 2011
Bing-Yu Chen, Jan Kautz, Tong-Yee Lee, and Ming C. Lin
(Guest Editors)

Volume 30 (2011), Number 7

Real Time Edit Propagation by Efficient Sampling
Xiaohui Bie1,3 and Haoda Huang2 and Wencheng Wang1
1 State

Key Laboratory of Computer Science, Institute of Software, Chinese Academy of Sciences
2 Microsoft Research Asia
3 Graduate University of Chinese Academy of Sciences

Abstract
It is popular to edit the appearance of images using strokes, owing to their ease of use and convenience of conveying the user’s intention. However, propagating the user inputs to the rest of the images requires solving an
enormous optimization problem, which is very time consuming, thus preventing its practical use. In this paper, a
two-step edit propagation scheme is proposed, first to solve edits on clusters of similar pixels and then to interpolate individual pixel edits from cluster edits. The key in our scheme is that we use efficient stroke sampling to
compute the affinity between image pixels and strokes. Based on this, our clustering does not need to be strokeadaptive and thus the number of clusters is greatly reduced, resulting in a significant speedup. The proposed
method has been tested on various images, and the results show that it is more than one order of magnitude faster
than existing methods, while still achieving precise results compared with the ground truth. Moreover, its efficiency
is not sensitive to the number of strokes, making it suitable for performing dense edits in practice.
Categories and Subject Descriptors (according to ACM CCS): I.4.0 [IMAGE PROCESSING AND COMPUTER
VISION]: General—Image processing software

1. Introduction
Nowadays, digital cameras are very popular, but since most
end users are not professional photographers, they often
need to refine their photographs or videos by changing the
color, brightness, contrast, and so on. Owing to the large
number of appearance samples in images and the need to
maintain the intricate patterns, it is a laborious process to
manually alter appearance samples individually. With regard
to this, recent methods [LFUS06,PL07,AP08,XLJ∗ 09]have
provided a simple interaction mode for appearance editing,
where edits are roughly specified by users on a sparse set
of image locations (e.g., the strokes in Figure 1) without the
need for accurate region selection, and then they are automatically propagated to the rest of the image by solving an
optimization problem. To find the appropriate editing parameters to achieve the final desired look, some methods use
other images as color references [WHCO08, AP10], which
works very well. However, the slowness of edit propagation
is still a big obstacle preventing its widespread application.
The well-known AppProp method [AP08] requires a prohibitive amount of memory and substantial computation
time to process the large inputs, owing to the fact that the
method needs to solve an optimization problem, whose size
c 2011 The Author(s)
Computer Graphics Forum c 2011 The Eurographics Association and Blackwell Publishing Ltd. Published by Blackwell Publishing, 9600 Garsington Road, Oxford OX4 2DQ,
UK and 350 Main Street, Malden, MA 02148, USA.

is proportional to the number of pixels in the data. Observing that the propagated edits form a smooth function, which
could be approximated by piece-wise linear segments in a
higher dimensional affinity space, Xu et al. [XLJ∗ 09] proposed generating clusters of pixels using a kd-tree in the
affinity space, and solving the optimization problem with
clusters instead of individual pixels. Because the number
of clusters is much smaller than the number of pixels, their
method brought about a considerable speedup in edit propagation, allowing interactive editing of the appearance of an
image. However, since clustering is stroke-sensitive and the
propagation time increases dramatically as the number of
user strokes increases, the method is not suitable for performing dense edits.
Recently, Li. et al. [LJH10] proposed instant propagation
of sparse edits by reformulating propagation as a function
interpolation. Although propagation speed is improved, efficiency is still dependent on the number of strokes, and thus
this method is not suited to dense edits either. Moreover, it is
difficult to choose basis functions that produce high-quality
results.
In this paper, we propose a two-step edit propagation
scheme for appearance editing, which first solves edits on

2042

Xiaohui Bie & Haoda Huang & Wencheng Wang / Real Time Edit Propagation by Efficient Sampling

clusters of similar pixels and then interpolates individual
pixel edits from cluster edits. The key observation is that as
there are many similar pixels in each stroke, we can reformulate the stroke constraint in our energy function and use efficient Monte Carlo sampling to compute the affinity between
image pixels and strokes. One benefit of this observation is
that we are able to use a more efficient clustering method instead of a stroke-adaptive clustering one [XLJ∗ 09] to generate far fewer clusters. Since the cluster number is greatly reduced, we can efficiently solve a very small propagation optimization problem using a simple dense matrix solver. Another significant benefit of the observation is that it is able to
support many strokes efficiently. Experimental results show
that our method is faster than existing methods by at least
one order of magnitude, while still obtaining high-quality
results compared with the ground truth.
Our real time edit propagation is made possible by a number of technical contributions:
(1) A novel adaptive stroke sampling technique that automatically determines a minimal number of samples for userspecified strokes. This not only improves the ability to support dense strokes, but also greatly reduces the size of the
appearance space.
(2) An efficient edit propagation that computes edit
propagation in a reduced stroke-independent appearance
space. Compared with a previous stroke-adaptive method
[XLJ∗ 09], our edit propagation method is unique in that it
performs edit propagation in a reduced stroke-independent
appearance space, thus requiring far fewer clusters.
(3) Finally, an efficient edit interpolation method that accurately interpolates cluster edits to each pixel. Instead of
heuristically interpolating pixel edits from nearby cluster edits, we derive a more rigorous interpolation method from the
original edit propagation formulation.
2. Related Work
Appearance editing of images/videos is widely used in applications. The general approach is to control the adjustment locally by applying edits selectively in different regions. However, performing such selections is very laborious. To alleviate this problem, several methods have been proposed,
such as the edge-aware image methods [CPD07, LAA08,
FCA09]. Recently, intuitive stroke-based methods have also
been proposed to simplify the selection process, where users
only need to mark with strokes those regions that should receive the same edit [LLW04, LFUS06, PL07, XWT∗ 09]. To
ensure that such methods are used more generally, do not
completely rely on selections, and are more efficient and
robust numerically, the AppProp method [AP08] was proposed to edit according to the policy that similar edits are
applied to spatially-close regions of similar appearance. To
achieve this, it needs to detect the affinity over all pairs of
pixels, and solve an energy optimization with large linear

systems. Although an approximation algorithm has been derived to compute such a solution, computation of the method
is still very expensive, preventing its practical use.
To speed up edit propagation and promote practical use,
Xu et al. [XLJ∗ 09] proposed solving the optimization problem on clusters instead of individual pixels, thereby achieving an interactive speed. However, the generation of clusters
is stroke-sensitive, which could lead to a very large number of clusters, thus preventing its acceleration efficiency
and making it unsuitable for application to dense edits. Recently, Li et al. [LJH10] proposed using the pixels covered
by strokes to formulate the constraints as a least-square energy function. This approach is very fast for sparse edits, but
is not suited to dense edits as its complexity is dependent
on the stroke pixels. Moreover, the selection of basis functions is difficult in practice. If a few basis functions are used
in the energy function, edits cannot be fully propagated to
distant regions with similar appearances. On the other hand,
increasing the number of basis functions could increase the
cost.
3. Overview
Our method works by using the similarity between pixels to
reduce the time cost of propagating edits. Using the similarities, many computations for solving the optimization problem can be simplified with a few samples. For every stroke,
we randomly sample a few points to compute the affinity of
each with regard to every pixel. Based on clusters of similar
pixels, we can divide the edit propagation process into two
steps, the first of which propagates edits to clusters by solving the optimization problem, while the second propagates
edits to individual pixels by simple interpolation of cluster
edits. Using samples to solve the optimization problem, the
size of the problem is greatly reduced, and thus speedup can
be achieved, while still realizing high-quality results.
As illustrated in Figure 1, for an image with three strokes
(a), we only need to sample about 30 points in every stroke
(b), and generate 100 clusters of pixels (c) to propagate edits
(d) for obtaining a result with an error of 0.937% (e). The edits by AppProp [AP08](f) and their results (g) are used as a
reference. As for Xu’s method, it needs 10k corners as clusters (h) to obtain a result with an error of 1.01% (i). With regard to the time cost, our method requires only 0.01 s, while
Xu’s method needs 0.26 s. It is clear that our method is much
faster and obtains high-quality results for edit propagation.
4. Efficient Sampling for Edit Propagation
According to the introduction in [AP08],edit propagation is
formalized as an optimization problem, by defining the propagated parameter e as the one that minimizes the following
energy function:

∑ ∑ w j zi j (ei − g j )2 + λ ∑ ∑ zi j (ei − e j )2
i

j

i

(1)

j

c 2011 The Author(s)
c 2011 The Eurographics Association and Blackwell Publishing Ltd.

Xiaohui Bie & Haoda Huang & Wencheng Wang / Real Time Edit Propagation by Efficient Sampling

2043

Figure 1: Our pipeline for edit propagation and the results thereof compared with AppProp and Xu’s method. It is clear that
our method significantly improves the efficiency of edit propagation.

where zi j = exp(−( f i − f j )2 /σa ) exp(−( x i − x j
)2 /σs ), is the affinity between pixel i and pixel j, computed
as the product of two guassians of the distance between the
pixels’ spatial locations x i and their appearance vectors f i ,
respectively. λ is a parameter for controlling the relative contributions of these two terms. The weight w has a value of 0
for non-edited pixels and larger values for edited pixels to
propagate the user-specified edits g.

where N(s) is the number of pixels covered by stroke-s, N is
the number of pixels sampled from these covered pixels, and
s(k) is the kth sampled pixel.
To perform Monte Carlo integration efficiently, we add
samples iteratively to a stroke until the following energy
function for this stroke converges:
E = (1/N) ∑

∑

zi,s (k)

(5)

i k=1...N

As w j is 0 for the non-edited pixel j, the energy function
(1) can be reformulated as:

∑∑
i

2

zim (ei − gs ) + λ ∑ ∑ zi j (ei − e j )

∑

i

S m∈Stroke(s)

2

(2)

j

where s represents a stroke in the set of strokes S, and m is
a pixel covered by stroke-s. Because the user-specified edits
retain the same gs for all pixels in a stroke, regardless of the
pixel appearance, we can further reformulate (2) as

∑ ∑ zis (ei − gs )2 + λ ∑ ∑ zi j (ei − e j )2
i

i

S

where

(3)

j

∑

zis =

zim .

m∈Stroke(s)

Equation (3) forms the basis for efficient stroke sampling
in our new method.

4.1. Stroke Sampling
In (3), it is costly to compute zis according to its definition as
this requires the summation of all the stroke pixels for each
image pixel, where there are typically thousands of stroke
pixels. Fortunately, variations in the appearance of the stroke
pixels are mostly small, so we need very few sample points
to perform Monte Carlo integration [PH04] to compute zis
in the following equation:
zis = (N(s)/N)

∑

zi,s (k)

k=1...N
c 2011 The Author(s)
c 2011 The Eurographics Association and Blackwell Publishing Ltd.

(4)

In other words, for the tth iteration, there are Nt samples,
and the energy function has the value Et . When the following
inequality holds:
|Et+1 − Et |
<ε
|Et |

(6)

it means there are enough samples in this stroke for propagation computation. In our tests, 5 samples are added each
time, and ε is always set as 0.005.
Figure 2 shows that our method can adaptively sample
sufficient points for different strokes. For strokes covering
the smooth parts, like the sky in this case, our method samples fewer points to do the affinity computation. On the
other hand, for strokes covering parts that have complex
content, such as textures on a flower, our method samples
more points. Clearly, if there are more complex features in a
stroke, more samples are required adaptively to achieve good
results. But the number is never very high.
Table 1 gives the time cost for the affinity computation
by (4) and by summing all the stroke pixels for each image
pixel. Clearly, using (4), the affinity computation can be accelerated about 100-fold.
4.2. Cluster Edits
Because similar pixels are subject to similar edits, we can
group similar pixels into clusters for edit propagation. Here,

2044

Xiaohui Bie & Haoda Huang & Wencheng Wang / Real Time Edit Propagation by Efficient Sampling

Figure 2: Our method can adaptively sample sufficient
points for different strokes. In this case, the color change in
the sky parts is very smooth, so our method samples fewer
points on the "sky-stroke", whereas the features are more
complex in the flowers parts, so the "flower-stroke" needs
more samples.

Table 1: Efficiency comparison of the affinity computation
using our sampling measure and by summing all the stroke
pixels.

we apply the k-means clustering method [Har75] and accelerate it by ANN searching. After similar pixels have been
grouped into clusters, the center point of each cluster is selected as the affinity space sample to solve the propagation
optimization problem. By (3), the edits are propagated to
clusters using the following formula:

∑ ∑ wu zus (cu − gs )
u

s

2

+ λ ∑ ∑ zuv wu wv (cu − cv )

2

(7)

u v

where cu represents the uth cluster, wu denotes the number
of pixels in cluster u, and as the weight for the cluster, zuv is
the affinity between clusters u and v, and zus is the affinity
between the uth cluster and the sth stroke.
As our clustering is not stroke-sensitive, a small number
of clusters is sufficient to achieve very precise results. In Figure 3, we list some statistics of the edit propagation errors
with varying numbers of clusters using our method (Figure
3(b)) compared with Xu’s method (Figure 3(a)). It is obvious
that our method uses very few clusters to achieve very good
results, with the clusters reduced by over two orders of magnitude. It can be argued that good results can be obtained by
randomly sampling points in the image. For this, we also list
the related statistics in Figure 3(c), which show that the error
of random sampling converges more slowly as the number
of clusters increases. This is because random sampling can-

Figure 4: Statistics for the numbers of most similar clusters
used for interpolating edits.

not guarantee that the affinity space is well sampled, especially for complicated images such as the "Tulip" image. In
contrast, k-means clustering adaptively samples the affinity
space, so very precise results can be achieved with 100 clusters, even for the complicated "Tulip" image. Because our
method generally uses at most hundreds of clusters, we can
solve the optimization problem directly using a simple dense
matrix solver, without the need for an approximate solution
as in [AP08].
4.3. Pixel Edits
Taking advantage of the observation that propagated edits
form a smooth function in the affinity space [XLJ∗ 09], we
can interpolate pixels edits from cluster edits. One simple
method is to realize pixel edits by assigning the cluster edits to their respective member pixels. In practice, we find that
such an approximation already yields good results. However,
we can derive a more precise interpolation method from the
energy function. We first reformulate the energy function according to the relation between clusters and pixels as

∑ ∑ wu zus (cu − gs )2 + λ ∑ ∑ zu j wu (cu − e j )2
u

s

u

(8)

j

By minimizing the energy function in (8), we refine the pixel
edits as
e j = ∑ zu j wu cu / ∑ zu j
u

(9)

u

In this way, an efficient solution is provided for propagating
edits to individual pixels.
To speed up the computation, we adopt an approximate
technique as explained below. For every pixel, we first find a
few clusters whose features are most similar to the feature at
the pixel. Then we only use the most similar clusters while
refining the edit at a pixel, without the need to use all the
clusters. Figure 4 gives the statistics of the number of nearest clusters used for every pixel and the corresponding edit
errors for the tested images. From the statistics, it is clear that
the error is smaller if the number is larger. Very good results
are obtained with 3 clusters, and thereafter the edit quality
c 2011 The Author(s)
c 2011 The Eurographics Association and Blackwell Publishing Ltd.

Xiaohui Bie & Haoda Huang & Wencheng Wang / Real Time Edit Propagation by Efficient Sampling

2045

Figure 3: Statistics for the edit errors with varying numbers of clusters using our method (b), and compared with Xu’s method
(a) and random sampling (c). The graphs show that our method can generate high-quality results with very few clusters.

improves slowly. Thus, in our implementation, we generally
select three clusters for each pixel in such an approximate
computation.
5. Algorithm Analysis
Based on the above discussion, we summarize the procedure
for our algorithm. In the preprocessing stage, we group similar pixels of an image into clusters using k-means clustering,
and then find the 3 nearest clusters for each pixel. Note that
the indices and the affinity values of the 3 nearest clusters
for each pixel are stored for runtime edit propagation. In the
runtime edit propagation stage, the user draws strokes on the
image, and inputs the edit parameter for each stroke. Thereafter, we apply our two-step method to solve the cluster edits
and interpolate pixel edits.
Space. In our experiment, typically only 100 clusters are
selected to generate results, so the storage for cluster information is negligible. Most of the storage is for the indices
and affinity values of the nearest clusters for each pixel. The
storage complexity of this part is O(n), where n is the number of pixels.
Time. Our method works in two stages. In the preprocessing stage, k-means clustering accelerated by ANN searching
takes O(nlog(m)) time, where n is the number of pixels, and
m is the number of clusters. The time complexity to find the
nearest clusters for each pixel is also O(nlog(m)). In the runtime stage, it takes O(m3 ) to solve a dense matrix inverse for
computing cluster edits, and O(n) time to interpolate pixel
edits from cluster edits. Generally, propagating edits to clusters takes less time than interpolating edits from clusters to
pixels. As a result, our method can reasonably be regarded
as taking O(n) time for edit propagation.
6. Results and Discussion
We implemented our new method, and the methods in
[AP08, XLJ∗ 09] for comparison. We carried out the tests on
a commodity computer installed with an Intel Q9400 CPU
and 4GB RAM.
c 2011 The Author(s)
c 2011 The Eurographics Association and Blackwell Publishing Ltd.

For fairness, we edited images with strokes for color and
brightness adjustment as was done in [AP08, XLJ∗ 09].
These are listed in Figure 5, together with the edited results
and related statistics, with the errors computed relative to
the edited results by AppProp [AP08]. Here, σa is set to
be 500 for all examples, and σs is set to be 0.2 for Figure 6
and 10 for all other examples. From the statistics, it is clear
that our method uses very few clusters to achieve precise results. As for the time cost of performing the tests, we list
the statistics for Xu’s method and our method in Table 2. In
our method, preprocessing is only performed once and the
generated clusters can be used repeatedly. The preprocessing times are 0.12, 0.11, 0.12, 0.12, 1.0, 1.5, and 1.2 s for the
images Building, Tulip, Tree, Fog tree, Swan, Butterfly, and
River, respectively.
From the image experimental results, it is clear that our
method uses very few clusters to achieve precise results,
is faster than existing methods by at least one order of
magnitude, and is able to handle medium-size images in real
time. The required memory is less than 50 MB for all the
images in our experiment. We also tested the efficiency on
dense edit examples using our method and Xu’s method. As
shown in Figure 6, as the stroke number increases, the edit
error and time cost of Xu’s method increase dramatically.
In contrast, our method is not sensitive to the number
of strokes and the edit error and time cost only increase
slightly. Obviously, our method is more robust for dense
edits.
Limitations. The main limitation of our method is
that the memory required increases linearly with the number
of pixels in the datasets. In future work, we will try to
reduce the memory requirements to make the method more
practical for long high-resolution video editing applications.
Another limitation is that our method may generate artifacts when σs is too small. As discussed in [AP08], this is
because in this case the affinity matrix would be of high rank,
and so cannot be well approximated by a low rank matrix.
In Figure 7, an example is illustrated that the error for edit

2046

Xiaohui Bie & Haoda Huang & Wencheng Wang / Real Time Edit Propagation by Efficient Sampling

Table 2:Statistics for the performance of our method in editing the images displayed in this paper compared with Xu’s
method.

propagation increases when σs becomes smaller and smaller,
and artifacts will be very evident if σs is too small. Here, the
ground truth image of propagation results for the test image
of 128*128 pixels is accurately computed by solving equation (1) on a workstation with 48GB RAM. As pointed out
in [AP08], in many applications this limitation may not be
a big issue. However, σs may be very small for local edits,
and this is an interesting problem to be further studied.

Figure 7: Artifacts will occur when the σs is too small in
applying the AppProp method and our method, as shown
in (b) for the statistics about the errors with the values of
σs . In the below two rows, it is displayed that the blue sky
part in the upper right region of the edited results by these
two methods are wrongly colored, in comparison with the
Groundtruth, which is produced by minimizing the energy
function (1) without a low rank approximation of the affinity
matrix.

7. Conclusions
This paper presents an efficient two-step method for solving
the optimization problem in edit propagation. By taking
advantage of the similarity between stroke pixels, we use
stroke sampling to compute the affinity between image
pixels and strokes efficiently. Based on this stroke sampling,
we develop a stroke insensitive clustering method that
greatly reduces the number of clusters. Since the cluster
number is small, we can efficiently solve the cluster edit
using a simple dense matrix solver. Finally, a smooth edit
is achieved across the pixels by interpolating cluster edits.
Experimental results demonstrate that our method performs
much faster than existing methods, and is much more robust
to dense edit conditions.
Acknowledgements:
This work was partly supported by NSFC (60773026,
60873182, 60833007). Original Images in Figures 1, 5(d),
5(e), 5(f), 5(g) and 7 are courtesy of [AP08], and Figures
2 and 5(b) courtesy panasonic.jp, Figure 5(a) courtesy
wodehuayuan.com, Figure 5(c) courtesy caistv.com and
Figure 6 courtesy cnz1hh.com.
References
[AP08] A N X., P ELLACINI F.: Appprop: all-pairs appearancespace edit propagation. vol. 27, ACM, p. 40. 1, 2, 4, 5, 6
[AP10] A N X., P ELLACINI F.: User-Controllable Color Transfer. In Computer Graphics Forum (2010), vol. 29, John Wiley &
Sons, pp. 263–271. 1

[CPD07] C HEN J., PARIS S., D URAND F.: Real-time edge-aware
image processing with the bilateral grid. In SIGGRAPH ’07:
ACM SIGGRAPH 2007 papers (New York, NY, USA, 2007),
ACM, p. 103. 2
[FCA09] FATTAL R., C ARROLL R., AGRAWALA M.: Edgebased image coarsening. ACM Trans. Graph. 29, 1 (2009), 1–11.
2
[Har75] H ARTIGAN J.: Clustering algorithms. Wiley series in
probability and mathematical statistics (1975). 4
[LAA08] L I Y., A DELSON E., AGARWALA A.: Scribbleboost:
Adding classification to edge-aware interpolation of local image
and video adjustments. In Computer Graphics Forum (2008),
vol. 27, pp. 1255–1264. 2
[LFUS06] L ISCHINSKI D., FARBMAN Z., U YTTENDAELE M.,
S ZELISKI R.: Interactive local adjustment of tonal values. In
SIGGRAPH ’06: ACM SIGGRAPH 2006 Papers (New York, NY,
USA, 2006), ACM, pp. 646–653. 1, 2
[LJH10] L I Y., J U T., H U S.: Instant Propagation of Sparse Edits
on Images and Videos . In Computer Graphics Forum (2010),
vol. 29, John Wiley & Sons, pp. 2049–2054. 1, 2
[LLW04] L EVIN A., L ISCHINSKI D., W EISS Y.: Colorization
using optimization. In SIGGRAPH ’04: ACM SIGGRAPH 2004
Papers (New York, NY, USA, 2004), ACM, pp. 689–694. 2
[PH04] P HARR M., H UMPHREYS G.: Physically Based Rendering: From Theory to Implementation. Morgan Kaufmann Publishers Inc. San Francisco, CA, USA, 2004. 3
[PL07] P ELLACINI F., L AWRENCE J.: Appwand: editing measured materials using appearance-driven optimization. In SIGGRAPH ’07: ACM SIGGRAPH 2007 papers (New York, NY,
USA, 2007), ACM, p. 54. 1, 2

c 2011 The Author(s)
c 2011 The Eurographics Association and Blackwell Publishing Ltd.

Xiaohui Bie & Haoda Huang & Wencheng Wang / Real Time Edit Propagation by Efficient Sampling

2047

Figure 5: Performance comparison of our method, Xu’s method using a kd-tree, and the AppProp method. It is clear that our
method obtains similar edit results with very few clusters.
c 2011 The Author(s)
c 2011 The Eurographics Association and Blackwell Publishing Ltd.

2048

Xiaohui Bie & Haoda Huang & Wencheng Wang / Real Time Edit Propagation by Efficient Sampling

Figure 6: Our method is not sensitive to the number of strokes, whereas the edit error and time cost of Xu’s method increase
dramatically as the number of strokes increases. For Xu’s method, time statistics were collected with edit errors around 2%,
and the error statistics were collected with the corner number about 40k. This experiment demonstrates that our method is well
suited to dense edits.

[WHCO08] W EN C., H SIEH C., C HEN B., O UHYOUNG M.:
Example-based multiple local color transfer by strokes. In Computer Graphics Forum (2008), vol. 27, John Wiley & Sons,
pp. 1765–1772. 1
[XLJ∗ 09] X U K., L I Y., J U T., H U S., L IU T.: Efficient affinitybased edit propagation using k-d tree. In SIGGRAPH Asia
’09: ACM SIGGRAPH Asia 2009 papers (New York, NY, USA,
2009), ACM, p. 118. 1, 2, 4, 5
[XWT∗ 09] X U K., WANG J., T ONG X., H U S., G UO B.: Edit
Propagation on Bidirectional Texture Functions. In Computer
Graphics Forum (2009), vol. 28, John Wiley & Sons, pp. 1871–
1877. 2

c 2011 The Author(s)
c 2011 The Eurographics Association and Blackwell Publishing Ltd.

