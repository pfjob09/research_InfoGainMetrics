DOI: 10.1111/j.1467-8659.2010.01807.x
Pacific Graphics 2010
P. Alliez, K. Bala, and K. Zhou
(Guest Editors)

Volume 29 (2010), Number 7

L4RW: Laziness-based Realistic Real-time Responsive
Rebalance in Walking
Mingliang Xu†1 , Huansen Li‡1 , Pei Lv§1 , Wenzhi Chen¶1 , Gengdai Liu∥2 , Pengyu Zhu∗∗1 , Zhigeng Pan††1
1 State

Key Lab of CAD&CG, Zhejiang University, China
of Computer Engineering, Xidian University, China

2 Department

Abstract
We present a novel L4RW (Laziness-based Realistic Real-time Responsive Rebalance in Walking) technique to
synthesize 4RW animations under unexpected external perturbations with minimal locomotion effort. We first devise a lazy dynamic rebalance model, which specifies the dynamic balance conditions, defines the rebalance effort,
and selects the suitable rebalance strategy automatically using the laziness law after an unexpected perturbation.
Based on the model, L4RW searches over a motion capture (mocap) database for an appropriate motion segment to follow, and the transition-to motions is generated by interpolating the active response dynamic motion. A
support vector machine (SVM) based training, classification, and predication algorithm is applied to reduce the
search space, and it is trained offline only once. Our algorithm classifies the mocap database into many rebalance
strategy-specified subsets and then online predicts responsive motions in the subset according to the selected strategy. The rebalance effort, the ‘extrapolated center of mass’ (XCoM) and environment constraints are selected as
feature attributes for the SVM feature vector. Furthermore, the subset’s segments are sorted through the rebalance
effort, then our algorithm searches for an acceptable segment starting from the least-effort segment. Compared
with previous methods, our search increases speed by over two orders of magnitude, and our algorithm creates
more realistic and smooth 4RW animation.
Categories and Subject Descriptors (according to ACM CCS): I.3.3 [Computer Graphics]: Animation—

1. Introduction
Simulating balance recovery is of fundamental importance in a wide range of fields, such as robotics, biomechanics, medical science and computer animation. It
has been receiving great interest in recent publications
[MdLH10, SYLH10, LKL10, dLMH10, SBvdP10, KH10,
WFH10, WZ10b, WZ10a, YL10b, YL10a, TLC∗ 10], and its
importance is also embodied in the widely used modern
animation software tools available to synthesize rebalance

† develop_game@yahoo.com.cn
‡ lihuansen@cad.zju.edu.cn
§ lvpei@cad.zju.edu.cn
¶ Corresponding author. wzchen@cad.zju.edu.cn
∥ gdliu@xidian.edu.cn
∗∗ zhupengyu@cad.zju.edu.cn
†† zgpan@cad.zju.edu.cn
c 2010 The Author(s)
⃝
c 2010 The Eurographics Association and Blackwell Publishing Ltd.
Journal compilation ⃝
Published by Blackwell Publishing, 9600 Garsington Road, Oxford OX4 2DQ, UK and
350 Main Street, Malden, MA 02148, USA.

animation, for example, Havok and Natural Motion. However, it is still a challenge to generate Realistic Real-time
Responsive Rebalance animation in Walking (4RW) that are
natural and can response to unexpected external perturbations, because of the difficulty of categorizing human strategies to rebalance and describing such strategies procedurally
[HR99,Hof07,QN09,YL10a]. To address this challenge, we
propose a novel technique called L4RW (Laziness-based
4RW) to automatically produce 4RW, inspired by the laziness law (‘minimum variance model’ or ‘the principle of
least effort’) in neuroscience and biology that human beings tend to follow their inherent characteristics of "laziness" to minimize the effort spent during their motions
[Zip72, FH85, UKS89, Kaw99].
To generate realistic motion, it is important to build an appropriate rebalance model for computer simulation for us to
tackle the challenge of animation techniques. Therefore, we
propose a Lazy Dynamic Rebalance Model, which com-

2188

Xu et al. / L4RW: Laziness-based Realistic Real-time Responsive Rebalance in Walking

here lies in selecting the rebalance effort, the ‘extrapolated
center of mass’ (XCoM) and environment constraints as feature attributes to make the input feature vector for the SVM
effective, yet minimal. (3) To avoid an exhaustive search, the
subset’s motion segments are first sorted by their rebalance
effort, followed by a search for an accepted motion segment
starting from the lest-effort segment. Moreover, the motion
variance in the unit rebalance effort is used to accurately
measure the pose difference between the simulated motion
and the mocap segment.

2. Related Work
Figure 1: Overview of L4RW pipeline.

bines the latest biomechanics results and the laziness law
to automatically select the most suitable rebalance strategy,
in the most lifelike way, after arbitrary unexpected perturbations. The model can be applied into any motion generation techniques, including the data-driven approaches, the
physics-based control methods, and a combination of these
two. In this paper, the motion is generated using a mix of
the dynamic and the kinematic methods, extended from the
dynamic response technique of Zordan et al. [ZMCF05].
Figure 1 shows an overview of L4RW pipeline: initialized from the walking mocap segment (the black curve), the
character’s momentum will be updated when it recognizes
the external perturbation. If the character is out of balance
after the perturbation, a ragdoll-like forward simulation is
performed to simulate the falling (passive simulation) and
simultaneously begin to search for an appropriate mocap
segment for the character to follow the perturbation. Once
a suitable motion segment (the blue curve) is selected from
the motion database, an active response (active simulation)
is generated using the selected segment as its desired state.
Finally, the transition-to motions (the red curve) is generated by interpolating the active response motion so that it
matches the desired state at the end of the generated segment. However, in Zordan’s original algorithm, finding the
desired mocap segment consumed about 70% computation
time [ZMCF05] and made the technique a stumbling block
for real time applications such as games. To address this issue, the laziness law is cleverly exploited in the pipeline to
speed up the search without sacrificing motion quality.
The contributions of our work are as follows: (1) the lazy
dynamic rebalance model is simpler, more efficient, and accurate. The model specifies the dynamic balance conditions,
defines the rebalance effort, and selects the suitable rebalance strategy automatically using the laziness law. (2) A support vector machine (SVM) based training, classification,
and predication algorithm is applied to reduce the search
space, and it is trained offline only once. The main novelty

Physics-based controllers for rebalance fall into
three categories [YL10b, PP10]: manual design
[YLvdP07, SCCH09, dLMH10, YL10a], optimization
for robust behaviours [YCBvdP08, CBYvdP08, WFH09,
CBvdP09, WFH10, WZ10b, WZ10a], and a combination
of these two categories for a wider range of dynamic
responses [dSDP09, CBvdP09, JYL09, SBvdP10, MdLH10].
The cumbersome tuning of numerous parameters, complex optimization procedure, and reduced motion quality
as the trade-off for robust balance control are the main
drawbacks of these controllers [YL10b, TLC∗ 10]. Moreover, designing controllers for lifelike 4RW animations
is still a challenge. Great effort has been made to address other issues, including developing controllers
to create transitions between motion poses [PZ05]
or sequences [ZMCF05, MLPP09, KH10, YL10b]
or reproducing an entire sequence under perturbations [YCP03, SKL07, dSAP08, YL08, MZS09]. However,
the resulting synthesized motions are restricted to those similar to the input mocap data, and greatly limit the range of
permissible perturbations [YL10b]. Up to now, the so-called
ragdoll effects are still the current benchmark for real-time
reactive animation characters [ZMM∗ 07]. Conversely, as
observed with 4RW animation, dynamics is usually only
needed for a short time, during which the disturbance
changes the character’s momentum. After that, the utility of
the dynamics decreases and its simulated motions become
less reliable than the mocap segment [ZMCF05]. Thus,
L4RW prefers to switch the dynamics simulation back to
mocap sequence as soon as possible after the disturbance.
Blending or concatenating mocap sequences directly is an
alternative way to synthesize rebalance animation [PP10].
For example, Yin et al. [YPvdP05] synthesized motions responding to pushes on the character’s waist in real time.
Arikan et al. [AFO05] tried to handle more challenging
situations such as in walking, but this method needs considerable manual processing and a large number of mocap
data. More recently, Ye et al. [YL10a] introduced different
technique which involves learning a nonlinear probabilistic
model to synthesize responses and recovery motions for a
walking character under perturbations. However, the learning process is too complicated to be suitable to large diverse
c 2010 The Author(s)
⃝
c 2010 The Eurographics Association and Blackwell Publishing Ltd.
Journal compilation ⃝

Xu et al. / L4RW: Laziness-based Realistic Real-time Responsive Rebalance in Walking

2189

data sets. Subsequently, L4RW presents a straightforward
simple method for 4RW animation and can deal with large
data sets.
Techniques combining data-driven techniques with controller-based simulation are promising. Zordan et al.
[ZMCF05] introduced a technique for incorporating unexpected impacts into a motion capture-driven animation system through the combination of a physical simulation and
a mocap data search routine. Zordan et al. [ZMM∗ 07] employed a pre-trained SVM to speed up the search for the
transition-to mocap segment. Built on their excellent research, we improved their model to reflect human beings’
natural rebalance characteristics and to support more environment constraints.
Recent advancement in biomechanics forms the theoretical foundation for L4RW. The dynamic stability conditions which takes into account the velocity of the body’s
Center of Mass (CoM) have been used to detect imbalance in walking [HGS05,Hof07,AKM08,Hof08,QN09]. As
pointed out in many previous literatures [HR99, SHGB99,
BK00, Hof07, WJJP07, Hof08, QN09], the arm-hip, grasping
and stepping are among the most effective rebalance strategies in walking. L4RW has implemented all these responsive actions. However, due to the complicated decision process for human beings to select a suitable rebalance strategy responding to unexpected external pushes, there is no
computational model to describe the process procedurally
[HR99,Hof07,QN09,YL10a]. Our L4RW combines the laziness law to enable virtual characters automatically select a
suitable rebalance strategy in the lifelike way after unexpected perturbations.
3. Lazy Dynamic Rebalance Model
3.1. Dynamic Imbalance Detection
Our approach for the character’s dynamic imbalance detection in walking is based on a simplified inverted pendulum
model, as shown Figure 2. The body is modelled as a single
mass m balancing on top of a stick with length l. The Center
of Pressure (CoP) u is the location of the effective ground
reaction force, and x is the vertical projection of the Center
of Mass (CoM). The Base of Support (BoS) is the area to
which the CoP is confined.
The walking balance differs from standing balance, in that
the CoM constantly moves beyond the base of support and
the support leg can do little to alter this motion [BK00]. The
rebalance condition for the standing stability is that the vertical projection of the CoM should be within the BoS. However, this condition is insufficient in dynamic situations. The
velocity of the CoM should also be accounted for: even if
the CoM is above the BoS, balance may be impossible if
the velocity of CoM is directed outward. The reverse is also
possible: even if the CoM is outside the BoS, but its velocity
directed towards it, balance can be achieved [HGS05].
c 2010 The Author(s)
⃝
c 2010 The Eurographics Association and Blackwell Publishing Ltd.
Journal compilation ⃝

Figure 2: Simplified inverted pendulum model.

Recently, a concept of ‘extrapolated center of mass’
(XCoM) [HGS05, Hof08, QN09] was introduced in biomechanics besides CoM and CoP to formulate a dynamic stability condition which is also valid for static situations. When
the projection of the CoM position on the ground is denoted
as x and CoM velocity as vx , XCoM position ξ is defined as:
ξ = x+

vx
w0

(1)

√
where w0 = gl is the eigenfrequency of the inverted
pendulum. It has been shown that the relative of CoP and
XCoM can predict balance for the character in walking. In
the case: CoM < XCoM < CoP < BoS, no action is needed.
In the case: CoM < CoP < XCoM < BoS, the CoM will
pass the CoP after some time, and will then accelerate forward. An action is then needed to bring the CoP forward
to a position in front of the XCoM. Finally, in the case:
CoM < CoP < BoS < XCoM, the CoM will pass forward of
the BoS, so possible actions to prevent a fall are also needed.
3.2. Rebalance Effort
The disturbance leading to imbalance can be expressed as
momentum change of the character. The changes of linear
and angular momentum about the CoM control the trajectories of the character’s CoM and CoP respectively. The linear and angular momentum of motion state p are denoted as
L(p) and H(p) [YPvdP05]:
L(p) = ∑ L(pi ) = ∑ mi vi = mv

(2)

H(p) = ∑ li wi + ∑ cci × L(pi )

(3)

where m is the total mass, c is the location of the CoM,
v is the velocity of the CoM, cci is the vector pointing from
c to ci . li and wi represent the moment of inertia and the

2190

Xu et al. / L4RW: Laziness-based Realistic Real-time Responsive Rebalance in Walking

angular velocity of the ith segment respectively. Therefore,
the disturbance can be described as:
∆ϕ(p′ , p) =

[

∆L(p′ , p)
∆H(p′ , p)

]

[
=

L(p′ ) − L(p)
H(p′ ) − H(p)

]
(4)

where ∆L(p′ , p) and ∆H(p′ , p) are the changes of linear
and angular momentum respectively, p and p′ are the motion states before and after the disturbance. Similarly, the
effort for transforming motion from p to p′ can be written as
∆E(p′ , p). Furthermore, the rate of change of linear and angular momentum can be calculated as following [YPvdP05]:
fGRF + f + mg = L˙

(5)

cs × f + cp × fGRF + (0, y, 0)T = H˙

(6)

where the external force f applies at point s, and cs is the
vector pointing from the CoM c to s. Resultant GRF fGRF
applies at the CoP p, and y is the resultant moment around
the vertical axis exerted by fGRF . In human walking, the angular momentum of the body about its CoM is typically very
small [HP08]. For modelling the perturbation as impacts, we
assume that the fGRF is constant as the impacts lasts for only
a short interval, thus having no effect about the horizontal
axes for ∆L(p′ , p) and ∆H(p′ , p). As a result, the approximation for ∆L(p′ , p) and ∆H(p′ , p) can be simplified as following:
∆L ∼
=f

(7)

∆H ∼
= cs × f

(8)

We used Equation 4 to calculate the disturbance absorbed
by a specific captured rebalance mocap segment, and then
used Equation 7-8 to estimate the intensity of the force exerted to the character.
We use M = {Ci |Ci = ⟨pi.1 , pi.2 , ..., pi.n ⟩, 1 ≤ i ≤ N} to
represent the rebalance mocap database, where Ci denotes
a mocap segment, and ⟨pi.1 , pi.2 , ..., pi.n ⟩ represents the motion states sequence of the ith segment. By using a segment
Ci ∈ M, all the possible motion sequences for any motion
state pγ to regain balance can be defined as ψ(pγ ,Ci ) =
{T = ⟨pγ , pi.m , pi.m+1 , ..., pi.n ⟩, 1 ≤ m ≤ n − 1}. According
to the momentum conservation principle, how to eliminate
the momentum changes induced by the perturbation is the
key of balance recovery. Thus, the rebalance effort from pγ
to the following selected mocap sequence T ∈ ψ(pχ ,Ci ) was
defined as the maximal momentum changes of the motion
transforms in T :

E(pχ ,Ci , T ) =

max

{∆ϕ(pi.c , pχ )}

pi.c ∈T,T ∈ψ(pχ ,Ci )

(9)

3.3. Lazy Rebalance
Following the initiation of an impending fall after an external
disturbance in walking, various effective responsive strategies can be employed for balance recovery. Based on the fundamental characteristics of biomechanics system, all these
strategies can be roughly classified into three categories
[BK00, HGS05, Hof07, QN09]: (1) by increasing the base of
support, such as stepping strategy [HR99, WJJP07, Hof08],
(2) by counter-rotating segments around the CoM, such as
arm-hip [SHGB99, YPvdP05, Hof07, QN09], and (3) by applying an external force, other than the ground reaction
force, such as grasping [SHGB99, Hof07, QN09]. Notably,
grasping strategy is constrained by graspable fixtures when
a fall occurs and is a human beings’ first choice under similar
conditions [Hof07, AKM08, QN09].
Although each rebalance strategy has its own strengths
and weaknesses, their anti-disturbance capacity can be ordered as follows, from weak to strong: (1) arm-hip strategy; (2) grasping strategy and (3) stepping strategy. To simplify the strategy selection process, only one was used to
response to the disturbance. This simplification was equivalent to classifying a motion according to the availability of
the strongest balance strategy [YPvdP05]. As pointed out in
neuroscience and biology, it is natural and intuitive for human beings to choose strategies following the laziness law
[FH85, UKS89, Kaw99]. As such, only the strategy which
spends the minimal rebalance effort to remove the external
disturbance will be chosen for balance recovery. Without
considering the environment constraints such as graspable
fixtures, the best rebalance motion segment Cselect in the mocap database M to select is:

Cselect =

arg min

(E(pχ ,Ci , T ))

(10)

Ci ∈M,T ∈ψ(pχ ,Ci )

To get a more realistic segment, the environment constraints such as graspable fixtures, the pose differences between simulated motions and mocap motions are also worth
to be considered.

4. Strategy Prediction
SVM is employed to select an appropriate rebalance strategy under the laziness law and to reduce the search space.
SVM first took a set of training data to create a model which
contains attribute information to classify the mocap database
into a few subsets (offline and only once), in which all the
segments belong to the same strategy type, under similar environment constraints and also share other intrinsic traits.
Subsequently, in accordance to the character’s current motion feature attributes, SVM is used to predict, in real time,
the specific strategy to adopt, selected from a subset of the
database. Our SVM uses a polynomial kernel function:
c 2010 The Author(s)
⃝
c 2010 The Eurographics Association and Blackwell Publishing Ltd.
Journal compilation ⃝

Xu et al. / L4RW: Laziness-based Realistic Real-time Responsive Rebalance in Walking

K(xi , x j ) = (γxiT x j + t)d , γ > 0

(11)

where γ, t, d are user-defined kernel parameters.
The selection of feature attributes is the crucial key to
apply SVM, because increasing the size of the feature vector requires more training examples. The feature vector also
cannot be too small, otherwise, we will not be able to differentiate certain rebalance strategies. Our SVM classification
is unique, as the feature vector only contains 8 key attributes,
compared to the 20 attributes used in [ZMM∗ 07], without
losing the realism. These attributes include rebalance effort,
XCoM, the position of graspable fixtures, the state of the feet
and hands, the position and the velocity of the CoM. The
main novelty of our work is introducing the rebalance effort,
the nature to reflect the laziness law, as a feature attribute.
Furthermore, the XCoM reflects the dynamic stability of the
character; the position of graspable fixtures helps the character adapt to complex environment; the state of the feet indicates the walking state and is sensitive to ground support;
and the state of the hands is sensitive to grasp the fixtures.
Finally, in order to keep the size of the predicted subset small and the prediction accuracy high, samples of the
same strategy are labelled and classified into three categories (small, medium, and large) according to the magnitude of the exerted forces, expanding upon the single level
in [ZMM∗ 07]. In each of the three categories, six types of
rebalance strategies (arm-hip, grasping, and forward, backward, left-sideward, right-sideward stepping) were classified. As a result, our database was classified into 18 subsets.
The search space is roughly reduced to 1/20 of its primary
size.

2191

difference and R(Ws ,Wc ) is the rebalance effort between Ws
and Wc . The size of the window equals the time of a typical
transition. Accordingly, we can formulate the search problem as selecting the frame window pair {Ws ,Wc } that best
matches the simulated motion and the reaction mocap segment with the minimal pose difference in the unit of rebalance effort:
{Ws ,Wc }select = arg min (Ω(Ws ,Wc ))
Wc ∈Ci ,Ci ∈M

(13)

The pose difference D(Ws ,Wc ) equivalent to Zordan’s
[ZMCF05] "motion distance" function between Ws and Wc ,
the weighted sum of the distances between the positions and
orientations of matching body parts of each frame pair. The
highlighted R(Ws ,Wc ) is described as:
R(Ws ,Wc ) = min {E(ps.t ,Ci , T )}
1≤t≤ws

(14)

The larger the Ω(Ws ,Wc ), the worse the match between
Ws and Wc . We sorted the subset by the value of R(Ws ,Wc )
instead of exhaustively searching over the whole prediction
subset for the best match with Ω(Ws ,Wc ). We then searched
for a suitable match starting from the segment with the
smallest R(Ws ,Wc ) value in the sorted subset. Once a match
is found, the search is terminated. The reason that we did
not look for the best match and the surprising speedup result
because of this will be presented in Section 6.2.
6. Implementation and Results
6.1. Experimental Setup

(12)

The skeleton model used in the experiments is from our mocap database with 43 degrees of freedom (DOF) in total.
The motion capture subject within the database is 178 cm
in height with a total mass of 74.3kg. The moment of inertia parameters are estimated by approximating each limb of
the subject using a cylinder of matching size and the mass of
each segment is calculated by estimating a uniform density
to match the total mass of the skeleton model of the subject. To construct our database, we captured 72 sessions of
balancing motions in walking, each between 40 to 120 seconds in duration, at 60HZ, using an Eva Real-Time (EVaRT)
motion capture system. We hand-segmented the resulting
data into distinct segments, which were also passed through
a series of automatic post-processing stages such as footground contacts. Finally, we exploited symmetry to increase
the number of motions in our database. As a result of this,
around 1900 motion segments composed our database.

where Ws = ⟨ps.1 , ps.2 , ..., ps.ws ⟩ represents a window of
the simulated motion sequence containing ws frames, and
Wc = ⟨pc.1 , pc.2 , ..., pc.ws ⟩ represents that of the mocap sequence in a mocap segment Ci ∈ M. D(Ws ,Wc ) is the pose

The controller of the active response uses an inertia-scaled
PD-servo at each joint [ZH02]. The Open Dynamic Engine
(ODE) is used for dynamic simulation and general collision generation, with the exception that we developed a custom collision handler for the foot/ground contact. Our model

5. Lazy Search
Once the desired mocap subset is predicted by the SVM, the
laziness law is performed to find a suitable motion segment
as a reference for the subsequent response and blending. According to the laziness law, the rebalance effort determines
the best match mocap segment for the simulated motions.
We also take into account motion variance between the simulated and the captured motions due to the small numbers of
motion features in the prediction phase. The difference between the simulated motion sequence and the selected mocap segment as the pose difference in the unit of rebalance
effort within a frame window, denoted as:

Ω(Ws ,Wc ) =

D(Ws ,Wc )
R(Ws ,Wc )

c 2010 The Author(s)
⃝
c 2010 The Eurographics Association and Blackwell Publishing Ltd.
Journal compilation ⃝

2192

Xu et al. / L4RW: Laziness-based Realistic Real-time Responsive Rebalance in Walking

uses a penalty method with Coulomb friction plus additional friction derived from rotation to impede free spinning
movement between the foot and the ground [ZMCF05]. The
ground friction in the passive simulation was set to 1.0 (a
rough surface), but was reduced to 0.6 for the active simulation. The time slice assigned for each turn of the rendering
thread and calculation thread were set to 30 ms and 0.5ms
respectively. We employed the library LibSVM [CL01] to
implement the SVM. We labelled the segments and classified the segments into 18 subsets by hand. Afterwards, we
trained the SVM offline using the selected feature attributes
as the input vector. The subset types and the feature attributes
are described in Section 4.
A polar coordinate plot GUI is used to allow the users applied pushes interactively by selecting the desired direction
and magnitude. We computed the direction and magnitude
by "throwing" a heavy ball at the normal walking character
while varying its angle, speed and starting height.

(a) normal walking

(b) arm-hip strategy

6.2. L4RW Results
We synthesized a normal walking character to respond to
unexpected impulse under various conditions (Figure 3). We
also compared the normal walking with arm-hip, grasp-ing,
and forward/backward/right-sideward stepping (Figure 3).
The results demonstrate that L4RW is able to find an appropriate balancing motion to get realistic active response
for balance recovery and achieve 30 fps without visual artefacts. Further test cases are available in the accompanying
video.
6.3. Evaluation and Analysis

(c) grasping

(d) forward stepping

We compared our L4RW and both of Zordan’s methods (presented in [ZMCF05] and [ZMM∗ 07]). The evaluation metrics include time cost, accuracy, motion quality, and robustness.
We initially trained the SVM using 700 training samples. The prediction accuracy when using various feature
attributes were tested 5 cases: (1) our feature vector described in Section 4, (2) removing the rebalance effort attribute from our feature vector, (3) adding all the motion
states into our feature, (4) the feature vector proposed by
Zordan [ZMM∗ 07] and (5) adding all the motion states into
Zordan’s feature vector. The test results are illustrated in Figure 4(a)-(b). Results showed that our L4RW could accurately
predict the grasping strategy at nearly 100% (Case 3), taking
into account the environmental constraints, such as the position of fixtures, and the motion state of hands. The accuracy was 91.4% (Case 1) and 74.4% (Case 4) for our feature
vector and Zordan’s testing for new examples, respectively.
Training time using Zorand’s feature vector was doubled
compared to ours when more attributes were added. L4RW
could increase the accuracy to 97.5% but will approximately
experience a 3x time hit for classification, whilst Zordan’s

(e) backward stepping

(f) right-sideward stepping

Figure 3: Balance behaviours under perturbations of different directions and magnitudes.

c 2010 The Author(s)
⃝
c 2010 The Eurographics Association and Blackwell Publishing Ltd.
Journal compilation ⃝

2193

Xu et al. / L4RW: Laziness-based Realistic Real-time Responsive Rebalance in Walking

raises to 80.7% with approximately a 2x time hit for classification. Surprisingly, if we removed the rebalance effort attribute from our feature vector the accuracy would drop significantly (Case 2). This fact proves the validity of the laziness law in balance recovery. The accuracy of exerting force
on different body parts is shown in Figure 4(c), with high
accuracies for the push on breast, arms, and back. Lower accuracies are observed on the hip and shoulder. For different
rebalance strategies, as shown in Figure 4(d), the SVM was
almost 100% accurate in identifying the stepping and grasping strategies, however, the arm-hip strategy was predicted
with lower accuracy. Thus, we reconducted these same experiments on a larger training set with 1100 data examples
containing more examples which have previously lower accuracy and found an overall accuracy of 95.8%.

Figure 4: (a) prediction accuracy for different feature vectors; (b) training time for different feature vectors; (c) prediction accuracy for different contact body parts; (d) prediction accuracy for different strategies.
Our prediction after training using SVM classification can
be executed in real time (1-2 msec). The run-time search
within several thousands of frames for an appropriate mocap
segment in the selected subset was the most time-consuming
part, despite the search space in the predicted subset was approximately 1/20 of its primary size. To reduce the search
time, the laziness law was applied and the result is showed
in Table 1. In aggregation, we see that the laziness law based
improvements exhibited an approximately 20x speed-up on
average in comparison to [ZMCF05] and 10x in comparison
to [ZMM∗ 07] (which also used the SVM for prediction).
Figure 5(a) shows that the search time of L4RW considerably outperformed that of Zordan’s and L4RW (without
the laziness-based search) when the size of search space increases. Figure 5(b) shows that the hit percentage of the suitable mocap segment could reach 97% while computing the
lower rank of 20% segments in the sorted subset, the hit percentage rieses to 99% while computing the lower 30%. Noticeably, the best hit within the lower 20% segments is about
81%. These results revealed that the rebalance effort accurately reflects the nature of the laziness law in human balc 2010 The Author(s)
⃝
c 2010 The Eurographics Association and Blackwell Publishing Ltd.
Journal compilation ⃝

ance recovery. However, in practice, to minimize the search
time and find a suitable balancing motion segment, computing within the lower 20% of the sorted subset is a good compromise between the computed percentage of the sorted subset and the hit accuracy.
Table 1: Average search time (seconds) in different subsets.

❵❵❵
❵❵Method
Strategy
❵❵

Zordan

Zordan

L4RW

+SVM

-Sorting

L4RW

Arm-hip

1.63

0.39

0.18

0.04

Grasping

–

–

0.15

0.03

Forward Stepping

1.78

0.43

0.19

0.04

Backward Stepping

1.85

0.44

0.19

0.04

Left-side Stepping

1.76

0.38

0.18

0.04

Right-side Stepping

1.77

0.36

0.17

0.04

Figure 5: (a) search time for the size of subset (thousands
frames); (b) hit /best hit percentage for the computing percentage of the sorted subset.

Figure 6: Motion variance trends of unit rebalance effort.

Figure 7: Results of the user study.

2194

Xu et al. / L4RW: Laziness-based Realistic Real-time Responsive Rebalance in Walking

For improving motion quality, we think it is more important to reduce the search time than to increase the accuracy of SVM or find the best match mocap segment. As
showed in Figure 6, the longer the simulation, the larger the
Ω(W s,W c). In other words, a sharp transition will happen
after a long simulation even if we find a best match. Therefore, we tend to transfer from the active simulation to the
mocap segment as soon as possible. As our series of search
speed-ups results in L4RW experiencing a boost of two orders of magnitude in comparison to [ZMCF05], we have reason to believe that, the motions generated using L4RW can
be realistic, which was confirmed by our experimental studies (Figure 7).
Our study group consisted of 20 computer science undergraduate students, without any background on our research
or motion synthesis technology. The students were requested
to watch the interactive balancing animation generated by
L4RW and to give scores between 1 and 5 in response to the
question: Did the animation videos look realistic? In Figure 7, 11 students graded 4 points and 6 students graded 5
points with the average score of 4.1. The result indicated
that L4RW was more realistic. Four students noticed some
tiny visual artifacts in the final motions, which were due to
inaccuracies in marker trajectories when the mocap actor endured a large push.
More subtly but no less importantly, instead of only considering the friction to maintain the naturalness, we found
the initial walking velocity and the ground friction to be
both sensitive parameters [ZMCF05]. If the initial walking
velocity was 1.2m/s - 1.5m/s and the friction was 1.0, the result is natural However, when the walking velocity exceeded
1.6m/s (a brisk walking style), the friction needed to be increased to more than 1.1 under the same environment so as
to eliminate any visual motions artefacts. The findings suggested that increasing the initial walking velocity may decrease the character’s dynamic stability because XCoM is
partly determined by the velocity [HGS05, Hof08, QN09].
Moreover, we also found that for realistic balancing motions,
forward walking speed should not increase or fluctuate too
much and the step length cannot be too large. Otherwise,
the generated motion would jitter too much. Empirically, the
velocity variety should be controlled within 20% of the reference velocity.
We also found that L4RW could synthesize rebalance motions responding to multiple pushes in a short period time
separately under some cases despite our mocap database
only contained rebalance behaviors for the single push. We
attributed this to the real time search for the suitable balancing motion segment. However, some motions had poor
quality when the exerted external force was very large. This
was mainly due to the lack of corresponding mocap data, as
reactions to strong contact strikes were omitted during the
time of capture to avoid any injury to the subject.

7. Discussion and Conclusion
We have presented a simple yet more efficient and effective
approach to synthesize walking motions under unexpected
perturbations, making use of the laziness law. A series of
experiments were conducted to test time, accuracy, motion
quality, and robustness of our approach. We have found that
our approach can generate more realistic and smoother motions compared to the state-of-the-art, with a speed up of
well over two orders of magnitude. Our method might be
much more suitable for real time applications such as games.
Major results from this work include the following. First,
we believe that the rebalance strategies employed by L4RW
are best suited for 4R animation in walking with various external unexpected disturbances such as pushes from
light to strong. However, other techniques might be better
for small disturbances [YCP03, ZH02, KGP02] or in stance
[YPvdP05]. Next, the accuracy of our SVM prediction is
much higher and the search time is significantly reduced after sorting the predicted subset by the rebalance effort so as
to find a suitable balancing motion quickly. These speed-ups
are the key to synthesize the pleasing final motions. Finally,
some other unique features of the system are also worthy
of attention: (1) L4RW takes into account the environment
constraints such as graspable fixings, in the feature vector of
the SVM to achieve the grasping strategy, which is always
overlooked by other techniques. (2) The XCoM for the dynamic rebalance condition is applied for more reliable imbalance detection and as an attribute of the feature vector.
(3) The motion variance in the unit rebalance effort is used
to accurately evaluate the differences between the simulated
motions and the mocap motions.
We have realized some other future directions using our
L4RW approach. For example, the use of the protective motions in anticipation of an impending disturbance can further
improve the realism. L4RW can also be used for large external disturbance when the corresponding mocap data and
the mocap segment are available. Similarly, artifacts caused
by insufficient data in our database can also be resolved by
using the safety harness equipment in the biomechanics experiments [CS09]. In addition, to allow L4RW to support
the rebalance following multiple contact pushes in series, a
secondary search (or more) can be carried out to find a good
transition-to mocap segment. We are also interested in studying responses to pushes during running, jumping and dancing, based on the laziness law. Finally, besides the laziness
law, we believe there are many other factors that influence
the perception of motion and understanding these factors is
important to generate more lifelike animation.

8. Acknowledgments
We appreciate the anonymous reviewers for their insightful
comments. We thank James Hofer and other motion capture
subjects, and all the students who help post-process the data.
c 2010 The Author(s)
⃝
c 2010 The Eurographics Association and Blackwell Publishing Ltd.
Journal compilation ⃝

Xu et al. / L4RW: Laziness-based Realistic Real-time Responsive Rebalance in Walking

We thank Jian Chen and El Rhalibi Abdennour for their generous help on revising the paper, and Stelian Coros et al. for
their publicly available SIMBICON controller editor framework. This work was supported by the National High Technology Research and Development Program of China (863
Program No. 2009AA062704).

References
[AFO05] A RIKAN O., F ORSYTH D., O’ BRIEN J. F.: Pushing
people around. In ACM SIGGRAPH/Eurographics symposium
on Computer animation (2005). 2

2195

[JYL09] JAIN S., Y E Y., L IU C. K.: Optimization-based interactive motion synthesis. ACM Trans. Graph. 28, 1 (2009), 1–12.
2
[Kaw99] K AWATO M.: Internal models for motor control and trajectory planning. Current opinion in neurobiology 9, 6 (1999),
718–727. 1, 4
[KGP02] KOVAR L., G LEICHER M., P IGHIN F.: Motion graphs.
ACM Trans. Graph. 21, 3 (2002), 473–482. 8
[KH10] K WON T., H ODGINS J.: Control systems for human running using an inverted pendulum model and a reference motion
capture sequence. In ACM SIGGRAPH/Eurographics symposium
on Computer animation (2010). 1, 2
[LKL10] L EE Y., K IM S., L EE J.: Data-driven biped control. In
SIGGRAPH (2010). 1

[AKM08] A RAMPATZIS A., K ARAMANIDIS K., M ADEMLI L.:
Deficits in the way to achieve balance related to mechanisms of
dynamic stability control in the elderly. Journal of biomechanics
41, 8 (2008), 1754–1761. 3, 4

[MdLH10] M ORDATCH I., DE L ASA M., H ERTZMANN A.: Robust physics-based locomotion using low-dimensional planning.
In SIGGRAPH (2010). 1, 2

[BK00] BAUBY C., KUO A.: Active control of lateral balance
in human walking. Journal of biomechanics 33, 11 (2000), 1433–
1440. 3, 4

[MLPP09] M UICO U., L EE Y., P OPOVIC J., P OPOVIC Z.:
Contact-aware nonlinear control of dynamic characters. ACM
Trans. Graph. 28, 3 (2009), 1–9. 2

[CBvdP09] C OROS S., BEAUDOIN P., VAN DE PANNE M.: Robust task-based control policies for physics-based characters. In
SIGGRAPH Asia (2009). 2

[MZS09] M ACCHIETTO A., Z ORDAN V., S HELTON C. R.: Momentum control for balance. ACM Trans. Graph. 28, 3 (2009),
1–8. 2

[CBYvdP08] C OROS S., B EAUDOIN P., Y IN K., VAN DE PANNE
M.: Synthesis of constrained walking skills. ACM Trans. Graph.
27, 5 (2008), 1–9. 2

[PP10] P EJSA T., PANDZIC I. S.: State of the art in examplebased motion synthesis for virtual characters in interactive applications. Computer Graphics Forum 29, 1 (2010), 202–226. 2

[CL01] C HUNG C.-C., L IN C.-J.: LIBSVM: a library for support
vector machines, 2001. 6

[PZ05] P OLLARD N. S., Z ORDAN V. B.: Physically based grasping control from example. In ACM SIGGRAPH/Eurographics
symposium on Computer animation (2005), pp. 311–318. 2

[CS09] C YR M.-A., S MEESTERS C.: Maximum allowable force
on a safety harness cable to discriminate a successful from a
failed balance recovery. Journal of biomechanics 42, 10 (2009),
1566–1569. 8
[dLMH10] DE L ASA M., M ORDATCH I., H ERTZMANN A.:
Feature-based locomotion controllers. In SIGGRAPH (2010). 1,
2
[dSAP08] DA S ILVA M., A BE Y., P OPOVIC J.: Interactive simulation of stylized human locomotion. In SIGGRAPH (2008).
2
[dSDP09] DA S ILVA M., D URAND F., P OPOVIC J.: Linear bellman combination for control of character animation. ACM Trans.
Graph. 28, 3 (2009), 1–10. 2
[FH85] F LASH T., H OGAN H.: The coordination of arm movements: an experimentally confirmed mathematical model. Journal of neuroscience 5, 7 (1985), 1688–1703. 1, 4
[HGS05] H OF A. L., G AZENDAM M. G. J., S INKE W. E.: The
condition for dynamic stability. Journal of neuroscience 38, 1
(2005), 1–8. 3, 4, 8
[Hof07] H OF A. L.: The equations of motion for a standing human reveal three mechanisms for balance. Journal of biomechanics 40, 2 (2007), 451–457. 1, 3, 4
[Hof08] H OF A. L.: The ’extrapolated center of mass’ concept
suggests a simple control of balance in walking. Human movement science 27, 1 (2008), 112–125. 3, 4, 8
[HP08] H ERR H., P OPOVIC M.: Angular momentum in human
walking. The Journal of Experimental Biology 211, 4 (2008),
467–481. 4
[HR99] H SIAO E. T., ROBINOVITCH S. N.: Biomechanical influences on balance recovery by stepping. Journal of biomechanics.
32, 10 (1999), 1099–1106. 1, 3, 4
c 2010 The Author(s)
⃝
c 2010 The Eurographics Association and Blackwell Publishing Ltd.
Journal compilation ⃝

[QN09] Q U X., N USSBAUM M. A.: Evaluation of the roles of
passive and active control of balance using a balance control
model. Journal of biomechanics 42, 12 (2009), 1850–1855. 1, 3,
4, 8
[SBvdP10] S TELIAN C., B EAUDOIN P., VAN DE PANNE M.:
Generalized biped walking control. In SIGGRAPH (2010). 1,
2
[SCCH09] S HIRATORI T., C OLEY B., C HAM R., H ODGINS J.:
Simulating balance recovery responses to trips based on biomechanical principles. In In ACM SIGGRAPH/Eurographics symposium on Computer animation (2009). 2
[SHGB99] S ABICK M. B., H AY J. G., G OEL V. K., BANKS
S. A.: Active responses decrease impact forces at the hip and
shoulder in falls to the side. Journal of biomechanics 32, 9
(1999), 993–998. 3, 4
[SKL07] S OK K. W., K IM M., L EE J.: Simulating biped behaviors from human motion data. In SIGGRAPH (2007). 2
[SYLH10] S OK K. W., YAMANE K., L EE J., H ODGINS J.: Editing dynamic human motions via momentum and force. In ACM
SIGGRAPH/Eurographics symposium on Computer animation
(2010). 1
[TLC∗ 10] T SAI Y., L IN W., C HENG K., L EE J., L EE T.: Realtime physics-based 3d biped character animation using an inverted pendulum model. IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS 16, 2 (2010), 325–337.
1, 2
[UKS89] U NO Y., K AWATO M., S UZUKI R.: Formation and control of optimal trajectory in human multijoint arm movement. Biological cybernetics 61, 2 (1989), 89–101. 1, 4
[WFH09] WANG J. M., F LEET D. J., H ERTZMANN A.: Optimizing walking controllers. In SIGGRAPH Asia (2009). 2

2196

Xu et al. / L4RW: Laziness-based Realistic Real-time Responsive Rebalance in Walking

[WFH10] WANG J. M., F LEET D. J., H ERTZMANN A.: Optimizing walking controllers for uncertain inputs and environments.
ACM Trans. Graph. 29, 3 (2010), 1–8. 1, 2
[WJJP07] W U M., J I L., J IN D., PAI Y.: Minimal step length
necessary for recovery of forward balance loss with a single step.
Journal of biomechanics 40, 7 (2007), 1559–1566. 3, 4
[WZ10a] W U J.-C., Z ORAN P.: Goal-directed stepping with momentum control. In ACM SIGGRAPH/Eurographics symposium
on Computer animation (2010) (2010). 1, 2
[WZ10b] W U J.-C., Z ORAN P.: Terrain-adaptive bipedal locomotion control. In SIGGRAPH (2010). 1, 2
[YCBvdP08] Y IN K., C OROS S., B EAUDOIN P., VAN DE PANNE
M.: Continuation methods for adapting simulated skills. In SIGGRAPH (2008). 2
[YCP03] Y IN K., C LINE M. B., PAI D. K.: Motion perturbation
based on simple neuromotor control models. In Pacific Graphics
(2003). 2, 8
[YL08] Y E Y., L IU C. K.: Animating responsive characters with
dynamic constraints in near-unactuated coordinates. In SIGGRAPH Aisa (2008). 2
[YL10a] Y E Y., L IU C. K.: Optimal feedback control for character animation using an abstract model. In SIGGRAPH (2010). 1,
2, 3
[YL10b] Y E Y., L IU C. K.: Synthesis of responsive motion using
a dynamic model. Computer Graphics Forum 29, 2 (2010), 1–8.
(Proc. Eurographics’10). 1, 2
[YLvdP07] Y IN K., L OKEN K., VAN DE PANNE M.: Simbicon:
simple biped locomotion control. In SIGGRAPH (2007). 2
[YPvdP05] Y IN K., PAI D. K., VAN DE PANNE . M.: Data-driven
interactive balancing behaviors. In Pacific Graphics (2005). 2, 3,
4, 8
[ZH02] Z ORDAN V. B., H ODGINS J. K.: Motion capture-driven
simulations that hit and react. In ACM SIGGRAPH/Eurographics
symposium on Computer animation (2002), pp. 89–96. 5, 8
[Zip72] Z IPF G.: Human behavior and the principle of least effort. Hafner, 1972. 1
[ZMCF05] Z ORDAN V. B., M AJKOWSKA A., C HIU B., FAST
M.: Dynamic response for motion capture animation. In SIGGRAPH (2005), pp. 697–701. 2, 3, 5, 6, 7, 8
[ZMM∗ 07] Z ORDAN V. B., M AJKOWSKA A., M EDINA J., S O RIANO M., W U C.-C.: Interactive dynamic response for games.
In Proceedings of the 2007 ACM SIGGRAPH symposium on
Video games (2007), pp. 9–14. 2, 3, 5, 6, 7

c 2010 The Author(s)
⃝
c 2010 The Eurographics Association and Blackwell Publishing Ltd.
Journal compilation ⃝

