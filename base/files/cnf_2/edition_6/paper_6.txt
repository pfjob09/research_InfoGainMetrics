DOI: 10.1111/j.1467-8659.2009.01544.x

COMPUTER GRAPHICS

forum

Volume 29 (2010), number 1 pp. 60–74

Fast Gauss Bilateral Filtering
Shin Yoshizawa1 , Alexander Belyaev2 , and Hideo Yokota1

1 RIKEN, Saitama, Japan
{shin, hyokota}@riken.jp
2 Heriot-Watt University, Edinburgh, Scotland, United Kingdom
a.belyaev@hw.ac.uk

Abstract
In spite of high computational complexity, the bilateral filter and its modifications and extensions have recently
become very popular image and shape processing tools. In this paper, we propose a fast and accurate approximation
of the bilateral filter. Our approach combines a dimension elevation trick with a Fast Gauss Transform. First we
represent the bilateral filter as a convolution in a high dimensional space. Then the convolution is efficiently
approximated by using space partitioning and Gaussian function expansions. Advantages of our approach include
linear computational complexity, user-specified precision, and an ability to process high dimensional and nonuniformly sampled data. We demonstrate capabilities of the approach by considering its applications to the image
and volume denoising and high-dynamic-range tone mapping problems.
Keywords: bilateral filter, fast Gauss transform (FGT), Yaroslavsky filter, fast image filtering
ACM CCS: Numerical Analysis [G.1.2]: Approximation; Computer Graphics [I.3.3]: Picture/Image Generation;
Image Processing and Computer Vision [I.4.3]: Enhancement.

Mathematically, the classical bilateral filter in its continuous setting is defined as a spatial-tonal normalized
convolution

1. Introduction
The bilateral filter presents a natural combination of the
Gaussian spatial and tonal filters. The bilateral filter was first
proposed by [AW95] and then rediscovered in [SB97] within
the so-called SUSAN approach and in [TM98] where its current name was coined. The bilateral filter can be also considered as a very powerful modification of the Yaroslavsky filter
[Yar85] in which the spatial convolution with a box function
is changed to the spatial convolution with a Gaussian.

I new (x) =

y ∈ Rn ,
(1)

applied to an image I (x), x ∈ Rn . Here g1 (·) and g2 (·) are
Gaussian kernels used for spatial and tonal filtering, respectively. Often other types of decaying kernels are used in (1)
instead of Gaussians.

Because of its edge-preserving ability and conceptual
simplicity, the bilateral filter has become a popular and
powerful image and shape processing tool. It has been extended and generalized in several ways [CT03], [BCM05b,
BCM05a], [TSP07] and successively used for video enhancement [BM05, MS05], mesh denoising [FDCO03], highdynamic-range (HDR) image compression [DD02] purposes,
and many other image processing and computer graphics
applications. See [PKTD07] for a nice overview of properties, extensions, and applications of the bilateral filtering
approach.
c 2010 The Authors
Journal compilation c 2010 The Eurographics Association and
Blackwell Publishing Ltd. Published by Blackwell Publishing,
9600 Garsington Road, Oxford OX4 2DQ, UK and 350 Main
Street, Malden, MA 02148, USA.

g1 (x − y)g2 (I (x) − I ( y))I ( y)d y
,
g1 (x − y)g2 (I (x) − I ( y))d y

Previous work on fast bilateral filtering. The non-linear
and non-local nature of (1) makes its straightforward implementation computationally expensive: a naive discrete implementation of (1) has O(N 2 ) computational complexity
where N is a number of image elements (pixels/voxels). So
various approaches have been proposed for accelerating the
bilateral filter.
Noted that a separable convolution with a Gaussian is fast,
Pham and Vliet [PvV05] suggested to apply a 1D bilateral

60

S. Yoshizawa et al. / Fast Gauss Bilateral Filtering

filter subsequently to each spatial direction. The resulting
filter scheme mimics (1) and is quiet fast. However it often
generates undesired artifacts at image regions where image
edges are aligned with coordinate axes.
Weiss [Wei06] introduced a 3D histogram based approach
for accelerating the 2D bilateral filter with a square box spatial kernel. In a very recent paper [Por08], Porikli has also
employed a 3D histogram technique and achieved a remarkably low computational complexity when a box spatial kernel
is used. Another achievement of the approach of [Por08] consists of a constant complexity algorithm for a modification
of the Yaroslavsky filter with constant spatial kernel (i.e.
g1 = const in (1)).
Durand and Dorsey [DD02] proposed a fast approximation to the 2D bilateral filter by interpreting (1) as a Gaussian convolution with g2 (η − I ( y))I ( y) where η is a parameter, computing the convolutions for a sparse set of
values of η via 2D Fast Fourier Transforms (FFT), and
then linearly interpolating the results. It turns out that
the algorithm of [DD02] can be considered as a special
case of a more general convolution-based scheme introduced by Paris and Durand in [PD06] where 3D FFT is
combined with a downsampling strategy. In [PD09] Paris
and Durand extended their approach to colour images (bilateral filtering in 5D space). In their bilateral grid approach, Chen et al. [CPD07] combined the convolution-based
representation of (1) [PD06] with a GPU parallelization
scheme.
Of course, the above-mentioned approximations of the bilateral filter are not free of drawbacks. As noted in [PD09],
convolution and 3D grid based schemes may lead to memory overhead when dealing with multidimensional data. The
histogram-based approaches of Weiss and Porikli [Wei06,
Por08] are also sensitive to image dimensionality and, in
addition, do not allow for controlling the approximation
error.
Our approach. In this paper, we propose a fast and accurate approximation of the bilateral filter. The method is
conceptually simple and combines the dimension elevation
trick of [PD06] with Fast Gauss Transform (FGT), a technique for fast and error-controlled computation of a weighted
sum of Gaussians. FGT belongs to the family of fast multipole methods that combine clustering and manipulations
with truncated series expansions to achieve computationally
efficient and accurate approximations of sums of radial basis functions. First we apply the dimension elevation trick of
[PD06] and convert the discrete bilateral filter to a normalized
weighted sum of Gaussians in a spatial-tonal domain. Then
FGT is used for a fast and error-controlled numerical evaluation of the sum. To demonstrate the computational power of
our approach we consider a number of applications including
image denoising and HDR image tone mapping. The contributions and benefits of our approach can be summarized as
follows.

61

• It has linear computational complexity w.r.t image elements, such as pixels, voxels, etc.
• It allows the user to control speed/accuracy trade-off.
• It is applicable to non-uniformly sampled data.
• It leads to an extremely fast implementation of a version
of the Yaroslavsky filter with a spatially constant kernel.
• It turns out to be very efficient for volumetric filtering
and HDR image tone mapping tasks.

2. Bilateral Filtering as Convolution
It looks now obvious that bilateral filter (1) can be represented as a spatial-tonal normalized convolution and, therefore, may share many nice properties with linear filtering
schemes. To the best of our knowledge, it was first noted by
Boomgaard and de Weijer [vdBvdW02] and then extended
by Paris and Durand [PD09] who revealed the great power
of this seemingly simple observation. As shown below, it
is straightforward to extend the Paris-Durand approach to a
general multidimensional case.
Observation 1 (nD bilateral filter → (n + 1)D convolution). The n dimensional bilateral filter is given as a ratio
of two (n + 1) dimensional convolutions:
J (x, u) =

R
R

f ( y, v)g1 (x − y)g2 (u − v)d ydv
, (2)
h( y, v)g1 (x − y)g2 (u − v)d ydv
Rn

Rn

where f ( y, v) = h( y, v)I ( y), h( y, v) = δ(v − I ( y)), x,
y ∈ Rn are spatial variables and u, v ∈ R are tonal ones.
Here δ(·) is the Dirac delta-function.
Substituting f ( y, v) = h( y, v)I ( y) and h( y, v) = δ(v −
I ( y)) to (2) yields (1) with I new (x) = J (x, I (x)).
Although (2) opens an avenue for fast approximations of
the bilateral filtering scheme, constructing such approximations is far from being straightforward. At the first glance,
a straightforward use of FFT could be an computationally
efficient way to evaluate (2). However FFT can not be applied to (2) without a modification because (x, u) and ( y, v)
may not be equally spaced in Rn+1 . In addition, FFT has
O(nN log N ) computational complexity in Rn [FJ05] and,
therefore, is not very efficient when dealing with multidimensional data. These difficulties were partially overcome
in [PD06] where a FFT-based approach to bilateral filtering
was combined with uniform resampling techniques coupled
with linear interpolation and downsampling. The bilateral
grid [CPD07] also employs uniform resampling for approximating the bilateral filter on GPU.
In contrast to the previous approaches, we use the full
power of (2) and obtain a fast and accurate approximation of
the nD bilateral filtering.

c 2010 The Authors
Journal compilation c 2010 The Eurographics Association and Blackwell Publishing Ltd.

62

S. Yoshizawa et al. / Fast Gauss Bilateral Filtering

in [SSN09]. In our notations, it is given by

3. Bilateral Filtering via Gauss Transforms
In this paper, we focus on the situation when g1 (·) and g2 (·)
of (1) are Gaussian kernels because it is commonly used in
applications. Let G(x) = g1 (x)g2 (x) ≡ exp(− x/σ 2 ) with
x = {x1 , x2 , . . . , xn+1 }, σ = {σ1 , σ2 , . . . , σn+1 } ∈ Rn+1 and
2
x/σ 2 = n+1
i=1 (xi /σi ) . The discrete Gauss transform we
need for approximating (2) is now defined as follows.
Definition. Consider two point sets: targets {t1 , t2 , . . . , tN }
and sources s = {s1 , s2 , . . . , sM } in Rn+1 . Assume that each
source point sj is equipped with a positive scalar weight αj
where α = {α1 , α2 , . . . , αM }. The discrete Gauss transform
of target point t i w.r.t. all source points is defined by

IYnew (x i ) =

GT({I ( yj )}, I (x i ), {I ( yj )}, M))
,
GT(1, I (x i ), {I ( yj )}, M))

(6)

where {I ( yj )} = {I ( y1 ), I ( y2 ), . . . , I ( yM )}. We call it SCYaroslavsky filter because it has a spatially constant kernel.
For any dimensionality n, (6) consists of only 1D Gauss transforms and, therefore, allows for an accurate and extremely
fast implementation, see Section 6 for details. In addition
we will demonstrate that (6) is very useful for denoising and
segmenting applications in image and volume processing.
4. Fast Gauss Transform

M

GT(α, ti , s, M) ≡

αj G(ti − sj ).

(3)

j =1

Now Observation 1 implies that
Observation 2 (nD Bilateral to (n + 1)D Gauss Transform). The n dimensional bilateral filter with Gaussian
kernels is given as a ratio of two (n + 1)-dimensional Gauss
transforms
J (u) =

G(u − v)f (v)dv
, u, v ∈ Rn+1 ,
G(u − v)dv

(4)

where J (u) = I new (x) is the image resulting after bilateral
filtering, u = (x, I (x)), and v = ( y, I ( y)).
Let us consider two sets of points in the image space
x = {x 1 , x 2 , . . . , x N } and y = { y1 , y2 , . . . , yM }. The corresponding spatial-tonal points are given by u = {u1 ,
u2 , . . . , uN } and v = {v1 , v2 , . . . , vM } where ui = (x i ,
I (x i )) and vj = ( yj , I ( yj )). Denote I ( yj ) by qj where
q = {q1 , q2 , . . . , qM }. We have
I new (x i ) =

M
j =1 qj G(ui − vj )
M
j =1 G(ui − vj )

=

GT(q, ui , v, M)
(5)
GT(1, ui , v, M)

which delivers a discrete approximation of (4).
The Gauss transform and its fast implementations are often used as kernel density estimators in statistics. Relations
between kernel density estimators and bilateral filtering was
recently studied in [TSP07]. It is interesting to observe that
(5) can be also considered as a variant of mean-shift filtering [CM02], see also [vdBvdW02] for relationships between
normalized convolution filters, local-mode finding, robust
estimators, and mean-shift analysis.
Straightforward computing of (5) for all xi requires O(NM)
operations. Thus a naive implementation of bilateral filtering
of an image with N elements (pixels, voxels, etc.) has O(N 2 )
complexity.
Setting g1 (x − y) ≡ 1 in (1) yields a modification of the
Yaroslavsky filter [Yar85] which can be thought as a linear
diffusion in the tonal space. The filter was thoroughly studied

The Fast Gauss Transform (FGT) method we employ
is derived from a more general fast multipole method
[GR87] adapted for dealing with Gaussian kernels. FGT
was introduced in [GS91] for rapid evaluations of sums of
Gaussians. Since then, FGT has been improved in terms
of accuracy [GS98, BR02, WK06] and memory efficiency
[GM00, YDGD03, LGM06]. Besides numerous applications

Algorithm 1: Fast Gauss Transform
Subroutine: FGT(n, σ , {α}, {t}, {s}, N , M, )
Inputs: error , dimension n, bandwidth parameters σ ∈ Rn ,
targets {t}, sources {s}, number of targets N, number of
sources M, and scalar weights {α}.
Inside Parameters: box length w and interaction region
radius r.
Outputs: a scalar set {β}.
Require: > 0 and αj ∈ {α} ≥ 0.
1:
Set up box partitions with side length w(σ ) for s and t.
2:
Compute the number of kept terms p from via an error
estimator (we use that derived in [WK06]).
3:
for all source boxes. do
4:
for k = 0 to p do
5:
Compute the Hermite expansion coefficients Ak .
6:
end for
7:
end for
8:
for all target boxes i. do
9:
for all interaction region within (2r + 1)n nearest
boxes. do
10:
for k = 0 to p do
11:
Compute the Taylor expansion coefficients Bi
with Ak .
12:
end for
13:
end for
14:
end for
15:
for all sources do
16:
Evaluate the Taylor expansion.
17:
for k = 0 to p do
18:
Summing up the Taylor series with Bk .
19:
end for
20:
Store the sum to a scalar set {β}.
21:
end for
22:
Return {β}.

c 2010 The Authors
Journal compilation c 2010 The Eurographics Association and Blackwell Publishing Ltd.

63

S. Yoshizawa et al. / Fast Gauss Bilateral Filtering

in physics and computational mathematics, FGT has been
used in the fields of image processing and computer vision. In particular FGT was applied for image segmentation
[YDGD03] and object tracking [EDD03] purposes.
A full description of FGT is beyond the scope of this paper
and we give only a brief overview of how FGT works. The
Fast Multipole Method strategy for evaluating the sum of
Gaussians (3) includes using far-field and near-field asymptotic expansions for G(t − s). For the sake of simplicity, we
consider the 1D case because multi-index notations allow for
treating the multidimensional case in a very similar way. A
far-field expansion centered at s0 for 1D Gaussian G(t − s)
has the form
∞

k=0

1
k!

s − s0
σ

k

hk

t − s0
σ

∞

=

Ak hk
k=0

t − s0
σ

,

k

d
2
where hk (x) = (−1)k dx
k exp(−x ) are Hermite functions.
Interchanging t and s treats this formula as the Taylor series expansion centered at a nearby target t0 (near-field
expansion)
∞

G(t −s) =
l=0

Bl =

1
s − t0
hl
l!
σ

(−1)l
l!

∞

Ak hk+l
k=0

∞

t − t0 l
t − t0 l
=
Bl
,
σ
σ
l=0
s 0 − t0
σ

Algorithm 1 describes a FGT pseudo-code which reduces
the computational complexity of evaluating (3) for all targets
ti from O(NM) to O(M + N ). Given a specified precision
, the algorithm starts from determining the number of kept
terms p. We refer to [GS91, GS98] and rest of this paper for
further technical details.
The final FGT approximation accuracy is given by
|αj |,

(7)

where {αj } are the coefficients in (3). The upper bound
(7) corresponds to the worst-case scenario. In our experiments with the FGT-based approximation of the bilateral filter, we have found out that the real error is much
smaller.
Writing a good implementation of FGT is a difficult task.
Several implementations of FGT and its modifications and
improvements [BR02, GM00, YDGD03, MSR∗ 08] are available on the web [IM03, MRY∗ 08]. However after testing
some of these free-available codes we decided to write our
own implementation of FGT in order to have a full control
over our FGT-based image filtering schemes. In our implementation we follow [GS91, GS98] with a corrected and
improved error estimate as in [WK06].

.

Since the Gaussian falls off quickly, only a limited number of terms, say first p terms, in the above expansions are
needed for evaluating the sum of Gaussians (3) with a given
precision .
The original FGT method starts from constructing a space
partition consisting of regular boxes parallel to the coordinate
axes in Rn . Then the targets and sources are assigned to these
boxes. For each source box, it requires O(p n N ) operations
to compute the coefficients Ak corresponding to p-truncated
expansions. For each target box, all the Hermite expansions
in the source boxes within an interaction region are transformed into a Taylor series expansion to be used inside the
target box. The sources within (2r + 1)n nearest boxes are
sufficient to obtain single (r = 4) and double (r = 6) precisions [GS98]. Computing Bl involves O(np n+1 ) operations.
This leads to O((2r + 1)n np n+1 ) complexity per each target box if (2r + 1)n interaction regions are involved. Finally,
for each target, evaluating the Taylor series expansion takes
O(p n M) operations.
The FGT approximation error consists of two origins: errors due ignoring sources that are far form a given target
and truncation errors. The first component of the approximation error is easy to control by choosing a proper value
for parameter r, as discussed above. Controlling the second
component is based on appropriate error bounds for truncated expansions. In this paper, we use a new and sharp error
estimate derived in [WK06].

5. O(N) Algorithms
Now Algorithm 1 and Observation 2 lead to O(N) implementations of the bilateral and SC-Yaroslavsky filters, as described by Algorithms 2 and 3, respectively. In contrast to
[Por08] and [AGDL09] our FGT-based approximations are
error-controllable.

Algorithm 2: O(N) Bilateral Filter
Input: error , dimensionality n, spatial bandwidths σ g1 ∈ Rn ,
tonal bandwidth σ g2 ∈ R, targets {x}, sources { y}, number of
targets N, number of sources M, scalar image intensity
{I (x)}.
Called Functions: FGT(·).
Output: {I new (x)}.
Require: > 0, ∃I (x) ≥ 0, ∃I (y) ≥ 0.
1:
{q} ← {I (y1 ), I (y2 ), . . . , I (yM )}, yj ∈ y.
2:
{1} ← {1, 1, . . . 1}.
3:
{u} ← {u1 , u2 , . . . , uN } : u ui ← (xi , I (xi )).
4:
{v} ← {v1 , v2 , . . . , vM } : v vj ← (yj , I (yj )).
5:
σ ← (σ g1 , σ g2 ).
6:
{fi } ← FGT((n + 1), σ, {q}, {u}, {v}, N , M, ).
7:
{gi } ← FGT((n + 1), σ, {1}, {u}, {v}, N , M, ).
8:
for i = 1 to N do
9:
I new (xi ) ← fgii .
10:
end for
11:
Return {I new (x)} ← {I new (x1 ), I new (x2 ), . . . I new (xN )}.

c 2010 The Authors
Journal compilation c 2010 The Eurographics Association and Blackwell Publishing Ltd.

64

S. Yoshizawa et al. / Fast Gauss Bilateral Filtering

Algorithm 3: O(N) sc-Yaroslavsky Filter
Input: error , tonal bandwidth σ g2 ∈ R, number of targets
N, number sources M, scalar image intensity {I (x)}.
Called Functions: FGT(·).
Output: {IYnew (x)}.
Require: > 0, ∃I (x) ≥ 0, and ∃I (y) ≥ 0.
1:
{I (x)} ← {I (x1 ), I (x2 ), . . . , I (xN )}, xi ∈ x.
2:
{I (y)} ← {I (y1 ), I (y2 ), . . . , I (yM )}, yj ∈ y.
3:
{1} ← {1, 1, . . . 1}.
4:
{fi } ← FGT(1, σ g2 , {I (y)}, {I (x)}, {I (y)}, N , M, ))
5:
{gi } ← FGT(1, σ g2 , {1}, {I (x)}, {I (y)}, N , M, ))
6:
for i = 1 to N do
7:
IYnew (xi ) ← fgii .
8:
end for
9:
Return {IYnew (x)} ← {IYnew (x1 ), IYnew (x2 ), . . . IYnew (xN )}.

Figure 1: Left: Lena image consisting of 512 × 512 pixels.
Right: after applying the exact bilateral filter with σ g2 =
(16,16) and σ g1 = 51; computational time: 58 m.

1, 2, . . . , N enumerates the image elements (pixels, voxels,
etc.). In addition to the method noise d(x), the following
error metrics are used for evaluating our fast bilateral filter:

6. Results
Our implementation of FGT is based on the original approach
of Greengard and Strain [GS91, GS98] and, therefore, is
especially efficient in dealing with low dimensional data.
For high dimensional data, one should probably use the socalled IFGT, Improved Fast Gauss Transform, which has a
number of benefits over FGT [YDGD03, MSR∗ 08]. However
our own experiments with IFGT were not very encouraging.
Given an image y = I (x), x ∈ Rn , n = 2 or 3, let
us recall that the Gaussian kernel in (3) is given by
G(x) = g1 (x)g2 (x) ≡ exp(− x/σ 2 ) with vector of bandwidth parameters σ = [σ g1 , σ g2 ] = [σ1 , σ2 , . . . , σn+1 ] ∈
Rn+1 . Assume that the source points belong to the
bounding box [0, γ1 ] × · · · × [0, γn+1 ]. In our experiments with FGT, we employ the bounding box
=
[0, w1 ] × · · · × [0, wn+1 ] with wi = √σ2γi and use

L1 =

1
N

N

|dj |,

L∞ = maxj (|dj |),

j =1

ARE =

1
N

N
j =1

|dj |
,
Ije

MRE = maxj |dj |/Ije ,

MNR = |maxj (dj ) − minj (dj )|,
where the abbreviations ARE, and MRE stand for average
and maximum relative errors, respectively. We also employ
PSNR, the peak signal-to-noise ratio (the larger, the better),
used for similar purposes in [PD06, Por08]. Here
⎛
⎞
2
N
1
d
j
⎠.
PSNR = −10log10 ⎝
N j =1 maxj Ije , Ija

i

{10−4 , 10−3 , 10−2 , 10−1 , 1, 10, 102 , 103 } and interaction region radii r = {2, 3, 4, 5, 6}. At the first glance, in view of
(7) it does not seem correct to use large epsilon values. However, as noted before, the FGT accuracy upper bound (7)
represents the worst-case scenario and that scenario is not
realized for typical images (e.g. for a typical image, its intensity distribution is not concentrated on a small set of points).
In our numerical experiments, even setting = 103 leads to
a reasonably good FGT-based approximation of the bilateral
filter.
We will also need the standard deviation sd of 1D distribution of the intensity values {I (x)}.
Error metrics. Given an original image I (x), denote by
I e (x) and I a (x) the images obtained after applying an exact filtering scheme (we consider the bilateral filter and its
variations) and an approximation of the scheme (e.g. our
FGT-based approximations), respectively. Let dj = Ije − Ija
be the difference between the exact and approximated
bilateral filtering results, where the subindex j =

Timing and accuracy. The computation time is measured
in seconds (s), minutes (m), and hours (h). All our numerical experiments reported in this paper were performed on a
Core2 Extreme X9770 (3.2 GHz quad core, no parallelization
was used) PC with 16GB RAM and 64 bit OS. We compare
our FGT-based bilateral filter with the recent state-of-the-art
CPU-based fast bilateral filtering schemes: the histogrambased approach of [Por08], the FFT-based fast bilateral filter
of [PD06], and the separable bilateral filter of [PvV05]. We
use the program codes available from the authors of [PD06]
and from the web [Era08] for [Por08]. The Gaussian functions used in these codes are appropriately modified to coincide with G(x) defined in Section 3.
We start our numerical experiments from the famous Lena
image: Figure 1 presents the original image and an exact bilateral filtering result. Figure 2 delivers the visual, method
noise, and PSNR comparisons of our FGT-based method
with those developed in [PvV05], [Por08], and [PD06]. We
set the number of bins equal to 256 in our evaluation of the

c 2010 The Authors
Journal compilation c 2010 The Eurographics Association and Blackwell Publishing Ltd.

65

S. Yoshizawa et al. / Fast Gauss Bilateral Filtering

approach of [Por08] and, as a ground truth benchmark, use
exact bilateral filtering of the Lena image with a constant
spatial kernel (it takes 9.8 s to compute) instead of the right
image of Figure 1. Following notations adopted in [PD06,
PD09], we use ss and rs to denote the space (spatial) and
range (tonal) sampling rates. The timing and errors measurements corresponding to Figure 2 are given in Table 1. Figures
3, 5, and 6 demonstrate speed and accuracy advantages of our
method over the approaches developed in [PvV05], [PD06],
and [Por08] for varying bandwidth parameters. The graphs
in Figures 3, 5, and 6 correspond to [PvV05] (red), [Por08]
(green), [PD06] with (1,1) abbreviating (ss , rs ) = (σ g1 , σ g2 )
(blue) and (0.1,0.1) staying for (ss , rs ) = (0.1σ g1 , 0.1σ g2 )
(pink), and our method where (10,2) means ( , r) = (10, 2)
(orange), and (1,6) stays for ( , r) = (1, 6) (sky-blue). We
do not include detailed graphs for the ARE and L∞ metrics
because they are similar to the graphs for L1 and MRE error
metrics, respectively. Table 2 presents a computational time
comparison of the methods for various image sizes (we use
the same the enumeration notations and parameter settings
as in Figure 2). Table 3 summaries the bilateral filter approximation error results for the Lena image. As demonstrated by
the top image of Figure 6, the relation between the computational time and accuracy (we use L1 metric in this case) for
our method differ for different pairs of the bandwidth parameters. This is so because, for given bandwidth parameters,
our FGT-based algorithm automatically adapts the necessary
computational cost in order to satisfy a given precision.
Figure 7 presents visual and method noise comparisons of
our method with that of [PvV05] for a volume filtering task.
The corresponding timing results and error measurements
are presented in Tables 4 and 6, respectively, for various
volume sizes. Table 5 demonstrates how fast our method in
processing large size volumetric images (5123 voxels) for
various sets of the bandwidth parameters. According to our
estimates, a straightforward and exact bilateral filtering of a
volume dataset consisting of 5123 would take approximately
31 years of computational time.

1

∞

curate approximation of the bilateral filter w.r.t. L , L ,
MNR, and PSNR error metrics than the methods of [PD06,
PD09] and [Por08] with the highest accuracy settings. Setting ( , r) = (10, 2) gives approximately the same accuracy
as the above mentioned methods with the highest accuracy
settings w.r.t. L1 and PSNR metrics but our method is much
faster. In addition, those highest accuracy settings may cause
memory overflows when dealing with large-size images, as
indicated by (b) and (d) of Table 2.
Table 7 presents the timing results for our fast SCYaroslavsky image and volume filters. Since the filter is
based on 1D FGT which is very accurate [LKdF05], we
do not include here a detail error analysis in this case and
provide the reader with a typical example: for the Engine
volumetric image consisting of 643 voxels, our FGT-based
SC-Yaroslavsky filtering scheme ( , r) = (1, 6) takes only
0.05 s to compute with high accuracy w.r.t. the error metrics employed (L1 = 0.0098, L∞ = 1.27, ARE = 0.0016,
and MRE = 0.02).
Overall, the numerical experiments show that our approach
leads to fast and accurate bilateral and SC-Yaroslavsky image
and volume filtering. For example, our fast bilateral filter
processes 116K (71K), 474K (541K), 467K (812K), and
873K voxels (pixels) per second in average when ( , r) is set
to (1,6), (10,2), (102 ,2), and (104 ,2), respectively. Our fast
SC-Yaroslavsky filter with ( , r) = (1, 6) is highly accurate
and processes images and volumes at high speed of 5.28M
pixels/voxels per second.
The plots of Figure 4 illustrate timing and accuracy of our
methods w.r.t. the FGT parameters ( , r) and can serve as a
guidance for choosing these parameters. It is well known that
the r = 4 and r = 6 are sufficient to obtain single and double error precisions [GS98]. It is rather unexpected that using
r = 2 delivers quite satisfactory results as demonstrated by
Tables 1–5 and in Figures 2–8 and 10–12. We refer to
[LKdF05] for an empirical study of how the computational
cost depends on the FGT accuracy .

When σ g1 is small, our method requires greater computational time to compare with middle and large values of σ g1
for the same approximation accuracy.

7. Applications

As mentioned before, we have examined the fast bilateral filter of [PD06, PD09] with two parameter settings,
(ss , rs ) = (σ g1 , σ g2 ) and (ss , rs ) = (0.1σ g1 , 0.1σ g2 ) (the image intensity range is supposed to be rescaled to [0, 1]).
Although the first setting is recommended by the authors,
we decided to test the second one because it delivers a much
more accurate approximation to the bilateral filter. In our
experiments with the histogram-based approach of [Por08],
we use the 256 bins, although following numbers of bins:
16, 32, and 64 are recommended by the author. Obviously
the more bins are used, the more accurate approximation
is achieved. In all numerical experiments presented in this
paper, our method with ( , r) = (1, 6) delivers a more ac-

Noise reduction. The bilateral filter is well known as a
powerful denoising tool. Thanks to our FGT-based fast bilateral filtering scheme, we can use it iteratively in real time. In
our experiments with image denoising by iterative bilateral
filtering, we set σ g2 proportional to the standard deviation
of the image intensity sd which is updated after each iteration. Dealing with colour images, we process each colour
channel separately. For volume denoising, the same volume
rendering transfer function and pseudo colour are used for
visualizing noisy and corresponding denoised volumetric images. Figures 8 and 13 demonstrate how well our fast bilateral filter applied iteratively performs image and volume
denoising.

c 2010 The Authors
Journal compilation c 2010 The Eurographics Association and Blackwell Publishing Ltd.

66

S. Yoshizawa et al. / Fast Gauss Bilateral Filtering

Figure 2: A visual comparison of the fast bilateral filtering schemes of [PvV05] (a), [Por08] (b), [PD06] (c,d), and our FGTbased method (e,f). Here ss and rs are the space and range sampling rates for the fast bilateral filter of [PD06]. The bandwidth
parameters are those used in Figure 1. For each experiment, the lower-right image represents the method-noise image, the
differences between the exact filtering result and its approximation. The lower-left images are the method-noise images after
rescaling in order to fit the standard 0 − 255 intensity range. See also Table 1 for the method-noise intensity ranges (MNR)
before rescaling, timings, and approximation errors.

c 2010 The Authors
Journal compilation c 2010 The Eurographics Association and Blackwell Publishing Ltd.

67

S. Yoshizawa et al. / Fast Gauss Bilateral Filtering

Timing (Seconds: log-scale)
Our Method (1,6)
[PD06] (0.1,0.1)

Our Method (10,2)
[PD06] (1,1)

Seconds: log-scale

Seconds: log-scale

102

103

101

101
100
10

100

-1

10-20
0

Intensity Bandwidth

200

200

250 500

10

20
30
40
Intensity Bandwidth

50
60

Spatial Bandwidth

400

70
80 100

250 500

102

g2

Average Timing (seconds: log-scale) w.r.t. varying Intensity Bandwidth σ
[PvV05]
[Por08]
[PD06] (1,1)
[PD06] (0.1,0.1)
Our (10,2)
Our (1,6)

2

Seconds (log-scale)

Seconds (log-scale)

103

10

300

Spatial Bandwidth

400

0

200

150

Intensity Bandwidth

300

1

10

100

100

200

150

2

10

0

50

100

100

10

10-10

10-10
50

[PvV05]
[Por08]
[PD06] (1,1)
[PD06] (0.1,0.1)
Our (10,2)
Our (1,6)

Seconds: log-scale

101

10

90

80

70

60

50

30

40

20

10

0

Spatial Bandwidth

Average Timing (seconds: log-scale) w.r.t. varying Spatial Bandwidth σ

g1

1

100

100

10-1

0

10

20

30

40

50

60

70

80

90

100

10-1

0

10

20

30

Spatial Bandwidth σg1

40

50

60

70

80

Intensity Bandwidth σg2

Figure 3: Timing comparisons of the exact bilateral filter and its approximations applied to the Lena image (512 × 512 pixels).
Varying bandwidth parameters are used. The upper images present a timing comparison of our method and with those developed
in [PvV05], [PD06], and [Por08] in bandwidth parameter domains. The lower-left and lower-right images are the detailed 2D
plots of computational time averaged w.r.t. σ g2 against σ g1 and vice versa, respectively.
Table 1: Timing and approximation errors corresponding to
Figure 2.

(a)
(b)
(c)
(d)
(e)
(f)

Timing

L1

L∞

ARE

MRE

MNR

14.7 s
1.59 s
0.16 s
8.2 s
6.79 s
0.59 s

1.47
0.56
2.98
0.5
0.02
0.395

39
2
33
35
1
31

0.0129
0.0046
0.025
0.004
0.0001
0.0033

0.3659
0.0178
0.3
0.018
0.018
0.215

75
2
60
2
2
49

Average L1 (log-scale)

size

2562

5122

10242

20482

40962

81922

(a)
(b)
(c)
(d)
(e)
(f)

1.6
0.34
0.04
2.7
1.92
0.18

13.2
1.59
0.14
7.95
6.64
0.65

109
6.46
0.6
38.03
17.8
1.8

877
26.98
2.3
134.2
50.9
6

7235
N/A
9.2
N/A
149.6
22.9

69828
N/A
37.5
N/A
679.7
144.5

Maximum Time (Seconds: log-scale)

Minimum PSNR
0
-2
-4
-6
-8
-10
-12

0
-2
-4
-6
-8
-10
-12
2
3
4
Radius: r

Table 2: Computation times (in seconds) for the Lena image in various resolutions. Labels (a)–(f) refer to the methods and parameter
settings used for Figure 2.

100

10-1
10-2

5
6 10

-3

10

1

102

103

Error: ε

104

100
90
80
70
60
50
40
30

100
90
80
70
60
50
40
30
6
5
Radius: r

-1

4
3
2 10

0 10
1 10
2 10
Error: ε
3 10
4 10

10-2

-3

10

5.5
5
4.5
4
3.5
3
2.5
2
1.5

5.5
5
4.5
4
3.5
3
2.5
2
1.5
6
5
Radius: r

-1

4
3
2 10

0 10
1 10
2 10
Error: ε
3 10
4 10

10-2

10

-3

Figure 4: The plots show the variation of L1 error (left, log-scaling is applied), PSNR (centre), and computation time (right)
as functions of the FGT parameters ( , r). We present averaged L1 error, minimal PSNR, and maximal computational time w.r.t.
the bandwidth parameters σ g1 and σ g2 .
c 2010 The Authors
Journal compilation c 2010 The Eurographics Association and Blackwell Publishing Ltd.

68

S. Yoshizawa et al. / Fast Gauss Bilateral Filtering

Average Error (L1)

Maximum Relative Error
0.7

[PvV05]
[Por08]
[PD06] (1,1)
[PD06] (0.1,0.1)
Our (10,2)
Our (1,6)

6
5
4

[PvV05]
[Por08]
[PD06] (1,1)
[PD06] (0.1,0.1)
Our (10,2)
Our (1,6)

0.6

3
2

PSNR (dB)
100
90

0.5

80

0.4

70

0.3

60

0.2

1

50

0.1

00

40

00
10
20
30

40
50
Intensity Bandwidth

60
70

80 100 90

80

70

60

50

40

30

20

300

10

0

10

[PvV05]
[Por08]
[PD06] (1,1)
[PD06] (0.1,0.1)
Our (10,2)
Our (1,6)

20
30
40
50
Intensity Bandwidth

Spatial Bandwidth

60
70

70

80

80 100 90

60

50

40

30

20

10

10

0

20
30
40
Intensity Bandwidth

Spatial Bandwidth

50
60
70
80 100

90

80

60

70

50

40

30

20

10

0

Spatial Bandwidth

Average L1
4

1

g2

Average L w.r.t. varying Intensity Bandwidth σ

3.5

2

[PvV05]
[Por08]
[PD06] (1,1)
[PD06] (0.1,0.1)
Our (10,2)
Our (1,6)

1

g1

3

1

2.5

Average L

Average L

1

4

3

1.5

1

Average L w.r.t. varying Spatial Bandwidth σ

4.5

3.5

2.5
2
1.5
1

0.5

0.5

0

0
0

10

20

30

40

50

60

70

80

90

0

100

10

20

g1

30

40

50

60

70

80

g2

Spatial Bandwidth σ

Intensity Bandwidth σ

Maximum MRE
0

0

g2

Maximum MRE (log-scale) w.r.t. varying Intensity Bandwidth σ

-1

10

-1

10

[PvV05]
[Por08]
[PD06] (1,1)
[PD06] (0.1,0.1)
Our (10,2)
Our (1,6)

-2

10

g1

Maximum MRE (log-scale) w.r.t. varying Spatial Bandwidth σ

10

Maximum MRE

Maximum MRE

10

-2

0

10

20

30

40

50

60

70

80

90

100

10

0

10

20

g1

30

40

50

60

70

80

70

80

g2

Spatial Bandwidth σ

Intensity Bandwidth σ

Average PSNR
100

Average PSNR w.r.t. varying Intensity Bandwidth σg2

80
70

Average PSNR (dB)

Average PSNR (dB)

75

[PvV05]
[Por08]
[PD06] (1,1)
[PD06] (0.1,0.1)
Our (10,2)
Our (1,6)

90

g1

Average PSNR w.r.t. varying Spatial Bandwidth σ

80

60

70
65
60
55
50
45

50

40
40

35

30

30
0

10

20

30

40

50

60
g1

Spatial Bandwidth σ

70

80

90

100

0

10

20

30

40

50

60

Intensity Bandwidth σg2

Figure 5: A comparison of the fast bilateral filtering schemes considered in this paper on the Lena image. The top images present
plots of L1 error (left), MRE error (centre) and PSNR (right) against the bandwidth parameters (σ g1 , σ g2 ) ∈ [0, 100] × [0, 75].
The remaining six images demonstrate dependence of average L1 error, maximal MRE error and average PSNR w.r.t one
bandwidth parameter against another bandwidth parameter.

c 2010 The Authors
Journal compilation c 2010 The Eurographics Association and Blackwell Publishing Ltd.

69

S. Yoshizawa et al. / Fast Gauss Bilateral Filtering

101

L (log-scale)

10

L1 vs Timing

0

g
g
(σ 1,σ 2)=(98,75)

-1

10

(σg1,σg2)=(2,75)

(σg1,σg2)=(98,5)

[PvV05]
[Por08]
[PD06] (1,1)
[PD06] (0.1,0.1)
Our (10,2)
Our (1,6)

1

(σg1,σg2)=(2,5)
(σg1,σg2)=(6,75)

(σg1,σg2)=(98,75)

10-2
g
g
(σ 1,σ 2)=(98,5)

(σg1,σg2)=(6,5)

-3

10

10

-1

100

0

1

10

10
Timing (seconds, log-scale)

Maximum Relative Error (MRE) vs Timing

2

3

10

10

Peak Signal-to-Noise Ratio (PSNR) vs Timing

[PvV05]
[Por08]
[PD06] (1,1)
[PD06] (0.1,0.1)
Our (10,2)
Our (1,6)

[PvV05]
[Por08]
[PD06] (1,1)
[PD06] (0.1,0.1)
Our (10,2)
Our (1,6)

90
80
PSNR (dB)

MRE (log-scale)

100

-1

10

70
60
50
40

-2

10

-1

0

10

10

1

10
Timing (seconds, log-scale)

2

30
10-1

3

10

10

10

0

1

10
Timing (seconds, log-scale)

2

3

10

10

Figure 6: Error vs timing comparisons (the Lena image is used) for varying bandwidth parameters: (σ g1 , σ g2 ) ≤ (100, 75).L1
error (top), MRE error (bottom-left), and PSNR (bottom-right) are considered.
Table 3: The average and maximal L1 , L∞ , ARE, MRE errors and the average and minimal PSNR w.r.t. bandwidths (σ g1 , σ g2 ) ≤ (100, 75)
for the fast bilateral filtering schemes tested in this paper. The Lena image is used for this comparison.

[PvV05]

Max.
Ave.

L1

L∞

ARE

4.9
2.36

55.0
36.8

0.041
0.02

[Por08]

MRE

L1

0.66
0.39

Min. 31
37

PSNR

ARE

MRE

1
0.55

8
2.24

0.0088
0.0045

0.1
0.024

[PD06] (0.1,0.1)

Max.
Ave.

[PD06] (1,1)

L∞

PSNR

L1

L∞

ARE

MRE

PSNR

Min. 47
51

5.38
2.66

46
20

0.048
0.022

0.52
0.19

Min. 31
38

Our method (10,2)

Our method (1,6)

L1

L∞

ARE

MRE

PSNR

L1

L∞

ARE

MRE

PSNR

L1

L∞

ARE

MRE

PSNR

0.51
0.5

2
1

0.0044
0.004

0.024
0.0173

Min. 51
51

1.37
0.448

31
14.5

0.012
0.0037

0.21
0.1

Min. 42
51

0.045
0.019

1
0.96

0.00035
0.00015

0.022
0.016

Min. 62
68

c 2010 The Authors
Journal compilation c 2010 The Eurographics Association and Blackwell Publishing Ltd.

70

S. Yoshizawa et al. / Fast Gauss Bilateral Filtering

Figure 7: Left section: an input Engine 3D volumetric image consisting of 1283 voxels is shown with aspect ratio 1:1:0.5
(bottom-left), we use a part of the Engine image (top-left) in this comparison, the same part after exact bilateral filtering with
σ g1 = (5,5,10) and σ g1 = 0.5 sd (top-right), we use a colouring scheme represented by a pseudo colour bar (bottom-right) with
its lower end (blue) corresponding to 0 and its upper (red) corresponding to 255. Middle section: approximate bilateral filtering
according to [PvV05] is applied (top), method noise (bottom) shows the difference between the exact and approximate bilateral
filtering results. Right section: the results our FGT-based method tested for various setting of parameters ( , r) (top), method
noise results for the same parameter settings. See Tables 4 and 6 for the corresponding computational times and approximation
errors, respectively.
Table 4: Computation times for different bilateral filtering schemes
applied to volumetric datasets of various sizes. The parameter settings and the labels (a)–(e) are those used in Figure 7. The Engine
volumetric dataset is used in these experiments.

size

163

323

643

1283

2563

5123

(a)
(b)
(c)
(d)
(e)

0.86 s
0.01 s
3.3 s
2.6 s
2.5 s

59 s
0.16 s
9.2 s
3.4 s
3.3 s

1.03 h
2.7 s
2.7 m
14 s
12.7 s

66.7 h
46 s
1.4 h
1.7 m
42 s

N/A
13 m
5h
4.4 m
1.4 m

N/A
3.6 h
6.6 h
15.4 m
3m

Table 5: Dependence of computation time for our bilateral filter
on the bandwidths σ g1 and σ g2 for Engine volumetric dataset with
5123 voxels. First five columns: σ g2 = 0.5sd and σ g1 = ϕ (5,5,10).
Last three columns: σ g2 = ϕ sd and σ g1 =(10,10,20). Parameters
( , r) for (c)-(e) are those used in Figure 7.
ϕ

2

4

(c)
(d)
(e)

1.3 h
208 s
108 s

15 m
154 s
89 s

8

16

32

0.2

0.4

Table 6: Approximation errors corresponding to experiments described in Figure 7 and Table 4.
323

size

643

1283

323

643

1283

L∞

L1
(b)
(c)
(d)
(e)

0.077
2.6 × 10 −9
0.14
0.14

0.337
0.532
4.4
29.5
4.2 × 10 −9 4.9 × 10 −3 1.5 × 10 −5 1.5 × 10 −5
0.1
0.1
6.3
12
0.15
0.2
6.3
12
ARE
MRE

48.8
0.73
24
21

(b)
(c)
(d)
(e)

3.8 × 10 −3
3.2 × 10 −3
0.11
0.11

0.017
8.6 × 10 −4
0.1
0.12

3838
46
590
1216

0.036
0.13
0.1
0.12

1.8
0.98
30
30

173
0.78
9.8
14

Table 7: Computation times for our fast sc-Yaroslavsky image
(81922 pixels) and volume (5123 voxels) filtering with ( , r) = (1,6).
The bandwidth parameter σ g2 is given by ϕ sd .

0.8
ϕ

5.2 m 4.9 m 4.8 m 3.1 h 1.7 h 43 m
139 s 136 s 132 s 4.8 m 3.7 m 184 s
84 s
81 s
78 s 136 s 117 s 100 s

Image
Volume

0.1

0.2

0.4

0.6

0.8

1.0

13.4 s
27.6 s

13.4 s
26.4 s

13.2 s
25.8 s

11.4 s
24.5 s

12.8 s
24.3 s

12.4 s
24 s

c 2010 The Authors
Journal compilation c 2010 The Eurographics Association and Blackwell Publishing Ltd.

S. Yoshizawa et al. / Fast Gauss Bilateral Filtering

71

Figure 8: Examples of volume denoising with our FGT-based fast bilateral filter: two iterations with σ g2 = sd and ( , r) =
(102 , 2). Left-most: original noisy cell-cytokinesis volumetric dataset of size 256 × 256 × 60 voxels obtained using a confocal
laser microscope. Middle-left: it takes only 9.3 s for our FGT-based bilateral denoising with σ g1 = (1.6, 1.6, 5). Middle-right:
noisy CT-foot volume with 2563 voxels. Right-most: it takes 450 s for our FGT-based bilateral denoising with σ g1 = (8, 8, 8).

Figure 9: Volume processing with our fast sc-Yaroslavsky filter, ( , r) = (1, 6): Blade (4 iterations, 5.7 s), MRI-Head (4
iterations, 12.7 s), and Tomato (10 iterations, 8 s). Zoomed parts of the Blade models (two upper images) demonstrate capabilities
of the sc-Yaroslavsky filter to reveal hidden image structures. The pseudo colours are those used in Figure 7.

Figure 10: HDR image tone mapping with gamma correction 1.6 and cp = 15: processing 2000 × 1312 pixels takes
2.07 s.

Figure 11: HDR image tone mapping with Gamma correction 1.6 and cp = 50: processing 1025 × 769 pixels takes
0.98 s.

Figure 12: HDR volumetric tone mapping with cp = 50, processing 512 × 512 × 100 voxels takes 320 s. The pseudo colours
are those used in Figure 8. Four left images: different transfer functions are used for visualizing the tone mapped HDR volume.
c 2010 The Authors
Journal compilation c 2010 The Eurographics Association and Blackwell Publishing Ltd.

72

S. Yoshizawa et al. / Fast Gauss Bilateral Filtering

Figure 9 demonstrates 3D image processing with
our fast SC-Yaroslavsky volumetric filter applied iteratively. It reveals hidden image structures and seems useful for 3D image segmentation and feature extraction
purposes.
HDR tone mapping. Our fast bilateral filter is useful for
high-dynamic-range (HDR) tone mapping. We have combined the HDR image displaying technique of [DD02] with
our FGT-based filter and extended the technique to 3D volumetric images. In our numerical experiments, we have used
a part of the HDR image displaying code available from the
authors of [DD02]. Figures 10, 11, and 14 demonstrate the results of HDR image tone mapping based on our fast bilateral
filtering scheme with ( , r) = (102 , 2). In Figure 12, a 3D
hurricane velocity image is used to demonstrate the potential of our FGT-based bilateral filter for HDR processing of
volumetric data (in this example, we set ( , r) = (104 , 2) and
cp = 50 where the latter is the contrast parameter described
in [DD02]).

8. Conclusion

Figure 13: Colour image denoising with our fast FGT-based
bilateral filter. Top: original noisy Dragon image consisting of 1200 × 1600 pixels. Bottom: after three iterations of
our approximate bilateral filter with ( , r) = (102 , 2), σ g1 =
(10, 10) and σ g2 = 0.05sd . Computational time is 240 s.

In this paper, we have developed a FGT-based approach to
a fast and accurate approximation of bilateral filtering with
Gaussian kernels. Our FGT-based approximation has linear
computational complexity and is precision guaranteed. It can
be used to process high-dimensional and/or non-uniformly
sampled image data. We have demonstrated that our method
outperforms three recent state-of-the-art fast bilateral filtering schemes. We have also presented applications of our fast
bilateral filter to real-time image and volume denoising and
HDR image displaying problems.
Limitations and future work. In our current implementation of the bilateral filter, we deal with the Gaussian kernels
only. Dual-tree algorithms of [LGM06] may be useful for
extending the FGT approach to other kernels.
The non-local means filter of Buades et al. [BCM05b,
BCM05a] is a very powerful image denoising tool and active research is going on to build fast and accurate approximations of the filter [AGDL09]. Since the filter can
be described in terms of multi-dimensional Gauss transforms, it seems promising to use our approach for accelerating of the filter. High-dimensional FGT schemes developed in [YDGD03, MSR∗ 08] may be appropriate for this
purpose.
Finally, a GPU-based implementation of FGT also constitutes a promising future work.

Figure 14: HDR image tone mapping with gamma correction 2.2 and cp = 50. Processing the image with 767 × 1023
pixels takes only 0.8 s.

Acknowledgments
We are grateful to Sylvain Paris, Fr´edo Durand, Julie Dorsey,
and Mark Eramian for making their source codes available.

c 2010 The Authors
Journal compilation c 2010 The Eurographics Association and Blackwell Publishing Ltd.

S. Yoshizawa et al. / Fast Gauss Bilateral Filtering

73

We would like to thank the anonymous reviewers of this
paper for their helpful comments and suggestions.

Transactions on Graphics (Proceedings of ACM SIGGRAPH) 26, 3 (2007), 103.

The models are courtesy of Dani Lischinski (Belgium
House and National Cathedral), General Electric (Engine), Lawrence Berkeley Laboratory (Tomato), MIT CSAIL
(Dragon), NCAR and NSF (Hurricane), Philips Research
(CT-Foot), University of Erlangen (MRI-Head), and Satoshi
Shimozono (Cell-cytokinesis). The volume rendering software employed to visualize volumes is courtesy of Takehiro
Tawara.

[CT03] CHOUDHURY P., TUMBLIN J.: The trilateral filter for
high contrast images and meshes. In EGRW’03: Proceeings of the 14th Eurographics workshop on Rendering
(2003), Eurographics Association, pp. 186–196.

This work was supported in part by Grants-in-Aid for
Scientific Research of Japan (20700175 and 20113007).
Alexander Belyaev acknowledges the support from the
Joint Research Institute for Signal & Image Processing,
which is a part of the Edinburgh Research Partnership in
Engineering and Mathematics (ERPem).

References
[AGDL09] ADAMS A., GELFAND N., DOLSON J., LEVOY M.:
Gaussian kd-trees for fast high-dimensional filtering. ACM
Transactions on Graphics (Proceedings of ACM SIGGRAPH) 28, 3 (2009), 1–12.
[AW95] AURICH V., WEULE J.: Non-linear Gaussian filters
performing edge preserving diffusion. In Mustererkennung, 17. DAGM-Symposium (1995), Springer-Verlag,
Berlin, Germany, pp. 538–545.
[BCM05a] BUADES A., COLL B., MOREL J. M.: A non-local algorithm for image denoising. In Proceedings of IEEE-CS
conference on Computer Vision and Pattern Recognition
(CVPR’05) (2005), 60–65.

[DD02] DURAND F., DORSEY J.: Fast bilateral filtering for the
display of high-dynamic-range images. In Proceedings of
ACM SIGGRAPH (2002), ACM Press, pp. 257–266.
[EDD03] ELGAMMAL A., DURAISWAMI R., DAVIS L. S.: Efficient kernel density estimation using the fast Gauss transform with applications to color modeling and tracking.
IEEE Transactions on Pattern Analysis and Machine Intelligence 25, 11 (2003), 1499–1504.
[Era08] ERAMIAN M.: Fast bilateral filter (C, Command Line
Utility). In Code of the histogram-based approach [Por08]
(2008). img.cs.usask.ca/img/index.php?page=download.
[FDCO03] FLEISHMAN S., DRORI I., COHEN-OR D.: Bilateral mesh denoising. ACM Transactions on Graphics
(Proceedings of ACM SIGGRAPH) 22, 3 (2003), 950–
953.
[FJ05] FRIGO M., JOHNSON S.: The design and implementation of fftw3. In Proceedings of the IEEE (2005), IEEE,
pp. 216–231.
[GM00] GRAY A. G., MOORE A. W.: ‘n-body’ problems in
statistical learning. In Advances in Neural Information
Processing Systems (NIPS) (2000), pp. 521–527.
[GR87] GREENGARD L., ROKHLIN V.: A fast algorithm for
particle simulations. Journal of Computational Physics
73 (1987), 325–348.

[BCM05b] BUADES A., COLL B., MOREL J. M.: A review
of image denoising algorithms, with a new one. SIAM
Multiscale Modeling & Simulation 4, 2 (2005), 490–530.

[GS91] GREENGARD L., STRAIN J.: The fast Gauss transform.
SIAM Journal on Scientific and Statistical Computing 12,
1 (1991), 79–94.

[BM05] BENNETT E. P., MCMILLAN L.: Video enhancement
using per-pixel virtual exposures. ACM Transactions on
Graphics (Proceedings of ACM SIGGRAPH) 24, 3 (2005),
845–852.

[GS98] GREENGARD L., SUN X.: A new version of the
fast Gauss transform. In Proceedings of IEEE International Congress of Mathematicians III (1998), pp. 575–
584.

[BR02] BAXTER B. J. C., ROUSSOS G.: A new error estimate
of the fast Gauss transform. SIAM Journal of Scientific
Computing 24, 1 (2002), 257–259.

[IM03] IHLER A., MANDEL M.: Kernel density estimation
toolbox for matlab (2006). http://www.ics.uci.edu/∼ihler/
code/.

[CM02] COMANICIU D., MEER P.: Mean shift: a robust approach toward feature space analysis. IEEE Transactions
on Pattern Analysis and Machine Intelligence 24, 5 (2002),
603–619.

[LGM06] LEE D., GRAY A., MOORE A.: Dual-tree fast Gauss
transforms. In Advances in Neural Information Processing
Systems 18. Y. Weiss, B. Sch¨olkopf, J. Platt (Eds.), MIT
Press, Cambridge, MA, 2006, pp. 747–754.

[CPD07] CHEN J., PARIS S., DURAND F.: Real-time edgeaware image processing with the bilateral grid. ACM

[LKdF05] LANG D., KLAAS M., DE FREITAS N.: Empirical
Testing of Fast Kernel Density Estimation Algorithms.

c 2010 The Authors
Journal compilation c 2010 The Eurographics Association and Blackwell Publishing Ltd.

74

S. Yoshizawa et al. / Fast Gauss Bilateral Filtering

Technical Report UBC TR-2005-03, University of British
Columbia, 2005.
[MRY*08] MORARIU V. I., RAYKAR V. C., YANG C.,
DURAISWAMI R., DAIVS L. S.: Figtree: Fast improved
Gauss transform with tree data structure (2008).
http://www.umiacs.umd.edu/∼morariu/figtree.
[MS05] MAHMOUDI M., SAPIRO G.: Fast image and video
denoising via nonlocal means of similar neighborhoods. Signal Processing Letters 12, 12 (2005), 839–
842.
[MSR*08] MORARIU V. I., SRINIVASAN B. V., RAYKAR V. C.,
DURAISWAMI R., DAVIS L. S.: Automatic online tuning for
fast Gaussian summation. In Advances in Neural Information Processing Systems (NIPS) (2008).
[PD06] PARIS S., DURAND F.: A fast approximation of the bilateral filter using a signal processing approach. In ECCV
(4) (2006), pp. 568–580.
[PD09] PARIS S., DURAND F.: A fast approximation of the
bilateral filter using a signal processing approach. International Journal of Computer Vision 81, 1 (2009), 24–52.
[PKTD07] PARIS S., KORNPROBST P., TUMBLIN J., DURAND F.:
A gentle introduction to bilateral filtering and its applications. In SIGGRAPH ’07: ACM SIGGRAPH courses (New
York, NY, USA, 2007), ACM, p. 1.

[SB97] SMITH S. M., BRADY J. M.: SUSAN - A new approach
to low level image processing. International Journal of
Computer Vision 23, 1 (1997), 45–78.
[SSN09] SINGER A., SHKOLNISKY Y., NADLER B.: Diffusion
interpretation of nonlocal neighborhood filters for signal
denoising. SIAM Journal of Imaging Sciences 2, 1 (2009),
118–139.
[TM98] TOMASI C., MANDUCHI R.: Bilateral filtering for
gray and color images. In ICCV ’98: Proceedings of
International Conference on Computer Vision (1998),
pp. 839–846.
[TSP07] TAKEDA H., SINA F., PEYMAN M.: Higher order bilateral filters and their properties. In Proceedings of SPIE
Conference on Computational Imaging (2007).
[vdBvdW02] VAN DEN BOOMGAARD R., VAN DE WEIJER J.: On
the equivalence of local-mode finding, robust estimation
and mean-shift analysis as used in early vision tasks. In
ICPR ’02: Proceedings of International Conference on
Pattern Recognition (2002), vol. 3, IEEE Computer Society, pp. 30927–30930.
[Wei06] WEISS B.: Fast median and bilateral filtering. ACM
Transactions on Graphics (Proceedings of ACM SIGGRAPH) 25, 3 (2006), 519–526.
[WK06] WAN X., KARNIADAKIS G. E.: A sharp error estimate
for the fast Gauss transform. Journal of Computational
Physics 219, 1 (2006), 7–12.

[Por08] PORIKLI F.: Constant time O(1) bilateral filtering. In Proceedings of IEEE-CS conference on
Computer Vision and Pattern Recognition (CVPR)
(2008).

[Yar85] YAROSLAVSKY L. P.: Digital Picture Processing–An
Introduction. Springer-Verlag, Berlin, Germany, 1985.

[PvV05] PHAM T. Q., VAN VLIET L.: Separable bilateral filtering for fast video preprocessing. In Proceedings of
IEEE International Conference on Multimedia & Expo
(2005).

[YDGD03] YANG C., DURAISWAMI R., GUMEROV N. A., DAVIS
L.: Improved fast Gauss transform. In ICCV’03: Proceedings of International Conference on Computer Vision
(2003), pp. 464–471.

c 2010 The Authors
Journal compilation c 2010 The Eurographics Association and Blackwell Publishing Ltd.

