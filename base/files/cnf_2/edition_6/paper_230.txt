DOI: 10.1111/j.1467-8659.2010.01717.x

COMPUTER GRAPHICS

forum

Volume 29 (2010), number 8 pp. 2328–2339

A Shape Descriptor for 3D Objects Based
on Rotational Symmetry
M. Martinek, R. Grosso and G. Greiner
Department of Computer Science, University of Erlangen-Nuremberg, Germany
michael.martinek@cs.fau.de

Abstract
The ability to extract spatial features from 3D objects is essential for applications such as shape matching and
object classification. However, designing an effective feature vector which is invariant with respect to rotation,
translation and scaling is a challenging task and is often solved by normalization techniques such as PCA,
which can give rise to poor object alignment. In this paper, we introduce a novel method to extract robust and
invariant 3D features based on rotational symmetry. By applying a rotation-variant similarity function on two
instances of the same 3D object, we can define an autocorrelation on the object in the space of rotations. We use a
special representation of the SO(3) and determine significant rotation axes for an object by means of optimization
techniques. By sampling the similarity function via rotations around these axes, we obtain robust and invariant
features, which are descriptive for the underlying geometry. The resulting feature vector cannot only be used
to characterize an object with respect to rotational symmetry but also to define a distance between 3D models.
Because the features are compact and pre-computable, our method is suitable to perform similarity searches in
large 3D databases.
Keywords: feature vector, shape descriptor, shape matching, object retrieval
ACM CCS: I.3.5 [Computer Graphics]: Computational Geometry and Object Modelling

1. Introduction
The use of computer-aided 3D modelling is becoming increasingly popular, a phenomenon which is mainly advanced
by new technologies. New modelling tools and 3D scanners
facilitate the process of generating 3D models whereas the
internet provides a means of fast distribution and allows anyone access to any type of 3D data. Be it publicly available
models on the internet or company-internal databases, which
include all CAD data accumulated in the course of manufacturing processes, the number of 3D objects is on a constant
rise and so is the need for new analysing tools. A popular and
challenging task in this field is to measure the similarity of 3D
objects. Only in rare cases does 3D data feature additional
semantic information, which would allow for a text-based
search. The objects are rather provided as bare geometrical
descriptions—a phenomenon which has driven the desire for
shape-based similarity measures.
c 2010 The Authors
Computer Graphics Forum c 2010 The Eurographics
Association and Blackwell Publishing Ltd. Published by
Blackwell Publishing, 9600 Garsington Road, Oxford OX4
2DQ, UK and 350 Main Street, Malden, MA 02148, USA.

However, the geometric description of 3D objects is not
suitable for comparisons due to the inconsistent structure
and the large amount of information. Instead, it is necessary to extract mathematical features from the objects in a
pre-processing step. Such a feature vector reduces the large
amount of data in an object description to a few shape describing parameters. The comparison of complex 3D models
is then reduced to the comparison of its corresponding feature
vectors. A challenging task in designing such a feature vector
is to provide invariance with respect to rigid body transformations. Most existing approaches do not provide invariance
by definition and therefore require a global normalization of
the objects prior to the actual feature extraction. This dependency is crucial to the quality of the measure because
global alignment techniques such as PCA often reveal severe inaccuracies as illustrated in [FMK∗ 03, PSG∗ 06]. Some
researchers have proposed methods to compensate for the
weaknesses of PCA. Papadakis et al. [PPPT07] normalize

2328

M. Martinek et al. / Rotational Symmetry Descriptor

the input objects twice, by applying PCA on the face normals
(NPCA) and the vertices. For the computation of the similarity between two objects, the version with the smaller distance
is chosen. Vajramushti et al. [VKTP04] use PCA as a preprocessing step but perform a post-processing to improve the
obtained alignment. These methods may improve the quality of the alignment but require additional computations. A
better approach is to avoid the need for a normalization step
and to provide invariance by definition. This goal is met by
the feature vector proposed in this paper. Our idea is to apply
a rotation-variant similarity function on two instances of the
same object which provides an autocorrelation measure of
the object in the space of rotations. Using a formula which
maps rotations to a differentiable manifold of the SO(3),
we efficiently detect significant feature points inside this domain. The obtained points define significant rotation axes of
the underlying object. We sample the similarity function during rotations around said axes, revealing descriptive features
which are invariant with respect to translation, rotation and
scaling.
Our feature vector is not only a bare mathematical description but can be visualized by three graphs which are intuitive
and well interpretable. Therefore, we cannot only define a robust distance measure between two feature vectors, but also
derive valuable information about an object’s geometry by
only regarding its feature vector.
1.1. Related work
In the past, many different approaches to the problem of 3D
shape matching have been proposed. We can roughly classify
them into the following categories:

2329

function is defined by the furthest intersection of rays emanating from the origin and the object’s surface. Vranic et al.
[Vra03] extend this idea by also considering interior intersection points, whereas Papadakis et al. [PPPT07] apply the
ray-based approach on spherically partitioned objects. All
these methods use the spherical harmonic transform as expansion series and perform a PCA normalization to obtain rotational invariance. Kazhdan et al. [KFR03, FMK∗ 03] avoid
the need for a normalization step by considering the energies
of spherical harmonics in each energy band rather than the
rotation-variant coefficients. In [NK04], Novotni et al. use 3D
Zernike invariants as features and reveal that Zernike descriptors are a natural extension of descriptors based on spherical
harmonics.

1.1.3. Distribution based
In this category, shape histograms, which reflect a certain
distribution, are used as 3D descriptors. This distribution can
be obtained either statistically [OFCD01, ILSR02, OMT03]
or by means of space division. Ankerst et al. [AKKS99] partition the space around the objects into sectors and shells. A
shape histogram is obtained by assigning each bin the number
of surface points it contains. The approaches in [KPNK03,
BMP02] use the same partitioning but obtain histograms by
means of shape contexts, which capture the distribution of
the remaining points relative to a certain feature point. However, if shape contexts are to be applied for global matching,
it is required to determine point-to-point correspondences
between similar objects.

1.1.1. 2D image based methods

1.1.4. Topology based

Methods from this category represent a 3D object by a
number of 2D projections. Most approaches use depth images, that is 2D projections which also feature a z-value
at each pixel while others only use silhouette descriptions
[NASO07]. Features from depth images are usually obtained
by means of Fourier analysis [CVB06, ONT03]. Chauouch
et al. [CVB07] extract depth lines from the images and use
dynamic programming for a comparison of corresponding
depth lines. In [CTSO03], Chen et al. introduce the Lightfield Descriptor where a model is represented by a collection
of images rendered from the vertices of a regular dodecahedron. The dissimilarity between two 3D models is defined as
the minimum dissimilarity of corresponding images under
all possible rotations of camera positions.

Methods from the fourth category extract shape descriptors
by capturing the topology of the objects. A popular approach
is to use skeletons [SSGD03, CDS∗ 05, LKM07]. Other approaches use Reeb Graphs [HSKK01], geodesic eccentricity [IAP∗ 08] or conformal factors [BCG08]. All methods
from this category provide invariance with respect to articulated transformations. Therefore, they are particularly suitable for matching dynamic objects such as animals in different poses rather than static objects with only little topological
information.

1.1.2. Spherical function based
The objects are represented as a function on a sphere which
is expanded in a series. The respective expansion coefficients are then used as features. In [SV01], the spherical

1.1.5. Hybrid methods
Some researchers have combined different approaches to
form a hybrid descriptor. Papadakis et al. [PPT∗ 08] combine
a 2D image based and a spherical function based method
whereas Vranic [Vra05] has designed a feature vector which
combines depth buffer images, silhouette images and a spherical function defined on ray-extends.

c 2010 The Authors
Computer Graphics Forum c 2010 The Eurographics Association and Blackwell Publishing Ltd.

2330

M. Martinek et al. / Rotational Symmetry Descriptor

1.1.6. Symmetry
Another important topic in shape analysis is symmetry because it plays a fundamental role in human recognition. Although symmetry detection has been well studied in the past
[MGP06, MSHS06, PSG∗ 06, KCD∗ 03], only little research
has been done on the application of symmetries for 3D shape
matching. One existing approach is the work of Kazhdan
et al. [KFR04]. The authors introduce descriptors for rotational and reflective symmetries of 3D objects with respect to
every axis passing through the centre of mass (the barycentre). Unit vectors on the sphere are scaled in proportion to
the measure of the respective symmetry. The result is a set
of spherical functions, one for reflective symmetries and one
for each rotational symmetry of order n. The symmetry information is used to augment the spherical harmonic descriptor
[KFR03] to improve its discriminating power.

Figure 1: The matching volume of the two objects is approximated by the matching areas of six depth images taken from
the faces of a cube.
The desired function has the general form
SAB (M) : SO(3) → [0, 1].

1.2. Overview
In this paper, we introduce a compact feature vector which
captures significant rotational symmetries (even of high order) in a single structure. We show that symmetric properties
of an object alone are sufficient to obtain robust and invariant
features for shape matching and object classification. Furthermore, we do not rely on the barycentre of the object as
centre of rotation and introduce an optimization of this centre to improve the significance of the features. The rest of
this paper is organized as follows: in the subsequent section, we shortly describe the prerequisites for our method
which include a rotation-variant similarity function as well
as a suitable rotation representation. In Section 3, we provide
the definition of our feature vector and an efficient method
to extract it from 3D objects. Section 4 describes a distance
metric between the features of two objects which provides a
robust similarity measure. Section 5 demonstrates the quality
of the proposed 3D shape descriptor for object classification
and database queries, whereas Section 6 concludes our work
and allows insight into future work.

2. Prerequisites
To examine the rotational symmetries of an object, we use
two essential prerequisites: (i) a similarity function which is
defined on the space of rotations and (ii) a suitable representation of the SO(3), which allows for an efficient analysis of
this function. These issues are the topics of the following two
subsections.

2.1. The rotation-variant similarity function
The desired function should reflect how much two objects A
and B match each other in their current alignment. Assume
that the two objects are normalized with respect to translation
and scaling and a common centre of rotation has been defined.

(1)

The parameter M describes a rotation matrix which is to
be applied to one of the objects to change the alignment.
We always apply this rotation to object A and denote this
operation as M · A in the following:
A function which complies with the draft from equation
(1) can be seen as an exchangeable module of our algorithm.
However, we require not only a high degree of accuracy but
also a high performance because a lot of function evaluations
are necessary for the process of feature extraction. For our
implementation, we use a function introduced in [MG09]
which will be briefly described in this section.
The two objects are rendered from the six faces of a surrounding cube as illustrated in Figure 1.
We compare corresponding depth images of size N × N
for each perspective. Let Pij(k) (A) and Pij(k) (B) denote the
projected depth value of objects A and B from the perspective
k at a point [i, j ]. A value of 0 thereby indicates an empty
projection at the respective point. We define the operator ∗
on two depth projections as follows:
⎧
Pij(k) (A) · Pij(k) (B) > 0, and
⎪
⎪1
⎨
Pij(k) (A) ∗ Pij(k) (B) =
Pij(k) (A) − Pij(k) (B) <
⎪
⎪
⎩
0
otherwise.
(2)
We define the required similarity function SAB (M) as a
normalized sum over all perspectives and projected points
SAB (M) =

1
C(M)

6

N

N

Pij(k) (M · A) ∗ Pij(k) (B),
k=1 i=1 j =1

(3)

where C(M) states the total amount of projected points, that
is the number of points where either object A or object B has
a non-zero depth value. The function sums up all matching

c 2010 The Authors
Computer Graphics Forum c 2010 The Eurographics Association and Blackwell Publishing Ltd.

2331

M. Martinek et al. / Rotational Symmetry Descriptor

projection points where the difference according to the depth
values of the two objects is within a certain threshold . To
obtain a value between 0 and 1, we normalize this sum by
the factor C(M).

tion, we introduce an algorithm which extracts pose-invariant
features from an object without the need of a pre-processing
normalization.

While the generation of depth images is a trivial task on
the GPU, the comparison operations can also be performed
on the GPU-side. Using a fragment shader to discard points
which return a value of 0 in equation (2), we can apply occlusion queries to count the matching fragments. Due to this
efficient GPU-implementation, a single function evaluation
takes approximately 1 ms on a Nvidia Geforce 8800 GTX
with an image size of 200 × 200.

3.1. Rotational autocorrelation
The function SAB (R(w)) from Equation (3) can be seen as a
correlation function defined on the space of rotations. It states
how two objects correlate for different alignments. The idea
is now to apply the function to an object itself to obtain an
autocorrelation
SAA (R(w)) =

1
C(M)

6

N

N

Pij(k) (R(w) · A) ∗ Pij(k) (A).
k=1 i=1 j =1

2.2. Representation of the SO(3)
In computer graphics, rotations are usually represented as
orthogonal matrices. In this form, a rotation can be applied
to points in space by means of a matrix–vector multiplication. However, for computational aspects in the SO(3), other
representations are more suitable. The following equation,
which is also known as Rodrigues Rotation Formula, maps a
point w ∈ R3 to a rotation matrix R(w)
R(w) = I + w˜ sin θ + w˜ 2 (1 − cos θ ),
where I is the identity matrix, θ = ||w|| and w˜ is the skew
symmetric matrix which is formed by the normalized vector
ˆ = w/||w|| as follows:
w
⎞
⎛
wˆ y
0
−wˆ z
⎟
⎜
0
−wˆ x ⎠ .
w˜ = ⎝ wˆ z
−wˆ y

wˆ x

0

The origin is mapped to the identity matrix and therefore
ˆ correpresents the current alignment. For a point w = 0, w
responds to the axis of rotation and θ states the angle of
rotation. We observe that any possible rotation can be expressed by Euclidean points w ∈ R3 inside a sphere with
radius π , which we refer to as rotation sphere. This representation is very suitable for examining the behaviour of a
function which depends on rotation.

(4)

In their initial state, two instances of one and the same object
are perfectly aligned. Thus, evaluating SAA (R(0)) always returns 1.0. An important issue in applying the autocorrelation
function to values other than 0 is the choice of the centre
of rotation. As an initial guess, we use the barycentre of the
object’s vertices. However, the quality of the rotation centre is too crucial to stick with this initial choice because the
barycentre may significantly differ for similar objects. This
may be due to a potentially non-uniform distribution of the
object’s vertices. We will therefore optimize the centre of
rotation during the extraction process. This procedure will
be described after the definition of the feature values because
they provide the required quality measure for the optimization of the rotation centre.
Using the rotation representation described in Section 2.2,
the domain of the autocorrelation function SAA (R(w)) is the
sphere with radius π centred at the origin. This is the domain
in which we want to extract geometrical features. However,
the absolute values of the aurocorrelation are not invariant
with respect to rotation. Figure 2 shows various 2D plots
through the rotation domain for an axis-aligned cuboid. We
can see that the local maxima change their absolute coordinates when the object is differently oriented. Therefore, it
is necessary to find significant values in a relative manner,
which will be done in the following section.
3.2. Definition of the feature vector

3. Extracting Spatial Features
The pose-variant similarity function which we have introduced in the previous section is only suitable for shape
matching if the two objects are perfectly aligned. In fact,
many approaches use rotation-variant features from depth
images in combination with a normalization step [NASO07,
CVB07, CVB06]. This is crucial because it is a well-known
fact that global alignment techniques such as PCA can give
rise to poor alignment. More elaborate alignment techniques
[Kaz07, MD03, MG09] only work on two objects but cannot
be used for a global normalization with respect to rotation.
However, we require pre-computable features for 3D shape
matching to perform efficient database queries. In this sec-

The behaviour of the autocorrelation function SAA (R(w)) inside the rotation sphere is significant for the geometry of
the underlying object. Strong local maxima reveal rotational
symmetries of the object. However, not only are the magnitude, the amount or the relative positions of such maxima
relevant factors, the behaviour of the function outside these
peaks also contributes to the description of the geometry.
This consideration allows the features to work well also for
objects with a moderate amount of rotational symmetry.
The searching domain for significant local maxima can be
reduced by considering properties of rotational symmetry.
By strict definition, rotational symmetry of order n occurs

c 2010 The Authors
Computer Graphics Forum c 2010 The Eurographics Association and Blackwell Publishing Ltd.

2332

M. Martinek et al. / Rotational Symmetry Descriptor

The orthogonal system defined by the three feature points
always has the same context for similar objects and is able to
capture the most significant rotational symmetries for most
man-made objects. Only in rare cases of objects with oddordered rotational symmetries, such as a tetrahedron, we neglect significant symmetries because we cannot capture them
with an orthogonal set of axes. However, detecting all symmetries is not the purpose of this method. It is the definition of
a feature vector which is rotation-invariant and discriminative
for different geometries. This is achieved by the following
definition:
Aij = SAA R

j
pi
100

,

i = [1..3], j = [1..100].
(5)

Figure 2: Two-dimensional plots of the autocorrelation
function at three exemplary slices through the rotation domain for a cuboid. The function values are indicated by intensity.

if the object looks the same after a rotation about an angle
of 2π/n. We reformulate (and weaken) this definition in the
following manner:
An object has a rotational symmetry of order n if there is a
point m with ||m|| = 2π/n so that SAA (R(m)) is a significant
local maximum.
Every rotational symmetry of even order implies rotational
symmetry of second order, thus, at least one local maximum
has to be found on the surface of the rotation sphere for
(almost) all man-made 3D objects, especially with our alleviated definition of rotational symmetry. Let the feature
point p1 be the global maximum of the autocorrelation function on said domain. We introduce the axis defined by p1
and the origin as the main rotation axis of the underlying
object and define further feature points p2 and p3 so that the
corresponding axes form an orthogonal system. This idea is
closely related to the principal symmetry axes introduced in
[PSG∗ 06], which are the normals of the orthogonal set of
planes with maximal reflective symmetry.
The three feature points on the surface of the rotation
sphere are defined as follows:
p1 = max SAA (R(w)),
|w|=π

p2 = max SAA (R(w)) with p1 , p2 = 0,
|w|=π

p3 = π

p1 × p2
.
|p1 × p2 |

Equation (5) defines a shape descriptor in the form of a
3 × 100 matrix A. It arises from sampling the autocorrelation
function along the axes defined by the feature points with 100
samples per axis. These sample values can be interpreted in a
very intuitive way: The ith column of the matrix A arises from
recording the similarity function during a 180◦ -rotation of
one of the object’s instances around the rotation axis defined
by pi which we refer to as ri . This is illustrated in Figure 3 for
a chair model. The figure also shows the alignments of the
object with itself at the endpoints of the respective rotation
(i.e. the alignments at the feature points). As we can see in
Figure 3, the barycentre is not necessarily the optimal choice
as the centre of rotation. This problem will be solved in the
subsequent section.
Note that the feature vector can be visualized by means
of three curves, which we refer to as feature graphs. In
Figure 3 and in all subsequent figures containing feature
graphs, we use red/green/blue for the graph which arises
from the first/second/third feature point, respectively.

3.3. Optimization of the rotation centre
The centre of rotation should be optimized in a way that the
obtained feature points, which define the rotation axes, have
the highest significance. As a quality measure Q we take the
sum of the function values at the three feature points and
parameterize this measure by a point c:
3

Q(c) =

SAA (R(pi )T (c)),

(6)

i=1

where T is the 4 × 4-transformation matrix which performs
a translation by the vector −c. This matrix is multiplied by
the rotation matrix R (represented as 4 × 4-matrix using homogeneous coordinates) from the right so that the translation
is applied prior to the rotation. The strategy for the feature
extraction including the optimization of the rotation centre is
the following:

c 2010 The Authors
Computer Graphics Forum c 2010 The Eurographics Association and Blackwell Publishing Ltd.

2333

M. Martinek et al. / Rotational Symmetry Descriptor

Figure 3: (a) A chair object with its rotation axes using the barycentre as centre of rotation. The respective alignments at the
feature points as well as the corresponding feature graphs are also displayed. (b) The same with optimization of the rotation
centre. We can see that the significance of the features has improved after this optimization step. Especially the rotational
symmetry of fourth order at the seat is now perfectly reflected by the local maximum in the first feature graph.
1. Compute the feature points p1 , p2 and p3 starting with
the barycentre as the centre of rotation.

This section covers the details about the realization of these
strategies.

2. Use the feature points in Equation (6) and optimize the
centre c by maximizing Q(c). If no significant improvement is possible, go to 4.

Finding the first feature point can be formulated as a global
optimization problem in 2D. Due to the fact that we represent
rotations in a differentiable manifold of the SO(3), we can
use efficient local optimization methods based on gradients.
Because we have to consider a spherical domain we first
reformulate the similarity function S as a spherical function
Sˆ with a constant radial component:

3. Translate the two instances of the object so that the
new centre c coincides with the origin. Recompute the
feature points with this new centre and go back to 2.
4. Sample the three feature points according to Equation
(5) to obtain the feature vector.

The feature axes and the centre point are both optimized in
two iterative processes. The current iteration of the centre is
used to compute the new iteration of the feature points. Then,
these feature points are used to compute a new iteration of
the centre of rotation by means of Equation (6). These iterations are initialized with the barycentre as centre of rotation.
An example for an improvement due to the centre optimization is shown in Figure 3(b). The example shows that the
direction of the axes does not change significantly after the
centre optimization (only their order does). This behaviour
is quite common and the reason for that is two-fold. First,
the barycentre is rarely far away from the best rotation centre. Secondly, the rotational symmetry axes defined by the
feature points are very robust to perturbations of the rotation
centre. As a consequence, a re-computation of the feature
points is hardly necessary and the strategy converges after
a single iteration in most cases. The fact that the order of
the axes may flip after this optimization process also does
not require any correction in this stage as we will perform
a re-ordering of the feature points as a post-processing step
anyway. This strategy will be described in Section 3.5.

3.4. Implementation details
As for now, we have provided a definition of the three feature
points as well as a strategy to optimize the centre of rotation.

⎛

π · sin θ · cos φ

⎞

⎜
⎟
SˆAA (φ, θ ) = SAA (w) with w = ⎝ π · sin θ · sin φ ⎠
π · cos θ
and compute the gradient of Sˆ as follows:
⎛ ˆ
ˆ − h, φ) ⎞
S(θ + h, φ) − S(θ
⎟
⎜
π · 2h
⎟.
∇(θ, φ) = ⎜
⎝ S(θ,
ˆ φ + h) − S(θ,
ˆ φ − h) ⎠
π · sin θ · 2h
The ability to determine the gradient vector at each spherical
point, except for the poles, allows us to apply the conjugate
gradient method to obtain a local maximum on the hemisphere. However, we first need to determine a starting value
which will most certainly converge to the global maximum.
In most cases, it is not even necessary to find the global maximum in this stage, but only to find a significant maximum.
This is due to the fact that symmetry axes for man-made
objects mostly occur pairwise orthogonal. The true global
maximum is then one of the three feature points. The correct
order of the feature graphs is recovered in a post-processing
ordering strategy which will be described in Section 3.5. It
has turned out, that a sampling of the rotation sphere at 100
uniformly distributed points is sufficient to find a starting
point which converges to a significant maximum. Prior to
the conjugate gradient optimization, we rotate both instances
of the object so that the starting point lies on the equator

c 2010 The Authors
Computer Graphics Forum c 2010 The Eurographics Association and Blackwell Publishing Ltd.

2334

M. Martinek et al. / Rotational Symmetry Descriptor

Figure 4: Two door models with their respective feature
graphs. Due to the fact that the function value at all three
feature points is approximately at 1.0, the axes are ordered
in an inconsistent way.

according to the spherical coordinates. This avoids that we
fall into a pole during the optimization.
Finding the point p2 is only a 1D problem. The searching domain for this point is the equator line of the rotation
sphere which has the first feature point as pole. The maximum is found by sampling this circle line. We first sample
this domain with a rough sampling interval and the best sample point together with its two neighbouring samples serve
as initial interval for a golden section search.
The optimization of the centre of rotation is a 3D problem but it is totally sufficient to approach to the next local
maximum in each iteration. This is due to the fact that the
barycentre is a good initial guess for the optimal centre of
rotation. Furthermore, the rotation axes which we have computed by means of the feature points provide an eigensystem
of the object. The gradient of the rotation centre for the
local optimization is therefore computed along the axes of
this eigensystem rather that along the world coordinate axes
which can be aligned arbitrarily.
For the entire extraction of the feature vector, a total of
approximately 700 evaluations of the similarity function from
Section 2.1 is necessary. Because a single evaluation of this
GPU-implemented function takes approximately 1 ms on
our test hardware (Nvidia 8800 GTX), the entire extraction
process takes approximately 700 ms for a triangulated object.

3.5. Re-ordering the feature graphs
The three feature graphs which arise from plotting the
columns of the 3 × 100 shape descriptor are naturally ordered by the function value of the respective feature point.
However, if two or more feature points have approximately
the same value, the order of the feature points might be more
or less random, depending on which of the maxima is determined to be the global one. Figure 4 illustrates such a
situation.

A comparison of corresponding feature graphs in this case
would mistakenly lead to a high distance between the objects. A possible solution to this problem is to consider all
six permutations of the graphs and to pick the best one. However, this would scale the costs for an object comparison by
the factor 6, which can be crucial if the method is applied to
large 3D databases. We find a better solution to this problem
in performing a post-processing ordering. After the features
have been computed as described in Section 3.4, we posses
more information than just the values of the feature points.
We sum up all 100 values along each axis and thereby approximately obtain the area below each graph. This integral value
describes the amount of information in the respective graph
and has turned out to be a good key to re-sort the axes. It is
obvious that the feature graphs from Figure 4 will posses the
correct order after we apply the described re-ordering strategy. Experimental results have shown that this heuristic is as
successful as the consideration of all possible permutations.

4. Distance Metric
Now that we have introduced spatial features which can be
pre-computed for each 3D object, we can define a distance between objects by introducing a distance between two feature
vectors. Because the components of the vectors are sorted
in a consistent way, we can now compare two graphs of the
same order. A straightforward approach would be to sum up
the differences at each discrete point.
Let A and B denote the 3 × 100 matrices of the two objects
which we want to compare. We define the distance AB as
follows:
3
AB

=

100

|Ai,j − Bi,j |.

αi
i=1

(7)

j =1

The parameters αi are employed to take into account the
fact that the significance of the axes decreases with increasing order. Therefore, feature graphs with a lower order should contribute more to the distance metric than the
higher-ordered graphs. To find the optimal values for these
parameters, we performed an exhaustive brute-force strategy in various test databases. It has turned out, that the values α1 = 0.42, α2 = 0.33 and α3 = 0.25 provide the best
overall retrieval results which confirms our assumption that
lower-ordered feature graphs have more significance. However, comparing corresponding function values alone does
not enfold the full potential of the feature graphs because
this comparison does not take the relative behaviour of the
graphs into account which is also an important factor of the
descriptor. Therefore, we also compare the derivatives which
we obtain by means of central differences. For an element
Ai,j i ∈ [1..3], j ∈ [2..99], the derivative is computed as follows:
Ai,j =

Ai,j +1 − Ai,j −1
.
2·h

c 2010 The Authors
Computer Graphics Forum c 2010 The Eurographics Association and Blackwell Publishing Ltd.

M. Martinek et al. / Rotational Symmetry Descriptor

2335

Figure 6: Objects with a high degree of rotational symmetry
(left panel) have the property that the second and the third
feature graph coincides while the first is approximately a
straight line. This leads to a significant loss of distinguishing power. In case of objects with thin parts (right panel),
the feature graphs show a noisy behaviour on a very low
level.

Figure 5: For each class, the feature graphs of four representative objects are visualized. While the distinction between
different classes is clear, objects from the same class show
similar behaviour in their respective feature graphs.

with h being the sampling interval. Because we sample the
range [0, π ] with 100 sample points, the value for h in our
case is π/99. The distance between two feature vectors
becomes the sum of the distances between corresponding
derivative values:
AB

=

50
·
π

3

99

|Ai,j +1 − Ai,j −1 − Bi,j +1 + Bi,j −1 |.

αi
i=1

j =2

(8)

The final distance metric is a weighted combination of the
two measures from Equations (7) and (8):
d(A, B) = s ·

AB

+ (1 − s) ·

AB .

(9)

It turned out that the relative behaviour which we capture by
the derivatives, is more important than the absolute function
values. A value for s of 0.25 has rendered the best results.

5. Results
The proposed feature vector consists of three graphs, which
reflect the rotational autocorrelation of the underlying geometry. It is very suitable for shape matching because it reveals
significant differences between uncorrelated objects while
same-class objects posses similar feature graphs. Figure 5
provides examples of different object classes with their respective feature graphs.

5.1. Limitations
Before demonstrating the advantages of our feature vector,
we address some limitations. Because the basis for our fea-

ture vector is rotational symmetry, there are two types of
properties of an object which limit the performance of our
method: too much and too little rotational symmetry. The
first property leads to a loss of distinguishing power. Objects
with an approximately perfect symmetry axis possess almost
the same feature graphs despite the fact that the geometry of
the objects can be quite different. This is illustrated in the
two objects to the left of Figure 6.
The objects to the right of Figure 6 have feature graphs
which contain only little information due to the absence of
rotational symmetry. This behaviour is significant for models
with exclusively thin parts. In a similarity measure, which is
based on overlapping regions, only in rare cases do we find
significant function values in the rotation sphere because thin
parts can easily miss each other.
Retrieval results with classes belonging to one of these
extreme cases will not be too promising using our feature
vector. However, these cases are well predictable. If the values of all three feature points are close to zero, we know
that the corresponding object has no significant rotational
symmetries. If the first feature graph shows almost a straight
horizontal line, we have detected an object with a perfect
rotation axis. A query object which belongs to one of these
cases can automatically be rated as unsuitable for our feature vector and a method which is not based on symmetry
features should be used instead. A detailed analysis of our
method with respect to database queries is performed in the
subsequent section.

5.2. Database queries
To evaluate the quality of our shape descriptor for database
queries, we use the Princeton Shape Benchmark (PSB)
[SMKF04], which provides 1814 classified models along
with some software tools to perform quality benchmarks.
The results of various database queries are depicted in
Figure 7. It can be observed that our method provides satisfying results for different kinds of object classes. Nevertheless,

c 2010 The Authors
Computer Graphics Forum c 2010 The Eurographics Association and Blackwell Publishing Ltd.

2336

M. Martinek et al. / Rotational Symmetry Descriptor

Figure 7: Examples for various database queries using our feature vector for object comparison. The leftmost object is the
query while the rest of the respective row depicts the best matches in ascending order.

there are some outliers in the case of the bench in row 4 and
the drinking glass in row 5. They result from the limitations
described in Section 5.1.
As mentioned before, many existing approaches use shape
descriptors which are not rotation-invariant by definition.
These methods have to rely on a good initial alignment of
the objects which is commonly obtained by PCA. For evaluation purposes we can use the function as introduced in
Section 2.1 as measure because it provides the similarity
between two objects if they are perfectly aligned. We have
measured the distance between two models in two different ways: (i) We normalized the objects in the database by
means of PCA alignment and measured the similarity by
applying the similarity function from Section 2.1. (ii) We
pre-computed the feature vectors for the entire database and
used the distance metric from Section 4 to compare two objects. We refer to the feature vector as rotational symmetry
descriptor (RSD).

Figure 8: Precision-recall plot for the test classification of
the PSB for the RSD (with and without centre optimization)
and a combination of PCA and the similarity function from
Equation (3).

The results are shown as a precision-recall plot in
Figure 8. It turns out that our technique provides better results
than PCA-based normalization, even if we use the barycentre
of the objects as rotation centre throughout the method. The
full algorithm with the centre optimization provides another
significant improvement of the retrieval quality.

We evaluated these quality measures for our rotational
symmetry descriptor using the test classification of the PSB.
Table 1 lists a few samples of a class-wise evaluation. It
shows, that the quality is not uniformly distributed across the
object classes.

The PSB is a benchmark tool which is widely applied by researchers to evaluate the quality of a shape matching method.
The most common quality measures are nearest neighbour
(NN), first-tier (FT) and second tier (ST) and the discounted
cumulative gain (DCG). For a description of these measures,
we refer to [SMKF04].

This is not surprising according to the limitations of our
method for objects with too much or too less rotational symmetry. In fact, the tires in row 5 clearly belong to the first
category while the bush-class is a member of objects with no
rotational symmetries. The other entries of the table reveal
excellent query results.

c 2010 The Authors
Computer Graphics Forum c 2010 The Eurographics Association and Blackwell Publishing Ltd.

M. Martinek et al. / Rotational Symmetry Descriptor

2337

Table 1: Quality measures for different classes in the PSB testclassification.

Airplane
Human
Chair
Guitar
Tire
Bush

NN (%)

FT (%)

ST (%)

DCG (%)

90.0
90.0
81.8
84.6
25.0
11.1

60.0
62.1
52.7
51.3
16.7
30.6

74.4
79.3
68.2
53.2
16.7
45.8

83.6
89.3
81.2
74.6
39.2
50.6

Figure 9: The number of local maxima in the first feature
graph can be used to distinguish between a square, a hexagonal and an octagonal base area of the three bolts.

Table 2: Comparison of our method to other approaches.

DLA–DPD
RSD
LFD
SHD
D2
RSD–LIM

NN (%)

FT (%)

ST (%)

DCG (%)

66.7
64.9
65.7
55.6
31.1
68.1

39.5
37.5
38.0
30.9
15.8
40.3

50.2
50.3
48.7
41.1
23.5
53.3

65.3
64.6
64.3
58.4
43.4
67.4

Note: The values for the LFD-, the SHD- and the D2-descriptor are
taken from table 4 in [SMKF04], whereas the result for the DLADPD was taken from figure 5 in [CVB07].

An accumulated measure over 92 different classes of the
PSB base test classification was performed for our RSDdescriptor and compared to various existing approaches
which have been evaluated on the same data set. The D2shape distribution (D2) [OFCD01], the spherical harmonic
descriptor (SHD) [KFR03, CVB07] the light field descriptor (LFD) [CTSO03] and the depth line approach with dynamic programming distance (DLA-DPD) [CVB07]. The latter method was a winner in the Shape Retrieval Contest 2009
[GDA∗ 09]. Table 2 shows the results of the comparison. An
additional row (RDS-LIM) shows another test run of our descriptor with enabled filtering. The method filtered out the
classes which were automatically rated as unsuitable according to the limitations described in Section 5.1. A total of eight
classes were filtered out in this way.
Our shape descriptor applied to the entire range of objects
outperforms the SHD and the D2 descriptor and is competitive to the light field descriptor. The newest of the compared
methods, the depth line descriptor, is superior for the entire
range of objects in the PSB test classification. However, our
method is able to automatically filter out object classes for
which it is not suited and applying this filtering (approximately 7% of the objects were filtered out) provides the best
results over all compared methods. In case of the filtered
classes, a combination with a method which does not use
rotational symmetry features can be applied to achieve good
query results over the entire range of objects. Because our de-

scriptor is orthogonal to most existing shape features, it can
be perfectly combined with other methods to significantly
improve the discrimination power.
5.3. Classification
Most existing feature vectors are bare mathematical descriptions, which are only suitable for the definition of a distance
between 3D objects. In contrast to that, the features proposed
here can be visualized by three graphs which provide valuable information about the objects. Consider the graphs in
Figure 5. In case of the chessboard, for example, the fact
that the first graph shows a strong maximum at π/2 tells us
that the object has a rotational symmetry of 4th order and
must therefore have a rectangular base area. In addition, the
fact that the second and third graph decline to almost zero at
π/2 implies that the object is very thin. In case of the brains,
we observe that the graphs are quite flat which indicates a
rather spherical shape.
Thus, we can roughly describe the geometry of an object
by only considering its feature graphs which provides the
possibility to perform classifications in a 3D database without
a query object. In a database which consists of bolts, for
example, we can easily classify the objects by considering
the first feature graph. Figure 9 provides an illustration of this
example. We can see, how the first feature graph perfectly
reacts on the different base areas of the bolts.
6. Conclusion and Future Work
In this paper, we have introduced a 3D shape descriptor,
which captures significant properties of an object with respect
to rotational symmetry. Our method is based on a function
which reflects the match of two objects at their current alignment. Instead of using this function as a similarity measure
by relying on global alignment techniques, we use it to define an autocorrelation of 3D objects in the space of rotations.
This is achieved through application of the function on two
instances of the same object. We determine three significant
rotation axes and sample the function values during 180◦ rotations around these axes. The resulting sample values can be

c 2010 The Authors
Computer Graphics Forum c 2010 The Eurographics Association and Blackwell Publishing Ltd.

2338

M. Martinek et al. / Rotational Symmetry Descriptor

plotted to form three feature graphs, which reflect important
geometric properties of a 3D object. While these graphs can
be used to characterize objects with respect to rotational symmetry, we also defined a measure of similarity between 3D
objects by comparing corresponding feature graphs by means
of their values as well as their derivatives. Experimental results have shown, that our shape descriptor is competitive
to state-of-the-art methods despite the fact that it is solely
based on rotational symmetry. In the future, we will improve
the descriptor by combining it with descriptors from other
fields. We expect good results because symmetric properties
are orthogonal to most existing descriptors. Concerning the
distance metric, which we defined on our shape descriptor,
we will experiment with more elaborate techniques from the
field of signal processing to compare corresponding feature
graphs. This may reflect more accuracy than the comparison
of the derivatives and function values.

References
[AKKS99] ANKERST M., KASTENMU¨ LLER G., KRIEGEL H.P., SEIDL T.: 3D shape histograms for similarity search
and classification in spatial databases. In SSD (Springer,
1999), pp. 207–226.
[BCG08] BEN-CHEN M., GOTSMAN C.: Characterizing shape
using conformal factors. In 3DOR (2008), pp. 1–8.
[BMP02] BELONGIE S., MALIK J., PUZICHA J.: Shape matching
and object recognition using shape contexts. IEEE Transactions on Pattern Analysis and Machine Intelligence 24
(2002), 509–522.
[CDS*05] CORNEA N. D., DEMIRCI M. F., SILVER D.,
SHOKOUFANDEH A., DICKINSON S. J., KANTOR P. B.: 3D
object retrieval using many-to-many matching of curve
skeletons. Shape Modeling and Applications (International Conference) (2005), 368–373.
[CTSO03] CHEN D.-Y., TIAN X.-P., SHEN Y.-T., OUHYOUNG
M.: On visual similarity based 3d model retrieval. Computer Graphics Forum 22, 3 (2003), 223–232.
[CVB06] CHAOUCH M., VERROUST-BLONDET A.: Enhanced
2d/3d approaches based on relevance index for 3d-shape
retrieval. In SMI ’06: Proceedings of the IEEE International Conference on Shape Modeling and Applications
2006 (Washington, DC, USA, 2006), IEEE Computer Society, p. 36.
[CVB07] CHAOUCH M., VERROUST-BLONDET A.: 3d model retrieval based on depth line descriptor. IEEE International
Conference on Multimedia and Expo (2007).
[FMK*03] FUNKHOUSER T., MIN P., KAZHDAN M., CHEN J.,
HALDERMAN A., DOBKIN D., JACOBS D.: A search engine

for 3d models. ACM Transactions on Graphics. 22 (2003),
83–105.
[GDA*09] GODIL A., DUTAGACI H., AKGA˜ L C. B.,
AXENOPOULOS A., BUSTOS B., CHAOUCH M., DARAS P.,
FURUYA T., KREFT S., LIAN Z., NAPOLEON T., MADEMLIS A.,
OHBUCHI R., ROSIN P. L., SANKUR B., SCHRECK T., SUN X.,
TEZUKA M., VERROUST-BLONDET A., WALTER M., YEMEZ Y.:
Shrec’09 track: Generic shape retrieval. In 3DOR (2009),
Eurographics Association, pp. 61–68.
[HSKK01] HILAGA M., SHINAGAWA Y., KOHMURA T., KUNII
T. L.: Topology matching for fully automatic similarity
estimation of 3d shapes. In SIGGRAPH ’01 Proceedings
(2001), pp. 203–212.
[IAP*08] ION A., ARTNER N., PEYRE G., LOPEZ MARMOL S.,
KROPATSCH W., COHEN L.: 3d shape matching by geodesic
eccentricity. In S3D08 (2008), pp. 1–8.
[ILSR02] IP C. Y., LAPADAT D., SIEGER L., REGLI W. C.:
Using shape distributions to compare solid models. In
SMA ’02: Proceedings of the Seventh ACM Symposium on
Solid Modeling and Applications (2002), ACM, pp. 273–
280.
[Kaz07] KAZHDAN M.: An approximate and efficient method
for optimal rotation alignment of 3d models. IEEE Transactions on Pattern Analysis and Machine Intelligence 29
(2007), 1221–1229.
[KCD*03] KAZHDAN M., CHAZELLE B., DOBKIN D.,
FUNKHOUSER T., RUSINKIEWICZ S.: A reflective symmetry descriptor for 3d models. Algorithmica 38 (2003),
201–225.
[KFR03] KAZHDAN M., FUNKHOUSER T., RUSINKIEWICZ S.:
Rotation invariant spherical harmonic representation of
3d shape descriptors. In SGP’03: Proceedings of the
2003 Eurographics/ACM SIGGRAPH Symposium on Geometry Processing (2003), Eurographics Association,
pp. 156–164.
[KFR04] KAZHDAN M., FUNKHOUSER T., RUSINKIEWICZ S.:
Symmetry descriptors and 3d shape matching. In ACM
SIGGRAPH Symposium on Geometry Processing (2004),
ACM, pp. 115–123.
[KPNK03] K¨ORTGEN M., PARK G. J., NOVOTNI M., KLEIN R.:
3D shape matching with 3d shape contexts. In The 7th
Central European Seminar on Computer Graphics (April
2003).
[LKM07] LU Y., KANEKO K., MAKINOUCHI A.: Using a partial geometric feature for similarity search of 3d objects.
Information and Media Technologies 2 (2007), 1181–
1189.

c 2010 The Authors
Computer Graphics Forum c 2010 The Eurographics Association and Blackwell Publishing Ltd.

M. Martinek et al. / Rotational Symmetry Descriptor

2339

[MD03] MAKADIA A., DANIILIDIS K.: Direct 3d-rotation estimation from spherical images via a generalized shift
theorem. In CVPR (2) (2003), pp. 217–226.

using a concrete radialized spherical projection representation. Pattern Recognition 40, 9 (2007), 2437–
2452.

[MG09] MARTINEK M., GROSSO R.: Optimal rotation alignment of 3d objects using a gpu-based similarity function.
Computer Graphics 33, 3 (2009), 291–298.

[PPT*08] PAPADAKIS P., PRATIKAKIS I., THEOHARIS T., PASSALIS
G., PERANTONIS S.: 3D object retrieval using an efficient
and compact hybrid shape descriptor. Eurographics Workshop on 3D Object Retrieval (2008), 9–16.

[MGP06] MITRA N. J., GUIBAS L., PAULY M.: Partial and
approximate symmetry detection for 3d geometry. ACM
Transactions on Graphics 25, 3 (2006), 560–568.
[MSHS06] MARTINET A., SOLER C., HOLZSCHUCH N., SILLION
F.: Accurate detection of symmetries in 3d shapes. ACM
Transactions on Graphics 25, 2 (April 2006), 439–464.
[NASO07] NAPOLE´ ON T., ADAMEK T., SCHMITT F., O’CONNOR
N. E.: Multi-view 3d retrieval using silhouette intersection
and multi-scale contour representation. SHREC 2007—
Shape Retrieval Contest (2007), 33–37.
[NK04] NOVOTNI M., KLEIN R.: Shape retrieval using
3d zernike descriptors. Computer-Aided Design 36, 11
(2004), 1047–1062.
[OFCD01] OSADA R., FUNKHOUSER T., CHAZELLE B., DOBKIN
D.: Matching 3d models with shape distributions. In Proceedings of SMI ’01 (2001), IEEE Computer Society,
p. 154.
[OMT03] OHBUCHI R., MINAMITANI T., TAKEI T.: Shapesimilarity search of 3d models by using enhanced shape
functions. In TPCG (2003), pp. 97–104.

[PSG*06] PODOLAK J., SHILANE P., GOLOVINSKIY A.,
RUSINKIEWICZ S., FUNKHOUSER T. A.: A planar-reflective
symmetry transform for 3d shapes. ACM Transactions on
Graphics 25, 3 (2006), 549–559.
[SMKF04] SHILANE P., MIN P., KAZHDAN M. M., FUNKHOUSER
T. A.: The princeton shape benchmark. In SMI (2004),
pp. 167–178.
[SSGD03] SUNDAR H., SILVER D., GAGVANI N., DICKINSON S.
J.: Skeleton based shape matching and retrieval. In Shape
Modeling International (2003), pp. 130–142, 290.
[SV01] SAUPE D., VRANIC D. V.: 3d model retrieval with
spherical harmonics and moments. In Proceedings of the
23rd DAGM-Symposium on Pattern Recognition (London,
UK, 2001), Springer-Verlag, pp. 392–397.
[VKTP04] VAJRAMUSHTI N., KAKADIARIS I. A., THEOHARIS T.,
PAPAIOANNOU G.: Efficient 3d object retrieval using depth
images. In Multimedia Information Retrieval (2004),
pp. 189–196.

[ONT03] OHBUCHI R., NAKAZAWA M., TAKEI T.: Retrieving
3d shapes based on their appearance. In Multimedia Information Retrieval (2003), pp. 39–45.

[Vra03] VRANIC D. V.: An improvement of rotation invariant 3d shape descriptor based on functions on concenrtic
spheres. In Proceedings of the IEEE International Conference on Image Processing (2003), IEEE Computer Society, pp. 757–760.

[PPPT07] PAPADAKIS P., PRATIKAKIS I., PERANTONIS S. J.,
THEOHARIS T.: Efficient 3d shape matching and retrieval

[Vra05] VRANIC D. V.: Desire: A composite 3d-shape descriptor. In ICME (2005), pp. 962–965.

c 2010 The Authors
Computer Graphics Forum c 2010 The Eurographics Association and Blackwell Publishing Ltd.

