The MOSTImmersive Approach for
Parallel and Distributed Program Analysis
Bernhard Reitinger, Dieter Kranzlmiiller, Jens Volkert
GUP Linz, Johannes Kepler University Linz
Altenbergerstr. 69, A-4040 Linz, Austria/Europe
reitinger@gup.uni-1inz.ac.at

Abstract

graphics technology and the disciplines of graphic design,
typography, color, cinematography, animation, and sound
to enhance the comprehension of algorithms and computer
programs [2]. One of the definitions for visualization tries
to explain it as a mental image or vision of something not
actually present to sight [ I 11 in order to improve the understanding of programs and their executions [ 121.
In our project two different types of visualization are distinguished:

Examining a program’s state during execution is of major importance for software developers when analyzing an
applicationfor pegormance tuning or error detection. This
demandfor suitable analysis tools is further pushed by parallel and distributedprograms, which process huge amounts
of complex data. A solution to this problem is offered by visualization, such that even large amounts of data can be
presented eficiently for the user ’s investigations. This paper presents an immersive approach, where monitoring and
steering activities combined with Virtual Reality visualization components help the user to understand the behavior
of running parallel and distribu,ted programs. On the one
hand, program visualization tries to induce a ‘yeeling”for
program. On the other hand, data visualization provides a
facility to display preliminary results of any kind of scientific calculations.

Program visualization

0

Data visualization

The former tries to express the behavior of a running parallel program with the main idea of using visualization and
associated forms of sensory modalities to find an answer for
the question:

Where to set the starting point for in-depth
program analysis tasks?
This question is especially difficult for large scale parallel programs with long execution times, where the amount
of analyzed data can easily overload the user and the analysis tool. Data visualization offers some techniques for
on-line visualization of application-specific data structures.
With the aid of an existing library, an extensible framework
for displaying arbitrary data sets of any dimension is provided. This approach should help the user to evaluate preliminary results of a calculation or simulation running as a
parallel application.
The basic strategy of our approach can be described with
a simple example. We assume, that an arbitrary scientific
application is already running on some high-performance
computing (HPC) system. At some time during its execution, the user decides to investigate the program’s current
state, which initiates the following steps (as presented in
Figure 1):

1. Introduction
Scientific applications in the field of molecular biology, chemistry, astronomy, or physics often produce huge
amounts of data, which are processed by parallel and distributed programs on high-performance computing systems.
The computation time of such applications may last for
hours, days, weeks, or even months. These issues have
inspired the development of a set of tools comprising the
MOST (Monitoring and Steering) environment, which allows to interact with such kinds of programs. MOST tries
to support users during various stages of the software lifecycle such as performance tuning and error detection. This
is achieved by incorporating different kinds of visualization
features in order to cope with the complexity of multiple
concurrently executing and communicating tools [ 101.
In this context, software visualization can be defined as
the systematic and imaginative use of interactive computer

1. The main user interface of MOST (called MOST++)

is initialized on a graphics workstation.

517
0-7695-1195-3/01 $10.00 0 2001 IEEiE

0

MOST++

provides an intuitive command center which performs
analysis tasks on the running program.
2. The user logs into the HPC system by starting the software monitor, which attaches itself to the selected target application.

3. The user is now able to control the target application
and starts downloading program state information.
4. The observed data is presented to the user in a certain
way, which in turn tries to identify critical points for
in-depth investigation.

Figure 2. Visualization components of Most
the MOST environment. The next section gives a brief
overview of these visualization components and outlines
their role within the MOST project. Therefore it briefly discusses our communication network, which is used to provide flexible and efficient data transmission between different concurrent components. Section 3 focuses on program
visualization including Virtual Reality aspects and voice
control, while Section 4 explains the second visualization
components of the MOST environment and discusses its
benefits for the user. Afterwards a discussion about some
future work and a conclusion summarizes this paper.

5 . After these critical points have been identified, indepth analysis is initiated, revealing more and more
information about the program’s state and increasing
the user’s knowledge. Moreover, preliminary results
computed by the target application are accessible.

6. Eventually, the user identifies some key parameters,
and changes their values.
7 . After the changes have been committed, MOST is de-

tached from the target application and awaits future
initiation.

2. hteraction between MOSTcomponents
The MOST environment consists of several modules
which allow to monitor and steer applications during execution on HPC systems [7]. Each module operates independently and is connected via standard sockets to all other
modules. This paper is focused on the visualization components of MOST (see Figure 2)

I.

Start

2. 3.

Monitoring

4.

Program visualization

5.

Data visualization

6.

w
I+

MOST-I - program visualization, and

Q

MOST-VIS-data visualization.

‘The input for both tools is provided by the PREMOST
module, which is attached to the HPC application and monitors its execution (for details see [6]).
The intention of MOST-I is to improve the understanding of a program’s behavior by mapping the extracted activity information onto a suitable graphical representation.
By utilizing a Virtual Reality (VR) environment, the impression of the program should be supported by the arising immersion. For MOST, we use the CAVE (CAVE Automated Virtual Environment), a multi-person, room-sized,
high-resolution, 3D video and audio environment developed
at the EVL (Electronic Visualization Laboratory, University
of Illinois at Chicago) in 1992 [ 3 ] .
MOST-VIS offers several visualization possibilities for
analyzing complex multi-dimensional data structures distributed across the processes of the target application. By
using a third-party visualization library and a modular design, MOST-VIScan be easily integrated with any arbitrary
scientific application.

Steering

7.

0

Figure 1. Sample scenario of Most
For the rest of this paper we concentrate on the two different visualization components, which are integrated in

518

AI1 components of MOST work concurrently and possibly distributed among several computers. Their connection is established by an efficient network communication
mechanism to transmit the data streams generated by the
MOST components. Each component plays either the role
of a server or a client. In c0ntras.t to todays often used object request brokers (ORBS) like CORBA or the JAVA ORB,
MOST does not send objects over the network. Instead, the
data is just one byte stream being in compressed or uncompressed form, as in nearly every web application nowadays.
In particular, the MOST cominunication network combines several facilities like standixd UNIX sockets and the
clientkerver model to provide an easy-to-use framework.
As soon as communication is started between two entities,
a special parser receives the byte stream, verifies, and processes it. In order to address parallel and distributed programs, the server must be capable of receiving several data
streams in parallel. Whenever a client requests a connection, the server creates a new thread to handle its requests.
The correctness of each data stream is controlled by
a communication protocol MoCoP (see Figure 2). Any
streams which do not confirm to this protocol are not accepted by the client or the server. MoCoP is a pre-defined
grammar in BNF form and is interpreted by the UNIX tools
yacc a n d j e x , which offer a high degree of flexibility and
extensibility.

This formula computes the accumulated activity of a single memory cell i between [tmin,t,,,]. This formula can
be scaled to a complete process within the given time interval as follows:

With both formulae the activity of arbitrary areas or
memory blocks, of distinct processes, or even a complete
program can be determined. However, the problem of this
approach is, that each memory cell has to be obtained iteratively by the monitor in order to compare it to its previous
values. This may be a big obstacle, if large programs processing huge amounts of data are considered. As a consequence, instead of comparing single memory cells, memory
blocks with a definable granularity level are computed and
the level of granularity can be adapted at runtime.
One of the biggest problem of our approach was to find a
suitable representation for this kind of data. During a brainstorming session several viable ideas have been collected,
some of which have been discussed and evaluated afterwards. The most suitable approach is the so-called activity
runnel, which tries to represent the activity of a running parallel program with a 3-D tube. The activity tunnel consists
of N stripes, where each stripe represents the memory content of one process. The tunnel starts with memory block 0
and ends up with memory block n. The shading of the tunnel (or the color respectively) represents the measured activity in particular memory regions and may change during
instrumentation. Figure 3 shows a sample analyzing session, where the user is inspecting the behavior of the targetapplication. The brighter regions (more red respectively)
express high program activity, whereas the darker regions
(more blue respectively) mean less activity.
In addition to the behavioral representation, communication visualization is also applied. This is done by connecting the message buffers of the sending process with the
message buffer of the receiving process. Therefore, a fictitious communication channel in the middle of the tunnel
is used to represent the physical media between the sender
and receiver node. All communication is transferred over
this main channel.
Whenever a communication statement is executed, each
send event is represented by a green cylinder, drawn from
the memory location of the corresponding buffer straight
to the communication channel. On the contrary, a receive
event is displayed in yellow as a cylinder from the memory
location of the message buffer to the corresponding sending
event in the message channel. A dedicated thread, acting as
a message collector, removes both cylinders after a certain
amount of time determined by the duration of the communication operation.

3. Program Visualization
Before in-depth analysis of a program can be performed,
the user has to locate the hot-spots of the running program.
Therefore, activity information is obtained during the program's execution, which requires some kind of instrumentation [6]. The obtained data is then transmitted on-line to
the program visualization tool.
In our context, activity information describes the program's behavior by dividing the content of the memory of
each process into areas of different activity levels. This
means, that the number of accesses to memory blocks containing code- and data-segments are counted and evaluated
by our monitor.
The activity a z ( t )of each memory block i (or cell respectively) at a certain time t is 0, if the: memory block is not accessed, or I , if it has been accessed recently. This activity is
observed over a given interval of time [tmin,t,,,], so that
memory locations with many accesses will yield higher activity values. Since an arbitrary area of a program consists
of n such memory cells, its normalized level of activity A;
can be computed as follows:

5 19

Figure 3. Controlling the activity tunnel
through voice-input
Figure 4 shows an inspected parallel program running on
8 processes. Process 0 broadcasts a message and the slaves
receive it according the location in the message channel.
When the transmission has finished, all message events are
collected and removed from the tunnel.
In addition to the graphical representation, we also offer mappings to other sensory modalities. One example is
sound, which was originally inspired by the following story
about the Whirlwind computer (1950) [ 5 ] : “You even had
audio output in the sense that you could hear the program
because there was an audio amplijer on one of the bits of
one of registers - so each program had a signature. You
could hear the tempo of how your program was running.
You could sense when it was running well, or when it wus
doing something surprising.” Similar ideas are presented
in [4].
By integrating sound output in MOST,we try to emphasize the activity of a program in the region of the tunnel,
that is currently inspected by the user. Another idea is to
include sonification of hardware performance counters, the
program counter, and similar state data.
Besides the idea of auralization, MOST-I also includes a
voice input processing system, which controls the behavior
of the analysis tool. Additionally to common input-devices
like mouse or joystick, speech recognition can open new
possibilities in controlling the application. Ordinary devices
restrict the user in the number of control sequences, which is
a real drawback of interactive applications. The voice control system interprets natural spoken commands as steering
commands for the environment.
Figure 3 shows the user wearing a microphone steering the application. A typical command is “next level”
which tells the environment to show the next level of activity granularity. Another command offers a so-called “warp-

Figure 4. Activity tunnel showing communication channels
mode” where the user is guided through the tunnel automatically, which offers benefits for inspecting the whole memory without giving additional commands.

4. Data Visualization
After the program analysis step has been performed, the
user can start with in-depth investigations t o pct preliminary results of the target application. Therefore, symbol
table information is needed to extract application specific
data structures. Based on this information, interesting parts
of the running program can be selected. This selected data
is then extracted by the monitor and is either displayed immediately in a textual manner, or forwarded to the data visualization module.
The graphical representation provided by this modulc
depends on the processed data of the scientific application.
Hence, an existing visualization library to offer different
techniques has been integrated. At present, the IBM’s Open
Data Explorer (OpenDX) [ 11 is used while similar functions
are currently developed for AVSlExpress [9]. The output of
these tools is viewed on standard 2-D screens. However, we
are developing dedicated modules for both, OpenDX and
AVS, to direct their output to 3-D Virtual Reality cnvironments. As soon as the work of these modules is completed,
we should be able to view all the results in the CAVE.
Before the data is sent to the visualization module, the
user has to specify the semantic meaning of the extracted
data. In particular, a f l o a t ” may contain valucs corresponding to a 1-D field, or values corresponding to a

520

PreMoSt

;Most++

Proc.

Proc.

.......
Proc.

U

U

data
specification

data
composition
technique
selection

Figure 6. Data field showing some errors

Figure 5. Combining the data of concurrently
operating processes

5. Conclusion and Future Work
2-D field. This information is neither stored in the program’s source-code, nor in the symbol table. Another important aspect is the data distribution of the target application. Since we address parallel programs, the data is partitioned in a certain way. Before the visualization component
can display the whole calculation’s data, the user has to reensemble the distributed parts according to the initial distribution. All these pre-steps (data specification, data composition, and technique selection) performed by the user
within the GUI of MOST are shown in Figure 5.
After these two steps, the visualization module is ready
to display the data using the technique belonging to the application’s processed data. Figure 6 shows a screenshot produced by MOST while the target application was actually
calculating the result for Poisson’s equation. The algorithm
of this solver operates on an an-ay f and performs iteratively operations on each element o f f based on its previous
values according to the following formula [8]:

This paper describes the MOST environment for analyzing parallel and distributed programs. Of major importance
are the on-line visualization modules, which try to improve
the user’s analysis activities. Program visualization concentrates on the activity data observed during the target application’s execution, which is used to identify critical points
for in-depth investigations. This task is further improved by
exploiting VR technologies.
After hot-spots have been identified, data visualization
is used to display concrete values as processed by the program. With this information, the user’s knowledge of an
application’s behavior is increased, which is necessary before conducting changes to the values of selected variables.
By performing all these activities on-the-By, time consuming termination and restart cycles can be reduced.
The VR visualization of activity data may seem a little bit controversial. However, the problem of leading the
user to an suitable starting place for in-depth investigations
is very important, and there is only limited support from
related work in this area. Nevcrtheless, it is certainly necessary to assess the usefulness of the current approach for
real-world applications, and to continue studying this important aspect.
As far as the data visualization component is concerned,
additional visualization techniques have to be implemented
to cover a wide variety for scientific application. Moreover we believe, that Virtual Reality environments will offer
some novel insights into the visualized data structures.

The parallelization step is rather straightforward. The
whole array is partitioned into smaller pieces and each piece
is assigned to one process. Since the dependency to the
neighboring elements is present, overlapping borders must
be appointed in order to get the ekment values of neighboring processes.
The picture displays the heat-diagram of such an array
which was not calculated correclly. Obviously, the target
application had problems with the border exchange between
neighboring processes. With MOST-VIS,these errors can
be detected easily during the program’s execution, which
may otherwise require much effort in their localization.

Acknowledgments
Several of our colleagues contributcd to the work described in this paper, and we arc MOST thankful to the rest
of the MOST-Team, Christian Glasner and Roland Hugl.

52 1

References

[7] D. Kranzlmuller, B. Reitinger, and J. Volkert. Experiencing a program's execution in the CAVE. In Proceedings of
the IASTED International Conference on Parallel and Distributed Computing and Systems (PDCS), volume 1, pages
259-264, November 2000.
[SI D. Kranzlmuller, C. Schaubschlager, and J. Volkert. Ar-

[ l ] G. Abram. OpenDX Overview. In Visualization Development Environments 2000, Princeton Plasma Physics Laboratory, April 2000.
[2] R. Baecker, C. DiGiano, and A. Marcus. Software visualization for debugging. Communications of the ACM, 40(4):4454, April 1997.
[3] C. Cruz-Neira, D. Sandin, T. DeFanti, and R. Kenyon. The

ray visualization for parallel program debugging.
In
PDPTA '2000, volume 5 , pages 26 15-262 1. CSREA Press,
June 2000.
[9] F. Lin, S . Larkin, A. Grant, and R. Slinger. AVS/Express
fisualization Edition. University of Manchester, 1996.
[ 101 C. Pancake. Visualization techniques for parallel debugging
and performance-tuning tools. In A. Zomaya, editor, Parallel Computing: Paradigms and Applications, pages 376393. Intl. Thomson Computer Press, 1996.
[ 1I] J. Stasko, J. Dominigue, M. Brown, and B. Price. S o f i u r e
Visualization. MIT Press, 1998.
[12] K. Zhang, X. Ma, and T. Hintz. The role of graphics in
parallel program development. Journal of Visual Languages
and Computing, 10(3):215-243, June 1999.

CAVE: audio visual experience automatic virtual environment. In Communications of the ACM, volume 35, pages
64-72, 1992.
[4] J. Francioni and J. Jackson. Breaking the silence: Auralization of parallel program behavior. Journal of Parallel and
Distributed Computing, 18:181-194, 1993.
[5] K. Frenkel. An interview with Femando Jose Corbatb. Communications of the ACM, 34(9):83-90, September 1991.
[6] D. Kranzlmiiller, C. Glasner, and J. Volkert. Premost - on-

the-fly monitoring and steering of parallel programs.

In

Proc. PDPTA 2001, Intl. Conferencer on Parallel and Distributed Processing Techniques and Applications, Las Vegas, Nevada, USA, June 2001 (to appear).

522

