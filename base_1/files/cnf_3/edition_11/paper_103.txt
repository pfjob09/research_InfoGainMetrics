Slice-Based Virtual Endoscopy Navigation
Hai Linl ', Gordon J. Clapworthy', Feng Dong', Meleagros Krokosl, Jiaoying Shi'

' Deparlment o f Computer & Information Sciences, De Montfort University,
Milton Keynes MK7 6HP, United Kingdom

{hlin, gc, fdong, melk} @dniu.ac.uk
'State K e y Lab of C A D & C G , Zhejiang University, Hangzhou 310027, C h i n a

(lin, jyshi] @cad.zjii.edii.cn

Absl ract
Nm~igntiotipnth plantiin): is a crircinl part of virtiral
endoscopy, but the ident$ccr~ion of the optimal jlytlirorrgh pntli is a tirue-intensi\,e process. This paper
describes N protorj'pe system for vit" enrioscop rind
proposes ii slice-based npproncli to calcirlating the purh
of the virtiral cuiiiera thnt iises the slice borderlines of
region-ofinrerest images 10 obtairi the nppro.x-iniate
cenirelitie, cetitriiliserl loctrli:\ rvitli respect io the hollo,~~
object ~ r r l l By
. irsing the 2 0 slice borderlines to e.xpress
the liollo\t. object hormtlar:~, the pcith searching and
polygon ir!tersection conipirting are sirtiplified cincl macle
ttiorc efficiotit. Finall!, we present resrrlts of oirr
dgoritliiti tesred on the Visible Hiunmi Dtrrri set.

1. Introduction
The visualisation of human organs employing 3D
imaging modalities, such as C T and MRI, has been
widely used for patient care. By making increasing use
of computer graphics techniques, virtual endoscopy [ 1 61, which combines the feat,ures of endoscopic viewing
and cross-sectional volumetric imaging, can provide
improvements in diagnosi:;, surgical planning and
endoscopic training.
Virtual endoscopy reconstructs a 3D virtual model of
the hollow organ and allows a physician to navigate
inside the modcl to detect anomalies. Compared to the
thousands of conventional endoscopic procedures
performed each year, the advantages of virtual
endoscopy are manifold. It is non-invasive, costeffective, and free of risks and side effects such as
perforation and infection. It could also improve

2. Related Work
There is already an extensive collection of work
relating to the control of the virtual camera and the
extraction of the fly-through path in virtual endoscopy.

711
0-7695-1195-3/01 $10.00 0 2001 IEEE

diagnostic sensitivity and be used to explore body
regions not accessible to conventional endoscopy [6].
In recent years, virtual endoscopy has become very
popular in medical visualisation. Several research groups
have proposed their virtual endoscopy systems in various
applications such as colonoscopy [2-41, bronchoscopy
[ 7 ] , or angiography [8].
While all of these systems focus on different
applications, they nevertheless have similar components
[5-61. Generally, most of the systems consist of the
following parts: data acquisition, segmentation, surface
extraction, navigation, surface and volume rendering.
Many papers have been published on each of these parts,
but considerable work still remains to be done. One of
thc main research topics at present is the fast and
automatic extraction of the fly-through path.
In this paper, we provide a prototype virtualendoscopy system, in which a slice-based method is used
to extract the fly-through path. By expressing a hollow
organ with slice borderlines of region-of-interest (ROI),
the pre-processing and calculation of the camera path are
simplified.
The related works for camera control and flight path
extraction are discussed i n Section 2 . In Section 3, we
give the overview of our virtual endoscopy system.
Section 4 discusses the slice-based generation of the flythrough path and the control of the virtual camera. Some
preliminary results based on the Visible Human Dataset
are given in Section 5 , and the work is summarised in
Section 6, along with pointers to future work.

removed while thinning. Hong et al [4] adopted the
potential field approach to path planning, in which the
potential
field
is
calculated
using
distance
transformation. This method has a major drawback - the
pre-processing for virtual colonoscopy takes many hours

Generally speaking, there are three main techniques
for virtual camera control [4][51[1 I]:
plunned navigation forces the camera to remain on
a pre-determined path; the viewer cannot adjust the
camera parameters, such as camera position, view
direction and field-of-view, so there is lack of
interactivit y.
manual navigation gives users complete control of
camera: the user can control the camera parameters
at every step and therefore can easily get lost,
especially inside the hollow organs.
guided navigation is a combination of planned and
manual navigation; the user moves the virtual
camera along the guided path and can control the
camera parameters when desired.
The guided navigation method is practical and has
been the main focus for researchers in last decade. For
example, Hong et al. [4] adopted a physically based
submarine model to support guided navigation in their
virtual colonoscopy system. Their approach achieved a
good balance between guiding the physician through the
colonic interior and the physician’s freedom to
manipulate the camera.
The main problem in guided navigation is the
planning of the fly-through path of the virtual camera.
Manual planning is a tedious and time-consuming task,
and to relieve this, there are some approaches that allow
the path to be extracted automatically.
Skeletonization is the main approach and this contains
three categories of methods, based on topological
thinning, distance transforms and Voronoi diagrams,
respectively [ 131. Skeletonization is a process for
“shrinking” an image or object into a thinner remnant
that largely preserves the extent and connectivity of the
original region. Skeletonization has well been explored
in 2D and many algorithms have been extended to 3D
thinning for centreline extraction in a hollow object.
Topological thinning is an iterative process that peels
off the boundary, layer by layer, by deleting the simple
points. The removal can maintain the topological
characteristics of the object and can, thus, guarantee the
connectivity of the object [14-15]. Hong et al [3]
extended the technique from 2 D image processing [ 141
to the 3 D volumetric domain for automatic extraction of
the flythrough path. Paik et al [12] mixed thinning with
Euclidean Distance Mapping to generate a smooth flight
path. Since thinning is based on voxel operations, it is a
time-intensive process when voxel numbers are large.
The distance-transform method is a popular approach
to flight-path extraction for virtual endoscopy. The
distance transform at a point within a hollow object is
defined as the minimum distance to a boundary point.
So, points closest to the centre of the object would have
the maximum distance-transform value and would not be

[161.
Zhou et al [I71 used the approximate minimum
distance field to express the skeleton as a set of local
maximum paths from the inner wall of the object.
Although their algorithm takes less time to find the local
maximum path, preparing the 3D binary volume data to
provide the input of the algorithm consumes more preprocessing time.
It is well know that the medial axis of polygonal
shapes can be obtained by calculating the Voronoi
diagram of the boundary line segments [18]. Some
authors [ 19][20] have extended the concept into the 3 D
domain. Compared with the other two categories, which
work in discrete space, Voronoi diagrams are continuous
skeletonization methods.
The system presented in this paper is a guided
navigation system that uses a slice-based algorithm to
simplify the computation of the fly-through path. The
following section provides an overview of our system in
terms of function and components.

3. System Overview
Our interactive virtual endoscopy system takes
volumetric image data from several data sources, such as
CT, MRI, or VHD (Visible Human Data [9]). T o
perform the navigation interactively in the sliced image
data, the system is divided into the components
described below. The systcm architecture is illustrated in
Figure 1 .
Datu Acquisition. The input to the system is a set
of 2D slice images, usually in standard formats
(DICOM. TIFF, etc). T o obtain better image
quality, we can put some filtering processes on the
original images.
Segmentation. The segmentation component is
used for the definition of the Region of Interest
(ROI). Normally, to make sure that the correct
segmentation is produced, someone with medical
experience should supervise this procedure.
Extraction of ROI boundary. After segmentation,
regions-of-interest (ROIs) are identified on the
slices through different colours. Our first task is to
find the border polygon or border points of these
ROls. The boundary of the ROIs will be used later
in defining the camera path. T o make the outer
wall surface of the human organ covered by the
borderlines of the ROIs, the system adjusts the
borderlines of ROIs in an outward-growing

’

7 12

Data P.cqu!sition
(CT. MRI. etc)

c

Region of Interest
Slice Iniuee

I

1

4

I

, - Exti-action
A T +

I

-

Surface Rendering

I

L?
1

16
I C

I

:

,
I

I
I
II

I
I

I' Y
Z

' 5

I

(Po1y:jon data)

Subvolume (Indexed
Slice Im'iges)

Marching Cuhes
(3D Mesh Data)

(Segmented Slice Image)

Rendering

I T
I.?

Canieru Parh
Extraction

I

Figure 1. System Architecture

should be towards the end of the currently visible crossregion to provide the user with the feeling of what is
coming next; the speed of camera movement should not
be too great, in order to avoid missing details inside the
object. I n this section, we present the key steps of the
fly-through path-extraction algorithm, then discuss
camera control i n our system.

incremental fashion. The advantage of using the
borderline of the ROls to extract the slice images
of ROIs from the original images is that data size
can be significantly reduced.
Swface extractiorr. Taking slice images of ROI as
input. we can extract the surface using, for
example, the marchirig cubes algorithm [IO].
Interactive path plarrriing. We mainly use a slicebased method to find the centerline of a tubulur
organ as the virtual camera path. After smoothing
the centerline, we can locate the camera at any
point on the path. By using a split-screen display to
present an overview of the location of virttiiil
camera and the c;imera's view, the u e r can
interiictively locate the camera start and end
positions which can later be tised for surface and
vol time navigation.
Reirderirig. This includes both surface rendering
and Loluine rendering. The wall of the organ is
reprcsentcd as a mesh of triangles. which clin be
rendered by standard techniques. For realistic
volume
visualisation.
perspective
volume
rendering is required because the camera location
e
is near to the wall o f ~ h organ.

1.1 Extraction of Fly-through Path
Our algorithm was developed considering the
iollowing principles: rapid generation of the navigation
path is very important for interactive virtual endoscopy;
it is inore important that the navigation path is smooth,
even if only roughly centred within the interior hollow
organ, than that is fully optimised: the slice boundaries
provide enough information about a hollow object,
provided that the image data is acquired at an adequate
sampling rate.
The algorithm aims to extract a path that satisties the
following properties:
discrete points in the path are approximately
centred with respect to the boundary wall of the
hollow object;
the distance between successive points on the path
should be no inore than a chosen value th;it
depends upon the sample rate of data acquisition.
The latter point is to support smooth camera
inovement along the path to ensure that details on the
interior organ wall are not missed.
The first phase of the algorithm involves the
calculation of an initial rough path.

4. Slice-based Navigation
Navigation path planning is a crucial component in
virtual endoscopy. which should meet the following
requirements: changes of (he camera view should not be
too jerky; the camera position should stay in center ot
the hollow object; the view direction of the camera

713

contains too many points, making the subsequent
calculations rather cumbersome.

Extracting the Rough Path
I. Extract the borderline B , from 2D segmented slice
image Si (expressed by a polygon, where i is the slice
index number, j is the number of borderlines in
slice);

Smoothing the Path

th

1. If a is larger than a threshold angle hL,,, defined by
the user, delete the point C,, and connect Ci-,,k to
Ci+/,,- see Figure 3(a):

2. Simplify B , by deleting some detail points on the
borderlines:

3. Compute the center point
of Bijfi,;
4. Use a PointInPolygon method to find if C, is outside
the borderlines (concave polygon), if so, divide it into
, C;,,:
convex polygons and output new B i ~ iand
5 . Create a center point list LC, connecting the nearest

2. Repeat Step 1 until all the paths satisfy the condition
and output the path RP’,;

center points, slice by slice, from top to bottom, and
categorize the points into normal, end, saddle and
wall points (see Figure 2 ) ;

4. Repeat Step 3 until all the paths satisfy the condition
and output the path RP’,:

3. If a is smaller than a threshold angle B.,,,,

defined by
the user, delete the point C , , and connect Ci./,kto
Ci+/,, - see Figure 3(b):

5 . Interpolate R F , using cardinal spline interpolation
[21] and output the smoothed path SP,.

6. Merge each wall point to the nearest saddle point, to
form a normal point, then merge the LC, into LCk
which connect the pair of end points (O<k<j):
7 . Output the rough path RPk.

...E..
,.T,T.....................................

.....................

........................................................

End Point
/

I

Wall Point
..............................................................................................................

/

1

........................................................................................................

I

(a)

a>a,,,.,

1 ( b ) a<%,”

Figure 3. Path smoothing

The final stage of path extraction is to make the path
travcrsal uniform - resampling the navigation path to
ensure an equal gap between points can y a r a n t e e that
the camera moves with a steady speed.

Figure 2. Four kinds of point

The second phase of the algorithm is concerned with
smoothing the rough paths obtained above to provide a
more suitable environment for investigating the wall of
the organ.
We may find that there are some noisy points on the
rough path RPk, because the shapes of the slice
borderlines vary according to the segmented slice
images. The rough paths RP, will possibly consist of too
many points, causing the direction of the virtual camera
to change too frequently along the path.
We use the following algorithm to simplify and
smooth the rough path. We consider three successive
points, Ci.l,krCikand Ci+/,k,on the path RPk and find the

4.2 Virtual Camera Control
We use a split screen to control the virtual camera
interactively within the surface model of the hollow
organ. One screen displays the model and the camera
position, another displays the scene that the virtual
camera sees. The camera can be controlled indirectly
using a control panel or directly using a mousc.
Control panel. Users select discrete points in the
tly-through path by moving the sliders in the user
control panel or produce the navigation animation
using the “play” button. The selected point is taken
as camera’s position or focal point. Users can
control the camera parameters such as changing the
field-of-view, adjusting the view direction of the
camera by moving its position or focal point,
rolling the view-up vector and zooming inhut.
Mouse. The controls permit the operations
mentioned above. Although the manual techniques

.

- -

k Cj,kCi+,,k
.
angle, CY, between the lines C i - , , k C l ,and
If a is too large, the path direction is changing too
violently between slices and the algorithm “cuts the
corner”. If a is too small, the path is already smooth but

714

We used 356 segmented slice images from the Visual
Human Male cross-sectional anatomy data set. These
images show four parts of the colon - descending,
transverse, ascending and sigmoid The physical location
of these images is between 51 I mm to 866“
from top
to bottom. Their resolution is 400x300 pixels. The
extraction of the fly-through path takes less than 5
minutes on a standard PC (Intel PI11 SOOMHz, 256MB
RAM)
Figure 4 shows the borderlines of the colon wall and
the virtual camera path extracted from these borderlincs
by using our slice-based algorithm Figure 5 shows a
view inside the colon surface model that was extracted
using marching cubes

give users the feeling of greater freedom in view
changing, the users can easily get lost. So, the
control panel provides the facilities to return the
camera to the navigation path.

5. Results
W e tested our virtual endoscopy system on the
Visible Human Data set. The examples illustrate the
interactive path planning, the slice borderlines
expression of the colon and the display presentation.

6. Conclusions and future work
This paper describes a general approach to virtual
endoscopy in which we have emphasized the algorithmic
issues in extracting the navigation path, which is a
crucial component of virtual endoscopy and which is
usually a time consuming process. The preliminary
results are encouraging but more tests need to be
performed in other endoscopy applications.
As mentioned above, the borderlines of the ROI
reduce the size of the original slice images that form the
input data of the subsequent volume rendering. This
reduces the quantity of data that has to be handled during
the volume rendering.
At any given camera position, only a small fraction of
the slice borderlines are visible to the camera, so t h e
camera viewing frustum reduces the slice number of R 0 1
images that contribute to the final perspective volume
rendering result. We are extending our work on slicebased perspective volume rendering to try to take
advantage of this.

Figure 4. The fly-through path in the colon

Acknowledgements
This research is supported by the Information Society
Technologies Programme of the European Commission
within the project VAKHUM (lST-1999-10954), and the
Chinese National Natural Science Fund (No. 60003009).

References
[I]

F.A. Jolesz, W.E. Lorensen, R.Kikinis, P. Saiviroonporn.
S. Seltzer, S. Silverman, M. Philips. B . Geiger, “Virtual

Endoscopy: Three-Dimensional Rendering of CrossSectional Images for Endoluminal Visualization”,
Rudiology, 193(P), 469, 1994
[2] M. Wan, Q. Tang, A. Kaufman and 2. Liang, “Volume
Rendering Based Interactive Navigation within the
Human Colon”, fEEE Visitnlimion ’99, IEEE Computer
Society Press, pp. 397-400, 1999

Figure 5. A view inside the colon; the fly-through
path is showed by cylindrical tube.

715

[12] D.S. Paik, C.F. Beaulieu, R.B.Jeffrey, G.D. Rubin and S.
Napel, “Automated Flight Path Planning for Virtual
Endoscopy”, Med Phys., 25(5):629-37, May 1998
[ 131 N. Gagvani and D. Silver, “Parameter-Controlled
Skeletonization of Three Dimensional Objects”, CAIPTR-216, Rutgers University,l997
[ 141 T. Pavlidis, Algorirhms ,for Graphics and Image
Processing, Computer Science Press, 1982.
[ 151 C. Min Ma and M. Sonka. “A Fully Parallel 3D Thinning
Algorithm and its Application”. In: Computer Vision,
Graphics and Imaging Processing: Image Understanding,
64(3), pp.420-433, November 1996.
[I61 R.C.H. Chiou, A.E. Kaufman, Z.R. Liang, L.C. Hong and
M. Achniotou, “Interactive Path Planning for Virtual
Endoscopy”, Conf Record IEEE NSS-MIC, on CD-ROM,
1998
(171 Y. Zhou, A. Kaufman and A.W. Toga, “ThreeDimensional Skeleton and Centerline Generation Based
on an Approximate Minimum Distance Field”, The Visual
Computer, 14:303-414, 1998.
[18] F.P. Preparata and M.I. Shamos, Computer Geometry,
Springer-Verlag, New York, 1990.
[ 191 D.J. Sheehy, C.G. Armstrong, and D.J. Robinson, “ShapeDescription by Medial Surface Construction”, IEEE
Trans. on Visualization and Computer Graphics, 2( 1):6272, March 1996
[20] E.C. Sherbrooke, N.M. Patrikalakis, and E. Brisson, “An
Algorithm for the Medial Axis Transform of 3D
Polyhedral Solids”, IEEE Trans. on Visualization and
Computer Graphics, 2( 1):44-61, March 1996
[2I ] 1.J. Schoenberg, Cardinal Spline Interpolation, SIAM,
Philadelphia, 1973.

[3] L. Hong, A. Kaufman, Y. Wei, A. Viswambharan, M.
Wax and Z. Liang, “3D Virtual Colonoscopy”, IEEE
Symposium on Frontiers in Biomedical Visualization
IEEE Computer Society Press, pp. 26-32, Oct. 1995
[4] L. Hong, S. Muraki, A. Kaufman, D. Bartz, and T. He,
“Virtual Voyage: Interactive Navigation in the Human
Colon”, Proc. SIGGRAPH ‘97, pp. 27-34, Aug. 1997
[SI A. Vilanova, A. Konig and E. Groller, “VirEn: A Virtual
Endoscopy System”, Machine Graphics & Vision,
8(3):469-487, 1999.
[6] R. Robb, “Computed (Virtual) Endoscopy: Development
and Evaluation Using the Visible Human Datasets”. In
National Library of Medicine Visible Human Project
Conference, pp. 19-20, 1996.
[7] W.E. Higgins, A.J. Sherbondy, J.P. Helferty, A.P. Kiraly,
G. McLennan, E.A. Hoffman and J.Z. Turlington, “Virtual
Bronchoscopy for 3D CT Assessment and Endoscopic
Guidance”, infoRAD2000, Radiology, vol. 2 17(P), pp.
706-706, Nov. 2000
[8] E. Gobbetti, P. Pili, A. Zorcolo and M. Tuveri,
“Interactive Virtual Angioscopy”, IEEE Visualization 98,
IEEE Computer Society Press, pp. 435-438, 1998
[9] National Library of Medicine (NLM, US ), “The Visual
Human Project”, http://rcw~v.nlm.nih.gov/researcW~isible/
visible-himian. htrnl
[IO] W.E. Lorensen and H.E. Cline, “Marching Cubes: a High
Resolution 3D Surface Construction Algorithm”,
Computer Graphics, 21(4): 163-169, 1987
[ I I] C. Hand, “Survey of 3D Interaction Techniques”,
Coinpurer Graphics forum, 16(S):269-281, December
I997

716

