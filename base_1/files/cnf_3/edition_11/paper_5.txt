RAPID VISlJALIZATION OF GEOMETRIC INFORMATION IN
A CONSTRUCTION ENVIRONMENT
Yong-Kwon Cho
Postdoctoral Fellow, Civil Engr. Dept., University of Texas at Austin
E-mail: choyk@niail. utexas. e h
Carl T. Haas
Associate Professor, Civil Engr. Dept., University of Texas at Austin
E-mail: huus(u>mnil.utexas.erlu
Katherine A. Liapi
Assistant Professor, Civil Engr. Dept., University of Texas at Austin
E-mail: k l i a p i ( ~ n r t r i 1 . u t t ~ x u s . e ~ ~
S.V. Sreenivasan
Associate Professor, Mechanical Engr. Dept., University of Texas at Austin
E -mail: sv.ween i@mu il.ute-xas.e h
1. INTRODUCTION

ABSTRACT
Construction workspace is a dynamic
environment thut NIIOWS Ijttle time to obtain and
updrite graphical and image modeling information
required in construction equipment operations.
Comprehensive 3 0 models of the workspace require
computationally intensive and expensive imaging
processing and usually take much longer than the ongoing construction operations permit. Rapid 3 0
positioning and modeling in construction can be used
to plan. visualize, and communicate operations before
execution. It can also help to optimize equipment
operations, significantly improve safety, and enhance
a remote operator’s spatial perception of the
workspace. The paper presents a rapid method, by
combining humnn-assisted graphical workspace
modeling with pre-stored CAD models and simple
sensors (such as single-axis laser rangefinders and
remote video cameras), which can significantly
reduce modeling time while potentially increasing
modeling accuracy.

Controlling equipment in an unstructured work
area can be very difficult and dangerous due to the
difficulty an operator has in obtaining continuously
sufficient visual feedback from equipment in the
changing working environment.
To solve this
problem, most researchers have focused on building
comprehensive 3D models of the workspace derived
from a combination of design data and from highly
computationally intensive interpretation of dense
clouds of range scan and position data. Automated
procedures for measuring geometric shapes of objects
in a workspace play an important role in state-of-theart process automation and quality control systems 111.
Since they also present a number of advantages in
construction, considerable efforts have been devoted
to the development of applications for improved
visualization and geometric modeling of remote and
inaccessible areas of equipment operation by using
modern technologies such as graphical simulation,
virtual reality, off-line programming, machine vision,
sensor fusion, and real-time graphical control.
Global
properties
such
as
volumetric
descriptions are very useful and can unambiguously
identify and localize objects.
However, global
properties are difficult to compute when only a partial

Keywords: Construction Automation, CAD, laser
rangefinder, manipulator, graphical simulation

0-7695-1195-3/01 $10.00 0 2001 1EE)E

31

In this research, speed of modeling is the critical
driver. In contrast to other industries such as
manufacturing and architectural design, construction
exhibits a more dynamic workspace which allows
little time to gain geometric information from the
changing workspace. This research has resulted in
the development of framework of rapid local area
sensing and 3D modeling for better planning and
control of construction equipment operation, which
combines the cognition skills of a human operator in
conjunction with efficient data acquisition, data
processing, and modeling methods.

view of the object is available [3]. It can be even
more difficult when the target object has occluded
regions. For example, to get a complete 3 D model
with area range scanning approaches, an object
should be scanned from several different angles and
the view must be merged into one model. It is
impossible to obtain full geometrical data from one
position even with current state-of-the-art methods.
In addition to the surface scanning process, the
fused results are then manually converted into
conventional Computer-Aided-Design (CAD) models.
The CAD modeling process with position data
requires a substantial amount of time. Modeling of
a workspace usually takes hours or even days, which
is unacceptable in the midst of ongoing construction
operations.
As an alternative to manually converting the
surveyed range data or points clouds to CAD models
of the workspace, image analysis algorithms can be
used to automate the process.
However, the
complicated image analysis algorithms required are
another time intensive and computational burden.
3 D data can come in the form of depth maps, isolated
3D points and lines, or 3D intensity images,
depending on the sensor and sensing algorithm.
Most of the existing range-sensing techniques are
point-by-point or segment -by-segment measurements,
and these just give range maps from the viewer. For
real-world robotic applications, range map analysis is
required to obtain geometrical information of target
objects [ 5 ] . Unfortunately, in terms of accuracy,
extracting reliable geometric features from real-world
images is still very difficult. Even with state-of-theart geometric image recognition technologies, a
solution of the correspondence problem is still
complex and computationally expensive.
This
computational burden can also slow the modeling
process to a crawl.

2. THEORY OF MODELING
2.1. Man-Machine Balanced Local Area
Sensing
Successful automation requires a balance
between exploitation of the machine’s ability to
efficiently process vast amount of information while
also executing tasks with accuracy and force, and the
human’s ability to react intelligently to unforeseen
circumstances or to pull patterns out of apparent
chaos [4]. By strategically incorporating human
assistance, geometrical data acquisition of reaLworld
objects can be simplified and accelerated
considerably because distance and orientation can be
obtained without processing full area range maps.
Furthermore, rapid object recognition by human logic
can be brought about without computationally
complex and intensive image analysis.
Since most target objects are known and manmade, they can be graphically generated and stored
with complete properties in a computer database. In
a design process, pre-stored models include all global
properties of the real-world objects such as shape,
texture, color, and roughness (Fig.]).

Representation

Sensor output,
measurements,

and human cognition

Fig. 1. Model Structure for the Human-Assisted Graphical Modeling Process
As long a s the Cartesian coordinates of a certain
number of vertices, or points on the edges or on the

faces of the object, are identified, position and
orientation of most solid objects can be determined.

32

The number of vertices or points on the edge or a
surface depends on the geometric and topological
features of the solid object. Two different types of
solid modeling methods (parametric modeling and
complex modeling) were implemented.
Parametric modeling uses parameters to define
the size and geometry of features and to create
relationships between features.
The geometric
description of parametric models composed of
primitives (simple shapes such as box, sphere,
cylinder or cone) which could reflect construction
material such as a pipe and an I-beam were examined
to obtain minimum required points with regard to
their position and orientation.
Unlike primitives, most complex models need to
be pre-designed and imported to the scene for the
fitting and matching procecs based on the measured
surface data. Hence, even with only a partial view
of an object, or even if the object has occluded or
hidden areas, as long as a few points on the surface
can be measured, and as long as the partially visible
object can be recognized by a human operator, in

theory, the proposed method can represent the object
accurately.
This method allows for a very precise graphic
model of the immediate environment 'of the
construction equipment and significantly reduces
sensor data acquisition time and computer processing,
when compared to 3D modeling procedures that
require a combination of design data and
computationally intensive interpretation of dense
clouds of laser scanned position and range data. I t is
likely that an ideal approach will use the ideas
described so far, but relaxed either to allow for some
error or to allow the acquisition of sparse point clouds
and subsequent interpretation.
As a simple demonstration of the well-known
geometric laws involved, three points on a pipe and
four points on a pipe rack were measured by a
lasericamera system mounted on the LSM (see
Section 2.2.). Based on the kinematically calculated
position data, a pre-stored pipe rack was placed and a
parametric model, a pipe was drawn in the LSM's
workspace (Fig. 2).

Fig. 2. Fitting and Matching Process for the Pipe and Pipe Rack Models in the LSM's Workspace

2.2. Laser and Camera System

in a smooth manner until { E } = { G }at the end motion.
Then, the link transformation can be multiplied
together to find the single transformation that relates
frame { G } to frame { B}. As with vectors and rotation
matrices, a symbol T is called as transformation
operator [ 2 ] . Here,
describes the frame { G }
relative to the frame { B ) and equals to form a
transform equation as shown below Eq. (1):

A laser rangefinder system mounted on a 2
degrees of freedom (DOF) pan and tilt mechanism
was developed and mounted on the LSM to more
efficiently obtain an object's position and orientation
(Fig. 3). By adding 2 DOF's - the pan and tilt
mechanism - to the current UT LSM, careful
kinematics calculations arc: required to correlate the
camera/laser coordinates with the manipulator
coordinates. Fig. 4 shows a brief kinematics frame
illustration for the lasedcamera mounted UT LSM.
The LSM control system calculates a series of
joint angles to move the joints through in order that
the end-effector frame moves from its initial location

l7'

Then, each joint angle
from the transform equation.

33

(8,) can be computed

System on the LSM

Fig.
- 4. Brief Kinematics Frame Illustration for the LasedCamera
Mounted UT LSM

accurately to the LSM when the laser is on the endeffector of the crane rather than on the tripod in a
fixed position; the crane can extend its boom close to
target objects to measure their position, which
eventually reduces the laser's error caused from
distance as long as appropriate error adjustment is
provided. The purpose of this graphical modeling
experiment for a trench site was to demonstrate the
potential of this method to keep people out of a
trench, to provide a safety boundary representation of
a trench with a form of non-parametric model, and to
provide the operator with precise spatial information
that can potentially improve equipment control for
high precision pipe placing and connecting tasks in a
trench.

2.3. O u t d o o r D a t a C a p t u r e and Modeling Test
2.3.1. Trench Work Site
A small trench was made at the laboratory's
outdoor facilities, and the laser system was used to
obtain geometric data of the trench and three pieces
of aluminum pipe placed in front of a crane (Fig. 5 ) .
Due to the easiness for the experimental process, the
laser system was mounted on the tripod rather than
on the crane (a crane requires a more complex
kinematic solution than a tripod as well). If the
laser system had been mounted on the end-effector of
the crane, the more realistic site scene for a trench
work would have been created.

Also, it may be

easier to build accurate models and relate them

>

Fig. 6. Four Views of the Completed Models

Fig. 5. Trench/Pipes/Crane Fitting and Matching
Process

equipment and the trench walls during operation.
Thus, instead of describing the detailed topography of

Especially, the safety boundary representation of
the trench can eliminate interference between the

34

street. A crossroad including electric cables and
poles was selected for the modeling test (Fig. 7).
To locate and model four poles and four cable
connections, eight points were measured to locate the
cables and four points to indicate the bottom of each
pole's position. Pre-designed poles were fitted and
matched to the end points of the cables and to the
bottom points (Fig. 8). The complete modeling
process took 8 minutes.
Regardless of the complexity and size of object,
the average processing time for graphically modeling
for an object was 2 min. 47 sec. with the current
prototype system.
Thus, it is likely that this
graphical modeling approach would be more effective
with respect to the modeling process time when
handling larger and more complex objects than
smaller and simpler.

the trench, seven points located slightly inside its
walls were measured to represent this safety boundary.
Other objects - the two pipes, the pipe connector, and
the crane - had been previously designed and were
imported from a graphics library. Six points were
measured to locate a pipc connector model and three
points were measured to lo'zate a crane model (Fig.5).
The total modeling time for the five objects took 10
minutes and 20 seconds using 24 points. Fig. 6
shows the completed 3 D virtual workspace.

2.3.2. Electric Power Cables and Poles on a Street
The purpose of this part of the experiment was
to rapidly provide a virtual workspacc for equipment
with long b o o m or arms, such as cranes, truck
mounted concrctc pumps, or man-lifts, working under
or around high voltage electric power cables on a

System (laser)
I

:I

6

Fig. 8. Scanning Process and CAD Results
Target Objects

orientation. In the same way, by giving a motion
script developed from the graphical simulation to the
current LSM control system, the LSM automatically
moved to the inputted goal position with the results of
six-joint values. The joint values obtained from the
graphical simulation and the ones from the LSM
operation were compared as a means of verifying the
proposed graphical geometric modeling method (Table

3. GRAPHICAL SIMLLATION
To verify the laser-camera mounted manipulator
coordinatcs system, graphical kinematics calculations
wcre conducted to updatc the prc-stored model of the
LSM with the sensor-bascd models as they are
constructed from the camcrailascr coordinates.
Then. the graphical geometric simulation was
executed to find the required joint angles by
manipulating a virtual LShA to the desired position and

1).

35

Table 1. Graphical Simulation and Real Task Execution for the Pipe Placing by the LSM
Simulated
Position of the Endeffector (cm)

Graphical Simulation

Real Task Execution

(325.18, -14.22,
98.72)

(409.6323, 8.37,
174.85)

Mechanics & Control. Addison-Wesley.

4. CONCLUSION

[3] Johnson, A. and Hebert, M. (1996). “Recognizing
Object by Matching Orientated Points.” Robotics
Institiite Ccrrnegie Mellon University, C M U-RITR-96-04.

new feasible method for graphical
workspace modeling has been developed by
combining human perception with pre-stored
CAD models and use of simple sensors, such as
single-axis laser rangefinders and remote video
cameras, which can significantly reduce modeling
time while potentially increasing modeling
accuracy in terms of volume, position, and
orientation. Potential impact of this research
includes safer and more efficient operations with
computer-assisted construction and maintenance
equipment.
In order to increase the modeling speed, as
an on-going project, this research currently
focuses on improving the control system and
algorithms by optimizing manual guidance of
sensor data acquisition system and minimizing
human’s interruption in the modeling process.
A

[4] Kim, Y. and Haas, C. (2000). “A Model for
Automation of Infrastructure Maintenance using
Representational Forms,” Joiwtiul of Airtotnation in
Construction, Vol. 10, No. I .

[SI. Tsukiyama, T. (1996).
and Orientation of a
Nonstructurcd Lighting3-D
Indoor Mobile Robots.”

IEEE T/,rni.scrction on
Instriinietitatioti and Mmsir/wnmt, vol. 45,no.

REFERENCES
[I] Albrecht, P. and Michaelis, B. (1998).
‘‘ Improvement of the Spatial Resolution of an Optical
3-D Measurement Procedure.” IEEE Trunsactions on
Instritnieritation und Measurement, 47( I ).
[2] Craig, J. (1986).

“Measuring the Distance
Planar Surface Using
Measurcment System for

Infrochiction to Robotics:

36

