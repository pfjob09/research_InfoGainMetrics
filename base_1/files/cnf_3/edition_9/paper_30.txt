Memory-Efﬁcient and Fast Enumeration of Global States
Artur Andrzejak
Zuse Institute Berlin (ZIB)
Takustr. 7, 14195 Berlin, Germany
Email: andrzejak@zib.de

Abstract
We describe a simple algorithm for level-wise enumeration of the global states of a distributed computation. In
addition to fast execution, it requires working memory for
only two global states plus a variable amount of memory
which permits the trading of higher speed for storage. Furthermore, we present a new caching strategy that speeds up
the state enumeration algorithm described in [1].

1 Introduction
Detecting certain conditions in a distributed computation
is a fundamental building block for many solutions related
to the control and debugging of distributed programs. Examples include error reporting, process control, decentralized coordination or load balancing [11, 3]. These conditions corresponding to global predicates are detected and
evaluated over global states, which are essentially unions
of local states of all processes.
Except for stable global predicates [4], i.e. predicates
that do not become false once they are true, the evaluation
of global predicates is not an easy task. Most approaches
exploit the structure of a global predicate to identify the
global states for which a predicate might apply [7]. The
major drawback of these methods is that they either apply
to small classes of predicates, or are predicate-speciﬁc.
On the other hand, evaluating non-speciﬁc global predicates is NP-hard, as shown in [5]. For such predicates, or
if the structure of the predicate is not known a priori, the
most general approach is taken - enumeration of all global
states [6, 9]. Such enumeration might be prohibitively expensive due to the large number of global states. Moreover,
the memory-efﬁciency of known approaches is very poor,
including the algorithms in [6, 9].
In an attempt to provide a practically feasible method for
the enumeration of global states we present here a simple algorithm with fast execution and low memory requirements.
In more details, our algorithm requires memory for only two

global states plus a variable amount determined by the user.
This additional amount allows trading memory requirement
for higher speed: essentially, doubling the additional memory (up to a certain limit) doubles the execution speed.
The new algorithm explores the lattice of global states
level-wise, bearing similarities to Breadth-First Search
(BFS). It complements the memory-efﬁcient algorithm
from [1], which traverses this lattice in Depth-First Search
(DFS) manner; for a particular application, either BFS or
DFS traversal might be a better choice.
Using the insights gained from the new approach, we
also improve the strategy for caching of local states described in [1]. This improvement provides a further speed
up of the DFS-based enumeration without increasing its
memory requirement.

1.1 Deﬁnitions
We assume that the reader is familiar with the deﬁnitions
of a distributed computation, a run R, local history of a
process pi , global history of a distributed computation, and
a consistent cut [2, 4].
For a process pi , 1 ≤ i ≤ n, and an integer k ≥ 0 let σik
denote the local state of a process immediately after having
executed event eki . The local state of a process may include
information such as the values of local variables and the
sequences of messages sent and received. The global state
of a distributed computation is an n-tuple Σ = (σ1 , . . . , σn )
of local states of all processes together with the messages
still in the communication channels, see [10]. It is not hard
to see that a run R = e1 e2 . . . results in a sequence of global
states Σ0 Σ1 Σ2 . . ., where Σ0 is the initial global state. Each
global state Σi of the run R is obtained from the previous
state Σi−1 by some process executing the single event ei .
We say that Σi succeeds Σi−1 or that Σi is a successor of
Σi−1 . Conversely, let us say that Σi−1 precedes Σi or that
Σi−1 is a predecessor of Σi . The set of all consistent global
states of a computation along with the successor relation
deﬁnes a lattice L. Let Σk1 ,...,kn be a shorthand for the
global state (σ1k1 , . . . , σnkn ) and let = k1 + . . . + kn be

Proceedings of the Seventh International Conference on Information Visualization (IV’03)
1093-9547/03 $17.00 © 2003 IEEE

e
p1
p2

1
1

e

2
1

e 12

e

3
1

e 22

e

e 23

4
1

e

rithm in [1] as well as the one in this paper assumes such a
mechanism.
Reverse execution is a well established concept used in
debugging, fault-tolerant computing, human-computer interaction and speculative computation [8, 12]. Implementations include both hardware and software approaches.

5
1

e 24

e 25

2.1 Reverse execution with time versus space
trade-off

Σ 00
Σ 01

Σ10

Σ 02

Σ11
Σ12

Σ 21
Σ 31
Σ 41

Σ13

Σ 22
Σ 23

Σ 32
Σ 33

Σ 42

Σ 04
Σ14

Σ 24
Σ 34

Σ 43
Σ 44

Σ 53

In the following we discuss an approach for reverse execution approach and describe how to parameterize the tradeoff between its execution time and the memory requirements.
Assume that P is a path in a lattice corresponding to a
distributed computation. Given a node (global state) Σ in P ,
we want to obtain its predecessor Σ . The only difference
between, say both global states is that in Σ exactly one of
the processes pi , has not yet executed its next event eki i . In
other words, the difference between the signatures of Σ and
of Σ is that the former is less by 1 in position i; in all other
positions the signatures are identical. Thus, given Σ, the
goal is to “set back in time” pi by a single step to the local
state σiki −1 .
Obviously the method with the highest memory usage is
to cache all global states on the path P and then retrieve the
required global state from the memory or other storage as
necessary. Note that we can cache the path in a “differential” way, i.e. we store only changes in a single local state
for every node of P . Still, if Σ is the last global state in P
and has the signature (k1 , . . . , kn ), then we must store ki
local states of the process pi for each i = 1, . . . , n, in total
= k1 + . . . + kn .
To decrease memory usage, we might also cache only
some local states of each process. For i = 1, . . . , n, let us
cache every qi -th local state of the process pi , where qi is a
natural number of our choice. For qi = 1, the retrieval of
Σ from Σ is the same as above. For qi > 1 we ﬁrst retrieve
the cached local state of pi with index (ki − 1)/qi qi from
memory or secondary storage and “load” this state into pi .
Subsequently, if (ki − 1)/qi qi < ki − 1, we compute the
local state of pi in Σ by “forward” execution of its program
code. Note that we have to execute at most qi − 1 steps
to reach the desired state. Since the messages received by
pi are considered a part of its local state [2], we cache also
those (together with the index of the sender and the event
number causing this message).

Σ 03

Σ 54

Σ 35
Σ 45

Σ 55

Figure 1. A distributed computation and its
lattice

its level. Figure 1 shows such a lattice together with the
original distributed computation.
We say that for a global state (σ1 , . . . , σn ), its signature is the tuple (k1 , . . . , kn ) of subscripts of the recently
executed events ek11 , . . . , eknn leading to the local states
σ1 , . . . , σn . The signature of the initial global state is
(0, . . . , 0).

2 Reverse Execution of an Event
Computing a global state Σ from its predecessor Σ in L
is straightforward: we let a (certain) process execute its next
event. Thus, having all global states of level in the memory of the enumerating machine, we can obtain all global
states of level + 1. This property is used in the algorithms
described in [6, 9]. However, the number of global states
of a single level can be exponential in n, and this is also
a reason why the above-cited algorithms are not memoryefﬁcient.
On the other hand, memory-efﬁcient enumeration algorithms require to keep in the memory the least number of
global states at a time, in extreme case only the currently
visited one. This frequently leads to a situation where
we must compute a predecessor of a global state, and so
memory-efﬁcient global state enumeration algorithms are
likely to use reverse execution of events. Indeed, the algo-

2.2 Space and time requirements
We bound now the time and space requirements of the
above approach for a single process. For i between 1 and n
let us write:
2

Proceedings of the Seventh International Conference on Information Visualization (IV’03)
1093-9547/03 $17.00 © 2003 IEEE

• Ri for an upper bound on the time to retrieve a local
state and to “load” it into process pi ,

004
013
022
031
040

• Ei for an upper bound on the time needed by pi to
execute an event, and
• Si for an upper bound on memory requirement of a
local state of pi .

Si

301
310

global states are visited in lexicographical order (in Table 1:
top to bottom, then left to right). Note that each column of
the table corresponds to a sequence initiated by fetching σ20
from cache and “loading” it into p2 .
The full implementation details are presented in the following algorithm.

(1)

If the last global state in P has signature (k1 , . . . , kn ),
then the total memory or secondary storage needed for
caching of local states of process pi is at most
ki
.
qi

202
211
220

Table 1. Signatures of the global states visited
in the example for n = 3

For qi > 1, in order to compute Σ from Σ process pi must
forward execute at most qi − 1 events after retrieval of its
last stored local state. Therefore, the time for computation
of Σ from Σ is at most
Ri + Ei (qi − 1).

103
112
121
130

Σ := initial global state (GS); visit Σ ;
compute F , set of signatures of successors of Σ;

(2)

k

n−1
, where ki
M := cache with local states (LS) σ1k1 , . . . , σn−1
is minimal entry at position i over all signatures in F ,
i = 1 . . . , n − 1;

3 Level-Wise Enumeration of Global States

repeat {next level}
a := smallest signature in F ;
z := largest signature in F ;
i = (i1 , . . . , in ) := a;
update C, cache of LSs of pn between σnzn and σnan ;
Σ := GS with signature a (use M and C here) ;
clear F , set of signatures of next level;
add signatures of successors of Σ to F ;
repeat {compute and visit next GS}
i := lexicographical successor of i in F ;
for k := each position at which i = i do
if k < n then {forward execution}
using LSs in M and Σ, forward execute pk until its
local state has index ik ;
else {reverse execution}
using C, compute LS of pn with index in ;
end if
update Σ with changes; visit Σ;
add signatures of successors of Σ to F ;
end for
i := i ;
until i = z;
update M by forward executions and copying LSs from Σ;
F := F ;
until F empty.

In this section we describe an algorithm for level-wise
enumeration of global states. In addition to memory efﬁciency, it achieves high speed by reducing the amount of reverse computations. The key idea is to execute only forward
computations on the processes p1 , . . . , pn−1 and reverse
computations on pn only. As a consequence, only one local state needs to be cached for each of p1 , . . . , pn−1 , while
we apply caching techniques from Section 2 to speed up reverse computations of pn . Note that choosing the “fastest”
process as pn further improves the execution speed.

3.1 Implementation details
Figure 1 illustrates for n = 2 the order in which the
global states are visited (bold arrows). Assume that we have
cached the local states σ10 , σ24 and want to enumerate global
states in level 4. To this aim we repeatedly reverse execute
p2 and forward execute p1 and obtain Σ04 , Σ13 , Σ22 , Σ31
in this order. (Note that this approach could be easily extended to simultaneously visit most of the global states in
level 5 which occur “between” the reverse and the forward
executions).
During this process we calculate the minimum index of
a local state of p1 in level 5 (which turns out to be 1) and the
maximum such index for p2 (which is 4). Thus, to prepare
the algorithm for traversing of the next level, we compute
by forward execution (or fetch from cache) σ11 and σ24 .
Since the enumeration is slightly more complicated for
n > 2, we give an example for n = 3 in Table 1. The algorithm traverses here level 4 of a ﬁctive lattice; in the beginning, local states σ10 , σ20 and σ34 are stored in a cache. The

3.2 Running time and memory requirements
Obviously, the lowest cost to generate a global state is
achieved by one reverse computation followed by one forward computation. However, sometimes a local state of one
of the processes p1 , . . . , pn−1 must be restored from the
3

Proceedings of the Seventh International Conference on Information Visualization (IV’03)
1093-9547/03 $17.00 © 2003 IEEE

cache. It is not hard to see that the cost of computing the
ﬁrst global state that is visited per level and the cost of updating M can be neglected. Thus, with notation from Section 2, R := maxi=1...n−1 Ri and E := maxi=1...n−1 Ei
we obtain as an upper bound on the running time of the enumeration

1

Σ 00
Σ 01

Σ10
2
3

Σ 31

|L| (R + E + Rn + En (qn − 1)) ,

Σ 41

where |L| is the total number of global states. Note that
the time per single global state compares favorably to the
cost of moving from one global state to the next in an actual
distributed computation, which is on the order of E.
As for the memory requirements, the above algorithm
stores the currently visited global state, the cache M , and
the cache for reverse computations of pn . While M requires no more memory than for a single global state, the
cache for pn needs memory amounting to Sn kqnn , where
kn is the highest index of a local state in pn . The memory
requirements of F and F are small compared to a single
global state and are neglected. Summarizing, the size of the
working memory equals to memory for two global states
plus a variable amount determined by the user.

20

Σ 32

21

Σ 42

27
22

18

Σ 43

7
8

Σ 53

13

Σ13

Σ 54

Σ 23
Σ 33

23
14

Σ 44
15

11
10

Σ 04
Σ14

Σ 24

26

17

12
9

Σ 03

Σ 22

29

19
6

Σ12

Σ 21

4
5

Σ 02

Σ11

Σ 34

25
24

16

Σ 35

Σ 45

Σ 55

Figure 2. The spanning tree of the lattice from
Figure 1 used for the DFS

e.g. from Σ55 to Σ54 . At these steps the algorithm presented in [1] incurs reverse computation. During such an
operation the local state of only one of the processes, say
pi , must be reverse computed. It is not hard to see that the
higher the process index, the more frequently this process is
affected by reverse computation. In the following we want
to explore this fact for a better caching strategy.
Consider the sequence of global states in the order as
visited by the algorithm. For i = 1, . . . , n let us deﬁne an
i-trace as a longest subsequence of it such that the process
i was subject to reverse computation only. Every such a
subsequence can be determined by a path in T . In Figure 2,
the only one 1-trace is determined by the path from Σ55 to
Σ00 at the left “edge” of the lattice, and e.g. Σ21 , Σ22 , Σ23 ,
Σ24 determines one of the multiple 2-traces.
To bound the number of i-traces in T consider a complete lattice which has m levels, and all global states except
those with the highest level have exactly n successors (recall that n is the number of processes). It is not hard to see
that the number of i-traces in such a lattice is maximal (over
all lattices) for i = 1, . . . , n. Especially, it has only one
1-trace. Furthermore, every global state Σ with signature
(k1 , . . . , ki−1 , 0, . . . , 0) where k1 + . . . + ki−1 = < m
gives rise to a unique i-trace. This is due to the fact that
at some point (exactly when it encountered Σ after a reverse execution of pi−1 ) the algorithm will visit all global
states with signatures starting with k1 , . . . , ki−1 . By doing
so, it ﬁrst only forward executes pi (m − many times) and
then reverse executes it until the global state with signature (k1 , . . . , ki−1 , 0, . . . , 0) is encountered again (the second part corresponds to our i-trace). Of course, during this
process the processes pi+1 , . . . , pn are forward and reverse
executed. It follows by induction that in the complete lattice

4 Improved Caching of Local States
The algorithm presented in [1] enumerates global states
of a distributed computation by traversing the corresponding lattice in a DFS-manner. This algorithm is memoryefﬁcient, albeit it applies reverse computation which is responsible for the major share of its computational effort.
This effort can be reduced by caching of certain local states,
thus trading the running time for memory efﬁciency. In this
section we describe an improved strategy for selecting the
local states to be cached. This can signiﬁcantly decrease
the running time as compared to the version in [1] with the
same working memory.

4.1 Depth-First Search and i-traces
Without going into implementation details, we describe
in the following how the lattice of global states is traversed
by the algorithm in [1]. For such a lattice let T be a spanning tree such that each edge connects a global state and its
successor with lexicographically largest signature. Figure 2
shows such a spanning tree for the lattice in Figure 1. The
order of enumeration of the global states is the same as the
order of node visits of a Depth-First Search algorithm applied to T and starting at the initial global state. Figure 2
indicates in which order the nodes are visited by the numbers at some edges.
From the same ﬁgure we see that sometimes the traversing of the tree moves from a global state to its predecessor,
4

Proceedings of the Seventh International Conference on Information Visualization (IV’03)
1093-9547/03 $17.00 © 2003 IEEE

we have for i between 2 and n exactly

computations utilized in the algorithm. If all local states of
a single process can be cached, the algorithm computes a
single global state at the speed comparable to the original
computation.
Using the insights gained from the development of the
new approach we showed how the strategy for selecting local states to be cached applied in [1] can be improved. This
implies a higher execution speed of the algorithm from [1]
without increased memory requirement.

tri := (m − 1)(m − 2) . . . (m − i + 1)
i-traces (and tr1 := 1), which is also an upper bound on the
number of i-traces in any lattice of depth m.

4.2 Minimizing the running time
We assume that the total time spent for reverse execution
of process pi is proportional to the number of i-traces. This
assumption is not completely accurate, since not every local
state of pi will occur in equally many i-traces; e.g. in the
complete lattice the local state of p2 with index j will occur
in exactly m− j of the m− 1 2-traces. However, since these
frequencies depend on the form of the lattice and so on the
distributed computation we do not consider them.
Using the notation and results from Section 2, the total
time for the reverse computations is obviously proportional
to

References
[1] A. Andrzejak and K. Fukuda, “Debugging Distributed Computations by Reverse Search”, Applied Informatics 2003,
Innsbruck, Feb. 2003.
¨ Babaoˇglu and K. Marzullo, “Consistent global states of
[2] O.
distributed systems: Fundamental concepts and mechanisms”,
S. J. Mullender (eds.), Distributed Systems, Addison Wesley,
NY, 1994, pp. 55-96.
¨ Babaoˇglu and M. Raynal, “Speciﬁcation and Veriﬁcation
[3] O.
of Behavioral Patterns in Distributed Computations”, Proc.
4th IFIP Working Conference on Dependable Computing for
Critical Applications, San Diego, 1994.

n

trev =

tri (Ri + Ei (qi − 1)) .

(3)

i=1

We can minimize this number by choosing the values for
q1 , . . . , qn subject to the following constraint that the total
memory or secondary storage devoted for caching does not
exceed Stotal :

[4] K. M. Chandy and L. Lamport, “Distributed Snapshots: Determining Global States of Distributed Systems”, ACM Transactions on Computer Systems, 3(1):63-75, Feb. 1985.
[5] C. Chase and V. K. Garg, “Detection of Global Predicates:
Techniques and their Limitations”, Distributed Computing,
11(4):191-201, 1998.

n

Stotal

ki
≥
Si
,
qi
i=1

(4)

where ki ≤ m is the highest index of the local state of
process pi .
Since the above optimization problem requires nonlinear integer programming, ﬁnding an optimal solution is
likely to be NP-complete. Thus, heuristics such as genetic algorithms seem to be a good choice. Another approach worth noting is to try to balance out the summands
in the r.h.s. of (3). This can be achieved by setting e.g.
qi = (trn−i + 1)/Ei (under the assumption that Ri = 0)
for i = 1, . . . , n.

[6] R. Cooper and K. Marzullo, “Consistent detection of global
predicates”, ACM/ONR Workshop on Parallel and Distributed
Debugging, Santa Cruz, May 1991, pp. 163-173.

5 Conclusion

[10] F. Mattern, “Virtual Time and Global States of Distributed
Systems”, Proc. International Workshop on Parallel and Distributed Algorithms, Chateu de Bonas, October 1988, pp. 215226.

[7] V. K. Garg and B. Waldecker, “Detection of strong unstable
predicates in distributed programs”, IEEE Trans. on Parallel
and Distributed Systems, 7(12):1323–1333, 1996.
[8] T. J. LeBlanc and J. M. Mellor-Crummey, “Debugging parallel programs with Instant Replay”, IEEE Transactions on
Computers, C-36(4):471– 482, April 1987.
[9] K. Marzullo and G. Neiger, “Detection of global state predicates”, WDAG-91, Delphi, Oct. 1991, pp. 254-272.

The most universal approach to evaluate global predicates is the enumeration of global states. Although such an
enumeration might generate a huge number of global states
to be checked, a real limitation of this approach is the ﬁnite
size of working memory.
We addressed this problem by designing a memoryefﬁcient enumeration algorithm which traverses the lattice
of global states level-wise. As a minimum, it has a memory requirement of two global states. Additional memory
devoted to it by the user is used to speed up the reverse

[11] N. Mittal and V. K. Garg, “Debugging distributed programs
using controlled re-execution”, Proc. Symposium on Principles of Distributed Computing, 2000, pp. 239-248.
[12] R. Sosiˇc, “History Cache: Hardware Support for Reverse
Execution”, Computer Architecture News, 22(5):11-12, Dec.
1994.

5
Proceedings of the Seventh International Conference on Information Visualization (IV’03)
1093-9547/03 $17.00 © 2003 IEEE

