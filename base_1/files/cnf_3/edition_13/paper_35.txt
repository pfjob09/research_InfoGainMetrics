Robotic 360° Photography for Virtual Site Visits
Qunhuan Mei and Robert Wing
Department of Civil Engineering, Imperial College, London SW7 2BU
q.mei@ic.ac.uk and r.wing@ic.ac.uk
Abstract
A robotic photographic method has been developed for
use in outdoor locations such as construction sites, to
provide 360° panoramic visual database material for
representation of a virtual site, together with the software
for authoring and delivery the material to users via the
Internet. A portable digital photographic system thus built
can take a 360° panorama photograph in digital form
within minutes. The Java software package can present
an image in an efficient and effective “video” style with
full dynamic “hyperlink” support.

1. Introduction
The teaching of building construction related disciplines
ideally requires the provision of visits to operational
construction sites. Today, the time and expense that such
visits demand, together with increasingly restrictive HSE
regulations make it very difficult to provide actual site
visits, and lecturers are resorting to use of conventional
audio/visual materials, predominantly 35mm slides.
Virtual site visits using on-line delivery of the
materials would provide a close simulation and affordable
alternative to the real thing. In its simplest case the
virtual site visit could take the form of video footage, but
this would involve only passive student behaviour. An
interactive system, teleoperated over the network or from
a local server, would allow the student to move around
the site according to his own commands; such operation is
extremely desirable in its involvement of the student.
Ideally, a virtual site would consist of dozens of
360° panorama images, with “hyperlinks” built among
them, so that student can go from one image/page to
another through a “door”/button/hyperlink. Furthermore,
as almost all images are 360° panoramas, when they are
presented, continuous, endless and controllable panning
and zooming functions would be expected.
The problems facing creation and presentation of the
virtual site are:

•

The lack of portable hardware support to be used
indoor/outdoor for taking 360° panorama image files.
Traditional manual 360° photography must be
considered inefficient – it usually involves taking
many pictures at pre-calculated angles, carefully
slicing them into strips and then stitching them
together using software to make complete 360°
panorama pictures. Another approach uses spherical
lenses
to
produce
spherical
panoramas
(www.ipix.com) [1, 2]; these tend to produce large
image files as they also include sky and/or ground;
the system is generally good for interiors but poorer
for outdoor sites. The image resolution varies
considerably across the picture, and the use of film in

Fig. 1 - The hardware system

the process also limits the resolution and involves the
extra task of scanning into a computer.
•

Lack of effective Web authoring software support
with dynamic hyperlink capability for 360° panorama
images. Although there are a few commercial
software packages available, such as Apple’s QTVR
(www.apple.com/quicktime)
and
LivePicture
(www.livepicture.com), these either use movie
formats, which produce very large source files
(usually more than 400k for average viewing effect),
or they require download of plug-in software, which
needs extra effort and time. Futhermore, there is only
minimal support for the variety of user interfaces
needed to support different applications in the large
panorama image domain.

To solve these two problems, a two-stage R&D plan was
proposed:
(1). To construct a remote-controllable portable digital
360° panorama photographic system with pan and
tilt functions using robotic principles. This involves
panning and titling mechanisms, digitally indexed
servo-motors, and a notebook computer, such that
the 360° panorama image would be generated and
transferred automatically into the computer. The
image file format chosen was JPEG, as the file sizes
and viewing effect are well matched to Internet
applications. Fig. 1 shows the prototype of the
hardware system developed.
(2). To develop a “Panorama Web design” tool kit based
on pure Java technology. The kit had to support
automatic horizontal panning, together with support
for dynamic hyperlink and various user interfaces.
Java has a unique feature of “once written, runs
anywhere”. The size of a Java program is also
negligible in comparison to the panorama images.

2. Portable digital panorama photographic
system
Automated 360° panorama photography can be imagined
as using a video camera seated on a stepping rotational
device, catching a video frame after each step movement,
extracting a narrow strip from each frame and then
stitching these together to form a 360° panorama image.
Our 360° panorama imaging concept uses an areascan CCD with image strip stitching, and thus differs the
method which used for line-scan CCD cameras. The linescan system has much higher resolution, is over-qualified
for Web work, and is expensive (www.spheron.com). We

favour area-scan since the quality of the results is more
suited for general Web use. Line-scan can be considered
as a special case of area-scan. In our system, the video
camera has been positioned with a 90 degree turn so that
the better resolution appears in the vertical direction,
i.e.utilising the longer axis of the frame.
A usual way to realise the controlled step rotation is
by using a stepping motor with a dedicated logic
controller. The problems with this are that, firstly, the
stepping motor and its dedicated controller are quite
costly; secondly, the mechanical connection between the
motor and camera has to be custom designed, as does the
tilting mechanism.
The decision was made to use an inexpensive offthe-shelf pan and tilt device as used for security camera
applications. The device already had basic functions for
both continuous panning and tilting, supported by two
general-purpose D.C. control motors rather than stepper
motors. Our first task was to realise the stepping
movement control so that stepwise image- strip stitching
could be realised. Fig 2 shows a schematic diagram of the
hardware system.
A PCMCIA frame grabber (24-bit colour) with
resolution of 922x576 was used to catch video frames on
Video Camera - Rotation device
Position
feedback

Tilt Control

Control
Circuitry

Motor driver -

Video Frame

Control Logic Serial/parallel
converter Rotation
Control
Serial port

Frame
Grabber
(PCMCIA)

Notebook Computer

Fig. 2 – Schematic diagram of the system

Fig. 3 - A panorama image generated by the hardware system (5681x922 pixels – 6mm normal lens)

the fly. A narrow image strip was obtained from the frame
and then stitched to make a full 360° digital image using
C++ software. The number of horizontal pixels of the
image is determined by the lens used. For a normal lens
(6mm), about 5600 pixels will be generated in the
horizontal direction. Fewer pixels in horizontal direction
will be generated if a wide-angle lens is used, and vice
versa. The vertical resolution is always 922 pixels.
The whole system is powered by two separate
batteries, one for the video camera, and the other for the
rotation device and logic control circuitry. Two batteries
rather than one are used to isolate the camera from any
power supply ’bounce’ caused by digital switching.
The position feedback was realised using an optoswitch to monitor the position of the main drive shaft.
When the horizontal drive shaft, to which is attached a
small metal vane plate, completes a full turn, the optoswitch generates a pulse. This pulse stops the motor via
control logic; additionally, it triggers the computer,
signalling that the camera has made another step
movement and another image strip can be stitched. The
enhanced rotation device is capable of doing 300 steps
maximum for a full 360° turn.

3. The software components
hardware system

of

the

The hardware system is controlled by software written in
MSVC++5.0. The current C++ system has the following
main functions:
1.

2.

Control of rotation through a serial line by stepping
either clockwise or anti-clockwise. Given starting
and ending angles, the camera can be controlled to
move in steps of 1.2° each.
Control of the frame grabber through the PCMCIA
interface so that the image is grabbed and a strip is
obtained.

3.

Stitch image strips to make a complete panorama
image in BMP format.

4.

Turn the BMP file(s) into JPEG file(s) with chosen
parameters from a dialogue menu.

The system can produce a 0~360° panorama image file
directly into a notebook computer in 3~9 minutes. Using
such a system, a normal 360° panorama image will be
sized at about 5600 by 920 pixels, which is 15 MB in
BMP or around 1MB in JPEG [Fig 3].
Considering the screen size of the computer display
(say 1024x768) and typical network bandwidth, the
image resolutions are considered more than adequate for
Web applications.

4. Use of Java for 360° panorama viewing
software
Once the 360° panorama images have been captured, we
identified three choices to let the user view these special
images:
(1) use of QTVR software to present the 360° panorama
images
(2) use of other Panorama Viewing Plug-in software to
view the image
(3) provision of a Java program (either applet or standalone application) to view the image.
The main difference between a normal and a panorama
image is that the 360° panorama must have a perfect
match between its start and end. This makes it possible
for the 360° panorama image to be presented in a
continuous panning mode.
One commercial software package suited to these
images is QTVR from Apple Computer. It has an ideal
video fashioned multifunction ability for image/model
presentation, and can present a 360° panorama image in

Initial position of the viewport

Image Display after translation

Image reconstruction

(0, 0)

Viewport
(translateX, translateY)

Viewport

(translateX, translateY)

Viewport

Panorama Image

Fig. 4 – Fast Panning using image translation when inside
and viewport image reconstruction when across the border
an interactive video style. The problem of using QTVR
for virtual construction site applications is its large image
file size, as some intermediate frames have to be
generated [3]. This is not ideal for this application, as the
video file is slow to download, especially when the
original image files are, say, more than 1M pixels.
Plug-in software packages can be very fast in their
performance; they are usually platform dependent in order
to be fully optimised. The disadvantage of using this
approach is that it requires the first time user to download
the platform-dependent plug-in software. The user
interface creation has also to be confined to the
capabilities available.
Java holds the claim that "written once, will run
everywhere". Java programs are very small, secure and
capable. It is an object-oriented and architecture-neutral
language. The main advantage of using Java to present
our panorama images is that the user/viewer has no need
to download a plug-in, and it is also easier to program
than other OO languages, such as C++. Also worth
noticing is that Java’s performance on panning/zooming
360° panorama images can be made as good as that done
in any native language such as C++, since this involves
mostly image operations, rather than intensive data
processing. It can be seen that for presenting a 360°
panorama image, Java is probably the best choice.

5. The principle of panning 360° panorama
images
Java by default recognises two types of image: JPEG and
GIF. Since GIF is only used for images of 8 bits colour, it
was not suitable for our 24-bit colour Panorama project.
Panning a 360° panorama image involves preparation of
the data, timing, thread synchronisation, and user
interface control. The major issue here is how image data

is prepared for panning. Other issues can be solved by
Java programming directly.
As with any other programming language, there is
no direct support in Java for automatic panning of a 360°
panorama images. The default colour model for Java uses
a single integer to describe each pixel, thus allowing 32
bits for a pixel’s colour model. The bits are divided into
four bytes: three for the familiar red (8 bits), green (8 bits)
and blue (8 bits), which defines 24 bits colour; the fourth
byte is used for "alpha", which defines the transparency of
the pixel (0 for transparent; 255 for opaque).
An image is an array of pixels. Java has methods
both for converting an image to an array of pixels and
converting an array of pixels back to an image.
We have tried various ways to realise the panning of
a 360° panorama image. The following three methods are
found to be useful for image panning data preparation:
(1) Fast panning inside and reconstructing when across
the border.
When the image is initially shown, it is displayed with its
upper-left corner corresponding to the upper-left corner of
the viewport. When the viewport is moved right inside the
current image space [Fig. 4], a simple translation can
realise panning. Whenever the viewport is moved across
the image border, an extra image reconstruction sized for
the viewport is carried out, which combines two parts
from both the beginning and end of the image according
the origin of the viewport. It is then displayed.
Using this method, panning is fast when the
viewport is right inside the image space. The
disadvantage is that an uncomfortable “wait” will occur
when the panning position is outside the border of the
360° panorama image, since the reconstruction takes an
amount of time proportional to the size of the viewport. In
addition, the switch of image for display between normal

Panning position

Panorama image

(translateX , translateY )
Viewport

Viewport
Reconstructed image

Fig. 5 - Constantly reconstructing the viewport image while panning
and the extra reconstructed one takes yet further time.
(2) Constantly reconstruction of the viewport image
while panning
The logic underlying this method is to track the current
viewport position inside the given image’s space,
constantly reconstruct an image out of the original one,
then display it. Fig. 5 shows the principle of this method.
The time spent on reconstruction of the image is
proportional to the size of the viewport. The disadvantage
is that there is an uncomfortable delay between each
frame, so that the feeling of panning will not be “real
video” as the reconstruction is data processing intensive,
which takes a noticeable time and makes translation based
on one pixel a time usually not possible.
However, this method has very good potential in
functional panning where data intensive processing is
necessary, such as perspective panning or other image

processing panning where image reconstruction according
to a specific algorithm is necessary.
(3) Reconstructing initially, then always fast panning.
It is worth noticing that almost all computers have an
efficient way of copying a block of bits from memory
onto the screen. As seen from method (1), if
reconstruction of the image can be avoided when the
viewport strides over two ends of the image, fast panning
can be realised. The way to reach this objective is to
reconstruct the original image before panning it. As
shown in Fig. 6, the end part of the image has been
extended by adding the initial section of the image that is
proportional to the viewport size. When the viewport
appears to stride over two ends of the original image, it
can be viewed as still falling right inside the reconstructed
image, so that no further reconstruction is necessary and
fast panning can be realised.

Image width after reconstruction
Original image width

(translateX, translateY)
Viewport

Reconstruction - extend the image with part of the beginning proportional to the viewport

Fig. 6 – Extending image for fast panning

Using this method, the image display can be
refreshed at a controllable rate of more than 30 frames per
second. Even when the viewport size is as large as the
screen (say 1024x768), real-time and controllable panning
can still be realised. A screen sized viewport with panning
360° panorama image provides enough information to
cover all the details of a scene from a construction site or
any similar application.
Adding dynamic hyperlink ability, we can now build
“hot spots” into the panning image, which enables the
user to click on the “hot spot” during panning to go to
next interesting “place”.
Method (3) has been fully implemented in our
JAVA software package, which is capable of doing realtime, photo-realistic, zoomable and interactive operations.
An example is shown in Fig. 7. An initial test showed
that to generate about 50 seconds of panning “video”,
with the original image sized at 1600x400, it needed a
JPEG file sized at about 55kb when using Java panning
software, whereas for a similar sized
image, it needs about 400k when using
Apple’s QTVR. The size benefit is
obvious considering today’s congested
network bandwidth.

system with a consumer digital camera and to include the
perspective viewing function during image panning.
Ackowledgement:
The authors gratefully
acknowledge the financial assistance for this project
provided by HEFCE under the JISC initiative (see
http://www.jisc.ac.uk/

7. References
1.

2.
3.

M. Yachida, “Omnidirectional Sensing and Combined
Multple Sensing”, Proceedings of the 1998 Workshop on
Computer Vision for Virtual Reality Based Human
Communications, IEEE.
S.K. Nayar, “Omnidirectional Vision”, proceedings of the
1997 International Symposium on Robotics Research,
Japan.
S. Chen, “QuickTime VR – An Image-Based Approach to
Virtual Environment Navigation”, Proceedings CD-ROM
Computer Graphics SIGGRAPH 95, 6-11 August 1995,
Los Angeles, California

6. Conclusion
It can be concluded that the method of
robotic 360° photography for virtual site
visits presented is pragmatic, in terms of
its concept, approach and performance.
The hardware system provides an easy,
quick and effective way to capture
surround scenes (0~360°). The JAVA
software simply gives a normal image a
"video" life, which shows an image with
dynamic, stepless and real time
appearance. It is also equipped with
dynamic "hyperlink" ability, which
extends that of the HTML, as HTML's
image map can only be used for static
images.
The whole process, from taking
panorama images (0 ~ 360°) using the
portable computer integrated panorama
imaging system, to HTML scripting for
selecting appropriate Java class file and
setting up imageMaps and other
parameters,
etc,
is
streamlined,
systematic,
complete
and
straightforward. There is no third party
software nor other process involved. Our
future objective is to integrate the

Fig. 7 – An example of controlled panning and zooming, accessed from
a hotspot (an elliptical button) inside a map image.

