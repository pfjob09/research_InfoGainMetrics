Visualizing Real Estate Property Information on the Web
Theodore Hong
Department of Computing
Imperial College of Science, Technology and Medicine
180 Queen’s Gate, London SW7 2BZ, United Kingdom
t.hong@doc.ic.ac.uk
Abstract
We have designed and are implementing a system called
ReV (Real estate Visualiser) for exploring real estate
property listings on the world-wide web. Given the large
number of different websites providing listings, each with
its own presentation format, and the high-dimensionality
of the property space itself, it is difficult to obtain a
comprehensive single view of property data on the web.
ReV addresses this problem by using grammar induction
techniques to automatically learn to parse pages from
new websites and collate all of their listings together. It
them visualizes this listing data using a map-based colorcoding technique. This work draws together a number of
strands from the fields of information visualization,
machine learning, and database integration. We also
hypothesize that ReV will be adaptable to inducing
structures from other types of web data.

1. Introduction
The rapid growth in data of all kinds stored in
computerized form is bringing a surge of interest in
visualization and analysis techniques to interpret the raw
data. But while most efforts have been focused on
analyzing fielded static databases, we are now seeing
information increasingly being provided on a substantial
scale through the dynamic medium of the web. In the web
context, existing methods of information retrieval have
largely emphasized keyword-based searching (e.g.
Harvest [4] and WebCrawler [11]), but this approach
neglects the possibility of fielding within web documents,
treating them simply as unstructured text collections.
An alternative approach is to exploit the markup
structure of HTML to enable more sophisticated methods
of information extraction and visualization. Many web
documents, particularly those generated by query scripts,

can be considered as semistructured data sources: that is,
sources containing data which is fielded but not
constrained by a global schema (for an overview, see e.g.
[1, 5]). Documents such as on-line product catalogs or
real estate listings fall into this category, for example. In
these documents, patterns in the HTML markup such as a
hierarchical or repeating layout can be used as hints to
automatically tag data fields and extract them to a
structured format, rather than simply treating the page
data as a set of keywords. This allows us to apply
established techniques of visualization and analysis in the
new setting of the web. We describe a system for web
visualization which we are building, called ReV (Real
estate Visualizer).

2. Extracting real estate data with ReV
ReV is designed to explore the domain of real estate
property listings on the web. There are a large number of
competing sources of listings in operation, each with its
own unique presentation format, making it difficult to
obtain a comprehensive single view of the information
available. Furthermore, since there are a multitude of
variables which affect the price and desirability of a
property, the data space is inherently high-dimensional
and cannot easily be visualized. ReV addresses these
problems with two main features. First, it provides an
extensible way to easily and automatically add new data
sources to the system. Given a new website, it sends a
few typical queries to obtain samples of the web pages
that the source returns. Grammar induction is applied to
these pages, to look for regularities in their layout that
might be used to parse them into fields. When combined
with a few domain-specific heuristics to semantically
identify the field contents, together with some manual
tweaking if necessary, this yields a wrapper which ReV
can use to extract fielded listing data from the new source.
(In fact, since very little domain-specific knowledge is

Figure 1. Typical result page from a search on Hot Property.

used, we hypothesize that ReV can be easily adapted to
parse other types of web data as well.) Second, once
wrappers for each of the data sources have been
constructed, ReV is able to issue unified queries that
merge search results from all sources. These combined
results are then presented to the user in an intuitive,
navigable form. Specific details on the visualization used
by ReV are given in section 3, below.

2.1. Real estate data sources
A quick web search turns up some twenty-odd sites
carrying property listings within Greater London. Hot
Property (http://www.hot-property.com) is a typical
example. Figure 1 shows a partial screenshot of a result
page from a property search on Hot Property, which
carries over four thousand London listings in total. The
page is structured with a header, a left column containing
instructions, a right column with listings, and a footer (not
shown). To the eye, it is easy to segment the right column
into individual listings, but when looking only at the
source HTML it is not so obvious. However, by
analyzing the structure of the HTML, ReV is able to

discover the repeated pattern of an image (“Clip Ad”)
followed by two strong fields, free text, then two more
strong fields, and deduces that each of these repetitions
constitutes an instance of a listing.
Given this
information, ReV can examine the particular instances and
(by applying some heuristics) determine that, for example,
the first strong field contains the price while the second
contains the address. It can then generate a parser to
search for that particular markup pattern and extract the
price and address fields from any Hot Property page.

2.2. Grammar induction algorithm
The task of deriving a parse based on a sample
HTML page can be formulated as a grammar induction
problem. In this type of problem, the objective is to infer
a formal language from a finite sample set. The result
should be a derived grammar which is a consistent
generalization of the given set of positive examples (and
possibly some negative ones). Machine learning
techniques have in the past been used for grammar
induction tasks such as segmenting unmarked letter
sequences into words [14], identifying semantic units in C

code fragments [9], and generating a grammar for a
document containing dictionary entries [3]. In the ReV
context, we are given as input an HTML document
containing a set of property listings, and would like to
induce a general grammar describing its structure. From
this grammar, we can later identify rules as corresponding
to particular data fields of interest and create wrappers to
extract them.
ReV determines a grammar based on a stylized
version of the web page being examined. Attributes are
stripped from HTML tags, so that all tags of the same type
(e.g. anchor start tags) are considered indistinguishable
tokens. Free text occurring between tags is also reduced
to a single token simply indicating the presence of text.
This is so that structural patterns can be detected despite
varying content. For example, two different occurrences
of a listing footer giving contact information:
<hr><a href=”mailto:sales@a.com”>
Company A</a>
<hr><a href=”mailto:help@b.com”>
Company B</a>
would both reduce to the stylized version:
<hr><a>text</a>
To the stylized page we apply a modified version of
Wolff’s induction algorithm [14]. First, a single start rule
is created whose expansion is the entire document. ReV
scans the document, counting the occurrences of each
digraph within it, where a digraph is a pair of adjacent
tokens. If any digraph count exceeds a given threshold
(currently ten occurrences), it is considered significant
and a corresponding new grammar rule is created. All
occurrences of that digraph are then replaced with the rule
token, and ReV discards its counts and scans the
document again from the beginning. This process
continues until no further digraphs exceeding the
threshold are found.
We make one exception and specify that rules should
not be formed from identical pairs. This prevents an exact
repetition such as AAAAAAAA from being subsumed into a
rule, since we actually expect such a sequence to occur (as
when A corresponds to an entire listing) and would like to
see it clearly.
At this point, no rule is more than two tokens long.
Longer patterns in the input will be transformed into a
cascade of rules.
For example, if the sequence
<hr><a>text</a> occurred as a frequent pattern, it
would become the rule token C, where:

C -> B </a>
B -> A text
A -> <hr> <a>
To flatten this cascade, we specify that if a rule is
referenced fewer than a certain number of times (currently
five), it is dropped from the grammar and expanded inline
wherever it is referenced. Repeated application of this
requirement gives first:
C -> B </a>
B -> <hr> <a> text
and then:

C -> <hr> <a> text </a>

(assuming that rules A and B are not referenced
elsewhere. We may now recognize the cascade as having
concealed a pattern four tokens long. In addition to
flattening cascades, this modification also ensures that
rules created accidentally and without explanatory power
are dropped.

2.3. Application of the algorithm
When the induction algorithm is applied to the Hot
Property page from Figure 1, we obtain the grammar
shown in Figure 2. (Some rules have been omitted for
space reasons. Also, for clarity, nested rules have been
expanded and are indicated by parentheses.) The rule
corresponding to a single listing may be easily identified
as 57, which is the largest rule and occurs in a long
repeated block in the input (rule 0). From this rule, ReV
scans the page searching for occurrences of the pattern,
<a><img></a>…<font><strong><a></a>text
</strong></font></td><td><font><strong>
text</strong>…etc., and extracts the text fields in it.
In this particular instance, we obtain records such as those
shown in Figure 3.
Heuristics are then applied to determine what each
field represents semantically – for example, the first field
contains a pound sign and numbers and is likely to be the
price, while the last field contains eleven digits beginning
with the London exchange code 0171 and is probably a
contact telephone number. Some post-processing may
also be necessary to find further features of interest within
the long description that usually accompanies a listing
(here, the number of bedrooms, for example). Finally, if a
postcode can be determined, either by matching a street
name against a postcode database or by direct recognition
of a postcode field, a cross-reference is created linking to
supplementary information about the area (such as school
quality or transport accessibility).

0:

1:
2:
4:
5:
6:
7:
32:
33:
34:
36:
38:
39:
56:

57:

58:
59:
60:

!-- base !doctype html head meta meta meta title text /title /head body 9 9 map area
area area area area /map 6 map area /map 11 15 16 13 59 22 6 6 12 6 59 10
/table 16 9 text 22 26 59 26 9 6 26 20 60 22 text 13 text 22 9 12
17 form input input input /strong /font 13 9 9 12 img br text 25 23 23 13 9
12 12 input 13 input 23 13 br text 20 17 br 18 27 25 font text br 27 25
font text br 27 25 font 27 13 input /form 23 22 11 15 16 22 9 9 20 22
20 23 13 9 17 text a strong 18 /a 18 /font 22 25 23 23 5 9 5 36 22 12
12 11 15 13 4 26 26 20 13 20 60 13 9 59 23 60 10 tr td 57 57 57 57
57 57 57 57 57 57 57 57 57 57 36 /td td table tr td 17 a /a 18 /font /td
td 20 /td /tr tr td font 27 /td /tr tr td 20 /td td 20 /td /tr /table /td /tr
tr td div table tr td img /td /tr /table /td /tr 13 font img img 36 36 /font 23
10 15 13 text 22 text 13 6 26 9 17 text a strong 18 /a 18 /font 22 25
23 60 13 59 13 text 22 text 60 60 10 /table 16 /body
text text td
img img /td
text text tr text td
table table (text tr text td)
img img /td text td
text text /tr
...
table table tr td)
/td /td td ((font strong) (text /strong) /font)
/table /table /td /tr tr td
a a img /a
/a /a (text /strong) /font
font font (text /font)
(a img /a) (a img /a) /td td table tr td (font strong) a /a (text /strong) /font /td td
((font strong) (text /strong) /font) /td /tr tr td font (text /font) /td /tr tr td
((font strong) (text /strong) /font) /td td ((font strong) (text /strong) /font) /td
/tr /table /td /tr tr td div table tr td img /td /tr
(a img /a) (a img /a) /td td table tr td (font strong) a /a (text /strong) /font /td td
((font strong) (text /strong) /font) /td /tr tr td font (text /font) /td /tr tr td
((font strong) (text /strong) /font) /td td ((font strong) (text /strong) /font) /td
/tr /table /td /tr tr td div table tr td img /td /tr /table /td /tr tr td
font font img
font font img /font
(/td text /tr) (/td text /tr) (text /table text) /div

Figure 2. Grammar induced from the Hot Property result page.

£215,000

St Johns Square

2 bed loft style apartment, stripped wooden floors
throughout, balcony, fully fitted kitchen with
integrated appliances, en-suite shower room.

Tower Properties

0171-613
3311

£186,500

Pemberton
House

1 bed ground floor apartment, kitchen appliances
included, private square, feature
fireplaces, new development, between Chancery
Lane and Blackfriars station.

Carringtons

0171-247
4002

Figure 3. Some records extracted using the grammar from Figure 2.

3. Visualizing real estate data
Visualisation in the ReV system is to be
geographically-based. The main mode of presentation
envisioned is through a map displaying an overview of all
properties known to the system, shown as colored points.
The user will be able to set ranges for each of the major
property attributes, such as price, number of bedrooms,
school quality, etc., which will toggle the display of only
those listings matching the conjunction of all requested
attributes. One attribute can be chosen as the primary
attribute, which will be shown by using a rainbow
spectrum to color-code the points appearing – yellow
(brightest) for listings in the center of the specified range,
fading out to darker blues and reds at the high and low
ends, respectively. This gives an overall view at a glance
of the geographical trend in that attribute. By adjusting
the various ranges chosen and seeing listings appear,
disappear, and change color, the user can quickly follow
trends up and down and observe the interaction among the
different attributes. Selecting an individual point will
bring up a detailed display for that listing.

4. Related work
Work on integrating data from different websites has
been carried out by a number of researchers. Krulwich’s
BargainFinder [8] was able to scan product listings and
prices from a set of on-line web stores and place them into
a unified ordered table. However, it was not extensible,
as it was based entirely on hand-coded wrappers which
needed to be tailored specifically to each source site.
ShopBot [7] went a step further by defining a set of
heuristics which could be used to automatically parse
pages from new sites and extract prices, although the
heuristics used were quite specific to parsing on-line store
pages. In our system, much greater emphasis is placed on
the post-processing and visualisation phase which makes
the output useful, vis-a-vis the initial collation phase.
Further, we add extra value to the output by crossreferencing it against additional external data sources.
The Stanford TSIMMIS project [6] is another system
aimed at integrating web data sources; however, its main
focus is on query planning and reasoning about source
capabilities rather than information extraction, which is
again performed by hand-coded wrappers.
Lorel [2] is a query language for semistructured data
which attempts to give a SQL-like semantics to the worldwide web, but does not cover the issues of fielding the
data in the first place or of visualizing the results
afterwards. WebSQL [10] enhances simple keyword
searching with facilities for expressing hyperlink

relationships between documents, but this link structure is
at the meta-document level and does not examine the
internal structure of the documents themselves.
The proposed visualization concept is similar to that
of HomeFinder [13], but differs from it in two important
respects. First, while HomeFinder used only fictitious
data, this system draws data from real, current listings
which are continually being updated.
Secondly,
HomeFinder showed points only as either matching or not
matching the criteria given and did not show any
differentiation between listings. It was necessary to slide
a range up and down and watch points appearing and
disappearing in order to detect trends, whereas we show
that time-resolved process in a single snapshot by using
gradations of color.

5. Conclusion
We have designed and are currently implementing
ReV, a real estate visualization system for the world-wide
web. ReV brings together a number of previously
disparate ideas from the fields of information
visualization, machine learning, and database integration.
It provides an extensible means of collating a highdimensional space of property listings from a number of
data sources and visualizing it for the user in an intuitive
and navigable way. Additionally, the front-end grammar
induction component of the system contains very little that
is domain-specific, making it adaptable to inducing
structures from other types of web data.

Acknowledgements
The author acknowledges the support of the Marshall Aid
Commemoration Commission. This material is based
upon work supported under a National Science
Foundation Graduate Fellowship.

References
[1] Abiteboul, Serge, “Querying semi-structured data,” in
Database Theory, 6th International Conference (ICDT ’97),
Delphi, Greece, 1-18. London: Springer (1997).
[2] Abiteboul, Serge, Dallan Quass, Jason McHugh, Jennifer
Widom, and Janet Wiener, “The Lorel query language for
semistructured data,” Journal on Digital Libraries 1 (1).
(1996).
[3] Ahonen, Helena and Heikki Mannila, “Forming grammars
for structured documents: an application of grammatical
inference,” in Grammatical Inference and Applications,
2nd International Colloquium (ICGI ’94), Alicante, Spain,
153-167. London: Springer-Verlag (1994).

[4] Bowman, C. Mic, Peter Danzig, Darren Hardy, Udi
Manber, and Michael Schwartz, “The Harvest information
discovery and access system,” Computer Networks 28 (12), 119-126 (1995).

[10] Mendelzon, Alberto, George Mihaila, and Tova Milo,
“Querying the world wide web,” in Conference on
Parallel and Distributed Information Systems (PDIS ‘96),
Miami Beach, FL, USA, 80-91. (1996).

[5] Buneman, Peter, “Semistructured data,” in Proceedings of
the
16th
ACM
SIGACT—SIGMOD—SIGART
Symposium on Principles of Database Systems (PODS
’97), 117-121. New York: ACM Press (1997).

[11] Pinkerton, Brian, “Finding what people want: experiences
with the WebCrawler,” in Proceedings of the Second
World Wide Web Conference, Chicago, IL, USA. (1994).

[6] Chawathe, Sudarshan, Hector Garcia-Molina, Joachim
Hammer, Kelly Ireland, Yannis Papakonstantinou, Jeffrey
Ullman, and Jennifer Widom, “The TSIMMIS project:
integration of heterogenous information sources,” in
Proceedings of the 10th Meeting of the Information
Processing Society of Japan (IPSJ ’94), 7-18. (1994).
[7] Doorenbos, Robert, Oren Etzioni, Daniel Weld, “A
scalable comparison-shopping agent for the world-wide
web,” in Proceedings of the First International Conference
on Autonomous Agents (Agents ’97), Marina del Rey, CA,
USA, 39-48. New York: ACM Press (1997).
[8] Krulwich, Bruce, “The BargainFinder agent: comparison
price shopping on the Internet,” in Bots and Other Internet
Beasties, ed. by Joseph Williams. Indianapolis, IN (USA):
Sams Publishing (1996).
[9] Nevill-Manning, Craig and Ian Witten, “Inferring lexical
and grammatical structure from sequences,” in
Compression and Complexity of Sequences (Sequences
’97), Positano, Salerno, Italy. Los Alamitos, CA (USA):
IEEE Computer Society (1997).

[12] Stolcke, Andreas and Stephen Omohundro, “Inducing
probabilistic grammars by Bayesian model merging,”
Grammatical
Inference
and
Applications,
2nd
International Colloquium (ICGI ’94), Alicante, Spain,
106-118. London: Springer-Verlag (1994).
[13] Williamson, Christopher and Ben Shneiderman, “The
dynamic HomeFinder: evaluating dynamic queries in a
real-estate information exploration system,” in
International Conference on Research and Development
in Information Retrieval (SIGIR ’92), Copenhagen,
Denmark, 338-346. New York: ACM Press (1992).
[14] Wolff, J.G., “The discovery of segments in natural
language,” British Journal of Psychology 68, 97-106
(1977).

