12th International Conference Information Visualisation

Effectiveness of Machine Learning Techniques for Automated
Identification of Calling Communities
Keivan Kianmehr
Reda Alhajj
Department of Computer Science
University of Calgary
Calgary, Alberta, Canada

Abstract

nificantly important for increasing profitability in
the telecommunication industry.

In this paper, we demonstrate how cluster analysis can be used to effectively identify communities using information derived from the Call Detail Record
(CDR) data. We use the information extracted from
the cluster analysis to identify customer calling patterns. Customers calling patterns are then given to a
classification algorithm to generate a classifier model
for predicting the calling communities of a customer.
We apply two different classification methods: Support
vector machine and fuzzy-genetic classifier. The latter method is used for possibly assigning a customer to
different classes with different degrees of membership.
The reported test results demonstrate the applicability
and effectiveness of the proposed approach.

1

The main focus of this study is to use a unsupervised
machine learning technique, namely clustering to classify customers of a mobile service provider into appropriate calling communities according to the statistics
extracted from the CDR data. Once an acceptable
clustering has been found using the similarities and
dissimilarities in the training data set, the clustering
is transformed into a classifier by using a classification
technique. In this study, the agglomerative hierarchical
clustering approach has been applied for the clustering
task; it can produce an ordering of the objects.
In this study, two different techniques have been
selected for the classification task. The support vector machine (SVM) as a statistical-based learning approach has been used to build the classifier model.
A fuzzy-genetic algorithm has been also applied for
the classification task. The SVM algorithm has been
used for identifying crisp user communities and fuzzygenetic algorithm has been adapted for assigning a particular customer to possibly more than one community
with different degrees of membership. This way, we
differentiate between strict membership and gradual
membership. Fuzziness is attractive because it facilitates the possibility of having partial membership in a
given group. Each fuzzy set has a corresponding membership function which is used to decide for each customer its degree of membership in the group.
The rest of this paper is organized as follows. Section 2 covers CDR data and calling neighbors. Section 3 presents the proposed model. Section 4 reports
experimental results. Section 5 is conclusions.

Introduction

Identifying social communities is an emerging research area that has already attracted the attention of
several research groups, e.g., [2, 3, 4, 8, 9, 13]. Other researchers concentrated on identifying terrorist groups,
e.g., [12]. In this paper, we investigate customer relationships by analyzing Call Detail Record (CDR) obtained from a telecommunication company. It is beneficial for [19]:
• Churn Prediction: The goal is to understand when
and why company’s customers are likely to leave
so that appropriate action can be planned. Data
mining is applied to perform two major tasks:
1. predict whether a particular customer will
churn and when this will happen;
2. understand why particular customers churn.

2

• Identifying Calling Communities: this helps the
effective targeted marketing design which is sig-

1550-6037/08 $25.00 © 2008 IEEE
DOI 10.1109/IV.2008.68

CDR Data and Calling Neighbors

From the CDR data, it is possible to extract customer’s calling destination numbers, duration and fre-

308

quency for each destination number for a particular period of time. Customer’s calling neighbors can be also
identified by using the links of who calls whom [19].
There are two types of calling neighbors: 1) Direct calling neighbor: A person who calls the customer or whom
the customer calls. The majority of these neighbors of
a customer may be outside of the service provider’s own
network, and no information about them is available.
An example of direct calling neighbor can be described
as follows: members of a research community call each
other heavily. 2) Indirect calling neighbor: A person who calls the same number(s) as another customer
does. For example, employees of a large organization
such as a bank who work in different local branches may
call their headquarter frequently, and each employee is
possibly a calling neighbor of other employees. Even
though employees of different branches may not know
each other, they can be classified as colleagues.
There are two major challenges in using the CDR
data for finding the calling communities: 1) The majority of the destination phone numbers are outside service
provider’s network. So, information about these customers such as their calling records and links between
them is not available. 2) The other type of phone numbers are those in the service provider’s network, and
each of them corresponds to a customer of the service
provider. The connectivity between these customers is
very sparse because customers more likely call numbers
outside their home network. After identifying the customers communities, the information derived from the
calling communities can be used for building a classifier model. This classifier model is able to assign a new
customer to one or possibly more of the existing communities according to his/her general calling pattern
extracted from the CDR data as well as closeness of
his/her direct and indirect calling neighbors.

3

phone number, called destination numbers (within and
outside of the home network), and each destination
number’s calling duration and frequency in that particular period of time are extracted from the CDR data.
During pre-processing of the CDR data, inactive customers have been excluded from the data since these
numbers greatly skewed the distance distribution. Inactive customer refers to a customer who barely makes
a phone call within a particular time period.
Distance Measures: In order to identify the closeness of a particular customer to his/her direct calling
neighbors, a similarity measure weighted by call duration or frequency between two phone numbers has been
used. The weighted similarity measure is a first order
distance [19] defined as follows:
D1 (i, j) =

1
wi,j

(1)

where wi,j is the call duration or frequency between
customers (or phone numbers) i and j.
As described earlier, the direct calling neighbors of
customers within the service provider’s network are
very sparse because most of the phone numbers are
outside the service provider’s network. Therefore, it
is needed to include another distance measure, namely
the second order distance [19], which reveals relationships between customers according to their indirect
calling patterns where two customers have common direct calling neighbors. In order to define the second
order distance between a pair of customers i and j,
the set of phone numbers customers i and j called, respectively, in the specified time period, are weighted
by calling duration or frequency:
Nw (i) = {wi (1), wi (2), . . . , wi (ni )}

(2)

where ni is the total number of distinct phone numbers customer i called during the specified time period.
Here, we normalize the value of calling duration or fre-

Model Details

quency, wi (k), such that

The classifier model consists of three major phases:
data preprocessing, clustering, and classification.
Data Preprocessing:
During the first step of
the data preprocessing, all phone numbers (customers)
within the service provider’s network are identified.
Since the CDR data includes information about customers, all the source phone numbers have been considered as subscribers of the service provider. The
given data set consists of 55,000 calling records of 2,000
subscribers (distinct phone numbers within the service
provider’s network). Calls with very low duration (less
than 5 seconds) are assumed to have no effect on identifying the subscriber’s neighbors and are ignored.
In the second step, for each subscriber, his/her own

ni

wi (k) = 1. Finally, the

k=1

second order distance between two customers i and j
is defined as follows:
D2 (i, j) = 1−

1
2

wi (ki (x)) + wj (kj (x)) (3)
x∈N (i)∩N (j)

where x is a common phone number which both customers i and j called during the specified time period,
and ki (x) and kj (x) are the corresponding weights of
common called phone number x in Nw (i) and Nw (j),
respectively. According to Eq. 3, two customers are
considered very close when they call some common
numbers frequently (or heavily), regardless of how

309

many other numbers they regularly call. The distance
between a pair of customers is 1 (maximum distance)
if they do not call any common phone number.
Clustering Technique: Using the first and second
order distance measures, a hierarchical clustering approach which works based on links between customers,
can be applied to identify communities. The following
distance measure is defined to incorporate both the first
and second order distance measures into the similarity
measure of the clustering algorithm:
D(i, j) = (1 − α)D1 (i, j) + αD2 (i, j)

initions is built to represent relationships between this
particular customer and all other customers within the
existing communities. Then, a set of feature vectors,
each of which corresponds to a specific customer, is
used as the training set for the classification algorithm.
Classification Technique: For building a classifier
model that satisfies the purpose of this paper, two different approaches have been used. The first approach is
Support Vector Machine (SVM) [16] from the family of
statistical-based learning algorithms. Basically, SVM
can be used to solve binary classification problems.
However, in order to use SVM for real world classification tasks, the idea has been extended for multi-class
problems as well. The extension can be done either
during the learning process or during the decision process. One-vs-rest and adaptive code algorithm are two
of the most well-known extensions of SVM to multiclass problems [1].
The second approach that has been applied for classification task is a fuzzy genetic rule-based classification technique [7]. In contrast to SVM, this rule-based
approach is more understandable by humans, but suffers from efficiency issues. In this work, the characteristics of the fuzzy-rule based approach have been used
for possibly doing fuzzy classification.
For conducting the classification based on SVM, a
MATLAB interface of LIBSVM [6] has been used. LIBSVM is a free library for SVM classification and regression. The fuzzy-genetic rule-based algorithm has been
implemented in MATLAB. The MATLAB genetic algorithm built-in functions have been integrated into
the implementation. In the rest of this section, we first
present some basics of the genetic algorithm required
to understand the rest of this paper, then we describe
the fuzzy-genetic rule-based.

(4)

The term α controls the degree of relevance of the first
and second order distance measures and typically depends on the network characteristics of the mobile service provider. As α −→ 0, the similarity measure approaches the first order distance measure. Intuitively,
α captures the customers indirect calling neighbors.
Eq. 4 makes it possible for the clustering algorithm
to merge clusters with the most number of links, which
are defined as the common neighbors of the customers
based on both direct and indirect calling patterns. For
discovering calling communities in this study, the agglomerative hierarchical clustering algorithm has been
used [21]. The MATLAB Statistics Toolbox has been
used for conducting the hierarchical clustering.
Building the Classifier:
After identifying user
communities, it is time to transform the clusters into a
classifier model which is able to predict a community
where a new customer belongs to according to his/her
calling patterns. We use the community of a customer
as his/her class label; then we derive several features
using the information extracted from calling links and
clusters. Finally, we create a training set in which every column represents a distance feature and every row
represents a certain customer’s values for the features.
Distance Features:
The following input features
have been constructed for each customer from his/her
calling neighbors based on the first order and second
order distances. 1) Total number of customer’s direct calling neighbors. 2) Percentage of a customer’s
calls made to her/his closest direct calling neighbor.
3) Percentage of a customer’s direct calling neighbors
which are within the service provider’s network. 4) Percentage of a customer’s direct calling neighbors which
are outside of the service provider’s network. 5) The
shortest distances of a customer to all existing classes.
6) Percentage of direct calls to neighbors (within the
network) belonging to all existing classes. 7) Percentage of indirect calls to neighbors (within the network)
belonging to all existing classes.
For every customer within the service provider’s network, a feature vector based on the above feature def-

Figure 1. Membership functions of five linguistic values (S: small, MS: medium small,
M: medium, ML: medium large, and L: large).
Fuzzy-Genetic Rule-Based Systems: In order to
build a fuzzy rule-based system, the major task is to
find an appropriate fuzzy rule set which represents the
problem. Genetic algorithms have shown to be a powerful tool for performing: 1) generation and optimization of fuzzy rule-base, and 2) generation and tuning
of membership functions. In a fuzzy rule-based sys-

310

rule. In other words, the rule set S is formulated as:
Rj = A11 . . . A1n A21 . . . A2n . . . AN 1 . . . AN n .

The fitness of the rule set S is measured as:
f itness(S) = N CP (S), where N CP (S) is the number of correctly classified training patterns by S.
The genetic algorithm has been set to use the uniform crossover, where each substring is handled as a
block. That is, some rules are exchanged between the
two parents by the crossover. A mutation operation
has been set to randomly replace an antecedent fuzzy
set of a rule with another one.

Figure 2. Accuracy using hierarchical clustering with SVM.
tem, fuzzy if-then rules for an n−dimensional pattern
classification problem are defined as follows:
Rj : If, x1 is Aj1 and . . . and xn is Ajn then Class Cj with CFj
(5)

where Rj is the label of the j−th fuzzy if-then rule,
j indexes the number of rules, x = (x1 , x2 , . . . , xn ) is
an n−dimensional pattern vector, Aij is an antecedent
fuzzy set with linguistic label (i.e., a linguistic value
such as small or large) on the i−th axis, Cj is a consequent class, and CFj is a certainty grade. As the
antecedent fuzzy sets Aij ’s, five linguistic values shown
in Figure 1 and “don’t care” have been used. Therefore, the number of combinations of the antecedent
fuzzy sets is 6n , which is very large in the case of highdimensional problems.
As shown in figure 1, the meaning of each linguistic
value is specified by a triangular membership function
on the unit interval [0, 1]. “don’t care” has been handled by a special linguistic value with the following
membership function:
µdon t

care (x)

=

1 0 ≤ x ≤ 1,
0 otherwise.

(7)

4

Experimental Analysis

This section is dedicated to describe the evaluation
criteria and the conducted experiments. We summarize
the experimental results and highlight the performance
and applicability of the system.

4.1 Evaluation Criteria
After linking the customers of the service provider
network into a cluster tree, it has to be decided to divide the tree at a particular level to generate the clusters. For the community identification problem, the
validity of the clusters produced by a clustering algorithm is an important consideration. The reason may
be articulated as follows: once the clustering is complete, each of the clusters must be labeled and then
used in the classification task. Since the number of
generated clusters is subjective to the accuracy of the
classifier, the approach that has been used to determine
the validity of the cluster divisions is to compare the accuracy of the classifiers built based on different cluster
divisions. That is, we divide the cluster tree at a level
that generates two clusters at the beginning. Then we
labeled the clusters and build a classifier using SVM
algorithm. At the next iteration, we increase the number of clusters by 2 and we divide the cluster tree such
that it generates that particular number of clusters.
The stopping criteria is when an acceptable classification accuracy is obtained using the generated clusters.
To evaluate the accuracy of the classifier model, the
cross validation method has been used. Basically, the
data is randomly divided into 5 disjoint groups. The
first group is set aside for testing and the other four
are put together for model building. The model built
on the 80% group is then used to predict the group
that was set aside. This process is repeated a total of
five times as each group in turn is set aside. Finally, a
model is built using all the data. The mean of the five

(6)

In this study, a small number of fuzzy if-then rules
have been randomly generated. When antecedent fuzzy
sets of a fuzzy if-then rule are specified, its consequent
class and certainty grade are determined by applying a
heuristic [21]. After generating a small number of initial fuzzy if-then rules, the genetic algorithm has been
applied to optimize the initial rule set so that it will
be able to classify the test set with a reasonable classification accuracy. This work does not involve the adjustment of membership functions or certainty grade.
Assume that the fuzzy if-then rule Rj in Eq. 5
is denoted by its n antecedent fuzzy sets as Rj =
Aj1 . . . Ajn . That is, Rj is coded as a string (chromosome) of length n. Let S be a set of N fuzzy if-then
rules (i.e., S = {R1 , . . . , RN }). S is denoted by a concatenated string of the length n × N , where each substring of length n corresponds to a single fuzzy if-then

311

independent error rate predictions is used as the error
rate for the final model.

The examination of the overall accuracy between the
SVM classifier and the fuzzy-genetic approach using
5-fold cross validation can be seen in Table 2. The
LIBSVM default parameter settings have been used
for running the SVM algorithm. Based on some initial test runs, the following settings have been applied
for running the fuzzy-genetic classifier: 1) The number
of fuzzy rules: 40, 60 or 80; 2) The number of rule sets:
20; 3) Crossover probabilities: 0.9; 4) Mutation probabilities: 0.1; 5) Stopping condition: 500 generations.
For the given CDR data, SVM has an average overall
accuracy of 98.5%, whereas in comparison, the fuzzygenetic classifier has an overall accuracy of 82.5%.
Thus, we find that SVM outperforms the fuzzy-genetic
classifier by almost 13%. This shows that using genetic algorithm for tuning the fuzzy rules of the fuzzygenetic classifier results in a reasonable accuracy but
not as high as the accuracy obtained by SVM. However, the rules in the fuzzy-genetic classifier are easily
understandable and interpretable.

4.2 Experimental Results
Using the CDR data, a cluster tree has been built.
In all the experiments, α has been set to 0.75 in the
distance measure formula. By choosing such a large
value, we give more weight to the second order distance than the first order distance. We believe that
customer’s indirect calling patterns will provide more
useful information compared with direct calling patterns since a customer more likely calls numbers which
are not inside his/her home service provider.
The overall effectiveness of the clustering algorithm
is calculated using overall accuracy of the classifier
model. This overall accuracy measurement determines
how well the clustering algorithm is able to create communities that contain customers with similar behaviors. The number of correctly classified customers in a
cluster is referred to as the True Positives (TP). Customers that are not correctly classified are considered
False Positives (FP). The overall accuracy is thus calculated as follows:
T P for all classes
overall accuracy =
total number of customers

Table 3. Running time of fuzzy-genetic classification algorithm
Data set

(8)

CDR Data

Figure 2 and Table 1 show how the clustering algorithm was evaluated with K being the number of
clusters created from the cluster tree. The minimum,
maximum, and average results for the clustering algorithm are shown as well. The classification algorithm
used for evaluating clusters is SVM. The reason that
fuzzy-genetic classifier has not been used is because of
its running time.
Considering the above analysis, it has been decided
to set the number of clusters to 10 for building the
classification model. That is, every cluster has been
labeled as a community, and customers within all the
10 communities have been used as the training set for
the classification algorithm.

5

Table 2. Overall accuracy of each algorithm
Average
99.75%
86.4%

Minimum
97.95%
75.25%

Accuracy
86.4%
80.80%
73.15%

CPU time
448 min
365 min
378 min

The runtime of both approaches is an important
consideration because the model building phase is computationally time consuming. For the analysis, all operations are performed on a Dell Optiplex 745 with an
Intel Core2 Duo 6600 @ 2.4 GHz processor and 3 GB of
RAM. The number of data objects in the training set
is 2000. In general, the runtime for the SVM classifier
was significantly less than the fuzzy-genetic algorithm
when building the classification models. For example,
with 2000 objects running 5-fold classification took less
than a second, whereas fuzzy-genetic took much longer
to build the classification model. The running time
of the fuzzy-genetic approach while varying the number of fuzzy rules is shown in Table 3. Although the
SVM classifier was faster, the size of the training set is
ultimately limited by the amount of memory because
both approaches must load the entire training set into
memory before building the model.

Table 1. Accuracy using SVM.

Algorithm
SVM
Fuzzy-Genetic

Number of rules
40
60
80

Maximum
100%
94%

Summary and Conclusions

In this paper, we demonstrated how cluster analysis
can be used to effectively identify calling communities
by using information derived from the CDR data. We

312

used the information extracted from the cluster analysis to identify customer calling patterns. Customers
calling patterns are then given to a classification algorithm to generate a classifier model for predicting the
calling communities of a customer. This work is especially important for targeted marketing campaigns
in the telecommunication industry since the CDR data
is often the only primary data source available for the
customers. Based on the assumption that customers
in the same calling community might behave similarly,
targeted efforts can be focused on certain communities. Further, the fuzzy classification proposed in this
project provides more convenience for selecting customer communities and for measuring the efficiency
and validity of the communities regarding the marketing campaign design. The flexibility of the fuzzy
approach featured by the application of membership
functions provides the ability to increase or decrease
the homogeneity between the targeted customers depending on whether the proposed products are very
specific or intended for a large community.

[8] M. Kretzschmar and M. Morris. “Measures of concurrency in networks and the spread of infectious
disease,” Math. Biosci., 133:165195, 1996.
[9] M. Magdon-Ismail, M. Goldberg, W. Wallace, and
D. Siebecker. “Locating hidden groups in communication networks using hidden markov models,”
Proc. of ISI, 2003.
[10] B. Malin. “Data and collocation surveillance
through location access patterns,” Proc. NAACSOS Conf., 2004.
[11] L. A. Meyers, M. Newman, and B. Pourbohloul.
Predicting epidemics on directed contact networks. Journal of Theoretical Biology, 240:400418,
2006.
[12] M. Nasrullah, H. L. Larsen: “Structural Analysis
and Mathematical Methods for Destabilizing Terrorist Networks,” Proc. of ADMA, pp.1037-1048,
2006.
[13] M. Newman and M. Girvan. Finding and evaluating community structure in networks. Phys. Rev.,
69, 2004.

References
[1] E. Allwein, R. Schapire and Y. Singer: “Reducing
Multiclass to Binary: A Unifying Approach for
Margin Classifiers,” AT&T Corp., 2000.

[14] M. Newman, A.-L. Barabasi, and D. J. Watts, editors. The Structure and Dynamics of Networks.
Princeton University Press, 2006.

[2] L. Backstrom, D. Huttenlocher, J. Kleinberg, and
X. Lan. Group formation in large social networks: Membership, growth, and evolution. Proc.
of ACM KDD, 2006.

[15] S. F. Smith: “A learning system based on genetic algorithms,” Ph.D. Dissertation, University
of Pittsburgh, Pittsburgh, PA, 1980.
[16] V. N. Vapnik: Statistical Learning Theory, John
Wiley, NY, p.732, 1998.

[3] J. Baumes, M. Goldberg, M. Magdon-Ismail, , and
W. Wallace. Discovering hidden groups in communication networks. Proc. of NSF/NIJ Symp. on
Intelligence and Security Informatics, 2004.

[17] N. Werro, H. Stormer, and Andreas Meier: “A
Hierarchical Fuzzy Classification of Online Customers”, Proc. of IEEE International Conference
on e-Business Engineering, Shanghai, 2006.

[4] T. Y. Berger-Wolf and J. Saia. A framework for
analysis of dynamic social networks. Proc. of ACM
KDD, 523528, 2006.

[18] D. Whitley: “A genetic algorithm tutorial,”
Statistics and Computing, (4):65-85, 1994.

[5] L. B. Booker, D. E. Goldberg, and J. H. Holland: “Classifier systems and genetic algorithms,”
Artificial Intelligence, Vol.40, No.1-3, pp.235-282,
September 1989.

[19] L. Yan, M. Fassino, and P. Baldasare: “Predicting customer behavior via calling links”, Proc. of
IEEE International Joint Conference on Neural
Networks, Vol.4, pp.2555-2560, 2005.

[6] C.C. Chang and C.J. Lin: “LIBSVM: A Library for Support Vector Machines”, URL:
[http://www.csie.ntu.edu.tw/∼cjlin/libsvm],
2001, Last Accessed on 16/7/2006 .

[20] URL: [http://en.wikipedia.org/wiki/Call detail record],
Last Accessed on 9/2/2008.

[7] H. Ishibuchi, K. Nozaki and H. Tanaka: “Distributed representation of fuzzy rules and its application to pattern classification,” Fuzzy Sets and
Systems, Vol.52, No.1, pp.2132, Nov. 1992.

[21] URL: [http://http://www.mathworks.com/], Last
Accessed on 9/2/2008.

313

