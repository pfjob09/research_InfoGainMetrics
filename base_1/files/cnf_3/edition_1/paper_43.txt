2011 15th International Conference on Information Visualisation

Using Visual Analysis to Weight Multiple Signatures to Discriminate
Complex Data
Renato Bueno1 , Daniel S. Kaster2,4 , Humberto L. Razente3 ,
Maria Camila N. Barioni3 , Agma J. M. Traina4 and Caetano Traina Jr.4
1
Federal University of S˜ao Carlos (UFSCar) – S˜ao Carlos, SP, Brazil – renato@dc.ufscar.br
2
University of Londrina (UEL) – Londrina, PR, Brazil – dskaster@uel.br
3
Federal University of ABC (UFABC) – Santo Andr´e, SP, Brazil – {humberto.razente, camila.barioni}@ufabc.edu.br
4
University of S˜ao Paulo (USP) at S˜ao Carlos, SP, Brazil – {agma, caetano}@icmc.usp.br

tuning the weight associated with each signature in order to
discover a reasonable tradeoff between them. It allows the
comparison of several multidimensional mappings from the
same dataset, using distinct sets of signatures and weights.
Our goal is to help the user with an intuitive view of how
to balance multiple signatures giving a view of the impact
of varying the weight relation among them. The technique
was implemented as an extension of the FastMapDB tool
[2], allowing the interactive visualization of data stored in
relational databases in 3D representations.
The paper is organized as follows. Section II surveys the
concepts involved in similarity, multiple signature balancing
and complex data visualization. Section III presents the
proposed technique. Section IV shows case studies using
the technique over real image datasets and Section V brings
the conclusion of the paper.

Abstract—Complex data is usually represented through
signatures, which are sets of features describing the data
content. Several kinds of complex data allow extracting different signatures from an object, representing complementary
data characteristics. However, there is no ground truth of
how balancing these signatures to reach an ideal similarity
distribution. It depends on the analyst intent, that is, according
to the job he/she is performing, a few signatures should have
more impact in the data distribution than others. This work
presents a new technique, called Visual Signature Weighting
(ViSW), which allows interactively analyzing the impact of
each signature in the similarity of complex data represented
through multiple signatures. Our method provides means to
explore the tradeoff of prioritizing signatures over the others,
by dynamically changing their weight relation. We also present
case studies showing that the technique is useful for global
dataset analysis as well as for inspecting subspaces of interest.
Keywords-visual data analysis; multiple signature weighting;
complex data similarity;

II. F UNDAMENTAL C ONCEPTS

I. I NTRODUCTION

A. Manipulation of Complex Data Through Similarity

Data visualization is a task of great importance in the
data exploration process. Many works have addressed the
development of visual data exploration environments, by
adding interaction and analytical reasoning to one or more
visual representations of data. From this integration emerged
visual data mining, which relies on human visual processing
channel and utilizes human cognition [1].
Several kinds of complex data can have a set of signatures
extracted to describe its content. Each signature allows
stating similarity relations between pairs of objects. When
employed together, these signatures can enhance the data
representation power, as they may provide complementary
identifying information. However, stating the relative importance of each signature in the similarity distribution is
a challenging task, as it depends on the analyst intent and
background.
The work presented in this paper describes a new technique called Visual Signature Weighting (ViSW), which
allows the user to visually interact with multiple visualizations of different signatures extracted from the same data,
1550-6037/11 $26.00 © 2011 IEEE
DOI 10.1109/IV.2011.59

Complex data are represented through signatures, or feature vectors, describing one or more object properties, which
are generated by algorithms known as feature extractors.
Classic feature extractors work on describing low-level data
properties, covering a wide scope. For instance, images
present three intrinsic low-level properties: color, texture and
shape. Each of which has several feature extractors focused
on it, such as the Normalized Histogram [3] for color,
the Haralick’s descriptors [4] for texture, and the Zernike
Moments [5] for shape. To improve the semantics in the data
representation, there have been developed several speciﬁc
feature extractors, focused on particular domains, such as
extractors for a given specialty of images of medical exams.
Representing complex data through signatures allows organizing the objects according to the similarity among them.
This is usually done using distance functions to compute the
dissimilarity between two signatures, such as the functions
of the Minkowski family, the Quadratic distance and the
Canberra distance [6]. The challenge is to identify the
282

techniques [8]. Although very useful, such approaches
lack to give to the analyst a global view of the impact
of variations in the balancing of the multiple features.
Furthermore, real datasets usually have subspaces of interest,
which can have conﬂicting parameters to deﬁne the most
adequate similarity. Depending on the goal of the analyst,
the balance of the multiple signatures may require a different
adjust. Therefore, it must be provided mechanisms that allow
users to explore similarity measure settings interactively, to
ﬁgure out the impact of the variations available. This is the
main goal of the work presented herein.

components that form the similarity space, i.e. the signatures
and distance functions, which best ﬁt the user expectation.
One alternative is to employ more than one signature
in the similarity, as distinct feature extractors can provide
complementary information about the complex data content.
The basic approach to combine several signatures is to
concatenate every of them in a single “super-vector”. One of
the drawbacks of this approach is that the resulting similarity
space is high dimensional, facing the curse of dimensionality
problem, which drastically degrades the precision of the
results as well as the performance of the analysis tasks.
Several approaches involving either supervised or unsupervised techniques aim at fusing complementary signatures,
considering the correlation among features, in order to
reduce the dimensionality and enhance the representativeness of the features [7]. Despite of the improvements for
dimensionality reduction, the super-vector approach does not
allow employing extractors that do not generate dimensional
signatures. Moreover, every signature that composes the
super-vector are compared using the same distance function.
However, it has shown that distinct signatures describing the
same object can achieve better results using distinct distance
functions [6]. Therefore, there are several works addressing
alternative ways to combine multiple signatures.

C. Visualization of Complex Data
Through data visualization techniques users may interact
with large amounts of data at the same time. Colors allow
users to immediately recognize the similarities of millions
of data items and the data distribution can be arranged to
express any relationship among them. The integration of
visualization and automatic data mining algorithms in visual
data mining techniques aim to use human perception to discover useful information, in order to help the user on many
tasks such as data clustering [10], data classiﬁcation [11],
post-analysis of discovered rules [12], and trends and outliers
detection [13].
An important issue for most algorithms is the embedded
dimensionality of data. Dimensionality reduction techniques
may be used to generate a new representation of data
for the visualization in a 3D environment. A well known
algorithm for dimensionality reduction is MDS (Multidimensional Scaling) [14], which allows performing data
mappings from high dimensional or metric spaces to lower
dimensional Euclidean spaces, preserving the characteristics
of the original dataset through the distance computation
among pairs of objects. However, MDS presents a computational cost of O(n2 ). An algorithm that provides an
alternative for applications with real time needs, such as data
visualization, is FastMap [15]. This algorithm also allows
performing data mappings from high dimensional to lower
dimensional Euclidean spaces, in linear computational time.
The mappings performed by these algorithms try to preserve
the distances among the data objects minimizing possible
distortions caused by the mapping. The FastMapDB tool [2]
aims at providing an environment for visual data mining.
The input dataset from a relational database is seen as a
collection of points in a complex data space, where each
attribute represents a numeric value describing a given object
property. In this sense, each tuple of the relation represent
a complex object, and the user may try different distance
functions. Thereafter, it uses the FastMap algorithm to map
the original space into a 3-dimensional space, in which the
visualization and interaction is performed. It allows the comparison of multiple mappings from the same dataset, using
distinct subsets of features to visually identify correlations
and perform feature selection. Distinct subsets of features

B. Product Metrics and Multiple Signature Balancing
Another approach to combine multiple signatures is to
aggregate the individual feature similarities, generating a
value that measure the global similarity. This allows employing signatures that do not have a dimensionality deﬁned as well as compare every individual signature using
the best suited distance function. Most feature extractors
produce signatures comparable through metrics, therefore
they can be aggregated using a product metric [8]. A
metric δ is a function deﬁned over a data domain S, that
measures the distance, or dissimilarity, between elements
in S, satisfying the following properties, ∀s1 , s2 , s3 ∈ S:
(1) symmetry: δ(s1 , s2 ) = δ(s2 , s1 ); (2) non-negativity:
0 < δ(s1 , s2 ) < ∞ if s1 = s2 and δ(s1 , s1 ) = 0; and
(3) triangular inequality: δ(s1 , s3 ) ≤ δ(s1 , s2 ) + δ(s2 , s3 ).
It is worth to notice that the most wide employed distance functions are metrics, such as the functions of the
Minkowski family, the Canberra distance, and so on. Each
pair S, δ forms a metric space M. A product metric is a
metric over the cartesian product of a set of metric spaces
M1 × M2 × ... × Mn , which aggregates the metrics that form
the metric spaces.
When individual similarities regarding multiple signatures
are aggregated in a global similarity, it is crucial to balance
them adequately. We call the problem of multiple signature
balacing as how to weight each individual similarity in a
way that they are neither underestimated nor overestimated
in the global computation. Several works addressed this
problem, relying either on supervised [9], or on unsupervised

283

generate mappings that may not maintain direct correspondence to each other in the mapped space, therefore we
employed algorithms to superimpose them using a common
spatial base, with regard to a set of carefully chosen tuples.
This is achieved by computing the geometric transformations
that best approximate the elements of the common base and
appling such transformations to the remainder elements, as
proposed in the techniques Topological Fit and Best Fit [16].

of pivots. The sum of the individual squared errors is the
minimum squared error E, as deﬁned in Equation 1.
E = [e(pivot1 )]2 + [e(pivot2 )]2 + ... + [e(pivotn )]2 (1)
Thereafter, the equation system is stated into the form
A · x = b, which is submitted to a Gaussian elimination
procedure that is used by the least squared error method,
returning the transformation matrix. This adjustment helps
the users to visually state the relevance of individual similarities for each situation, comparing the generated mappings
of several alternative weight relations.
As the visual weight tuning process provided by ViSW is
interactive, it is important to provide the alternative mapping
as fast as possible. In order to reduce the wait time, the
technique pre-computes mappings in background, following
a pre-deﬁned weight relation step. Our hypothesis is that in
general users experiment slight variations in a gradual way,
to ﬁne tune these parameters. At most, one or two abrupt
weight changes can be performed, followed by several slight
variations, which can take advantage of the pre-computed
mappings.

III. T HE V I SW T ECHNIQUE
This section presents the Visual Signature Weighting
(ViSW) technique, developed to allow users to interactively
vary the relative weight of signatures representing a complex
object in the similarity evaluation based on a visualization
of the induced space and also visually analyze the resulting
data distribution.
In essence, a similarity space is deﬁned by the dataset
and the similarity measure employed. Therefore, any modiﬁcation in such components induces an alternative similarity space instance. The FastMapDB, in which ViSW is
implemented, treats features using a variation of the supervector approach for combining multiple vectorial signatures.
The ViSW technique enhanced the FastMapDB to deal with
multiple signatures using a product metric. The user loads a
set of signatures and chooses one of the distance functions
available in the system for each signature. Thereafter, he/she
selects the product metric that will aggregate the partial
similarities. The set of signatures and the product metric
form a metric space, which is employed in the mapping
algorithm to generate the 3D visualization.
After having the ﬁrst 3D mapping, ViSW allows users to
dynamically change the weight relation among the signatures
and visually analyze the generated impact. The weight
relation affects the product metric distance distribution, generating a new mapped space that is visually different from
the original. To compare the mappings, ViSW approximate
the spaces using a technique similar to the Best Fit. The
main difference is that it is necessary to superimpose several
mappings, instead of only two, as the user can vary the
weights on-the-ﬂy. This method selects six elements that
are “in the border” of the mapping whose product metric
has what we call the fundamental weight relation, i.e. when
all partial similarities have weight equal to 1. These elements
are the base pivots and compose axes that are as orthogonal
to each other as possible, as datasets seldom have a set
of elements that are far away from each other that allows
tracing orthogonal axes. The base pivots are used to calculate
the transformation matrix, which converts the original pairs
of base pivots into these pivots in the weight modiﬁed
mapping. Multiplying the transformation matrix and the base
pivot matrix, generates the pivot matrix of the modiﬁed
mapping. These matrixes are expanded generating a system
of equations, whose linear approximation produces the errors
e(pivot1 ), e(pivot2 ), ..., e(pivotn ), where n is the number

IV. C ASE S TUDIES
This section shows case studies employing real datasets
to illustrate the usefulness of the ViSW technique.
A. The ALOI Dataset
The ﬁrst dataset discussed is the Amsterdam Library of
Object Images (ALOI) [17]. It was built photographing small
objects from several view angles and illumination color.
We used a subset of 10 classes in this example, shown
in Figure 1. As it is illustrated in the ﬁgure, each class is
composed by the set of pictures of the same object, totalizing
84 images per class. To simplify the visual interpretation
of the results, the aggregated similarity is given by the
following linear product metric:
n

Δ(x, y) =

wi ·
i=1

δi (xi , yi )
dmaxi

(2)

where x and y are two images, each one with n signatures to
be aggregated, δi is the distance function used for the i-th
signature, wi is the weight of this signature in the global
similarity and dmaxi is the maximum distance between two
instances of this signature, which is used to normalize the
values. In this example, we employed two signatures: a set
of 140 Haralick descriptors (texture) and the 256 gray-level
normalized histogram (color).
We generated several visualizations, varying the relative
weight of the two signatures. In the visualizations in Figure 2a, the whole dataset is plotted, where each class is
represented with a distinct color. It can be visually perceived
that, in general, the classes are better separated from each
other with a higher weight for the Haralick signature (the
leftmost visualization), and when the Histogram signature

284

class

2

1

...

3

...

4

5

6

...

7

8

9

10

...

Figure 1. Sample images of the ALOI dataset. In the ﬁrst line are pictures of the objects employed in this example. The second line shows that each
class is composed by the set of images of the same object.

a)

1 x Histogram + 10 x Haralick

1 x Histogram + 1 x Haralick

10 x Histogram + 1 x Haralick

b)

1 x Histogram+7 x Haralick

1 x Histogram + 1 x Haralick

7 x Histogram+1 x Haralick

class 8

class 7

Figure 2. Visualizations of the ALOI dataset, with varying weight relations. a) Distribution of all classes. b) Zoom on the distribution of classes 7 and 8.

1

Average Precision

is assigned a higher weight the elements become more interleaved in the space (the rightmost visualization). In order
to check this insight, we calculated the retrieval average
precisions [18] of several weight combinations in the product
metric, regarding the whole dataset, as well as two selected
classes (7 and 8), generating the graph in Figure 3. This
graph conﬁrms the visual insight, showing that the best
weight conﬁguration, that is, the combination that yields the
highest average precision, for all classes (the solid black
line in the graph) prioritizes the Haralick signature in the
similarity evaluation. With regard to the two selected classes,
it can be noticed that their average precision curves, also
shown in Figure 3 (the red dashed and the blue dotted lines),
present a pattern similar to the average precision curve of
the whole dataset. This behaviour can be clearly noticed in
the visualizations in Figure 2b, which show zoomed views
of the two classes. These classes are better separated with
higher weights for the Haralick signature, even becoming

0.9
0.8
0.7
0.6

all classes
class 7
class 8

0.5
0.1

1

10

wHistogram / wHaralick
Figure 3.

Average precision graph of the ALOI dataset.

totally disjoint in the space, as it can be seen in the leftmost
visualization in Figure 2b.
B. The MRI 704 Dataset
The MRI 704 dataset is a collection of 704 images of
Magnetic Resonance Imaging (MRI) exams, provided by the

285

1

class 1
Figure 4.

...

class 8

class 9

...

Average Precision

0.9

class 40

Sample images of the MRI 704 dataset.

0.8
0.7
0.6

0.4
0.3

Clinical Hospital of the Faculty of Medicine of Ribeir˜ao
Preto, University of S˜ao Paulo, Brazil. The images are
classiﬁed into 40 classes, according to the body part and
the scan plane, as illustrated in Figure 4. In this case study,
we employed a texture versus shape tradeoff, using 140
Haralick descriptors for texture and the 256 ﬁrst Zernike
moments for shape. The product metric is the same of
the previous example. However, instead of analyzing the
global class behaviour, or comparing pairs of classes, in
this experiment we focused on inspecting the behaviour
of individual classes against the remainder of the dataset.
This task is common in real complex data applications.
For example, in a medical application the analyst could
be interested in the best similarity evaluation settings to
distinguish images that present a given type of lesion from
all the remainder exams.
Figure 5 shows the effect of the weight variation, highlighting two classes with adverse behaviours. In Figure 5a,
the class 9 is highlighted in the visualizations (the yellow
points). Analyzing these visualizations from the left to the
right, it is noticeable that the elements of this class are
mixed with elements of other classes when the value for the
Haralick signature is higher and become increasingly better
separated when the weight of the Zernike signature domains
the similarity. This behaviour is conﬁrmed by the average
precision curve of this class, which is the red dashed line
of the graph in Figure 6. Moreover, this class follows the
general behaviour of the dataset, whose average precision
curve (the solid blue line) reaches the highest value with
higher weights for the Zernike signature. Although it is
not shown in the ﬁgure, usually there is a peak in the
retrieval precision when the best weight combination is
reached, and the retrieval precision drops after this point.
Therefore, even if a signature is dominated by another in the
similarity evaluation, it contributes to improve the precision
of the results. Figure 5b shows visualizations highlighting
the class 1. It can be seen in these visualizations that
this class presents a behaviour that is the opposite to the
behaviour of the whole dataset, being better distinguished
assigning a higher weight for the Haralick signature. Again,
this can be conﬁrmed comparing the average precision curve
of this class (green dotted line) to the other curves in the
graph. Situations similar to the presented in this example are
frequently faced in other real datasets. This makes visible
that the signature weighting depends on the goal of the
analysis being done, focusing on different aspects of the

Figure 6.

all classes
class 9
class 1

0.5

0.1

1

wZernike / wHaralick

10

Average precision graph of the MRI 704 dataset.

data representation according to the situation. The proposed
technique allows detecting such particularities, by selecting
a speciﬁc class and analyzing the variation of its distribution
on the space, regarding different similarity settings.
V. C ONCLUSION
This paper presented the Visual Signature Weighting
(ViSW) technique, which allows visually inspect the impact
of varying the relative weight among multiple complex data
signatures. The technique provides superimposed views of
several mappings of different weight relations, which help
users to analyze the effects both over the whole dataset
and/or focusing on subspaces of interest. ViSW was implemented as an extension of the FastMapDB tool, allowing
to handle large complex datasets identiﬁed through multiple
signatures stored on relational databases, whose similarity
is aggregated into a product metric. We also presented
case studies showing the usefulness of the technique when
performing visual analysis of real image datasets. Future
work include adding knowledge in the signature balancing
process, to try to reduce the iterations performed, while still
being user-guided through the visualizations provided.
ACKNOWLEDGMENT
This work has been supported by CNPq, CAPES,
FAPESP, STIC-AmSud and Microsoft Research.
R EFERENCES
[1] S. J. Simoff, M. H. B¨ohlen, and A. Mazeika, “Visual data
mining: An introduction and overview,” in Visual Data Mining, ser. LNCS. Springer, 2008, vol. 4404, pp. 1–12.
[2] M. Barioni, E. Botelho, C. Faloutsos, H. Razente, A. Traina,
and C. T. Jr., “Data visualization in RDBMS,” in IASTED
ISDB, 2002, pp. 264–269.
[3] R. C. Gonzalez and R. E. Woods, Digital Image Processing
(3rd Edition). Upper Saddle River, NJ, USA: Prentice-Hall,
Inc., 2006.
[4] R. M. Haralick, “Statistical and structural approaches to
texture,” in IEEE, vol. 67, 1979, pp. 786–804.

286

a) class 9
1 x Zernike + 8 x Haralick

1 x Zernike + 4 x Haralick

1 x Zernike + 1 x Haralick

4 x Zernike + 1 x Haralick

8 x Zernike + 1 x Haralick

b) class 1
1 x Zernike + 8 x Haralick

Figure 5.

1 x Zernike + 1 x Haralick

8 x Zernike + 1 x Haralick

Visualizations of the MRI 704 dataset with varying signature weight relations, highlighting the classes 9 and 1.

[5] A. Khotanzad and Y. H. Hong, “Invariant image recognition
by Zernike moments,” IEEE TPAMI, vol. 12, no. 5, pp. 489–
497, 1990.

[12] K. Zhao, B. Liu, T. M. Tirpak, and W. Xiao, “A visual
data mining framework for convenient identiﬁcation of useful
knowledge,” in IEEE ICDM, 2005, pp. 530–537.

[6] P. H. Bugatti, A. J. M. Traina, and C. Traina Jr., “Assessing
the best integration between distance-function and imagefeature to answer similarity queries,” in SAC. Fortaleza,
CE, Brazil: ACM, 2008, pp. 1225–1230.

[13] E. A. Rundensteiner, M. O. Ward, J. Yang, and P. R. Doshi,
“XmdvTool: Visual interactive data exploration and trend
discovery of high-dimensional data sets,” in SIGMOD Conf.,
2002, p. 631.

[7] Y.-H. Yuan, Q.-S. Sun, Q. Zhou, and D.-S. Xia, “A novel
multiset integrated canonical correlation analysis framework
and its application in feature fusion,” Pattern Recogn., vol. 44,
pp. 1031–1040, 2011.

[14] J. B. Kruskal and M. Wish, Multidimensional Scaling. SAGE
Publications, 1978.
[15] C. Faloutsos and K.-I. Lin, “FastMap: A fast algorithm for
indexing, data-mining and visualization of traditional and
multimedia datasets,” in SIGMOD Conf., 1995, pp. 163–174.

[8] R. Bueno, D. S. Kaster, A. A. Paterlini, A. J. M. Traina,
and C. T. Jr., “Unsupervised scaling of multi-descriptor
similarity functions for medical image datasets,” in CBMS.
Albuquerque, New Mexico, USA: IEEE, 2009, pp. 1–8.

[16] H. L. Razente, F. J. T. Chino, M. C. N. Barioni, A. J. M.
Traina, and C. T. Jr., “Visual analysis of feature selection for
data mining processes.” in Brazilian Database Symposium,
Brasilia, DF, 2004, pp. 33–47.

[9] B. Bustos, D. Keim, D. Saupe, T. Schreck, and D. Vranic,
“Automatic selection and combination of descriptors for effective 3d similarity search,” in Multimedia Software Engineering. Miami, FL, USA: IEEE, 2004, pp. 514–521.

[17] J. M. Geusebroek, G. J. Burghouts, and A. W. M. Smeulders,
“The Amsterdam library of object images,” International
Journal of Computer Vision, vol. 61, no. 1, pp. 103–112,
2005.

[10] K. Chen and L. Liu, “iVIBRATE: Interactive visualizationbased framework for clustering large datasets,” ACM Trans.
Information Systems, vol. 24, no. 2, pp. 245–294, 2006.

[18] R. A. Baeza-Yates and B. A. Ribeiro-Neto, Modern Information Retrieval. Wokingham, UK: Addison-Wesley, 1999.

[11] J. Zhang, L. Gruenwald, and M. Gertz, “VDM-RS: A visual
data mining system for exploring and classifying remotely
sensed images,” Computers & Geosciences, vol. 35, pp. 1827–
1836, 2009.

287

