2011 15th International Conference on Information Visualisation

Abstract Camera Controller for Three-Dimensional Visualizations
1

Adrian Rusu1, Spence DiNicolantonio1, Robert Russell , Eric Velte2
1
Department of Computer Science, Rowan University, U.S.A.
2
Mission Solutions Engineering, U.S.A.
rusu@rowan.edu, {dinico58, russel42}@students.rowan.edu, eric.velte@missionse.com
default camera orientation. IV programmers are free to
query or apply rotations in a variety of forms: Euler
angles, axis and angle notation, a unit quaternion, or a
direction-cosine matrix (DCM). Our controller also
contains a locking focus system and, in turn, automated
orbital movement around the camera’s point of focus.
From an integration point of view, our system
requires only a few lines of code to be tied into any
graphics API. A few queries must be made to get the
camera’s position and orientation information, which can
then be applied to a graphics API of choice, as needed.
Extensive work has been done in the past to
overcome obstacles in the field of graphics camera
systems, but this research tends to focus on the design of
high-level behavior concepts and is typically embedded
in large-scale systems [18]. These systems often bring
limitations to users with regard to input methods and
offered behaviors. In contrast, our system places priority
on simplicity, providing the basics of three-dimensional
control and leaving all other aspects of camera behavior
and input extraneous to the camera. Our system is an
API for graphics and IV programmers. It is not tied to
any graphical front-end and thus remains flexible for use
in virtually any system. Because user input is extrinsic to
our system, IV programmers are free to leverage the
convenience of our system, without being limited in any
way.
Another key benefit of our camera control system is
the way in which it encourages the development of highlevel automation and innovative viewpoint techniques.
By hiding the intimidating complexities of simple
camera manipulation, more advanced displays and frontend systems can be achieved.
Our paper is structured as follows: in section 2 we
explain the architecture of our camera controller system,
in section 3 we describe how our system benefited IV
programmers through a use case, and in section 4 we
explain future enhancements, followed by conclusions in
Section 5.

Abstract
In the realm of computer graphics, methods used to
control a user’s point of view in a three-dimensional
world are rather convoluted and are often tightly
coupled to the rendering system used. In response to this
issue, we have developed a robust camera controller
system that provides an intuitive interface for
visualization and simulation programmers, while
removing renderer dependencies completely. Our system
follows common object oriented design principles to
encapsulate the complex mathematics and computations
involved in synthetic camera manipulation, providing a
firm foundation for high-level camera features. We
provide a use case where students with no graphics
experience developed a visualization system using our
camera controller.

1. Introduction
Proper manipulation of a user’s viewpoint is
essential to any visualization posed in three-dimensional
space. If a 3D visualization system does not provide fluid
movement and control in an intuitive manner, users may
become distracted from the data or concepts being
presented to them. Unfortunately, the current methods
used in computer graphics programming for viewpoint
manipulation do not provide an easy way to meet this
need and, in fact, don’t allow movement of the viewpoint
at all.
According to the synthetic camera model adopted by
most 3D graphics APIs, the virtual camera can be
controlled only as far as defining the dimensions of its
view frustum. This is the frustum (truncated pyramid) of
viewable space extending from the front of the camera.
Rather than allowing manipulation of the camera’s
position and orientation within respect to the world
coordinate system, all objects in the world must be
projected to the camera’s local coordinate system [1],
[15].
Our camera controller system acts as a façade
between the counter-intuitive graphics API and the
aspiring information visualization (IV) programmer,
providing multiple conveniences and features. The
controller stores camera state information internally and
supplies a straightforward API to programmers for
manipulation and queries. Essentially, the dynamic
properties of a camera can be reduced to two
characteristics: position and orientation. Position is
represented as a three-dimensional vector, while
orientation is represented as a rotation relative to a
1550-6037/11 $26.00 © 2011 IEEE
DOI 10.1109/IV.2011.55

2. Architecture
Our camera controller system has three distinct
modules (see Figure 1). The first layer is the synthetic
camera itself. Following the camera layer is a layer that
encapsulates all geometric transformation logic needed
to support the function and features of the synthetic
camera. Finally, below the logic layer is a layer
consisting of all non-primitive data types used in the
system.
434

Figure 1. An IV application is built on top of the
camera controller, which can then be integrated
with any graphics API via a simple adapter.

Figure 2. A three-gimbal system (left), providing
three degrees of freedom. Gimbal lock (right):
two axes are aligned, resulting in a loss of one
degree of freedom.

2.1. Integration
Integration with any graphics API can be
accomplished via a simple adapter. The adapter queries
the camera system for information on its current state,
including position, orientation, and optionally, clipping
or field of view information. This queried data is then
applied according to the graphics API in use. After the
adapter has been created, IV developers are free to
control all aspects of viewpoint manipulation via the
camera controller’s interface without worrying about the
underlying graphics system.
By leveraging the adapter pattern [6], a user is able
to change platforms and/or graphics API’s as needed,
with very few changes required to the actual application.
Upon switching to a new graphics API, a developer can
simply create a new adapter, applicable to the new API.
All other aspects of the application, with regard to
camera control, remain unaffected.

In order to resolve this difficulty, we abstracted the
concept of rotation from its underlying representation
entirely and designed a Rotation class that can be defined
using a variety of forms. Internally, a Rotation object is
represented by a unit quaternion, because it avoids
gimbal lock and requires less memory for storage than a
DCM matrix. From an IV programmer’s perspective,
however, Rotation objects can be constructed using Euler
angles, axis and angle notation, a unit quaternion, or a
DCM matrix. In addition, Rotation objects can be
queried for description in any notation desired following
creation. This feature is made possible by a collection of
conversion algorithms [10], [16], [17] hidden within the
Rotation abstraction, which is convenient for IV
programmers. Beyond the simple elegance of a unified
abstraction, it allows the use of Euler angles, or any
preferred notation, without the limitation of gimbal lock.

2.2. Data Types
2.3. Conventions
The two fundamental elements of camera state are
position and orientation. Position in 3D space can easily
be represented as a three-dimensional vector, but
defining orientation is more complex. One can inherently
describe an orientation by the rotational variation from a
given origination, or default orientation; however, there
are many ways to define a 3D rotation mathematically
and each has its advantages and disadvantages.
When first approaching the concept of rotation, the
most intuitive, and thus desirable, representation is with
the use of Euler angles (i.e., yaw, pitch, and roll).
Unfortunately, when dealing with relative rotation, the
use of Euler angles introduces a problem known as
gimbal lock. In a three-gimbal system, bringing the axes
of two gimbals into a parallel configuration results in the
loss of one degree of freedom (see Figure 2) [9]. A threegimbal system is analogous to a system based purely on
Euler angles, thus gimbal lock poses a serious limitation.
To avoid gimbal lock, one can use DCM matrices or unit
quaternions to represent rotation [4], [13], [14], but these
methods are rather abstract and specifying rotations
explicitly in this manner is very difficult from a user’s
standpoint.

Prior to development, certain conventions needed to
be established for our system. First, the default
orientation of the camera (represented by the identity
matrix) must be defined. We chose to adopt the
convention used in OpenGL, the industry standard
graphics API, in which the camera faces the negative zaxis, with the positive y and x axes extending upward
and to the right, respectively (see Figure 3) [15].
In addition, there must be an established convention
for the application order of Euler angles, as variation will
yield differing results. We chose to adopt the order used
in the NASA standard airplane: yaw, pitch, and then roll
[3]. It is important to note that while our chosen Euler
order convention adheres to the NASA standard, our
chosen coordinate system does not (see paragraph
above). Therefore, with regard to our camera’s
coordinate system, yaw-pitch-roll equates to y-x-z,
whereas the same ordering equates to y-z-x with using
NASA’s standard airplane system. From a user’s
standpoint, the difference is unnoticeable with regard to
relative rotation and only visible when applying absolute
rotation to the camera system (using the world
coordinate system). Furthermore, this divergent behavior

435

about viewpoint’s origin; however, our system also
supports rotation about any given point (see section
2.4.5).

is invisible when thinking about camera control in terms
of yaw, pitch, and roll (rather than coordinate axes),
which is typically the case.

2.4.3. Look At
Many graphics APIs support a “Look at” feature that
will adjust the projection matrix in order to face a given
point in 3D space [1], [15]. This feature, while
convenient, may cause problems. When dealing with a
graphics API directly to manipulate viewpoint,
orientation is typically stored and updated manually
when change is needed. In this situation, upon making a
call to the graphics API’s “Look at” function, the stored
orientation is invalidated, as the resultant orientation will
no longer match the stored orientation data. Within our
system, this is not an issue because orientation is selfcontained. Upon receiving a “Look at” invocation, our
camera controller automatically updates all fields as
needed.

Figure 3. Our system follows the camera
orientation convention established by OpenGL,
in which the camera faces negative z-axis, with
positive y and x axes extending upward and to
the right, respectively.

2.4.4. Focus System
2.4. Features
While designing our “look at” functionality, we
began to recognize a certain amount of importance
associated with the camera’s focus point. This is the
point in space at an arbitrary distance along the camera’s
view vector on which the camera is “focusing”. In
particular, we realized that in many situations, it is
desirable to maintain the camera’s focus on a given point
regardless of movement. An example of this can be seen
in our use case (see Section 3), in which the camera
needed to focus on the center of a virtual Earth model
while orbiting around to a desired vantage point. As a
result, we chose to make the focus point of the camera
persistent and developed a toggle-able locking
mechanism. Our camera controller’s interface allows a
user to easily toggle a lock on the camera’s current focus
point. Doing so will prevent the camera from altering its
focus. When the camera’s focus is locked, modifications
to the camera’s state will cause its orientation to be
subsequently rectified to view the locked focus point.

2.4.1. Basic Movement
Although movement is the simplest feature in a 3D
camera system, it is also one of the most important. Fluid
movement is key in the attempt to portray realism. Our
camera control system not only gives the ability to get
and set the position of the camera, but also provides an
interface for both absolute and relative movement of the
camera according to a given displacement vector.
Absolute movement can be used in the event that the
camera needs to be moved with respect to the world
coordinate system, while relative movement is available
in the event that movement relative the camera’s local
coordinate system is more desirable. For example, the
movement in a first-person simulation will always be
relative to the orientation of the viewer, thus relative
movement is preferred. Alternatively, when a scripted
movement track is involved with simultaneous usercontrolled viewing, such as in a simulation of an
amusement park ride, absolute movement is better suited
in order to keep user-invoked orientation changes from
altering the path of motion.

2.4.5. Orbital Movement
The locking focus system provides a foundation for
a variety of new features, one of which being orbital
movement. When the camera’s focus is locked, yaw and
pitch are restrained, but roll functionality is left
unaffected, as it will not cause any alteration of the focus
point. Movement, on the other hand, becomes rather
different, depending on the approach used. Absolute
movement will only be divergent with regard to a
resetting of the camera’s orientation after movement has
been completed (in order to face the locked focus point).
Relative movement forward and backward will not be at
all different. However, any relative movement involving
the x or y axes while the camera’s focus is locked will be
substantially different than while the focus is unlocked.

2.4.2. Orientation/Rotation
Using the Rotation class abstraction, achieving
proper orientation and rotation of the viewpoint is
straightforward. Querying the camera controller for
orientation yields a Rotation object, which can then be
queried for any form of rotational notation. Similarly, the
orientation of the camera is set according to a given
Rotation object, created via any desired notation.
Much like the provided movement support, a
camera’s orientation can be altered with respect to the
world coordinate system, or to the camera’s local
coordinate system. By default, all rotation is performed

436

Consider an arbitrary point, p, located on the
negative z-axis. Now consider a camera located at the
world origin, with focus locked on p, undergoing a series
of relative movements along the camera’s local x-axis.
Following the first movement, the camera will still be
located on the world x-axis, but its orientation will have
been consequently rectified to continue facing p. It can
be easily seen that although each movement applied to
the camera is in the same direction with regard to the
camera’s local coordinate system, the absolute direction
of motion (in the world coordinate system) has changed
and will be continuously changing with each subsequent
movement. If we were to map this movement within the
x/y plane, we would actually see a spiral around p (see
Figure 4). The behavior we have just encountered is
essentially orbital movement, but with some error based
on the magnitude of displacement. In a perfect
theoretical system, with an infinitesimal displacement
per time quanta, no error would be present, resulting in
perfect circular movement about the focus point

computations involved in synthetic camera manipulation
within a three-dimensional visualization. In this section,
we establish how an IV programmer interacts with our
system for a simple and intuitive experience. The
interface is designed for ease and efficiency, as it
promotes elegance and effectiveness within the
production of IV applications.
2.5.1. Adapter
The following example describes the essential
component of an adapter integrating our camera control
system with JOGL, the Java bindings to OpenGL, a
common graphics API (see Listing 1). The methods
called will be discussed in Sections 2.5.2 and 2.5.3.
/**
* Called by the drawable to initiate OpenGL rendering
*/
public void display(GLAutoDrawable drawable) {
// get rotation camera’s current orientation
Rotation orientation = camera.getOrientation();
// inverse for application to Modelview matrix
orientation = orientation.inverse();
// get orientation in matrix form
Matrix rotMatrix = orientation.toMatrix();
// construct array containing matrix data
double[] matData = rotMatrix.toArray(
Matrix.ArrayOrder.COLUMN_MAJOR);
// create double buffer of using rotation matrix data
DoubleBuffer matrixBuffer =
BufferUtil.newDoubleBuffer(matData.length);
matBuffer.put(matData);
matBuffer.rewind();

Figure 4. Illustration of spiral affect experienced
during relative movement with locked focus,
prior to orbital rotation fix.

// apply camera orientation to Modelview matrix
gl.glMultMatrixd(matBuffer);
// get camera position
Vector3D pos = camera.getPosition();
// inverse for application to Modelview matrix
pos = pos.inverse();

We fix this spiral effect by implementing an orbital
movement algorithm and integrating it into our relative
movement algorithms for the specific case in which the
camera’s focus is locked. Because orbital movement is
effectively rotation about an arbitrary point, we start by
adding this functionality to our camera. Then, within our
relative movement algorithm, we leverage orbital
rotation in the event that focus is locked, using the given
displacement vector’s magnitude and direction as arc
length and rotational tangent respectively. After the
rotation has been performed, we simply adjust the
camera’s orientation to look at its initial focus point, thus
achieving the desired results.

// apply camera position to Modelview matrix
gl.glTranslated(pos.getX(), pos.getY(), pos.getZ());
// graphics code
…
}
Listing 1. Example camera adapter, taken from
“Reverie”, an information visualization testing
environment being developed at Rowan
University.

2.5. Programming Interface
As established in previous sections, our camera
controller
system
encapsulates
the
complex

437

At this point, the camera controller is completely
wired to the graphics API. The bottom two layers of our
IV application architecture (see Figure 1) have been
completely established; therefore, the camera controller
can be used exclusively for camera manipulation without
consideration of the layers beneath.

useful when such information is dynamic and needed by
the adapter.
2.5.3. Rotation
The Rotation class provides a variety of constructors
and methods for creating, querying, and manipulating
abstract rotations. The constructors available allow the
creation of Rotation objects via Euler angles, an axis and
angle of rotation, a DCM matrix, or a unit quaternion.
Once created, methods such as getEulerAngles(),
toMatrix(), and setPitch(double), among many others,
can be used to query or alter information about the
Rotation object with respect to any desired rotational
formatting. The Rotation class provides an inverse()
method, which computes and returns the inverse rotation,
as well as an append(Rotation) method for concatenating
a series of rotations. In addition, the slerp(Rotation,
double) method can be used for computing the spherical
linear interpolation across a given rotation, according to
a given interpolation factor.

2.5.2. Camera
Since we have established the foundation for an IV
application, we now describe the interface available for
manipulation and control of the synthetic camera. Our
system follows the principles of information hiding, and
thus all camera control methods are supplied within the
Camera class itself, independent of the underlying logic.
The getPosition() and setPosition(Vector3D)
methods are used to get and set the camera’s position,
respectively. The move(Vector3D, …) method is used to
move the camera according to a given displacement
vector. Optionally, a boolean value can be supplied to
explicitly specify whether absolute or relative movement
should be applied to the camera; movement is relative by
default.
The getOrientation() and setOrientation(Rotation)
methods are used to get and set the camera’s orientation,
respectively, in the form of an abstract Rotation object.
The rotate(Rotation, …) method is used to rotate the
camera about its origin. Similar to the move method, the
rotate method can be given an optional boolean value, in
order to explicitly specify absolute or relative rotation,
relative rotation being the default. The rotate(Rotation,
Vector3D, boolean) method is used for orbital rotation;
i.e., rotation about a given point. As parameters, it takes
the rotation to be applied, the point about which rotation
will occur, and a boolean flag stating whether or not to
alter the camera's orientation with the applied rotation.
The lookAt(Vector3D, …) method is used to rotate the
camera to focus on a given point, changing the local yaxis (relative “up”) as little as possible. Optionally, a
desired local y-axis can be specified.
The following methods can be used to access
information about the camera’s focus. The
getFocusPoint() method will return the point in 3D space
on which the camera is focused, while getFocusDepth()
will return the distance between the camera and the focus
point. Another method called getFocusVector() is also
provided, which will return a vector pointing from the
camera’s
origin
to
its
focus
point.
The
getFocusedLocked() method is used to determine
whether the camera’s focus is currently locked.
Furthermore, mutator methods are provided for each of
these focus methods.
Information regarding the camera’s local coordinate
system can be queried using the getLocalXAxis(),
getLocalYAxis(), and getLocalZAxis() methods. For
convenience, the Camera class also provides storage and
accessors/mutators for querying/setting near clipping
distance, far clipping distance, and field of view angle.
While these elements are not actually used intrinsically
by the camera system, this added interface could be

2.5.4. Vector3D
The Vector3D class encapsulates vector algebra logic,
including addition, subtraction, scalar multiplication, dot
and cross products, inverse computation, and linear
interpolation. Many other query methods are supported
such as isUnitVector(), which checks for a magnitude of
1, and isParallel(Vector3D) which determines if the
vector is parallel to another given Vector3D object. The
Vector3D class also contains a rotate(Rotation,
Vector3D) method that rotates the vector by a given
amount about a given point in 3D space.

3. Use Case
Our camera control system is currently being used at
Rowan University. Undergraduate computer science
students are required to take a course titled “Software
Engineering I”. In this course, students work on realworld projects with customers from large corporations.
One project given in a recent semester required the
assigned group to develop a system that could display
and track various data elements, which are represented as
spheres, around Earth using a three-dimensional
visualization (see Figure 5). This project required
graphics programming to display the visualization as
well as precise camera control, including movement and
reorientation, within the 3D world to provide coherent
following behaviors while tracking objects. None of the
students in the group had any experience with computer
graphics. By leveraging our camera control system, the
group was able to successfully deliver the project to their
customer with very little external guidance.
Overall, the use of our camera control system was a
success. Undergraduate students, who had no prior
experience with OpenGL or any other form of graphics
programming, were able to develop an application that
leverages advanced three-dimensional graphics. The

438

movement of the camera and rendering of the world is
completely decoupled from their application, which
allows development of new functionality for either part
of the system in the future. Information hiding is
prevalent, as the students were not concerned with the
mathematics and science associated with manipulating
the camera. The students were only concerned with our
supplied API and how these methods could be leveraged
to accomplish their goals.

References
[1]

[2]

[3]
[4]

[5]

[6]

[7]

[8]

Figure 5. Students had to track elements around
the Earth using our camera controller system.
[9]

4. Future Enhancements

[10]

Our camera controller can be expanded with other
high-level features and automation. One of the planned
developments includes an automated object-following
algorithm and enhancement of our focus system. This
expansion will provide the camera with the ability to
focus on a collection of arbitrary focus points by
computing the centroid of these points. In addition, the
extended system will support any number of secondary
focus points, which will stipulate additional points of
interest. The camera system will be able to intelligently
reorient and reposition itself in order to center viewing
on the centroid of all primary focus points, while keeping
all secondary focus points in view as well.

[11]

[12]

[13]

[14]

5. Conclusion

[15]

Our abstract camera controller system offers an
intuitive and elegant replacement to an otherwise
byzantine process. The system successfully encapsulates
the complexities of the synthetic camera model,
providing a comprehensible and pleasant experience for
any IV developer or graphics programmer. Our system is
currently in use within a variety of applications and
visualization systems, and is even used as a learning tool
within certain University courses. Students are provided
with the opportunity to experience graphics and
animation programming without the hurdle of learning
low-level camera manipulation.

[16]

[17]

[18]

439

Hearn Baker. Three-Dimensional Viewing. In Computer
Graphics with OpenGL, Third Edition. Pearson Prentice
Hall. 334-400. 2004.
Frederick Brooks. Walkthough – A Dynamic Graphics
Environment for Simulating Virtual Buildings. In
Proceedings of the 1986 Workshop on Interactive 3D
Graphics. 9–22. October 1986.
Haim Baruh. Analytical Dynamics. Mcgraw Hill. 1999.
Evangelos A. Coutsias and Louis Romero. The
Quaternions with an application to Rigid Body
Dynamics. February 1999.
Steven M. Drucker and David Zeltzer. CamDroid: A
System for Implementing Intelligent Camera Control. In
Proceedings of the 1995 symposium on Interactive 3D
graphics. ACM, 139-144. April 1995.
Erich Gamma, Richard Helm, Ralph Johnson, and John
Vlissides. Design Patterns: Elements of Reusable
Object-Oriented Software. AddisonWesley. November
1994.
Sundaram Ganapathy. Decomposition of transformation
matrices for robot vision. In International Conference on
Robotics. 130–139, March 1984.
Michael Gleicher and Andrew Witkin. Through-the-lens
camera control. In Proceedings of the 19th annual
conference on Computer graphics and interactive
techniques (SIGGRAPH '92), James J. Thomas (Ed.).
ACM, 331-340. 1992.
David Hoag. MIT Instrumentation Laboratory Document
E-1344: Considerations of Apollo IMU Gimbal Lock. In
Apollo Guidance and Navigation. April 1963.
Noel H. Hughes. Quaternion to Euler Angle Conversion
for Arbitrary Rotation Sequence Using Geometric
Methods.
url:
http://www.euclideanspace.com/maths/geometry/rotation
s/conversions/quaternionToEuler/quat_2_euler_paper_ve
r2-1.pdf
P. Karp and S. Feiner. Issues in the Automated
Generation of Animated Presentations. Graphics
Interface '90 Halifax, Nova Scotia. 1990.
A. R. Klumpp. Singularity-free extraction of a
quaternion from a direction-cosine matrix. In Journal of
Spacecraft and Rockets, vol. 13. 754-755. Dec. 1976.
E. E. L. Mitchell and A. E. Rogers. Quaternion
Parameters in the Simulation of a Spinning Rigid Body.
In Simulation: the dynamic modeling of ideas and
systems with computers. John McLeod. 1988.
Ken Shoemaker. Animating rotations with quaternion
curves. Computer Graphics. 245–254. July 1985.
Dave Shreiner and The Khronos OpenGL ARB Working
Group. Viewing. In OpenGL(R) Programming Guide:
The Official Guide to Learning OpenGL, Version 3.0 and
3.1 (7th Edition).
Arland Thompson. Euler Sequences. Advanced
Technology
Associates.
url:
http://
www.atacolorado.com/eulersequences.doc
Arland Thompson. Quaternion Simulation. Advanced
Technology
Associates.
url:
http://
www.atacolorado.com/quaternionsimulation.doc
Colin Ware and Steven Osborne. Exploration and virtual
camera
control
in
virtual
three-dimensional
environments. In Proceedings 1990 Symposium on
Interactive 3D Graphics. 175–184. March 1990.

