Haptic and Sound Correlations: Pitch, Loudness and Texture
Dessislava Peeva
Bridget Baird
Ozgur Izmirli
Donald Blevins
Ammerman Center for Arts & Technology, Connecticut College
dtpee@conncoll.edu bbbai@conncoll.edu oizm@conncoll.edu dkble@conncoll.edu
Abstract
People process information through multiple
modalities and many studies have been done that show
interaction among the auditory, haptic and visual modes.
This paper reports on a correlation between the haptic
property of roughness and each of the audio properties of
pitch and loudness. There were four experiments: given a
roughness, match a loudness level to it and vice versa and
given a roughness, match a pitch to it and vice versa.
Subjects showed a strong correlation in the first two
experiments, associating louder sounds with rougher
textures and softer sounds with smoother textures. They
also showed, although not always in the same direction, a
strong correlation between pitch (high/low) and
roughness. Applications of this study are to multimodal
user interfaces and to music cognition.

1. Introduction.
Multimodal information is used in most everyday
tasks and many studies have shown that multimodal
computer interfaces and processing improves performance
of some tasks. Reasons for including multiple modes in
interface design include the obvious one that people are
more used to processing certain kinds of information in
one mode rather than another, but also reflect the idea that
information can be conveyed more clearly in one mode
than in another and that processing in one mode may ease
the overload on a different mode (usually the visual). In
particular, as regards haptics, Hale & Stanney [1] suggest
that, based on the work by James et al. [2], object
identification through haptics is a good alternative when
there is visual overload. Thus, understanding how
multiple modes interact with each other will shed light
into more effective interface design. The present study
explores the presence of correlations between specific
haptic and auditory qualities: haptic texture and pitch, and
haptic texture and loudness.
Haptic textures can be synthetically generated using
high resolution haptic devices and can be varied under

program control for experimental purposes. Previous
studies by Lederman in the perception of haptic texture
have shown that the perceived roughness increases with
increasing groove width and interelement spacing on a
surface [3]. Costa and Cutkovsky [4] studied the
perceptual roughness of haptically displayed fractal
surfaces and found that surfaces were characterized by
their root mean square amplitude and that the perceived
roughness was negatively correlated with the fractal
dimension.
The integration of haptic and aural cues has been
studied under various experimental conditions. Yu et al.
[5] studied the integration of surface property and
auditory cues in a system that was designed to assist blind
users in exploring haptic graphs. Yu & Brewster [6] have
developed a system in which multimodal data
visualization is achieved using force feedback,
synthesized speech and non-speech audio to present
graphical data. Lederman et al. have demonstrated that
audio cues improve performance in haptic tasks [7,8,9].
To find the relative contributions of haptic and auditory
modalities, they experimented with touch-only, auditiononly and bimodal conditions and found that the
participants were more confident in the bimodal case in
their judgments. They also reported that touch cues were
twice as heavily weighted as auditory cues. Zahariev &
MacKenzie [10] examined the role of auditory and visual
cues in the presence of haptic cues and found that
auditory cues made a significant contribution.
Chu [11] has reported that incorporation of haptics in
the context of audio navigation in sound editing improves
precision and response time in locating audio content.
High resolution multimodal interfaces play a vital role in
experimentation and application in this field. DiFilippo et
al. [12] reported on a low latency computer interface that
had the haptic and auditory modes tightly coupled. The
amount of permissible delay time (just noticeable
difference) between a haptic event and its corresponding
auditory signal has been studied by Adelstein et al. [13].
Several studies have been done that link auditory
information to perceptions of roughness. McGee et al.
performed studies examining the effects the addition of
auditory cues has on the perception of texture [14, 15].

Proceedings of the Eighth International Conference on Information Visualisation (IV’04)
1093-9547/04 $ 20.00 IEEE

Poling et al. studied multisensory feedback, consisting of
visual and haptic conditions, in the perception of surface
roughness [16]. Their results suggest that the haptic
modality was dominant at low surface amplitudes, the
visual modality was dominant at high surface amplitudes
and at intermediate levels both modalities were being
utilized. The bimodal case was more effective when
compared to either single modality condition. Recent
work by Weisenberger and Poling [17] employs audio
(controlled by user actions) to discriminate virtual surface
textures.
The studies mentioned above that relate audio and
haptics employ either realistic audio to guide the user or
generate audio that is a combination of band-limited
noises or synthesized speech. Two of the authors have
developed applications that use multiple modalities and
have music as the audio source. In [18], Baird and Izmirli
look at the visualization of musical sound. Their work in
studying the movements of conductors examined how
magnetic tracking devices could be used to create a virtual
conductor [19]. This work also addressed the issues of
coordination, synchronization and anticipation in
generating movement using aural feedback. In [20,21]
they created a virtual toolkit, which provided a visual,
sound and haptic coupling of an array of parameters. For
example, an increase in haptic pressure on an object could
trigger a visual intensification of color as well as
simultaneously causing a raising of the pitches associated
with the object.
The current work stems from an inquiry into
connections between audio characteristics and haptic
characteristics and forms part of a broader examination of
the nature of multimodal correlations. Results about these
correlations could not only shed light on the interactions
of these modalities but could then be exploited in the
construction of user interfaces.
The current study tested the hypothesis that users
would make a correlation between audio characteristics
and haptic characteristics. We decided that the two audio
characteristics that were most salient and quantifiable
were pitch and loudness. We considered using timbre
(the kind of instrument, e.g. the sound of a violin as
opposed to that of a piano) as another possible
characteristic, but it is a complex issue that is not well
quantified or understood in the music domain. Similarly,
auditory roughness, which would be the most obvious
auditory characteristic, is hard to quantify and it is
difficult to generate sounds with varying roughness using
a single dimensional control parameter. We also felt that
users were well equipped to distinguish among levels of
loudness, given that the range was large and that the
levels were chosen uniformly in that range. Pitch is a
more complicated parameter for users, because those
more familiar with music have a greater facility for
distinguishing different pitches, but since we were not

asking users to identify absolute pitches, but rather to
compare the order of pitches that were not close together,
we felt that most users could make the distinction. The
pitches had a wide range of values from high to low and
did not include any that were close together. However,
because the experiments involved musical tones, we
asked the subjects to complete a questionnaire that
included inquiries about their musical background. The
haptic characteristic that is generally used in these
multimodal experiments and the one we felt would be
most strongly correlated with audio characteristics was
roughness and so this was the haptic characteristic we
used.
In order to test our hypothesis, there were four
experiments in this study: given a texture, choose a
loudness level (from among the choices) that most closely
matches the texture; given a loudness level, choose a
texture that most closely matches it; given a texture,
choose a pitch; and given a pitch, choose a texture. In all
cases the levels for each of the characteristics (seven in
all) were fixed and the user was forced to make a choice
from among those options.

2. Method.
2.1. Participants.
There were 20 subjects for this experiment, 11
females and 9 males, all of whom volunteered from
computer science courses and a psychology course. Their
ages ranged from 18 to 23. Their musical backgrounds
ranged from no experience with musical instruments or
voice training to perfect or acquired pitch and the ability
to play by ear.

2.2. Apparatus.
A PHANToM force-feedback device from SensAble
Devices, Inc. was used in conjunction with the GHOST
software to generate the textures. Audio tones were
transmitted via closed headphones to minimize outside
interference. Graphics on the screen depicted a
rectangular surface (with no texture mapping) and a small
sphere to give the location of the haptic device. The
rectangular surface did not give any indication of the
roughness being experienced through the haptic device
and was included so that users (who were not experienced
with haptic devices) would not get disoriented. There was
a virtual haptic wall and ceiling around the rectangle so
that users could not fall off the surface or explore the
shape. Graphics were rendered in World Toolkit (Sense8).
Seven different textures for the surface were
generated by using virtual sinusoidal gratings with
varying amplitude and constant spatial frequency. We
determined experimentally the highest amplitude the

Proceedings of the Eighth International Conference on Information Visualisation (IV’04)
1093-9547/04 $ 20.00 IEEE

PHANToM device could tolerate with stability; the
smoothest texture had zero amplitude. Intermediate
textures were calculated by equally spaced amplitudes.
This meant that the textures ranged from completely
smooth to very rough.
For the pitch experiment, seven sounds with the same
loudness but different fundamental frequencies were used.
These sounds were composed of five equal amplitude
harmonics with fundamental frequencies ranging from
100 Hz to 653 Hz in increments of perfect fourths. i.e. the
frequency ratio of the fundamentals between two
neighboring tones was 2(5/12). All tones were normalized
to have the same loudness: a linear approximation was
used based on equal loudness curves for compensation of
the change in loudness due to different fundamental
frequencies.
The
normalization
was
verified
experimentally by asking a small group of subjects. Each
sound was 1.5 seconds long.
For the loudness experiment the fundamental
frequency was kept constant at 237.7Hz and seven
harmonic tones with varying loudness levels were
generated. The overall
amplification of the audio
apparatus was adjusted so that the quietest tone was well
above the hearing threshold and was clearly audible.
Once this amplification was determined, the same
loudness setting was used throughout the experiment.
Among the seven tones the amplitude ratio of the loudest
to the softest was 30 and the ratios for the intermediate
sounds were distributed logarithmically. As the nature of
our experiment was to capture correlations between audio
and haptic texture, an absolute loudness reference was not
necessary.

2.3. Experiments.
In each experiment, subjects were given an audio
(respectively haptic) characteristic and then asked to
toggle a haptic (respectively audio) characteristic until the
best match was found. There was no time limit on how
long the subject could take to choose a match. For
example, a subject would be given a pitch and then asked
to toggle roughness (smoother and rougher), until the user
was satisfied the best choice had been made. After
making the choice the user was then asked to rate (from 15) the confidence she felt in her choice. Each subject
performed 10 trials of each of the four experiments.
Because the audio characteristics (pitch and loudness)
were not designed to represent the actual sounds of
moving across an object, the audio was activated with a
user key press and was not dependent upon the haptic
contact. The subject could repeat sounds.
Each subject began the session in an exploration
mode. A subject was given the three characteristics (pitch,
loudness, texture), one at a time, and allowed to freely
explore that characteristic by using two keys. Three pairs

of keys (Q/E, S/F and A/D) were used to toggle from one
level to another and for different subjects the direction of
the toggle was randomly varied. In other words, for some
subjects, ‘S’ meant that the sound became louder and ‘F’
meant the sound became softer and for other subjects it
was the opposite. Pairs of keys were chosen to be side by
side (rather than below and above) so that there was no
built-in bias toward making a correlation that “up” could
correlate with higher pitch or louder volume. This
exploration also gave the subjects an opportunity to
become familiar with the PHANToM device, since for
most of them this was their first experience with computer
haptics.
Each subject performed 10 trials of one experiment
before moving on to the next experiment. There were
four experiments in all (texture to loudness, loudness to
texture, texture to pitch and pitch to texture) but the order
of the four experiments was randomly varied from subject
to subject. Within each experiment, the level of the
characteristic that was given (one of seven possibilities)
was randomly generated while ensuring that all seven
levels were used. At the end of each trial (a total of 40
times) the subject was asked to rate, on a scale from 1 to
5, the confidence of the match she had made.
At the conclusion of the four experiments the subject
was asked to fill out a questionnaire. This questionnaire
included questions about the musical background of the
participant and basic feedback about the experiments.

3. Results.
In all of the data shown below, the textures are
ranked from 1 (smoothest) to 7 (roughest), the loudness
levels range from 1 (softest) to 7 (loudest), and the pitches
range from 1 (lowest) to 7 (highest). Data from the four
experiments were analyzed with a nonparametric
correlation test using Kendall’s W statistic. The data were
first treated as an aggregate collection. For three of the
experiments there was a statistically significant (p<0.05)
correlation, as shown in Table 1 below. In the first two
experiments subjects correlated rougher textures with
louder sounds and smoother textures with softer sounds (W
values of .588 and .502 with p values near 0). For the
third and fourth experiments (given a texture, match a
pitch and given a pitch, match a texture) less significant
correlation was found (in both cases W was near 0), at least
partially because some subjects matched higher pitch to
smoother texture while others matched higher pitch to
rougher texture. Because individual subjects correlated
pitch and texture in different directions, the data were
normalized: in cases where subjects matched higher pitch
with rougher texture, the scale was reversed. For the
normalized data, strong and significant correlations
emerged. These are shown in the fourth and sixth rows of

Proceedings of the Eighth International Conference on Information Visualisation (IV’04)
1093-9547/04 $ 20.00 IEEE

Experiment
Given texture, match loudness
Given loudness, match texture
Given texture, match pitch
Given texture, match pitch (normalized)
Given pitch, match texture
Given pitch, match texture (normalized)

W
.588
.502
-.024
-.579
-.108
-.499

p
<0.0005
<0.0005
.652
<0.0005
.047
<0.0005

with high pitches and 7 correlating rough textures with
low pitch. And in the fourth experiment (given pitch,
match texture) 14 of the 20 subjects had statistically
significant correlations (|W|>0.53), with 5 correlating
rough texture to high pitch and 9 correlating rough texture
with low pitch. The third and fourth experiments
(texture/pitch) exhibited a strong bimodal characteristic.

Table 1. Correlations

Given Texture, Match Pitch
Frequency

Table 1. This demonstrates that there is not a common
association in one direction or the other for matching
pitch and roughness.
The same correlation test was applied to the 20
individual subjects for each of the four experiments.
Histograms summarizing the W values for each of the four
experiments is shown in Figures 1-2. For the first
experiment (given texture, match loudness) 19 of the 20
subjects had statistically significant correlations
(|W|>0.64), with 17 correlating rougher texture with louder
sounds. For the second experiment (given loudness, match
texture) 16 of the 20 subjects had statistically significant
correlations (|W|>0.56), with 15 correlating rougher texture
with louder sound.

Frequency

10
5
0
-1

-0.5

0

0.5

1

W values
Given Pitch, Match Texture

Frequency

20

Given Texture, Match Loudness
20
15
10
5
0

15
10
5
0
-1

-0.5

0

0.5

1

Wvalues
-1

-0.5

0

0.5

Given Loudness, Match Texture
20
15
10
5
0
-1

-0.5

0

0.5

Figure 2. Pitch/texture correlations

1

W  values

Frequency

20
15

1

W values
Figure 1. Loudness/texture correlations
For the third experiment (given texture, match pitch)
15 of the 20 subjects had statistically significant
correlations (|W|>0.53), with 8 correlating rough texture

The data were also analyzed with a linear regression,
which yielded very similar results as above. The trend
lines for the four experiments, with data from all subjects
aggregated, are shown below in Figure 3. Note that the
figure also includes the trend lines for the normalized data
from experiments three and four. As above, a strong
correlation is indicated.
An analysis of confidence ratings for the subjects was
performed. Means of confidence ratings for the aggregate
subjects in each of the four experiments showed no
significant difference for the various experiments and
were close to 3 (on a scale of 1-5). Two-sample t-tests
were performed on experiment pairs (texture/loudness
and texture/pitch) and also showed no significant
difference. We also looked at confidence rating values at
the ends of the texture/sound scales, but found they were
similar to the confidence ratings given to textures in the
middle of the scale.

Proceedings of the Eighth International Conference on Information Visualisation (IV’04)
1093-9547/04 $ 20.00 IEEE

also in development of computer-user interfaces that use
multidimensional data.

Pitch or Loudness

Trendlines of the Aggregate Data

Acknowledgements.

7
6
5

The authors would like to thank Andrzej Nowak for
suggestions about the design of these experiments. They
would also like to thank the referees for many helpful
comments.

4
3
2
1
0
0

1

2

3

4

5

6

7

Texture
Loudness -> Texture
Texture -> Pitch
Pitch -> Texture (norm)

Texture -> Loudness
Pitch -> Texture
Texture -> Pitch (norm)

Figure 3. Aggregate data

4. Discussion.
Results of the four experiments that explore the
correlations between haptic texture and loudness and
haptic texture and pitch have shown that there are strong
correlations between these properties. The two
experiments that dealt with texture and loudness showed
significant correlations and lead us to conclude that
subjects matched rougher textures with louder sounds,
independent of which one was given and which one was
matched.
In the two experiments in which the correlation
between texture and pitch was explored, significant
correlations were found after the data were normalized.
This indicated that a generalization as to whether pitch
and texture were positively or negatively correlated could
not be made. However, due to the strong correlations at
the subject level, we conclude that it is user-dependent,
strongly correlated and consistent only within its group
(positive or negative). An implication of this could be that
if pitch and texture were to be incorporated in a bimodal
user interface, the preference of the user should be
inferred and the pitch scale should be set accordingly.
Our future work will focus on exploring the relative
weighting of pitch versus loudness, using experiments
that combine both properties of sound. Isolating other
haptic and aural properties and exploring their bimodal
correlations is of interest in order to expand the collection
of correlated properties in multiple modalities. Another
direction will be to use auditory stimuli that are
multidimensional in nature, such as timbre, and explore
their relationship with haptic attributes. Although we have
focused on the auditory and haptic modalities in this
work, our long-range plans include incorporation of the
visual modality in this mix. The results of this research
will have implications in multimodal ‘icon’ design and

References.
[1] Hale, K.S. & Stanney, K.M. (2004). Deriving haptic
guidelines from human physiological, psychophysical, and
neurological foundations. IEEE Computer Graphics and
Applications, 24(2), 33-39.
[2] James, T.W., Humphrey, G.K., Gati, J.S., Servos, P.,
Menon, R. S. & Goodale, M.A. (2002). Haptic study of threedimensional objects activates extrastriate visual areas.
Neuropsychologia, 40, 1706-1714.
[3] Lederman, S.J. (1974). Tactile roughness of grooved
surfaces: The touching process and effects of macro- and micro
surface structure. Perception and Psychophysic, 32, 109-116.
[4] Costa, M.A. & Cutkosky, M.R. (2000). Roughness
perception of haptically displayed fractal surfaces. ASME
IMECE 2000 Symposium on Haptic Interfaces for Virtual
Environments and Teleoperator Systems, .
[5] Yu, W., Ramloll, R. & Brewster S.A. (2001). Haptic graphs
for blind computer users. Haptic Human-Computer Interaction.
Brewster, S.A. and Murray-Smith, R. (Eds.), Springer LNCS,
Vol 2058, 41-51.
[6] Yu, W. & Brewster, S.A. (2003). Evaluation of multimodal
graphs for blind people. Journal of Universal Access in the
Information Society 2(2), 105-124.
[7] Lederman, S. J., Klatzky, R., Morgan, C. & Hamilton, C.
(2002). Integrating multimodal information about surface texture
via a probe: relative contributions of haptic and touch-produced
sounds. Proceedings of the 10th International Symposium on
Haptic Interfaces for Virtual Environment and Teleoperator
Systems, 97-104.
[8] Lederman, S. J., Martin, A., Tong, C., & Klatzky, R.
(2003). Relative performance using haptic and/or touchproduced auditory cues in a remote absolute texture
identification task. Proceedings of the 11th International
Symposium on Haptic Interfaces for Virtual Environment and
Teleoperator Systems, 151-158.
[9] Lederman, S.J. Klatzky, R. (1998). Feeling through a
probe. Proceedings of the ASME Mechanical Engineering
Congress: Dynamic Systems and Control Division 64, 127-131.
[10] Zahariev, M.A. & MacKensie, C.L. (2003). Auditory,
graphical and haptic contact cues for a reach, grasp, and place
task in an augmented environment. Proceedings of the 5th
International Conference on Multimodal Interfaces, 274-276.
[11] Chu, L.L. (2003). Haptic interactions for audio navigation.
Ph.D. Dissertation, Stanford University.
[12] DiFilippo, D & Pai, D. K. (2002). Contact interaction with
integrated audio and haptics. Proceedings of the International
Conference on Auditory Display.
[13] Adelstein, B.D., Begault, D.R., Anderson, M.R. & Wenzel,
E.M. (2003). Sensitivity to haptic-audio asynchrony.

Proceedings of the Eighth International Conference on Information Visualisation (IV’04)
1093-9547/04 $ 20.00 IEEE

Proceedings of the 5th International Conference on Multimodal
Interfaces, 73-76.
[14] McGee, M.R., Gray, P. & Brewster, S. (2000). The
effective combination of haptic and auditory textural
information. Proceedings of the First Workshop on Haptic
Human-Computer Interaction, 33-38.
[15] McGee, M.R., Gray, P. & Brewster, S. (2001). Feeling
rough: multimodal perception of virtual roughness. Proceedings
of Eurohaptics 2001, 29-33.
[16] Poling, G. L., Weisenberger, J. M., & Kerwin, T. (2003).
The role of multisensory feedback in haptic surface perception.
Proceedings of the 11th International Symposium on Haptic
Interfaces for Virtual Environment and Teleoperator Systems,
187-194.
[17] Weisenberger, J.M. & Poling, G.L. (2004). Multisensory
roughness perception of virtual surfaces: effects of correlated
cues. Proceedings of the 12th International Symposium on

Haptic Interfaces for Virtual Environment and Teleoperator
Systems,161-168.
[18] Baird, B. & Izmirli, O., (1999). An approach to
visualization of musical sound. Proceedings of the Seventh
Biennial Symposium on Arts and Technology at Connecticut
College. 11-14.
[19] Baird, B. & Izmirli, O. (2001) Modeling the tempo
coupling between an ensemble and the conductor. Proceedings
of the International Computer Music Conference (ICMC2001),
163-166.
[20] Baird, B. & Izmirli, O. (2001). A tool for designing
interactions with multi-modal objects. Proceedings of the Eighth
Biennial Symposium for Arts and Technology at Connecticut
College, 1-5.
[21] Baird, B., Izmirli, O. & Smalley, D. (2000). Interactive
exploration of multimodal objects in a virtual gallery.
Proceedings of Consciousness Reframed 3, 38-41.

Proceedings of the Eighth International Conference on Information Visualisation (IV’04)
1093-9547/04 $ 20.00 IEEE

