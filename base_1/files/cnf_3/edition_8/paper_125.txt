A Path Based Model for Sonification
Keith M. Franklin, Jonathan C. Roberts
Computing Laboratory, University of Kent, UK
{kmf1@kent.ac.uk, j.c.roberts@kent.ac.uk}
Abstract
Recently researchers have been interested in nonvisual forms of presentation. Sound, touch, smell, as well
as vision can be used to depict information. One
important medium is sound; it can encode information
for the blind or partial sighted, used to display
information when it is impossible to use a screen, and
the hardware is cheap and widely available. Researchers
have investigated sonifying various data sources with
different data types and configurations. In this paper we
present a novel path-based model that can be used to
describe each of these different sonifications. In
summary, the path dictates the sonification tour, the data
is mapped into sound via a transfer function, and the
quantity of information being sonified is determined by
both the span and how the abstract path is registered to
the data.
Keywords--- Sonification, sonifying images, path
based sonification, non-visual representations.

1

Introduction

In recent years, there has been a growing interest
into non-visual techniques such as sound, touch and
smell to represent information. For example, line graphs
of stock market data can be represented by sound (the
day to day growth by time, and the stock value
represented by a pitch change) and the same information
could be represented by a tactile display (allowing the
user to feel the increase or decline of the stock).
Accessibility is one of the main motivations to this
work, such that the presented information can be
understood by those with disabilities such as blind or
partially sighted. However these non-visual forms are
useful for other situations. For instance, haptic
representations are useful for training (e.g. the fine
kinesthetic movements surgeons need to learn) or remote
vehicle operation (such may be useful by a bomb
disposal team). Sonification can enhance the display of
information on small screens, as used in phones or
personal organizers, and importantly sonification is
useful to display quickly changing data (as the ear is
good at noticing subtle changes).

One important non-visual presentation medium is
sonification. Sound is available on a wide variety of
systems, therefore it is cheap to both develop
sonification systems and for a user to use. However,
much of the current sonification research has been
unstructured (indeed this is a case facing all researchers
of non-visual ‘visualization’). Researchers have
imagined new realizations, implemented these ideas and
tested their systems, but few have sought to generalize
and unify principles from related work. Thus in this work
we propose a unifying model that unites and generalizes
the current sonification approaches.
One of the most challenging aspects of creating new
sonifications is to develop an appropriate mapping that
will map an n-dimensional data set into sound (which is
primarily a non-spatial medium, and highly dependent on
time). For example, one challenge is to generate a
sonification of an image. On strategy researchers have
adopted is to sweep a line across the image, converting
the pixels (that fall under the sweeping line) into sound.
Other strategies have been developed for vector and
object-based images (see the related work section 2).
This has often caused researchers to create complex
mappings; some are more understandable than others.
The difference in usability may be due to the encoding
style that the developers have adopted, with mappings
that are too abstract for the listener to understand, merely
inappropriate for the task in hand, or overload the user
with too much irrelevant information.
We purpose a model that unifies all current methods
and approaches to sonifying information. This model
determines the sequential order, size of area that is
sampled for sonification.
Both researchers and users will benefit from this
model. Researchers will be able to utilize a standard
model in which they can describe their sonifications,
develop generic sonification systems, and explore new
representation strategies. Using the model users will be
able to select the sonification method that best presents
the information, and comprehend the construction of the
sonification and thus better understand the underlying
information. In the future we foresee that automated
systems can select the most appropriate sonification style
based on an analysis of the input data.

Proceedings of the Eighth International Conference on Information Visualisation (IV’04)
1093-9547/04 $ 20.00 IEEE

In this paper we (1) discuss the model in detail, (2)
describe examples of how the model relates to current
methods and how it can be used to create new
approaches, and (3) briefly present and evaluate a
prototype system based on the model.

2

Background and related research

Sonification has been applied to numerous
application domains and datasets, including statistical
information such as stock market data [1], network
diagrams (such as central heating schematics) [2],
algorithm presentation (e.g. sorting algorithms [3]) and
physical data (such as oil and gas well sonification [4]).
In each of these representations, there are two
independent stages that occur. First, a transfer function is
generated that details how the data values are exchanged
to sound values or the relationship between the sounds
[5], this is a similar process to generating a color map for
traditional graphics visualizations. Second, the developer
needs to consider the order in which the data is to be
played (in some situations, such as when displaying
time-series data, this order is implicit). This latter stage,
which is the focus of this paper, can be further
subdivided into two general areas (1) query based
methods, where the user continuously selects the
information to be sonified, and (2) tours, where the
information is arranged into a predefined order for
sonification.
There are numerous transfer functions that could be
applied. For instance higher values to higher pitches, x,
y space to localized sound position, categories to
different timbres. These are abstract mappings, where
any particular association must be learnt. Furthermore,
auralization could be used instead of sonification, where
the data value is mapped into the spoken word. An
example of this would be the work done by Frankie
James [6], who presented a method for auralizing both
the contents and structure of HTML pages based on the
concept of radio presenters (different content read by
different voices). Although auralization has the
advantage that users are not required to learn the
mapping, it tends to be longer in duration, harder to
realize complex information and can be annoying when
used for prolonged periods of time. Therefore within this
paper we concentrate on sonification and the use of
abstract mappings.

2.1

Query base methods

Query based methods use a selector (such as a
pointer) that is controlled by the user. When an area of
information is selected the system generates an
appropriate sound. An example of this approach is in the
use of earcons [7], such as used by Helle et al [8] to
represent mobile phone menus. As the user moves down
the menu items so a unique motif is played. The earcons
are structured musical motifs that are uniquely
identifiable, in the case of the mobile phone menu; the
motifs are carefully crafted such that users can perceive

the location within the menu and sub-menus (e.g. each
menu item exhibits similar traits to its parent).
Another example is the work by Bennett [2] who
presented sonification of heating schematics. Two scales
sonified the position of the nodes within the diagram,
each in a different instrument and one for each axis, the
number of notes in the scale corresponded to the position
in along an axis. A final example of a query based
approach is AudioGraf [9]. In this application users
explore a graph by using a touch panel. As the user
moves their finger around the touch pad, auditory
information is presented based on the currently selected
nodes or edges.

2.2

Tour based methods

The second method of encoding information is
based on the concept of a tour. A tour arranges the data
into a predefined order for sonification. For example, to
represent a bar chart [10] the order of the categories (the
bars themselves) is chosen, which is typically left to right
along the x-axis, and then a transfer function is applied
to the ordered information, which maps the y-values to
(say) pitch. In pie chart sonification [11], the tour
describes the order in which the segments are sounded.
This representation uses a transfer function that maps the
start and end location of each segment to an equivalent
location in the azimuth plane, which surrounds the user’s
head. Similarly, other mathematical visualizations have
been sonified, such as line graphs [12].
Other more challenging sonifications include the
representation of images. To sonify an image, the
developer needs to work out an appropriate tour, which
will convey all necessary information to the user.
For a vector image, the developer only needs to find
a path that visits the individual components that are of
interest. For instance if the image contained a series of
geometric shapes, the tour might order the shapes left to
right, top to bottom (sounding them out similarly to
Bennett’s central heating sonification [2]).
For a bitmap image (such as a digital camera image)
the developer could either (1) provide a sonification tool
that located and visited the main features of the image,
sounding out the positions and values of various
attributes, much like the eye moves saccadically from
one feature to another; or (2) consecutively visit every
pixel in the image applying the desired transfer function.
This latter method has been used in a number of systems,
e.g. the vOICe system, as detailed by Jones [13].
Moreover, Jones mentions head-mounted cameras that
exchange moving pictures from a video camera into
sound.

3

The model

To help both researchers and users understand and
select the most appropriate tour based methods, we have
defined four terms path, span, span angle and span
envelope. These terms form the bases of our model. The
path expresses the ordering of the information, whilst the

Proceedings of the Eighth International Conference on Information Visualisation (IV’04)
1093-9547/04 $ 20.00 IEEE

other three allow the developer to richly explain the how
the information will be sonified. We believe this model
can be used to express all current techniques in such a
way that other users will be able to understand the
relationship between the sonification and the underlying
data, with the exception of the transfer function, which is
independent to the tour.

3.1

spaces, such as depicted in Figure 2, this specific
instance is a sonification mask.

Path

A path describes the order in which information will
be presented to the listener. Within our model, a path is
created from a series of path points. During the
development of a new path each path point represents an
arbitrary location, which is defined relative to other path
points. When the path is applied to a data set, each path
point maps to a tangible part of the dataset. This allows
the path to be rescaled independently of the data. In
principle the path can be placed in two or threedimensional space, however for descriptions within this
paper we detail the paths in two-dimensions.
In addition, and unlike current techniques which
consecutively order the information, each path point can
be placed anywhere within the abstract space in a
completely random order. For example, users could
create paths that can compare different areas of their
data, such as moving from one feature of interest to
another in a bitmap image, alternatively the path may be
used to describe a route from one geometric primitive to
another for vector images.
Two different paths are shown in Figure 1. Figure
1(a) is an example of the path that would be used to
create the sweeping line (also known as an occluding
front), which is currently the most popular tour based
method. Figure 1(b), shows a path that can provide an
overview of the information over a wider area.

Figure 2 An irregular shaped span, which would
be impossible to create by increasing the area a
path point maps to.

3.3

Span angle

In addition to the ability to specify the span, we can
also specify the angle of interception between the span
and the path (values range from 0° - 180°).
Currently, all systems detailed in the literature, use a
span that is perpendicular to the path (Figure 3a).
However, angular spans are useful (Figure 3b). For
example, there may be artifacts in the data that are
aligned or grouped together at an angle, this may not
perceived by a vertical (traditional) span but may
become obvious when the span angle matches the angle
of the data entities. Moreover, the span angle would
dynamically change to keep particular alignments of the
span, even when the orientation of the path varies.

(a)

(b)

Figure 3 (a) Depicts a path that is using a span
angle of 90° (b) Shows a path that is using a
span angle of 45°.
(a)

(b)

Figure 1 The schematic shows two possible
arrangements of path points; adjacent (a) and
non-adjacent path points (b). Both create
different sonifications when applied to the same
dataset.

3.2

Span

The span defines a neighborhood, which is
associated with every path point. In principle, the path
points could map directly into single entities of the data,
however the span allows more innovative sonifications
to be generated. For instance, we are able to specify
irregularly shaped neighborhoods that can include

3.4

Span envelope

The span envelope designates the size of the span,
dependent on the time and the position of the path. In
most situations a fixed span envelope will be used (e.g.
determined by a constant or the height of the image).
However, it is useful to dynamically change the span
envelope (this may be imagined as two additional paths
that surround the main path, Figure 4).
It is envisaged that the span envelope can be
generated either manually or automatically by the
system, which could optimize the overall length of the
path, by using large spans (where there is little or no
relevant information) and a smaller span (with extra path
points) in locations of densely packed data points.

Proceedings of the Eighth International Conference on Information Visualisation (IV’04)
1093-9547/04 $ 20.00 IEEE

3.6.1

(a)

(b)

(c)

(d)

Figure 4 A sequence of images that show how
the span size is changed as time progresses
along the path. The span size depends on the
span envelope (shown by the dotted line).

3.5

Sonifying the path

There are two stages to generate a sonification from
a path. The first stage is to map the path onto the actual
data set. This requires specifying how each span section
maps onto the underlying data. In the situation when the
resolution of the data and those of the path points are
different, then registration of one to the other will need
to take place, i.e. scaling, sampling or averaging. In our
system, we have scaled the path and the sampled data to
register the span and path to the data.
Additionally, the mapping stage also depends upon
assigning timing information. For example, time could
continue linearly, or could speed up or slow down at
various stages through the path. Time is treated as an
additional variable on the path.
The second stage is to generate the sounds
associated with each path point. This is dependant on (a)
the data values that are currently under the span, and (b)
the transfer function (describing how particular data
values should be converted into sound).

3.6

The scan line path is the equivalent of the sweeping
line method (as described in the introduction). It uses a
path that crosses the data area in a straight line, a span
angle of 90°, with a fixed span envelope. The height of
the span envelope is equal to the height of the data (see
Figure 5). As the span moves along the path all
information that lies beneath the span is simultaneously
sonified.
Furthermore, this style of path is often used to
represent time-series data, where time is mapped to the x
axis and the values to the y axis.

(a)

(b)

Figure 5 Scan line path. (a) Shows the position
of the path points used in the scan line path (b)
Indicates how the span is related to the each
path point.

3.6.2

Raster scan path

This path demonstrates a method in which users
would be able to understand the spatial relationship
between different objects contained within the data set.
The raster scan path uses a series multiple scans, which
are parallel and equally spaced (see Figure 6a). A
constant envelope is used such that the bottom of the
envelope on one scan meets the top of the envelope on
the next scan (see Figure 6b).

Example Paths

To assist with the understanding of our model, we
will describe how various paths can be used and
developed in our model. Some of the paths are variations
of those found in current literature, while others we
newly present. Each path has advantages, disadvantages
and particular challenges for perception; however, it is
not our goal in this paper to discuss such perceptual
issues, rather it is to demonstrate how the model can be
applied to generate a wide range of sonification
strategies.

Scan line path

(a)

(b)

Figure 6 Raster Scan path. (a) Shows the path
points and their order used in a raster scan path
(b) Shows the span envelope for the path in (a).

3.6.3

Zigzag path

Unlike the raster scan path, the zigzag path uses a
more continuous path to arrange the data into an order
where every path point is adjacent to both the previous
and the following point (see Figure 7). We believe that

Proceedings of the Eighth International Conference on Information Visualisation (IV’04)
1093-9547/04 $ 20.00 IEEE

this might lower the mental demand placed on the users
since the movement is not jumping from one edge of the
data set to the other. But, depending on the span angle,
some points may be sounded multiple times.

(a)

(b)

Figure 9 a) Shows the size of the span using the
water droplet path at the being b) Shows how
the span has increase in diameter as it has
moved along the path.
Figure 7 An example of a zigzag path.

3.6.4

Spiral path

This path traverses the data set in a spiral motion
either from the outer edge (Figure 8a) or from a center
point (Figure 8b). Spiral paths have a particular
challenge of what to do when the spiral path exceeds the
physical boundary of the data. For example, if the data
set is not square and an outward spiral motion is applied
from the center point, then the path reaches the bottom
boundary before all the information has been presented.
There are three possible solutions, (1) ignore the
remaining information, (2) jump to the next path point
that is within the data set area, or (3) add some indication
to the listener that the area being sonified is outside the
boundary of the information space. Each of these
approaches has their own implications to the users,
which need to be studied before we can select the most
appropriate option.

(a)

(b)

Figure 8 (a) and (b) show the two possible
arrangements to create a spiral path
sonification.

3.6.5

Water droplet path

This path aims to provide a way to convey
information that is ordered by distance from a particular
area. This is achieved by creating a circular span and
increasing its diameter as the span moves along the path,
shown in Figure 9. The path may be a fixed length, or
extend to the edge of the dataset.

4

Prototype system

We are currently developing a prototype system that
demonstrates the model, Figure 10. If the system is being
used by a blind user then a developer would be required
to create a path or set of paths (which are independent of
any image source) and that the blind users could load and
use to sonify the image. In practice, we do not make a
distinction between a developer and user and so any user
can modify pre-existing tours.
The developer proceeds by creating a path, which
represents particular areas of interest or key features
within the data. Each path point is placed on a selectable
grid, shown on the top left of Figure 10, the system
draws a line connecting the previously placed path point
to the newly introduced point.
When all the path points have been placed, the
developer then needs to create the span. Again this is
achieved by using a separate selectable grid in which the
user indicates the relationship between the path point and
the span area, shown on the right hand side of Figure 10.
Currently, the system only implements the path and the
span features of our model. However, in future versions,
the developer would also setup the desired span angle
and the span envelope.
Before the system can convert the abstract path into
a tour based sonification, the system requires additional
information about the conversion process. In particular,
the system needs to know the area of the image that is to
be sonified and how to fill or increase the size of the
abstract path so that it fills the specified area. Currently
our system provides two sets of slider controls, which
both the developer and the user can adjust as necessary.
The first set of sliders control the ‘target
sonification area’ that is to be sonified. The user
specifies x and y coordinates for the top left hand corner,
together with its width and height. The second set of
sliders control the number of times the abstract path
should be repeated within the ‘target sonification area’.
This process is often known as tiling. If the required
amount of tiled repeats does not exactly fit the area, then
the whole abstract path is scaled to fit.
Users can load pre-generated paths, along with any
image, and listen to the sonification based on the path,
span and other mapping controls.

Proceedings of the Eighth International Conference on Information Visualisation (IV’04)
1093-9547/04 $ 20.00 IEEE

Finally, it is important to investigate perceptual
appropriateness of various tours because some paths may
be more appropriate for a given task. For instance, the
water droplet is useful to investigate a small area in
detail (at the center) and the surrounding areas in less
detail (as the span increases). Such perceptual evaluation
is important.

7

Acknowledgements

We would like the thanks all the people that
participated in the pilot study of our system.

Figure 10 Our prototype
demonstrates the model.

5

system,

which

Results and discussion

Currently, we are investigating the usability and
effectiveness of new sonification paths in the
representation of different information from equivalent
mathematical visualization to image based sonification.
In addition to studying what makes a usable/effective
path, we are also considering if there is a relationship
between different paths and the type of tasks that it is
most effective in convey information for.
Initial results from the preliminary testing indicate
that the raster scan allows users to correctly perceive
spatial relationship between different data objects.
In conclusion, we have presented a model that
unifies current tour based sonification methods by
defining a set of terms which we believe will facilitate
the development and expansion of sonifications. Our
model allows researchers, developers and end users to
convey the concepts of each path and what information
will be presented, so that the most appropriate path can
be selected when generating a sonification for a
particular data set or task.

6

Future work

We plan to expand this research by continuing
testing and developing new paths and the system.
Currently we are carrying out an extended pilot study
into a set of new paths that we have designed to
eliminate paths that are completely unusable. After
which, we plan to carry out an empirical study, which
will look at the usability, effectiveness and the mental
load that each path places on the users in relation to
typical tasks that the user might wish to carry out on
various data sets.
One future plan is to investigate the possibility of
automatically generating paths. The system will need to
analyze what is ‘interesting’ in the data and create a tour
that travels to the interesting features of the data [14],
perhaps moves to an interesting area, sonify the
information in detail and then move onto the next
‘interesting’ area.

8

References

[1]

D.L.Mansur, M.M.Blattner and K.I.Joy “Sound-Graphs:
a numerical data analysis method for the blind”. Journal
of Medical Systems, 9(3), 1985, pp.163-174
D.J.Bennett “Effects of Navigation and Position on Task
when Presenting Diagrams to Blind People using
Sound”. Proc Diagrams 2002, Mark Hegarty, et al (eds),
LNAI 2317, Springer
M.H.Browns and J.Hershberger. “Color and Sound in
Algorithm Animation”,IEEE Computer, 25(2):62-63,
1992
S.Barrass and B.Zehner. “Responsive Sonification of
Well-logs” Proceedings of International Conference on
Auditory Displays (ICAD) 2000, Atlanta, April 2000
R.S.Tannen. “Breaking the Sound Barrier: Designing
Auditory Displays for Globla Usability”. Proc of Human
Factors & the Web, Basking Ridge, USA, June 5, 1998
F.James. “AHA: Audio HTML Access”. Computer
Networks and ISDN Systems, Volume 29, Issues 8-13,
September, 1997, pp 1395-1404
M.Blattner, D.Sumikawa and R.Greenberg. “Earcons and
Icons: Their structure and common design principles”,
Human Computer Interaction, 4(1):11-44, 1989
S.Helle, G.Leplâtre, J.Marila and P.Laine. “Menu
Sonification in a Mobile Phone - a prototype study”.
Proc International Conference on Auditory Display,
Espoo, Finland, July 29-August 1, 2001, pp 255-260
A.R.Kennel. “AudioGraf: A diagram reader for blind
people”. Proceedings of ASSETS96, Vancouver,
Canada, 1996, pp 51-56
W.Yu and S.Brewster. “Comparing Two Haptic
Interfaces for Multimodal Graph Rendering”. In
Symposium on Haptic Interfaces for Virtual
Environment and Teleoperator Systems. 2002. Florida
K.M.Franklin, J.C.Roberts. “Pie Chart Sonification”.
Proceedings of Information Visualization (IV03),
London, UK, July, 2003, pp 4-9. IEEE Computer Press
T.L.Bonebright,
M.A.Ness,
T.T.Connerley
and
G.R.MaCain. “Testing the Effectiveness of Sonified
Graphs for Education: A Programmatic Research
Project”. Proc Int Conf on Auditory Displays, Espon,
Finland, July 29-August 1, 2001
W.D.Jones. “Sight for sore ears”. IEEE Spectrum,
February, 2004, pp 11-12
S.Colton, A.Bundy, and T.Walsh. “On the Notion of
Interestingness in Automated Mathematical Discovery”.
International Journal of Human Computer Studies, Vol
53, No. 3, 2000, pp 351-375.

[2]

[3]

[4]

[5]

[6]

[7]

[8]

[9]

[10]

[11]

[12]

[13]
[14]

Proceedings of the Eighth International Conference on Information Visualisation (IV’04)
1093-9547/04 $ 20.00 IEEE

