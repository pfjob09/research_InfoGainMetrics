Web-Based Distributed Pattern Recognition System
Sung-Jung Hsiao
Department of Computer
Science & Information
Engineering, National Central
University, Taiwan
song1208@ms5.hinet.net

Wen-Tsai Sung
Automation & CAD Lab.,
Department of Electrical
Engineering, National Central
University, Taiwan
sung.wentsai@msa.hinet.net

Abstract
This study attempts to apply the principle of neural
networks and pattern recognition (PR) technologies to
real-time recognition by client-Server network structure
into a web-based recognizing system. In this paper, we
recommend a Web-Based PR technology, which is
improved recurrent neural network (RNN) from
possessing feedback and non-linear activation function
with its input, be taken out threshold. The purpose of this
article is to construct a Client-Server network structure
for PR system with associative memory. The Server-end is
built a databases management system for storage sample
patterns. In proceed with training, the user can real-time
assign any pattern, which is a record in the Server-end
databases. In deal with retrieve task, we propose a novel
PR method via databases matching, it can efficient solve
spurious states problem from RNN in the WBPR system.
On the other hand, taking advantage of Database
Matching is to overcome the capacity restrictions on
RNN. In order to clarify and corroborate the above WebBased PR technology, thus a simulation experiment will
be presented and their algorithms are also discussed.
Keywords: Web-Based,
Pattern Database

Pattern

Recognition, RNN,

1. Introduction
Pattern recognition with neural network is widely
discussed in the Internet. Many subjects are discussed,
such as Weather Forecasting (http://www.eunetat.
de/en/area2/cqms/ap3-13.htm), Document Analysis and
Recognition CEDAR)(http://www.cedar.buffalo.edu/into.
html), Optical character Recognition (OCHRE)(http://
www.geocities.com/SiliconValley/2548/ochre.html),Atmo
spheric Blocking Recognition and Prediction (http://www.
aquila.infn.it/atmosfera/neurotools/),
even
Finanical

Kuo-Chin Fan
Department of Computer
Science & Information
Engineering, National Central
University, Taiwan
kcfan@csie.ncu.edu.tw

Forecasting could also use the technology of pattern
recognition [1]. In the many recognized technologies with
limited capacity are discussed, although they could be
improved partially. In these mass data are dealt with, they
aren’t to bring up the optimal solution yet [2] [3] [4].
Associative memory is very important in the neural
network with the technology of pattern recognition. Many
studies of pattern recognition are based on the structure
of associative memory [5] [6]. The recurrent neural
network (RNN) is the representative of the structure of
associative memory. Using the RNN to work in the
environment of pattern recognition, and it is a very nice
method [7] [8].
Good deal technologies of pattern recognition are still
improving with the present situation, but the
environmental development of Internet is more and more
importance. A lot of programs of pattern recognition are
still developing in the local-end. Therefore that used the
technology of pattern recognition in the Internet is an aim
with integrated science and technology in the future.
We could also suggest that used the web-based
structure of multiplatform to establish important pattern
database. Except the original technology of pattern
recognition is improved in the development of the
technology of pattern recognition. Our technology of
pattern recognition is to join the efficiency of real-time and
let all system of recognition are integrated in the Internet.
On the other hand, used the technology of pattern
recognition in the Internet that to deal with securely the
document and recognize the document for truth or
falseness.
Internet technologic development has been the key
already for integration science and technology. It is an
important task to recognize the identity of user and truth
or falseness of document that how to do in the
environment of complex network.

Proceedings of the Sixth International Conference on Information Visualisation (IV’02)
1093-9547/02 $17.00 © 2002 IEEE

2. Problem Description
In this paper, our network of pattern recognition is to
improve the network structure of RNN .In the classical
approach [9], an RNN is a discrete-time discrete-valued
dynamic system which at any given instant of time t is
characterized by a binary state vector.
n
x(t) = [x 1 (t),..., x i (t),...x n (t)] ∈ {1, −1}
(1)
The behavior of the system is described by a dynamic
equation of the type
n

x i (t + 1) = sgn ∑ WijX j (t)− ? i 
 j=1


(2)
i = 1,2, …… .n.
A point x is a fixed point, for any pattern prototype

vectors

?

u

[

? 1 ,? 2 ,....? p [10]

]

= x1 (t),....,x i(t) ,...xn (t) ∈ {1,−1}n

(3)
In our approach, x (t) is a record of pattern database. The
x1(t) or xi (t) is a field of any data record, as Figure 1;
furthermore it is to limit bipolar data between 1and -1.
Actuality a“1 “represents a point of pattern, which is
black and a”-1” represents a blank of pattern, which is
white.
In our approach, sample pattern are directly stored in the
database system of server-end by the Internet .User can
modify patterns of database system any time ,even let
remote user to build up own sample pattern ,as Figure . 2.

threshold rector ?, we are improving from the discrete
Hopfield networks [11]. In Our approach, initially, at the
training stage ,to cut the records of pattern database ;
used distributional compute to find out the W value and
? value of every segment, afterwards used again the W
value and ? value of every segment to bring back as
Eq(2),we would find out the most similar pattern records of
retrieval in every segment .Collecting the most similar
pattern records, and compute again the parameter of the
W value and ? value to bring back as Eg(2);such as
circulated in the compute of many times, finally, we would
find out the correct pattern in the a large number sample
pattern.
For example, if we have 50 records in the pattern
database and the cut number are 10, we would use
distributional compute to find out the W value and ?
value of every 10 records; afterwards used again the W
value and ? value of every 10 records to bring back as
Eq(2), we would find out the most similar a pattern record
to become a new pattern record; Collecting the new
pattern records, and compute again the parameter of the
W value and ? value according to the first cut number;
Such as circulated in the compute of many times, until we
find out the result of recognition ,as Figure 3.

A point represents a data field

All data records
represent a
pattern in the
database.

Figure 1.. Relation of point and pattern

SQL
Server

Browser

Internet

Prototype Database
record

UserClient-end
Remotelongin

Server-end

Figure 2. Network structure for the WBPR system
In the network parameter, the synaptic matrix W and the

Proceedings of the Sixth International Conference on Information Visualisation (IV’02)
1093-9547/02 $17.00 © 2002 IEEE

Calculate
W 10 and ?10
Divide
into 10
records

Divide
into 10
records

Input
source
pattern

Again calculate
W new and ? new

Similar pattern
Calculate
W 20 and ?20

Similar pattern

Calculate
W 30 and ?30

Output
recognized
pattern

Similar
pattern
Divide
into
10

Divide
into 10
records

1 N
∑ ? ? µ ⋅i
p µ =1 µ ⋅ j

Wji =

50 records in the pattern database

Calculate
W 40 and ?40

(4)

The reason for, that using 1/p as the constant of
proportionality is to simplify the mathematical description
of inform retrieval. [12] Note also that the learning rule of
eq. (4) is a “One shot” computation.
In the normal Operation of the Hopfield network, We set
(5)
W ii=0 for all i , i=1,…,p
W ii=0, can avoid positive feedback to take place. [13]
Let W denote the P by P Synaptic weight matrix of the
network, with W ji as its jith element. We may then
combine Eq.(4) and Eq.(5) into a single equation written in
matrix form as follows:
1 N
N
(6)
W=
? ?T − I
p

∑

µ

µ

P

µ

The I is an identity matrix of P x P , and W is a symmetric
matrix with the diagonal line all for zero,
W11 Λ W1p 
(7)

W= Μ Ο
Wp1 Λ


 0 Λ Λ
 Μ 0
=
 Μ
Ο

Wp1 Λ Λ


Μ
Wpp 

(8)

W1p 
Μ 
Μ

0 

There are two modes for the threshold of the jth neuron;
Similar pattern
rn
Calculate
W 50 and

? j = 0, j = 1,..., p

(9)
Or

? j=

P

∑ W , i = 1,..., p

(10)

ij

i= 1

Similar pattern

Figure 3. Using the pattern database system to distribute
the compute of W value and ? value.
There are two phases to the Operation of the discrete
Hopfield network as a content-addressable memory,
namely the storage phase and the retrieval phase as
described here.

2.1 Storage Phase
Suppose that we wish to store a Set of N-dimensional
vectors (binary word), denoted by {? µ µ = 1,2,....N } , we

The threshold of the Eq.(10) can raise the memory
capacity of network[14].

2.2 Retrieval Phase
If we input a recognizing pattern vector X, we would the
X regard as initial output value X (0) .Every neuron followup output is computed by
(11)
p
X j (n + 1) = sgn(∑ W ji X j (n) − ? j )
i =1

= sgn(u j (n) − ? j )

cal these N vectors fundamental memories, representing
the patterns to be memorized by the network, Let ? µ ,
denote the ith element of the fundamental memory ? µ ,
where the class µ = 1,2,..., N
According to the outer product rule of storage, that is
the generalization of Hebb’s postulate of learning the
synaptic weight from neuron i to neuron j is defined by

 1
if

= X j (n) if
 − 1 if


u j (n) > ? j
u j (n) = ? j
u j (n) < ? j

In his original paper , Hopfield used the values of 0 and
1 for the outputs [11].However, the values of 1 and –1 are
now in common usage [15] [16] for convenience in using
the zero threshold.
In this Eq. (11), the n is iterative times. We must
emphasize that the discrete Hopfield network used

Proceedings of the Sixth International Conference on Information Visualisation (IV’02)
1093-9547/02 $17.00 © 2002 IEEE

asynchronization method to change the output of neuron,
and the complete process of associative memory can use
the Eq. (12) to describe the relation of chain-state:
X(0)? X (1)? X (2)? …? X (k)? X (k+1)? (12)
Until the state converges on the stable state, the output
unchanged after continuous iterative computed .If we
used mathematics to express for the formula as X = sgn
(WX-?), and X is a stable state. If we used
synchronization mode to change the output of network, .a
lot of the result are different, and the neural network is still
convergence., in the partial state can be converged on the
stable state. Another partial state can show a limit cycle of
length at most 2.[17].
In our approach, although we use asynchronization
method to change the output of network, the X would
converge on the stable state, the X sometimes can also
converge on the incorrect recall [18], and therefore we use
the X state of final convergence to match the original
pattern database. Computing each other Hammer distance
finds out the minimal value. [19] If we have n records
pattern, we compute Hammer distance for
P
(13)
u
dH = ∑ X i − ? i

Figure 4. Using the technology of matching database to
improve the recall of partial wrong.
The solution of incorrect recollection maybe must to
reduce the noisy percentage. According to the experiment
our laboratory, the result as

u = 1,2,...n

,

i =1

u

3. Problem Analysis

86.3%

58.1%

Incorrect recollection

0

17%

18.5%

correct 0

12%

23.4%

We know how to improve partial correct recollection in
the above table, and it would raise the correct rate of the
recognition of the system by a wide margin.

4. Storage Capacity

According to the Lippmann in 1987, his experiment
explained that the ability of the recall of discrete Hopfield
network [16] would have the condition of two mistakes
take place [18].
1.The noise of the sample pattern is too heavy, and the
network would produce the sample pattern of wrong recall
2.Although the network converged on correct pattern, the
convergent result unequal to the original sample
pattern .This is a recall pattern of partial wrong, as Figure
4
In our approach, used the Eq(14) to match database can
improve the recall of partial wrong by a wide margin, as
Figure 4

Sample pattern”9”

0.5

100%

(In the above form is accorded the condition of
Lippmann in the laboratory, it don’t consider the problem
of capacity provisionally)

sample pattern ? , the dHmin = 0 , If the convergent
result of the X unequal to some vector of sample
u

0(no noise) 0.25

Correct recollection
Partial
recollection

The minimal
value asp
p
p
Χ i − ξ 1i , ∑ Χ i − ξ i2 ,⋅ ⋅ ⋅ ⋅ ⋅ ⋅ ⋅, ∑ Χ i − ξ in }
dHmin=min {∑
(14)
i =1
i =1
i= `
If the convergent result of the X equal to some vector of

pattern ? , the dHmin > 0 ;We would think that the X is
similar to the sample pattern ? u .

Noisy probability

Noisy sample
pattern”9”
Convergence

As an important model of associative memory, Hopfield
network has been extensively studied and applied to such
kind of pattern recognition with the sum-of-outer product
scheme [11]. Since the memory capacity of Hopfield
network with the sum-of-outer product scheme is very low
[21], further researches have been made on the asymmetric
or generalized Hopfield model with the other learning
algorithms [22] [23].Hopfield put the number of stable
patterns for the Hopfield RNN at 0.15P (for P neurodes) in
his original paper [11]. Since then, many others have
obtained results that show better performance
capability.The capacity of a Hopfield RNN is the number C
of stable states it has. Obviously, C depends on the
weight matrix, which we take to be symmetric with zeros
on the diagonal. It is shown by McEliece et a1. [21] that
P/[(4)ln(P)]<C<p/[Q]ln(P)
(21)
Example .for 100 neurodes, this yields c that satisfies
5<C<10, the C is a number of data record in the stable

Matching
pattern database
to find out the
Proceedings of the Sixth International Conference on Information Visualisation (IV’02)
1093-9547/02 $17.00 © 2002 IEEE

state.There is a up-limit in the memory capacity of discrete
Hopfield network. If the number of neuron is P, we can
accord to the Eq.(21) as
M max =

P
, M max: The maximum memory capacity
2ln(P)

(22)

D.J.Amit[24] brought up that the number P of neuron has
99% correct rate in the phase of retrieval ,and it wouldn’t
storage the number of the data record to exceed following
formula :
P
M: memory capacity
(23)
M≤
,
4ln(P)

In Our approach, the M in the Eq.(22) and Eq.(23) would
become the basis of divided segment in the pattern
database, namely the M is the cut number of distributed
compute. In this paper, there is an implementation of
pattern recognition. We would stand on the establishing
process of Chinese word in the computer to use the
P=240(15×16 matrix) neurons and the P2-P=57360 weight
value for the recollection. Therefore we would the P=240
bring into Eq.(22)and Eq.(23), and we would can find out
the number of different capacity namely the number of the
cut record of pattern datadabe.Supposing we used the
Eq.(23) to compute the cut number in the condition with
the recognized rate of 100%.
M≤

P
4ln(P)

Figure 5. Using Web-based method to build pattern
database (Prototype Database)
We used the method of as the Figure 5 to build the
sample pattern, and we adopted that the front narration
mentioned the distributed compute of cut records. It
would be solved in the about the problem of the capacity
of neural network. Because our learning pattern used a
dynamic method, we can do the task of pattern
recognition in the any time.
In our method of pattern recognition, we adopted also
the real-time way with web-based method to integrate the
complete Internet network, as Figure 6.
Remote User
User 1
Firewall
Pattern Database
User 2
Server-end
Internet
User 3

, the P=240

User 4
:
:
:
Client-end

240
4ln(240)
M ≤ 10
(records)
M≤

For this reason, we would set the cut number of pattern
database as 10. Thus we would the pattern of every ten
records set into a segment to calculate their W value and
? value individually

Figure 6. The system of pattern recognition is integrated
in the Internet

5. System Implementation
The first, we established the system of pattern
database in the server-end, and used Microsoft SQL
Server to become the platform of data management. The
input is a dynamic action in the sample pattern, and we
used real-time way with web-based method to input the
pattern. We can build the new learning pattern in the any
time; Even we can update, modify ,and delete the
established sample pattern.
The front narration is to conform to the rule of build the
pattern database, that refer to Figure 5
(Remote
user
or
administrator input the
sample pattern in the
environment of browser)

Database System

Storage patterns
Real-time

Figure 7. These patterns are inputted from the client-end,
and they are displayed in the server-end
In order to convenient view the recognized process of
system; we would put the recognized result of pattern
database in the same web page, as Figure 7.In the Figure
7, the right of the web page is a client-end and the left of
the web page is a server-end; when the user inputted the
pattern with the noise from the server-end and the user
after clicked the recognized button from the client-end, the
system would begin recognizing the pattern. Finally, we
would find out the result which is a correct pattern by the
input of the user in the server-end. Our recognized system
already improved a lot of problems which are existed
previously. The capacity and correct rate are ameliorated
substantially, and the neural network with distributed

SQL Server 2000
Proceedings of the Sixth International Conference on Information Visualisation (IV’02)
1093-9547/02 $17.00 © 2002 IEEE

compute would turn into an excellent efficiency system. In
the following content, we would analyze the convergence
of recognized system. We referred to Lippmann’s
experiment which the inputs applied to the network
assume the value +1 for black point and -1 for white point.
Next, to demonstrate the error-correcting capability of
the Hopfield network, a pattern of interest is distorted by
randomly and independently reversing each point of the
pattern from +1 to -1 and vice versa with a probability of
0.25,and then using the corrupted pattern as a probe for
network. The result of this experiment for the Chinese
word is presented in Figure 8. The patterns produced by
network after 30, 60, 100, 150, 200, and 236 iterations is
increased, we see that the resemblance of the network
output to the Chinese word is progressively improved.
Indeed, after 236 iterations, the network converges onto
the exactly correct form of the Chinese word.

After 30 iterations

After 60 iterations

Figure 9. Partial incorrect recollection in the retrieve

Figure 10. The accurate condition of convergence after
the matching of pattern database

6. Recognition rate analysis

After 100 iterations

After 150 iterations

After 200 iterations

After 236 iterations

Figure 8. Complete system of pattern recognition is
showed in the convergent process.
In the Figure 8, we can view the correct pattern of stable
convergence by pass 236 iterations in the server-end. Next,
it is a case of spurious states, we input the noisy pattern
from the client-end, and we would recognize partial pattern
of recall in the server-end. Because we don’t input such as
sample pattern, the pattern is not correct recall, as Figure
9

In our approach, the system increased the matching
application of pattern database. So the recollection of the
partial incorrectness of the Figure 9 wouldn’t take place
again. After the system passed the matching of pattern
database, it would converge to accurate pattern, as Figure
10.Finally, we used 40 patterns to do an experiment for our
recognized system, and these sample patterns are showed
in the Figure 11.

Figure 11. 40 sample patterns
We used the recognition of 100 times for standard to
input the pattern at random. We used the probability of
0.25 and o.5 to do that the +1 changed into the -1, or the -1
changed into the +1 for noisy interference. In the process
of the experiment and that is divided into two modes. The
first, we used the traditional method to recognize, the
second, we used our improved method to recognize, as

Proceedings of the Sixth International Conference on Information Visualisation (IV’02)
1093-9547/02 $17.00 © 2002 IEEE

following form is showed in the Figure 12 and Figure 13.

M, 2M, 3M,….., to compute the W value and the ?
value,.
P
1 M
M
W ji(M) , i = 1,......, P
∑ ? K ? TK − P I,? j(M) = ∑
P K =1
i =1
2M
P
1
M
? K ? TK −
I, ? j(2M) = ∑ W ji(2M) , i = 1,......, P
=
∑
P K = M +1
P
i =1
P
1 3M
M
T
? K? K −
I,? j(3M) = ∑ W ji(3M) , i = 1,......, P
=
P K =∑
P
2M + 1
i= 1
Μ
Μ
Μ
Μ

W (M) =
W (2M)
W (3M)

,

Figure 12. Using the traditional method to recognize

Step 3: Entering the stage of retrieval, n is the number of
iteration, X indicates that the pattern wants to
recognize pattern.
X j(M) (n + 1) = sgn(

P

∑W

ji(M)

X i(n) − ? j(M) )

i= 1

P

X j(2M) (n + 1) = sgn( ∑ W ji(2M) X i(n) − ? j(2M) )
i =1
P

X j(3M) (n + 1) = sgn( ∑ W ji(3M) X i(n) − ? j(3M) )
i =1

Μ

Step 4: To find out every convergent X value in the Step 3,
and matching pattern database to find out the
minimum Hamming distance,
Figure 13. Using our improved method to recognize
Obviously, we could discover that the recognized rate
of traditional method is less low in the experiment,
because we used 40 sample patterns to exceed the memory
capacity of the correct rate of 99% [24]. In the same
condition of sample pattern, we used our approach to do
that the result is better. Because we adopted the matching
technology of pattern database and the way of distributed
compute to solve the problem of capacity, we would be
able to obtain the better result of recognition

P
P
P

(n +1)
(n +1)
(n +1)
− ?1i , ∑ X ij(M)
− ? 2i ,......, ∑ X ij(M)
− ?M
dH min(M) = min ∑ X ij(M)
i 
 i=1

i =1
i =1
P
P
P

(n+1)
(n +1)
(n +1)
M +2
M +1
=
−
−
− ?2M
dH min(2M) min ∑ X ij(2M)
? i , ∑ X ij(2M)
? i ,......, ∑ X ij(2M)

i
 i =1

i =1
i =1
P
P
P

+1
+2
dH min(3M) = min ∑ X ij(3M) (n +1) − ? 2M
,∑ X ij(3M) (n+1) − ?2M
,......, ∑ X ij(3M) (n +1) − ?3M

i
i
i
 i =1

i =1
i =1
Μ
Μ

Μ

be combined these similar sample patterns to
become new pattern records, next return to Step 2
and repeated compute until the record of the Step5
is found out to equal to1

7. Algorithm Analyses
Our algorithm based on the theory of Lippmann [16] to
improve some faults, and we added our new approaches in
our algorithm. It is easy to implement in a computer
program.
The steps of our algorithm for finding the correct pattern
in the prototype are as follows:
Step 1: The first, computing the number of the cut records
of pattern database,
M=

P
, P is the total number of neurons
4ln(P)

Step 2: Every M records is a segment in the records of
pattern database, next the all records is divided into

Μ

Step 5: The dHmin is computed in the Step 4 can find out
the most similar sample patterns ξ , and they would

Step 6: Finally, finding out the sample pattern ξ , and it is a
correct pattern of recognition.
The recognized method is a new method in this paper,
only according to above content of step would be easily
to write the web page with the function of pattern
recognition.

8. Conclusion
At present, the application which deals with document
recognition has not developed into mature phase in the
Internet yet. If we use credit cards with recognition of realtime autograph as ordinary by the shopping of Internet,

Proceedings of the Sixth International Conference on Information Visualisation (IV’02)
1093-9547/02 $17.00 © 2002 IEEE

the shopping of network would be more and more popular;
simultaneously, the security of the shopping of network
would be raised.
In this paper, we use real-time way and web-based
method to recognize the network patter in the structure of
Internet. In the phase of recognized technology, we
mention the learning of pattern database to improve a lot
of defects. This paper brings up three new solutions, as
follows,
1. Using the pattern database to establish the learning
pattern, and it would overcome the problem of the
capacity of RNN in the meantime.
2. Adopting the matching technology of pattern database
to find out the most similar pattern, and the technology
would be able to decrease the spurious states of RNN;
relatively, it could raise the recognized rate of neural
network.
3. Our web-based approach adopts the way with real-time
Internet, and any user in the world would be able to use
the browser to connect the server-end by the Internet;
moreover, the user could input the training pattern and
recognize the pattern at once.
Many recognized programs must be performed in the
local machine, and these programs are limited in many
operating systems. If these programs are transplanted to
Internet, it would produce some difficulties in the phase of
CGI.
Our program is built in the environment of web server.
Because our system is real-time learning and real-time
recognition, the program wouldn’t delay in the stage of
performance.
This recognized system is managed by the back-end
database system. After the user login the system, all
patterns data would be stored in the database. This is a
new method, and it could ensure that these pattern data is
completeness and security
In the further development, our recognized system can
be applied in the electronic commerce (EC) widely. If the
server-end is a bank, we can register self account of
autograph (as sample pattern) in the remote home or office.
When we use network business, the signed pattern would
be recognized in the server-end of bank. The people in the
network would be more secure to buy, and the electronic
commerce would be developed further.

10. References
[1] Singh, S., ”A Long Memory Pattern Modeling and
Recognition System for Financial Forecasting,”Pattern Analysis
and Applications, vo1.2, no.3, 1999,pp.264-273.
[2] S. kak, “Better Web Searches and Prediction with
Instantaneously Trained Neural Networks” IEEE Intelligent
Systems, vo1.14, no.6, 1999, pp.78-81.
[3] R.P.W.Duin, “Superlearning and neural network magic,”
Pattern Recognition Letters, vol.15, 1994, pp.215-217.
[4] M.A.Kraaijveld and R.P.W.Duin, “The effective capacity of
multilayer feedforward network classifiers,”Proc.12th Int’l Conf.
on Pattern Recognition.( ICPR 94), Israel, vol.B,1994,pp.99-103.
[5] Z.TAN and M.K.ALI, “Pattern recognition with stochastic
resonance in a generic neural network,” International Journal of
Modern Physics C, vo1.11, no.8, 2000, pp.1585-1593.
[6] M.Perus, “Neural networks as a basis for quantum
associative networks,” Neural Network World, vol.10, no.6,
2000, pp.1001-1013.
[7] Brouwer, R.K., “An Integer Recurrent Artificial Neural
Network for classifying Feature Vectors,” International Journal
of Pattern Recognition and Artificial Intelligence, vol.14, no. 3,
2000, pp.339-335.
[8] Brouwer, R.K., “A Fuzzy Recurrent Artificial Neural
Network for Pattern classification, “International Journal of
Uncertainty, Fuzziness and Knowledge-Based Systems, vo1.8,
no.5, 2000, pp.525-538.
[9] Kamp, Y. and Hasler, M., Recursive Neural Networks for
Associative Memory,: Wiley-Interscience Series in Systems and
Optimization, England ,1990, pp.10-34.
[10] V.Gimenez, L.Aslanyan, J.Catellanos, and V.Ryazanov.
“Distribution Functions as Attractor for Recurrent Neural
Networks,” Pattern Recognition and Image Analysis. vol. 11, no.
3, 2001, pp. 492-497.

9. Acknowledgments

[11] J.J. Hopfield, “Neural networks and physical systems with
emergent collective computational abilities,” Proc. the National
Academy of sciences, USA,vol. 79, 1982, pp.2554-2558..

The authors would like to thank the National Central
University of Taiwan for financially supporting this
research.

[12] Simon Haykin, Neural networks a comprehensive
foundation, 2nd, Macmillan College Publishing Company, Inc.,
New York, 1999.

Proceedings of the Sixth International Conference on Information Visualisation (IV’02)
1093-9547/02 $17.00 © 2002 IEEE

