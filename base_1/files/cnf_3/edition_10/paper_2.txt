Visualising Human Dialog
A. Tat, M. S. T. Carpendale
Department of Computer Science
University of Calgary
{annie,sheelagh}@cpsc.ucalgary.ca

Abstract
Human dialogue is so complex that definitively analysing
patterns of conversation may well be impossible. Within
a conversation, all the complexities and ambiguities of
natural language exist and each speaker will have his/her
own speech characteristics and moods. Examining these
characteristics through text dialog can be a demanding
cognitive task. One reason is because the whole
conversation cannot be viewed at one time. This task can
be made more convenient if there is a way of visualising
all this information at once through graphical patterns.
Graphical patterns can revolve around the conversation,
creating an abstract piece of artwork. From these
patterns, one can guess at the speaker’s emotion and how
he/she is connected to another speaker during a
conversation. This paper will discuss the different
visualisation techniques that are used to represent several
aspects of a conversation.

There are several research challenges in this project
such as deciding what data this should be based on,
retrieving that data from the postings, creating a
meaningful mapping from the text data to a visual
representation, and developing an overall pattern from
this mapping while keeping variations in the patterns both
distinctive and spatially explicit. Human dialogue is so
complex that analyzing patterns of conversation fully may
well be impossible. However, within a conversation, each
of us is capable of assimilating subtle nuances with the
spoken word to develop our own understanding. In online
typed ‘chat’ communication many of the conversational
subtleties that so enrich our communications are lost.
People have resorted to interesting uses of capitals and
punctuations developing what are becoming recognized
styles that can be read as emotions. In fact many of these
are being called ‘emoticons’.

1. Introduction
This paper explains how text listings are visualised
with abstract representations of the patterns of social and
conversational interactions and histories. We wish to
provide a visual impression of the quality or tone of the
conversation that is taking place. While this information
may be available through examining these characteristics
through the text dialog, this can be a demanding cognitive
task because the whole conversation can not be viewed at
one time. One would have to inconveniently switch back
and forth between postings in order to compare
conversational characteristics. This task can be made
more convenient and perhaps pleasurable if there is a way
of visualising all this information at once through
graphical patterns. We generate visual patterns from
simple conversational elements such as tempo,
punctuation and character usage. It is hoped that the
resulting graphical patterns will revolve around the
conversation, contributing to both the artistic impression
and the usability of the interactive space. Figure 1 shows
the patterns of one conversation.

Proceedings of the Sixth International Conference on Information Visualisation (IV’02)
1093-9547/02 $17.00 © 2002 IEEE

Figure 1: The pattern of a conversation

2. Related Work
There are various ways of visualising text. Most of
them focus on visualising the content. Theme River [2]
retrieves information about frequency of word usage to
visualise thematic variations. These variations are laid out
horizontally giving the impression of a river of varying
thickness according to the recurring topics. Lin [4]
visualises the topics and their relationships to create a 2D
document space. Rohrer et al. [5] map document content
to shape and use implicit surfaces to create 3D models of
Shakespeare’s plays. Wise et al. [10] visualise the
interrelationships between documents to create Galaxies
[10] and use themes found within the documents to create
ThemeScapes [10].
None of these investigate portraying the spirit of a
conversation. Online chat systems come closer to this
goal. However, most chatspaces are either totally textbased or graphical with text insertions. Comic Chat [3] is
a graphical chat space and, as its name suggests, uses
aspects of comics such as balloons, spatial organization of
comic characters, and the possibility of character gesture
and expression. While we will not pursue the quasirepresentational style of comics we are interested in the
fact that Comic Chat supports incorporation of emotional
information into the delivery of messages.
It is our intention to explore the creation of a visual
but abstract visualisation. While there is been little
research in this area, the success of Chat Circles [8] in
which use of abstract visual representations are explored,
indicates the potential of moving in this direction. In Chat
Circles each individual is represented as a circle. Postings
appear in your circle as you type. In order to ‘hear’ or see
the words of another’s posting, your circle must be close
to theirs. Your next posting replaces the previous one.
Social groupings form indicating who is listening to
whom, size and frequency of postings are apparent.

3. The Approach
The text visualisation called Bubba Talk was
developed. Currently it receives input data from text
conversations. This visualisation is intended to give an
impression of the spirit and timbre of the conversation.
When one starts to look at the readily parse-able aspects
of on-line typed communication, one realizes that there
are many options. Initially we have looked at:
• the response relationship,
• the use of capitals,
• the use of exclamation marks,
• the number of words, and
• the number of characters.

each individual speaker. In Bubba Talk, speakers are
initially laid out in a circle so that connections between
each individual can be easily seen (Figure 2, left image).
Whereas in Figure 2, right image, the speakers are not laid
out in a circle and as a result there are overlapping lines
and some of the connections are covered. For this reason
in Bubba Talk speakers are initially placed in a circle, but
if the initial setting is not preferred the user has the choice
to interactively move the speakers around.

Figure 2: circle layout on the left and linear
layout on the right
Different colours are chosen in order to easily
distinguish one speaker from another. The colours of
each individual were chosen in a manner that creates an
overall combination of the colours that are not too
overwhelming, but work together in harmony. The colour
of a speaker is also used for the other aspects of the
visualization that relate to this speaker.

3.1. The response relationships
There is a need to present connections between the
speakers to see how one speaker responds to another.
Seeing the direction in which the speaker is talking is
important in this case, so a simple line between two
speakers will not be sufficient. For example in Figure 3
one can not tell whether speaker one (blue) is talking in
response to speaker two (red) or the other way around.

Presenting all of this information together in one
visualisation first involves thinking about the layout of

Proceedings of the Sixth International Conference on Information Visualisation (IV’02)
1093-9547/02 $17.00 © 2002 IEEE

Figure 3: A non-directed connection

A simple solution to this problem is to draw an arrow
to see the direction of connection, but a simple arrow is
not as interesting to look at. Another approach is to use
animation.

from the speaker and get small as they approach the
person that is being spoken to. Notice how bi-directional
communication is also apparent.

Figure 4: Animated connection shows no
direction when stopped
This is effective in showing the direction of motion
while the object is moving, but once the object stops the
sense of motion and connection is lost, as can be seen in
Figure 4 without the animation. In this case it would be
nice to see the motion with a trail left behind as shown in
Figure 5.

Figure 6: The response relationships

3.2. The use of capitals
In online communications repeated use of capitals
has come to indicate that someone is shouting or trying to
capture attention. Capitals are also used in the beginning
of sentences and used in abbreviations. For this program
capitals are only assumed to indicate yelling and trying to
grab someone’s attention if they are used repeatedly.
Since flashing or flickering is also used to gain someone’s
attention and will be used for this purpose in the program.
The number of circles represents the number of capitals
used (Figure 7).
Figure 5: Circles of decreasing size indicate
direction
The circles become smaller and less faded as they
approach the target to emphasise direction of movement.
This direction technique can be used to show which
speaker is going to speak next. However, in Bubba Talk
this direction of movement is used to show whom the
speaker is responding to. For example, in Figure 5, lets
say destination 1 and 2 are speakers 1 and 2, respectively.
In this case, speaker 1 will be talking in response to
speaker 2. Depending on what type of conversation is
being looked at, the direction of connection will be
different, which would need to be looked at further.
Figure 6 shows the connections visualisation from a
conversation between six people. The connection lines are
drawn with repeated circles. The larger circles emanate

Figure 7: The capitals representation vibrates
when animated

3.3. The use of exclamation marks
Exclamation marks are used to either exaggerate or
emphasise a point. Exaggerations are often used in
cartoons or animation by enlarging a specific feature of a
person or an object. In this case, every time a speaker
uses an exclamation mark an animated circle will grow in

Proceedings of the Sixth International Conference on Information Visualisation (IV’02)
1093-9547/02 $17.00 © 2002 IEEE

size. As the speaker uses more exclamation marks, more
circles will be created with a size bigger than the previous
one (Figure 8). Each circle is transparent so the previous
circles are not covered. This way the user can see how
many exclamation marks there are by counting the
number of circles created.

The green person spoke a simple utterance, perhaps
hello since it only has five characters. The blue person
had a much lengthier response. The advantage of making
the dots equal to the number of characters or words is that
a sense of quantity can easily be distinguished (Figures 9
and 10).

4. Motion

Figure 8: Repeated exclamations

3.4. The number of words
Each word in the posting is represented by a dot that
hovers around the speaker (Figure 9). This builds up
giving a general impression of quantity of contributions to
the conversation.

Figure 9: The words from one speech
overlapping the speaker

Rather than moving particles at a constant speed,
realistic motion requires physics of how an object travels
from one destination to another. In reality if a car was
moving too fast and doesn’t slow down at a red light, the
car will go past the red light. The car would normally
have to slow down as it approaches the red light in order
stop at the appropriate spot. This realistic movement
effect can be calculated from formula [A], so that the
object travels only half the remaining distance every time.
[A]

Where we want to go = where we are +
((where we want to go – where we are)/2)

Formula [A] can be applied at every frame so that the
object will actually appear to slow down as it approaches
the target destination (Figure 11). Technically speaking
the object will never approach the exact point of the final
destination by using this formula because the object
travels only half the remaining distance every time. In
this case, it won’t matter because the distance between
where the object is and the final destination will
eventually become so small that it won’t be visible.
[B]

Where we want to go = where we are +
((where we want to go – where we are)/n)

3.5. The number of characters
Similarly each of the characters is represented by a
dot. Character dots are smaller than word dots and travel
from the speaker to the person who is being spoken to.
Character dots disperse slightly so that they can be seen
distinctly. Figure 10 show the representation of two
speakers.

Figure 10: The small dots representing the
characters travel towards the person to whom
they are addressed

From formula [B], the variable n is a measure of how
quickly the equation reacts to change. This is a summary
of how different values n can approximate how an object
moves.
If n < 0, the object will accelerate past target.
If n = 0.5, the object will oscillate around target.
If 0.5< n <1, the object will accelerate past the target
and come back the other way, then will eventually stop at
the target after a few bounces.
If n = 1, the object will get to the target immediately
with no realistic effect.
If 1 < n < 2, the object will slow down as the particle
gets closer to the target.
If n > 2, the object will never reach the target.
This movement effect is useful in moving one object,
but if there was more than one object such as in the Bubba
Talk, an adjustment to the algorithm will be needed. The
problem with using the original formula is that all the
duplicated objects will follow the same path so that all the
objects will start overlapping one another and will end up

Proceedings of the Sixth International Conference on Information Visualisation (IV’02)
1093-9547/02 $17.00 © 2002 IEEE

appearing as one object. To create a natural movement of
particles without overlaps, a swarming behaviour
algorithm is used. Swarm travels as whole to a single
destination, but individual swarm members have slightly
different destinations. As a result each individual in the
swarm will land slightly to one side of its neighbour as
shown in Figure 12.

Starting point

Final destination

Figure 13: One person talking to people all
around them gives a general party air

Figure 11: Slowing down when approaching a
target
Using formula [B], one can apply this swarm effect
by adding a random number to (where we want to go –
where we are) and the n value will also need to be
adjusted to get the right speed movement toward the
target.
This motion is applied to the character
representations and to the word representations. The
characters travel as a swarm to their intended destination.
The words merely swarm around the person who said
them.

5. Emerging Patterns of Conversation
The individual components can be viewed as a whole
(Figure 1) or in any chosen combination. Figure 14(a)
shows the word contributions to this conversation. Figure
14(b) show the characters and Figure 14(c) shows the use
of capitals and exclamation marks. As more individuals
start to speak, more patterns will be generated and will
eventually clutter the screen. This can be addressed in
that visualised aspects of the conversation fade with time
or as just stated by selecting only a chosen subset of the
visualisations to be displayed.

6. Future Considerations

Figure 12: the dark arrow indicates the principle
direction. The lines indicate the directions of
individual particles.
Using formula [B], one can apply this swarm effect
by adding a random number to (where we want to go –
where we are) and the n value will also need to be
adjusted to get the right speed movement toward the
target.
This motion is applied to the character
representations and to the word representations. The
characters travel as a swarm to their intended destination.
The words merely swarm around the person who said
them.

Currently Bubba Talk parses typed text. We are
interested in incorporating these ideas with on-line
conversations in real time. Further development of Bubba
Talk will address the following:
Creating
more
visualisations
for
different
punctuations such as question marks, commas,
backspaces, and emoticons etc, to give more
characteristics to the mood of the conversation.
Exploring how different texture techniques, such as
Noise Algorithms, can also be applied adjustments to
the visual patterns.
Extending the program so that different data files of
conversation can be used, and different patterns from
different conversations can be compared at a time.
Studying whether these visualisations are meaningful
to people. Informally, people have said it provides
the flavour or perhaps intensity level of a
conversation and some have claimed to recognise a
friend’s style.
However, this still needs to be
investigated

Proceedings of the Sixth International Conference on Information Visualisation (IV’02)
1093-9547/02 $17.00 © 2002 IEEE

Preserving patterns of a particular conversation. It
would also be nice to be able to save the patterns
generated instead of having them disappear
completely when the reset button is pressed.

7. Conclusion
Bubble Talk has shown that many characteristics of a
conversation can be visualised. From looking at the
resulting pattern one can see who was interacting more
and who was not interacting as much. One can see who
was talking to whom and who was ignoring whom. Also
we investigated the application of simple aesthetics to
visualisation. Analogous colours and variations on a
single shape, the circle, were used exclusively for all the
representations.
Bubba Talk was created to explore visual ideas for
representing human dialog and serves to show how
graphical patterns can be visualised to reveal some
aspects of the mood of each speaker when they are
speaking and of the connections between the speakers.

8. Acknowledgements

(a)

This project relates to the CodeZebra project [1] and the
authors would like to acknowledge their discussions with
Sara Diamond and all the people in the CodeZebra [1]
project.

9. References
1.
2.

(b)

(c)
Figure 14: Visualising different aspects (a)
words, (b) characters and (c) capitals and
exclamations marks

http://www.codezebra.net
Susan Havre, Beth Hetzler and Lucy Nowell.
“ThemeRiver: Visualizing Theme changes over Time”, In
the proceedings of the IEEE symposium of Information
Visualization, InfoVis’00. Pages 115-123. 2000
3. David Kurlander, Tim Skelly and David Salesin. “Comic
Chat”, In Proceedings of the SIGGRAPH, 1996.
4. X. Lin. “Visualization for the document space”,
Proceedings of Visualization '92, pp. 274-81, IEEE
Computing. Soc. Press, 1992.
5. R.Rohrer, D. Ebert, J. Sibert. “The Shape of Shakespeare:
Visualising text using implicit surfaces”, In the
proceedings of the IEEE symposium of Information
Visualization, InfoVis’98. Pages 121-129. 1998
6. Bhangal, Sham. “Foundation Action Script. Friends of
Designer to Designer”, Star Southfield Theatre. Michigan,
Detroit, 2000.
7. Shneiderman, Ben and Ahlberg, Christopher. “Visual
Information Seeking: Tight Coupling of Dynamic Query
Filters with Starfield Displays”, In the Proceedings of
ACM Conference on Human Factors in computing Systems.
Conference Proceedings CHI’94, pp. 313-317, 1994.
8. Fernanda B. Viegas and Judith S. Donath., “Chat Circles”,
In Proceedings of the ACM Conference on HumanComputer Interaction CHI’99, 1999.
9. Ware, Colin. Information Visualization: Perception for
Design. Morgan Kaufmann Publishers. 2000.
10. J.Wise, J. Thomas, K. Pennock D. Lantrip, M. Pottier, A.
Schur, V. Crow. “Visualizing the Non-Visual: Spatial
Analysis and Interaction with Information from Text
Documents”, Proc. IEEE Symp. Information Visualization,
InfoVis, pp. 51-58, IEEE. Press, 30-31, October 1995.

Proceedings of the Sixth International Conference on Information Visualisation (IV’02)
1093-9547/02 $17.00 © 2002 IEEE

