Faster is Better: Optimal Speed of Animated Visualizations for Decision Makers
Mats Lind, Andreas Kjellin
Department of Information Science, Uppsala University, Uppsala, Sweden
mats.lind@dis.uu.se, andreas.kjellin@dis.uu.se
Abstract
Controlling dynamic processes is a task that is increasingly important in many areas. A possible visualization
technique for time-dependent events is animation. However, there are to our knowledge no data available on how
different animation speeds affect the performance of human
decision makers when trying to discover complex patterns
in animations. An experiment was therefore deigned using
a cue probability learning paradigm. The results indicate
that speed is indeed affecting performance, at least in the
more challenging condition we used. Some implications of
these results are discussed.
Keywords— Animation, visualization, velocity, complexity,
situation awareness.

1. Introduction
The understanding and control of complex dynamic
processes is an increasingly important part of many endeavors in modern society. Handling trafﬁc ﬂow, managing emergency operations and exerting military command
and control are just a few examples. A central concept in
research in this area concerns what is usually referred to as
situation awareness[5, 6]. It has several levels, but for a successful handling of a dynamic situation it suggests that the
person in command needs to have grasped the nature of the
chain of events leading up to the present state and also to be
able to make correct predictions of the (near) future states
of the system to be controlled.
How can a computer system aid a decision maker (DM)
in reaching this level of situation awareness, especially
when the dynamic process is fuzzy and not well modeled
by formal methods? One solution might be to create 2D
computer animations of what has happened to give the DM
a better sense of the spatio-temporal relationships. This is
perhaps especially viable when the process to be controlled
has a clear geographical aspect, such as when ﬁghting ﬁres
or exerting military command and control. If we accept this,
it follows that a number of parameters controlling the computer animation need to be set to some reasonable value.
A prime such parameter is the speed by which the objects

in the animation should move. Speed should here be understood as the mean absolute speed in degrees of visual
angle per second of the objects shown. The relative speed
between the objects is of course given by the dynamics of
the situation depicted. A good way of thinking of it is to
consider a movie that is already shot. All you can do when
showing it is to alter the speed of the playback.
If the speed is too slow, the DM will not even see the objects move (c.f the hour hand of a watch) and if it is too fast,
they will be seen as smeared lines instead of moving objects. However, between these extremes lies a world of possibilities and this deﬁned our primary research question: If
we create computer animations of dynamic processes aimed
at supporting a DM in a complex dynamic situation, does
the mean speed of the objects in the animations matter?
Previous research on the effect of different speeds on
the ability of human observers to predict future states involves low-level perceptuomotor tasks such as predicting
when two moving objects will collide or when one moving object will hit a stationary target, see for instance
[4, 7, 8, 11, 13, 14, 16]. The generalized ﬁnding is that,
within limits, higher speeds increase performance.
However, such cognitively simple tasks are not really
relevant for our purposes in that computerized prediction
algorithms could easily handle them. We are primarily interested in more complex and cognitively challenging processes. Therefore, we turned to the literature and
adapted a well-known research tradition in the decisionmaking literature to our purposes. The methodological
framework is known as Cue Probability Learning (CPL).
It is based on ideas originally conceived by Egon Brunswik
in the early 20th century [9]. Later Berndt Brehmer and
others developed CPL as a method to study judgment and
decision making based on these ideas, see for example [2]
and [3].
The central theme in CPL is performance. Performance
is expressed in terms of achievement, which is deﬁned as
the correlation between the judgment and the correct value
(also called criterion). The participants’ goal in a CPL experiment is to predict the criterion value based on some information in the experiment situation, the cues. Directly

Proceedings of the Ninth International Conference on Information Visualisation (IV’05)
1550-6037/05 $20.00 © 2005 IEEE

after the answer, the participant is given the correct answer
as feedback. In CPL there are two kinds of cases, Narrowfocus task and Wide-focus task. Narrow-focus tasks require
the participant to use some of the available cues and ignore the others. In wide-focus tasks the participant needs to
use all available cues in order to reach maximum achievement. The achievement, the correlation between the judgment (answer) and the criterion (the best possible answer),
is expressed as a correlation. The higher correlation a participant gets, the better he/she is in choosing and utilizing
the correct cue in the task.
A wealth of knowledge exists on how people perform
in CPL tasks. It is therefore possible to choose conditions
that are known to be different in terms of how cognitively
challenging they are. In turn this allows us to study the relation between task difﬁculty and different mean animation
speeds.

2. Purpose
The purpose of our study was to investigate the relationship between mean speed of the animated objects’ speed
and the ease of learning a complex relationship deﬁned between the moving objects.

3. Method
As cue(s) in the CPL task we used relative speed. One
of the objects, the reference object (a red triangle), had always the same speed during an animation and the relative
speed between this reference object and the other object(s)
was the cue to be learned by the subject. The objects, apart
from having different speeds, moved in different directions
and started from different positions (see below). Thus, the
task can be thought of as a narrow-focus task since the subjects were required to detect that "direction of motion" and
"starting position" were unrelated to the criterion.
The relationship the subjects had to discover between
the relative speed(s) and the criterion was linear one. That
is, the value of the criterion could be expressed as a linear
function of the cue(s). This relationship could also be characterized as deterministic since no extra noise was added to
the cues. However, in practice the relationship was probabilistic to the observers since the resolution of human vision
[15] did not allow them to exactly estimate the actual relative speed between the moving objects. Because of this we
could predict that the best performance, in terms of correlation, would be less than 1.0.

Lower two objects were moving across the screen.
Higher three objects were moving across the screen.
It is well known in the CPL literature that a two-cue (three
moving objects in our case) task is more difﬁcult to learn
than a one-cue task (two moving objects in our case).
The between factor "speed" had three levels: "Slow",
"medium" and "fast". In the slow condition, the speed of the
reference object was 8◦ /s, in the medium condition it was
13.34◦ /s, and in the fast condition it was 40◦ /s. For each
of these conditions an identical and predeﬁned series of relative motions were used. The other object(s) had speeds
ranging between -50% and +50% of the reference object.
The linear equations used, one for each level of difﬁculty,
were constructed such that the criterion ranged between 10
and 50. The distribution of the cue values in the single
cue condition (two objects) was uniform; the 42 values in
a block of trials were equally spaced between -50% and
+50%. The criterion value was determined by the equation:
Crit = 0.4 ∗ relative_speed − 10
To achieve a greater degree of comparability between the
one-cue and two-cue conditions, the distributions of the cue
values in the two-cue condition (three objects) were slightly
non-uniform. This was the result of the use of identical sets
of criterion values in both conditions during a block of trials. In the two-cue condition the equation used was:
Crit = 0.2∗relative_speed_1+0.2∗relative_speed_2−10
The task given to the subjects was to try to learn the
relationship between the moving objects and the criterion
value. The moving objects could start anywhere along the
leftmost 43% of a horizontal (invisible) line in the middle
of the screen, and the direction of their motion paths could
be of any angle within a 90◦ sector, see ﬁgures 1 and 2.

3.1. Stimuli and experimental design
The experiment used a so-called split-plot design with
two between subject factors (difﬁculty and speed) and one
within subject factor (blocks of trials).
The factor between subjects factor "difﬁculty" had two
levels:

Figure 1: A schematic example of a stimulus in the lower
difﬁculty condition.

Proceedings of the Ninth International Conference on Information Visualisation (IV’05)
1550-6037/05 $20.00 © 2005 IEEE

rest. The chin rest was adjusted such that the observer
had his/her cyclopean eye along the surface normal from
the midpoint of the monitor screen. Normal lighting levels
were used in the room and care was taken so that no lamp
produced glared on the glass surface of the monitor.

3.3. Procedure

Figure 2: A schematic example of a stimulus in the higher
difﬁculty condition.

These values were independently and randomly sampled
for each object and each trial. The length of the motion path
of the reference object was always 482 pixels. The lengths
of the other motion paths were determined by the relative
speed of the objects in question.
Thus, we controlled overall speed by controlling the total time during which the motion paths were shown in each
condition. By randomly assigning the starting points of the
objects, the subjects could, however, not use relative ending positions as a cue to the criterion value. Each animation
was calculated and shown using the monitors vertical sync
signal as a synchronization pulse. This meant that the animations were calculated and shown with a frame rate of 85
frames per second (see below), ensuring a smooth motion
appearance in all conditions.
All stimuli were shown against a randomly textured
background in nuances of dark gray. The moving objects
were differently shaped (squares, triangles and circles) and
colored, but retained their shape and color for each subject
throughout the experiment.
No help was given to the subjects about what cue to look
for; the only information the subjects were given was that
the relationship between the objects would remain the same
throughout the experiment. Each experimental session consisted of four blocks of 42 trials each.

3.2. Apparatus and viewing conditions
A computer was programmed using MATLAB c and the
Psychophysics toolbox [1, 12]. The program ran on a computer with a Pentium c 4, 2.0 GHz processor and a Nvidia
GeForce c 4 graphics card. The screen was a 22" Philips c
202P40 monitor with a 56 cm visible diagonal run at 1280
x 1024 pixels in resolution at a refresh rate of 85 Hz. The
observer was seated with his/her eyes 37 cm in front the
screen. This distance was controlled by the use of a chin

When the participants arrived at the experiment they
were ﬁrst asked about their age, and if their vision was normal or corrected to normal. They were then seated in front
of the computer screen and read the instructions for the experiment. The instructions for the experiment were simple.
They only described that objects on the screen would move
and that the subject’s goal was to ﬁnd the relationship between the objects and an even number between 10 and 50.
The subjects controlled the display by hitting the space
bar when they wished a trial to commence. The objects
then appeared and after their motion had ended, a square
appeared in the middle of the screen containing all even
numbers from 10 to 50. The participant then clicked on the
number he/she thought was the correct one.
Immediately after the subject had clicked on a number,
the correct number was shown as feedback for 1.5 seconds.
Then a blank screen was shown until the subject once again
hit the space bar. Four blocks of 42 trials each were shown
to each subject yielding a total of 168 trials per subject.

3.4. Observers
Forty-eight subjects took part in the experiment, 24 male
and 24 female. They were all students at Uppsala University and aged between 19 and 41 years. During a pre-test
interview all participants stated that they had normal color
vision and normal, or corrected to normal, vision.
They received a small compensation for taking part in
the experiment and had no prior knowledge of the purpose
of the experiment or the speciﬁc hypotheses employed. Regarding their sex all subjects were randomly assigned to one
of the six between subjects conditions (2 levels of complexity * 3 speeds).

4. Results
For each block of 42 trials, and for each subject, the correlation between the subject’s answer and the set of criterion values was calculated. Thus a total of 192 (4 blocks by
48 subjects) data points were collected and used in the subsequent analysis. Before analyzing the data by an ANOVA,
they were transformed to Fisher’s Z-values [10]. The result
of the ANOVA is shown in table 1.
A conservative decision criterion of 1% was used due
to the large number of tests involved in a multi-factorial
ANOVA.

Proceedings of the Ninth International Conference on Information Visualisation (IV’05)
1550-6037/05 $20.00 © 2005 IEEE

Effect

Split-plot Analysis of Variance

Intercept
Complex
Speed
Complex*Speed
Error
BLOCK
BLOCK*Complex
BLOCK*Speed
BLOCK*Complex*Speed
Error

SS

DF

MS

F

p

32.18220
0.72343
0.29824
4.08655
15.23068
0.89927
0.14648
0.05648
0.08017
1.88922

1
1
2
2
42
3
3
6
6
126

32.18220
0.72343
0.14912
2.04328
0.36264
0.29976
0.04883
0.00941
0.01336
0.01499

88.74539
1.99492
0.41121
5.63452

0.000000
0.165195
0.665488
0.006796

19.99199
3.25649
0.62778
0.89117

0.000000
0.023910
0.707774
0.503585

Table 1: The results of the ANOVA. Bold indicate signiﬁcant results at the 1% level.

Interestingly, there was no main effect of speed or difﬁculty. The only main effect was of blocks of trials (see
ﬁgure 3), which is not surprising, it simply means that the
subjects in all conditions were getting better as they went
along. There is, however, a most interesting signiﬁcant interaction between difﬁculty and speed. It is illustrated in
ﬁgure 4.
A post-hoc analysis using Fisher’s post-hoc test and,
again, using a conservative decision criterion of 1%, reveals that there is no effect of speed in the conditions with
lower difﬁculty. In the conditions with the higher difﬁculty,
however, the performance in the highest speed is signiﬁcantly different from the performance in the lowest speed
(p < 0.01).

BLOCK; LS Means
Current effect: F(3, 126)=19.992, p=.00000
Vertical bars denote 0.95 confidence intervals
0.7

0.6

Fisher's Z-values

0.5

0.4

0.3

0.2

0.1
Block 1

Block 2

Block 3

Block 4

Figure 3: Mean values of Fisher’s Z-scores for the four blocks
of trials.

Difficulty*Speed; LS Means
Current effect: F(2, 42)=5.6345, p=.00680
Effective hypothesis decomposition
Vertical bars denote 0.95 confidence intervals
1.0
0.9
0.8

Fisher's Z-scores

0.7
0.6
0.5
0.4
0.3
0.2
0.1
0.0
-0.1
slow

med
Speed

fast
Low difficulty
High difficulty

Figure 4: Mean values of Fisher’s Z-scores for all six between
subject conditions illustrating the signiﬁcant interaction
between difﬁculty and speed.

5. Conclusions and discussion
If these results hold for other user groups and tasks, there
seems to be a range of speeds that are optimal for discovering complex spatio-temporal patterns hidden in animations. Furthermore, this range of speeds is much higher
that what, according to our experience, is used in most animations of dynamic events. Thus, these results may have
far-reaching implications for how we employ animations as
decision support tools.
When exerting real-time control in a dynamic situation,
animation speed cannot be controlled, of course. But there
are at least two situations where these results can be of use
even in relation to real-time control: looking at the history
of the event and looking at the possible future by using simulations. Both of these situations are becoming increasingly
common since all incoming data are stored in large databases and more computer power becomes available to control centers. The value of better understanding the process
leading up to the present situation is easy to see and, at least
in military command and control, the possibility to simulate
the results of plans for future actions is considered to be extremely interesting.

Proceedings of the Ninth International Conference on Information Visualisation (IV’05)
1550-6037/05 $20.00 © 2005 IEEE

The results from this experiment must be validated in
more realistic settings. A new experiment is therefore under
development where the participants will be run in a more realistic situation using a command and control scenario. Further down the road are experiments combining the results
from these experiments with the use of 3D-visualizations.

6. Acknowledgements
The research described here was sponsored by a grant to
Mats Lind from the AQUA project at the Swedish National
Defense College in Stockholm, Sweden.

References
[1] D. H. Brainard. The psychophysics toolbox. Spatial
Vision, 10(4):433–436, 1997.
[2] Berndt Brehmer. Response consistency in probabilistic inference tasks. Organizational Behavior and Human Performance, 22:103–115, 1978.
[3] Berndt Brehmer. The development of social judgement theory. In B. Brehmer and C. R. B. Joyce, editors, Human Judgement: The SJT view, pages 13–40.
Amsterdam: North-Holland, 1988.
[4] Robert H. Davis and Richard A. Behan. A study of
visual prediction behavior. Human Factors, 2(1):228–
234, 1960.
[5] Mica R. Endsley. Measurements of situation awareness in dynamic systems. Human factors, 37(1):65–
84, 1995.
[6] Mica R. Endsley. Toward a theory of situation awareness in dynamic systems. Human Factors, 37(1):32–
64, 1995.
[7] H. C. Foot. Visual prediction of the point of coincidence of two moving targets. Ergonomics, 12(5):723–
733, 1969.

[8] Rob Gray and Ian M. Thornton. Exploring the link
between tim to collision and representational momentum. Perception, 30(8):1007–1022, 2001.
[9] Kenneth R Hammond. The psychology of Egon
Brunswik. New York : Holt, Rinehart & Winston,
1966.
[10] William L. Hays. Statistics for the social sciences.
New York : Holt, Rinehart & Winston, 2 ed edition,
1973.
[11] Kent A. Kimball, Mark A. Hoffmann, and Richard O.
Nossaman. Differential velocity and time prediction
of motion. Perceptual and Motor Skills, 36(3):935–
945, 1973.
[12] D. G. Pelli. The videotoolbox software for visual psychophysics: Transforming numbers into movies. Spatial vision, 10(4):437–442, 1997.
[13] Lowell M. Schipper and John Versace. Predictions
of arrival sequences of simulated radar targets as a
function of display size, target size, and target sharpness. Technical report, Wright Air Development Center, 1956.
[14] J. R. Tresilian. Perceptual and cognitive processes
in time-to-contact estimation: Analysis of predictionmotion and relative judgment tasks. Perception & Psychofysics, 57(2):231–245, 1995.
[15] Alexander H. Wertheim. Motion perception during
selfmotion: The direct versus inferential controversy
revisited. Behavioral and Brain Sciences, 17(2):293–
355, 1994.
[16] Xidong Xu and Esa M. Rantanen. Conﬂict detection
and resolution in air trafﬁc control: A task analysis,
literature review, and need for further research. In
Proceedings of the 12th International Symposium on
Aviation Psychology, 2003.

Proceedings of the Ninth International Conference on Information Visualisation (IV’05)
1550-6037/05 $20.00 © 2005 IEEE

