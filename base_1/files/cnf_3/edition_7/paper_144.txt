Virtual Change of Illumination Color
in Image Based Rendering
Tadahiro Kitahashi
School of Information Science, Kwansei Gakuin University
kt@ksc.kwansei.ac.jp

Abstract
An extension of the ability of the Image Based Rendering
(IBR) is described by presenting a method of generating
images corresponding to the virtual change of the lighting
color. It is an additional ability to the previous proposal
that allows generating images by virtually changing the
lighting orientation. It is also suggested that the basic
idea developed in this paper might be applicable to the
virtual varying object material.

1. Introduction
In the field of virtual reality, one of the most
important tasks is how to efficiently generate virtual
images matching with the given scene including
illumination environments. The Image Based
Rendering (IBR for short) is a well known and unique
rendering method especially useful for generating
virtual images of complex shaped objects such as a
stuffed doll and plants with lots of leaves without
constructing CG models of the object.
However, it was believed that IBR had a fatal
disadvantage that it is impossible to virtually vary the
lighting conditions so as to match with a required
illumination circumstance different from the original
environment. Shakunaga have presented a solution to
this problem [1], which was finally combined with IBR
by Kitahashi [2].
One of the recent issues in the area of virtual reality
and mixed reality is how to measure the total
illumination conditions surrounding the space where
virtual objects are to be situated. This is because that
acquiring the conditions is inevitable to render images
of virtual objects with realty in the same illumination
circumstance as the real objects, especially in the
mixed reality. It is not difficult to cope with the
problem in case that the virtual object has a three
dimensional (3D for short) object model generated by

CG, because its characteristics can arbitrarily be
designed as is necessary to the environmental
conditions. However, there occurs a problem, if the
situation requires an object of much complicated shape
that it is hard to create its model by either CG or some
other tools. IBR is relevant to this case.
Considering applications of the technique to various
examples of mixed reality, more flexibility in IBR
should be desired, for example, to vary color conditions
of original image sequences to meet with the new
circumstance by means of rewriting a term of the basic
formula by another detailed form.

2. Preparations
Before going into the discussion of the main subjects
in this paper, we will mention about the solutions
known until today as preparations of description of the
problems.
In the area of optics, the optical process along a path
from light sources to the image plane is represented by
the following formula.
ȡ(ș) 䋽  E(Ȝ) S(ș,Ȝ) R(Ȝ) dȜ
(1)
,where E(Ȝ) : Light source, S(ș,Ȝ) : Surface spectral
reflectance of an object, R (Ȝ) : Relative wavelength
sensitivity of the visual color sensor.
In the discussion of the lighting direction-free IBR
(ldf-IBR for short), the bi-chromatic model proposed by
Schefer and Kanade is employed as the reflectance
model of objects involved in an image in order to make
the discussion simple.
(2)
S(ș, Ȝ) = CS䋨ș䋩 + CD(ș) SD(Ȝ)
Substituting the formula (2) into the formula (1), we
have the following one.
ȡ(ș) 䋽  E(Ȝ) CS(ș) R (Ȝ)dȜ
(3)
+  E(Ȝ) CD(ș) SD(Ȝ) R(Ȝ)dȜ
The first term of the right side of the above formula
is denoted by specula reflection and the second one is

Proceedings of the Ninth International Conference on Information Visualisation (IV’05)
1550-6037/05 $20.00 © 2005 IEEE

by diffusion reflectance. The features of the two terms
are as follows.

2.1 Bi-chromatic model and ldf-IBR
Specula reflection means the miller reflection, which
causes so called high light points on the surface of an
object where each surface normal satisfies a specific
relationship between the lighting direction and the eye
direction of an observer. Consequently, locations of
high light points on an object in a given new
circumstance cannot be produced from vector
manipulation without knowing the distribution of
surface normal on the objects in a scene. On the other
hand, the second term indicates the effect of diffusion
reflectance. It is known that the reflected light is
equally radiated to all direction and the magnitude is
computed by the inner product of the lighting direction
and the surface normal. In other words, the intensity of
every pixel other than high light points, the value of the
diffusion reflectance, can be computed in terms of the
inner product of the surface normal and the lighting
direction at every point in an image.
Therefore, representing the direction of a light in the
form of a linear combination of three independent
components, the total illumination can also be
composed of a weighted sum of images of scenes, each
of which is illuminated with an independent component
of a light source. Thus, the second term of ldf-IBR
could be changed so as to match the illumination
conditions of the aimed circumstance.
This idea just provides us with a key of another
dimension of the improvement of IBR.

2.2

ldf-IBR and icf-IBR

The above discussion presents that the theory of the
ldf-IBR is based on the optical geometry and the
reflection mechanism, while the illumination color free
IBR (icf-IBR for short) is concerned with not the
geometric theory but the characteristics of the spectrum
of a lighting source. In this sense, icf-IBR, i.e. the main
topic in this paper, is essentially different from the
original IBR and ldf-IBR. Instead, the intension of
developing ldf-IBR and icf-IBR are similar to each
other in the point that they are both practical
improvements of IBR. Also, the approach of both are
similar as shown below.

㧟㧚Light color free IBR
Now we go into the description of solving one of the

remaining problems.
If a light source of an arbitrary color can be
substituted by a combination of a few kinds of colored
lamps, the light color free IBR can be realized in a
similar way to the known ldf-IBR. The assumption is
supported by a widely known theory in optics saying
that any color can be realized by mixing the three basic
colors; red, green and blue in a certain ratio.

3.1 Theoretical Solution
Generally speaking, the radiation spectrum of a light
source can be represented in a liner combination of
some basic spectral components of specific band-widths.
It is expressed in the following formula.
E(Ȝ) = Ȉi E i (Ȝ)
Substituting it into the formula (1), we have the
following formula.
ȡ(ș) 䋽 Ȉi E i (Ȝ) S(Ȝ) R(Ȝ)dȜ
䋽 Ȉi ȡi
(4)
It
should
be
noted
that
the
term
Ei(Ȝ)S(Ȝ)R(Ȝ)dȜ represents an image ȡi which is taken
under an illumination of a definite colored light E i (Ȝ).
The following is one of the points in this paper. The
formula indicates that it is necessary not to make the
characteristics of S(Ȝ) clear, but to take some pictures of
a scene under some different illumination conditions.
Saying more precisely, each picture should be
illuminated with a lamp of a color independent of each
other in the attribute space of hue.
In this way, we have readily obtained the theoretical
solution of the initial problem. However, the solution
necessitates at least three sorts of image sequences in
applying it to IBR.
We also need to prepare more than three image
sequences to cope with producing images matching the
illumination orientation in a given situation.
Additionally, if to deal with matching the illumination
color, more than three image sequences are desired to
each orientation, more than nine image sequences are
required to generate aimed images. This is not practical.

3.2 Practical Improvement
In a recent camera, the input light is separated into
three color components i.e. R, G, B by filtering and
stored in component wise. Using these three images in
place of the images required as in the above discussion,
the proposed method becomes practical for generating
images in a virtual lighting with an arbitrary color.
The scheme is represented by the following formula,
where F i (Ȝ) : a filter of R, G, B, s(Ȝ) : spectral

Proceedings of the Ninth International Conference on Information Visualisation (IV’05)
1550-6037/05 $20.00 © 2005 IEEE

㫊㪼㫅㫊㫀㫋㫀㫍㫀㫋㫐

㪇㪅㪇㪇㪜㪂㪇㪇 㪌㪅㪇㪇㪜㪄㪇㪋 㪈㪅㪇㪇㪜㪄㪇㪊 㪈㪅㪌㪇㪜㪄㪇㪊 㪉㪅㪇㪇㪜㪄㪇㪊 㪉㪅㪌㪇㪜㪄㪇㪊 㪊㪅㪇㪇㪜㪄㪇㪊

characteristics of a sensor.
ȡ(ș) 䋽  E (Ȝ) S(Ȝ) {Ȉi F i (Ȝ) s(Ȝ)dȜ
(5)
If the filtered picture is denoted by ȡi (ș), we have a
formula,
(6)
ȡ(ș) 䋽 Ȉi ȡi (ș)
On the other hand, if S(Ȝ) and F i (Ȝ) are commutative,
we have another expression of the formula (5) as
follows.
ȡ(ș) 䋽 Ȉi  F i (Ȝ)E(Ȝ) S(Ȝ) s(Ȝ)dȜ
䋽 Ȉi  E i (Ȝ) S(Ȝ) s(Ȝ)dȜ
(7)
This means that the filters F i (Ȝ) in a camera are
moved onto the lamps E(Ȝ), and each filtered light
Fi(Ȝ)E(Ȝ) works as the illumination of a different color
E i (Ȝ) independent of each other. Comparing the terms
on the right hand side of both formulas (6) and (7), the
images in the formula (7), which could be taken under
these circumstances, are equivalent to the filtered
pictures ȡi (ș) in the camera.
These ȡi (ș) are obtained from filtering of an input
image. Accordingly, it is not necessary to take at least
three images desired in the theoretical solution, but
only one input image is needed to make the proposed
method a practical one.

㪋㪇㪇

㪞
㪙
㪰
㪮
㪚㫆㫄㫇㫆㫊㫀㫋㫀㫆㫅
㪩㪼㪾㫉㪼㫊㫊

㪋㪌㪇

㪌㪇㪇

㪌㪌㪇

㪍㪇㪇

㪍㪌㪇

㪎㪇㪇

㫎㪸㫍㪼㫃㪼㫅㪾㫋㪿㩷㩿㫅㫄㪀

Fig.1 Spectrums of the referred lamps

4.2 The results of an experiment
In the above chart, each of the wavelength
distribution of three kinds of colored lamps is shown
as a dotted line in the same color to that of the lamps.

5.

Discussions

4. Experiment
The theoretical consideration is so clear that
experimental verification is not necessarily needed to
the method of ldf-IBR. Instead, we will show an
experiment as follows.

4.1 Procedure
The procedure of the proposed method for lcf-IBR is
as follows.
(1) The wavelength distribution of each colored
lamp is measured.
(2) desired wavelength distribution is
approximated by a linear combination of those
of lamps
(3) The aimed image of a desired virtual color is
generated by combining the three basic images
using the same coefficients as calculated in (2).

The final result tells us that, if we get any kind of an
image of a scene illuminated by synthetic lights, we
could conceptually reconstruct an image likely taken
under day light circumstance by means of decomposing
of the input image in basic color component wise and
recombining them with revised coefficients. This is just
an explanation of the mechanism of color constancy in
human visual system.
In the conventional discussions [3] on the color
constancy problem, not only the spectrum of lighting
but also that of surface reflectance is taken into
consideration. It suggests the method proposed here is
simplified in the mechanism and manipulation. The
discussion in detail will be out of the paper.

Proceedings of the Ninth International Conference on Information Visualisation (IV’05)
1550-6037/05 $20.00 © 2005 IEEE

(a) Input image

Fig.2 Images lighted in separate by each of the three
kinds of the fundamental colored lamps
(b) Generated image

(a)

(c) Real image
Fig.4 The effect of the final method

(b)

Fig.3 (a): A Virtual image of weighted sum of the
images in Fig.2
(b): A Real image lighted with an electric bulb

Acknowledgement
The author would like to extend great appreciation to
Professor S. Tominaga of Osaka Electric
Communication University for his kind support in data
acquisition of the experiments. He also thanks Mr.
Koichi Sakaguchi for the endeavor of experiments in
order to verify the proposal in this paper.



Proceedings of the Ninth International Conference on Information Visualisation (IV’05)
1550-6037/05 $20.00 © 2005 IEEE

Fig. 5

Three differently colored blocks

Fig. 6

Wavelength Characteristics of a lamp and a virtual lamp

Fig. 7 Generated image in the virtual lamp

Fig.8

An Actual image in an orange-colored lamp

References
[1] Y. Mukaigawa, H. Miyaki, S. Mihashi, T. Shakunaga:
“Photometric Image-Based Rendering for Image
Generation in Arbitrary illumination”, Proc. ICCV
2001, vol.2, pp.652-659, 2001.07
[2] Tadahiro Kitahashi: “Illumination-free IBR”,
Proceedings of World Automation Congress (WAC
2002), 3rd Int’nl Forum on Multimedia and Image
Processing(IFMP),(WAC best paper award) 2002. 06

[3] L.T. Maloney, B.A. Wandell:“Color constancy: a method for recovering surface spectral reflectance”,
J. Opt. Soc. Am. A, Vol.3, No.1, pp29-33, 1986.01
[4] S. Tominaga, B.A. Wandell: “Standard Surface-reflectance model and illuminant estimation”, J.Opt .Soc.
Am. A, Vol.6, No.4, 1989.04

Proceedings of the Ninth International Conference on Information Visualisation (IV’05)
1550-6037/05 $20.00 © 2005 IEEE

