Model-Based Analysis of Chinese Calligraphy Images
Sam T. S. Wong, Howard Leung, Horace H. S. Ip
City University of Hong Kong
{tswong@cityu.edu.hk, howard@cityu.edu.hk, cship@cityu.edu.hk}
Abstract
Chinese fonts with smooth outlines and solid
colouring have been produced for computer displays and
printings for a long time. However, the aesthetic
properties of the characters produced by calligraphers
could not be simulated with these methods. Ip and Wong
proposed a parameterised brush model that enables
efficient generation of Chinese calligraphic writings
such that the rendering is scalable in resolution and it
allows high quality publishing. While this graphical
model facilitates the synthesis of calligraphy writing
given a set of writing parameters, for the inverse
problem, a lot of user stroke manipulation is required to
regenerate the model parameters given a calligraphic
image. Consequently, an intelligent method is required to
automatically determine the model parameters from
images of Chinese calligraphy. This paper describes a
methodology for automatically estimating the set of 3-D
geometric and dynamic writing parameters along a
stroke trajectory from images of calligraphic writings.

1. Introduction
Early Chinese computer fonts were typically stored
in black and white bit-map formats. With the advance of
computer hardware thus the processing power, high
quality scalable characters focusing on describing
character shapes using smooth curves [1][2][3] with
techniques of image enhancement, edge detection [4][5],
stroke analysis [6][7], and fractal-based outline font
technology [8][9] have been proposed. Parameters of the
best fitted curves described by mathematical functions
[10][11] were recorded for character regeneration.
Outline fonts of character sets of smooth boundaries are
also available commercially nowadays.
Although characters with smooth outlines and solid
colouring could be produced by the above approaches, it
is still a challenging problem to preserve the aesthetic
properties such as the natural running of stroke shapes
produced by calligraphers; the impression of physical
rubbing between the brush and the underlying paper; and
the grey level details of painted oriental calligraphy. A
number of past researches focused on image synthesis
using brush model. For instance, Whitted‚Äôs brush
extrusion method performed anti-aliasing and produced
3-D appearance for curves and straight lines [12] . Posch
and Fellner‚Äôs circle-brush algorithm aimed at producing
constant line width [13] . Fishkin and Barsky‚Äôs brush
movement algorithms simulated image movements [14] .

Strassmann‚Äôs hairy brushes‚Äô model provided a
description of physical properties of brush materials to
generate hairy brush sumi-e images [15] . However, all
of the work above focused on synthesising painting
artwork but did not aim at generating hairy-brush
calligraphic writings.
Ip and Wong proposed a novel methodology for
generating hairy-brush writings maintaining a number of
aesthetic features of oriental calligraphic writings [16].
Their approach simulated the physical process of brush
stroke creation. A parameterised model was built to
specify the varying brush orientation, tip pressure, hair
properties, and ink deposition variations along a stroke
trajectory. As a result, realistic calligraphic images can
be produced and are applicable for very high quality
publishing
purpose.
By
applying
geometric
transformations and scaling on the stroke trajectories that
define a specific character, scalable grey-level fonts can
be designed and generated in contrast with traditional
vector fonts and imaging techniques. In addition, Mi et
al. proposed a droplet model for the synthesis of Chinese
calligraphic writings [19]. Yu and Peng also proposed
another model using brush texture patches to synthesise
calligraphic writings in cao style [20].
While the above proposed graphical models
facilitate the synthesis of calligraphy writing given a set
of parameters, for the inverse problem, a lot of user
stroke manipulation is required to regenerate the model
parameters given a calligraphic image. Consequently, an
intelligent method is required to automatically determine
the model parameters from images of Chinese
calligraphy. This paper describes a methodology for
automatically estimating the set of 3-D geometric and
dynamic writing parameters along a stroke trajectory
from images of calligraphic writings based on the Virtual
Brush model [16] . This paper is organised as follows. In
Section 2, Ip and Wong‚Äôs Virtual Brush model is
highlighted. The estimation for the Virtual Brush model
parameters is described in Section 3. The results and
discussions are provided in Section 4. The conclusions
and future work are presented in Section 5.

2. Virtual Brush Model
The main features of the Virtual Brush model
described in [16] and [17] are summarised here. Virtual
Brush allows the definition of a stroke‚Äôs appearance in an
interactive manner. With this brush model, the shape of
the brush bundle, the brush stem orientation, the three-

Proceedings of the Ninth International Conference on Information Visualisation (IV‚Äô05)
1550-6037/05 $20.00 ¬© 2005 IEEE

dimensional brush motion, and the individual ink
deposition process of each brush hairline are modelled in
a hierarchical structure with well defined object-oriented
operations and attributes. Virtual Brush includes three
models: the brush geometry model, the brush motion
dynamic model and the ink depositing model.

2.1. Brush Geometry Model
The physical properties of the stem and the hairlines
as well as the three-dimensional movement of the brush
are modelled to allow the synthesis of grey-level
calligraphic images with fine ink trails. Figure 1 shows a
brush bundle in normal state. The major parameters used
in this model are the radius R, length of brush bundle L
and number of hairs M.

where ktu and ktv are the scaling factors for the major
and minor radii; and bt is the spreading factor.

2.3. Ink Depositing Model
By varying the parameters that control the ink
absorption and ink deposition, realistic calligraphic
effects can be produced. In this model, the parameter gt
is used to model the ink depositing level. Another
parameter et known as the absorption variant is used to
model the effect when ink is not deposited by a particular
hair due to the motion of the brush.
The detailed explanation on the synthesis process for
generating the calligraphic characters based on these
three models can be found in [16] and [17].

3. Estimation of the Virtual Brush Model
Parameters

R
O

L
Hair hi

Figure 1 Brush Bundle Model

2.2. Brush Motion Dynamic Model
Aesthetic character images of different calligraphic
writing styles can be generated by first defining the
appropriate stroke trajectories using a mouse or a
digitising pen, followed by specifying the physical
parameters that influence the stroke appearance such as
brush pressure and orientation. The contact between the
brush hair bundle and the writing paper is modelled
using an elliptic ‚Äúfootprint‚Äù in which the principal axes
can be dynamically adjusted according to different
bending and brush turning control. The results are good
approximations to characters written by a real brush.

By specifying the parameters of the Virtual Brush
model summarised in Section 2, users can draw brush
stroke trajectories by using a digitising pen and
‚Äúpractise‚Äù calligraphy electronically. This facilitates the
synthesis of Chinese calligraphic writings to produce
various visual effects by the user. On the other hand,
given a real calligraphic image, a lot of work on stroke
manipulation is required by the user to determine the
Virtual Brush model parameters needed to specify that
particular character. As a result, an intelligent method is
required to automatically estimate the Virtual Brush
model parameters from the analysis of Chinese
calligraphic images such that those images can be easily
re-synthesised using the estimated Virtual Brush model
parameters with the capability to produce various effects.
The following sections describe our approach for
estimating the parameters of the Virtual Brush model.

3.1. Parameter Estimation for the Brush
Geometry Model
As mentioned in Section 2.1, the major parameters
used in the brush geometry model are the radius R,
length of brush bundle L and number of hairs M. A
default value can be used for modelling L since it is only
used in the relative sense as indicated by equation (1).
The estimation of the parameters for the radius of brush
stem R and the number of hairs M will be discussed in
the following sections.

Figure 2 Brush-Paper Intersection
Figure 2 shows the computation of brush-paper
intersection in Virtual Brush. The major parameters in
this model are the instantaneous positions of the brush tip
(Pt.x, Pt.y, Pt.z) and the ‚Äúfoot-print‚Äù (ut, vt, Zt) that is the
ellipse parameters of the brush at time t. The relationship
between the parameters in this model and those in the
Brush Geometry Model are defined in equation (1).
ut

R (1 

Pt .z u
) kt  bt
L

vt

R (1 

Pt .z v
)kt  bt
L

(1)

3.1.1. Estimating the Radius of Brush Stem
It is intuitive that the larger the radius of brush stem,
the larger is the width of the written stroke. In Figure 3,
the vertical line at the middle is the trajectory of the
stroke and the line segments are perpendicular to the
tangents at some points on the trajectory. The
perpendicular line segment with the largest width is also
indicated in Figure 3. We can first model the relationship
between the maximum width of the stroke and the radius
of brush stem from some training data. This model can

Proceedings of the Ninth International Conference on Information Visualisation (IV‚Äô05)
1550-6037/05 $20.00 ¬© 2005 IEEE

then be used to estimate the radius after determining the
maximum width of the stroke.
Perpendicular line with the
largest width

Lines perpendicular to
trajectory

Figure 3 Maximum width of a stroke
In this experiment, the relationship between the
radius of brush stem and the maximum width of the
strokes for the images was examined. A total of 1000
images were generated by using the Virtual Brush model
with various combinations of radius of brush stem and
number of hairlines. The range of the radius of brush
stem is from 5 units to 45 units; and the number of
hairlines ranges from 100 to 1000. The power model is
used for the estimation of the radius RÀÜ empirically
given the maximum width w according to equation (2):

RÀÜ = A wB

(2)

where A and B are the parameters to be determined.
After determining the maximum width w of each of the
strokes in the images, together with the value of radius of
brush stem R used in generating those images, the
parameters A and B from equation (2) were computed by
power regression with the ANOVA model.

of hairlines decreases, the mean distance between the
hairlines also increases. This leads to an increase in the
number of pixels without ink deposition, and thus the
variance of the pixel intensity.
The support region of each of the stroke was
examined to estimate the number of hairlines. It can be
obtained by eroding the outer-most layer so only the
pixels in the central region are retained to reduce the
effect by the spreading of the ink. When there are more
hairlines, the support region will be darker, and thus the
mean and variance of the intensity for those pixels inside
the support region will be lower. As a result, we
expected an inverse relationship between the number of
hairlines M and the mean intensity ¬µ; and similarly an
inverse relationship between the number of hairlines M
and the variance of intensity ƒ±¬≤. In order to model such
relationships, we used the functions ‚Äìlog(¬µ) and ‚Äìlog(ƒ±¬≤)
which are monotonic decreasing functions in ¬µ and ƒ±¬≤
respectively. The width of the stroke also provides some
indication about the number of hairlines. If the width of
the stroke is larger, it is expected that this stroke is
generated by brush with relatively more hairlines under
constant darkness. By considering this condition, in our
modelling for the number of hairlines, we multiplied the
stroke maximum width w with each function: ‚Äìlog(¬µ)
and ‚Äìlog(ƒ±¬≤) such that the resulting functions ‚Äìwlog(¬µ)
and ‚Äìwlog(ƒ±¬≤) satisfied the above condition. A linear
model can be used to estimate the number of hairlines as
shown in equation (3).

MÀÜ = ‚ÄìkH0wlog(¬µ) ‚Äì kH1wlog(ƒ±¬≤)+kH 2 , ¬µz 0 and ƒ±¬≤z 0 (3)
The weights kH0, kH1 and kH2 were found by mean
square fitting using the data obtained from more than
3000 images. It can be seen from equation (3) that the
surface used for fitting is a plane in the
(‚Äìwlog(¬µ), ‚Äìwlog(ƒ±¬≤), M) space. To analyse the goodness
of the fitting, the 3-D data points (‚Äìwlog(¬µ), ‚Äìwlog(ƒ±¬≤),
M) obtained from the images have been plotted in Figure
5 together with the plane used for fitting the data. It can
be observed that the plane fits the data well.

Figure 4 Radius Estimation of Strokes
The experimental data of radius versus maximum
width were plotted in Figure 4. In addition, the resulting
fitted curve after determining the parameters from the
power model given in equation (2) is also shown. From
the experiment, the correlation of regression is found to
be 0.9847, suggesting that there is a strong correlation
between the radius of the brush stem and the maximum
width of the stroke.
3.1.2. Estimating the Number of Hairlines Forming
the Brush Bundle
A stroke becomes darker when there are more
hairlines in the brush bundle. At the same time, under
constant number of hairlines, as the radius of the brush
stem increases, the roots of the hairlines in the brush
bundle become more distant. Furthermore, as the number

Figure 5 3-D data points (‚Äìwlog(¬µ), ‚Äìwlog(ƒ±¬≤), M)
and the fitted model for estimating the number
of hairlines forming the brush bundle

Proceedings of the Ninth International Conference on Information Visualisation (IV‚Äô05)
1550-6037/05 $20.00 ¬© 2005 IEEE

3.2. Parameter Estimation for the Brush Motion
Dynamic Model
As described in Section 2.2, the major parameters in
the brush motion dynamic model are the instantaneous
positions of the brush tip (Pt.x, Pt.y, Pt.z) and the ‚Äúfootprint‚Äù (ut, vt, Zt) which are the ellipse parameters of the
brush at time t. We will discuss how these parameters
can be estimated given a stroke region in the image in the
following sections.
3.2.1. Estimating the Planar Co-Ordinates of
Instantaneous Positions
The set of instantaneous positions (Pt.x, Pt.y) form a
trajectory that must be determined for each stroke given
its image region. The trajectory of a stroke can be
modelled using the skeleton of the stroke. Before
computing the skeleton, the support region should be
determined and processed with morphological filters to
remove holes and to smooth out the boundary. Thinning
can then be applied to the support region in the image to
obtain the skeleton. Both ends of the skeleton are
extended by extrapolation based on the slopes of those
skeleton points near each end point. The trajectory could
be obtained using the resulting extended skeleton to
estimate the planar coordinates of the brush tip.
3.2.2. Estimating the Vertical Distance between the
Root of Hair Bundle and the Paper
The set of heights Pt.z of the brush head along the
trajectory of the stroke is denoted as the Z Profile and it
needs to be estimated given an image region of a stroke.
To estimate the Z Profile, the thickness of the stroke
along the trajectory is used. The thickness along the
trajectory is computed as the length of the line segment
that is perpendicular to the trajectory and that intersects
with the boundary of the stroke. The Z Profile and the
radius together affect the width of a stroke. Various
combinations of the radius and Z Profile can produce
strokes with the same contour. For a specific stroke, if
we decrease the radius of brush stem, the height of brush
head could be adjusted by decreasing its value so that the
result remains unchanged. As a result, the absolute value
of the Z Profile is not important as long as the relative Z
Profile values of the points along the trajectory are
proportional to the actual width of the stroke. The height
of the brush bundle of the Z Profile ranges from hmax to
hmin, corresponding to the cases when the stroke has zero
width and maximum width respectively. The height of
brush head ht is estimated by equation (4) after obtaining
the width of the stroke at time t:
w
PÀÜt . z =ht = hmin + (hmax ‚Äì hmin)¬ß¬©1 ‚Äì w t ¬∑¬π
m

(4)

where wt is the width of stroke at instance of time t;
and wm is the maximum width of the stroke. Figure 6
shows a stroke with its ground truth as the bottom curve
and estimated Z Profile as the top curve. It can be seen
that the estimation is quite close to the ground truth.

Figure 6 A stroke with the ground truth and its
estimated Z Profile
3.2.3. Estimating the Footprint
The ‚Äúfoot-print‚Äù of the brush at time t can be
represented as an ellipse formed by the intersection
between the brush and the paper with parameters (ut, vt,
Zt) indicating the major radius, the minor radius, and the
degree of rotation of the ellipse. As described in [16] and
[17] , the default ratio between the major radius and the
minor radius is 1.2 to 0.7. However, at some special
locations such as the head and the tail of a stroke, some
ellipses with the default ratio between major and minor
radii fall outside the boundary. In this case, the minor
radius could be reduced so that the entire ellipse is
always within the boundary of the stroke. The scaling
factors ktu and ktv specifying the size of the ellipse can be
determined by considering the distance from the skeleton
to the boundary of the stroke. The degree of rotation of
each intersecting ellipse can be estimated as the
orientation normal to the trajectory.

3.3. Parameter Estimation for the Ink Deposition
Model
As described in Section 2.3, the major parameters in
the ink depositing model are the ink depositing level gt
and the absorption variant et. In this paper, we will
consider only the parameter for the ink depositing level
and leave the parameter for the absorption variant as
future work.
Higher ink depositing level results in more amount
of ink deposited to the paper, and thus the region of
contact is darker. The amount of ink deposited to the
paper at any time instance varies due to the writing
velocity and strength.
There is a strong correlation among the ink
depositing level, the darkness of the region, and the
number of hairlines. Moreover, the darkness of the
region depends on the mean intensity of that region. As a
result, the ink depositing level gt at instance of time t
could be modelled in equation (5).

gÀÜ t = kI0Pt + kI1M + kI2Pta + kI3PtM + kI4Ma + kI5,

(5)

where M is the number of hairlines; kI0, kI1, ‚Ä¶, kI5 are
the weights; a is the exponent; Pt is the mean intensity
along the line segment perpendicular to the tangent at the

Proceedings of the Ninth International Conference on Information Visualisation (IV‚Äô05)
1550-6037/05 $20.00 ¬© 2005 IEEE

instantaneous position of the brush tip at instance of time
t. Strokes with constant ink depositing level were
generated by the Virtual Brush model with different
number of hairlines. The mean intensity of the ink pixels
of each of the strokes was then computed from the
images. After performing least square fitting, the values
of the weights were obtained.
Figure 7 shows the comparison between the ground
truth data and the estimated values for the brush models
with 100 hairlines, 200 hairlines, 500 hairlines and 1000
hairlines. The solid lines represent the ground truth data
and the dashed lines correspond to the estimated curve. It
can be seen from Figure 7 that the estimated curve is
very close to the ground truth data. The mean squared
error of the estimation is 0.006512 that is quite small.

the synthesised result after performing the automatic
image analysis are shown. The similar outlook and ink
concentration at the centre of the images in Figure 8
suggest that our proposed modelling is quite good for
reproducing realistic calligraphic strokes.

4.2. Character images
Chinese characters are often composed of more than
one stroke. Therefore, the analysis for single stroke
needs to be extended to handle multiple strokes. Since
character segmentation is not our main focus in this
paper, we made use of the manually segmented multiplestroke character images. For each stroke region, we
applied our estimation algorithm to obtain the brush
model parameters and then use the resulting estimated
parameters to synthesise the images. Figure 9 shows two
examples of the original multiple-stroke character
images and the corresponding synthesised results.

(a)
Clerical
style

Figure 7 Comparison between the ground truth
and the estimated values of ink depositing
levels under different numbers of hairlines
(b)
Seal
style

Original Character
Image
(a)

(b)

Figure 8 Two examples of real calligraphic
strokes images and the corresponding
synthesised images using the automatically
estimated virtual brush parameters

4. Results and Discussions
4.1. Real Stroke Images
In this section, real digitalised calligraphic images
are used as the input for synthesis. The ink should be
segmented from the background paper to identify the
regions of interest before the stroke image regions can be
processed. We use the global thresholding approach [18]
to determine the threshold for distinguishing between the
ink deposited and the texture of the background paper. In
Figure 8, two examples of digitalised original image and

Synthesised Image

Figure 9 Examples of character images in
clerical and seal styles and the corresponding
synthesised images using the automatically
estimated virtual brush parameters
It can be seen in Figure 9 that the outlooks of the
characters are maintained. The sizes of the characters are
also similar to the original ones. For each character, the
darkness of the synthesised character is close to the
original one which shows that the estimation of number
of hairlines is satisfactory. For each stroke, the outlook,
length and thickness resemble the original one. Strokes
in different styles such as drop, vertical and horizontal
could all be synthesised well. Most of the composite
strokes, that are the strokes composed of two or more
simple strokes, could also be synthesised. For strokes
with variation in thickness in dispraised instances of
writing, the corresponding changes in thickness could
also be reflected in the synthesised strokes.

Proceedings of the Ninth International Conference on Information Visualisation (IV‚Äô05)
1550-6037/05 $20.00 ¬© 2005 IEEE

In Figure 9(a), it can be seen that there is a slight
variation in terms of the stroke thickness between the
original image and the synthesised image. This can be
improved in the future by refining the estimation of the
parameters in the brush geometry model. It can be seen
in Figure 9(b) that some ink spreading effects due to the
motion of the brush at the end of the stroke in the middle
are not well preserved and we will perform more analysis
on ink spreading as future work.

[2]

[3]

5. Conclusions and Future Work

[4]

In this paper, we proposed a methodology to analyse
Chinese calligraphic images for automatically estimating
the set of 3-D geometric as well as the dynamic writing
parameters such as the properties of the brush hair and
the variations of ink deposition along the stroke
trajectory. By extracting features from each stroke, our
approach estimates the major parameters of the three
models in Virtual Brush: (a) the brush geometry model
that consists of the radius of brush stem and the number
of hairlines forming the brush bundle; (b) the brush
motion dynamic model that consists of the trajectory, the
Z Profile and the footprint; and (c) the ink depositing
model that consists of the ink depositing level.
After the analysis, the parameters of the Virtual
Brush model could be automatically determined from
digitalised Chinese calligraphic images such that a
vector-based representation of each image could be
obtained. The synthesis-after-analysis results for the
characters were shown. The synthesised strokes have
similar outlook to the original ones. This shows the
effectiveness of our approach. With our approach, the
amount of work done by the user for stroke manipulation
is largely reduced in determining the brush model
parameters for the raw image of a specific character.
As future work, we will consider more variations by
analysing the ink spreading effects and the properties of
the writing papers such that the synthesised images can
be further improved aesthetically after the automatic
analysis. Besides, the segmentation of the strokes from a
character is done manually in our current approach. We
will work on the stroke segmentation issue so that the
characters could be automatically analysed and
synthesised without the need of manual segmentation
such that the amount of work done for stroke
manipulation by the user could be further reduced.

[5]

Acknowledgements

[17]

The work described in this paper was supported by a
grant from City University of Hong Kong (Project No.
7001614).

[18]

[6]

[7]

[8]

[9]

[10]

[11]
[12]
[13]

[14]

[15]
[16]

[19]

References
[1]

Chan K. M., Chow K. P. and Lo W. M. ‚ÄúJACM ‚Äì Just
Another Chinese Metafont‚Äù. Proceedings of 1988
International Conference on Computer Proceeding of

[20]

Proceedings of the Ninth International Conference on Information Visualisation (IV‚Äô05)
1550-6037/05 $20.00 ¬© 2005 IEEE

Chinese and Oriental Languages, September 1988. pp.
311-5.
Zhang X. ‚ÄúHigh-Precision Small-Volume Brush-Written
Chinese Characters with the Pattern Synthesis of
Hierarchical Synthesis by Analysis‚Äù. Proceedings of
1990 International Conference on Computer Processing
of Chinese and Oriental Languages, 266-271, April
1990.
Liao C. W and Huang J. S. ‚ÄúFont Generation by BetaSpline Curve‚Äù. Computer and Graphics 1991; 15(4):527534.
Pavlidis Theo. Algorithms for Graphics and Image
Processing. Computer Science Press. 1982.
Chang K. Y. and Tang G. Y. ‚ÄúA Shrinking Method for
Chinese Characters Generation Using Topology
Relation‚Äù. Computer Processing of Chinese Oriental
Languages 1992; 6(2).
Tong J. L. and Shu W. H. ‚ÄúAn Approach to Stroke
Extraction and Radical Classification of Hand-written
Chinese Characters‚Äù. Proceedings of 1988 International
Conference on Computer Processing of Chinese and
Oriental Languages, 104-107, September 1988.
Chen L. H. ‚ÄúA New Approach for Hand-written
Character Stroke Extraction‚Äù. Computer Processing of
Chinese and Oriental Languages 1992; 6(1):1-17.
Ip H. H. S., Wong H. T. F. and Mong F. Y. ‚ÄúFractal
Coding of Chinese Scaleable Calligraphic Fonts‚Äù.
Computers and Graphics 1994; 18:343-51.
Ip H. H. S., Wong H. T. F. and Mong F. Y.
‚ÄúRepresenting Oriental Hand-written Scripts Using
Fractals‚Äù. Computer Processing of Oriental Languages
1996; 10:49-64.
Gu Q. L., Suen C. Y., Bui T.D. and Li Z. C.
‚ÄúMathematical Methods for Font Generation and Shape
Design of Characters‚Äù. Computer Processing of Chinese
and Oriental Languages, 5(3, 4), November 1991.
Rogers D. F. and Adams J. A. Mathematical Elements
for Computer Graphics. McGraw-Hill. 1990.
Whitted T. ‚ÄúAnti-Aliased Line Drawing Using Brush
Extrusion‚Äù. Computer Graphics 1983; 17:151-6.
Posch K. C. and Fellner W. D. ‚ÄúThe Circle-Brush
Algorithm‚Äù. ACM Transactions on Graphics 1989;
8(1):1-24.
Fishkin K. P. and Barsky B. A. ‚ÄúAlgorithm for Brush
Movement in Paint Systems‚Äù. Graphics Interface‚Äô84
Proceedings, 1984. pp. 9-16.
Strassmann S. ‚ÄúHairy Brushes‚Äù. Computer Graphics
1986; 20:225-32.
Ip H. H. S. and Wong H. T. F. ‚ÄúCalligraphic Character
Synthesis Using a Brush Model‚Äù. Proceedings of
CGI‚Äô97, Computer Graphics International Conference,
Hasselt-Diepenbeek, Belgium, 13-21, June 23-27, 1997.
Ip H. H. S. and Wong H. T. F. ‚ÄúVirtual Brush: A ModelBased Synthesis of Chinese Calligraphy‚Äù. Computers
and Graphics 2000; 24:99-113.
Gonzalez Rafael C. and Woods, Richard E. Digital
Image Processing, Prentice Hall Inc, 2nd Ed., 2001.
Mi X., Tang M. and Dong J. ‚ÄúDroplet: A Virtual Brush
Model to Simulate Chinese Calligraphy and Painting‚Äù.
Journal of Computer Science and Technology 2004;
19(3):393-404.
Yu J. and Peng Q. ‚ÄúRealistic Synthesis of cao shu of
Chinese Calligraphy‚Äù. Computers and Graphics 2005;
29:145-153.

