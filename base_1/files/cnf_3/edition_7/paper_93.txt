MAPVIS: A Map-Projection Based Tool for Visualizing Scalar and Vectorial
Information Lying on Spheroidal Surfaces
Wafa Rekik

Dominique B´er´eziat

S´everine Dubuisson

Universit´e Pierre et Marie Curie
Laboratoire d’Informatique de Paris 6
8, rue du Capitaine Scott, 75015 Paris, France
E-mail: {rekik,bereziat,dubuisson}@anp.lip6.fr
Abstract
In this article, we present a novel fast algorithm dedicated to the visualization of scalar and vectorial information lying on elliptical surfaces. As the geometry of the
data is simple and not relevant, and inside structures are
meaningless, standard visualization methods appear to be
not well adapted to our context. Our algorithm is based on
map projections, good candidates to unroll elliptical surface around a region of interest, without being computationally prohibitive. It has the merit to project, on a 2D
cartographic reference, different views of, scalar, as well as,
vectorial 3D information lying on the surface. We display
results for synthetic and cell wall simulations data.

an elliptical surface on which lies interesting information.
Consequently, we focus on mapping relevant information
on a 2D reference around a region of interest. For this sake,
we use a suitable map projection to unroll the spheroid surface and the information that lie on it.
In section 2, we ﬁrst present a brief survey of data visualization techniques. These methods, mainly developed for the
sake of volume visualization do not appear to be adapted
to our context of study. We then describe, in section 3, our
novel fast-running algorithm based on suitable map projection. We make the distinction between scalar and vectorial
information lying on the spheroidal surface and we evoke
an interpolation method required by our algorithm. Finally,
we give some results in section 4.

2. State of the art
1. Introduction
Data visualization is of growing interest in diverse range
of computer vision applications. Computer graphics programmers widely investigated data-visualization techniques
in order to improve the understanding of the underlying information. Over the past few years, one of the most fastgrowing areas in information visualization is volume visualization. The purpose is to create high-quality images from
scalar and vector datasets deﬁned on multi-dimensional
grids. It’s the case for MRI brain imaging, where visualization of brain anatomy plays an important role for interpretation of functional brain data. Similarly, in cellular
imaging, visualization of 3D reconstructed data is an essential issue to analyze the dynamic behavior of structures of
interest. We are mainly interested on the visualization of
various information lying on spheroid surfaces. Standard
visualization techniques, care more about geometrical aspects, like volume rendering and surface ﬁtting, than about
information mapping (texture, vector ﬁeld...). However, in
our case, the geometry of the problem is well determined :

Currently, various computer vision applications require
advanced and accurate data visualization techniques, since
they play an important role in the understanding of the underlying information. This is the case in computer vision,
robotics, medical imaging, like MRI brain or cellular imaging. Therefore, a fast growing number of techniques is dedicated for this sake, and mainly for volume visualization.
A general survey of volume visualization algorithms is proposed in [2], besides, an evaluation and comparison of usual
methods can be found in Meissner et al [13]. We may distinguish two fundamental volume visualization algorithms
: direct volume rendering algorithms and surface-ﬁtting algorithms.
• Volume rendering is performed using the volumetric 3D data as such and it typically produces realisticlooking surface images. It has been studied extensively
with many different approaches, the most efﬁcient
software-based technique is the shear-warp factorization by Lacroute and Levoy [8]. The technique can

Proceedings of the Ninth International Conference on Information Visualisation (IV’05)
1550-6037/05 $20.00 © 2005 IEEE

be adapted to exploit 2D-texturing hardware. Moreover, common basic techniques are ray-casting, splatting and hardware-based 3D texture mapping. Recent visualization algorithms provide advanced shading techniques such as lighting [11], shadows [1],
high quality post-classiﬁcation using pre-integration
technique [3], gradient magnitude modulation [15] or
higher-dimensional transfer functions [7].
• Surface-ﬁtting algorithms approach (see [4]) includes
contour-connecting, marching cubes, marching tetrahedral, dividing cubes, and others. These algorithms
(sometimes called feature-extraction or iso-surfacing)
typically ﬁt, usually planar, surface primitives such as
polygons or patches to constant-value contour surfaces
in volumetric datasets. Despite several existing possibilities for surface representations, by far the most
common approach is to employ triangle meshes.
Both of these methods mainly emphasize on the volume geometrical aspects as they aim at providing an accurate
three dimensional model of the volume of interest. They are
more dedicated to create realistic high-quality images with
respect to shapes, geometric constraints, lightening conditions than to display information lying on each voxel. Moreover, surface-based rendering methods require segmentation of the volume of interest to deﬁne the surface being
visualized. Volume rendering can be applied to the unprocessed volumetric images so that volume element (voxel)
opacity depends on the voxel values. However, preprocessing steps, such as segmentation and tissue classiﬁcation, can
be very useful. In our particular context, the volumetric information is not relevant as we deal with elliptic objects.
We are merely interested by the information lying on the
surface, inside structures are not very meaningful. Therefore, last standard methods seem not to be adapted to our
problem. Besides, segmentation, classiﬁcation and several
processing techniques required by these algorithms made
them quite time and resource consuming. Consequently, we
think of a fast original algorithm dedicated to objects of an
elliptic, mainly spheroid surface. The purpose is to create
a visualization tool which improve the recovery of structures lying on the spheroid surface. The observation of vector data sets deﬁned on a three dimensional grid is useless
since these structures are of weak thickness. Therefore, our
algorithm projects the surface around a region or structure
of interest presenting different projective views of the surface. That’s why map projection is well adapted to the visualization tool. Furthermore, this tool can be applied easily
for the visualization of different and complex information
lying on the surface like texture, optic ﬂow motion ﬁeld,
multimodal data, ... Eventually, this approach has the merit
to make use of classic two dimensional displaying tools in
order to visualize three dimensional sets of data. That leads

to a simple visualization technique fast-running on a standard PC hardware, unlike the standard methods, which are
doubtless more resource consuming.

3. MAPVIS : Map projection based Visualization tool
As we aim at observing structures of small thickness, we
need to locally unroll the surface around the object of interest. Since the enclosing surface is elliptical, map projections seem to be good candidates to project locally the
3D surface. Moreover, map projection improve the visualization effect, as deformations resulting from this kind of
projection increase the recovery and the understanding on
the visualized area. In fact, unlike perspective projection,
this geographical does not map uniformly each point of the
3D surface, as shown on the ﬁgure 1.

S

P

Perspective Projection

S

P

Map projection

Figure 1. Comparison of projective sights
between perspective and map projection
method while considering the same view.

3.1. Map projections
More than a hundred map projections are available in
the literature: we meanwhile may make the distinction between secants and tangent ones (refer to [14] for an exhaustive survey). The tangent map projections are divided into
three categories, depending on the choice of the surface on
which the Earth surface will be unrolled (ﬁgure 2): conical,
cylindrical and azimuthal.
The ﬁrst two are purely geometrical projections of the
Earth upon a tangent cone or cylinder. The parallel on contact with the surface is mapped without any deformation
and corresponds to the line of zero distortion on the map.
Azimuthal projections project onto a plane tangent to the
Earth’s surface at a speciﬁed point. Distances measured
from the center are true, and distortions of other properties increases away from this center point. In this case the

Proceedings of the Ninth International Conference on Information Visualisation (IV’05)
1550-6037/05 $20.00 © 2005 IEEE

Conversion between computed cartesian coordinates and
pixel coordinates, as well as geometrical distortions introduced by this projection generate important number of
non-initialized points on the mapped surfaces. That’s why
we used an interpolation method in order to estimate values
of missing points.
conical

cylindrical

planar

Figure 2. Three kinds of secant map projections.

point of contact coincides with the point of zero-distortion
on the map, that is very interesting if we need to minimize
distortions around a speciﬁc region of interest. Since our
purpose is to recover structures of weak thickness lying on
the surface, we opt for the azimuthal equal area projection.
The latter maps locally the region of interest and limits deformations around. Besides, varying the projection origin
allows to display the surface from different scopes or projection views.
By the mean of this projection, we can visualize various
and complex kind of information lying on the spherical surface. On one hand, scalar information like gray values of
luminosity image (or texture) or gradient or magnitude or
divergence images can be naturally and directly displayed.
The corresponding algorithm is described in the section 3.2.
On the other hand, vectorial information like motion vector
ﬁelds can also be visualized with the same kind of technique, as explained in section 3.4. An interesting issue of
the method is to combine two kind of algorithms. In this
case, we ﬁrst project the region of interest on a cartographic
reference, then we display the motion vector ﬁeld in each
mapped point.

3.2. Scalar-data projection
We may sum up projection stages by the following
scheme (see [6, 10] for a complete mathematical analyze) :
(λ, ϕ) −→ (λl , ϕl ) −→ (r, θ) −→ (x, y)
The ﬁrst passage consist on a geographic coordinate
transformation. It is deﬁned by the passage from the couple
of geographic coordinates, i.e longitude and latitude (λ, ϕ)
with reference to the north pole and equator, to transformed
ones (λl , ϕl ), with reference to the center of projection,
which could be considered as a mathematics pole of a great
circle oblique to the equator. The second and the third
passages are the actual projection stages, they transform
geographical coordinates into polar then cartesian ones
in the projection plan. The last three transformations are
detailed in a preceding research work [12].

3.3. Missing-value interpolation
Our projection technique shows a considerable number
of non-initialized points in the mapped surfaces. Indeed,
when a point is mapped to another by a transform (that is the
case when we make the projection), it is generally mapped
to a non-grid position. Therefore, interpolation is required
to evaluate the image intensity at the mapped position. To
overcome this problem, we implement a bilinear interpolation of initialized points, using three closer neighbors pixelvalue forming a convex envelop for this point. A great variety of methods can be found in the literature (see [9] for a
complete review), we have chosen this interpolation scheme
as it is, relatively, easy to implement and because the image
intensity is piecewise constant (brightness function is bilinear in the neighborhood of a point) with jump-mid-way between grid positions. For separated bilinear interpolation,
the values of both direct neighbors are weighted by their
distance to the opposite point of interpolation. The 1-D interpolator kernel h is deﬁned by:

 1−x
h(x) =
1+x

0

if
x ∈ [0, 1]
if
x ∈ [−1, 0[
otherwise

3.4. Vectorial-data projection
In this case, we often deal with a composed three dimensional image. In fact, each component of the vector ﬁeld is
described by a three dimensional scalar image. If we take
the example of a motion vector ﬁeld, each component rep→
−
resents a direction of space. Let Ω be a vector ﬁeld that
→
−
we manage to project into a 2D composed vector. Ω is
→
−
described by three vectors : u(i, j, k) for the direction I ,
→
−
→
−
v(i, j, k) for J and w(i, j, k) for K . Our objective is to
−−−→
estimate the projected motion vector ﬁeld Ωproj in a given
angle of sight. The latter vector ﬁeld is deﬁned by a bidirectional and bi-dimensional vector ﬁeld uproj (i , j ) for
→
−
→
−
the direction I and vproj (i , j ) for J .
Firstly, we select a region of interest lying on the 3D surface. Secondly, we compute the position of projection origin C that coincides with the center of the selected 3D
block. Then, in each point M (x, y, z) on the close neighborhood of the origin C, is localized a tri-directional three

Proceedings of the Ninth International Conference on Information Visualisation (IV’05)
1550-6037/05 $20.00 © 2005 IEEE

→
−
dimensional motion vector, Ω . In order to compute the cor→
−
responding Ω , we proceed as follows :

P

x

1. calculate the position of the point M (x , y , z ) de−−−→ −
→
ﬁned by the equality : M M = Ω .

B
x

2. compute the azimuthal projection of both M
and M , respectively Mproj (xproj , yproj ) and
M proj (xproj , yproj ), according to the origin C.

(λ=π, ϕ=0)

xF
λ

(λ=π/9, ϕ =0)

−−−→ −−−−−−−−−→
3. compute Ωproj = Mproj M proj .
We are, especially, interested in apparent movement of
structures evolving on 3D surface, that’s why we have
mainly estimated the optical ﬂow ﬁeld. We have opted for
Horn and Schunck formulation extended to a three dimensional context [5].

4. Experimentation and results
4.1. Experimental context
In a ﬁrst step, we designed synthetic images to validate
our algorithms, i.e to visualize different kind of information
lying on spherical surfaces. Then we carry out several experiments on our biological data. We dispose of different
types of acquisitions of cell wall simulations. Camera and
microscope observe light signals emitted by some ﬂuorescent markers injected on the cell wall surface modeled by
ellipsoid vesicles. Acquisitions show lipid exterior phases,
that we call rafts, moving on these surfaces. In an enclosing research work, we attempt to carry out a three dimensional reconstruction of those vesicles in order to analyze
the functional role of rafts. MAPVIS is an important issue
for the validation and the veriﬁcation of the implemented
algorithms for 3D reconstruction. First we display results
on synthetic images then on actual cell wall simulations.

4.2. Visualization results
In order to illustrate the results of our algorithm, we
choose a simple 3D image. On the front sight of the surface, we put a circular stain of small diameter. The center
of that stain is localized on the couples of geographic coordinate, longitude : λf = 20 and latitude ϕf = 0. We
put also on the back side a darker stain whom center has the
geographic coordinates : λb = π, ϕb = 0. The designed
sphere is represented schematically by the ﬁgure 3.
Our 3D image is a structure of data organized in a certain
number of equal-sized plans. Indeed, they have all the same
number of lines and columns. Therefore, it is possible to visualize the sphere as a sequence of 2D plans. However, this

Figure 3. A non textured sphere with a couple of homogeneous stains centered respectively on geographic coordinates F (λf = 20,
ϕf = 0) and B(λb = π, ϕb = 0).

solution is insufﬁcient to visualize structures of small thickness lying on the spheroidal surface. That’s why we manage to the last sphere with our method. An equatorial map
projection (with reference to the origin of geographic coordinates O(λf = 0, ϕf = 0)) is sufﬁcient to show relevant
data lying in front sight of the sphere. Besides, a projection
on B(λb = π, ϕb = 0) allows to recover the stain lying
of the back sight of the sphere. Furthermore, it is possible
to choose a projection origin in jump-mid way between the
two stains center since this position has the merit to visualize the partially the two stains in the same projection sight.
The geographic north pole, P (λp = 0, ϕf = π), is suitable
origin for this sake. We present in ﬁgure 4, a visualization of the sphere with the default method (as a sequence
of 2D plans), then three map projection with reference to
respectively O(λf = 0, ϕf = 0) B(λb = π, ϕb = 0) and
P (λp = 0, ϕf = π).
We notice that MAPVIS results are more meaningful
as they allow recovery of small structures lying on the
spheroidal surface. Besides, unlike standard visualization
techniques, projection view only depends on the choice
of the origin of the map projection. So a modiﬁcation of
the data view requires only slight additional computation
effort. In the ﬁgure 5, we present a comparison between
a perspective view of our set vesicle+raft and a MAPVIS
visualization. We can see that the latter displays better the
raft shape.
Eventually, we re-consider the sphere described in the
ﬁgure 3, we vary the geographic position of both stain centers F and B by δλ = 2. We manage to display projected
3D optic ﬂow velocity ﬁelds between the two spheres. In
ﬁgure 6, we present the same three views as above for each
sphere for the projected textures and velocity ﬁelds.

Proceedings of the Ninth International Conference on Information Visualisation (IV’05)
1550-6037/05 $20.00 © 2005 IEEE

(a) Default projection
visualization tool.

(c) Map projection with reference to the origin
B(λb = π, ϕb =
0)

(b) Map projection with reference to the origin
O(λ = 0, ϕ =
0)

(d) Map projection with reference to the north
pole P (λp = 0,
ϕb = pi)

Figure 4. Comparison between the incomplete default visualization tool and MAPVIS
offering different views of objects lying on the
considered sphere.

Moreover, we consider the well known urban taxi sequence usually used to test 2D optical ﬂow computation.
In order to display results for textured 3D data, we map
textures of this sequence, into 3D spheres with suitable
parameters. Then, we compute 3D optical ﬂow between
the designed spheres and we project both textures and velocity ﬁelds into 2D cartographic references. Hence we
can visualize movement of the white taxi toward the right
road. We present in the ﬁgure 7, two consecutive projected
frames.

5. Conclusion
In this paper, we have presented a novel fast algorithm,
baptized MAPVIS, and dedicated to the visualization of
scalar and vectorial information lying on elliptical surfaces.
This algorithm is based on a speciﬁc map projection : the
azimuthal equal area projection, having the merit to un-

Figure 5. From the left to the right: a perspective view of the vesicle surface + raft, then a
map projection of the latter set with reference
to the center of the white frame on the left,
which coincides with center of the raft. In order to highlight the latter, we applied a local
histogram stretching.

roll locally the elliptical surface with minimum deformation around a region of interest. The last property improve
the recovery of small structures lying on the surface unlike
perspective projection. The latter maps uniformly all points
on the surface. Besides, in our speciﬁc context of study,
geometrical information is not relevant as it is well determined, that’s why standard visualization methods (volume
rendering and surface ﬁtting) appear to be not adapted. Furthermore, MAPVIS doesn’t require prior segmentation of
the surface and displays quickly different views of the region of interest. It makes use of standard 2D visualization
tool to display complex information (texture, motion vector
ﬁeld, ...).
Finally, to increase the accuracy of map projection computation, we plan to consider, in a further step, the surface of vesicle as ellipsoidal, instead of spherical. We will
recover 3D conical contours instead of spherical contours
while computing the surface parameters (eccentricity, coordinates of focuses,...). Moreover, implementing a sophisticated interpolation method could signiﬁcantly improve the
displaying aspects.

References
[1] U. Behrens and R. Ratering. Adding shadows to a texturebased volume renderer. In Proceedings of the IEEE, ACM
SIGGRAPH, pages 39–46, 1998.
[2] T. Elvins. A survey of algorithms for volume visualization.
Computer Graphics, 26:194–201, 1992.
[3] K. Engel, M. Krauss, and T. Ertl. High-quality preintegrated volume rendering using hardware-accelerated
pixel shading.
[4] B. Fischl, A. Liu, and A. Dale. Automated manifold surgery:
constructing geometrically accurate and topologically correct models of the human cerebral cortex. IEEE Trans. Med.
Imag., 20:70–80, 2001.

Proceedings of the Ninth International Conference on Information Visualisation (IV’05)
1550-6037/05 $20.00 © 2005 IEEE

[5] B. Horn and B. Schunck. Determining optical ﬂow. AI,
17(1-3):185–203, August 1981.
[6] I. Jonathan. Datums and map projections for remote sensing, GIS, and surveying. Latheronwheel, caithness: Whittles
Pub. Boca Raton: CRc press, c200.
[7] J. Kniss, G. Kindelmann, and C. Hansen. Interactive volume
rendering using multi-dimensional transfer functions and direct manipulation widgets. In Proceedings of the IEEE Visualization, pages 255–262, 2001.
[8] P. Lacroute and M. Levoy. Fast volume rendering using a
shear-warp factorization of the viewing transformation. In
Proceedings of the Computer Graphics, ACM SIGGRAPH,
pages 451–458, Orlando, Florida, July 1994.
[9] T. Lehmann, C. Gnner, and K. Spitzer. Survey: interpolation
methods in medical image processing. IEEE Transactions
on Medical Imaging, 18(11):1049–1065, november 1999.
[10] D. Maling. Coordinate Systems And Map Projections. Pergamon Press, 2nd edition.
[11] M. Meiner, U. Hoffmann, and W. Straer. Enabling classiﬁcation and shading for 3d texture mapping based volume
rendering using opengl and extensions. In Proceedings of
the IEEE Visualization’99, pages 207–214, 1999.
[12] W. Rekik, D. B´er´eziat, and S. Dubuisson. Tracking of nonrigid structures evolving on 3d surfaces by compensating
perspective view deformations. In In the proceedings of
IASTED, SIP2004, Honolulu, Hawaii, USA, August, 15-17
2004.
[13] C. Rezk-Salama, K. Engel, M. Bauer, and T. Ertl. Interactive volume rendering on standard pc graphics hardware using multi-textures and multi-stage rasterization.
In S. Spencer, editor, Proceedings of the ACM SIGGRAPH/EUROGRAPHICS, pages 109–118, 2000.
[14] J. Snyder and P. Voxland. An Album Of Map Projections.
U.S. Geological Survey and University of Minnesota, 1994.
[15] A. Van Gelder and K. Kim. Direct volume rendering with
shading via three-dimensional textures. In Proceedings of
the Symposium on Volume Visualization, pages 23–30, 1996.

(a) Front view of the
ﬁrst sphere (equatorial projection)

(b) Front view of
the second sphere
(the stain center was
varied by δλ = 2 )

(c) azimuthal view of
the ﬁrst sphere

(d) azimuthal view of
the second sphere

(e) back view of the
ﬁrst sphere

(f) back view of the
second sphere

Figure 6. Visualization of texture and optical
computed between two spheres by the means
of MAPVIS.

Figure 7. Visualization of texture and optical
ﬂow for two consecutive frames from the sequence taxi mapped on spheroid surfaces by
the means of MAPVIS.

Proceedings of the Ninth International Conference on Information Visualisation (IV’05)
1550-6037/05 $20.00 © 2005 IEEE

