The effect that touching a Projection Augmented model has on Object-Presence
Emily Bennett, Brett Stevens
Department of Information Systems and Computer Applications,
University of Portsmouth, UK
Emily.Bennett@port.ac.uk, Brett.Stevens@port.ac.uk
Abstract
A Projection Augmented Model (PA model) is a type of
projection based haptic Augmented Reality display. It
consists of a real physical model, onto which a computer
image is projected to create a realistic looking object.
Users can physically touch the surface of a PA model
with their bare hands, which has clear experiential value
for the types of applications for which they are being
developed. However, the majority of PA models are
front-projected and do not provide haptic feedback for
material properties (e.g. temperature and physical
texture), which suggests a user’s sense of objectpresence will be reduced when this type of PA model is
touched. (Object-presence measures the subjective
feeling that the object the PA model represents exists in a
person’s environment, as opposed to a white physical
model and a projected computer image.) Alternatively, if
people consider PA models to be essentially computer
generated objects (i.e. it is the projected image that gives
the ‘dummy’ physical model meaning), then the act of
being able to touch computer generated information may
increase object-presence. The empirical investigation
reported in this paper found that object-presence was
lower when this type of PA model was touched. The
implications these results have for both PA models and
other types of displays, are discussed.

1. Introduction

consists of a physical three-dimensional model, onto
which a computer image is projected to create a realistic
looking object [1]. For example, the PA model shown in
figure 1 consists of smooth white plaster models of
various objects that are commonly found in a garden
shed [2]. The image projected onto these objects
provides color and visual texture, which makes them
appear to be made from different materials.
PA models naturally support haptic feedback. This is
because PA models include physical objects, which users
can touch with their bare hands. PA models therefore
provide whole-hand haptic feedback for geometric
properties, such as size and shape, without the need to
wear any additional equipment.
Object-presence is the subjective feeling a particular
object exists in a person’s environment, when that object
does not [1]. PA models use real physical objects;
therefore it could be argued that PA models do actually
exist in a person’s environment. However, objectpresence is the sense that the specific object that the PA
model is representing exists, as opposed to a white
physical model and a projected computer image.
The empirical investigation reported in this paper,
focuses on the most common type of PA model; a frontprojected PA model that does not provide haptic
feedback for material properties. This study investigates
the effect that touching this type of PA model has on
object-presence. Note: when this paper refers to ‘touch’
or ‘haptic’ it is actually referring to the situation when a
PA model is simultaneously viewed and touched. The
implications that the results have for both PA model
applications, and other types of displays, are also
discussed. However, before discussing the main study, it
is first necessary to review why this type of PA model is
important.

2. Projection Augmented models

Figure 1. PA model with projection on (main), PA
model with projection off (inset) [2].
A Projection Augmented model (PA model) is a type of
projection based haptic Augmented Reality display. It
Figure 2. Front-projected PA model setup

Proceedings of the Ninth International Conference on Information Visualisation (IV’05)
1550-6037/05 $20.00 © 2005 IEEE

To create a PA model, the image that is normally viewed
on a PC monitor is projected directly onto a white
physical model (figure 2). To register the image onto the
physical model, the projector and the physical model
must be carefully aligned. Every side of a PA model can
be illuminated by using multiple projectors, which allows
the PA model to be viewed from any direction.
Design is a key application area for which PA
models have been developed; examples include cars [3],
architecture [4] and mobile telephones [5]. Visualisation
is another key application area, for example geographical
visualization [6][7] and visualisation of complex data
sets, such as brain, seismic velocity and air temperature
data [8].
Regardless of the application, PA models can be
classified in two ways. Firstly, they can be classified by
the direction that the image is projected onto the model.
PA models can either be front-projected (e.g. figure 1 and
figure 2), or if a semi-transparent physical model is used,
they can be back-projected (e.g. [6]). The second way
that PA models can be classified is based on the level of
haptic feedback they provide for material properties, such
as temperature and physical texture. Although PA
models use physical objects that obviously have material
properties of their own, this classification is referring to
the material properties of the simulation. For example, if
a PA model that represents a brick was given a physically
rough surface, then it would provide haptic feedback for
material properties, whereas if it had a smooth surface, it
would not.
To summarize, there are four types of PA model:
front-projected with haptic feedback for material
properties; front-projected without haptic feedback for
material properties; back-projected with haptic feedback
for material properties; and back-projected without haptic
feedback for material properties.
The majority of the technology has been developed
for front-projected PA models that do not provide haptic
feedback for material properties. Dynamic visual effects
can be simulated for this type of PA model, for example,
different lighting conditions and apparent motion (see [9]
for a review). Recently, a system has been developed
that adjusts the projected image to make it appear correct
when projected onto a coloured object, hence removing
the requirement for a white physical object to be used
[10].
Moreover, technology has been developed that
enables this type of PA model to change their physical
shape e.g. [7] [11] [12].
Technology has also been developed that semiautomates the construction of front-projected PA models
that do not provide haptic feedback for material
properties. For example, technology that semi-automates
the process of aligning the projected image and the
physical model [4][13][14]. It is possible to combine this
technology with rapid prototyping techniques to semiautomate the whole construction procedure. This only
works if the projected image is a 3D computer model, as
opposed to a 2D image such as a .jpeg. In order to use a
3D computer model as the projected image, the physical

model must be exactly the same shape. Providing you
have either one, automated processes can be used to
obtain the other. If you have the physical model, the
equivalent 3D computer model can be obtained by using
3D scanning techniques. Textures and colours can then
be added to the 3D computer model, before being
projected back onto the physical model, for example [4].
Conversely, if you have a 3D computer model, the
equivalent physical model can be automatically obtained
using rapid prototyping techniques, which the 3D
computer model can then be projected onto, for example
[3].
Despite the capabilities of this type of PA model,
they have some limitations. Firstly, PA models that do
not provide haptic feedback for material properties, have
a mismatch between the visual and haptic feedback for
these properties. For example, the visual (projected)
texture does not match the haptic texture. A further
problem is that when a person touches a front-projected
PA model, the projected image appears on the back of
their hand, and their hand casts a shadow onto the
physical model.

3. Aims of the investigation
PA models are an interesting combination of both real
and computer generated objects; it is unclear whether
people will treat a PA model as a computer-generated
object or as a real object. The attitude that the user
adopts is likely to determine whether touching a PA
model increases or decreases their sense of objectpresence, in comparison to when they perceive it through
vision alone. This research focuses on the most common
type of PA model, i.e. front-projected PA models, which
do not provide haptic feedback for material properties
(section 2), which will now be referred to using the
shortened term ‘PA model’.
If people treat a PA model as if it is a real object, it
means that they treat a PA model as if it is the actual
object that it represents, as opposed to a white model and
a projected image. If this is the case, then touching the
PA model is likely to reduce object-presence. This is
because in the real world, if an object is touched and it
does not feel correct, then the sense of realism (for the
specific object it was thought to be) disappears.
Touching a PA model may reduce object-presence in two
ways. Firstly, the mismatch between the visual and
haptic feedback may become very apparent when a PA
model is touched. This suggestion is supported by
previous work which has shown that touch is very
sensitive for perceiving material properties, such as
texture (see [15] for a review). The second problem is
that when a person touches the surface of a frontprojected PA model, the projected image will appear on
the back of their hand, and their hand will cast a shadow
onto the physical model. This draws attention to the fact
that the PA model is not what it aims to represent, which
may reduce object-presence. The likelihood that people
will notice these problems associated with the projection
is supported by previous work that showed people find

Proceedings of the Ninth International Conference on Information Visualisation (IV’05)
1550-6037/05 $20.00 © 2005 IEEE

the shadows on a front-projected flat display very
noticeable [16]. Moreover, it has been shown that the use
of shadows on virtual objects displayed using an
augmented reality display can affect the users’ sense of
object-presence [17].
The alternative situation is that people may treat PA
models as if they are computer-generated objects. It
could be argued the object that the PA model is aiming to
represent, is essentially computer generated because it is
the projected image that gives the dummy physical
objects meaning. For example, the same rectangular
physical box could be made to appear to be a brick, piece
of wood, book, or even a small building, by projecting
different images onto it. If people think of a PA model in
this way, then touching what they perceive as basically a
computer generated object is likely to increase their sense
of object-presence. This is supported by research that
found that the addition of haptic feedback to an
immersive virtual environment, which are very obviously
computer generated, increased the user’s sense of
presence [18] [19]. Specifically, it has been found that in
this type of virtual environment, it is the existence of
haptic feedback, rather than the fidelity of the haptic
feedback, that is important for supporting the users’ sense
of presence [20].
Given this conflicting evidence, it is not possible to
predict what effect touching a front-projected PA model
that does not provide haptic feedback for material
properties, will have on object-presence. This is an
important issue because the majority of the technology
has been developed for this type of PA model, however,
both touch and object-presence are important for many
PA model applications (section 2).
For example,
consider the mobile telephone design PA model
application [5]; a strong sense of object-presence is
essential for any product design system, however, being
able to feel how a mobile telephone feels to hold is also
important. Therefore the aim of this research is to
investigate the following issue further:Given a front-projected PA model that does not provide
haptic feedback for material properties; what effect will
touching it have on object-presence?

4. Empirical investigation

PA models can actually be touched in two different ways;
with a bare hand or with an interaction device. The way
in which it is touched may affect a user’s sense of objectpresence; therefore both ways of touching a PA model
were investigated.
The specific type of interaction devices that are of
interest, are those that allow the user to directly interact
with a PA model by physically touching its surface with a
tool, thus allowing the user to haptically perceive its
physical shape. Such devices are referred to as spatiallycoincident devices, for example a Tangible User Interface
(TUI). A TUI allows a person to use small physical
objects to interact with digital information [21]. These
physical objects are referred to as phicons (physical
icons). A TUI can be used to interact with a PA model
by allowing the user to place a phicon directly on its
surface (figure 3).
Spatially-coincident interaction
devices can be contrasted with spatially-separate
devices. When using a spatially-separate device, the
action performed by the user is in a different location
from the PA model, thus the PA model cannot be
haptically perceived. The most common example of a
spatially-separate device is a mouse, as the user moves it
in a separate location to the mouse pointer, which is
projected onto the physical model (figure 2).
Thus, the specific question that this experiment
aimed to investigate was: Given a front-projected PA
model that does not provide haptic feedback for material
properties; what effect does touching it with a bare hand,
and/or touching it using a spatially-coincident
interaction device, have on object-presence?
In
comparison to just viewing it, and/or interacting with it
using a spatially-separate device. To operationalise this
question, the spatially-coincident device the experiment
focused on is a Tangible User Interface, and the spatiallyseparate device is a mouse.

4.1 Design
A 2 x 2 between-participants factorial design was used.
The two independent variables (IV) were; Device (Mouse
and TUI) and Feedback (Visual and Haptic). Therefore
the four conditions were Mouse+Visual, Mouse+Haptic,
TUI+Visual and TUI+Haptic. The procedure of the
experiment was as follows:-

An experiment was conducted to investigate the research
question outlined in the previous section.

Figure 3. Interacting with a PA model using
a Tangible User Interface.

Proceedings of the Ninth International Conference on Information Visualisation (IV’05)
1550-6037/05 $20.00 © 2005 IEEE

1. The participants looked at a photograph of items
from a garden shed (see below for details).
2. The participants then completed a target selection
task, which required them to use an interaction
device to select a series of points on the PA model
(20 in total). They did this task using either a TUI
or a mouse interaction device (Device IV).
3. Participants then did a task that required them to
estimate the size of various of parts of the PA
model (20 in total). They did this either by
looking at it, or by both looking at and touching
the PA model (Feedback IV). (The results of this
specific task can be found in [22].)

Object-presence was measured using a postexperiment questionnaire, which was developed
specifically for this experiment to measure objectpresence experienced when using a PA model (see
appendix). This questionnaire will be referred to as the
Projection Augmented Model Object Presence
Questionnaire (PAM-OPQ). Higher object-presence is
indicated by a higher score on questions 2, 3, 4, 5 and 8,
and a lower score on questions 1, 6, 7 and 9. When
analyzing these questions, the scores for 1, 6, 7 and 9
were inversed, therefore a higher score for the
questionnaire indicates higher object-presence.
The PA model that was constructed for this
experiment is shown in figure 1. This PA model
provided conditions that ensured, as far as possible, all
participants knew what it ‘should’ look and feel like.
This is important because object-presence can be affected
by how familiar a participant is with the situation that the
virtual environment represents. The PA model did this
by realistically representing everyday objects on a real
life scale. Items from a garden shed are objects that are
likely to be familiar to most people, however this cannot
be assumed. Therefore participants were shown a
photograph of real items from a garden shed. This
technique ensured everyone has the same base-line on
which to make their judgments, and it has been found to
increase the sensitivity of presence questionnaires [23].
A total of 80 participants (55 male 25 female) were
used; 20 in each condition. They were all students on
computing-related degree courses. The mean ages were
24 for males and 20 for females.

4.2 Results
Before comparisons can be made between conditions, the
properties of the PAM-OPQ must be analyzed. In order
to do this, the procedure recommended for analyzing
summative scales used in social science research [24]
was followed.
A Pearson’s correlation test was
conducted between each question and the total of the
other eight items. Question 5 did not significantly
correlate, therefore it was not included in the analysis of
the results.
A Cronbach Alpha test for internal
consistency was then conducted on the remaining eight
questions and the reliability value of 0.82 was found.
This is above 0.70, which is the recommended reliability
value for human centered research [24]. Therefore the
results can be analyzed further to compare the conditions.
Strictly speaking data obtained from Likert-type
questions (such as the PAM-OPQ) is ordinal data, and
hence parametric tests should not be performed.
However, when a questionnaire consists of a sufficient
number of questions such that the range of possible
scores a person can obtain is greater than 20, the data can
be treated as interval data [25], and hence parametric
tests can be performed. In this case the questionnaire

has 8 questions, each with 5 possible responses, thus a
persons total score for the 8 questions can be anywhere
between 5 and 40. Therefore the results were analyzed
using a between-participants two way ANOVA (figure
4).

Feedback IV

4. Finally, the participants completed a postexperiment object-presence questionnaire (see
below for details).

Haptic

(Mouse+Haptic)
Mean: 2.80
s.d: 0.63

(TUI+Haptic)
Mean: 2.91
s.d: 0.53

Visual

(Mouse+Visual)
Mean: 3.68
s.d: 0.48

(TUI+Visual)
Mean: 2.86
s.d: 0.56

Mouse

TUI

Device IV

Figure 4. Results of PAM-OPQ.
A significant main effect was found for Feedback
(F(1,76)=11.15, p<0.01). Thus, the average score of the
two Visual conditions was significantly higher than the
average score of the two Haptic conditions. Additionally,
a significant main effect was found for Device
(F(1,76)=8.02, p<0.01). Thus, the average score of the
two Mouse conditions was significantly higher than the
average score of the two TUI conditions. A significant
interaction was found (F(1,76)=14.10, p<0.001),
therefore the results were analyzed further by conducting
contrasts.
It was found the Mouse+Visual condition had a
significantly higher score than the TUI+Visual condition
(F(1,76)=21.65, p<0.001). However, there was no
significant difference between the Mouse+Haptic and the
TUI+Haptic (F(1,76)=0.42, p=0.52).
Also, Mouse+Visual condition had a significantly
higher score than the Mouse+Haptic condition
(F(1,76)=25.11, p<0.001). However, there was no
significant difference between the TUI+Visual and the
TUI+Haptic feedback (F(1,76)=0.08, p=0.77).

4.3 Discussion
The PAM-OPQ found that the level of object-presence in
the Mouse+Visual condition was significantly higher
than in the other three conditions (section 4.2). In the
Mouse+Visual condition the participants did not touch
the PA model in anyway, whereas in the other three
conditions they either touched it with their bare hand,
with the TUI interaction device, or with both. Therefore,
the results suggest that touching this type of PA model
reduces object-presence. Moreover, the results indicate
that it is the properties of the PA model that are causing
this reduction in object-presence, as opposed to the way
in which it is touched. I.e. object-presence was reduced
by the image being cast on the participants’ hands, the
shadows their hands cast on the display, or the lack of
haptic feedback for material properties.
These results have implications for PA model
applications. The majority of applications use frontprojected PA models that do not provide haptic feedback
for material properties (i.e. the type this research focused

Proceedings of the Ninth International Conference on Information Visualisation (IV’05)
1550-6037/05 $20.00 © 2005 IEEE

on). Both a high level of object-presence and the ability
to touch the PA model are important for many of these
applications. Indeed, the size perception task in this
experiment (not reported in this paper) found that
touching a PA model increases how accurately a user
perceives it [22]. However, these results suggest that
touching this type of PA model reduces object-presence.
This problem could be over come by either using a backprojected PA model to eliminate the problems associated
with the projection, and/or using a PA model that
provides haptic feedback for material properties.
However, technology needs to be developed to enable
these to be viable options, for example technology to
automate the setup and construction procedure.
In addition to the implications for PA model
applications and future technological developments, these
results also have implications for other display devices.
People may consider PA models in two different ways;
either as real objects or as essentially computer generated
objects (section 3). These results suggest that people
treat PA models as if they are real objects because objectpresence was probably lowered when the PA model was
touched because the participants noticed the problems
with the display. This conclusion has implications for
predicting the relative effect of visual and haptic
feedback on object-presence and in fact presence in
general, for other types of display devices.

Figure 5. Reality-Virtuality Continuum [26].
Milgram and Kishino [26] depicted a continuum of
mixed reality devices, which range from the real world to
purely computer generated immersive environments
(figure 5). In the real world if an object is touched and it
does not feel/appear correct, then a person’s sense of
realism (for the specific object it was thought to be)
disappears. However, the addition of even ‘basic’ haptic
feedback (i.e. haptic feedback for only some aspects of
the virtual objects, which does not completely match the
visual feedback) to displays at the purely virtual end of
the continuum, increases object presence [18].
This difference is likely to be because people know
computer generated objects do not really exist, so any
haptic feedback increases realism, and hence objectpresence/presence. However, the results from the study
reported in this paper suggest that there is a point at
which mixed-reality displays become so visually realistic
that despite the fact people know they are computer
generated, they will actually treat what the display is
presenting as being real, and hence the addition of ‘basic’
haptic feedback will reduce presence. It is important to
note that ‘visually realistic’ is not just referring to the
quality of the graphics, it is also referring to the
intrusiveness of the display, and the level of integration
with the real world. For example, a person viewing an
extremely realistic cat through a light-weight unintrusive

Augmented Reality display may feel that they are
viewing a real cat. However, if only ‘basic’ haptic
feedback is provided, such as when the user ‘touches’ the
cat, it feels hard and cold as opposed to feeling soft,
warm and furry, then the sense that they are perceiving a
real cat may disappear. This can be contrasted with the
finding that in an immersive virtual environment that was
not particularly visually realistic, the addition of haptic
feedback increased presence, but increasing the fidelity
of the haptic feedback did not [20].
Returning to Milgram’s continuum; although
empirical work is needed to confirm what factors affect
someone treating a display as a real object, it seems
likely that the displays for which this will happen, lie
towards the real world end of the continuum, i.e.
Augmented Reality displays. When considering adding
‘basic’ haptic feedback to these displays, it needs to be
considered whether they are already so visually realistic
that basic haptic feedback would actually reduce objectpresence.

5. Conclusions and future work
The study reported in this paper focused on frontprojected PA models that do not provide haptic feedback
for material properties. Touch is an important aspect of
many PA model applications, however it was found that
when this type of PA model was touched, objectpresence was significantly lower than when it was
perceived through vision alone.
It was argued that object-presence was reduced by
the image being cast on the participants’ hands, the
shadows their hands cast on the display, or the incorrect
haptic feedback for material properties. This problem
could be overcome by either using a back-projected PA
model to eliminate the problems associated with the
projection, or using a PA model that provides correct
haptic feedback for material properties. However,
technology needs to be developed to enable these to be
viable options.
In order to guide which direction technology needs
to be developed, a study is currently being conducted
that investigates the relative effectiveness of these two
options with regard to increasing object-presence. I.e.
the study investigates when a PA model is touched; is it
more effective to eliminate the problems associated with
the projection, or is it more effective to provide haptic
feedback for material properties.

6. References
[1]

[2]

Proceedings of the Ninth International Conference on Information Visualisation (IV’05)
1550-6037/05 $20.00 © 2005 IEEE

B. Stevens, J. Jerrams-Smith, D. Heathcote, and D.
Callear, Putting the Virtual into Reality: Assessing
Object-Presence with Projection-Augmented Models.
Presence: Teleoperators and Virtual Environments. MIT
Press, 11(1), 79-92. 2002.
E. Bennett, and B. Stevens, PARIS: Interacting with a
Projection Augmented model using a mouse and a
Tangible User Interface, In Proceedings of British HCI
group annual conference. 2004.

[3]

[4]

[5]

J. Verlinden, A. de Smit, A. Peeters, and M. van
Gelderen. Development of a flexible augmented
prototyping system, Journal of WSCG. 11(3). 2003
R. Raskar, G. Welch, K. Low, and D. Bandyopadhyay,
Shader Lamps: Animating Real Objects With ImageBased Illuminations, In Proceedings of the 12th
Eurographics Workshop on Rendering. Springer, 2001.
T. Nam and W. Lee. Integrating hardware and

software: augmented reality based prototyping
[6]

[7]

[8]

[9]

[10]

[11]

[12]

[13]

[14]

[15]

[16]

[17]

method for digital products. In Proceedings of CHI.
ACM Press, 957-957. 2003.
D. Clark, R. McKeon, R. Marciano, and M. Bailey. RearProjecting Virtual Data onto Physical Terrain: An
Exercise in Two Senses Being Better Than One. In
Proceedings of IEEE Visualization. 451-454. 1998.
C. Ratti, Y. Wang, H. Ishii, H. B. Piper and D.
Frenchman. Tangible User Interfaces (TUIs): A Novel
Paradigm for GIS. Transactions in Geographical
Information Systems. 8, 4, 407-421. 2004.
C. Ratti, Y. Wang, A. Biderman, B. Piper and H. Ishii.
Phoxel-Space: an Interface for Exploring Volumetric
Data with Physical Voxels. In Proceeding of Designing
Interactive Systems. 2004.
D. Dietz, R. Raskar, S. Mihelic-Booth, J. van Baar, K.
Wittenburg and B. Knep. Multi-Projectors and Implicit
Interaction in Persuasive Public Displays. In Proceedings
of Advanced Visual Interfaces. ACM Press, 209-217.
2004.
M. Grossberg, H. Peri, S. Nayer and P. Belhumeur.
Making one object look like another: controlling
appearance using a projector-camera system. In
Proceedings of IEEE Conference on Computer Vision
and Pattern Recognition. 452-259, 2004.
H. Zhu and W. Book. Speed control and position
estimation of small hydraulic cylinders for Digital Clay.
In
Proceedings
of
Symposium
of
Flexible
Automation.2004.
H. Iwata, F. Yano, R. Nakaizumi and Kawamura. Project
FEELEX: Adding Haptic Surface to Graphics. In
Proceedings of SIGGRAPH. ACM Press, 469-476. 2001
S. Hirooka and H. Saito. Virtual Display System Using
Video Projector onto Real Object Surface. In
Proceedings of the 14th International Conference on
Artificial Reality and Telexistence. 305-310. 2004.
J. Lee, P. Dietz, D. Maynes-Aminzade, R. Raskar and S.
Hudson. Automatic Projector Calibration with Embedded
Light Sensors. In Proceedings of ACM Symposium on
User Interface Software and Technology. 123-126. 2004.
M. Ernst and H. Bülthoff. Merging the senses into a
robust percept. Trends in Cognitive Sciences. Elsevier,
8(4), 162-169. 2004.
J. Summet, G. Abowd, G. Corso, J. Rehg. Rear
Projection: Do Shadows Matter? In Proceedings of CHI.
2005.
N. Sugano, H. Kato and K. Tachibana. The Effects of
Shadow Representation of Virtual Objects in
Augmented. In Proceedings of the IEEE International
Symposium on Mixed and Augmented Reality. 2003.

[18] H. Hoffman. A. Hollander, K. Schroder, S. Rousseau and
T. Furness. Physically touching and tasting virtual
objects enhances the realism of the virtual experiences.
In Proceedings of IEEE Virtual Reality International
Symposium. 1998.
[19] B. Insko, M. Meehan, M. Whitton and F. Brooks. Passive
haptics significantly enhances virtual environments. In
Proceedings of International Workshop on Presence.
2001.
[20] C. Borst and R. Volz. Preliminary report on a haptic
feedback technique for basic interactions with a virtual
control panel. In Proceedings of EuroHaptics. 1-13.
2003.
[21] H. Ishii and B. Ullmer. Tangible Bits: Towards Seamless
Interfaces between People, Bits and Atoms.
In
Proceedings of CHI. ACM Press, 234-241. 1997.
[22] E. Bennett and B. Stevens, B. The Effect that Haptically
Perceiving a Projection Augmented Model has on the
Perception of Size. In Proceedings of International
Symposium on Mixed and Augmented Reality (ISMAR).
IEEE Press. 2004.
[23] D. Nunez and D. Blake. The thematic baseline technique
as a means of improving the sensitivity of presence selfreport scales. In Proceedings of International Workshop
on Presence. 2003.
[24] P. Spector. Summated rating scale construction: An
introduction, In M. Lewis-Beck (Eds.) Basic
measurement: International handbook of quantitative
applications in the social sciences – volume 4, Sage.
1994.
[25] L. Grimm and P. Yarnold. Reading and understanding
more multivarient statistics. American Psychological
Association. 2000.
[26] P. Milgram and F. Kishino. Taxonomy of Mixed Reality
Visual Displays. IECE Transaction on Information and
Systems (Special Issue on Networked Reality). vol. E77D, 12, 1321-1329. 1994.

PAM-OPQ
(1 = strongly disagree, 2 = disagree, 3 = neither agree or
disagree, 4 = agree, 5 = strongly agree)
1. I had a strong sense that all the objects in the display had
the same physical texture.
2. I had a strong sense that the display was a very natural
way of presenting information.
3. I felt that the real life objects that the display represented,
were actually present in front of me.
4. I had a strong sense that all of the properties of the objects
in the display were three-dimensional.
5. I felt that it would be possible for me to perceive all of the
properties of the objects in the display from every
direction.
6. I had a strong sense that all the objects were the same
‘physical’ color.
7. I constantly paid attention to the displays deficiencies.
8. The real life objects the display aimed to represent were
represented accurately.
9. I had the strong sense that parts of the display were
computer generated.

Proceedings of the Ninth International Conference on Information Visualisation (IV’05)
1550-6037/05 $20.00 © 2005 IEEE

