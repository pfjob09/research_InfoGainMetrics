2010 14th International
Information
Conference
Visualisation
Information Visualisation

Network Visualization of Human and Machinebased Educational Standard Assignment
René F. Reitsma, Anne R. Diekema
Oregon State University, Utah State University
{reitsmar@bus.oregonstate.edu, anne.diekema@usu.edu}
catalogers and one from an accepted and well-regarded
automated standard assignment tool. From these
assignments we generate standard-to-standard networks
which are then analyzed for topology, connectivity and
layout and interpreted in the context of the curriculumstandard assignment challenge.

Abstract
Rapid growth in the availability of digital libraries
of K-12 curriculum, coupled with an increased emphasis
on standard-based teaching has led to the development
of automated standard assignment tools. To assess the
performance of one of those tools and to gain insight into
the differences between how human catalogers and
automated tools conduct these standard assignments, we
explore the use of network modeling and visualization
techniques for comparing and contrasting the two. The
results show significant differences between the humanbased and machine-based network maps. Unlike the
machine-based maps, the human-based assignment maps
elegantly reflect the rationales and principles of the
assignments; i.e., clusters of standards separate along
lines of content and pedagogical principles. In addition,
humans seem significantly more apt at assigning socalled ‘methodological’ standards.

2. Background
The standard assignment challenge in the U.S.A.
stems from an increasing emphasis on educational
accountability as illustrated by, for instance, the US 2001
Public Law 107: “An act to close the achievement gap
with accountability, flexibility, and choice, so that no
child is left behind,” more commonly known as the 'No
Child Left Behind' act [21] .
Both the available curriculum and the educational
standards change frequently. Authors make changes to
their curriculum as they fix errors, extend it, add new
examples, etc. Similarly, standard authoring bodies
regularly issue new standards. U.S. states, for instance,
change their standards about once every five years ([[11]
, [9] [19] . To complicate matters, in the U.S.A., K-12
education is the authority of the states and hence, each
state has its own set of standards. As a consequence, the
body of educational standards to which curriculum must
be assigned is substantial. The Achievement Standard
Network [20] , for instance, lists a total of about 60,000
U.S. K-12 standards in mathematics, science and
technology alone. The following are just two, random
examples of such learning standards:

Keywords--- standard assignment, network visualization,
clustering, human vs. machine-based assignment

1. Curriculum-Standard Assignment
The educational world is witnessing rapid growth in
Web-based educational content, from on-line university
course work to K-12 on-line curriculum. Examples of
on-line K-12 curricular collections include Teacher’s
Domain [10] , TeachEngineering [18] , NetTrekker [2] ,
Engineering is Elementary [4] , Curriki [12] , Middle
School Portal [17] , Thinkfinity [14] and the National
Science Digital Library [25] .
This paper addresses the important problem of
having to assign this growing body of Web-based
curriculum to a continuously changing and substantial
body of educational standards. We address three issues
associated with this assignment process:
• Can underlying standard assignment dimensions be
derived from existing standard assignment sets?
• Are these dimensions expressed in network layout
ordination?
• Do the differences between human catalogers’
networks and machine-based networks contain
information about how both assignments differ?
To explore these issues we visualize two sets of
standard assignments; one conducted by human
1550-6037/10 $26.00 © 2010 IEEE
DOI 10.1109/IV.2010.14

•

Colorado, Science, 2007, grades 3-5: There are
different types and sources of energy (for example:
light, heat, motion).

•

Iowa, Math, 2009, grades 9-12: Understand,
analyze, represent, and apply functions.

To assist teachers and curriculum developers with
this perennial assignment task, automated assignment
tools and techniques have been developed. One of these
is the Content Assignment Tool (CAT), developed by
Syracuse University’s Center for Natural Language
Processing [6] [7] , [24] . CAT uses natural language
processing technology to process standards and
curricular items. The contents of each standard and

29

educational resource are first
assigned so-called 'part-of-speech'
tags [23] . Then verb and noun
phrases are identified, terms and
phrases
are
categorized,
and
synonyms are found. These terms are
then used to match a curricular item
with one or more standards.

Table 1: Colorado Science 2007 standard assignments.
Human Catalogers
(CO Curriculum)

CAT (CO
curriculum
cataloged by
humans)

CAT
(all curriculum)

Assignments

324

139

706

Number of

63

47

100

86

86

449

0.73

0.55

0.22

3.78

1.61

1.57

Despite the attractiveness of standards covered
these tools to teachers and curriculum Curricular items
authors, early evidence on the assigned
validity of their results is not very
encouraging. Devaul et al. [6] , for Mean number of
instance, found low inter-rater curricular items
per standard
reliability (IRR) between expert
judgments of human curriculum- Mean number of
standard alignments informed by assignments per
CAT. Reitsma et al. [13] , however, curricular item
point out that this low IRR may be an
artifact of the applied measurement system. They point
to other, nonstandard alignment experiments that seem to
have suffered from similar measurement weaknesses
resulting in equally poor IRR; e.g., [22] [1] . As an
alternative they implement Saracevic's theory of
relevance 'clues,' [15] and decompose the overall notion
of standard assignment into a number of specific,
teaching-relevant dimensions and accomplish much
higher IRR. Their results, however, are experimentally
derived and may or may not be reflected in existing
standard assignment which lacked experimental control.
Moreover, the automated assignment mechanisms cannot
be subjected to the experimental controls and hence, to
compare human with machine-based assignments, we
must rely on the comparison of existing standard
assignment sets.

the curriculum in collaboration with K-12 math and
science teachers. All standard assignment decisions were
supervised by an engineering faculty member trained
both as an engineer and a K-12 science teacher.
The CAT assignments were collected by submitting
the curricular items to the CAT automated Web service
with a request for assignment to at most five standards
per standard-authoring body; typically a USA state. The
limit of five was chosen because CAT does not provide a
measure of fit other than an ordinal one in that it returns
standards in order of best fit and because the average
number of standards assigned per curricular item by the
human catalogers was 3.78 (Table 1).

4. Standards Networks
We defined standards to be associated (linked) if
they were jointly assigned to at least one curricular item.
This implies (n2−n)/2 associations for all n standards
assigned to a curricular item.

3. Data
Standard
assignment
data
are
from
www.TeachEngineering.org, a freely available digital
library of K-12 science and technology curriculum [18] .
in TeachEngineering, standards are assigned to curricular
items in two ways. Curriculum authors assign standards
as part of the curriculum submission process, and once
accepted into TeachEngineering, all curriculum gets
submitted to CAT. Since both TeachEngineering and
CAT employ the third-party ASN database of
educational standards [20] , standard assignment sets can
be compared between the two. All ASN standards are
identified by an S<hex-code> index which refers to a
PURL at http://purl.org/ASN/resources/S<hex-code>.

Figure 1 and Figure 2 show the FruchtermanReingold diagrams of both the human catalogers and
CAT networks [8] [5] . On first inspection, the networks
have similar topology and clustering. The human
catalogers’ network, however, seems denser; i.e., more
nodes and higher connectivity and its clusters are
substantially bigger. The network metrics in Table 2
confirm this impression.

5. Curricular units
A closer look at the two networks reveals some
interesting differences. Not only do the human catalogers
conduct more standard assignments per document, they
also more clearly associate specific groups of standards
with specific groups of curricular items.

We limit our analysis to Colorado Science 2007
standard assignments [3] . Both human-assigned and
machine-assigned data sets were collected from the
TeachEngineering system in late January 2009. Human
catalogers were graduate engineering students
participating in the USA NSF's Graduate STEM Fellows
in K-12 Education (GK-12) and Math and Science
Partnership (MSP) programs, who developed and taught
30

Figure 1: Fruchterman-Reingold diagram of human catalogers' standard association network.

Figure 2: Fruchterman-Reingold diagram of CAT standard association network.
All 15 standards in the human catalogers’ disjoint
Northwest cluster (Figure 1), for instance, are assigned to
the five curricular items—one lesson and four hands-on
activities—that reside on a single curricular unit on
energy-efficient housing in the TeachEngineering
collection.

Catalogers, curriculum authors in particular, are
aware of the central theme of these curricular units and
hence, hone in on the standards associated with that
theme and assign the same standards with the various
components of that curricular unit. CAT, however, has
no notion of curricular organization; it assigns each

31

curricular item in isolation This implies that on the one
hand it is not biased in the direction of specific standards,
but on the other it lacks the advantage of being able to
assign certain standards because they address the central
theme of the unit.

standards which express ways and means of conducting
science, and world standards; i.e., standards which
express facts and principles about the empirical world.
An example of either type is the following:

• methodological: S103ECE9: A controlled experiment
must have comparable
results when repeated.
Table 2: Measures of several standard association networks (Colorado, Science 2007).
• world: S103EC87: Light
1
The number of nodes being lower than the number of standards covered in Table 1 represents
and sound waves have
curricular items having been assigned but a single standard and that standard not co-occurring with
distinct
properties:
other standards on any other item.
frequency,
wavelength
and amplitude.
Human Catalogers
CAT
(CO curriculum)
(CO curriculum cataloged by
We can furthermore
humans)
subdivide
the
methodological standards
60
47
Nodes1
into what we would like to
256
172
Links
call 'pure' methodological
minimum: 1
minimum: 4
Degree
standards and ‘impure’
maximum: 33
maximum: 17
methodological standards.
mean: 8.53
mean: 3.20
Although the latter have a
sigma: 6.02
sigma: 3.64
clear
methodological
objective, they contain
Degree histogram
significant amounts of
world terms, typically in
the
form
of
world
examples. An example is
S103ECD4: Technology is
needed to explore space
(for example: telescopes,
spectroscopes, spacecraft,
life support systems).
Figure 3 and Figure 4
show
that
CAT
is
significantly less likely to
minimum: .146
minimum: .119
Closeness centrality
maximum: .579
maximum: .501
associate methodological
mean: .308
mean: .329
standards with curricular
sigma: .091
sigma: .102
items than the human
catalogers.
Moreover,
Histogram of
whenever it does assign
Closeness centrality
methodological standards,
it clearly prefers the impure
ones, most likely because it
uses their world terms to
assign them to curricular
items.
For
pure
methodological standards,
however, this is much more
difficult as often the
standard is expressed in
terms that either do not play a major role in the text of
the curricular item or if they do, only carry meaning
6. Cluster Content: Methodology vs. World
under a very specific interpretation and when used in
conjunction.
Another, important difference between the
CAT’s (alleged) preference for assignment based on
catalogers’ and machine-based networks is reflected in
world
terms, therefore, does not bode well for a state
the actual content of the various standard clusters.
such as Colorado which distinguishes between world and
Science standard—Colorado’s and those of others
methodological standards. After all, if CAT indeed
states—can be classified as either methodological; i.e.,
Degree centralization

0.21

0.11

32

Figure 3: Methodological and world standards in human catalogers' Southern cluster.

Figure 4: Methodological and world standards in CAT’s large cluster.
assigns standards based on world terms, it will likely
make many mistakes assigning the methodological ones.

Additional differences between the human and machine
catalogers can be gleaned from studying the positions of

33

[10] Johnson, A. (2003) Summative Evaluation Teachers’
Domain. WGBH, Boston, MA.
[11] Kendall, J.S., Marzano, R.J. (1997) Content Knowledge.
A Compendium of Standards and Benchmarks for K-12
Education. Second Edition. MCREL. Aurora, CO.
[12] McAnear, A. (2007) What Does Globalization Mean for
Education? Learning and Leading with Technology. 5.
[13] Reitsma, R., Marshall, B., Zarske, M. (2010) Aspects of
'Relevance' in the Alignment of Curriculum with
Educational Standards. Inf. Proc. & Mgt. 46. 362-376.
[14] Russakoff, S. (2008) Pilot Project: Technology
Integration in Underserved Schools using Thinkfinity.
Final Report Cornerstone 1 Reports: Expansion and
Enhancements
of
the
Thinkfinity
Platform.
http://digitalcommons.pace.edu/cornerstone1/4.
[15] Saracevic, T. (2007) Relevance: A Review of the
Literature and a Framework for Thinking on the Notion
in Information Science. Part II: Nature and
Manifestations of Relevance. J. Am. Soc. Inf. Sc. &
Techn. 58. 1915-1933.
[16] Saracevic, T. (2007a) Relevance: A Review of the
Literature and a Framework for Thinking on the Notion
in Information Science. Part III: Behavior and Effects of
Relevance. J. Am. Soc. Inf. Sc. & Techn. 58. 2126-2144.
[17] Saylor, J.M., Minton-Morris, C. (2006) The National
Science Digital Library: An Update on Systems, Services
and Collection Dev. Science & Techn. Libs. 26. 61-78.
[18] Sullivan, J.F., Cyr, M.N., Mooney, M.A., Reitsma, R.F.,
Shaw, N.C., Zarske, M.S., Klenk, P.A. (2005) The
TeachEngineering Digital Library: Engineering Comes
Alive for K-12 Youth. Proc. ASEE Annual Conf.;
Portland, OR. ASEE, Washington, D.C.
[19] Sumner, T. Ahmad, F., Bhushan, S., Gu, Q., Molina, F.,
Stedman, W., Wright, M., Davis, L., Janée, G. (2005)
Linking Learning Goals and Educational Resources
Through Interactive Concept Map Visualizations. Intern.
Journal on Digital Libraries. 5. 18-24.
[20] Sutton, S., Golder, D. (2008) Achievement Standards
Network (ASN): An application profile for mapping K–
12 educational resources to achievement standards. Proc.
of the Intern. Conf. on Dublin Core and Metadata
Applications. Berlin, Germany.
[21] USGPO (US Printing Office) (2001) Public Law 107. An
Act to Close the Achievement Gap with Accountability,
Flexibility, and Choice, so that No Child Is Left Behind.
[22] Voorhees, E. M. (1998) Variations in Relevance
Judgments and the Measurement of Retrieval
Effectiveness. In: Croft, W.B., Moffat, A., van
Rijsbergen, C.J. (Eds.) Proc. of the 21st Annual Intern.
ACM SIGIR Conf. on Research and Development in
Information Retrieval. Melbourne, Australia. ACM
Press. New York, NY. 315-324.
[23] Widdows, D. (2004) Geometry and Meaning. CSLI
Publications. Stanford, CA.
[24] Yilmazel, O., Balasubramanian, N., Harwell, S.C.,
Bailey, J., Diekema, A.R., Liddy, E.D. (2007) Text
Categorization for Aligning Educational Standards.
Proceedings of the 40th HI Intern. Conf. of Systems
Sciences. IEEE. New York, NY.
[25] Zia, L.L. (2002) The NSF National Science, Technology,
Engineering, and Mathematics Education Digital Library
(NSDL) Program. New Projects in Fiscal Year 2002. DLib Magazine. 8.

the different types of standards in the standards
networks. The position and linkages between
methodological and world standards in the human
catalogers’ cluster, for instance, shows clear evidence of
a pairing of world and methodological standards. Either
the curricular items contain world examples that
illustrate or provide opportunity to practice the
methodological principles, or vice versa, the curricular
items contain the scientific principles and methods by
means of which a world phenomenon can be studied.
The CAT network, in contrast, is very much dominated
by world standards.

7. Conclusion
Comparison of the network layouts of human vs.
automatic standard assignment suggests that lexical
classifiers have difficulty associating methodological
standards with curriculum. Hence, we expect that
providing classifiers with a controlled vocabulary on
methodological terms will likely improve their
performance on this type of standard assignment. We
also found that automated classifiers such as CAT could
benefit from being able to use the assignments of related
curriculum in making the assignment of the curricular
under consideration. Whereas the human standard
networks show clear evidence of clustering of curriculum
around a few, central standards, the automated classifier
networks lacks such clustering.

References
[1]
[2]
[3]
[4]

[5]
[6]

[7]

[8]
[9]

Bar-Ilan, J., Keenoy, K., Yaari, E., Levene, M. (2007)
User Rankings of Search Engine Results. J. Am. Soc. Inf.
Sc. & Techn. 58. 1254-1266.
Breen, C. (2008) Review: NetTrekker. MacWorld.com.
http://www.macworld.com/article/134787/2008/08/nettre
kker.html.
CDE-Colorado Department of Education (2007) Model
Content Standards for Science. Office of Learning and
Results. Denver, CO.
Cunningham, C.M., Hester, K. (2007) Engineering is
Elementary: An Engineering and Technology
Curriculum for Children. Proc. ASEE Annual Conf.,
Honolulu, HI. ASEE, Washington, D.C.
De Nooy, W., Mrvar, A., Batagelj, V. (2005) Exploratory
Social Network Analysis with Pajek, CUP.
Devaul, H., Diekema, A.R., Ostwald, J. (2007)
Computer-assisted Assignment of Educational Standards
Using Natural Language Processing. Annual Meeting of
the NSDL. Arlington, VA.
Diekema, A. R., Yilmazel, O., Bailey, J., Harwell, S. C.,
Liddy E. D. (2007) Standards Alignment for Metadata
Assignment. Proc. of the Joint Conf. of Digital Libs.
Vancouver, BC. IEEE-ACM. New York, NY.
Fruchterman, T. M. J., Reingold, E. M. (1991) Graph
Drawing by Force-Directed Placement. Software,
Practice and Experience, 21. 1129-1164.
Jay, M., Longdon, D. (2003) Death, Taxes and
Correlations: A Primer on the State of Correlation in the
K-12 Education. Upgrade, SIIA. 20-21.

34

