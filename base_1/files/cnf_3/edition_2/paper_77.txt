2010 14th International
Information
Conference
Visualisation
Information Visualisation

Trust Enabled Secure Multiparty Computation
Renren Dong, Ray Kresman
Department of Computer Science
Bowling Green State University
Bowling Green, OH, USA 43402
drenren@gmail.com, kresman@cs.bgsu.edu

computation. We develop a simple algorithm to derive the
friendlier path that improves the safety factor.
In the rest of this section, we define certain terms dealing
with HCs. In Section II, we use an example of SMC in the
literature that serves as a context for the work reported in
this paper. We introduce the notion of trust in Section III and
improve upon the instant example by deriving a friendlier
path. In Section III, we develop a trust model that allows us
to quantify the notion of trust. The algorithm for improving
the safety factor along with numerical results are presented
in Section IV.
A Hamiltonian cycle, H, is a cycle that visits every node
in the graph exactly once before returning to the source node.
Alternately, a Hamiltonian cycle can be defined as a nonself-intersecting cycle in which an edge or a vertex appears
at most once. In graph G = (V, E), if we define Hamiltonian
cycle as H = {h1 , h2 , . . . , hN }, hi ∈ E, 1 ≤ i ≤ N , we
−1
will have N = |V |, and V = (∪N
i=1 hi ∩ hi+1 ) ∪ (hN ∩ hi ).
Now we define a set of edge-disjoint Hamiltonian cycles
(EDHCs). A set of Hamiltonian cycles is called edge-disjoint
if no two HCs in the set share an edge. Formally, suppose
we have a set H = {H (i) |H (i) is a Hamilton cycle in graph
G}, |H| is the size of H. H is edge-disjoint if ∀e ∈ H (i) ,
e = d, ∀d ∈ H (j) , 1 ≤ i = j ≤ |H|.
EDHCs are useful in computer networks. They can be
used to improve the capacity of the network or to provide
fault-tolerance and computer security [5]. For example, if a
route in a network is faulty or compromised, traffic can be
routed through another - edge disjoint cycle or - route that
does not share any edges with the previous route. So, an
interesting question is how to find the various EDHCs.
Other researchers have investigated this problem for specialized network topologies. Alspach et. al., [6] provide
an algorithm to generate the EDHCs for fully connected
networks. Bae and Bose [7] give a method for generating
EDHCs in Torus and k-ary n-cubes by using Gray Codes.
A polynomial time distributed algorithm for k-ary n-cubes
and hypercubes is given in [8].

Abstract—Hamiltonian cycles play an important role in
graph theory and data mining applications. Two Hamiltonian
cycles that don’t have an edge in common are known as edgedisjoint Hamiltonian cycles (EDHCs). EDHCs are useful in
computer networks. They have found applications in improving
network capacity, fault-tolerance and collusion resistant mining
algorithms.
This paper extends previous work on collusion resistance
capability of data mining algorithms. We first propose a new
trust model for network computers. We then use this model as
a basis to improve the collusion resistance capability of data
mining algorithms. We use a performance metric to quantify
the improvement.
Keywords-Data mining; Privacy; Trust enabled

I. I NTRODUCTION
Distributed mining algorithms mine data in a network by
distributing the mining computation. An important issue for
these algorithms is how to mine the data while respecting
privacy or safety constraints. Secure multiparty computation
(SMC), a framework for safe mining of distributed data,
provides certain security promises of the computation.
Many SMC methods have been developed to solve a
number of derivatives of SMC problems [1]. Some of these
methods are based on the application of Hamiltonian cycles
(HCs). In this paper, we call an SMC as HC-based, also
known as HSMC, if the computation of the algorithm relies
on one or more HCs [2]–[4] to obtain the global result. HCs
plays an important role in graph theory and data mining
applications. Nodes participate in the mining computation by
exchanging messages along an HC. The goal is to compute
a global mining quantity in a distributed manner without
anyone knowing who contributed a value to the global
computation. By having multiple cycles to pass messages
around, the private value can be kept secret even if nodes
engage in unethical behavior - for example a group of nodes
collude to discover another node’s private value.
This paper takes a closer look at colluding nodes or
such unethical behavior. Intuitively, two nodes that trust
each other are less likely to engage in unethical behavior
among themselves. We first propose a model for trust and
define a metric for measuring the safety of a given topology.
We then show how the safety factor can be improved by
using a friendlier path, or a modified cycle, for the mining
1550-6037/10 $26.00 © 2010 IEEE
DOI 10.1109/IV.2010.95

II. S ECURE M ULTIPARTY C OMPUTATION
Figure 1 - similar to the one in [1] - shows an example of
HSMC. Assume the presence of a HC as shown in Figure 1.
We initiate a secure sum (SS) computation: the goal of SS
521
531

is to let the value of each site’s individual input be masked
while the global sum of all inputs is universally known. The
computation starts at the source station p1 whose private
value is x1 = 8. p1 uses a random rx , rx = 5, to mask its
private value [9]. Then p1 sends x1 + rx = 13 to the next
station. p2 receives x1 + rx = 13 and adds its local value,
x2 , to the sum before sending it to the next station. At the
5
end, start node, p1 , receives rx + i=1 xi . Since p1 selected
rx = 5, the global sum can be easily calculated. A similar
algorithm can also be used to compute secure set union and
secure set intersection [10].
One of the disadvantages of the method presented in
Figure 1 is that it can be vulnerable to collusion attack. For
example, in Figure 1, x3 can be easily found if p2 and p4
collude. In order to make HSMC more secure to collusion
attack, cycle-partitioned SMC algorithm is developed in [11]
and modified in [5]. The latter algorithm, known as cycle
partitioned secure sum computation (CPSS), improved the
original algorithm by using several HCs. An example of
CPSS is given in Figure 2. In Figure 2, p3 is connected
to 4 other participants which means that at least 4 other
participants have to collude in order to discover p3 s contribution to the global sum. Actually, if we use n HCs, one can
prove that CPSS is 2n − 1 collusion resistant, i.e. at least
2n participants have to collude to find out someone else’s
contribution.
Note that the HCs used in Figure 2 are edge-disjoint.
However, the number of EDHCs in a given graph is usually
very limited. The limited number of EDHCs in the graph
constrains the application of CPSS algorithms. So one
interesting question is how to defend against collusion attack
without using too many EDHCs.

Table I
A T RUST M ATRIX
Ti,j
A
B
C
D
E
F
G

A
1
94%
85%
75%
20%
29%
14%

B
90%
1
92%
90%
38%
31%
13%

C
95%
93%
1
88%
10%
43%
31%

D
69%
82%
78%
1
18%
21%
27%

E
45%
50%
25%
15%
1
99%
20%

F
30%
20%
12%
40%
90%
1
20%

G
5%
70%
40%
28%
38%
29%
1

N (pi ) is the number of direct neighbors of node pi in
HSMC. Actually, Si is the likelihood that pi s contribution
will be secure. i.e. the chance that at least one of its
neighbors does not disclose information against pi , making
collusion by all of its neighbors unlikely - at least not a
certainty - from a probabilistic viewpoint.
Si = 1 −

(1 − Ti,j )

(1)

pj ∈N (pi )

Figure 3 gives an example of computing SA of node A
using the data from Table I. In Figure 3, A has two direct
neighbors, F and B. SA can be computed using Equation (1),
and is seen to be 0.93.
Figure 4 is a more detailed example. Here, we see that
A - between the two HCs - has 4 direct neighbors, i.e. A’s
contribution to the SMC can be revealed if these 4 nodes
collude. With the trust level given by Table I, Equation 1
is used to compute the safety level, SA , of node A. From
Figure 4, SA = 94.1%. As noted earlier, SA measures the
likelihood that node A’s contribution will be secure, i.e. the
chance that at least one of its neighbors declines collusion!
Now, using the trust level matrix and the safety level
defined above, we can convert the TE-HSMC problem
into an optimization problem that maximizes the participant average safety level (PAS) for the entire network,
N
where P AS = ( i=1 Si )/N . Formally, given P the set
of participants with |P | = N , Ti,j the trust level matrix,
and H = {H (1) , H (2) , . . . , H (M ) } the set of EDHCs that
connect all the nodes, we want to find a better EDHCs set
H = {H (1) , H (2) , . . . , H (M ) } that maximizes PAS.

III. A M ODEL FOR T RUST E NABLED HSMC
(TE-HSMC)
In this section, we formulate a generalized model, trust
enabled HSMC (TE-HSMC), to define trust levels and their
impact on HSMC. In our model, each participant gives every
other participant a numeric trust level in the range 0 to 100%.
For example, A trusts B 90% (denoted as TA,B ) meaning
that A believes there is only a 10% (1 − TA,B ) chance that
B will leak information, about A, to the others during the
SMC process. Table I provides an example of a trust level
matrix, where each participant assigns a trust level to every
other participant.
With the trust matrix, we want to quantify the ‘Safety
Level,’ Si , of participant pi in the network. Note from
Section I, and the example in Section II, that the safety of
a participant depends on the reliability or trust-worthiness
of its neighbors. For each participant pi , the only way
for the other nodes to find out pi s contribution is for all
the neighbors of pi to collude in order to disclose pi s
information to a third party. Based on this consideration,
Equation (1) below defines the safety level, Si , of pi where

IV. G REEDY A LGORITHM FOR TE-HSMC
In this section, we present a greedy approximation algorithm, known as swap improvement (SI), for the optimization
problem given in the previous section. The idea behind SI is
quite simple; try to swap the position of a pair of participants
in all HCs of H. If the swap provides an increase in PAS
then save the modified HC set H as H, otherwise discard
the modified HC set H . Repeat swap operation on H until
there is no more improvement in PAS. Figure 5 provides a
walk-through of SI. Figure 5(A) is the initial configuration.
Figure 5(B) is the configuration after swapping the position
of E and C. Continuing this approach, Figure 5(C) gives
532
522

the final solution, since additional swaps don’t help improve
PAS. Consistent with the metric given by Equation 1, it is
easy to see that the new cycle (C), of Figure 5, provides
more security against collusion.

R EFERENCES
[1] C. Clifton, M. Kantarcioglu, J. Vaidya, X. Lin, and M. Y.
Zhu, “Tools for privacy preserving distributed data mining,”
SIGKDD Explor. Newsl., vol. 4, no. 2, pp. 28–34, 2002.
[2] J. Bondy and U. Murty, Graph Theory with Applications. The
Macmillan Press LTD, 1976.

A. Experimental results
We evaluate the performance of the greedy algorithm SI
for TE-HSMC against a synthetic workload. We generate
the trust level matrix, Ti,j , by simulating different network
environments. We also randomly select an initial network
configuration (a random HC). Then, we apply the greedy SI
algorithm to improve PAS. The results of our experiments
are given in Table II.
An explanation of Table II is in order. Column 1“(uniform
distribution),” means trust level Ti,j is chosen from uniform
distribution, and “(N: m,d)” means trust level Ti,j follows
a normal distribution with the parameters m(mean) and
d(standard deviation). I.PAS column gives the PAS for the
initial network configuration (a random HC). F.PAS is the
final PAS level after applying SI to the initial configuration.
I.MINS is the minimum of all Si s in the configuration while
F.MINS is the minimum of all Si s in the final configuration.
I.MAX and F.MAXS can similarly be explained. Each row
of Table II is the average value of 100 different trials.
Table III computes the improvement provided by SI, as
a ratio of the before-and-after effect of the corresponding
statistic. In most cases, SI offers a significant improvement
in PAS, especially in environments with low trust level, for
example, N : m = 0.25, d = 0.125. The greedy algorithm
terminates when no swap operation can improvement the
PAS.

[3] M. Garey, D. Johnson et al., Computers and Intractability:
A Guide to the Theory of NP-completeness. W.H. freeman
San Francisco, 1979.
[4] R. Diestel, Graph theory. Springer, 2005.
[5] S. Urabe, J. Wong, E. Kodama, and T. Takata, “A high
collusion-resistant approach to distributed privacy-preserving
data mining,” in Proceedings of the 25th conference on Proceedings of the 25th IASTED International Multi-Conference:
parallel and distributed computing and networks. ACTA
Press, 2007, p. 331.
[6] B. Alspach, J. Bermond, and D. Sotteau, “Decomposition into
cycles 1: Hamilton decompositions,” Cycles and Rays, p. 9,
1990.
[7] M. Bae and B. Bose, “Edge disjoint Hamiltonian cycles
in k-ary n-cubes and hypercubes,” IEEE Transactions on
Computers, vol. 52, no. 10, pp. 1271–1284, 2003.
[8] I. Stewart, “Distributed algorithms for building Hamiltonian
cycles in k-ary n-cubes and hypercubes with faulty links,”
Journal of Interconnection Networks, vol. 8, no. 3, p. 253,
2007.
[9] S. Shepard, “Anonymous Opt-Out and Secure Computation
in Data Mining,” Master’s thesis, Bowling Green State University, 2007.
[10] C. Clifton, M. Kantarcioglu, J. Vaidya, X. Lin, and M. Zhu,
“Tools for privacy preserving distributed data mining,” ACM
SIGKDD Explorations Newsletter, vol. 4, no. 2, pp. 28–34,
2002.

V. C ONCLUDING R EMARKS
This paper proposed a trust model for nodes in a data
mining network; the nodes participate in a multiparty data
mining computation, by passing messages over a cycle.
We defined a performance metric, known as safety level,
that gives a numerical measure of the goodness of the
cycle. We then developed an algorithm that allows us to
find a different cycle that has a better safety value. Though
the proposed algorithm is a greedy algorithm, it showed
promising results across a wide range of parameter values.
It found a global optimal solution or a good local optimal
solution. In a forthcoming paper, we will look at other more
efficient algorithms that can yield the same or even better
safety values. Therein, we will show how the algorithm can
be integrated with an underlying mining algorithm.

[11] S. Urabe, J. Wong, E. Kodama, and T. Takata, “A CollusionResistant Approach to Privacy-Preserving Distributed Data
Mining,” IPSJ SIG Technical Reports, vol. 2005, no. 63, pp.
21–25, 2005.

ACKNOWLEDGEMENT
The authors thank the reviewers for their valuable input
in improving the original manuscript.

533
523

Figure 1.

Secure Sum Computation - One Cycle

Figure 2.

Secure Sum Computation - Two Cycles

534
524

Figure 3.

Safety Level of Node A

Figure 4.

Safety Level with CPSS

Figure 5.

Swap Operation

535
525

Table II
S YNTHETIC W ORKLOAD AND S WAP I MPROVEMENT
Test Case (Distribution)

I.PAS

F.PAS

I.MINS

I.MAXS

F.MINS

F.MAXS

20 Participants (Uniform Distribution)
50 Participants (Uniform Distribution)
100 Participants (Uniform Distribution)
20 Participants (N : m = 0.5, d = 0.25)
50 Participants (N : m = 0.5, d = 0.25)
100 Participants (N : m = 0.5, d = 0.25)
20 Participants (N : m = 0.75, d = 0.25)
50 Participants (N : m = 0.75, d = 0.25)
100 Participants (N : m = 0.75, d = 0.25)
20 Participants (N : m = 0.25, d = 0.25)
50 Participants (N : m = 0.25, d = 0.25)
100 Participants (N : m = 0.25, d = 0.25)
20 Participants (N : m = 0.5, d = 0.125)
50 Participants (N : m = 0.5, d = 0.125)
100 Participants (N : m = 0.5, d = 0.125)
20 Participants (N : m = 0.75, d = 0.125)
50 Participants (N : m = 0.75, d = 0.125)
100 Participants (N : m = 0.75, d = 0.125)
20 Participants (N : m = 0.25, d = 0.125)
50 Participants (N : m = 0.25, d = 0.125)
100 Participants (N : m = 0.25, d = 0.125)

0.747
0.748
0.751
0.75
0.75
0.748
0.925
0.924
0.925
0.471
0.474
0.465
0.75
0.75
0.749
0.937
0.937
0.937
0.439
0.438
0.436

0.996
0.996
0.997
0.992
0.994
0.996
0.999
0.999
0.999
0.989
0.987
0.988
0.995
0.996
0.996
0.997
0.998
0.999
0.993
0.996
0.996

0.262
0.18
0.122
0.352
0.27
0.187
0.668
0.58
0.532
0.067
0.017
0.003
0.557
0.518
0.488
0.827
0.802
0.781
0.186
0.138
0.094

0.99
0.996
0.998
0.989
0.998
0.999
1
1
1
0.852
0.922
0.953
0.895
0.92
0.934
0.996
0.999
1
0.671
0.701
0.726

0.964
0.964
0.969
0.921
0.913
0.925
0.996
0.999
0.999
0.852
0.719
0.69
0.931
0.887
0.843
0.977
0.978
0.98
0.905
0.877
0.817

1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1

Table III
P ERFORMANCE OF S WAP I MPROVEMENT
Test Case (Distribution)

F.PAS/I.PAS-1

F.MINS/I.MINS-1

F.MAXS/I.MAXS-1

20 Participants (Uniform Distribution)
50 Participants (Uniform Distribution)
100 Participants (Uniform Distribution)
20 Participants (N : m = 0.5, d = 0.25)
50 Participants (N : m = 0.5, d = 0.25)
100 Participants (N : m = 0.5, d = 0.25)
20 Participants (N : m = 0.75, d = 0.25)
50 Participants (N : m = 0.75, d = 0.25)
100 Participants (N : m = 0.75, d = 0.25)
20 Participants (N : m = 0.25, d = 0.25)
50 Participants (N : m = 0.25, d = 0.25)
100 Participants (N : m = 0.25, d = 0.25)
20 Participants (N : m = 0.5, d = 0.125)
50 Participants (N : m = 0.5, d = 0.125)
100 Participants (N : m = 0.5, d = 0.125)
20 Participants (N : m = 0.75, d = 0.125)
50 Participants (N : m = 0.75, d = 0.125)
100 Participants (N : m = 0.75, d = 0.125)
20 Participants (N : m = 0.25, d = 0.125)
50 Participants (N : m = 0.25, d = 0.125)
100 Participants (N : m = 0.25, d = 0.125)

33.33%
33.16%
32.76%
32.27%
32.53%
33.16%
8.00%
8.12%
8.00%
109.98%
108.23%
112.47%
32.67%
32.80%
32.98%
6.40%
6.51%
6.62%
126.20%
127.40%
128.44%

267.94%
435.56%
694.26%
161.65%
238.15%
394.65%
49.10%
72.24%
87.78%
1171.64%
4129.41%
22900.00%
67.15%
71.24%
72.75%
18.14%
21.95%
25.48%
386.56%
535.51%
769.15%

1.01%
0.40%
0.20%
1.11%
0.20%
0.10%
0.00%
0.00%
0.00%
17.37%
8.46%
4.93%
11.73%
8.70%
7.07%
0.40%
0.10%
0.00%
49.03%
42.65%
37.74%

536
526

