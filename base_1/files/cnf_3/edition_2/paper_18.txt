2010 14th International
Information
Conference
Visualisation
Information Visualisation

Metric data analysis enhanced through temporal visualization
Renato Bueno1 , Humberto L. Razente2 , Daniel S. Kaster3,4 ,
Maria Camila N. Barioni2 ,Agma J. M. Traina4 and Caetano Traina Jr.4
1
Federal University of S˜ao Carlos (UFSCar) – S˜ao Carlos, SP, Brazil – renato@dc.ufscar.br
2
Federal University of ABC (UFABC) – Santo Andr´e, SP, Brazil – {humberto.razente, camila.barioni}@ufabc.edu.br
3
University of Londrina (UEL) – Londrina, PR, Brazil – dskaster@uel.br
4
University of S˜ao Paulo (USP) at S˜ao Carlos, SP, Brazil – {agma, caetano}@icmc.usp.br

is how to identify if a discovered relation is useful, and how
to interpret the findings. Data visualization techniques have
been successfully employed to help in such analysis.
Complex data are usually represented as elements in
high-dimensional or metric spaces. It is not intuitive to
visualize data embedded in high-dimensional spaces. One
alternative is to employ space mappings and dimensionality
reduction methods to build complex data visualizations.
Several examples of data visualization techniques proposed
in the literature are presented in [2]. Concerning metric
spaces, the interpretation is even harder, since they often
do not have a direct spatial representation.
There is a variety of research visualization systems that
include visualization techniques for data analysis, such as the
Weka Data Mining [3] and the XmdvTool [4]. However, in
several situations it is necessary to track changes in evolving
data. None of these visualization systems support exploring
metric (and high-dimensional) data regarding varying temporal interpretation.
In this paper, we explore graphical representations of
metric data that include temporal information. The proposed
techniques focus on different ways of interpreting temporal
information and provide ways to interactively visualize
datasets following each interpretation. The techniques are
complementary and can be useful to analyze complex data.
The paper is organized as follows. Section II presents
fundamental concepts. Section III describes the visualization
techniques proposed. Section IV shows visualization examples with real data. Section V brings the conclusions.

Abstract—The human vision can naturally interpret data in
spaces of 2 or 3 dimensions. When data is in higher dimensional
spaces, in most cases the visualization is not intuitive. Regarding metric spaces, the interpretation is even harder, since they
often do not have a direct spatial representation. However,
the need to analyze how metric-represented data evolve over
time is pretty common when one needs to understand several
phenomena and in decision making processes, as it occurs
in medical and agrometeorological applications. This paper
presents three interactive techniques to visualize metric data
that vary over time. Each one focus on a different way to
interpret the temporal information. The first technique shows
data evolving in a timeline axis. The second overlaps evolving
snapshots of the space showing how the space varies regarding
time. The last one does not treat temporal data as a dimension,
it is used instead to define the similarity among complex
data, employing the new concept of metric-temporal spaces,
which seamlessly integrate time and metric data into a single
similarity space. Visualization examples with real datasets are
presented to show the usefulness of the proposed techniques.
Keywords-visualization of temporal data; metric spaces;

I. I NTRODUCTION
Increasingly new applications make intense use of complex data. The term complex data in this paper is employed
to define information that cannot be embedded into simple
data types (e.g. numbers, dates or short strings), such as multimedia data, time series and biological data. For example,
medical applications have been handling radiological exams
codified in multimedia data, systems designed to analyze
the behavior of climate change variables rely on series
of measurements from sensors inspecting complementary
information from a phenomenon or process, and so on.
The availability of more and more powerful data capturing
mechanisms and the continuous cost reduction of storage
devices is leading to accumulation of complex data at an
increasing rate. Without adequate alternatives, these data
are just stored in huge unstructured repositories and may
never be accessed again [1]. In this scenario, data analysis
techniques are sought in order to put the data to work and
allow the extraction of useful information.
Searching for interesting patterns in the relationship
among complex data is commonly exploratory as, in general,
features or patterns adequate to provide useful information
are initially unknown. During this process, a crucial problem
1550-6037/10 $26.00 © 2010 IEEE
DOI 10.1109/IV.2010.26

II. F UNDAMENTAL C ONCEPTS
A. Metric data: what and when?
Complex data contain information that require a considerable reasoning effort to be interpreted and related to other
complex data. Usually, applications employ specialized data
processing algorithms to extract relevant information representing the data, organizing them in the so-called feature
vectors, which are thereafter used in place of the complex
data in further processing tasks.
Feature vectors are often composed of a constant amount
of values describing the essential characteristics of the
original data. It is common to interpret such data as points
116

in a vector or multidimensional space, where each feature is a dimension. However, several situations do not
meet this assumption. For instance, approaches based on
recognizing multiple regions in a scene do not generate
dimensional feature vectors, since each instance can have
distinct amounts of elements [5]. The Metric Histogram [6]
is obtained performing a piecewise linear approximation
over a normalized histogram, thus yielding varying numbers
of bins for each instance. Feature vectors composed by any
sort of nominal values are also not inherently embedded into
a dimensional space. All of those data are well suited to be
represented in metric spaces, where only the elements and
their pairwise distance matters [7].
Formally, a metric space is defined as a pair S, δ , where
S is the dataset and δ is a metric, that is a distance function
δ : S × S → R+ that complies with the following properties:
symmetry: δ(s1 , s2 ) = δ(s2 , s1 ); identity: δ(s1 , s1 ) = 0;
non-negativity: 0 < δ(s1 , s2 ) < ∞, if s1 = s2 ; and triangle
inequality: δ(s1 , s2 ) ≤ δ(s1 , s3 ) + δ(s3 , s2 ), ∀ s1 , s2 , s3 ∈
S.
Metric spaces can handle data embedded into vector and
multidimensional spaces whenever a metric is defined over
the space. The well-know family of distance functions Lp ,
p ≥ 1 (e.g. Manhattan, Euclidean and Chebychev), and
many other distances are metric, allowing defining metric
spaces over dimensional data.

Multidimensional Scaling is a distance-based method, i.e.,
only distance calculations between data elements are needed,
so it can be applied to multidimensional as well as metric
datasets, allowing treating both in an uniform way. Several
variants of the original multidimensional scaling algorithms
exist, such as the FastMap [10], the MetricMap [11], the
NLM [12] and the HyperMap [13]. Our work uses a tool
based on FastMap, described following.
C. The FastMap algorithm
The FastMap algorithm [10] projects the elements of a
metric space into an E-dimensional space, defining each
axis by a pair of elements, called pivots, selected from the
dataset . The algorithm uses the original metric to calculate
the distances between each element pair in that space. The
distance between each element pair in the target space is the
Euclidean distance, so the projection of each element can be
calculated using the Cosine Law.
As a mapping preserving exactly the same relative distances among the elements is not guaranteed if E < n − 1,
where n is the cardinality of the dataset, the FastMap aims
at minimizing the distortion reducing the average difference
of the distances among all elements. The compression for
the first axis takes into account just the Cosine Law, as there
is no need to correct the values obtained for the first axis.
For the subsequent axes, the distance function is modified in
order to consider the distortions introduced by the previous
axes. Intuitively, the method treats each distance between
a pair of elements as a “spring” between the elements, and
tries to rearrange the positions of the n elements to minimize
the springs’ stress.
The algorithm needs a pair of pivots that are as far away
as possible from each other for each dimension in the target
space, in such a way to approximate the axis to an orthogonal
spatial basis. To find the farthest pair of elements, the
distances among every pair of elements must be computed,
resulting in an algorithm with complexity complexity on the
dataset cardinality. Thus, the FastMap uses a heuristic to find
a pair of elements separated by a distance similar to that
of the farthest elements with linear complexity, bringing its
overall complexity linear on the dataset cardinality.

B. Visualization of metric data
Humans can naturally interpret data in spaces of 2 or 3
dimensions. When data is in high-dimensional spaces, in
most cases the visualization is not intuitive. An alternative is
to map the dataset into a lower dimensional space. For this
intent, the Multidimensional Scaling [8] and the Principal
Component Analysis [9] are the most commonly employed
dimensionality reduction techniques.
Regarding metric spaces, the interpretation is even harder,
since a spatial representation may not exist. The usual way
to visualize metric data is to embed the metric space into
a spatial one, preserving the distances among elements as
much as possible. A well-know property of metric spaces
is that a metric dataset of n elements can be embedded
into an n − 1 dimensional space exactly preserving the
original distances. However, if some errors are allowed
in the mapped distances, the dimensionality of the target
space can be much smaller. In fact, depending on the
original space data distribution, the errors can be very
small until the number of dimensions drops below a limit
known as the dataset’s intrinsic dimension. The concept of
the intrinsic dimension is related to the minimum number
of non-correlated dimensions able to represent the dataset
without degenerating its spatial distribution. It is independent
of the dataset cardinality and in real datasets the intrinsic
dimension is usually a small value, in general bellow twenty
or so.

D. The software FastMapDB
The FastMapDB [14] is a visualization tool that aims at
assisting in the analysis of data stored in relational databases.
The fundamental structure of this tool is the FastMap
algorithm, which maps the original metric distribution into
a dimensional space. Using the dataset mapped to a 2- or 3dimensional space, FastMapDB generates a graphical visualization using OpenGL, allowing one to interactively analyze
static metric data. Besides elementary visual operations, such
as rotation, zoom and translation, FastMapDB also provides
functionalities to select and weight the data attributes, to

117

adequately the metrics δs and δt . The main idea of the
technique proposed in [15] is to identify the contribution
amount of each component to define the metric-temporal
space, normalizing the metric and temporal components in
the similarity function of the metric-temporal space by the
intrinsic dimensions of S and T. Thus, if either component
has correlated attributes, the resulting redundancy is not
transferred to the similarity value, avoiding distorting the
distance distribution. The distance function used in the
metric-temporal space is defined as follows:

filter data subsets and to apply mining processes over the
visualized/marked objects.
In this work we enhanced the FastMapDB to deal with
time-evolving data.
III. V ISUALIZATION OF METRIC TIME - EVOLVING DATA
Our goal is to build interactive visualizations of timed
metric data. To reach this goal, we explored the observation
that temporal information can be used in varying ways to
achieve different purposes, as discussed following.

∆ ui , uj = (ws · δs (si , sj )) + (wt · δt (ti , tj ))

A. The facets of temporal information of metric data
Regardless of the application domain, it is often necessary
to be able to analyze time-evolving metric data. The commonest way of performing such analysis is considering data
embedded into a multidimensional space, where a specific
dimension represents the temporal information. The whole
analysis is guided by observing how data behave following
the timeline.
Nevertheless, many applications require using temporal
information to define the distance distribution among elements. For example, several medical studies use information
based on statistics of patient groups according to relative
temporal information, such as the disease stage and/or the
treatment time. If the patients’ information is composed by
the results of exams taken over a long treatment period, the
number and type of exams collected can vary according to
the current diagnosis and prognosis. In this case, the dataset
is inherently metric and it is necessary to approximate elements that have similar temporal information (in terms of the
distance in the modeled data space). However, the “amount
of approximation” must be calibrated, to avoid that the
non-temporal features dominate the temporal information in
the similarity evaluation and vice-versa. This consideration
is specially important due to the fact that complex data
usually are described through a set of many features and
the temporal information is represented through one or few
attributes.
In a previous work [15], we proposed the Metric-temporal
space to deal with this kind of situation. A metric-temporal
space is a pair U, ∆ , where U = S × T, being S the
component containing the metric information (features describing data) and T the component encompassing temporal
information, and ∆ : U × U → R+ is a metric between
elements of a metric space with time information associated,
that aggregates the functions δs and δt , which respectively
calculate the similarity between elements regarding the metric and temporal components of the metric-temporal data.
Therefore, both the complex data information encoded in the
extracted features and the associated temporal information
are taken into account to calculate the similarity, and,
consequently, affects directly the distance distribution.
To define a distance distribution that match the user
expectation as close as possible, it is necessary to mix

(1)

where ui , uj ∈ U, si and sj are respectively the projections
of ui and uj in S, ti and tj are the projections of ui
and uj in T and ws and wt are respectively the weights
of components S and T of the metric-temporal space. The
weigth ws is defined as ws = δs pmax , setting ps = D2 (S) ,
where D2 (S) is the correlation fractal dimension of S, which
provides a close estimation of the intrinsic dimension of
the dataset. The weight of the temporal component wt is
calculated following the same method. The values δs max
and δt max are respectively the largest distances between
two elements in the components S and T.
The metric-temporal space bridges the gap to analyze
complex data considering the temporal information in the
similarity between elements, tackling both dimensional and
metric datasets. The next subsections show three visualizations developed on top of the FastMapDB to support timeevolving analysis of complex data.
B. The Timeline visualization
The Timeline visualization maps the metric component
into a 2D space using the FastMap algorithm, and uses
the third axis to represent a “timeline”, thus showing the
“evolution” of the elements according to the temporal information. Each element is plotted as a series of dots and line
segments linking the dots, each sequence representing an
element evolving over the timeline. This procedure builds a
cascaded visualization joining the same elements at different
instants, producing the effect of “trend flow” of the elements
regarding their variation along the time, as illustrated in
Figure 1a. This technique in fact does not use the metrictemporal space, but as it is intuitive, it is useful to first
explore the space and allow the user to get acquainted with
the tool and with the dataset.
C. The Space Variation visualization
The Space Variation visualization aims at providing the
user to see the variations in the space positions that the
elements suffer over time. This visualization is generated
by mapping the metric component of the complex data to
a 3D space using the FastMap algorithm. The temporal
information does not appear as a separate axis, but is used to
link all instances of the same element during time through

118

a)

y

b)

y

a)

b)

1991

Hyper-plane n
...

Fortaleza
1980

Hyper-plane 3
Hyper-plane 2
t

Hyper-plane 1

x

x

1970

z

Ceará
Santa Catarina

Figure 1. Intuition of the proposed techniques a) Timeline visualization
and b) Space Variation visualization.

Figure 2. Evolution of statistics of the Brazilian cities from Cear´a and
Santa Catarina. a) Human development statistics. b) Education statistics.

line segments. Note that it is not equivalent to several
views parallel to temporal axis in the Timeline visualization,
because it uses the three dimensions to map the metric data,
so the error of the mapping is smaller. The effect obtained
by this visualization is an overlapped view of all temporal
slices of the dataset, showing the combined movements of
all elements over time, as illustrated in Figure 1b.
This visualization allows identifying, for example, the
elements that have the lowest and the highest variations in
the metric component over time. In a medical application,
it allows quickly spotting the patients whose evolution of a
degenerative disease is better or worse than that of the other
patients in the group regarding a given treatment.

IV. V ISUALIZATION EXAMPLES
This section presents examples of the proposed visualizations to highlight their usefulness. The examples employed
three representative real datasets.
A. The Brazilian City Statistics dataset
This dataset correspond to statistics regarding Brazilian
cities on several matters: human development, income and
education rates. We compared the behavior of some of these
variables over time in distinct regions of Brazil. Figure 2a
shows a Timeline visualization of the human development
statistics that is composed by 7 rates. The temporal attribute
(the census year) has the values {1970, 1980, 1991}, thus
resulting in three planes. Only the cities from the Cear´a
(Northeast) and Santa Catarina (South) states are presented
in the figure, highlighted respectively as blue circles and red
stars (only line segments linking the Cear´a cities are shown).
It is easy to perceive that the cities of each state define their
own clusters. We can also see that the clusters move over
time, so that the cities were more different (the clusters are
more spread) in 1991 and 1980 than they were in 1970. One
exception is the capital of Cear´a (Fortaleza), whose behavior
is similar to that of the Santa Catarina cities and it is very
different from the other cities from Cear´a.
Figure 2b shows a Space Variation visualization using
attributes about education (10 attributes). In the same way
as in the previous example, only the cities from Cear´a and
Santa Catarina are shown. However, in this visualization the
temporal attribute (the census year) has the values {1991,
2000}. The figure show line segments linking each city of
both states at different dates, showing the variation in the
space of the cities over time. Notice that although there
are some cities with different variations, most of them have
similar behavior, as well as its intensity.

D. The Metric-temporal visualization
The Metric-temporal visualization is a variation over the
Space Variation one that allows integrating metric and time
data into a homogeneous space. The temporal information is
commonly treated as increasing the original data space with
one (or more) dimension(s) to represent time. The treatment
of the additional dimension(s) must be as homogeneous to
the others as possible, as shown in the Timeline visualization.
However, when the temporal information must influence the
distance distribution of the metric space elements, time is
usually a distinct notion from the metric component, so a
feasible alternative is to employ metric-temporal spaces.
The Metric-temporal visualization is based on the metrictemporal space concept, where metrics for both the metric
and the temporal components are defined. The FastMapDB
is first used to estimate the correlation fractal dimension
of the metric and the temporal components to define their
weights in the metric-temporal space. Thereafter, the metrictemporal space is mapped to a 3D space using the FastMap
algorithm, and line segments are used to connect the instances of each element according to the temporal sequence.
To illustrate the notion behind this visualization demands a
metric-temporal dataset, thus it is shown in figures in the
examples section.
Although time is not explicitly represented in any of the
dimensions, this visualization also gives a notion of the
evolution of data in timelines, as time values are inherently
ascending.

B. The ALOI dataset
The second dataset is the Amsterdam Library of Object
Images (ALOI) [16]. It was built photographing one thousand small objects from 72 different viewing angles, each
5 degree apart from the previous. In the experiments, each
angle corresponds to its relative time stamp and the images
were represented by 256 gray-level histograms.
119

a)

Time:

0 ... 45 ... 90 ... 135 ... 180 ... 225 ... 270 ... 315 ... 350 ...

of the Faculty of Medicine of Ribeir˜ao Preto, University
of S˜ao Paulo, Brazil. The extracted features are the volume of plaques, percentage of brain parenchyma, relaxation
times of the white matter, gray matter and plaques, and
the magnetization transfer ratio of the white matter, gray
matter and plaques. Our goal in this example is not to find
medical significance in the visualizations, but to spot the
possibilities that the proposed visualizations can bring to
medical professionals.
Figure 4 shows data of patients with multiple sclerosis during treatment, where each point displayed in the
visualizations represents the feature vector extracted from
one exam. The FastMapDB tool was directed to highlight
the evolutions of four patients, which were diagnosed with
primary progressive multiple sclerosis that is characterized
by a progressive and continuous worsening.
The Timeline visualization (Figure 4a) allows comparing
patient evolutions regarding specific response times to the
treatment, analyzing the patients according to the hyperplanes generated. Analyzing the Space Variation visualization (Figure 4b) it is possible to verify that the “red patient”
presented the highest variation among the four, although
having the total treatment time similar to the “white patient”.
Note that this perception can had be biased by the fact of
the “red patient” has many more instances captured than
the “white patient”. Regarding the Metric-temporal visualization (Figure 4c), as the temporal information influence
the similarity between the elements, it can be noticed that
instances with similar response times were approximated in
the metric-temporal space. For instance, the first measurement of the “white patient” is much closer to the first one of
the “blue patient” than to its own last measurement, which
does not occur in the other visualizations.

obj.: 13
obj.: 8
obj.: 48

b)
time = 350

time = 0

c)
time = 0

obj.: 13

obj.: 8

obj.: 48

time =350

Figure 3. The ALOI dataset. a) Sample object images. b) Timeline visualization highlighting the sample objects. c) Metric-temporal visualization
also highlighting the same objects.

Figure 3a presents a sample of images of 3 objects of the
ALOI dataset. Figure 3b shows images of 50 objects, each
one at 36 different times, using the Timeline visualization,
connecting the sample objects by line segments. Figure 3c
presents images of 10 objects, using the Metric-temporal
visualization, also connecting the sample objects.
It can be noticed in figures 3b and 3c that the trajectory
of object 48 (red) is which presents the lowest variation, and
that of object 13 (yellow) presents the highest variation. This
can be visually confirmed in Figure 3a. Another interesting
observation can be made about the shape of the objects
8 (blue) and 13. The object 8 had its four identical faces
pictured during time (in the moments 0, 90, 180 and 270)
and the object 13 presented two identical faces (moments
90 and 270). This can be clearly seen in the visualizations,
where the mapped features of the four identical faces of the
object 8 are the blue stars, and the two identical sides of the
object 13 are the yellow stars.

V. C ONCLUSIONS
Increasingly new applications have been demanding to
manage and to analyze complex data. Data visualization
methods have been successfully employed to help in such
tasks. The need to analyze how data represented in metric
spaces evolve over time is frequent, thus it is necessary to
develop tools to allow exploring such data.
In this paper we showed that the temporal information
attached to the metric data can be used in varying ways to
achieve different purposes. We presented three interactive
techniques that allow both visual analysis and visually
mining trends on metric time-evolving datasets, enhancing
the perception of how data behave over time. In particular, in
the literature there is not any method similar to the proposed
Metric-temporal visualization, which brings a new way of
treating timed complex data by similarity.
The techniques are complementary and able to handle
metric and high-dimensional data. They were implemented
in the FastMapDB tool and their usefulness was highlighted
through examples with real datasets.

C. The MRI dataset
The third dataset consists of data obtained by quantitative
magnetic resonance imaging exams (MRI) of 120 patients
with multiple sclerosis, provided by the Clinical Hospital

120

a)

b)

c)

Figure 4. Visualizations of the MRI dataset highlighting four selected patients. a) Timeline visualization. b) Space Variation visualization. c) Metric-temporal
visualization.

ACKNOWLEDGMENT

[8] J. B. Kruskal and M. Wish, Multidimensional Scaling. SAGE
Publications, 1978.

This work has been supported by CNPq, CAPES,
FAPESP, STIC-AmSud and Microsoft Research.

[9] R. Johnson and D. Wichern, Applied Multivariate Statistical
Analysis. London: Prentice-Hall, 1982.

R EFERENCES
[10] C. Faloutsos and K.-I. Lin, “FastMap: A fast algorithm for
indexing, data-mining and visualization of traditional and
multimedia datasets,” in SIGMOD Conf., 1995, pp. 163–174.

[1] U. Fayyad and R. Uthurusamy, “Evolving data mining into
solutions for insights,” Commun. ACM, vol. 45, no. 8, pp.
28–31, 2002.
[2] D. A. Keim, “Information visualization and visual data mining,” IEEE Trans. Vis. Comput. Graph., vol. 8, no. 1, pp. 1–8,
2002.

[11] J. T.-L. Wang, X. Wang, K.-I. Lin, D. Shasha, B. A. Shapiro,
and K. Zhang, “Evaluating a class of distance-mapping algorithms for data mining and clustering,” in KDD. ACM,
1999, pp. 307–311.

[3] E. Frank, M. A. Hall, G. .Holmes, R. Kirkby, B. Pfahringer,
I. H. Witten, and L. Trigg, “Weka - a machine learning workbench for data mining,” in The Data Mining and Knowledge
Discovery Handbook. Springer, 2005, pp. 1305–1314.

[12] K. Iswandy and A. Konig, “Improvement of non-linear
mapping computation for dimensionality reduction in data
visualization and classification,” in HIS. IEEE, 2004, pp.
260–265.

[4] E. A. Rundensteiner, M. O. Ward, J. Yang, and P. R. Doshi,
“XmdvTool: Visual interactive data exploration and trend
discovery of high-dimensional data sets,” in SIGMOD Conf.,
2002, p. 631.

[13] J. An, J. X. Yu, C. A. Ratanamahatana, and Y.-P. P. Chen,
“A dimensionality reduction algorithm and its application for
interactive visualization,” J. Vis. Lang. Comput., vol. 18, no. 1,
pp. 48–70, 2007.

[5] R. O. Stehling, M. A. Nascimento, and A. X. Falc˜ao, “MiCRoM: A metric distance to compare segmented images,” in
VISUAL. Springer, 2002, pp. 12–23.

[14] M. Barioni, E. Botelho, C. Faloutsos, H. Razente, A. Traina,
and C. T. Jr., “Data visualization in RDBMS,” in IASTED
ISDB, 2002, pp. 264–269.

[6] A. J. M. Traina, C. Traina Jr., J. M. Bueno, F. J. T. Chino, and
P. M. A. Marques, “Efficient content-based image retrieval
through metric histograms,” World Wide Web Journal, vol. 6,
no. 2, pp. 157–185, 2003.

[15] R. Bueno, D. S. Kaster, A. J. M. Traina, and C. T. Jr., “Timeaware similarity search:a metric-temporal representation for
complex data,” in SSTD. Springer, 2009, pp. 302–319.
[16] J. M. Geusebroek, G. J. Burghouts, and A. W. M. Smeulders,
“The Amsterdam library of object images,” International
Journal of Computer Vision, vol. 61, no. 1, pp. 103–112,
2005.

[7] P. Zezula, G. Amato, V. Dohnal, and M. Batko, Similarity
Search: The Metric Space Approach (Series Advances in
Database Systems, vol. 32). Springer, 2006.

121

