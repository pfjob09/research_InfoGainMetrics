SphereViz - Data Exploration in a Virtual Reality Environment
Marco Soldati, Mario Doulis, André Csillaghy
University of Applied Sciences, Northwestern Switzerland
marco.soldati@fhnw.ch, mario.doulis@fhnw.ch, andre.csillaghy@fhnw.ch

Abstract
We present SphereViz, a novel 3D user interface
for the visual exploration of multi-dimensional data
sets in virtual reality environments. SphereViz builds
on known visualization and search concepts like
RadViz and RelevanceSphere. It combines them with
3D-interaction techniques like World in Miniature for
projection in virtual environments. A prototype
implementation of SphereViz allows to study, on one
hand, the visualization methods of images in 3D space,
and on the other hand, intuitive search methods and
adequate interaction techniques.

1. The SphereViz interface
We present current work on the design of
SphereViz. SphereViz is a new 3D interface for
searching multi-dimensional image data sets.
The 3D interface is designed for virtual reality
(VR) environments. It presents a collection of image
thumbnails in a virtual sphere as outlined in Figure 1.
The position of a thumbnail in the sphere is determined
by a number of parameters. These parameters either
describe image properties such as total intensity, color
proportions, etc, or characterize the image content.
Each parameter is associated with a dimension that
spans the virtual space. As a result the proximity of the
thumbnails gives an indication of the similarity of the
images. The users can interact with the dimensions in
the virtual reality environment. By modifying the way
the dimensions span the space in the sphere, the user
can rearrange the thumbnails and thus explore the
image similarities.

Figure 1. Schematic view of SphereViz.
parameters (ellipsoids) influence the position
of image thumbnails (rectangles)
VR technology has rarely been used for
information visualization, although it would provide
some powerful properties like stereoscopic 3D imaging
in real-time, first person view, and 3D interaction [1]
[2] . One reason for this is the performance restriction
set by current 3D imaging hardware. Even with
efficient data structures it is hard to present large data
sets in VR. But, as VR-systems become more and more
efficient, this should change in the near future.
SphereViz has been implemented as a prototype. It
allows to experiment with using such 3D user
interfaces for information visualization in general. It
serves as a presentation platform and as a test bed for
further development. It also gives us a first impression
of the whole interface.
The prototype has been presented to various
potential users at different stages of the development in
order to get early user feedback. The positive reactions
have motivated us to follow on with this approach.

2. SphereViz prototype implementation
The SphereViz prototype allows to visually search an
arbitrary chosen image archive. The images are
characterized by a multi-dimensional set of parameters.
Each parameter is associated with one dimension. The
main goal is to find yet undiscovered relations between

11th International Conference Information Visualization (IV'07)
0-7695-2900-3/07 $20.00 © 2007

these parameters as well as to group images with
similar properties.
For interaction and visualization we have chosen
VR technology mainly because of the need to
complement traditional visualization techniques in
presentation of a larger amount of images (see Section
3.1). We gain additional value through the advanced
interaction capabilities provided by VR compared to
mouse and keyboard (see Section 3.2).
The visualization and the interaction concepts of
SphereViz base on a combination of already known
techniques that we have optimized for a VR
application. For visualization we use a combination of
the Relevance Sphere [3] and RadViz [4] , for
interaction we use the World In Miniature (WIM)
technique [5] . A more detailed description of these
techniques is given in Section 4.
From a visual point of view, SphereViz presents a
set of 2D thumbnails inside a wire frame sphere. The
thumbnails are implemented as billboards. They
always turn their front side to the users viewpoint.
The algorithm to determine the place of the
thumbnails in the sphere is called Spring-Embedder
Model [6] . Figure 2 shows this principle. Each
parameter dimension is represented as a spring
connecting the thumbnail with a handle on the sphere
surface. The spring applies a given force on every
thumbnail. The strength of the force corresponds to the
thumbnail parameter value in the associated dimension.
The image is placed at the position where the
equilibrium of forces is reached.

Figure 2. Spring-Embedder Model applied to
SphereViz.
Figure 3 shows a snapshot of a photo archive in
SphereViz. The thumbnails are adjusted in relation to
their intension (top), and the amount of red (left at the
back), green (left in front), and blue (right in front)
colors. Images with similar hue are placed closer
together.

11th International Conference Information Visualization (IV'07)
0-7695-2900-3/07 $20.00 © 2007

Figure 3. Photo archive in SphereViz. Greenish
images are placed on the left side, bluish in
the front and reddish at the back
From an interaction point of view, the user can
now walk through the virtual world and inspect groups
of thumbnails or magnify single thumbnails.
Additionally he or she can grab the parameter handles
and move them freely on the sphere surface. This will
cause the thumbnails to be re-arranged in real-time.
This visible movement gives valuable feedback to the
user.
To ease moving handles we introduced a World In
Miniature (WIM). A small copy of the world is
presented right in front of the user. Like with a remote
control the user can move handles in the foreground
while the thumbnails will be re-arranged in the
background. Thus one can avoid to walk the whole
world just to grab two handles.
The photo archive mentioned above has been
implemented as a proof of concept for SphereViz and
serves well for illustration purposes. SphereViz has
also been applied to a scientific image archive
containing images of solar flares. These images have
been recorded by NASA's Reuven Ramaty High
Energy Solar Spectroscopic Imager (RHESSI)
spacecraft [7] [8] . RHESSI provides an archive of
about 60000 automatically generated thumbnails of
solar flares (Figure 4).

Figure 4. Image of a solar flare as recorded by
RHESSI. The image shows only a small part of
the sun.
The content of thumbnails is described with
additional metadata like flare duration, observing time,
location on the sun, or total intensity. These parameters
are used to arrange the thumbnails in SphereViz
(Figure 5).

Figure 5. Thumbnails of solar flares in
SphereViz

have an additional visual depth cue to structure objects
in space. In contrast to 21/2 D representations (in this
case 3D models displayed in 2D), a set of spatially
arranged thumbnails can be seen as a structured cluster,
even if they fill the whole display and cover each other.
Visualized data objects are characterized by three
attributes: size, scale, and distance. They play an
important role for a better understanding of the
displayed data in particular because the objects are
perceived in «natural scale». The design of the
SphereViz prototype allows to experiment with these
attributes. We already learned that the optimal
configuration depends on the problem domain.

3.2. Spatial interaction
For spatial interaction the SphereViz prototype
uses a video-based tracking system. This allows to
track the position of any reference point such as the
users' head or an input device. Users can freely walk in
the virtual world and interact with virtual data objects.
They can control the visualization by natural actions
like grabbing or moving objects. Thumbnails that are
covered by an other object can be brought to the
foreground just by walking around the object. Thus,
the user can focus on his or her main task, without
bothering about input devices.
Spatial interaction concepts are characterized by
three attributes: dimension, position and orientation.
These attributes depend on the users location and on
the input devices. Through the use of the WIM we
have added a way to experiment with these attributes.
A down-scaled hand-held copy of the virtual scene can
be manipulated by hand. When the user rotates or
moves the WIM he or she gets a second viewpoint
without changing the virtual scene. Additionally the
WIM can be used to move the parameter handles on
the sphere surface and thus to change search queries
comfortably without loosing the visual context.

3. Information exploration in virtual
reality

4. Used visualization and interaction
techniques

SphereViz benefits from the advanced spatial
visualisation and interaction methods provided by
Virtual Reality. Spatial visualisation allows presenting
clusters of images in a very user friendly way, spatial
interaction is used for evaluation and searching tasks.
VR increases the legibility of large datasets and
provides more intuitive techniques for browsing
through the data.

SphereViz is a combination of Lyberworld´s
RelevanceSphere, RadViz, and the World In
Minitature (WIM) interaction technique. They will be
briefly discussed in the following sections.

3.1. Spatial visualisation
For visualisation the SphereViz prototype uses
real-time stereoscopic displays. With stereopsis we

11th International Conference Information Visualization (IV'07)
0-7695-2900-3/07 $20.00 © 2007

4.1. Lyberworld's RelevanceSphere
In Lyberworld´s RelevanceSphere [3] a set of
documents is visually presented within a sphere.
Parameter objects, called terms, sit on the sphere
surface and can be used to rearrange the documents.
Therefore, the objects can be moved freely on the

sphere, while the clustering of the documents changes
accordingly.

4.2. RadViz
In RadViz, [4] a 2D visualisation method for high
dimensional data sets, every dimension is represented
as a point on a circle. These dimension points are
equally distributed on the circle. For the layout of the
data points within the circle RadViz uses a spring
embedded algorithm. Every data point is connected to
a dimension point by a spring. Based on a physical
calculation model, the spatial position of each data
point is set to the location where the equilibrium of
forces is reached. Data points with average properties
are located in the centre of the circle, extremes are
placed near the sphere border.

4.3. World in miniature (WIM)
The World in Miniature (WIM) is an interface
technique that uses a virtual hand-held miniature copy
of the immersive virtual scene for visualization and
interaction tasks. In addition to the first-person
perspective offered by a virtual environment, WIM
offers a second dynamic perspective onto the scene.
Objects can be manipulated directly in the immersive
scene or through the WIM.

ways to overcome the mental overload to be of great
interest.
As SphereViz is work in progress, there are also
several plans for further optimization of the interface
concept. Springs can be adjusted to control their
strength and therefore their relevance in the system.
Parameter handles can be moved to predefined
configurations such as being equally distributed on the
sphere surface. Images can be highlighted in order to
track their position while moving the assigned
parameter handles. Image details can be viewed in
high-resolution on a 2D-screen. Finally, SphereViz
will be extended to other types of data sets to become a
general 3D user interface for the exploration of nonimage data archives.

6. References
[1]

[2]
[3]

[4]

5. Conclusions
We presented SphereViz, a novel 3D user
interface for the visual exploration of multidimensional data sets. It bases on well-known data
visualization techniques which have been optimized
for the use with VR. Combined with virtual reality
interaction techniques our approach lead to a new,
intuitive way to interact with scientific data archives.
We see a great potential in using VR for visual
exploration of multi-dimensional data sets and in
particular in SphereViz. Amongst others driven by the
game industry, we expect VR technology to evolve
significantly within the next 10 to 15 years. VR will
allow users to look at and interact with large datasets in
new ways.
Our work focused on the optimization of the
visualization and interaction techniques for the search
task, as opposed to high-performing backend
algorithms and data structures. Taking the Visual
Information-Seeking Mantra into account [9] the
current application covers the zoom and filter and the
details on demand part. In future versions we plan to
extend the WIM to give the overview of all available
data. Next to solving performance issues we expect

11th International Conference Information Visualization (IV'07)
0-7695-2900-3/07 $20.00 © 2007

[5]

[6]
[7]
[8]
[9]

R.S. Kalawsky, The Science of Virtual Reality and
Virtual Environments: A Technical, Scientific and
Engineering Reference on Virtual Environments,
Addison-Wesley, Wokingham, England; 1993.
G. Burdea, and P. Coffet, Virtual Reality Technology,
Second Edition, Wiley-IEEE Press, 2003.
M. Hemmje, C. Kunkel, A. Willett, “LyberWorld - A
Visualization User Interface Supporting Fulltext
Retrieval”, Proc. SIGIR '94, Dublin, pp. 249-259, July,
3-6 1994.
M. Ankerst, D. Keim, D, and H.-P. Kriegel, “Circle
segments: A technique for visually exploring large
dimensional data sets”, Proceedings of the IEEE
Visualization Conference ´96, Hot Topic Session, San
Francisco, CA, USA, 1996.
R. Stoakley, M.J. Conway, R. Pausch, “Virtual Reality
on a WIM: Interactive Worlds in Miniature”,
Proceedings of CHI 95, Denver, Colorado, USA, ACM
Press, New York, 1995, pp 265-272.
P. Eades. “A Heuristic for Graph Drawing”
Congressus Numerantium 42, 1984, pp. 149-60.
J. McTiernan, A. Csillaghy, “The HESSI Data
Catalog”, Abstract #SP42A-02, American Geophysical
Union, Spring Meeting, 2001.
R.B. Lin, et al., “The Reuven Ramaty High-Energy
Solar Spectroscopic Imager (RHESSI)”, Solar Physics,
210, Issue 1, pp. 3-32, 2002.
B. Shneiderman, “The Eyes Have It: A Task by Data
Type Taxonomy for Information Visualizations”,
Proceedings of the 1996 IEEE Symposium on Visual
Languages, IEEE Computer Society, 1996, pp. 336343.

