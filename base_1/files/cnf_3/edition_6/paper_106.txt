Registration of Multiple Laser Scans Based on 3D Contour Features
1st Shaoxing HU, 2nd Hongbin ZHA, 3rd Aiwu ZHANG
1 School of Mechanical Engineering & Automation, Beijing University of Aeronautics and
Astronautics, Beijing 100083, 2nd National Laboratory on Machine Perception, Peking UniversityÀà
Beijing 100871, 3rd Ministry of Education of Key Laboratory on 3D Information Acquisition and
Application, Capital Normal University, Beijing 100037
husx@buaa.edu.cn , zhangaw163@163.com
st

Abstract
When 3D laser scanner captures range data of real
scenes, one of most important problems is how to align
all range data into a common coordinate system. In this
paper, we propose an algorithm of registration of
multiple range data from real scenes using 3D contour
features. Firstly, 3D contour features are extracted using
self-adaptive curve fitting, and a searching structure of
octree is built from the 3D contour features. Secondly,
using mahalanobis distance, the leaf nodes are matched
between two scans to compute original transform matrix,
and then transform matrix is refined step by step through
ICP until a best transform matrix is obtained. Lastly, a
new global registration strategy is given based on the
nearby principle. The experiments of multiple range data
registration from indoor scenes, outdoor scenes and
ancient buildings are done, and the results show the
proposed algorithm is robust.
Keywords---laser scanner, contour feature, mahalanobis distance, matching, registration.

1. Introduction
The technique of laser scanning also called "real
scene reproduction technology", it can directly captures
range data from real scenes, and it is useful in a variety
of fields such as nuclear power plant, cultural relic,
archaeology, architecture, aerospace, aviation, shipping,
manufacture, military, traffic, public security and so on .
The basic processing of laser range data including range
data segmentation, registration of range data, modeling,
and registration is the most key work. At present, range
data registration mainly depends on 5 approaches:
projection approach, target approach, conjugate approach,
external cooperation approach, surface match approach.
Projection approach, for example, Zhao et al. proposed zimage method[1,2], registration is completed using zimage. It reduces the complexity of algorithm, but it fails
to keep the 3D feature, and the precision of registration is
low. Target approach[3], it places the targets in the

Proceedings of the Information Visualization (IV‚Äô06)
0-7695-2602-0/06 $20.00 ¬© 2006

IEEE

overlap region of the neighboring scans, then using laser
reflection characteristics to the targets, the targets are
recognized automatically. Supposed there are three or
more targets in overlap region, we can obtain the
coordinates transform between the neighboring scans.
However, sometimes it is difficult to recognize targets if
there are some regions with the same reflective feature as
targets or angle between laser beam and the target plane
is little small. Conjugate approach[4], by the interactive
way, the plane is formed from points of coplanar (or
close to the coplanar), the coordinate transform is
computed by more than three unparallel conjugate planes.
This method must look for more than three unparallel
conjugate planes in the overlap region, otherwise,
registration fails. The external cooperation approach [5], it
use GPS to help registration. But GPS can‚Äôt accept the
signal where the buildings are high and the avenues are
narrow. Surface match approach[6], if the measured
object has surface with the ups and downs, the
registration can be completed through matching surface
in the overlap region, and surface match can not be fully
automated generally. These problems let us to develop
automatic registration method without any additional
devices.
This paper proposes a fast registration algorithm for
3D large-scale scene using contour features. Firstly,
contour features are extracted using self-adaptive curve
fitting, and a searching structure of octree is built from
the 3D contour features. Secondly, using mahalanobis
distance, the original transform is computed by matching
leaf nodes between two scans, and then transform is
refined step by step through ICP until a best transform is
obtained. Lastly, a new global registration strategy is
given based on the nearby principle.

2. Contour feature extraction
In the section, the direction images (X-image, Yimage, Z-image) are defined based on the scanning
features of laser scanner and the indexes of the laser
points, edges are detected from direction images

respectively, and then the edges are integrated into
contour curves.

2.1. Direction image
We use Cyrax-p2500 to capture range data of the
scene. Seen from the scanning process, the row and
column values of every scan are given according to
accuracy demand before scanning. Laser sampling points
are organised on 2D grid. Every grid point (i, j )
corresponds to 3D point ( x(i, j ), y (i, j ), z (i, j )) , just like
figure 1.
According to the indexes of laser sampling points,
(i, j , x(i, j )) forms X-image, (i, j , y (i, j )) forms Y-image,
(i, j , z (i, j )) forms Z-image. X-image, Y-image, and Zimage are called direction image.

where (i, j0 ) ¬è D(i r n, j0 ) , and it is minimized for
computing the coefficient a0 , a1 , a2 
w(i, j0 ) is weight function, which describe
reliability of each point in the fitting interval D(i r n, j0 ) .
The weight of the reliable point is considered as 1, and
the weight of the unreliable point is assign to very small
value. We choose iterative approach to improve the
weight of every point continuously to eliminate the
effects of outlies.
Supposed the coefficients in the k time are
a0k , a1k , a2k , how the coefficients of the k  1 time
a0k 1 , a1k 1 , a2k 1 is computed? First we calculate fitting
residual error and weight of the k time.
e k (i, j0 ) f (i, j0 )  fÀÜ k (i, j0 )
(3)

XÀÑor Y or ZÀÖ

w

x(i,j)(or y(i,j) or z(i,j))

i

Figure 1: The relationship between
2D grid points and 3D points

2.2. Self-adaptive local fitting
Supposed each scan line can be considered as a
piecewise smooth curve and the points of direction
images are sampling points with noise on these
piecewise smooth curves, then
(i, j0 ) ¬è L(i, j0 ) ( j0 is fixed) Àà We choose an
interval D(i r n, j0 ) , and local quadratic curve fitting is
done.
fÀÜ (i, j ) a  a i  a i 2
(1)
0

1

2

Where, f can be X, Y, Z a0 ,a1 ,a2 is coefficient.
General speaking, the least square method can
calculate coefficients a0 , a1 , a2 Àà but the least square
method is not sensitive to noise and outlies, so if the
fitting interval includes outlies, we cannot obtain the best
fitting results. However, before fitting we cannot
recognize and remove outlies, and the size of the interval
is fixed once the interval is selected. So we employ the
method of self-adaptive curve fitting with weight[11] to
compute the coefficients of the fitting curve because it
only fits the points on the same smooth curve and does
not fit those discontinuous points and outlies.
We define the curve fitting error function as follow,
E (i, j )
f (i, j )  fÀÜ (i, j ) w(i, j )
(2)
0

¬¶

0

0

Proceedings of the Information Visualization (IV‚Äô06)
0-7695-2602-0/06 $20.00 ¬© 2006

IEEE

(i, j0 )

E k (i, j0 ) d bs

¬≠1
¬∞
¬Æ bs
¬∞ E k (i, j )
0
¬Ø

(4)

E k (i, j0 )¬≤bs

where w0 (i, j0 ) 1 
Using (3) and (4) constantly improve the weight of
every point until fitting residual error meet demand.
Meanwhile, these points corresponding very small
weight are considered as outlies and removed.

j

0

k 1

0

2.3. Edge detection
Every point and the points in its corresponding
fitting interval form a curve, and then for the neighboring
points (il , j0 , f (il , j0 )) and (ir , j0 , f (ir , j0 )) , two curves
exist, they are recorded as
fÀÜ (i, j ) a  a i  a i 2 , (i, j ) ¬è L(i r n , j ) (5)
l

0

fÀÜr (i, j0 )

0l

1l

2l

0

l

0

2

a0 r  a1r i  a2 r i , (i, j0 ) ¬è L(ir r n , j0 ) (6)

If a0l  a0 r ¬≤ thresh1 , the neighboring points are
depth discontinuous points;
If a0l  a0 r ¬¢thresh1 , but a0l  a0 r ¬≤ thresh 2 , then
there is a normal discontinuous point between the
neighboring points.
We calculate the point of intersection
(c, j , f ) formed by fÀÜ (i, j ) . If
0

0

l

0

(il , j0 , fÀÜl (il , j0 ))  (c, j0 , f 0 )
ÀÑir , j0 , fÀÜr (ir , j0 ))  (c, j0 , f 0 )

(7)

, then the left point is normal discontinuous, or the right
point is normal discontinuous.

2.4. Edge integration
Using the method described in section 2.2 and
section 2.3 to process X-image, Y-imge and Z-image, we
obtain the edge maps. They describe the discontinuity of
three directions of 3D scene respectively. We fuse the
edge maps to describe contour features of 3D scene.

3. Local registration algorithm

control subdivision. The threshold conditions are given
by the following ways:

According to the principle of octree, we establish a
searching structure of the contour features. Using
mahalanobis distance, an original transform is obtained
though matching the leaf nodes between two scans, and
the transform is refined step by step through ICP until
the best transform is obtained.

1ÀÖDetermine whether each node contains points are
collinear, if they are collinear, stop subdividing.

i th point set g i ; C g i is covariance matrix of i th point

2ÀÖJudge each node contains points are less than the
Max point number, if less than, stop subdividing.
We give the algorithm of octree of the contour
features as follows:
1) Visit all data, derive the smallest cube containing
all points and record information of the cube, establish
root node, then push it to the stack and set it as the
current node.
2) Judge the current node meets threshold conditions
or not, if meeting, the current node is pushed out the
stack. If the stack is not null, the top node of the stack is
set as the current node, and return 2; if the stack is null,
stop. If the current node doesn‚Äôt meet threshold
conditions, return 3.
3) Let the current node divide equally into 8 subcubes
in the three coordinates axis direction, push the subcubes
in stack , add the information related to several subnodes
into current node. Set top node of the stack is the current
node, to 2).

set g i .

3.3. Leaf node matching

3.1. Mahalanobis distance between point sets
Mahalanobis distance is available to define the
distance from any point to a point set. Compared with
Euclidean distance, Mahalanobis distance describes not
only the relative distribution of point sets, but the own
distribution of point sets [8, 9].
Mahalanobis distance between point p and the i th
point set g i is defined as
(8)
m ( p ) ( p  m i ) C g 1 ( p  m i )
i

Where p

( x, y, z )T ; m i is the mean vector of the i

th point set g i , m i

C gi

1
N

N

¬¶P

j

; P j ¬è g i is point vector of

j 1

E[( P j  mi )( P j  mi )T ]

(9)

Mahalanobis distance between two point sets are
defined as
(10)
m(m j , m i ) (m j  m i )C g1i (m j  m i )
In order to keep the generality we remove the
correlation of location and size of point set, matrix A
formed by point set is normalized.
x1 x2  xn
A y1 y 2  y n
(11)
z1 z 2  z n
After normalization
x1c x2c  xnc
Ac y1c y 2c  y nc
z1c z c2  z nc

(12)

zi  z
xi  x
yi  y
Àà yic
Àà zic
Àà
r
r
r
1 n
1 n
1 n
x
xi Àà y
yi Àà z
¬¶
¬¶
¬¶ zi Àà
n i1
n i1
n i1
1 n
r
¬¶ ( xi  x ) 2  ( yi  y ) 2  ( zi  z ) 2
n i1
( x , y , z ) is the center of point set, r is average distance

Where xic

from point ( xi , yi , zi ) to the center in the point set..

3.2. Octree searching structure
The process of establishing octree searching
structure is the process of recursive subdivision of
contour features. Before establishing octree searching
structure, we need to designate the threshold condition to

Proceedings of the Information Visualization (IV‚Äô06)
0-7695-2602-0/06 $20.00 ¬© 2006

IEEE

Leaf nodes of octree contain some contour feature
points. According similarities between a node of scan A
and every node of octree of scan B by Mahalanobis
distance, the corresponding leaf nodes are searched from
top to bottom.
The similarities of the two nodes is defined as
1
(13)
S (m1 , m 2 )
m(m1 , m 2 )
Where m(m1 , m 2 ) is Mahalanobis distance between
two nodes.
k ¬è scanA , k is leaf node, if S (m Ak , m Bl )
max S (m Ak , m Bi ) ! LeapThresh , then leaf node k is
i

similar with leaf node l of scan B. A leaf node of scan A
may correspond to two or more than two leaf nodes of
scan B, we choose one pair of leaf nodes with the largest
similarities.

3.4. Optimal registration
According to the mentioned approach, n pairs of leaf
nodes are matched between two scans. An original
transform can be calculated by the centers of three pairs
of leaf nodes. If n pairs of leaf nodes are composed
according to C n3 , we will get C n3 original transforms.
According to the degree of matching, we do optimal
registration by the following two steps. Here, the degree
of matching is computed according to the number of
matching points.
The first step of optimal registration, contour
features of two scans are transferred into the same

coordinate system by the original transform, then the
degree of matching is calculated and the original
transform which matching degree is more than threshold
MacthThresh1 is recorded. On the basis of them, using
of ICP algorithms, the transforms are improved.
The second step of optimal registration, according to
the improved transforms of the first step, all points of
two scans are aligned into the common coordinate
system, then the degree of match is calculates. The
improved transform of the first step which matching
degree is more than threshold MacthThresh2 is recorded.
On the basis of the first step, ICP algorithm is executed
for all the points.
Finally, the transform which matching degree is
largest is selected as the final transform. If matching
degree of the transforms are equal, the average distance
of corresponding points is calculate, the transform which
the average distance is the most short is employed.
During Optimal registration processing, the value of
threshold is 70% of matching points of the best transform.

4. Global registration strategy
In a typical scanning session, tens and hundreds of
range scans must be registered. What method do we
employ to register all range scans? We developed a
global registration based on the nearby principle. This
method can solve the drawbacks of sequential and
simultaneous strategies. After all overlapping range
scans are put into our system, we first execute the local
registration, and then use the nearby principle to build a
topological graph of global registration. One of scans is
chosen to be the anchor scan S a from the topological
graph, and all other scans S are registered with respect
to the anchor S a based on the topological graph. The
steps of creating the topological graph are showed as
follow:
1) Register all pairs of overlapping scans, compute
transformation Ti [R i , t i ] and degree of registration
g (Ti ) (it is the number of points that are matched).
2) Regard the range scan S i as a node, and regard
1

as connecting weight between two nodes, then a
g (Ti )
weighted undirected graph is created G  V , E ! .
Where V is node, E is edge with weight,
and ei 1
¬èE .
g (Ti )
1

¬è E using MST, create
g (Ti )
MST compute a topological graph GLR . GLR includes all
range scans and describes the best registration path of all
range scans. Figure 2 shows the creating processing of a
topological graph GLR .

3) Based on ei

Proceedings of the Information Visualization (IV‚Äô06)
0-7695-2602-0/06 $20.00 ¬© 2006

IEEE

step0

step1

step2

step3

step4

step5

Figure 2:The topological graph of global registration

5. Results
We tested our methods on scans from indoor scenes,
outdoor scenes and ancient buildings and so on.
A range scan of outdoor scenes include many nonmeasured objects and outlies, it is the best way to test the
registration algorithm. Fig.3a is the image of Shaoyuan
of Peking University. Fig.3b shows contour features,
Fig.3c shows the registration result of a pair of
overlapping range scans. Fig.3d is the global registration
result of 5 range scans. We can see from the figures that
the registration algorithm proposed by us can not only
detect rich contour features but also make many range
scans better together into the common coordinate system.
The most of indoor scenes are more composed of
objects with simple structure, and less noise and outlies,
they are easily registered together in the short time.
Fig.4a and 4b are the registration results of two range
scans of the computer house of scientific information
center of Peking University.
Fig.5a and 5b are respectively the registration results
of two and three range scans of the first rock cave of
Yungang grotto.
Fig.6 employs the global registration method
proposed in this paper to align 12 range scans of Qilin in
the front of office building of Peking University.
From these registration results, they show: we can
obtain perfect registration results from range scans of
ancient architectures, and they test that the registration
method proposed by us is robust and it can be used in the
complex architectures.

4. Conclusion
We have described a fully automated method for the
registration of large-scale scenes. Our algorithm is based
on contour features that reduces complexity of
registration and solve practical problem of registration of
large-scale scenes, the main contributions of this paper
are as follows:
1) Use self-adaptive curve fitting techniques to
extract contour features from range scans so that
registration algorithm is not only adapted to the scene
composed of simple structures, but also adapted to the
scenes composed of complex structures.

(a)

(b)

(c)

(d)

Figure3: The registration results of Shaoyuan of Peking University

(a)

(b)
Figure4: The registration results of indoor scenes

(a)

(b)
Figure 5: The registration results of Yungang grotto

Proceedings of the Information Visualization (IV‚Äô06)
0-7695-2602-0/06 $20.00 ¬© 2006

IEEE

(a)

(b)

Figure 6: The registration results of Qilin in the front of office building of Peking University.

2) Introduce mahalanobis distance to describe the
distribution law of points in the point set.
3) Establish octree searching structure to not only
provide matching unit but also speed up matching.
4) Employ registration mode from bottom to up:
contour features of scenes ƒ∫leaf nodes ƒ∫all points of
scenes, step by step, and avoid falling into local minima.

Acknowledgements
The paper is supported by Program for Innovative
Research Team in University and National Key
Technologies R&D Program (2004BA810B01).




[7]

References
[1]

[2]

[3]
[4]
[5]
[6]

Huijing Zhao, Ryosuke Shibaski. A robust method for
registering ground based laser range images of urban
outdoor objects. In Photogrammetric Engineering &
Remote Sensng, 2001, 67 (10): 1143-1153.
Huijing Zhao, Ryosuke Shibasaki. Reconstructing Urban
3D Model using Vehicle-borne Laser Range Scanners. In
Proc. of 3D Digital Imaging and Modeling,2001, 49~356.
Cyra Technologies: http://www.cyra.com/
Multiple Range Data Set Registration: http://www.cs.unc.
edu/~ibr/projects/multiple/
3D Imaging Sensor LMS-Z420: http://www.riegl.co.at/
Yamany.S.M, Farag.A.A. Surface signatures: an orientation independent free-form surface repressentation scheme
for the purpose of objects registration and matching, In
Pattern Analysis and Machine Intelligence, IEEE
Transactions on, 2002 24(8): 1105 ~1120.

Proceedings of the Information Visualization (IV‚Äô06)
0-7695-2602-0/06 $20.00 ¬© 2006

IEEE

T. Pajdla and L. Van Gool. Matching of 3-D curves using
semi-differential invariants. In 5th International
Conference on Computer Vision, IEEE Computer Society
Press, Cambridge, MA,1995, 390~395.
[8] Xuan Guorong. The Optimal Characteristics of
Mahalanobis distance a feature selection. In Proc of 2th
international Conference Computer and application,
Beijing: CCF and Computer Society of IEEE, 1987(6):
149-191.
[9] Zhang Jumei, Ji Shiming and Li Han. Application of
invariant Theory to Geometry-part Recognition. In
Mechanical & electrical engineering magazine, 1999(5):
62~64.
[10] R.Bergevin, M.Soucy, H.Gagnon, and D. Laurendeau.
Towards a general multi-view registration technique. IEEE
Trans. PAMI. 1996, 18(5):540~547.
[11] D. Huber and M. Hebert. Fully Automatic Registration of
Multiple 3D Data Sets, IEEE Computer Society Workshop
on Computer Vision Beyond the Visible Spectrum (CVBVS
2001), December, 2001

