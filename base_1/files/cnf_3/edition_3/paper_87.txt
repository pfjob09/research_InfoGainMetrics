2009 13th International Conference Information Visualisation

Interaction Techniques using a Spherical Cursor for 3D Targets Acquisition and
Indicating in Volumetric Displays
Masaki Naito, Buntarou Shizuki, Jiro Tanaka
University of Tsukuba
{masaki,shizuki,jiro}@iplab.cs.tsukuba.ac.jp

Hiroshi Hosobe
National Institute of Informatics
hosobe@nii.ac.jp

Abstract
We present several innovative interaction techniques for
3D target acquisition and indication. These techniques
make use of the shape of our cylindrical multi-touch interface, which we are developing as an interface for a volumetric display. Our interaction techniques are used to control a
spherical cursor in 3D space. Notably, our techniques use a
two-handed operation in which the position and size of the
area touched is mapped directly to the position and size of
the spherical cursor. This mapping can instantly determine
the 4DOF of the spherical cursor, i.e., its 3D coordinates
and its radius, and thus allows rapid 3D target acquisition
and indication.

Figure 1. Conceptual image of two users controlling a spherical cursor using our interaction techniques on a CMTI.
to remember. Therefore, our approach differs from others
(e.g., [4]) that use special input devices such as data gloves
or Phantom.
This paper describes innovative interaction techniques
for 3D target acquisition and indication. The techniques use
our cylindrical multi-touch interface (CMTI) [5, 6]1 , which
we are developing as an interface for a volumetric display.
Figure 1 shows a conceptual image of two users examining the 3D model of a complex molecule. The user on the
right uses our proposed interaction techniques to control the
spherical cursor of the molecular viewer to indicate the central part of the model.
The features of our interaction techniques are as follows.
• We use a semi-transparent sphere as a cursor. The
sphere corresponds to the pointer in a traditional 2D
desktop environment.
• We rely on two-handed operation to determine both the
size and 3D position of the sphere simultaneously. The
user can thus control the sphere rapidly. Moreover, because these techniques require nothing more than the
user’s bare hands, our techniques are suitable for use
in public places.
The second of these features is particularly innovative.

1. Introduction
It is useful to be able to select or indicate objects in 3D
space when examining 3D models of objects such as artistic sculptures, ruins, and the structures of DNA sequences
and proteins, and the 3D results of scientiﬁc visualization.
When this is possible, users can use demonstratives in their
discussions, such as “Look at this atom!” or “These will be
too weak.” Moreover, after selecting the objects in the 3D
model, users can easily perform commands to examine the
objects in detail.
A pointer is used in traditional 2D GUIs. To indicate an
object, the user moves the pointer to the object. To indicate
more than one object, the user ﬁrst moves the pointer to the
left top corner of the bounding rectangle of the objects and
drags the pointer to the right bottom corner of the rectangle.
Then the user can also execute some command by doubleclicking or selecting a menu command.
The objective of our research is to develop easy interaction techniques for acquire objects or indicating a 3D area in
3D space. Here, the term easy means that these techniques
do not force the user to wear any special devices, can be
used even in public places, and are simple and thus easy
978-0-7695-3733-7/09 $25.00 © 2009 IEEE
DOI 10.1109/IV.2009.70

1 Our

613
607

web site [5] contains CMTI demonstration videos.

(a)

(b)

based on the concepts involved in the deictic gestures used
in the real world (such as those shown in Figure 2. Suppose that two people are examining a complex molecular
model. If one person wants to indicate a particular small
area (e.g., one atom) of the molecule to the other individual, they would move both hands, as shown in Figure 2,
while saying ”Look at this area!” In contrast, to indicate a
larger area within the molecule, the person would spread the
ﬁngers and use both hands, as shown in Figure 2b.
Note that the two deictic gestures indicated above specify both the size and the position of the target simultaneously. The target’s size is speciﬁed using small or large
hand gestures with both hands, whereas the target’s position
is speciﬁed by arranging both hands symmetrically with respect to the target. Our approach incorporates these intuitive
deictic gestures to specify both the size and the position of
a cursor in 3D environments.

Figure 2. Gestures for pointing to 3D objects
or for indicating 3D volumetric area in the real
world.

In this paper, after a brief review of our CMTI, we
present the basic concepts behind our interaction techniques. We then provide the design and implementation
details of our interaction techniques using the CMTI.

2. CMTI: An interface for a volumetric display
3.2. Semi-transparent sphere as a cursor
Our CMTI[5, 6] is a multi-touch interface for volumetric displays. It allows users to conduct 3D operations for
objects rendered in the cylinder in new ways that are made
possible by the CMTI’s cylindrical shape.
Our CMTI is designed to be used even in public places,
such as museums, for browsing 3D models of artistic sculptures or ruins, and laboratories, for examining 3D data or
the results of scientiﬁc visualization. Therefore, we adopted
the sensing technique introduced by Han [3] to detect points
contacted by the user’s bare hands. The technique uses an
acrylic surface and infrared LEDs. We used an acrylic pipe
600 mm in diameter and 1000 mm high as the basic structure of the CMTI. This size was chosen so that the pipe
would be large enough for an adult to hold. Note that the
structure of the CMTI allows the user to interact with the
device from any direction.
Compared to the hemispherical multi-touch surface [2],
the CMTI is fairly compact in terms of the ﬂoor space it
occupies, because a cylinder has a greater total surface area
2πrh, where r is the radius and h is the height than a hemisphere 2πr2 for h > r.

Our interaction techniques use a semi-transparent sphere
as a cursor. We refer to this sphere as a spherical cursor.
The spherical cursor is always present somewhere in the
cylinder, similar to the cursor in traditional 2D desktop environments. Our techniques enable the user to move the
spherical cursor anywhere in the cylinder.
Moreover, because the spherical cursor has a volume, our
techniques enable the user to scale the spherical cursor to
the desired size. This allows the user to point to adjoining
objects and to indicate a volumetric area, even a blank area,
in 3D space. To execute a command on a group of objects,
the user moves and scales the spherical cursor to contain the
objects, and executes the command from a menu. To point
only to a single object, e.g., one atom in a molecular viewer,
the user scales the spherical cursor to the minimum size and
moves it to the object.
Implementing scaling usually means increasing the DOF
that the user must control. Therefore, it is challenging to
develop interaction techniques for scaling and moving the
spherical cursor easily and rapidly.

4. Design of interaction techniques using the
spherical cursor on CMTI

3. Basic concepts
This section describes the basic concepts of our interaction techniques for pointing to objects or for indicating a
volumetric area using a sphere as a cursor.

This section describes the design of interaction techniques that enable the user to deﬁne the size and the position
of the spherical cursor easily and rapidly, using the shape of
the CMTI.
Our interaction techniques consist of two operations: a
two-handed operation and a one-handed operation. The
most signiﬁcant feature of our design is the two-handed
operation, which allows the user to scale and position the
spherical cursor simultaneously, by directly mapping the

3.1. Real-world gestures for pointing to 3D
objects or for indicating 3D volumetric areas
The design of our interaction techniques for pointing to
objects or for indicating a volumetric area in 3D space is

608
614

(a)

(a)

(c)

(d)
(b)
(d)

(b)

(c)

Figure 3. Size and the position of the spherical cursor in scale&position. The sizes and locations of the two touched areas are mapped
directly to the size and the position of the
spherical cursor, respectively.

Figure 5. Amount and direction of the movement of the spherical cursor in move.

(a)

Figure 4a. In a similar way, the spherical cursor can be
placed in the upper part of the cylinder by touching the
upper surface of the CMTI using both hands, as shown
in Figure 4b.
(b)

move This is a single-handed operation used to move the
spherical cursor from its current position. As Figure 5 shows, the spherical cursor is moved to the
touched area as the size of the touched area shrinks
(Figure 5a → 5c). This operation imitates the action
of a hand grasping a ball. Conversely, the spherical
cursor moves away from the touched area as the size
of the touched area increases (Figure 5c → 5a). More
speciﬁcally, for both these actions, the direction of the
movement is given by the vector between the center of
the spherical cursor and the center of the touched area,
as shown in Figure 5d. The amount of movement is determined by the amount of change in the touched area.
The same action can be repeated two or more times to
move the spherical cursor a long distance.

Figure 4. Sample usages of scale&position.

posture of the user’s hands to the cursor’s size and position.
These two operations are described in detail below.
scale&position This is a two-handed operation to determine both the size and position of the spherical cursor.
In this operation, the size of the two areas touched is
mapped directly to the size of the spherical cursor. As
Figure 3 shows, the radius of the spherical cursor decreases when the sizes of the touched areas decrease.
Therefore, when the user contracts one or both hands
while touching the surface, as if pinching something
on the surface, the spherical cursor becomes small,
as shown in Figure 3a. When the user expands one
or both hands, the spherical cursor becomes large, as
shown in Figure 3b. Moreover, the positions of the
two touched areas are directly mapped to the position
of the spherical cursor. More speciﬁcally, the center of
the spherical cursor is placed midway between the two
touched areas, as shown in Figure 3c and Figure 3d.
Therefore, when the user wants to place the spherical
cursor closer to the user’s body, the user should touch
the near side of the CMTI with both hands, as shown in

Note that the above scale&position can instantly determine four DOF of the spherical cursor, i.e., its 3D coordinates and its radius. The scaling of 3D cursors is usually
problematic because it requires increasing the DOF that the
user must control, but our scale&position is a novel solution to that problem.
Moreover, the combination of the above two operations
on CMTI allows them to be used on a case-by-case basis,
resulting in two distinct advantages. First, the combination
does not force the user to always keep both hands on the
surface; hand contact is required only when the size of the
spherical cursor must be changed. Therefore, when only
the spherical cursor position must be changed, one hand is
free for other purposes. This reduces the burden of our interaction techniques. Second, although both operations can

609
615

Figure 6. Finite state machine used to detect scale&position and move.

(a)

be used for adjusting the position of the spherical cursor,
the user can use scale&position for coarse or large adjustments and move for ﬁne adjustments. More speciﬁcally,
because scale&position relies on a direct mapping between
the positions of the touched hands and the position of the
spherical cursor, scale&position is suitable for coarse/large
adjustments. Moreover, although it is sometimes difﬁcult
for the user to concentrate on adjusting both the size and
position of the cursor simultaneously, the user can use the
single-handed operation for changing only the position of
the spherical cursor. This combination of operations contributes to the usability of our interaction techniques.
Note that the size of touched areas jitters somewhat due
to small involuntary hand movements, producing jitters in
both the size and the position of the spherical cursor. However, because the user can readjust by touching the surface
again immediately after lifting the hands, these jitters do not
cause any serious problems.

(b)

C
r
Figure 7. Image of the CMTI surface touched
by the user’s ﬁngers, and the parameters calculated from the image.
appears after the user continues to touch the same spot on
the surface with one ﬁnger. The menu can be manipulated
with the ﬁnger in the same way that a pull-down menu is
manipulated using a track pad.
Note that the above model allows the user to use the preferred hand for the single-handed operation. This approach
is similar to the order-based approach [1], which assigns
a role to each ﬁnger based on the order in which the ﬁngers touch the surface. In our approach, the user can use
either hand for the single-handed operation, depending on
the user’s position with respect to the surface.

5. Implementation details
Detection of operations
Our interaction techniques use a ﬁnite state machine, illustrated in Figure 6, to make the detection of scale&position
and move robust.
The system consists of four states: None, which is the
initial state; Single, in which the user can use move after touching the surface with one hand (“1st” in the ﬁgure);
Bimanual, in which the user can use scale&position after
the user touches with the second hand (“2nd” in the ﬁgure); and Transient, which occurs after the user raises any
ﬁnger or hand from the surface. In Transient, any ﬁnger
movements are ignored, keeping both the size and position
of the spherical cursor stable. This state is included to prevent unintended changes of the spherical cursor size and/or
position from occurring after the user has set the desired
size and position, because raising a ﬁnger usually involves
changing the positions of other ﬁngers. Commands, such as
editing, can be executed in None, where a pull-down menu

Size and position of the spherical cursor
This section describes the algorithm to determine the size
and position of the spherical cursor in our current implementation.
The size of the spherical cursor is determined by the
hand size, which is r in Figure 7, when scale&position
is executed. Our CMTI uses cameras to detect the user’s
touch on the surface of the cylinder. When the user’s hand
touches the surface, an image, such as that shown in Figure 7a, is obtained from the cameras. The white areas in
this image are the CMTI surface touched by the user’s ﬁngers. The system then calculates the center of gravity of
the touched areas (C in Figure 7b) for each frame. Now,

610
616

(a)

(c)

(e)

(g)

(b)

(d)

(f)

(h)

Figure 8. Photographs of the user using scale&position, one of the proposed interaction techniques,
to control a molecular viewer. (upper) When the user touches the CMTI, (lower) both the size and the
position of the spherical cursor change.

r is the length of the line between C and the point in the
touched area that is farthest from C. The size of the spherical cursor is a linear function of the size of both hands. The
maximum diameter is the diagonal of the bounding cuboid
of the cylinder, enabling the spherical cursor to be enlarged
to cover the area of the whole cylinder. The minimum diameter is a predeﬁned constant.
The position of the spherical cursor is determined by C
and r. When scale&position is executed, the center of the
spherical cursor is placed at the midpoint of the segment
between the two C. When move is executed, C and r are
used to determine the direction and amount of movement,
respectively. Note that the center of the spherical cursor is
kept within the cylinder for move.

User’ s hands

Marker of ARToolkit

Figure 9. Photograph of the image, including
the spherical cursor, seen by the user wearing a video see-through HMD.

of the hands, as if making deictic gestures to point to 3D objects in the real world. Note that because the CMTI allows
operation from any direction, the user can go to any side of
the CMTI to examine any part of the 3D object more closely
(Figure 8g) and touch the CMTI immediately to adjust the
spherical cursor, as if examining some interesting part of a
large sculpture in a museum.
Although, we originally designed our CMTI to be used
with a volumetric display at the center, we are currently testing the proposed interaction techniques using two alternative installations. One uses a sheet of tracing paper pasted
on half of the CMTI surface, which appears as the white
surface of the CMTI in Figure 8a, as a screen for rear projection. The other uses a video see-though HMD. Figure 9
is a photograph of the image, including the spherical cursor,
seen by the user wearing a video see-though HMD. We currently place an ARToolkit marker at the center of the CMTI

6. Testbed system and sample application
To validate our interaction techniques, we implemented a
testbed 3D molecular viewer, which displays molecular data
in MOL format on our CMTI. Figure 8 shows how the user
can manipulate the 3D molecular viewer using our interaction techniques. Note that all of the four photographs in the
upper row of this ﬁgure were taken from the same location.
In these photographs, the user executes scale&position by
touching the CMTI with both hands. When the user touches
the CMTI surface, as shown in Figure 8a, c, e, and g, the
spherical cursor in the molecular viewer changes size and
position appropriately, as shown in Figure 8b, d, f, and,
h, respectively. This demonstrates that the user can set the
spherical cursor size and position by changing the posture

611
617

of our work is that scale&position can instantly determine
four DOF of the spherical cursor, i.e., its 3D coordinates
and it radius, and thus allows rapid 3D target acquisition
and indication.
As future work, we plan to develop a ﬁlter to remove
the jitter of the touched areas caused by small involuntary
movements of the hands. This will make the spherical cursor easier to see during scale&position. We also plan to
place a real volumetric display in the CMTI and to conduct
a formal user study of our interaction techniques.

bottom base, as shown in Figure 9. A camera is attached to
the HMD to track the position of the CMTI relative to the
camera. The user’s view, which is rendered on the HMD,
is constructed by combining the image from the camera,
which includes the CMTI and the user’s hands, calibrated
3D models, and the spherical cursor.
Tests of our interaction techniques indicate that our proposed techniques work well for controlling volumetric displays.

7. Related work
Acknowledgements
The idea of using a semi-transparent volume as a cursor
is generally the same concept as that of the Silk Cursor [10]
and other 3D volume cursors. That is, semi-transparency
provides occlusion cues during target acquisition. There are
some systems, such as the 3D Bubble Cursor [8], that use
a sphere as a cursor. Moreover, many other research initiatives have explored the use of two-handed interactions to
control a volume cursor. For example, two-handed interactions to control a scalable volume cursor have been evaluated [7]. Among the most closely related works is Balloon
Selection [1], in which a spherical cursor above the surface
is controlled by multi-ﬁngered interaction on a ﬂat multitouch panel. Another closely related work is a 3D selection
technique for a volumetric display using the hemispherical
multi-touch surface [2]. In contrast to the above works, we
focused on providing novel interaction techniques for controlling four DOF using both the cylindrical shape and the
multi-touch sensitivity of the CMTI.
Our interaction techniques use a touch panel as its input
device. However, our touch panels are not gesture-based
interfaces like those used in many other interfaces based on
touch panels, such as that described by [9]; these sometimes
force the user to remember a complex command set. Our
interaction techniques require the user only to become accustomed to the mapping between the size and position of
the user’s hands and those of the spherical cursor. Therefore, we believe that our techniques are well suited for use
in public places.

This work was supported in part by the FY2008 Joint Research Grant of the National Institute of Informatics, Japan.

References
[1] H. Benko and S. Feiner. Balloon selection: A multi-ﬁnger
technique for accurate low-fatigue 3D selection. In IEEE
Symposium on 3D User Interfaces 2007, pages 79–86, Mar.
2007.
[2] T. Grossman, D. Wigdor, and R. Balakrishnan. Multi-ﬁnger
gestural interaction with 3D volumetric displays. In UIST
’04: Proceedings of the 17th annual ACM symposium on
User interface software and technology, pages 61–70, Oct.
2004.
[3] J. Y. Han. Low-cost multi-touch sensing through frustrated
total internal reﬂection. In UIST ’05: Proceedings of the
18th annual ACM symposium on User interface software
and technology, pages 115–118, Oct. 2005.
[4] M. Naef and J. Payne. Autoeval mkII - interaction design
for a VR design review system. In IEEE Symposium on 3D
User Interfaces 2007, pages 45–48, Mar. 2007.
[5] M. Naito.
Cylindrical multi-touch interface.
http://www.iplab.cs.tsukuba.ac.jp/
∼masaki/cylinder/.
[6] B. Shizuki, M. Naito, and J. Tanaka. Browsing 3D media using cylindrical multi-touch interface. In Proceedings of the
IEEE International Symposium on Multimedia, pages 489–
490, Dec. 2008.
[7] A. Ulinski, C. Zanbaka, Z. Wartell, P. Goolkasian, and L. F.
Hodges. Two handed selection techniques for volumetric
data. In IEEE Symposium on 3D User Interfaces 2007, pages
107–114, Mar. 2007.
[8] L. Vanacken, T. Grossman, and K. Coninx. Exploring the
effects of environment density and target visibility on object
selection in 3D virtual environments. In IEEE Symposium
on 3D User Interfaces 2007, pages 115–122, Mar. 2007.
[9] R. C. Zeleznik, A. Bragdon, C.-C. Liu, and A. Forsberg. Lineogrammer: creating diagrams by drawing. In UIST ’08:
Proceedings of the 21st annual ACM symposium on User interface software and technology, pages 161–170, Oct. 2008.
[10] S. Zhai, W. Buxton, and P. Milgram. The “Silk Cursor”: investigating transparency for 3D target acquisition. In CHI
’94: Proceedings of the SIGCHI conference on Human factors in computing systems, pages 459–464, Apr. 1994.

8. Summary and future work
We have presented innovative interaction techniques for
3D target acquisition and indication. The techniques use
the shape of our CMTI, which we are developing as an interface for a volumetric display. Our techniques consist of
two operations. scale&position is a two-handed operation
to determine both the size and the position of the spherical
cursor. In this operation, the extent of the two touched areas
is directly mapped to the size of the spherical cursor. move
is a single-handed operation used to move the spherical cursor from its current position. The most innovative feature

612
618

