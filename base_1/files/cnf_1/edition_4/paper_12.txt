Visual Analytics for Complex Concepts Using a Human Cognition Model
1

Tera Marie Green , William Ribarsky1, Brian Fisher 2
1Charlotte Visualization Center
University of North Carolina
at Charlotte

ABSTRACT
As the information being visualized and the process of
understanding that information both become increasingly
complex, it is necessary to develop new visualization
approaches that facilitate the flow of human reasoning. In this
paper, we endeavor to push visualization design a step beyond
current user models by discussing a modeling framework of
human "higher cognition." Based on this cognition model, we
present design guidelines for the development of visual
interfaces designed to maximize the complementary cognitive
strengths of both human and computer.
Some of these
principles are already being reflected in the better visual
analytics designs, while others have not yet been applied or fully
applied. But none of the guidelines have explained the deeper
rationale that the model provides. Lastly, we discuss and assess
these visual analytics guidelines through the evaluation of
several visualization examples.
KEYWORDS: visual analytics, cognition and perception theory,
embodied cognition, visualization taxonomies and models
INDEX TERMS: visual analytics, cognition and perception theory,
embodied cognition, visualization taxonomies and models

1

INTRODUCTION

In a previous paper [1], we discussed the necessity of

considering principles of human reasoning, problem-solving,
and decision-making, in addition to the already familiar areas of
sensation and perception, to develop information and knowledge
visualizations capable of attacking today's complex, important
problems which require both reasoning and analysis. In most
visualization development up to this point, "higher cognition"
processes have been considered as something of a human black
box, into which information is inputted, and from which
appropriate responsive behavior is somehow obtained. (We will
discuss this metaphorical view of human-visualization
interaction during our consideration of the van Wijk operational
model of visualization in Section 4.) But as both interactive
visualizations and their tasks become semantically complex, it
becomes apparent that we must peek into the black box in an
attempt to model a human-computer system and its interactions.
In truth, the black box analogy is an imperfect one for human
higher cognition. Psychology and other behavioral sciences have
•
•
•

Tera Marie Green: grepmon@gmail.com
William Ribarsky: ribarsky@uncc.edu
Brian Fisher: bfisher@sfu.ca

IEEE Symposium on Visual Analytics Science and Technology
October 21 - 23, Columbus, Ohio, USA
978-1-4244-2935-6/08/$25.00 ©2008 IEEE

2School of Interactive Arts and Technology
Simon Fraser University

been researching reasoning and other thought processes for
decades. One reason that much of this research has, as yet, been
unused in the construction of interactive visualizations is the
lack of a unifying theory of human reason. It is, as Newell once
wrote, as if "science advances by playing twenty questions with
nature" [2]. The study of higher cognition is not pursued
holistically; it is usually broken down into bite-sized
subprocesses, and competing theories of small, often binary,
aspects of reasoning have dominated the research.
In addition, holistic "higher cognition," unlike human
sensation and perception, employs combinatorial use of multiple
heuristics, which is rarely binary, almost never perfectly
sequential, and has, as yet, defied traditional model-based
prediction.
But while complex, higher cognition is still predictable to
some degree. The number of available heuristics is finite, and is
therefore theoretically knowable. And while extant research may
disagree on the fine points, it does confirm one essential fact:
humans use the simplest heuristic possible to accomplish the
task at hand. This by itself is no small starting point. But
humans are also predictable in other ways, which we will soon
explore.
This paper endeavours to lay the framework of a human
cognition model, whose guidelines would guide the
development of visual interfaces more able to attack the
complex problems now at hand. Additionally, this paper shows
how this model contributes new, cognition-based principles of
visualization design. Some of these principles are already being
used in the better visual analytics designs, but without the
deeper rationale that the model provides. We will discuss and
evaluate these visual analytics methods. Other principles from
the model have not been applied or not fully applied, and we
will discuss how their implementation and use will be of benefit.

2

COMPLEMENTARY STRENGTHS

Both human and computer bring strengths to a mixed-initiative
visualization, in which both the computer and the human initiate
processes and with which both collaborate in the exploration and
creation of knowledge. Several of the obvious strengths are
complementary, which further strengthens the potential of the
collaboration.
2.1

Human strengths

Some of the earliest reasoning skills humans develop are those
of adaptation and accommodation [3]. Adaptation is the ability
to incorporate newly perceived information into extant
knowledge schema and it relies heavily on an ability to
categorize sensory stimuli at an "instantaneous" rate. Even when
what is perceived is so novel it will not fit existing knowledge
schema, accommodation allows a human to temporarily place a
marker in a closely similar schema or create a new one [4].This
fast and frugal reasoning ability [5] enables humans to more

91

effectively deal with rapidly-changing situations. Biederman's
1987 "recognition by components" model provides a mechanism
by which basic level categorization of objects takes place
rapidly and accurately regardless of viewpoint or changes in
non-essential characteristics of those objects. [6].This all seems
effortless to a human, and allows the reasoning process to move
forward, even when the information is incomplete. It is also
vastly superior to rigid computer recognition; when presented
with what it has not been programmed to recognize, the
computer is stymied, often aborting the process.
Human perceptual abilities are also well adapted to complex
and rapidly changing scenes, defined here as complex sets of
objects and events distributed in space that interact with each
other in often novel ways. This takes place through a
combination of a low-level "gist" mechanism that recognizes
important scene characteristics and relationships [7]. This
preattentive visual process guides the allocation of multiple
attentional tokens i.e. FINSTS, see [8, 9] that support the
automatic calculation of a set of operations [10] on their
properties and relations to each other. All of this occurs prior to,
and in support ot: endogenous attention (attention to the task at
hand). This resulting cascade of processes frees cognition for
consideration of higher order characteristics of the information
contained in the display rather than the display itself -- object
properties and spatial relations with other objects and causal
relations to events taking place. Thus, cognitive operations can
proceed using more parsimonious representations that are wellsuited for the task at hand. This can be thought of as a two-step
process by which unconscious inference, the "logic of
perception", [11] works hand-in-hand with cognitive processes
to support reasoning. In this view, expertise is not only a
characteristic of higher-order cognitive logic, but also of
perceptual logic, which can be trained to better support cognitive
operations through "perceptual expertise" [12].
Partially due to a lifetime of experience in adaptation and
accommodation, humans are also vastly superior reasoners to
computers. Humans have a compendium of reasoning and
problem-solving heuristics, which can be used singly or
concomitantly to accomplish the task at hand. The simplest of
these, elimination heuristics such as satisficing [13], eliminate
available choices that do not possess an identified important
attribute. Elimination heuristics require little cognitive effort,
and so are often what a human will use first in an attempt to
narrow down available choices.
Of course, if the problem becomes semantically complex,
more effort is required. Our model assumes a mental model to
inferred rules mechanization [14], wherein the human uses all
available information to create a mental model of the concept
being considered. From this model, the human infers
generalizable rules - sometimes in a matter of seconds - that are
used in later instantiations of a similar concept or problem.
Because these models are based entirely on available (including
previously held) information, it is imperative that all pertinent
information is available to avoid the creation of incomplete
mental models, which are, in tum, likely to be the basis of
invalid rules.
2.2

Computer strengths

A computer is capable of two distinct processes that
complement human reasoning strengths well: superior working
memory and information processing without cognitive biases.
Humans depend on their working memory as they reason, but
are, at best, able to remember 7 ± 2 chunks of information [15].

92

The computer, on the other hand, has a "working memory"
limited only by hardware. The computer's ability to keep all
pertinent information visually available to the human aids in
complete mental modeling, among other things.
The other computer strength is the lack of inherent biases.
This bias-free environment is, to be sure, influenced by what the
interface is designed to see as relationally relevant. But unlike
humans, computers do not situationally filter out pertinent
information in accordance with a perceived belief or due to the
way a problem is presented [16,17]. By presenting all relevant
information, the computer can aid not only in mental modeling,
but also in the analysis of competing hypotheses.
3

USE OF A HUMAN COGNITION MODEL

This section will discuss the ways in which a knowledge of
higher cognition focuses a mixed-initiative human cognition
model (HCM), as well as provides several guidelines which can
be derived from the model's use. (See Figure 1.) On each of the
HCM's submodels, please see [1] for more discussion.
3.1
Information Discovery & Knowledge Building
The central process of the HCM is discovery, during which the
computer presents information in an ontological-like structure
within a relevant, possibly human-defined, context. Presenting
information with a relevant context is one method of mitigating
human cognitive overload in the midst of an overwhelming
number of semantic data points. The human directly interacts
with the visualized information, focusing the attention of
discovery. We will explore this idea further in Section 5.4.
An intuitive multi-model visualization also encourages
knowledge building through new knowledge creation.
Throughout the process of discovery, the human may uncover a
relationship between two currently unrelated concepts or ideas.
By creating a new relationship between the two concepts and
perhaps annotating the relationship, the human collaborator can
extend the knowledge base of the visualization, not only for
what is to be accomplished in that particular session, but for
every session by every human who uses the visualization
thereafter.
The computer can augment the discovery of relevant
information through computer-aided discovery. Through
observation of what interests the human collaborator, the
computer can suggest information that is semantically related,
but up to this point, has not been considered. This also would
include relational data which has been added by other human
collaborators, which allows one person to learn from another.
The human is free to explore or to reject the suggestion. But by
making the effort in ensuring that nothing important is
overlooked, the computer works to counteract human cognitive
biases which can interfere with complete mental modelling.
3.2 Guidelines for Discovery and Knowledge Building
We will now briefly discuss several guidelines based upon the
HCM discovery and knowledge submodels.
3.2.1

Multiple views

When the information being explored is semantically rich, and
could be visualized through a variety of categorization levels, it
is often left to the discretion of the visualization developer as to
which level merits the primary view. It is important to
categorize information to aid the human in directing attention,

but we would argue that a visualization that utilizes multiple
organizational views of the same information can be a powerful
aid. As the human interacts with information in any view, the
relational changes are visualized in all views.
While the concept of multiple views is not a new one [18],
what we would highlight is how multiple views are informed by
human cognition. First, as humans perceive information in a
variety of ways including through the filter of their own
assumptions, patterns are more likely to be discovered if
represented multiple ways, each tuned to particular, important
aspects of the data.
Secondly, as we have discussed previously, humans prefer to
narrow down the field of choices by eliminating those that do
not posses desired attributes. This is usually done before
utilizing more complicated heuristics. Multiple views make the
process easier; multiple layers of relational attributes are readily
knowable without additional search.
Thirdly, multiple views enable more intuitive manipulation.
Humans themselves do not interact with information in one
dimension; humans are capable of multi-layered processing:
perceptual, emotional, and higher-cognitive. Indeed, of all the
guidelines we will discuss, use of multiple views is the one most
likely to lead to spontaneous insight.
3.2.2

Direct interaction

By definition, a well-designed information visualization allows
the user to directly interact with information. But we would take
direct interaction one step further. In computer-aided discovery,
for example, the guideline of direct interaction would propose
that whatever tactic the computer uses to suggest relational
information to the human be done without interfering with a
human's train of thought or flow of reasoning.
Additionally, direct interaction supports the goals of other
HCM guidelines by facilitating rich, fast, and effective
interaction. The human thinks in terms of the analysis task,
which is closely aligned with the interaction, and then looks at
the visualized results. As a result, the user is more able to stay in
the cognitive zone (as we will discuss shortly), even with
multiple windows.
With this in mind, visualization design should avoid, as much
as possible, menus or other actions that take the user outside of
the frame of the task. Interactions should be through direct
manipulation and translucent wherever possible, avoiding the
traditional pull-down menus, which require the human to sort
through and think about menu items.
3.2.3

Central Role of Interaction

Human-computer interaction is not a series of disjointed
behaviors. And while the visual process is an important part of
visualization, it is not the central role. Interaction has a rhythm,
a cycle of give and take. Interaction is the process by which the
computer and the human give, take, and create knowledge. We
will see an example of this when we will consider the van Wijk
operational model in the next section.
3.2.4

Insulation of Reasoning Flow

One goal of intuitive visualization should be the facilitation of
the flow of human reasoning. Once the human has focused
cognitive resources in an area of interest, the visualization
should not hamper the rhythm of reasoning until the human
chooses to refocus resources elsewhere. This insulation can be

achieved partially through direct interaction within context and
intuitive computer-aided information discovery, as is discussed
elsewhere in this section. Insularity is also aided, where
possible, by an understanding of the temporal constraints of
human perception and patterns of cognitive activity, adapting
the timing of interface events and!or reducing the time required
to retrieve necessary information from interface interaction [33].
Additionally, the process of insuring cognitive insulation would
also encompass any interface process or rendering feature that
has the potential to interfere with rather than inform the
reasoning flow.
In the terminology of the HCM, being in the zone allows the
human collaborator to reason without attentional or cognitive
impediment. And further, when the task becomes crushingly
complex or when the human exhibits functional fixedness in
thought, the computer provides a scaffolding of support,
presenting the information within relevant context, suggesting
what may have been overlooked, and keeping relevant
information present.
3.2.5

Intimate interaction

It is important that the interaction is so translucent to the human

collaborator that the give and take which occurs in a successful
collaboration is seamless. Entering the interaction should seem
natural and obvious. The use of on-screen tools should not
require additional cognitive focus - i.e. be usable without the
human having to "think about it." Intimate interaction deters
attentional interference during the cognitive flow, and enables
the reasoning process to move forward unabated.
When interaction is intimate, what the human should see and
cognitively manipulate is not the tool being used or the method
of interaction, but only the interaction itself: Intimate interaction
is an important asset to flow insulation, and is supportive of the
central role of interaction.
3.3

Search by Example & Search by Pattern

Searching for information has traditionally been done by
stipulating a search term in a text box. But text boxes require
humans to know exactly what to look for (such as in Booleantype queries), as well as to stop where they are in the reasoning
process to look for information in concrete terms. When text box
queries are not ideal, such as work within an information-scent
model [34], we would propose that search be done by
graphically indicating an example to search by, or by drawing a
bounding box around a pattern or other organization of
relational information. In either case, search is done more
intuitively, and reasoning moves forward.
3.4

Creation and Analysis of Hypotheses

One extension of the knowledge building process that holds
great potential for multi-modal visualization is in the creation of
hypotheses. Hypothesis generation can be fraught with human
cognitive bias, as humans are wont to seek out evidence that
proves what they already believe or want to believe. Getting past
these biases can be time-expensive and destructive to the
process.
As Heuer described it [19], hypothesis analysis starts with a list
of hypotheses and a list of evidence that proves or disproves
each one. As the human creates of list of hypotheses, the
computer can aid in finding relevant evidence. From there, the
computer, with its superior working memory, creates a weighted

93

matrix or another relational structure which the human edits
with superior reasoning. Using the edited relational structure, the
human draws conclusions about which hypotheses are correct,
and if desired, sets up a data watch in the visualization which
will notify the user of data changes.
Hypotheses generation is initiated by the human, but the
computer plays a significant role in shortening the process and
neutralizing biases, as contributing to more solid conclusion
through use of its strengths.

4

K(t)

CONSIDERING THE VAN WIJK MODEL

We will now discuss what the implications of our model would
look like if integrated into the van Wijk operational model of the
visualization process [20]. We do this primarily as another way
to envision how a human cognition model interrelates with other
aspects of visualization theory, or as another way to broadly
sketch out the basic assumptions of the HeM within the context
of an extant model.
Van Wijk models the "user" as P (perception and cognition),
K (knowledge), and E (interactive exploration), as is
demonstrated in Figure 2. The user perceives the image (I) and
utilizes the specifications (S) in exploration.
It is difficult, however, to separate "knowledge" from the
reasoning process that created it. A person's knowledge is not
simply a compendium of declarative facts; it is also the
relational or inferential semantic meaning a person gives the
facts, patterns of facts and their relationships, the perceived
worth of those facts, and the ways in which facts are used to
reason about the encounter with future novel information.
Indeed, facts are useless without the reasoning power to
manipulate them, and so we believe that the 'K' submodel, must
include the cognition processes that created it.
Knowledge determines the methods used when new
knowledge is integrated with the old. Van Wijk also seems to
imply this in how he models his "user;" his model pictures
Knowledge feeding Exploration. But K cannot inform E without
the guiding focus of a reasoning process. Indeed, exploration
itselfis cognition in action.
With these thoughts in mind, it might truly be more
representative if Perception, Knowledge, and Exploration were
all modelled as cognitive processes informing each other. We
would see P as the early cognitive processes of selective
attention, categorization, accommodation, including perceptual
logic. (See Section 2.1.) K is viewed as meaningful knowledge
with the use of reasoning, problem-solving and other thought
processes which allow the human to create knowledge, and E as
a focused, interactive cognitive process utilizing both P and K.

data

visualization

user

Figure 2. Van Wijk's model with our integrations in red

94

When viewing the model this way, it's easy to see that two
additional directional arrows need to be added to the model:
from P to E, and from E to K. The first arrow indicates the
important role that perception and perceptual logic plays in
active exploration. The second arrow signifies how a rhythm of
interaction feeds knowledge reasoning. As the human explores
and learns, that learning directs and focuses the attention of
further exploration.
Additionally, van Wijk expressed Knowledge in this way:

=K0 +

r

P(I, K, t) dt

[20]

While this expression does encapsulate the idea that Perception
is a vital part of the process, our integration would express the
creation of knowledge over time more like the following:

K(t)

=K o +

f:

E(P, K, t) dt

where Knowledge is the extension of currently held knowledge
through the integrated perceptual and reasoning cognitive
processes of Exploration.

5

EXAMPLES

In this section, we will demonstrate the model guidelines by
using them to evaluate and/or illustrate several visual analytics
designs. The model, which was not used as a basis for these
designs, provides a deeper understanding of the choices made
and how the designs might be improved. Because we can
discuss the rationale behind them more fully, we present
predominantly designs in which we were developmentally
involved. However, the arguments we make here would also
apply to many other designs.

5.1

WireVis

Discovering financial fraud in the great stream of transactions at
a large bank is a difficult, time-consuming, and expensive
process since it must employ expert analysts and uncover everchanging modes of operation by criminals. The WireVis system
was designed to combine the art of analysis with the science of
visual analytics [21]. WireVis is an expert system, enhancing
insight with what, in the terms of our Knowledge expression in
the last section, is presumed to be the human's already sizeable
Ko; it provides intuitive visual representations of wire
transactions, enhancing P; different views within the system
allow the analysts to gain an overview of all transactions in one
glance, while the ability to drill down into specific details of
individual transactions enables finer examination and scrutiny.
The main interface is shown in Figure 2. A time-based
visualization allows the analysts to detect abnormal temporal
patterns. Search by example permits selection of a particular
keyword or time distribution pattern; the system then finds
patterns that are similar to (or quite different from) the selected
pattern. Finally, a keyword network shows keyword links for the
selected group of transactions (where linked keywords appear in
the same transaction), uncovering relationships that significantly
aid the analyst in picking out suspicious transactions. This
process highlights the importance of E in extending K. Results
of a user evaluation found WireVis to be an efficient, effective
tool, which can discover suspicious patterns in a great mass of
transaction data [21]; the tool is also generally applicable to
other types of transactional analysis.

WireVis has a number of capabilities that conform to the
above cognitive model and highlights some of the design
choices that must be made. Four windows are tailored to
specific, important views and tasks. Though having a single
window to focus the user's attention may be ideal in some
conceptual sense, and there is presumably a cognitive and
perceptual load during task switching, multiple windows seem
necessary for many complex analytical problems [22, 23]. The
key is to minimize the load in order to mitigate the interference
to the human's reasoning flow.
In WireVis, the views were carefully chosen so that
overviews of main aspects of financial analysis were
maintained Linking and brushing between all views was
enacted and immediate update to any interaction was enforced.
(There are not only perceptual but cognitive aspects to
maintaining high interactivity.) In addition, WireVis is designed
to promote "balanced interaction", during which the multiple
interlinked windows act and look like a single interface, rather
than separate entities; changes in one window are reflected
across the interface, allowing the human to focus on the
interaction; and similar types of interaction are supported in all
windows. Thus, various selecting, filtering, and drill-down
(through the transaction hierarchy of transactions) interactions
appear simultaneously in the multiple windows. Further, very
lightweight cursor passover interaction is enabled in several
places (for example, passing over specific keywords). Finally,
direct manipulation is used wherever possible to maintain user
focus. We believe that balanced interaction is an essential design
principle to keep investigators "in the cognitive zone" when
using a multi-window interface on complex problems. With
balanced interaction, the different components of the interface
merge into one cognitive whole where, as one of the papers coauthors remarked, "The interaction is the analysis" [24].
WireVis also has search by example, which has been
singled out in our cognitive model because it is very general and
it keeps the user in the context of her reasoning process without
interrupting it to construct the appropriate search query, which
can quite difficult to accomplish. In this case, the user selects the
keyword or transaction pattern she is thinking about to gather
similar or dissimilar patterns. Search by example has been
considered generally useful in other types of visualization, such
as image analysis [25], broadcast news event analysis [26], and
terrorism event investigation [27]. In fact, we believe that search
by example should be part of any visual analytics interface
involving analysis or reasoning tasks for large amounts of
information.
5.2

Jigsaw

Jigsaw is a visual analytics system used to support investigative
analysis [22]. It works with large collections of reports or other
text documents and with the entities extracted from them. Its
two main goals are to permit investigators to handle efficiently
and move quickly through large document collections and to
support hypothesis formation and evidence gathering. Jigsaw
won the university portion of the VAST 2007 Contest, which
centered on a simulated investigation similar to those carried out
by intelligence analysts.
As with WireVis, Jigsaw makes strong use of multiple
windows with carefully tailored representations for complex
investigative problems.
The user is thought be in an
"information cockpit" with multiple monitors, in front of and
above the user [22]. Jigsaw seeks to maximize pixel use to take
advantage of both the user's high acuity central focus and wide

peripheral field. This is also a valid design point for WireVis
(which requires at least two desktop monitors or a high
resolution cinema display) or any other multi-window system.
However, although Jigsaw has some linking and brushing to
integrate the windows, it does not have the balanced interaction
WireVis employs. Based on the HCM guidelines, we would
expect that users of Jigsaw would be less in the flow and require
more cognitive effort than in WireVis during window
management and connection. This is certainly a point worthy of
further analysis and evaluation.
As a point of contrast, Jigsaw uses a bottom-up approach,
employing an incremental, query-based method to bring in
subsets of data for exploration and possible connection, as
compared with WireVis's top-down visualization of the whole
dataset and its context. Undoubtedly both approaches are valid
and could be available in a general tool for complex problemsolving, and will be the subject of future study.
Finally, Jigsaw is usable and simple. The interface permits
direction interaction with representations of entities and reports,
changing focus and detail. As with WireVis and other tools
described here, simplicity and intuitiveness are not just goals
based on perception principles but also based on the need for
cognitive support. The HCM provides a point of view for
investigating these goals in that light.
5.3

UrbanVis

Urban Vis is a system created to combine views of detailed
geographical information with relational views of associated
abstract information [28]. The geographical view is based on
urban legibility theories in architecture, and the overall system
permits the user to interactively explore an urban environment to
understand the detailed characteristics of a city.
As with WireVis and Jigsaw and for the same general
reasons, UrbanVis is highly dependent upon multiple views,
with a 3D multiresolution map driving the updates of a straight
category view and a parallel coordinates view, giving the user a
rich overview of many categories and relations at once (Figure
3). These views were carefully chosen after consultation with
architects, urban planners, and GIS experts. UrbanVis provides a
general approach to reasoning with the combination of
geographic and abstract data. In addition to the data shown in
Figure 3, we are applying UrbanVis to bridge management data
over city and state regions and are planning to use it for situation
awareness in emergency response. This and the other examples
in Section 5 show the generality of a multi-window approach
that is designed with principles of human cognition in mind.
Users of UrbanVis interact directly with the information,
moving a geographic pointer and highlighting areas of interest
or conversely choosing categories or individual coordinates in
the parallel coordinates view to highlight specific geographic
areas. This makes it easer to discover hidden geographical
patterns for combinations of demographic or other abstract data.
In the same sense as with WireVis, UrbanVis provides balanced
interaction. This combined with direct manipulation, makes
interaction the central focus. In addition, UrbanVis also provides
a top-down, exploratory view with drill down controlled by
simple movement of the ball up and down. The interface has
only one menu, as it strives to keep the user cognitively focused
during problem solving.
Finally, since UrbanVis utilizes the central role of
interaction, the visualization makes E, as defined in Section 4,
the seminal focus. In this interface, designed for a broad cross-

95

section of users, Ko can be small or great, and an attempt is made
through use of color and spatial organization to facilitate P.
5.4

GVis

Although the human is uniquely qualified for "higher order"
reasoning, our human cognition model permits the computer to
support this process in numerous ways. GVis in this section and
SRS in the next provide some of this support. As several of the
visualization approaches utilize similar methods, in these final
sections we will highlight areas that are different from WireVis.
Using information available in public biological databases
such as NCBI, GVis pictures the relationships and publications
known about genomic data (Figure 5) [29]. Due to the detail
inherent in genomic data, the amount of information presently
viewable during drill down in direct interaction becomes quickly
overwhelming; the use of multiple views to visualize multiple
levels of information hierarchies prevents humans from "losing
their place" in the taxonomy. Also, similarly to WireVis, GVis
is an expert visualization, requiring a rather sizeable Ko to focus
effective Exploration. This may mitigate the cognitive overload
effects of information on P and K in Figure 2.
A popup menu allows the user to view and explore
publications on the spheres in the main. view. This is perhaps
not an optimum solution, as use of the menu is not intimate and
can obstruct the field of view, which could threaten reasoning
flow insularity and reduce the value of direct interaction.
The visualization uses color and simple circles to highlight
groups, insulating reasoning flow and focusing P. In addition, it
employs the notion of a stretchable canvas, similar to Pad++
[30], to handle detail at all scales. The latest version of GVis
applies the precepts of knowledge visualization, relying on
taxonomic and ontological representations of genomic
knowledge to determine what to visualize for the task at hand.
When combined with the stretchable canvas, important
knowledge at any scale can be made visible to support the
current reasoning task. Thus, for example, glyphs showing how
many genes are annotated (and what types) are made visible at
the genome or even the cluster level, even though the individual
genes are sub-pixel at these levels. This provides important
support for the human reasoning process.
5.4

Scalable Reasoning System (SRS)

In SRS, Pike et al. demonstrate nicely the capacity of visual

analytics to aid in hypothesis generation and analysis [31]. For
example, while searching by example in SRS is limited to text
searches, queried information can become "reasoning artifacts"
to be used as the basis of hypotheses, or as evidence for
hypotheses represented in "thought chains." The human is free
to manipulate these artifacts directly in a sandbox-like
information space, which encourages reasoning flow insularity
and focuses P as described in Section 4. Additionally, by
allowing the human to arrange artifacts, interaction becomes the
principle objective. While SRS does not use multiple views to
display information, by allowing rearrangement of artifacts, SRS
encourages the human to organize them in a way that is
meaningful to the individual.
Additionally, SRS is more than a display. New knowledge
can be created by creating relationships between reasoning
artifacts. Thus, as the human generates hypotheses and their
evidence, new knowledge that is created during the process is
not lost, either to the current analysis, or to all other humans
who use SRS after its creation. These new relationships are

96

given editable confidence ratings, which aids in the weighing of
evidence in hypothesis analysis.

6

CONCLUSIONS

If we in the visual analytics community are to attain our
aspiration of more effective, more human-perceptive
visualizations, we must begin to understand how humans
manipulate semantically-complex information. It is not enough
to understand what is being seen and given attention. Nor is it
appropriate to infer combinatorial, individually-variable
reasoning heuristics from the more binary cognitive behaviors.
Just as an understanding of perceptual cognition based on
evaluative research have been employed in creation of
information-valuable displays, a competent comprehension of
reasoning, problem-solving, and decision-making must be
employed in the development of mixed-initiative analytical
interfaces.
What we have proposed is not a derived working model, but
is, as yet, a framework of human cognition. Our goal is to sketch
out a system of "thinking about thinking" as a first step to
interface interaction which is no longer just between user and
data, but between human and computer partners, collaborating in
the discovery of information and the creation and extension of
knowledge.
What we have proposed is a model still in its rudimentary
stages, whose future will undoubtedly be marked by additions,
corrections, and multiple series of empirical evaluation. In some
ways, this work still has the emergent expectation and general
outline of an excavation; we cannot pretend to have all of the
answers, but we know we're digging at the right spot.
And yet, it doesn't take a bulldozer to uncover that humans,
like any other thinking system, behave in foreseeable ways.
Thanks to decades of psychological research and some research
in human-computer interaction, we aren't starting from scratch
or relying on anecdotal evidence; we have, at the very least, a
thorough understanding of how the model is shaped and where
to go from here.
We have been able to show extant examples of several of the
HCM's submodels, but there is still work to be done. There are,
as yet, no spontaneous methods of searching by analogical
structure. Computer-aided discovery will require both a better
understanding of learning interfaces as well as a comprehensive
understanding of human iterative thought chaining.
There is also the pesky problem of a unified theory of
reasoning. Understanding the available fragmented research is a
good foundation, but we must approach a more complete
discernment of how all of the pieces work together in an
information space to be better able to define and evaluate the
best ways to insulate reasoning flow, mitigate cognitive load,
facilitate appropriate task switching, and minimize attentional
interference during the reasoning process.
Finally, there is the issue of better understanding of the
temporal coordination of human reasoning and computation and
presentation of information. The temporal dynamics of control
actions and cognitive processing were addressed early in the
history ofHCI with GOMS and keystroke analysis. However the
dynamic coupling of scene gist perception, eye movements,
attentional allocation, cognitive processing and microstrategic
perception/action patterns [32] remains to be explored. Recent
advances in the application of nonlinear dynamical modeling
[33] may provide sufficient predictive validity for incorporation
into models of sensemaking in visual analytics

SEARCH BY EXAMPLE
SBAIICH BY

•

Computer and Human
at Initial State

PATTERN

GENERATION. & ANALVS.SopHYPOTHESES
Het»r.Jr.fU: .. {1fi9l~ofiMlfIlg&nce'~.~O'f1h&~"~

. ··0IAc

Figure 1. The Human Cognition Model (HCM)

Figure 2. WireVis interface: keyword window (upper left), transaction temporal window (lower left), search by example
window (upper right), keyword network window (lower right).

Figure 3. UrbanVis. Relational data (upper left) Strings and Beads view (lower left) Geographic view (right).

97

These tasks are broad items on a bold agenda. But our
evaluation has also uncovered multiple practical problems, and
directed the search for how best to tackle them: what number of
multiple views maximizes the cognitive return on investment,
the best way for the computer to suggest unconsidered
information without interrupting - or annoying - the human at
work, and methods of maintaining the interactive process so as
to keep cognition in the flow, whatever the task. Finally, it is
also clear that there must be strong support for permitting and
managing human annotations. But again, it all starts with daring
to peek into reasoning's black box.

[18]

[19]
[20]
[21]

ACKNOWLEDGEMENTS

This work was performed with support from the National
Visualization and Analytics Center (NYAC TM) , a U.S.
Department of Homeland Security Program, under the auspices
of the SouthEast Regional Visualization and Analytics Center.
Special thanks to Benjamin F. Green for helpful insights.

[22]

[23]

REFERENCES

[1]

[2]

[3]

[4]
[5]
[6]
[7]
[8]
[9]
[10]
[11]
[12]
[13]
[14]

[15]
[16]
[17]

98

T. M. Green, and W. Ribarsky, (2008) "Using a human
cognition model in the creation of collaborative knowledge
visualizations," Proc. ofSPIE Defense + Security 2008,
March 2008, Orlando, FL, (2008).
A. Newell, You can't play 20 questions with nature
and win: Projective comments on the papers of this
symposium. In Visual Information Processing. Chase, W.G.
(Ed). New York: Academic Press. (1973).
J. Piaget, "Piaget's theory" Cognitive development to
adolescence, K. Richardson, and S. Sheldon, (Eds.)
Erlbaum: Hillsdale, NJ, 3 - 18 (1988).
K.L. Komatsu, "Recent views of conceptual structure,"
Psychological Bulletin, 112, 500-526 (1992).
G. Gigerenzer, and D. G. Goldstein, Reasoning the
fast and frugal way: Models of bounded rationality.
Psychological Review, 103 (4) (1996).
I. Biederman, "Recognition by components: A
theory of human image understanding," Psychological
Review, 94 (2), p. 115 -147, (1987).
R.A. Rensink, A dynamic representation of scenes.
Visual Cognition, 7, (2000).
Z. Pylyshyn, Seeing and Visualizing: It's not what
you think, MIT Press/Bradford Books, Cambridge, MA:
(2003).
Z. Pylyshyn, Things and Places. IT Press/Bradford Books,
Cambridge, MA, (2007).
S. Ullman, Visual routines. Cognition, 18, p. 97-159, (1984).
I. Rock. The logic ofperception. MIT
Press/Bradford Books, Cambridge, MA, (1985).
M.J. Tarr, Learning to see faces and objects. Trends in
Cognitive Sciences, 7(1), (2003).
J. Kozielecki, "Elements ofa psychological decision theory,"
Studia Psychologica, 13(1), p. 53-60 (1971).
P. Cherubini, and A. Mazzocco, "From models to rules:
Mechanization of reasoning as a way to cope with cognitive
overloading in combinatorial problems," Acta Psychologica,
16(3), p. 223-243 (2004).
G.A. Miller, "The magic number seven, plus or minus two:
Some limits on our capacity for processing information,"
Psychological Review, 63, p. 81-97.
P.C. Wason, "On the failure to eliminate hypotheses in a
conceptual task ," Quarterly Journal ofExperimental
Psychology., 12, p. 129-140 (1960).
J.St. B.T. Evans, J. Varston, and P. Pollard, "On the conflict
between logic and belief in syllogistic reasoning," Memory
and Cognition, 11, p. 295-306 (1983).

[24]
[25]

[26]
[27]

[28]

[29]

[30]
[31]

[32]

[33]
[34]

M.Q. W. Baldonado, A. Woodruff, and A. Kuchinsky,
"Guidelines for using multiple views in information
visualization." In Proceedings of Working Conference on
Advanced Visual Interfaces, Palermo, Italy, (2000).
R. J Heuer, The Psychology ofIntelligence Analysis Center
for the Study of Intelligence. CIA. (1999).
J.J. van Wijk, "The value of visualization. " IEEE
Visualization, Proceedings ofVis 05, p. 79 - 86. (2005).
R .Chang, M. Ghoniem, R. Kosara, W. Ribarsky, J. Yang, E.
Suma, C. Ziemkiewicz, D. Kern, A. Sudjianto, "WireVis:
Visualization of categorical, time-varying data from financial
transactions." In Proceedings ofthe 2007 IEEE Symposium
on Visual Analytics Science and Technology Sacramento,
CA, October 2007, p.155-162. IEEE Computer Society,
1995.
J. Stasko, C. Gorg, Z. Liu and K. Singhal, "Jigsaw:
Supporting Investigative Analysis through Interactive
Visualization", Proceedings of2007 IEEE Symposium on
Visual Analytics Science and Technology, Sacramento, CA,
October 2007, pp. 131-138
J. A.Wise, J. J. Thomas, K. Pennock, D. Lantrip, M.
Pottier, A. Schur, and V. Crow. "Visualizing the nonvisual: spatial analysis and interaction with information
from text documents." In INFOVIS '95: Proceedings of
the 1995 IEEE Symposium on Information V visualization,
page 51. IEEE Computer Society, 1995.
Private communication, Remco Chang.
J. Yang, J. Fan, D. Hubball, Y. Gao, H. Luo, W. Ribarsky,
and M. Ward,. "Semantic Image Browser: Bridging
Information Visualization with Automated Intelligent Image
Analysis,". Proceedings ofIEEE VAST 2006, p. 191-198.
(2006).
M. Ghoniem, D. Luo, J. Yang, and W. Ribarsky,.
"NewsLab:Exploratory Broadcast News Video Analysis,".
IEEE VAST 2007, p. 123-130, (2007).
X. Wang, R. Chang, R. Kosara, W. Ribarsky, K. Smarick,
and E. Miller, "Investigative Visual Analysis of Global
Terrorism.," (Accepted for publication). EG/IEEE Euro Vis
2008. (2008)
R. Chang, G. Wessel, R. Kosara,
E. Sauda,and W. Ribarsky, "Legible Cities:
Focus-Dependent Multi-Resolution Visualization of
Urban Relationships". IEEE Transactions on
Visualization and Computer Graphics (TVCG) Info Vis
2007, Sacramento, CA, October 2007
J. Hong, D. H. Jeong, C. D. Shaw, W. Ribarsky, M.
Borodovsky, and C. Song, GVis: A Scalable Visualization
Framework for Genomic Data," In Proceedings ofEuro Vis
2005 p.191-198, (2005).
B.B. Bederson, J.D. Hollan, "Pad++: A zooming graphical
interface for exploring alternate interface physics". In: UIST
'94, p. 17-26, (1994)
A. P. Pike, R. May, B. Baddeley, R. Riensche, J. Bruce, and
K.Younkin, "Scalable visual reasoning: supporting
collaboration through distributed analysis," Proceedings
of. International Symposium on Collaborative Technologies
and Systems (IEEE), (2007).
W. D. Gray, and D. A. Boehm-Davis, "Milliseconds
Matter: An introduction to microstrategies and to their use in
describing and predicting interactive behavior." Journal of
Experiment Psychology: Applied, 6(4), p. 322-335, (2000)
M. Spivey, "The Continuity ofMind " Oxford Press,
NewYork, NY (2007).
P. Pirolli, "Computational models of information scentfollowing in a very large browsable text collection,"
Proceedings ofthe Conference on Human Factors in
Computing Systems, CHI '97, Atlanta, GA, (1997).

