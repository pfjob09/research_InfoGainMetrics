Detecting and Analyzing Relationships among Anomalies
VAST 2009 Traffic Mini Challenge Award: Intuitive visual presentation of alibis; best “one-screen shot” of the solution
David Allen, Tsai-Ching Lu, Dave Huber
HRL Laboratories, LLC
ABSTRACT
The HRL Anomaly Analysis Tool was developed as part of the
IEEE VAST Challenge 2009. One of the tasks involved
processing badge and network traffic in order to detect and
identify a fictitious embassy employee suspected of leaking
information. The tool is designed to assist an analyst in detecting,
analyzing, and visualizing anomalies and their relationships. Two
key visualizations in our submission present how we identified the
suspicious traffic using network visualization and how
subsequently we connected that activity to an employee using an
alibi table.
KEYWORDS: Anomaly analysis, social network analysis, VAST
2009, intelligence analysis, information visualization.
INDEX TERMS: E.1 [Data Structures]: Graphs and networks; H.5.2
[User Interfaces]: Graphical user interfaces (GUI)
1

INTRODUCTION

Data is being collected at a rate faster than can be manually
analyzed. Therefore, many domains such as business and the
Intelligence community have experienced a strong need to
automate some of the knowledge extraction and processing tasks
to assist analysts.
As part of the IEEE VAST Challenge 2009, HRL designed and
built the HRL Anomaly Analysis Tool to assist in detecting,
analyzing and visualizing anomalies and their relationships. It
allowed us to quickly detect suspicious traffic and then to connect
that with a suspect.
2

METHODOLOGY

Figure 1 depicts the methodology we followed to analyze the
dataset. It can be summarized by two main steps: 1) identify
suspicious behaviors, patterns, and entities; 2) reanalyze the data
based on this information and begin building a case against the
suspect(s).

Figure 1. Methodology used to process the IEEE VAST Challenge
2009 dataset.

3011 Malibu Canyon Road, Malibu, CA 90265
{dlallen,tlu,djhuber}@hrl.com

2.1
Domain Understanding
We begin the process by learning about the domain and
characterizing the dataset. It is critical for the subsequent analysis
to know information such as: each office had two
computers/workers assigned; that piggybacking into the building
was tolerated (albeit against the rules), but not allowed into or out
of the classified area; and that each computer was assigned to one
person and that no one else should have access to it. Also, we
generate some ‘common sense’ knowledge such as badge swipes
into and out of the classified area should match.
2.2
Visual Data Exploration
We then begin to characterize the data and perform visual data
exploration. The tool’s semi-automated techniques generate
various different visualizations of the data (some of which are
shown in the submission video) which are presented to the user
for analysis.
2.3
Anomaly & Severity Definition
Based on the domain knowledge and visual data exploration, we
identify a set of anomalies which can be automatically detected
and assign a severity to each. For example, having a mismatch in
swipes related to the classified area would be rated “severe”,
while piggyback events are considered “moderate” offenses, and
items that are rare (but valid) that could be part of a much larger
pattern, such as working on the weekends, are considered “mild”
events.
Our automated tool detected 449 anomalies in the dataset, of
which 98 were filtered out for further examination. For each
anomaly, we identify a set of attributes, such as the associated
user or computers, the date/time, etc. Since many have shared
attributes, we next analyze their relationships.
2.4
Network Analysis of Anomalies
In order to better model the relationships and common attributes
between the anomalies, we use our tool to automatically build a
network of the anomalies (Figure 2). We visualize it using a tool
called Pajek [1], which allows the analyst to interactively explore
various layouts, labeling, etc. (the figure depicted uses a KamadaKawai layout algorithm which nicely separates out the various
clusters). Much of the process, such as the layout, is automated;
however once Pajek produces the results the analyst can interact
with it and customize it to their specific task.
In the figure we are interested in looking at the relationships
between anomalies and looking for clusters which can show larger
patterns. A few clusters immediately stand out. First, there is a
large cluster of mild (green) anomalies in the upper left with a
common destination attribute; upon further examination these
turned out to be non-threatening. However immediately below
that is a cluster of 8 severe (red) anomalies with a common
destination, but various different source computers. Another
interesting cluster, to the right of that one, contains three
anomalies related to employee 30 having mismatched swipes
exiting the classified area.

IEEE Symposium on Visual Analytics Science and Technology
October 12 - 13, Atlantic City, New Jersey, USA
978-1-4244-5283-5/09/$25.00 ©2009 IEEE

255

Figure 3. Visualization of the average ratio of
request size to response size for all the destinations.
Figure 2. Network visualization of the detected anomalies (red,
yellow, & green nodes) and their related attributes (blue nodes).

2.5
Collect Evidence & Build Case
After identifying some suspicious activities in the previous
analysis, we next collect evidence and build a case against
possible suspect(s). We begin this process by analyzing all data
sent to the suspicious destination. We specifically focus on the
location of the user and the officemate that are both associated
with the source computers (Based on the domain knowledge, it is
critical to analyze the officemate’s location since employees
should not have access to other’s computers and hence the suspect
would not want to be observed using them.). We note that in all
instances but one both employees were not at their desk (e.g. they
were in the classified area, not in the building, etc.). This
provides further proof that the destination address is suspicious.
We further identify patterns related to this network traffic. For
example, it is always ‘single burst traffic’, in that there usually
was not any network activity prior to it or immediately afterwards.
It also occurred on Tuesdays and Thursdays. Consequently, we
reanalyze the entire dataset for similar patterns and identify 186
such instances; however no other destination had more than two
packets sent to it using this pattern.
Analyzing the ratio of request size to response size yields
another key piece of evidence. To allow for scalability, we group
destinations together; in Figure 3 we immediately see that one
group’s ratio is significantly different in that much more data was
sent to it than was received from it. After examining all the
destinations within that group, it is clear that one destination (the

same one identified above) is the cause of the anomalous ratio and
that the others are normal and can be excluded.
We conclude our analysis by associating a specific employee
with the suspicious network traffic. This is accomplished by
building an alibi table (Figure 4). For each instance of suspicious
network activity, we identify each employee’s location and assign
them an ‘alibi’ if they are swiped into the classified area or are not
in the building (shown as a green square in the figure). We then
total up the number of alibis each employee had for the month and
color coded them such that green shows employees with many
alibis and red shows employees with few or no alibis. In the
challenge dataset only one employee had no alibis and only one
had one alibi: the employee with no alibis also is associated with
multiple anomalies related to swiping out of the classified area in
Figure 2. Therefore we conclude this employee is our prime
suspect and should be investigated further.
3

CONCLUSIONS

Using the HRL Anomaly Analysis Tool we show that detecting
and analyzing the relationships between anomalies is a powerful
analysis tool. This system was able to quickly identify the
suspicious traffic using network visualization and subsequently
built an alibi table to connect the suspicious behavior with
potential suspects. The submission received an award for
“intuitive visual presentation of alibis; best ‘one-screen shot’ of
the solution.”
REFERENCES
[1]

W. de Nooy, A. Mrvar, and V. Batagelj. Exploratory Social Network
Analysis with Pajek, Cambridge University Press, 2005.

Figure 4. Alibi table showing which users have an ‘alibi’ (shown in green) during times of suspicious network activity.

256

