Eurographics Symposium on Rendering 2009
Hendrik P. A. Lensch and Peter-Pike Sloan
(Guest Editors)

Volume 28 (2009), Number 4

Efficient and Accurate Rendering of Complex Light Sources
S. Kniep1 and S. Häring2 and M. Magnor1
1 Technische

Universität Braunschweig, Germany
AG, Germany

2 Volkswagen

Abstract
We present a new method for estimating the radiance function of complex area light sources. The method is based
on Jensen’s photon mapping algorithm. In order to capture high angular frequencies in the radiance function,
we incorporate the angular domain into the density estimation. However, density estimation in position-direction
space makes it necessary to find a tradeoff between the spatial and angular accuracy of the estimation. We identify
the parameters which are important for this tradeoff and investigate the typical estimation errors. We show how
the large data size, which is inherent to the underlying problem, can be handled. The method is applied to different
automotive tail lights. It can be applied to a wide range of other real-world light sources.
Categories and Subject Descriptors (according to ACM CCS): Computer Graphics [I.3.7]: Three-Dimensional
Graphics and Realism—
Keywords: complex light sources, density estimation, photon mapping, position-direction space

1. Introduction
Researchers have put considerable effort into methods for
rendering the illumination of complex light sources [Ash95,
HKSS98, GGHS03, UWH∗ 03], even in realtime [GWS04].
Such methods are sufficient for many scenes and applications, but there is also a range of applications that require to
visualize the light source itself. One example is the virtual
prototyping of automotive tail lights, which we focus on in
this paper. Virtual prototyping of tail lamps is gaining interest in the automotive industry because the lit appearance of
tail lamps has become an important part of the car’s overall
design. The development of tail lamps is complicated and
typically, multiple iterations are needed to find a design that
fulfills the requirements of designers, engineers and executives. Virtual prototyping reduces the need for expensive
hardware prototypes in this development cycle.

Figure 1: Visualization of an automotive tail lamp. The image is composed of two separate parts. One part shows the
radiance that is emitted by the tail lamp, the other contains
a ray-traced visualization of the unlit lamp.

Light that is emitted from a filament (or LED) inside a tail
lamp is often reflected and scattered multiple times before it
leaves the lamp. The surface of the filament is small. This
renders the problem unsuitable for backward raytracing, because only a small fraction of rays will hit the filament before
reaching the reflection limit. Also, classical backward raytracing is not possible if the BRDF of the reflector has a non-

neglectable diffuse component, which is true for the typical
tail lamp. The radiance could be estimated with path tracing [Kaj86], but path tracing is time-consuming for strongly
varying radiance distributions. The flaw of path tracing in

c 2009 The Author(s)
Journal compilation c 2009 The Eurographics Association and Blackwell Publishing Ltd.
Published by Blackwell Publishing, 9600 Garsington Road, Oxford OX4 2DQ, UK and
350 Main Street, Malden, MA 02148, USA.

1074

Kniep, Häring and Magnor / Efficient and Accurate Light Source Rendering

this context becomes obvious if we consider a tail lamp that
contains waveguides. With a waveguide, the number of reflections needed to reach the emitter increases significantly.
In this paper, a method for visualizing complex light
sources is presented which is based on Jensen’s photon mapping algorithm [Jen96]. In a preprocessing step, particles are
traced from the filament through the inner parts of the lamp
until they reach a surface that encloses the lamp. When a particle passes this surface, its position, direction and flux are
saved. A kd-tree is built which allows to select particles depending on their position and direction. The kd-tree is used
to perform a four-dimensional kernel density estimation of
the radiance function. With this estimation, it is possible to
capture high spatial as well as high angular frequencies of
the radiance function. When the kd-tree has been built, it
can be used to create images from arbitrary directions and
distances. Only the efficient density estimation step has to
be carried out again in order to render the light source from
another viewpoint. This is an advantage if animations are
created that show the tail light from different directions and
distances (e.g. in order to present it to the management).

2. Related Work
There exist a variety of methods that deal with the illumination of complex light sources [Ash95, HKSS98, GGHS03,
UWH∗ 03]. These approaches use light field representations
like the two-plane parameterization and interpolation of the
samples which are stored in the light field. We take up the
notion from Ashdown [Ash95] of using a surface which encloses the light source to represent its luminous radiation.
Günther [GWS04] proposes acceleration strategies for photon mapping, which make it possible to render the illumination of complex light sources on diffuse surfaces in realtime.
Benthin has presented a case study on rendering unlit headlights in realtime [BDWS02].
Our method is based on the photon mapping algorithm
[Jen96]. Photon mapping is typically used to compute the
indirect illumination on non-specular surfaces. As the first
step, virtual photons are traced from the light sources
through the scene. Interactions of photons with non-specular
surfaces are stored in a data structure called the photon map.
For each interaction, the flux, position and incoming direction of the photon are saved. After building the photon map,
the contribution of the photons to the reflected radiance on a
surface can be estimated from the photons by kernel density
estimation. This density estimation is based on the k photons
that are closest to the evaluation point x on the surface.
Specular reflections are not saved in the photon map because a photon that is reflected from a specular surface contributes little to the reflected radiance in all but the direction
of the mirror reflection. Hence, the k nearest photons might
have little influence on the radiance that is being estimated.
To estimate directional radiance distributions as they result

from specular reflections or transmissions, the direction of
the photons has to be taken into account in the density estimation. This has been done by Moon and Marschner to
simulate multiple scattering in hair [MM06]. Because scattering in hair often roughly preserves the direction of incoming rays, the radiance function of illuminated hair is highly
directional. This is also true for the radiance function of a
typical tail light.
3. Photon Tracing
Like in the photon mapping algorithm, the first step of our
method is to generate virtual photons at the light sources. For
most tail lamps, the actual light source is the filament of an
incandescent lamp, but LED and fluorescent lamps are also
possible. Each photon has three parameters: flux, position
and direction. The generation of photons for real-world light
sources is described in [Jen01].
The photons are traced through the inner parts of the tail
lamp until they pass a surface that encloses the lamp. This
surface is defined by the user. It is convenient to use the
outer surface of the tail lamp. The tracing process is carried out like in the photon mapping algorithm. At each interaction of a photon with a surface, the photon is either reflected, transmitted or absorbed. Russian roulette [AK90] is
used to choose one of these possibilities. When a particle
passes the bounding surface, its position, direction and flux
at the time of intersection are saved. We employ a commercial software package for the photon tracing which supports
measured light sources.
The set of all photons represents the radiant flux on the
bounding surface. We call this representation the flux map.
The flux map is different from the photon map in some ways.
It represents emitted flux, whereas the photon map represents incoming flux on non-specular surfaces. In the flux
map, directions are saved as 3D vectors of four-byte floating point values. In the photon map, directions are saved as
a two-byte discretization of spherical coordinates.
4. Radiance estimation
In photon mapping, the radiance at x in the direction of ω
is estimated as a function of the flux that is carried by the
k photons that are closest to x. Each flux value is scaled by
the value of the BRDF for the corresponding direction. If
the BRDF has strong peaks, it is likely that only a few of the
photons contribute significantly to the reflected radiance in
the direction of ω, because the value of the BRDF is small
for most directions. This leads to a high variance in the estimate. For this reason, specular reflections are not saved in
the photon map, but are handled by ray tracing instead.
Saving specular reflections in the photon map is analogous to representing a directional radiance function with
the flux map: The radiance function strongly depends on
c 2009 The Author(s)
Journal compilation c 2009 The Eurographics Association and Blackwell Publishing Ltd.

1075

Kniep, Häring and Magnor / Efficient and Accurate Light Source Rendering

the direction of the photons. As pointed out by Moon and
Marschner [MM06], this situation can be handled by taking
the direction of the photons into account in the density estimation. The contribution of a photon to the estimated radiance has to decrease with increasing spatial and angular distance. To accomplish this, a distance function is needed that
represents both – spatial and angular distance. Moon uses a
weighted maximum of the spatial and angular distance.

4.1. Distance in position-direction space
We choose an euclidean metric to measure the distance in
position-direction space. Let
d(p, q) =

x p − xq

2 + (λ

ω p − ωq )2 ,

d(p, q) continuously grows with the spatial distance and
the angle included between p and q. This ensures that the
estimated radiance function is smooth if the kernel function
is smooth. Photons with a high spatial but low angular distance may have the same d-distance as photons with a high
angular but low spatial distance.
The error of the approximation (ω p , ωq ) ≈ ω p − ω p
grows with the angle (ω p , ωq ). For an angle of 10◦, the
relative error of the approximation is less than 0,15%. In our
tests (see section 6), this value was never exceeded. Also,
this error does not necessarily lead to an additional error in
the density estimation. The approximation can be seen as a
slight deformation of the kernel function. The actual shape
of the kernel function has little influence on the error of the
density estimation [Sil86].

4.2. The kernel function
The kernel is a weighting function that is applied to the vector difference between the evaluation point (x, ω) and the
photons within the bandwidth. The kernel function should
be smooth and fast to evaluate. The smoothness property is
important because discontinuities in the kernel might lead to
visible artifacts (as observed for photon mapping in [Jen96]).
The above requirements are met by the Epanechnikov kernel
(see e.g. [Sil86]). Let K be the 6-dimensional Epanechnikov
kernel without its normalization factor:
1 − xT x
0

if xT x < 1
otherwise.

H = diag(h, h, h, h/λ, h/λ, h/λ).

(2)

c 2009 The Author(s)
Journal compilation c 2009 The Eurographics Association and Blackwell Publishing Ltd.

(3)

For each evaluation point (x, ω), h is set to the distance between (x, ω) and its kth nearest neighbor. λ is the weighting
factor from equation 1. The centered and scaled kernel can
be written as
K p (x, ω) = K H −1

(1)

be the distance between two points p = (x p , ω p ) and q =
(xq , ωq ) in position-direction space, with a denoting the
magnitude of the vector a. The angle between ω p and ωq
is approximated by the magnitude of the vector difference
between ω p and ωq . The direction vectors are multiplied by
a weight factor λ ≥ 0 to control the relative importance of
spatial and angular distance. The influence of the angular
distance on d grows with λ. In the following, the distance
d(p, q) between two points is called their d-distance.

K(x) =

This kernel can be applied directly to the points in positiondirection space. To center the kernel at the photon p =
(x p , ω p ), it has to be applied to the vector difference between p and the point of evaluation (see below). To control
the size of the kernel, the vector difference is multiplied with
the bandwidth matrix

x − xp
ω − ωp

.

(4)

In K p (x, ω), the distance term xT x from equation 2 becomes
H −1

x − xp
ω − ωp

T

H −1

x − xp
,
ω − ωp

(5)

which is the squared d-distance between (x, ω) and (x p , ω p ).
By scaling the vector difference with H, we have adjusted
the kernel to the distance function d.
The kernel has to integrate to one to ensure that the integral over the estimated radiance function equals the radiant flux which is stored in the flux map. This can be
achieved by multiplying the kernel with a normalization factor m. Note that the normalization factor of the 6D Epanechnikov kernel cannot be used as m because it makes the kernel integrate to one in 6D euclidean space, rather than in
4D position-direction space. In Appendix A we show that
m = 6λ2 /(π2 h4 ). Interestingly, m equals the normalization
factor of the Epanechnikov kernel for 4D euclidean space.
Multiplying K p with m yields the normalized kernel for
position-direction space
K p (x, ω) =

6λ2
x − xp
K H −1
ω − ωp
π2 h4

.

(6)

To make sure that the angular bandwidth does not exceed
180◦, we require that h ≤ 2λ.
A second condition for the correctness of the flux integral is that the bandwidth of each photon is fixed. This is not
the case if h depends on the neighbors of (x, ω). We have experimentally analyzed the resulting error for known radiance
distributions (combinations of gaussian, cosine and uniform
distributions) by numerical integration of the estimated radiance function. Our result is that the error has the same order
of magnitude as bias and noise. However, if the correctness
of the flux integral is crucial to an application, another kernel
estimator (see [Sco92]) has to be chosen.
To estimate the radiance at (x, ω) from the flux map, the
kernel from equation 6 is applied to the k photons that are
nearest to (x, ω). The sum of the kernel values multiplied
with the flux of the respective photons is an estimate of the

1076

Kniep, Häring and Magnor / Efficient and Accurate Light Source Rendering




x



(a)

(c)

(e)

(b)

(d)

(f)

x

Figure 2: An example of locating the five nearest neighbors
of (x, ω) with two different bandwidth ratios. Top: λ is small,
so the spatial bandwidth is also small and the five nearest
neighbors (shown black) lie close to x. Bottom: λ is large,
so the angular bandwidth is small and the directions of the
nearest neighbors are very similar to ω.

radiant flux density at (x, ω). Dividing this value by the cosine of the angle between ω and the surface normal nx gives
an estimate of the radiance at (x, ω)
˜ ω) =
L(x,

1
(nx · ω)

k

∑ Kp (x, ω)Φ p ,

(7)

p=1

Figure 3: A synthetic radiance function and error plots for
two estimations of this function with a fixed number of nearest neighbors but different bandwidth ratios. (a) shows a
slice of the synthetic radiance function with a fixed direction.
(b) shows a slice with a fixed position, the radiance is plotted on the hemisphere of directions at this position. The plots
(c) and (d) show the error of the estimation with λ = 0.5 for
the same slices. Red indicates overestimation, blue indicates
underestimation. (e) and (f) show the error of the estimation
with λ = 20. Due to the increase of λ, the main source of
the error moves from spatial noise (c) to spatial bias (e) and
from angular bias (d) to angular noise (f).

where Φ p is the flux of the photon p. Like in photon mapping, a maximum bandwidth hmax is imposed to speed up
the search.

angular bias
✻

spatial bias

spatial noise

angular noise

k
4.3. The bandwidth ratio

✲
Consider the photon p = (x p , ω p ) and the evaluation point
˜ ω) iff x − x p < h.
(x, ω). If ω p = ω, p contributes to L(x,
This follows from the definition of the kernel. If x p = x, p
˜ ω) iff ω − ω p < h/λ. This means that
contributes to L(x,
the maximum possible spatial bandwidth is h and the maximum possible angular bandwidth is h/λ. For convenience,
we refer to these parameters just as the spatial and the angular bandwidth. λ is the ratio between the spatial and the angular bandwidth and controls the relative amount of smoothing in the spatial and in the angular domain.
If λ is small, the angular bandwidth is large. The spatial
bandwidth also depends on λ. For a small λ, the set of the k
nearest neighbors contains more photons that lie close to x
spatially than for a larger λ (see figure 2). This means that
the spatial bandwidth increases with λ. Thus, if λ is small,
the angular bandwidth is large and the spatial bandwidth is
small. This may result in angular bias and spatial noise. We
employ the term angular bias for a kind of bias that appears
˜ ω) if x is fixed and ω changes. Similarly, spatial noise
in L(x,
˜ ω) if ω is fixed and x changes.
is the noise that appears in L(x,
If λ is large, the angular bandwidth is small and the spatial
bandwidth is large. This may result in spatial bias and angu-

λ
Figure 4: Schematic diagram of how the tradeoff between
bias and noise can be controlled by k and λ.

lar noise, which are defined analogously. See figure 3 for an
illustration of these effects.
Just like k controls the overall tradeoff between bias and
noise, λ controls the tradeoff between spatial bias and angular noise on one side and spatial noise and angular bias
on the other side (see figure 4). To achieve a good tradeoff between spatial and angular errors, spatial and angular
frequencies of the radiance function have to be taken into
account when selecting λ. The more high-frequency components are contained in the angular domain, the larger λ
should be (assuming a fixed spectrum in the spatial domain).
Since the frequency spectrum of the radiance function is not
known, we need to determine λ empirically by varying its
value and comparing the results. This needs to be done once
for each tail light.
The distance l between the camera and the tail light also
c 2009 The Author(s)
Journal compilation c 2009 The Eurographics Association and Blackwell Publishing Ltd.

Kniep, Häring and Magnor / Efficient and Accurate Light Source Rendering

should be taken into account when selecting λ. This is due
to the constellation of the six-dimensional evaluation points
that result from a certain distance l. Let us assume that the
evaluation points are determined by a ray tracer. Each ray
that intersects the bounding surface of the tail lamp defines
an evaluation point (x, ω), with x being the intersection point
and ω being the inverted direction of the intersecting ray.
The larger l, the further apart from each other are the intersection points. And the larger the distance between two
adjacent evaluation points, the larger is the possibility that
the photon density differs significantly from one point to the
other (which is perceived as spatial noise). This effect can
be counteracted by increasing the spatial bandwidth with the
spatial distance between the evaluation points. This in turn
means that λ has to be increased with l.
The situation is similar in the angular domain. Imagine
that the camera is rotated around the tail light in an animation. The larger the rotation angle α of the camera between
two successive images, the larger is the risk of angular noise.
Angular noise can be seen as random differences between
the two images that show the tail light before and after rotating the camera. To reduce this kind of noise, the angular
bandwidth must be increased with α. The expected value of
α depends on l. The smaller l, the larger is the change of
α that results from a fixed-length movement of the camera.
This means that we can expect a larger change of α if l is
small. Consequently, the angular bandwidth should be increased when l becomes smaller. This also amounts to the
above finding that λ should be increased with l.
Note that the parameters which control the image formation in the human eye depend on l in a similar way. With
growing l, the surface area of the tail lamp that shines on a
single rod becomes larger. This corresponds to a large spatial bandwidth. With decreasing l, the direction range of light
rays that may enter the pupil (and hence may hit a rod) becomes larger. This corresponds to a large angular bandwidth.
We have tried to derive the relationship between l and λ
from a simple model of the human eye. Our results are that λ
should be proportional to l 2 . It turns out that in practice, this
relationship results in extreme values for λ, which lead to
biased and noisy estimations. For this reason, we have varied
the influence of l and compared the results visually. Good
results were achieved if λ is proportional to l 0.7 . For the sake
of lower bias and noise, we refrain from implementing the
relationship that is derived from the image formation in the
human eye.
Let λ0 be the bandwidth ratio that has been adjusted to the
spatial and angular frequencies of a certain radiance function
at the distance l0 . Define
c0 = λ0 l0−0.7

(8)

to be the bandwidth factor for this particular radiance function. For any other values of l, we employ the equation
Λ(l) = c0 l 0.7

(9)

c 2009 The Author(s)
Journal compilation c 2009 The Eurographics Association and Blackwell Publishing Ltd.

1077

to determine λ. We have observed that for λ ∈ [20, 600], the
estimate is often noisy and biased. For this reason, we restrict
λ to the range [20, 600]. In a test scene, we have chosen λ =
30 for l0 = 76.4 cm by visual comparison, which results in
c0 = 1.44 cm−0.7 . In an animation of this scene, Λ(l) ranged
from 27.6 for l = 67.7 cm to 82.6 for l = 324.4 cm.
If the above heuristic is used, λ has to be tweaked only
once for a particular tail light. If more images of the same tail
light are computed from different distances, e.g. for creating
an animation, reasonable bandwidth ratios can be computed
automatically for each l.
4.4. Locating the nearest neighbors
To evaluate equation 7, the k nearest neighbors of the evaluation point (x, ω) have to be located in the flux map. We use
a six-dimensional kd-tree for this search. If λ is fixed, standard algorithms can be used to locate the nearest neighbors
in the kd-tree. Each photon p = (x p , ω p ) is represented as
the six-dimensional point
xp =

xp
.
λω p

(10)

To avoid the computation of square roots, only squared distances are used in the search routine (as suggested by Sproull
in [Spr91]). The squared distance between two points x p and
xq is (x p −xq )T (x p −xq ). This is the squared d-distance of p
and q, which can be plugged directly into the kernel formula
(equation 4).
To locate the nearest neighbors, we employ the search algorithm by Arya and Mount [AM93] without the approximation that is described in their paper. Any other kd-tree
algorithm could be used, our choice is due to efficiency reasons. Arya’s algorithm visits only the tree cells that intersect
the hypersphere which is centered at the search point. This
approach improves the speed of the search in higher dimensions. Earlier search algorithms [Ben75,FBF77] also confine
the search to the hypersphere, but require that the boundaries
of each tree cell are stored in the kd-tree. The approach proposed by Arya and Mount removes this requirement by computing the boundaries of the tree cells incrementally from the
splitting values.
To reduce memory consumption, the tree is stored as an
array (see Jensen’s book [Jen01]). However, this representation requires left-balancing the tree, which restricts the splitting value to a small range. As the splitting dimension, we
choose the one with the largest cell extent.
4.4.1. Changing the bandwidth ratio
As noted in section 4.3, it might be necessary to adjust λ
to the distance between the observer and the tail light. To
prevent that the tree has to be built again when λ changes, the
tree points can be scaled during the search. Suppose that the
i-th coordinate of each tree point is multiplied with a fixed

1078

Kniep, Häring and Magnor / Efficient and Accurate Light Source Rendering

value si . If the splitting values of the tree nodes with splitting
dimension i are also multiplied with si , the inclusion of tree
points in tree cells is not affected, i.e. the tree stays valid.
Each dimension can be scaled with a distinct value si . In
the following, this scaling of tree points and splitting values
during the search is referred to as online scaling. In order to
search for the nearest photons according to their d-distance,
the scaling factors for the three angular coordinates are set
to λ. The spatial coordinates need no scaling.
Online scaling affects the speed of the search. The cost of
the additional multiplications can be neglected (see section
6). A more critical effect of online scaling is that it changes
the aspect ratio (the ratio of the longest to the shortest side)
of the tree cells. As pointed out by Duncan et al. [DGK99],
the aspect ratio has significant impact on the efficiency of
the search. The aspect ratio should not be too large, i.e. it
should be bounded. However, bounding the aspect ratio is
not possible in a left-balanced kd-tree because the splitting
value is restricted to a small range.
Still, the aspect ratio can be influenced by the choice of the
splitting dimension. In our implementation, the dimension
with the largest cell side is chosen for splitting. This keeps
the aspect ratio of the unscaled cells as small as possible (in
a balanced tree). The aspect ratio of the scaled cells might
exceed the aspect ratio of the unscaled cells by a factor of λ.
This may slow down the search significantly (see section 6).
To counteract this effect, the direction vectors of the photons
are multiplied with a value λ t before the tree is constructed.
λ t should be close to the bandwidth ratios that actually will
be used and has to be chosen empirically. During the search,
the variable value λv is used for online scaling. The resulting
bandwidth ratio is λ = λ t λv . If it turns out that the initial
ratio λ t differs strongly from the actual λ, the tree can be
reconstructed with λ t = λ.
5. Implementation
To estimate a four-dimensional function like the radiance
function on a surface, a large number of data points (photons) are needed. The kd-tree might not fit into main memory. For this reason, we have implemented a kd-tree that
arranges the photons on secondary storage. Only the inner
nodes (the splitting dimensions and the splitting values) are
kept in main memory permanently. During the search, small
subtrees are loaded to main memory on demand. The least
recently used subtree is unloaded if a user-defined memory
limit is reached. The amount of main memory that is used
for the tree construction can also be limited.
To further reduce the consumption of main memory, the
bucket size (the number of photons that are stored in a leaf
node) can be increased. By doubling the bucket size, the
number of inner nodes is halved. However, the search slows
down if the bucket size is too large (see Friedman et al.
[FBF77]). Because the tree is stored as an array, the bucket

size needs to be a power of two. For large trees, we have
achieved good results with 32 photons per bucket. With this
choice, the inner nodes of a kd-tree with 108 photons occupy
less than 16 MB.
To apply our method in practice, the evaluation points
have to be determined and mapped to pixel positions within
the image. This can be done via ray tracing. When a ray
intersects the enclosing surface which was used for photon
tracing, the ray tracer returns the intersection point x and the
direction ω of the intersecting ray, which then is inverted
and scaled to length λ t . (x, ω) is used as the six-dimensional
query point for the kd-tree search. Equation 7 is used to estimate the radiance.
6. Results
We have applied our method to the Volkswagen Touran and
Touareg tail lamps. The reflector of the Touran tail lamp contains many small bumps that result in high frequencies in the
radiance function. The reflector of the Touareg tail lamp is
smoother, hence its radiance function contains less high frequencies.
Figure 5a and 5b show the upper part of the Touran tail
lamp, 5c and 5d show its lower part. The Touareg tail lamp
is shown in 5e and 5f. Table 1 lists parameters and performance results for these scenes. 600 MB of main memory
were used for building the tree, 500 MB were used for rendering. The images contain 640 × 480 pixels, all renderings
were carried out on a Pentium M processor with 1.7 GHz.
The photon tracing was performed on a 2 GHz Opteron processor with four cores. In all tests, the maximum bandwidth
was restricted to 4, the bucket size was set to 32.
Note that although the flux map of the Touareg contains
fewer photons than the flux map of the Touran, we have chosen a larger number of nearest neighbors k for the Touareg
than for the Touran. The reason for this choice are the high
frequencies in the radiance function of the Touran lamp. If a
larger k is used for the estimation of the Touran tail lamp, the
small bright spots on the reflector (see figure 5) appear blurry
due to bias. On the other side, a rather large k is necessary to
reproduce the smooth radiance function of the Touareg lamp
without too much noise.
To verify the correctness of our estimation scheme, we
compare the result of our method for the Volkswagen
Scirocco tail lamp to a path-traced image in figure 6. Both
images show the same basic features of the lamp’s radiance
function. The comparison to the bias-free reference image
shows that the flux map estimation contains visible bias. Areas with low radiance appear smooth in the flux map estimation. In the path-traced image, these areas contain more
noise, although it was rendered with 16,000 paths/pixel (almost five billion rays), which took 32 hours on a quadcore
Opteron processor. The density estimation took 85.6 seconds
on a Pentium M with 1.7 GHz, additional 10.5 hours were
c 2009 The Author(s)
Journal compilation c 2009 The Eurographics Association and Blackwell Publishing Ltd.

1079

Kniep, Häring and Magnor / Efficient and Accurate Light Source Rendering

(a)

(b)

(c)

(d)

(e)

(f)

Figure 5: Visualization of different parts of the Touran and Touareg tail lamps from different camera positions.
Scene

# Photons

a
b
c
d
e
f

129 mio
129 mio
176 mio
176 mio
39 mio
39 mio

Tree size
on disk
3.5 GB
3.5 GB
4.8 GB
4.8 GB
1 GB
1 GB

Photon tracing
time
261 min
261 min
473 min
473 min
46 min
46 min

Tree building
time
49.9 min
49.9 min
80.9 min
80.9 min
9.3 min
9.3 min

k

λ

20
20
20
20
100
100

80
80
80
80
30
30

Rendering
time
69.6 sec
68.0 sec
75.3 sec
83.7 sec
73.0 sec
81.0 sec

# Evaluation
points
251,597
233,148
228,647
244,476
102,122
85,534

Table 1: Parameters and performance results for the Touran and Touareg scenes. The images contain 640 × 480 pixels, all
renderings were carried out on a Pentium M processor with 1.7 GHz.

needed for photon tracing and for building the tree (which
contains 160 million photons). In order to produce an image
from another viewpoint, just the density estimation part has
to be carried out again. The same commercial software has
been used for path-tracing and photon-tracing. Note that this
software is much slower than current ray tracers, it has been
used because of technical restrictions.
To test the effects of online scaling on the search speed,
we have rendered the Touran scene from figure 5a with different bandwidth ratios, using the same tree with λ t = 80
most of the time. Table 2 shows the results of this test. Note
that the rendering times for λ = 79 and λ = 81 with online
scaling are virtually the same as for λ = 80 without online
scaling. This shows that the additional multiplications have
little impact on the search speed. The tree with λ t = 80 allows efficient searches for a broad range of bandwidths. A
tree with λ t = 8000 results in smaller rendering times than
a tree with λ t = 80 for λ = 8000 (see section 4.4.1). A tree
with λ t = 0.8 performs only slightly better than the tree with
c 2009 The Author(s)
Journal compilation c 2009 The Eurographics Association and Blackwell Publishing Ltd.

Figure 6: A path-traced image of the Volkswagen Scirocco
tail lamp (top) and an image of the same scene that has been
generated with our method (bottom).

1080
λ
0.8
0.8
16
40
79
80
81
160
400
8000
8000

Kniep, Häring and Magnor / Efficient and Accurate Light Source Rendering

λt
0.8
80
80
80
80
80
80
80
80
80
8000

Online scaling
no
yes
yes
yes
yes
no
yes
yes
yes
yes
no

Rendering time
335.6 sec
383.1 sec
261.2 sec
126.7 sec
141.0 sec
141.5 sec
141.6 sec
170.8 sec
221.1 sec
818.6 sec
158.2 sec

Table 2: Rendering times of the Touran scene from figure 5a
with different bandwidth ratios.

λ t = 80 for λ = 0.8. The rendering times are higher than in
table 1 because we have used a rather large maximum bandwidth in order to prevent any influence of this parameter.
To generate an image of a tail lamp with different colors like in figure 1, the radiance of each set of light bulbs
with a common color has to be estimated separately. The
pixel values of the resulting images are summed up to obtain
one combined image. The colors have to be chosen manually during the tone-mapping. To show the ensemble of the
lit tail lamp and the rear part of the car, the pixel values of
a ray-traced image of the unlit tail lamp can be added to the
combined image.
7. Conclusion and future work
The radiance function of a light source with mostly specular reflection and transmission properties can be highly directional. To perform a density estimation of such radiance functions, it is necessary to take the position as well as
the direction of the virtual photons into account. Due to the
curse of dimensionality (see [Sco92]), the required number
of photons is high (in the order of 108 ). Density estimation
in position-direction space necessitates a tradeoff between
bias and noise in the spatial and in the angular domain. This
tradeoff can be controlled by the number of nearest neighbors k and the bandwidth ratio λ. With online scaling, both
these parameters can be changed quickly, that is without rebuilding the tree. λ should be adopted to the distance between the observer and the tail light. The heuristic Λ performs this adaption automatically.
The method could be improved by adding the possibility to handle different colors. One possibility to represent
color in the flux map is to assign three flux values to each
photon. These values represent the flux in the corresponding
RGB channel. In the density estimation, the radiance of each
channel has to be estimated separately. Another possible improvement is the use of a boundary kernel (see [Sco92])

for evaluation points with small angles between ω and the
bounding surface of the tail lamp. A boundary kernel reduces the boundary bias at the edge of the hemisphere of
directions. We have not addressed this problem here because
in the flux map of a typical automotive tail light, there are
no photons with small angles due to total internal reflection.
But when estimating the radiance of a light source which
has significant emission for small angles (like the Lambertian emitter), boundary bias becomes a problem.
The flux map could be used to illuminate virtual objects
in the near field, where the distance between the light source
and the object changes the irradiance pattern. While Goesele
uses photon mapping and wavelet-based importance sampling for photon generation [GGHS03], we would perform a
direct sampling of the estimated radiance function. The advantage of this approach is that it prevents topological bias.
First experiments with uniform sampling show good results.
To improve the convergence rate, a custom importance sampling strategy has to be developed. The basic idea for generating samples is to traverse the flux map randomly from
the root to the leaves, where only those cells are visited that
contain photons which might reach x (when estimating the
irradiance at x).
Our method could be used for the density estimation
in Moon and Marschner’s method for visualizing densely
packed scatterers [MM06]. The photons would be simulated
as described by Moon, but stored in the flux map and estimated with our method. This might lead to a speed-up
compared to Moon’s method because of the efficient kd-tree
search. With online scaling, it would be easier to find a reasonable value for the ratio between the spatial and the angular bandwidths (called w by Moon). It would also be interesting to investigate how the smooth kernel affects the density
estimation results.
Appendix A: Calculation of the kernel normalization
factor
In order to normalize K p , it has to be divided by the integral
of K p over the surface A and the hemisphere of possible directions at x with x ∈ A. If we assume that A is locally planar,
the domain of integration can be represented as the cartesian
product of a plane T and the hemisphere of directions Ω that
aligns with T . With this representation, the integral can be
written as
K p (x, ω) dω dx.

Ip =
T

(11)

Ω

If p includes an angle with T that is smaller than the angular bandwidth h/λ, the estimated radiance can be non-zero
for directions that point below T . Since these directions are
not included in the integral, some of the photon flux is lost.
This means that I p depends on the direction of p and on the
bandwidth h. To eliminate this dependence, we assume that
no photons with the above property exist. If this assumption
c 2009 The Author(s)
Journal compilation c 2009 The Eurographics Association and Blackwell Publishing Ltd.

Kniep, Häring and Magnor / Efficient and Accurate Light Source Rendering

does not hold, an error in the overall flux will result. We ignore this error because it decreases with h.
In the following calculation, we integrate over the whole
sphere instead of just the hemisphere. We choose this general
integration domain because the kernel might also be used
for radiance estimation in volumes, where the direction of
photons is not limited to the hemisphere. Without loss of
generality, we choose p = (x p , ω p ) with x p = (0, 0, 0)T and
ω p = (0, 0, 1)T . If ω is represented in spherical coordinates,
the angle (ω, ω p ) equals the polar angle θ of ω. Hence,
ω − ωp

2

2

2

= (1 − cos θ) + sin θ.

(12)

If we define x = (X,Y, Z), then x − x p = (X,Y, 0). This identity is used to transform the expression from equation 5,
which is denoted as D(H, x, ω, x p , ω p ) from now on.
D(H, x, ω, x p , ω p ) =
2

2

2

λ ω − ωp
x − xp
+
=
h2
h2
X 2 Y 2 λ2 (1 − cos θ)2 λ2 sin2 θ
+ 2+
+
.
h2
h
h2
h2

(13)

√

h2 −X 2
2π θ1
D(H, x, ω, x p , ω p ) sin θ dθ dϕ dYdX
√
−h − h2 −X 2 0
0

(14)
with
θ1 = arccos(1 − (h2 − X 2 −Y 2 )/ 2λ2 )

(15)

The integration limits in equation 14 ensure that the
domain of integration is the support S p of K p , S p =
{(x, ω)|D(H, x, ω, x p , ω p ) < 1}. The integration bounds for
X, Y and ϕ follow directly from the definition of S p . The
upper bound for θ follows from the equivalence
⇔

D(H, x, ω, x p , ω p ) < 1
2

2

2

2

2

2

X +Y + λ (1 − cos θ) + λ sin θ < h

2

arccos 1 −

h2 − X 2 −Y 2
2λ2

[AK90] A RVO J. R., K IRK D. B.: Particle Transport and Image Synthesis. In Proceedings of SIGGRAPH 90 (1990), vol. 24,
pp. 63–66.
[AM93] A RYA S., M OUNT D. M.: Algorithms for fast vector
quantization. In Proceedings of DCC 93: Data Compression
Conference (1993), IEEE Press, pp. 381–390.
[Ash95] A SHDOWN I.: Near-Field Photometry: Measuring and
Modeling Complex 3-D Light Sources. In SIGGRAPH Course
Notes (1995), pp. 1–15.
[BDWS02] B ENTHIN C., DAHMEN T., WALD I., S LUSALLEK
P.: Interactive headlight simulation: a case study of interactive
distributed ray tracing. In Proceedings of the 4th Eurographics
Workshop on Parallel Graphics and Visualization (2002), pp. 83–
88.
[Ben75] B ENTLEY J. L.: Multidimensional binary search trees
used for associative searching. Communications of the ACM 18,
9 (1975), 509–517.
[DGK99] D UNCAN C. A., G OODRICH M. T., KOBOUROV S.:
Balanced aspect ratio trees: Combining the advantages of k − d
trees and octrees. In Proceedings of the 10th Annual ACM-SIAM
Symposium on Discrete Algorithms (1999), pp. 300–309.

[GGHS03] G OESELE M., G RANIER X., H EIDRICH W., S EIDEL
H.-P.: Accurate light source acquisition and rendering. In Proceedings of SIGGRAPH 2003 (2003), vol. 22, pp. 621–630.
[GWS04] G UENTHER J., WALD I., S LUSALLEK P.: Realtime
caustics using distributed photon mapping. In Proceedings of the
15th Eurographics Symposium on Rendering (2004), pp. 111–
121.
[HKSS98] H EIDRICH W., K AUTZ J., S LUSALLEK P., S EIDEL
H.-P.: Canned light sources. In Proceedings of the 9th
Eurographics Workshop on Rendering (1998), Springer Wien,
pp. 293–300.
[Jen96] J ENSEN H. W.: Global illumination using photon maps.
In Proceedings of the 7th Eurographics Workshop on Rendering
(1996), pp. 21–30.
[Jen01] J ENSEN H. W.: Realistic Image Synthesis Using Photon
Mapping. AK Peters, Natick, 2001.

⇔

h − X 2 −Y 2
λ2
2
h − X 2 −Y 2
2 − 2 cos θ <
λ2
h2 − X 2 −Y 2
< cos θ ⇔
1−
2λ2

1 − 2 cos θ + cos2 θ + sin2 θ <

References

[FBF77] F RIEDMAN J. H., B ENTLEY J. L., F INKEL R. A.: An
algorithm for finding best matches in logarithmic expected time.
ACM Transactions on Mathematical Software 3, 3 (1977), 209–
226.

With this equality, I p can be written as
h

1081

2

⇔
⇔

> θ,

where we have presumed θ ∈ [0, π] and h ≤ 2λ. A vivid explanation for the condition h ≤ 2λ is that the angular bandwidth must not exceed 180◦ because otherwise, a part of the
sphere is contained twice within the bandwidth. The evaluation of equation 14 with a symbolic math package yields
I p = π2 h4 /(6λ2 ). The normalization factor is m = 1/I p .
c 2009 The Author(s)
Journal compilation c 2009 The Eurographics Association and Blackwell Publishing Ltd.

[Kaj86] K AJIYA J. T.: The Rendering Equation. In Proceedings
of SIGGRAPH 86 (1986), vol. 20, pp. 143–150.
[MM06] M OON J. T., M ARSCHNER S. R.: Simulating multiple
scattering in hair using a photon mapping approach. In Proceedings of SIGGRAPH 2006 (2006), vol. 25, pp. 1067–1074.
[Sco92] S COTT D. W.: Multivariate Density Estimation: Theory,
Practice and Visualization. Wiley series in probability and mathematical statistics. John Wiley, New York, 1992.
[Sil86] S ILVERMAN B. W.: Density Estimation for Statistics and
Data Analysis. Monographs on Statistics and Applied Probability. Chapman and Hall, New York, 1986.
[Spr91] S PROULL R. F.: Refinements to nearest-neighbor searching in k-dimensional trees. Algorithmica 6 (1991), 579–589.
[UWH∗ 03] U NGER J., W ENGER A., H AWKINS T., G ARDNER
A., D EBEVEC P.: Capturing and rendering with incident light
fields. In Proceedings of the 14th Eurographics Symposium on
Rendering (2003), pp. 141–149.

