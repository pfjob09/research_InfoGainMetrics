Volume 28 (2009), Number 2

EUROGRAPHICS 2009 / P. Dutré and M. Stamminger
(Guest Editors)

Heightfield and spatially varying BRDF Reconstruction for
Materials with Interreflections
Roland Ruiters and Reinhard Klein
Institute for Computer Science II, University of Bonn†

Abstract
Photo-realistic reproduction of material appearance from images has widespread use in applications ranging
from movies over advertising to virtual prototyping. A common approach to this task is to reconstruct the small
scale geometry of the sample and to capture the reflectance properties using spatially varying BRDFs. For this,
multi-view and photometric stereo reconstruction can be used, both of which are limited regarding the amount of
either view or light directions and suffer from either low- or high-frequency artifacts, respectively. In this paper,
we propose a new algorithm combining both techniques to recover heightfields and spatially varying BRDFs while
at the same time overcoming the above mentioned drawbacks. Our main contribution is a novel objective function
which allows for the reconstruction of a heightfield and high quality SVBRDF including view dependent effects.
Thereby, our method also avoids both low and high frequency artifacts. Additionally, our algorithm takes interreflections into account allowing for the reconstruction of undisturbed representations of the underlying material.
In our experiments, including synthetic and real-world data, we show that our approach is superior to state-ofthe-art methods regarding reconstruction error as well as visual impression. Both the reconstructed geometry and
the recovered SVBRDF are highly accurate, resulting in a faithful reproduction of the materials characteristic
appearance, which is of paramount importance in the context of material rendering.
Categories and Subject Descriptors (according to ACM CCS): I.3.7 [Computer Graphics]: Three-Dimensional
Graphics and Realism—Color, shading, shadowing, and texture I.4.8 [Image Processing and Computer Vision]:
Scene Analysis—Shape

1. Introduction
Research on photo-realistic rendering has shown, that for
a broad class of materials, a heightfield combined with a
spatially varying BRDF (SVBRDF) is already sufficient for
faithful and realistic visual reproduction. This representation
is very compact and allows for easy editing of the acquired
materials. Since modeling these representations either manually or procedurally is very time consuming, techniques for
their acquisition from material samples are of high practical use. A common approach in this context would be to
separate the geometry reconstruction, using techniques like
laser scanners or structured light, from the BRDF acquisition. However, since digital images of the sample are still
needed for the SVBRDF reconstruction, it is desirable to reconstruct also the geometry from these and avoid the additional acquisition step. Unfortunately, reconstructing geom† e-mail: {ruiters, rk}@cs.uni-bonn.de
c 2008 The Author(s)
Journal compilation c 2008 The Eurographics Association and Blackwell Publishing Ltd.
Published by Blackwell Publishing, 9600 Garsington Road, Oxford OX4 2DQ, UK and
350 Main Street, Malden, MA 02148, USA.

etry and SVBRDF together is a difficult problem, since both
are mutually dependent.
In [GCHS05] an algorithm is proposed which alternates
between SVBRDF and geometry estimation. However, the
use of photometric stereo limits this approach to a single
viewpoint. As a result, strongly view-dependent BRDF effects, like the Fresnel effect, cannot be reconstructed correctly. An approach combining multiple-views with photometric stereo reconstruction to overcome this restriction is
proposed in [PCF05], but it is limited to a very restrictive
BRDF model and requires the manual selection of corresponding points in the images to combine several view directions. A common problem of both techniques is that they
estimate a normal field and then perform an integration step
to obtain geometry. This is prone to low-frequency drifts as
small errors in the estimated normals can accumulate. Furthermore, the reconstructed normals can be inconsistent and
thus no corresponding geometry may exist.

514

Roland Ruiters and Reinhard Klein / Heightfield and SVBRDF Reconstruction for Materials with Interreflections

To overcome these restrictions, we propose a new algorithm which combines multi-view stereo and photometric
stereo. It extracts both a heightfield and a spatially varying
BRDF from images taken under different view- and lightdirections. In contrast to the previous approaches, our objective function does not depend on the normals, but instead directly on the 3D geometry of the reconstructed object. This
has several important advantages. We can reproject points
on the surface into the input images and thus optimize our
objective function for all viewpoints simultaneously. We do
not need any additional integration steps and therefore do not
have to cope with inconsistent normals. Furthermore, shadowing and masking effects can be included in the objective
function in a straightforward manner and it also becomes
possible to take interreflections into account. Both the reconstructed geometry and the recovered SVBRDF are highly
accurate, resulting in a faithful reproduction of the materials
characteristic appearance, which is of paramount importance
in the context of material rendering.
As in [GCHS05], we iterate between geometry and
SVBRDF reconstruction. In contrast to photometric approaches, our new objective function can no longer be optimized for each surface position independently, but has to
be minimized for the whole geometry at once. Since we are
reconstructing materials, we can restrict ourselves to the assumption of nearly planar surfaces, which can be represented
by a heightfield. In this case, the resulting optimization problem can be solved efficiently with a local optimization algorithm by taking advantage of the sparsity of the resulting
Hessian matrix.
To cope with interreflections within the surface mesostructure we perform an additional step during the iterative
optimization, in which the light-exchange within the surface geometry is approximated using the currently available
heightfield and spatially varying BRDF. For this calculation,
an efficient GPU implementation is used, as otherwise this
step would be prohibitively expensive. With the estimate of
the light transport, we are able to remove the contribution
of indirect light from the input images. The resulting images can then be used to reconstruct better heightfields and
SVBRDFs. This way, we are able to obtain spatially varying
BRDFs which are no longer influenced by the indirect light,
but instead faithfully represent the actual material. This is
especially important for editing applications, as here the interreflections have to be recalculated to be consistent with
changes to the geometry.
In contrast to previous approaches, our algorithm provides
the following key features:
• It reduces both high- and low-frequency artifacts, since
our objective function depends on the reprojected position of points on the surface and on their normals, and
thus it can take advantage of photometric information and
correspondences between several views.
• No additional integration step is necessary and we thus do

not have to cope with inconsistent normals which cannot
be represented by a heightfield.
• No parameters have to be adjusted by the user making our
technique easy to use, since our objective function measures the difference between our surface model and the
observed images.
• Interreflections are taken into account.
2. Previous Work
2.1. BRDF Acquisition
Several techniques to reconstruct BRDFs from images of
objects with known geometry have been proposed. Examples for the acquisition of homogeneous BRDFs are
[LKK98, MWL∗ 99, MPBM03] and in [SWI97] spatially
varying BRDF parameters are reconstructed. The use of
affine combinations of basis BRDFs to represent SVBRDFs
and an acquisition technique for these was first introduced
in [LKG∗ 03]. In [WWHL07] a further indirection is introduced by representing the BRDFs as linear combinations of
a second basis and a technique to obtain this decomposition
from a sparse measurement is proposed.
A few methods to cope with the influence of indirect light
during BRDF acquisition from objects exist. In [YDMH99]
a technique is described, which iterates between light exchange simulation and BRDF estimation. In [WSL04] a set
of homogeneous BRDF parameters is determined with a
simulated annealing algorithm. The fitting error is calculated
by rendering the object with a raytracer and comparing the
result to the input image. This way, interreflections are taken
into account. However, both approaches require knowledge
of the scene geometry.
2.2. Geometry Reconstruction
The reconstruction of geometry from images is one of the
central topics in computer vision and a lot of work has
been done in this area. Most techniques can be classified
into photometric stereo techniques, which capture objects
from a static viewpoint under varying light, and binocular
and multi-view stereo techniques, which use multiple viewpoints.
Photometric stereo [Woo80] techniques observe a given
object under different illumination directions to reconstruct
a normal map, which then can be integrated to obtain the object’s geometry. While older work in this area assumed the
object to be lambertian and homogeneous, recent approaches
overcome this limitation either by using sample objects of
the same materials and with known geometry [HS03], by
determining the direction of specular highlights to estimate
the normals [CGS06], or by iterating between SVBRDF
and shape estimation [Geo03, PCF05, GCHS05, HB08]. In
[NRDR05] geometry obtained from a 3D scanner is combined with photometric normals to obtain high quality models without low-frequncy drift.
c 2008 The Author(s)
Journal compilation c 2008 The Eurographics Association and Blackwell Publishing Ltd.

Roland Ruiters and Reinhard Klein / Heightfield and SVBRDF Reconstruction for Materials with Interreflections

Binocular and multi-view stereo techniques determine the
object shape either by determining correspondences between
pixels in images taken from different viewpoints and then triangulating the position on the surface or by finding an object
shape that maximizes a photo-consistency metric. Though a
lot of work has been done in this area, establishing the correspondences between pixels remains a difficult problem, especially when the objects have very homogeneous or specular surfaces. Furthermore, these techniques are prone to
noise. A recent evaluation of several multi-view stereo techniques can be found in [SCD∗ 06].
While the photometric stereo techniques often suffer from
a low frequency drift, resulting from the accumulation of
small errors in the estimated normals during the integration step, multi-view stereo techniques tend to exhibit high
frequency noise. For this reason, several combinations of
the two techniques have been proposed in recent years. In
[NZG05], images taken under several light directions are
combined to obtain viewpoint robust features, which are then
used for stereo reconstruction. In [CLL07] a technique for
the integration of several normal maps, reconstructed from
different points of view, is proposed. For this, a level set
method is used to reconstruct a surface which minimizes the
error between the estimated normal maps and the surface
normals. Another approach is to alternate between the photometric reconstruction of the surface and a parallax correction step. This step uses the surface estimate to resolve the
correspondences between the multiple views improving the
next photometric stereo reconstruction. In [LHYK05] this
technique is applied to lambertian objects and in [PCF05] a
spatially varying BRDF is additionally estimated. However,
both techniques require knowledge about corresponding pixels to combine images from different view points, which are
either selected manually [PCF05] or obtained by tracking
features in the images [LHYK05]. In [JCYS04], [VHC06],
and [EVC08] algorithms are proposed, which alternate between the estimation of surface normals and the evolution of
a mesh which corresponds to these normals to resolve the
parallaxes.
All of these techniques to combine photometric and multiview stereo separate the geometry reconstruction from the
normal estimation. To cope with the afore-mentioned ambiguous or inconsistent normals, a second optimization step
has to be conducted, which reconstructs the geometry by
minimizing the normal error. This increases the complexity
of these algorithms considerably. To avoid these problems
we directly reconstruct the geometry. A similar approach is
taken in [YXA04], where a star-shaped polygonal mesh is
directly optimized to correspond to the input images. However, their technique is limited to homogeneous materials.
A technique for the reconstruction of surfaces in the
presence of inter-reflections is proposed in [NIK90]. As in
our approach, the algorithm iteratively refines the reconstructed surface by subtracting an approximation of the inc 2008 The Author(s)
Journal compilation c 2008 The Eurographics Association and Blackwell Publishing Ltd.

515

Figure 1: Illustration of the capture setup for image Ii

direct light from the measured intensity. This approximation is calculated from the currently available surface geometry under the assumption of a lambertian object. Direct and indirect illumination can also be separated by using
polarization filters or with structured light techniques, e.g.
[NKGR06,CLFS07,CSL08]. However, these approaches require special measurement setups.
3. Objective Function
We use a set of images {Ii } as input each of which has been
taken under illumination by a single point light source at position Li from camera position Ci . We thus require the necessary calibration data to determine both the position of the
camera and light source as well as the intrinsic camera parameters. Additionally, we assume that the sample is nearly
planar and that a reference plane is available, which is already quite close to the surface of the material. In the following, we will use a coordinate system which is aligned to
this reference plane, with its origin in one corner of the material sample. We denote the bilinearly interpolated intensity
at the position x in the image Ii as Ii (x).
As in [GCHS05], the BRDF of the surface is modeled as
a linear combination of a set of basis BRDFs. Our objective
is thus to find a heightfield h, a weight map γ and a matrix of basis BRDF parameters α which describe the input
images as faithfully as possible. For the reconstruction, we
assume the heightfield h to be triangulated and the triangles
∆t to have consecutive indices t. For simplicity of notation,
henceforth we will identify the triangles by their indices.
Therefore, the normal of a triangle is given by nt and the
local light and view directions from the center of this triangle for the image Ii are denoted li,t and vi,t . Since the distance to both camera and light is large when compared to
the size of structures on the surface, we approximated these
directions using points on the reference plane neglecting the
heightfield value at that position. See Figure 1 for an illustration. For each of these triangles, the reconstructed intensity
when seen from Ci and illuminated from Li is denoted by
I (t, vi,t , li,t ) and is modeled as a function of the parameters
h,γ, α. We define the objective function as:
E(h, γ, α) = ∑ χ(t, vi,t , li,t ) Ii (Πi (t)) − I (t, vi,t , li,t ) 2 ,
t,i

516

Roland Ruiters and Reinhard Klein / Heightfield and SVBRDF Reconstruction for Materials with Interreflections

function ρc (n, l, v, α j ) to denote the Cook Torrance BRDF
in dependence on this parameter vector α j and the normal n,
light direction l and view direction v.
(a)Triangle normals

(b)Vertex normals

Figure 2: Normals calculated either for each triangle, or for
the vertices, by averaging triangle normals

where χ takes care of ignoring samples which are masked
and shadowed and the function Πi (t) maps the center of
the triangle ∆t into the input image Ii using the interpolated
heightfield value to obtain its 3D position. The actual reconstruction is performed by minimizing this objective function.
Each triangle in our heightfield is smaller than one pixel in
the input images, and thus it is sufficient to evaluate one sample per triangle, instead of integrating over the triangle surface. In the following we will describe the different components of the objective function in more detail.

The spatially varying weights for the basis BRDFs are
represented by a vector γ j (t) which gives the weight for the
contribution of the jth basis BRDF to the BRDF of the triangle t. We assume, that two adjacent triangles, forming a
square in the height field, have the same BRDF and thus
store only one weight for each of these, allowing us to represent the weights in a 2D-map. We restrict our BRDF weights
to convex combinations, and thus all γ j are non-negative and
sum to one at every position on the surface. The modeled
intensity of a triangle is then given by:

I (t, l, v) = ∑ γ j (t)ρc (nt , l, v, α j ))(l • nt ).
j

3.3. Shadow and Masking Model
3.1. Geometry Model
We model the geometry of the surface as a triangulated
heightfield, assuming a constant normal and BRDF for each
triangle. Since we choose our heightfield resolution in such
a way that it corresponds to the pixel size in the input images with the highest resolution, this is a sufficiently precise
approximation of the actual appearance of the surface and
allows us to evaluate the error using one sample for each
triangle. Note that it is important to model the surface with
per-triangle normals instead of interpolated vertex normals.
If the intensity is evaluated at the vertices instead, the normals of adjacent triangles have to be averaged to obtain this
normal. As illustrated in Figure 2(b), the averaged normals
can be smooth even for very strongly oscillating heightfields
and thus photometric methods cannot distinguish both cases.
This results in additional degrees of freedom in our objective
function. For homogeneous materials, the multi-view reconstruction is also not sufficient to resolve this ambiguity, and
thus the algorithm can fit oscillating heightfields to smooth
surfaces, resulting in strong high-frequency artifacts.
3.2. Spatially Varying BRDF Model
We use the well-known Cook-Torrance reflectance model
[CT82] with the Beckmann normal distribution function and
the Schlick approximation for the Fresnel term [Sch94],
which is important in a multi-view setting. We have chosen this model, since, as analyzed in [NDM05], it is able to
represent most materials with a single lobe quite faithfully
and thus requires the estimation of just a rather low number
of parameters. However, other BRDF models could be used
with our technique, too. The basis BRDFs are described by
a matrix of parameter values, where α j,k gives the kth parameter of the jth basis BRDF. We will denote the vector
of parameters for the jth basis BRDF with α j . We use the

We have to ignore samples which are either occluded or
shadowed. This is done by the term χ(t, v, l). It is composed
of a term V (t, v) which is 1 if the triangle is visible and 0
if not and a corresponding term S(t, l) for shadows. Furthermore, it renormalizes the error by dividing through the total number of samples that have been taken into account,
as otherwise, increasing the number of masked or occluded
samples would decrease the reconstruction error. It is thus
defined as follows:

χ(t, v, l) =

V (t, v)S(t, l)
.
∑t ,i V (t , vi )S(t , li )

4. Optimization
The minimization of the objective function E(h, γ, α) requires solving a non-linear optimization problem with a
large number of unknowns. Therefore, a direct optimization of all unknowns at the same time with a local optimization algorithm easily gets stuck in a local minimum.
However, due to the structure of this problem, the use of
global optimization algorithms is impractical. Therefore, as
in [GCHS05], we solve the problem by alternating between
the optimization of the basis BRDF parameters, the weight
map parameters and the heightfield until the error no longer
decreases sufficiently. This way we can use optimization algorithms which are specially tailored to each of the subproblems.
4.1. Initialization
As all three optimization problems depend on each other, it is
not clear which initial values should be used. Our approach,
which worked well in practice, is to first estimate an averaged homogeneous BRDF by fitting a single basis BRDF
c 2008 The Author(s)
Journal compilation c 2008 The Eurographics Association and Blackwell Publishing Ltd.

Roland Ruiters and Reinhard Klein / Heightfield and SVBRDF Reconstruction for Materials with Interreflections

assuming a planar surface and a constant weight map. For
the BRDF estimation we are using a genetic algorithm and
thus do not need to specify a start value. In the next step, this
homogeneous BRDF is used to reconstruct a first estimate
of the heightfield. For this, the reference plane is used as
initial geometry, which means that we set all heightfield values to zero. In order to get a reasonable first heightfield we
are only using view-directions up to an angle of 30◦ relative
to the reference plane normal for the heightfield reconstruction. For these views parallax effects are rather small, and in
our experiments this initialization resolves the pixel correspondences to a sufficient degree for the stable convergence
against an initial heightfield. To further improve the stability of the optimization, during both of these initial steps we
average the colors of the input images and use only the intensity during optimization.
Once we have found this initial estimate of the heightfield,
we have to initialize the weight maps γ j . This is done by successively adding further basis BRDFs up to a user specified
total number. We thus start with two basis BRDFs. Since for
many materials a strong correlation between surface geometry and BRDF exists, for these we use the heightfield to
initialize the weight maps γ0 and γ1 . This is done by scaling and shifting the heightfield values in the range between
0 and 1 to obtain the height h (t) at the position of triangle
t and then setting γ0 (t) = h (t) and γ1 (t) = 1 − h(t). Using
these weight maps, the BRDF estimation is now repeated
for two basis BRDFs and then weight map and basis BRDF
estimation are alternated until the error no longer decreases
sufficiently between two iterations. For materials which do
not exhibit a strong correlation, the use of a clustering step,
like the one described in [GCHS05] may be better, though.
When more than these two BRDFs are to be used or for
materials with no correlation between meso-structure and
BRDF, further basis BRDFs are added successively. Based
on the reasonable assumption that the error is especially high
at places where a further BRDF has a high contribution, the
new weight map γ j is initialized from the error obtained during the previous optimization step at the position of the entry γ j . This error is scaled to 0 and 1, assigned to the new
channel and then all basis BRDF weights are rescaled to enforce the convex combination constraint on γ. Now, BRDF
and weight map estimation are again iterated and then this
procedure is repeated for the next BRDF.
4.2. Basis BRDF Optimization
As already noted in [NDM05], because of their nonlinearity, the fitting of a single BRDF model with local optimization algorithms is already very prone to local minima. The simultaneous fitting of several basis BRDFs against
samples consisting of linear combinations of these BRDFs
is even more difficult, as a higher number of parameters has
to be optimized at the same time, and a good initial guess
of the BRDF parameters is crucial. A manual selection as
c 2008 The Author(s)
Journal compilation c 2008 The Eurographics Association and Blackwell Publishing Ltd.

517

suggested in [NDM05] is impractical for an iterative algorithm. In each iteration, the BRDF optimization is once performed with the last values as initialization and once with
the initialization obtained from a genetic algorithm and then
the better result is kept. This way, a bad initialization from
the genetic algorithm does not lead to an increase in the error, but we are also able to leave a local minimum. We used
the GADemeGA algorithm from the GALib library [Wal96]
with 30 populations each having 30 individuals and a mutation probability of 10% and the Quasi-Newton algorithm
from [MOHW07] using analytically computed first derivatives of the Cook-Torrance BRDFs.
Even with this initialization, the BRDF estimation was
still prone to local minima in our experiments. A further improvement can be made by reducing the dimensionality of
the optimization problems. To this end, we iterate between
the solution of different subsets of the parameter matrix α,
keeping the remaining parameters fixed. We thus first optimize the diffuse components of all BRDFs together. Then,
each of the basis BRDFs α j is optimized individually and
finally the full matrix α is optimized. To further reduce the
number of parameters that have to be optimized, this procedure is first performed for averaged colors and then repeated
for color BRDFs, initializing the diffuse and specular color
with the gray-scale intensity obtained in the previous step.
4.3. Weight Map Optimization
Given a set of basis BRDFs and a heightfield, determining
the weight map can be performed independently for each
entry of the weight map. The color of the corresponding triangles under the different light and view directions is extracted from the input images in a preprocessing step. Since
we are considering linear combinations of the basis BRDFs,
determining the γ j is a least squares problem. However, it is
necessary to enforce the non-negativity and the convex combination of the γ j during the optimization. Therefore, we perform this optimization also with a Quasi-Newton optimizer.
4.4. Heightfield Optimization
The heightfield optimization is a non-linear problem. This
results from the fact, that changes in the heightfield alter the
derived normals, which in turn result in non-linear changes
in the color because of the non-linearity of the BRDF model.
Furthermore, the problem cannot be solved for each heightfield entry independently, as each entry depends on the
neighboring entries through the derived normals. Therefore,
all entries in the heightfield are coupled to each other and
the problem has to be solved for the whole heightfield at
once. Thus, e.g. for a 129 × 129 sized heightfield, an optimization problem with 16,641 unknowns has to be solved.
The Quasi-Newton optimization algorithm we used for the
basis BRDFs and weight maps cannot be used directly for
problems of this size. However, it can be adapted to take advantage of the special structure of this problem.

518

Roland Ruiters and Reinhard Klein / Heightfield and SVBRDF Reconstruction for Materials with Interreflections

The gradients for the Newton algorithm are calculated using finite differences. Note that each entry in the heightfield
influences only four triangles. Thus, it is only necessary to
recalculate the error for these four triangles when calculating
the finite-difference derivative of one of the unknowns.
Standard Quasi-Newton methods cannot be used, because
the size of the inverse of the Hessian matrix, which is approximated by these algorithms, increases with the square
of the number of unknowns. However, for this special problem, the Hessian matrix has a sparse structure. As only four
terms in our objective function depend on one heightfield entry, the first derivative of the sum only contains these terms,
which together depend on only five heightfield entries. Each
row of the Hessian matrix of this problem thus contains just
five non-zero entries. Therefore, it can be approximated with
finite-differences in linear time in the number of unknowns
and it can be inverted efficiently using the conjugated gradients method. We used the TN [Nas84] algorithm for this
minimization, which we modified to take advantage of the
sparsity of the Hessian matrix.
In the first optimization steps, the correspondences are
only resolved correctly for views close to the top-view and
thus the algorithm can, like photometric techniques, reconstruct a first estimate of the surface from these, but it is more
difficult to determine the position of this surface relative to
the reference plane. To find this position we perform an additional optimization step, in which the whole heightfield
is shifted perpendicular to the reference plane. Afterwards,
most correspondences are already resolved correctly.
Even though the algorithm shows good convergence for
the global heightfield, we sometimes observed individual
pixels or small groups of pixels (up to about 5 pixels) which
got stuck in a local minimum. However, these minima could
be resolved by performing an additional step, which eliminates these outliers by searching for entries with very high
errors and setting these to the average of their surrounding
entries. If this step reduces the total error, the new values are
kept, otherwise the old ones are restored.
The full optimization of all heightfield entries, the optimization of the offset and scale, and the elimination of outliers are iterated until the error no longer decreases sufficiently between two iterations. Using this combination of
steps, we found that the algorithm, starting with the reference plane as initialization, showed a good convergence in
all of our experiments (cf. Section 6).
4.5. Acceleration
When a large number of input images has to be processed,
an efficient implementation of the reconstruction algorithm
is necessary. Since especially the evaluation of the objective
function is very expensive, we used several optimizations reducing the runtime considerably.
The two slowest parts of the reconstruction algorithm are

the genetic algorithm for BRDF estimation and the heightfield optimization, as both require a very high number of
evaluations of the objective function. However, the evaluation of the objective function is easily parallelizable and can
thus be accelerated by performing this calculation on a GPU.
A straight-forward CUDA implementation of the objective
function evaluation accelerated the BRDF optimization by a
factor of about 5 and the heightfield optimization by a factor
of about 20 when running on a GeForce 8800 GTX compared to a moderately optimized parallelized version running on a Q6600 quad-core CPU. Furthermore, we found,
that using rectangular facets with constant normal instead of
two triangles, neglecting the normal of one of the triangles,
to approximate the area in between four heightfield entries
is usually sufficient to reconstruct good heightfields and reduces the number of samples that have to be evaluated and
the storage needed on the GPU.
Instead of optimizing the BRDFs over the whole dataset,
we instead just optimize the BRDF for a subset of the full
dataset. Typically, about 100.000 samples are drawn, using a
simple binning scheme on the weight map to ensure that all
basis BRDFs are represented sufficiently by the samples.
Even though during each optimization step the objective
function always decreases, it is not guaranteed that the algorithm converges when these optimizations are used. This results from the fact, that we use different subsets of the whole
dataset and we thus do not optimize exactly the same objective function during each step. We therefore simply iterate
the algorithm until the weight map reconstruction error no
longer decreases.
5. Interreflections
Interreflections can result in wrong estimates of the heightfield and can disturb the SVBRDF reconstruction. Since
grooves in the surface are brightened by the interreflections,
the BRDFs estimated for these parts of the surface are also
too bright, when this effect is not considered during the reconstruction. In Figures 3(a) and 3(b) an example for this
effect is shown.
To remove this brightening of the SVBRDFs and to improve the quality of the heightfields further, we first calculate
the contribution of the indirect light to the measured brightness of each pixel and then subtract it from the input images.
To get an estimate of this contribution, we simulate the light
exchange within the meso-structure, using our current estimates of the heightfield and the spatially varying BRDF, for
all combinations of light- and view-directions present in the
input dataset. After these simulations we render views of the
heightfield from the camera viewpoints, in which only the
contribution of the indirect light is present. See Figure 3(c)
for an example of such an image. These renderings are then
subtracted from the input images. By rendering the heightfield from the viewpoints present in the input dataset we take
care of parallax effects and occlusions.
c 2008 The Author(s)
Journal compilation c 2008 The Eurographics Association and Blackwell Publishing Ltd.

Roland Ruiters and Reinhard Klein / Heightfield and SVBRDF Reconstruction for Materials with Interreflections

(a)

(b)

(c)

(d)

519

(e)

Figure 3: Two images from a synthetic sample dataset, rendered (b) without and (a) with interreflections . (c) shows the
contribution of indirect light simulated with the first reconstruction and (d) is the image then obtained by subtracting (c) from
(a). The remaining difference to the image without interreflections (b) is shown in (e). (Both (c) and (e) are scaled by a factor
of 10)
Since we use our first erroneous BRDF estimate for the
light exchange simulation, we overestimate the contribution
of the indirect light in the first step. When we subtract these
overestimated values, this results in the next step in BRDF
estimates which are too dark. However as long as the contribution of indirect light is smaller than the contribution of direct light, which can be assumed to be the case on nearly all
surface which can be described by heightfields, this second
estimate is still better than the first one and thus this algorithm converges against the real BRDF. In our experiments,
even after the first iteration the estimates were very close
to the correct result. An example for this is shown in Figure
3(d), which is obtained by subtracting the interreflections estimated using the fist reconstruction of the heightfield and
SVBRDF from the original image. As the difference image
in Figure 3(e) shows, this first step already removed nearly
all interreflections.

5.1. Simulation of the Interreflections
The calculation of the interreflections is repeated several
times during the iterative reconstruction process and has to
be performed for all input images. Therefore, an efficient
method to perform this simulation is needed. If a common
path-tracer is used, the simulation would take several minutes for each image. We thus implemented a path tracer
on the GPU, using a technique similar to the one proposed
in [HDKS00]. For each point on the surface, we first precompute for a fixed set of directions in which distance a ray
originating from this point will hit the heightfield again. This
information can then be used to perform the whole pathtracing algorithm in a pixel shader, as intersection tests can
now be calculated with a single texture look-up. We use a
non uniform sampling of the hemisphere, as in the heightfields usually only rays reflected in very shallow angles hit
the surface again. Therefore, we scale the uniform sampling
in such a way, that primarily these rays are considered and
adjust the probability distribution function accordingly to
compensate for the resulting bias. We performed our simulation with 128 rays for each pixel and simulated up to
three bounces. On a GeForce 8800, the algorithm then simc 2008 The Author(s)
Journal compilation c 2008 The Eurographics Association and Blackwell Publishing Ltd.

ulated the light exchange within a 129x129 sized heightfield
in about 3.5 seconds.
This technique can also be used to synthesize a new
BTF with interreflections from edited versions of the reconstructed representation, which can then again be used during
rendering. Furthermore, it is suitable for interactive preview
during the editing.
6. Evaluation
We evaluated our technique both on a synthetic dataset,
which provides a ground truth and thus allows for a direct
comparison of the reconstructed heightfields, weight maps
and BRDFs, and on several real world BTF datasets. To create the synthetic dataset, we simulated the image acquisition
process used for the real datasets as exactly as possible using a raytracer. The dataset contained all combinations of
26 viewpoints and 26 light sources. Furthermore, the images were rendered in the same resolution as the photographs
taken by the cameras (3 Megapixel). To render the images, a
Monte-Carlo path-tracer was used, which simulated the interreflections using 4096 rays for each pixel. The heightfield
was placed about 0.3 mm below the reference plane to simulate the imprecise calibration of the reference plane usually
obtained in practice.
In Figure 4, the reconstruction results obtained by either
using lambertian photometric stereo [BP03] to reconstruct
the heightfield, by iterating between SVBRDF estimation,
normal reconstruction and integration, similar to [GCHS05],
and by using our algorithm are compared to the ground truth.
For all techniques, the same code was used to reconstruct
the BRDFs and weight maps. The errors for the heightfield
are given in millimeters, using the size of the real measurement setup as reference. The cameras were placed in about
60 cm distance to the sample, which had a size of about
1.5 × 1.5 cm and a resolution of about 150 pixels in the
top-view. Using the photometric techniques, the position of
the heightfield with respect to the reference plane cannot be
determined, as the reconstructed heightfield can be shifted
along the z-axis without any change to the normals. In order to compare to the original heightfield we shifted the

520

Roland Ruiters and Reinhard Klein / Heightfield and SVBRDF Reconstruction for Materials with Interreflections

Original

Lambertian
Photometric Stereo

Photometric
Stereo with BRDF

Our Technique
(no light exchange)

Our Technique
(with light exchange)

– / 0.141 mm

– / 0.044 mm

0.029 / 0.008 mm

0.030 / 0.007 mm

0.411

0.310

0.141

0.077

42.50% 132.27%
67.16% 49.52%
9.56%
10.03%
8.91%
2.70%
Figure 4: Evaluation on a synthetic dataset. In the first row the reconstructed heightfields are compared. The average errors
compared to the ground truth are given below the images, first the absolute error and then the error obtained by aligning the
heightfield to the original one by shifting it upwards/downwards to the position minimizing this error. The next row shows the
reconstructed weight maps and gives their average difference to the original. The red channel describes the contribution of the
left BRDF and the green channel the contribution of the right one. In the last row the reconstructed basis BRDFs are shown.
Here the errors are obtained by averaging the relative error over the whole BRDF.
reconstructed one along the z-axis in such a way, that the
mean error between the two becomes minimal. For our technique, both the error for the absolute reconstructed heightfield values and the error obtained by aligning the height
fields are shown. The algorithm reconstructed the position
of the heightfield with respect to the reference plane up to a
precision of about 0.03 mm, which corresponds to a parallax
of about 0.15 pixel in the 30◦ views we used for the reconstruction. When the heightfields are aligned as for the photometric techniques, the actual surface geometry is reconstructed to a precision of 0.0069 mm, which is about 1.3%
of the total heightfield depth of about 0.55 mm.
The purely photometric techniques had considerably
higher errors in the estimated heightfield. This and the fact
that only one view-direction can be used result in considerably worse BRDF estimates. Especially the lambertian photometric stereo technique reconstructed a heightfield, which
was too deep and thus in consequence the BRDFs estimations based on this heightfield are very bad. Since the heightfield estimated without considering interreflections was already quite good, the correction for interreflections only improved the reconstruction of the actual surface geometry by a
small amount from 0.0080 mm to 0.0069 mm. On the other
hand, the reconstructed weight map and the BRDF in the

(a)Photometric Stereo

(b)Our Technique

Figure 6: Comparison of resulting low frequency-drift

cracks improved considerably when the correction for interreflections was performed. We found, that the use of several
view-directions eliminates most of the problems with lowfrequency drift that purely photometric techniques are prone
to. In Figure 6, a heightfield reconstructed from a real-world
dataset with normal estimation and integration and one obtained with our technique are compared. The data-set contained all combinations 26 view and light directions, however, for the photometric reconstruction only one view direction can be used. We assumed for both reconstructions
the same SVBRDF. Our technique removed nearly all low
c 2008 The Author(s)
Journal compilation c 2008 The Eurographics Association and Blackwell Publishing Ltd.

Roland Ruiters and Reinhard Klein / Heightfield and SVBRDF Reconstruction for Materials with Interreflections

521

(a)BTF

(b)Reconstruction

Figure 5: Comparison between renderings of the BTF and renderings of our reconstructed heightfields and SVBRDFs. Environment Map courtesy of Paul Debevec (http://www.debevec.org/probes/).
frequency drift, only in the boundary regions, where not
enough correspondences could be established, a small drift
remained.
In Figure 5, we compare renderings of BTFs with our reconstructions to show that we are able to reproduce the overall appearance faithfully. The BTFs were captured with our
measurement setups of which the newest one is described in
more detail in [RMS∗ 08]. The reconstruction was performed
with a subset of the BTF datasets containing all combinations of 31 light- and view-directions.
6.1. Timing
The full number of view directions was only used for the
BRDF reconstruction, as here shallow viewing angles are
necessary to obtain a good estimate of the Fresnel effect.
In contrast, for the spatially varying heightfield and weight
map estimation, we limit ourself to viewing angles up to 30◦
from the reference plane normal.
For the BRDF and SVBRDF estimation, the calculation of
shadowing and masking was performed before the actual optimization process, which is not possible for the heightfield
reconstruction. However, since we limit ourself to viewing
angles of 30◦ , the influence of these effects is small during
this step. Thus, we did not include these terms as it would
slow down the heightfield optimization considerably.
For our synthetic dataset, on a Q6600 quad-core with a
Geforce 8800 GTX about 20 min are needed for the BRDF
c 2008 The Author(s)
Journal compilation c 2008 The Eurographics Association and Blackwell Publishing Ltd.

reconstruction, 5-10 min for the estimation of the weight
map and about 1:15h for the first heightfield optimization. In
later iterations the heightfield estimation is faster, requiring
about 10-20 min, as better initial values are already available. About 5 iterations of these steps are performed to get
the first estimated heightfield and SVBRDF, requiring thus
about 6 hours. The calculation of interreflections requires
about 40 min and is iterated 3 times with the reconstruction.
As the reconstruction is faster for these later iterations, the
whole process requires about 13 hours.
7. Conclusion and Future Work
We presented a new algorithm, which combines multi-view
and photometric stereo to directly recover heightfields without any intermediate normal integration steps and takes
interreflections into account. Our evaluation on synthetic
datasets showed that our algorithm is able to reconstruct the
surface geometry considerably better than purely photometric techniques and that the removal of indirect light results in
much better estimates of the spatially varying BRDF. Both
the reconstructed geometry and the recovered SVBRDF are
highly accurate, resulting in a faithful reproduction of the
materials characteristic appearance, which is of paramount
importance in the context of material rendering.
Currently, we limited ourself to planar samples. However,
in the future we would like to investigate, if the same approach can be used for complex objects, when the heightfield
is instead parameterized over a reference mesh.

522

Roland Ruiters and Reinhard Klein / Heightfield and SVBRDF Reconstruction for Materials with Interreflections

8. Acknowledgments
This work was supported by the German Science Foundation
(DFG) under research grant KL 1142/4-1.
References
[BP03] BARSKY S., P ETROU M.: The 4-source photometric
stereo technique for three-dimensional surfaces in the presence
of highlights and shadows. IEEE Trans. PAMI 25, 10 (2003),
1239–1252.
[CGS06] C HEN T., G OESELE M., S EIDEL H.-P.: Mesostructure
from specularity. In IEEE Trans. PAMI (2006), pp. 1825–1832.
[CLFS07] C HEN T. B., L ENSCH H. P. A., F UCHS C., S EIDEL
H. P.: Polarization and phase-shifting for 3D scanning of translucent objects. In CVPR (2007), pp. 1–8.
[CLL07] C HANG J. Y., L EE K. M., L EE S. U.: Multiview normal field integration using level set methods. In CVPR (2007),
pp. 1–8.
[CSL08] C HEN T. B., S EIDEL H. P., L ENSCH H. P. A.: Modulated phase-shifting for 3D scanning. In CVPR (2008), pp. 1–8.
[CT82] C OOK R. L., T ORRANCE K. E.: A reflectance model for
computer graphics. ACM Trans. Graph. 1, 1 (1982), 7–24.
[EVC08] E STEBAN C. H., VOGIATZIS G., C IPOLLA R.: Multiview photometric stereo. Trans. PAMI 30, 3 (2008), 548–554.
[GCHS05] G OLDMAN D. B., C URLESS B., H ERTZMANN A.,
S EITZ S. M.: Shape and spatially-varying brdfs from photometric stereo. In ICCV (2005), pp. 341–348.
[Geo03] G EORGHIADES A. S.: Recovering 3-d shape and reflectance from a small number of photographs. In EGRW ’03:
Eurographics workshop on Rendering (2003), pp. 230–240.

[Nas84] NASH S. G.: Newton-type minimization via the lanczos
method. SIAM J. Num. Anal 21, 4 (1984), 770–788.
[NDM05] N GAN A., D URAND F., M ATUSIK W.: Experimental
analysis of brdf models. In Eurographics Symposium on Rendering (2005), pp. 117–226.
[NIK90] NAYAR S. K., I KEUCHI K., K ANADE T.: Shape from
Interreflections. Tech. Rep. CMU-RI-TR-90-14, Robotics Institute, Carnegie Mellon University, Pittsburgh, PA, July 1990.
[NKGR06] NAYAR S. K., K RISHNAN G., G ROSSBERG M. D.,
R ASKAR R.: Fast separation of direct and global components of a
scene using high frequency illumination. In SIGGRAPH (2006),
pp. 935–944.
[NRDR05]

N EHAB D., RUSINKIEWICZ
MAMOORTHI R.: Efficiently combining

S., DAVIS J., R A positions and normals
for precise 3D geometry. ACM Trans. Graph 24, 3 (2005), 536–
543.

[NZG05] N EUBECK A., Z ALESNY A., G OOL L. V.: 3d texture
reconstruction from extensive btf data. In Texture 2005 Workshop
in conjunction with ICCV 2005 (October 2005), pp. 13–19.
[PCF05] PATERSON J. A., C LAUS D., F ITZGIBBON A. W.: Brdf
and geometry capture from extended inhomogeneous samples using flash photography. Comput. Graph. Forum 24, 3 (2005), 383–
391.
[RMS∗ 08] RUMP M., M ÜLLER G., S ARLETTE R., KOCH D.,
K LEIN R.: Photo-realistic rendering of metallic car paint from
image-based measurements. Comput. Graph. Forum 27, 2
(2008).
[SCD∗ 06] S EITZ S. M., C URLESS B., D IEBEL J., S CHARSTEIN
D., S ZELISKI R.: A comparison and evaluation of multi-view
stereo reconstruction algorithms. In CVPR (2006), pp. 519–528.

[HB08] H ABER T., B EKAERT P.: Image-based acquisition of
shape and spatially varying reflectance. In BMVC (2008).

[Sch94] S CHLICK C.:
An inexpensive BRDF model for
physically-based rendering. Computer Graphics Forum 13, 3
(1994), 233–246.

[HDKS00] H EIDRICH W., DAUBERT K., K AUTZ J., S EIDEL H.P.: Illuminating micro geometry based on precomputed visibility.
In SIGGRAPH (2000), pp. 455–464.

[SWI97] S ATO Y., W HEELER M. D., I KEUCHI K.: Object shape
and reflectance modeling from observation. In SIGGRAPH ’97
(1997), pp. 379–388.

[HS03] H ERTZMANN A., S EITZ S. M.: Shape and materials
by example: A photometric stereo approach. In CVPR (2003),
pp. 533–540.

[VHC06] VOGIATZIS G., H ERNANDEZ C., C IPOLLA R.: Reconstruction in the round using photometric normals and silhouettes.
In CVPR (2006), pp. 1847–1854.

[JCYS04] J IN H., C REMERS D., Y EZZI A. J., S OATTO S.: Shedding light on stereoscopic segmentation. CVPR (2004), 36–42.

[Wal96] WALL M.: GAlib: A C++ Library of Genetic Algorithm
Components. Mechanical Engineering Department, MIT (1996).
http://lancet.mit.edu/ga/.

[LHYK05] L IM J., H O J., YANG M.-H., K RIEGMAN D.: Passive
photometric stereo from motion. In CVPR (2005), pp. 1635–
1642.
[LKG∗ 03]

L ENSCH H. P. A., K AUTZ J., G OESELE M., H EI W., S EIDEL H.-P.: Image-based reconstruction of spatial
appearance and geometric detail. ACM Transactions on Graphics
22, 2 (2003), 234–257.
DRICH

[LKK98] L U R., KOENDERINK J. J., K APPERS A. M. L.: Optical properties (bidirectional reflection distribution functions) of
velvet. Applied Optics 37, 25 (1998), 5974–5984.
[MOHW07] M EZA J. C., O LIVA R. A., H OUGH P. D.,
W ILLIAMS P. J.: Opt++: An object-oriented toolkit for nonlinear
optimization. ACM Trans. on Math. Software 33, 2 (2007), 12.
[MPBM03] M ATUSIK W., P FISTER H., B RAND M., M C M IL LAN L.: Efficient isotropic BRDF measurement. In Eurographics Workshop on Rendering (2003), pp. 241–248.
[MWL∗ 99]

M ARSCHNER S. R., W ESTIN S. H., L AFORTUNE
E. P. F., T ORRANCE K. E., G REENBERG D. P.: Image-based
brdf measurement including human skin. In Proceedings of 10th
Eurographics Workshop on Rendering (1999), pp. 139–152.

[Woo80] W OODHAM R. J.: Photometric method for determining
surface orientation from multiple images. Optical Engineering
19, 1 (1980), 139–144.
[WSL04] W U E., S UN Q., L IU X.: Recovery of material under
complex illumination conditions. In GRAPHITE (2004), pp. 39–
45.
[WWHL07] W EISTROFFER R. P., WALCOTT K. R.,
H UMPHREYS G., L AWRENCE J.: Efficient Basis Decomposition for Scattered Reflectance Data.
In Eurographics
Symposium on Rendering (2007), pp. 207–218.
[YDMH99] Y U Y., D EBEVEC P., M ALIK J., H AWKINS T.: Inverse global illumination: recovering reflectance models of real
scenes from photographs. In SIGGRAPH (1999), pp. 215–224.
[YXA04] Y U T., X U N., A HUJA N.: Recovering shape and reflectance model of non-lambertian objects from multiple views.
CVPR (2004), 226–233.

c 2008 The Author(s)
Journal compilation c 2008 The Eurographics Association and Blackwell Publishing Ltd.

