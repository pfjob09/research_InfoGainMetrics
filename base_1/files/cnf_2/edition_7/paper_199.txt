Pacific Graphics 2009
S. Lee, D. Lischinski, and Y. Yu
(Guest Editors)

Volume 28 (2009), Number 7

Variational Surface Approximation and Model Selection
Bao Li1,2 , Ruwen Schnabel1 , Shiyao Jin2 and Reinhard Klein1†

2 National

1 Institut für Informatik II, Universität Bonn, Germany
Laboratory for Parallel and Distributed Processing, National University of Defense Technology, China

Abstract
We consider the problem of approximating an arbitrary generic surface with a given set of simple surface primitives. In contrast to previous approaches based on variational surface approximation, which are primarily concerned with finding an optimal partitioning of the input geometry, we propose to integrate a model selection step
into the algorithm in order to also optimize the type of primitive for each proxy. Our method is a joint global optimization of both the partitioning of the input surface as well as the types and number of used shape proxies. Thus,
our method performs an automatic trade-off between representation complexity and approximation error without
relying on a user supplied predetermined number of shape proxies. This way concise surface representations are
found that better exploit the full approximative power of the employed primitive types.
Categories and Subject Descriptors (according to ACM CCS): I.3.5 [Computer Graphics]: Computational Geometry
and Object Modeling—Curve, surface, solid and object representations

1. Introduction
Approximating the geometry of an arbitrarily shaped surface
with a given set of simple surface primitives (e.g. planes,
spheres, cylinders etc.) is an important challenge in several
geometry processing applications. A concise and faithful approximation composed of these simple shapes can give important cues in multi-resolution modeling, remeshing, simplification, subdivision modeling or reconstruction and reverse engineering algorithms. It can also naturally be employed for compression of the geometry since a single of
these elements subsumes a large part of the input model and
faithfully represents it with just a small set of parameters.
Moreover, the structure recovered by the different primitives
can be exploited for feature recognition or symmetry detection.
The problem of finding a surface approximation composed of simple shape primitives (which we will also call
shape proxies) consists of three tightly coupled subproblems:
1. The input surface has to be partitioned in a way that
allows faithful representation of each part by a simple
shape proxy.
† {bao,schnabel,rk}@cs.uni-bonn.de
c 2009 The Author(s)
Journal compilation c 2009 The Eurographics Association and Blackwell Publishing Ltd.
Published by Blackwell Publishing, 9600 Garsington Road, Oxford OX4 2DQ, UK and
350 Main Street, Malden, MA 02148, USA.

Figure 1: The rolling stage model. Points are projected onto
the shape proxies. Left col.: Results of variational surface
approximation. Right col.: Our result. Top row: Proxies are
colored randomly. Bottom row: Proxies are colored according to type (red: plane, yellow: sphere, green: cylinder). Our
method identifies the number of primitives (54), partitions
the interior and finds consistent proxy types.

1986

B. Li & R. Schnabel / Variational Surface Approximation and Model Selection

2. For each partition the type of the approximating primitive
has to be determined. Choosing a different type of primitive might imply a different optimal partitioning of the
surface.
3. For the stability of the algorithm with respect to noise, i.e.
to avoid overfitting, the total number of primitives has to
be identified such that a balance between the complexity of the representation and the approximation error is
found.
In this paper we present a method that, to the best of our
knowledge, for the first time addresses these three problems
in a joint global optimization. Previous methods have primarily focused on global optimization of one or two of these
subproblems only (In this paper we use the term global optimization to refer to methods that use cost functions considering the entire input surface. However, these methods still
compute only local optima of the cost function).
For instance, the variational surface approximation (VSA)
method proposed by Cohen-Steiner et al. [CSAD04] is a
very popular algorithm to compute such surface representations. Their global optimization method aims at finding a
good partitioning of the input surface such that each part
can be well represented by a planar proxy and edges between proxies align with the anisotropy in the underlying
surface. To this end they introduced a novel distortion minimizing geometry partitioning technique reminiscent of the
well-known Lloyd iteration [Llo82]. However, in general
manual user intervention is required to determine a suitable
number of shape proxies. Moreover, the initial placement
and initial representation of the shape proxies have a great
influence on the quality of the final result. To this end, usually random or farthest point initialization is used in conjunction with heuristics such as incremental insertion and
deletion of regions as well as region teleportation. However,
the suitability of these heuristics varies from model to model
and it is still in general an open question when and where to
apply them.
Wu and Kobbelt [WK05] proposed an extension of the
original VSA that handles not only planar proxies but considers a more elaborate set of shape primitives. In addition to the drawbacks inherited from the original VSA, the
employed partitioning algorithm has no notion of the additional degrees of freedom introduced by the different types
of primitives since the type of the primitives is not included
in the global cost function. Indeed, in their extension Wu
and Kobbelt resort to a simple greedy strategy in order to
determine an appropriate surface type for each proxy independently. This strategy may be effective if the input models
contain many parts that closely correspond to the different
primitives under consideration, but for generic input surfaces
that often contain noise or parts not resembling any of the
employed primitives the algorithm may easily get stuck in
local minima or suffer from overfitting. In Fig. 1 some of
these problems become apparent: The VSA approach is un-

able to find a correct partitioning of the interior due to bad
heuristic placement of initial seeds and proxy types become
inconsistent.
In contrast to the above methods, which focus on finding an optimal partitioning for a given number of proxies,
range-image segmentation algorithms based on model selection [BA02] are primarily concerned with determining an
appropriate number of primitives, each of suitable type, in
order to best describe the input data in a globally optimal
manner [DSP90, LGB95]. While model selection allows an
automatic trade-off between the complexity of the representation and its residual error, these methods neglect the partitioning aspect of the approximation problem. This is due
to the fact that they are intended for segmentation of rangeimages that are primarily composed of the considered primitives only. These images usually contain relatively clear cut
features that bound the extend of any given proxy. Therefore these methods lack the ability to effectively handle more
generic surfaces and consequently do not achieve the same
approximation quality as obtained by VSA.
Thus, in this paper we propose a novel surface approximation algorithm that combines VSA with model selection
in a joint global optimization of both the partitioning of the
input surface as well as the types and number of used shape
proxies.
Compared to variational surface approximation, our combined approach offers several important benefits: Model selection allows a trade-off between model complexity and approximation error. This trade-off allows the identification of
a suitable number of appropriately typed proxies in a global
optimization step. Moreover, the selection procedure does
not rely on the heuristic placement of the proxy seeds. Also,
the model selection procedure increases the robustness of
the algorithm, both with respect to noise as well as to subtle
shape variations.
On the other hand, compared to the previous approaches
based on model selection, our method achieves far better
approximations on arbitrarily shaped generic input surfaces
due to the joint optimization of the surface partitioning.
Moreover, just as in the original VSA, the generated partitioning respects the anisotropy of the input surface and
aligns proxies accordingly.
2. Related work
Mesh simplification tries to find an optimal piecewise planar surface representation for either a given number of target
triangles or a given target approximation error. As Agarwal
and Suri [AS98] have proven this problem to be NP-hard
most approaches are greedy and employ heuristics based on
local geometric properties. Very popular methods are based
on vertex removal or edge collapse [Hop96,GH97,GGK02].
In a similar greedy fashion faces can be clustered [KT96,
She01,GWH01,SSGH01,SWG∗ 03,MK05] and replaced by
c 2009 The Author(s)
Journal compilation c 2009 The Eurographics Association and Blackwell Publishing Ltd.

1987

B. Li & R. Schnabel / Variational Surface Approximation and Model Selection

a single proxy per cluster. The coarse representations obtained with these methods usually only use planar approximations. Despite the greedy nature of the algorithms they
are for instance suitable for generation of a base mesh in
multiresolution modeling, but of course do not reveal the
structure of the original fine input model to the same degree
as approximations using higher order proxies and/or global
optimization.
An exception in this area is the method of Hoppe et al.
[HDD∗ 93] which uses global optimization to find a simplified mesh that well approximates the input geometry. However they do not consider using higher order primitives.
Variational surface approximation itself has also been extended to quadric shape proxies by Yan et al. [YLW06], but
since only a single type of primitive is employed the original partitioning algorithm is quite sufficient in that setting.
Chiosa and Kolb [CK08] proposed an interesting combination of hierarchical face clustering approaches with variational surface approximation but considered only planar
shape proxies.
Remeshing algorithms [Tur92,LSS∗ 98,KVLS99,GVSS00,
BK01] do not primarily aim at finding efficient approximations of the given input surface but rather seek to find
a representation composed of high quality mesh elements.
However, due to the anisotropy encountered in most models,
the shape of mesh elements is important in order to achieve
high approximation precision with few elements. Therefore
remeshing techniques can benefit from approximations composed of higher order proxies as demonstrated by Marinov
and Kobbelt [MK06].
Reverse
engineering
and
reconstruction techniques [VMC97, PR98, BKV∗ 02, PLH∗ 05] usually segment
the input geometry into parts corresponding to different surface primitives such that the obtained reconstruction exactly
recovers the underlying structure - often in a way suitable
for post-processing in a CAD system. Moreover, recovered
primitives can also be used for completion of missing parts
in the acquired model [SDK09]. For detection of the primitives, region growing approaches [FEF97,VHB08] or robust
methods such as for instance RANSAC [FB81, SWK07]
are employed. These approaches however usually do not
consider global optimization of the generated approximation
and can be attributed to the class of greedy algorithms.
Model selection is a branch of statistics and information
theory [BA02], which is concerned with finding the right
parametric model for a given set of data. A scoring function
is used to evaluate different models that were fitted to the
data. The model with the best score is then selected as the
most appropriate one. This paradigm has previously been
used for range-image segmentation with parametric models as discussed in the introduction [DSP90, LGB95]. These
c 2009 The Author(s)
Journal compilation c 2009 The Eurographics Association and Blackwell Publishing Ltd.

methods first construct a large set of redundant parametric models (which possibly overlap) and then select a suitable subset that best describes the data according to the respective model selection criterion. The model selection is a
global optimization that chooses the most appropriate types
of models. However, as mentioned earlier, these methods do
not consider a global optimization of the partitioning.
The hypothesize and select principle has also been applied
in other areas, e.g. Leonardis et al. [LBM02] have proposed
a similar algorithm for construction of multiple eigenspaces
for approximation of high-dimensional vector data. However, in this setting finding an optimal partitioning is trivial
and therefore is not addressed specifically either.
3. Problem
Given the input surface S, we seek to find a partitioning
Rk = {R1 , . . . , Rk }, S = ki=1 Ri where each Ri is a connected subset of S. For each such region a corresponding
shape proxy Pi has to be determined. The proxies Pk =
{P1 , . . . , Pk } can be of different type, i.e. in this work we consider Pi ∈ {plane, sphere, cylinder, cone, torus}. For some
applications it is also useful to allow unapproximated regions, in which case we write Pi = ∅. The partitioning and
the proxies shall minimize the following energy
k

E(Rk , Pk ) =

∑ C(Ri , Pi )

(1)

i=1

where C(Ri , Pi ) is defined by a model selection criterion. In
the model selection literature there is a large body of different criterions to choose from. One of the popular criteria is Akaike’s An Information Criterion (AIC) [Aka73]
which minimizes the expected entropy of yet unobserved
data, but suffers from a tendency to overfit [LB87]. Other
popular model selection criteria are based on minimizing
the coding length of the observed data with respect to
the employed models: Wallace’s Minimum Message Length
(MML) [WB68] and Rissanen’s very similar, but independently developed, Minimum Description Length (MDL)
[Ris78]. Although based on an Bayesian standpoint the
Bayesian Information Criterion (BIC) by Schwarz [Sch78]
also leads to a very similar measure. However, in practice
most of these models and their variants behave very similarly
and the differences are mostly negligible [BHG06]. Given
the small practical differences, we base the remainder of this
discussion on the MDL criterion as it provides a small set
of relatively simple and intuitive parameters for controlling
the trade-off between complexity and error. However, it is
important to note that our approximation algorithm is by no
means limited to this choice and other criteria can easily be
adapted to our setting as well [KL04].
Given our choice of model selection criterion we can define C(Ri , Pi ) as follows:
C(Ri , Pi ) = L(Ri |Pi ) + L(Pi )

(2)

1988

B. Li & R. Schnabel / Variational Surface Approximation and Model Selection

(a) Result of VSA

(b) Our intermediate result

(c) Intermediate result

(d) Intermediate result

(e) Our final result

Figure 2: Points are projected on their representing primitives and colored according to the primitive’s type (sphere: yellow,
cylinder: green, cone: purple, torus: grey) (a) Result of VSA. (b)-(d) Intermediate results of our algorithm (e) Our final result.
Compared to VSA our result better recovers the symmetries in the geometry, especially in the head area.

where L(Ri |Pi ) denotes the coding length required for describing the deviation of Ri from the given proxy Pi (usually
called residuals) and L(Pi ) for the model parameters respectively. Commonly L(Ri |Pi ) is defined as L(Ri |Pi ) = 2σ1 2 RSS
in the MDL framework, where RSS denotes the residual sum
of squares and σ2 the noise variance in the data [HY01].
Thus in our setting, one would ideally like to base L(Ri |Pi )
on the distance between Ri and Pi , i.e.
L(Ri |Pi ) = α

s∈Ri

d(s, Pi )2 ds

(3)

where α is an application dependent weighting factor and
d(s, Pi ) denotes the distance of s to Pi (using either the L2
or L2,1 norm). While computing s∈Ri d(s, Pi )2 ds exactly is
feasible if Ri is given as triangle mesh, this is no longer the
case when dealing with point sampled geometry. Therefore,
in practice we resort to a simple approximation that is based
on a point wise sampling of Ri (this is a common approximation, similar for instance to [HDD∗ 93]):
L(Ri |Pi ) = α

∑

w j d(p j , Pi )2

(4)

p j ∈Π(Ri )

where Π(Ri ) = {p1 , . . . , pn } denotes the point sampling of
Ri and w j is a weighting factor for each point that depends
linearly on the surface area represented by the sample p j .
In our implementation we use triangle barycenters for Π(Ri )
if S is given as a triangle mesh (and the triangle area for
weighting), for point-clouds we use the original input points
(and the area of a disk enclosing the k nearest neighbors for
determination of the weight). L(Ri |∅) is defined as
L(Ri |∅) = γ

∑

wj

4. Overview
To minimize the energy of Eq. (1) we have to simultaneously
determine the number of partitions k, the shape of the partitions Ri and the optimal type and parameters of the proxies Pi
- which all evidently are very tightly coupled. It is quite clear
that even for a relatively simple input surface S, it is computationally not feasible to explore all possible partitions and
test all possible proxies in order to find the optimal solution.
It is therefore necessary to limit the search space to a small
set of promising solutions. Our approach to this is threefold:
• We create an initial set of redundant proxy hypotheses using a RANSAC approach. Only hypotheses are included
in the set that promise a certain minimal merit. This way a
first reduction of the search space, albeit not very restrictive, is achieved.
• The entire set of hypotheses is iteratively refined. Each
hypothesis is optimized with respect to the other hypotheses in the set. To this end, for a given hypothesis, a model
selection procedure chooses the best proxies from the set
to complement the approximation.
• A partitioning algorithm finds suitable regions for each
of the selected proxies. These regions are used for reestimating the model parameters and in the next iteration
of the model selection procedure.

(5)

p j ∈Π(Ri )

where γ again is a user specified factor.
Finally, L(Pi ) considers the complexity of Pi and is defined as
L(Pi ) = β|Pi |

is an application dependent weighting factor (Please refer to
Sec. 9 for a discussion of the weighting factors). We set L(∅)
to zero.

(6)

where |Pi | denotes the number parameters of Pi and β again

By iteratively refining each hypothesis in the set with respect
to the remaining proxies, our algorithm is able to circumvent
early commitment to a small set of hypotheses and can therefore better avoid local minima (In contrast to other model
selection based algorithms such as [LBM02]). This principle of maintaining a set of possible solutions is similar to
genetic algorithms, however we use a different update rule
which is specific to our setting.
c 2009 The Author(s)
Journal compilation c 2009 The Eurographics Association and Blackwell Publishing Ltd.

1989

B. Li & R. Schnabel / Variational Surface Approximation and Model Selection

Algorithm 1 The main steps of the proposed algorithm
1: (R0 , P 0 ) = CreateInitialSet(S)
2: repeat
3:
for all Pi ∈ P t do
4:
(Ti , Qi ) = ModelSelection(Pit , Rti , (Rt \ Rti , P t \
5:
6:
7:
8:
9:
10:

Pit ))
(Ti , Qi ) = Partitioning(Ti , Qi )
Pit+1 = Q0
Rt+1
= T0
i
end for
until convergence
return Partitioning(ModelSelection(R, P))

The main structure of our method is outlined in Algorithm
1. After creation of the initial set the algorithm consists of
two nested loops. In each iteration of the outer loop (lines
2 - 9) the set of shape hypotheses with associated partitions
(Rt , P t ) is refined until convergence is detected. The inner
loop (lines 3 - 8) is responsible for the actual evolution of the
set and iterates over all hypotheses and for each computes an
updated version. A proxy Pit is refined in two steps:
1. A model selection procedure selects a suitable subset
(Ti ⊂ Rt , Qi ⊂ P t ) of hypotheses such that the surface
S is well approximated according to the model selection criterion. This selection however is forced to include the proxy Pit with associated region Rti (line 4), i.e.
Ti = {Rti , . . .} and Qi = {Pit , . . .}. Thus, the model selection effectively determines a set of hypotheses to complement (Rti , Pit ).
2. In the second step an optimal partitioning given the selected subset (Ti , Qi ) is determined using variational
shape approximation (line 5). Finally the hypothesis Pit+1
and its associated region are updated with the new model
parameters and region estimated during the partitioning
(line 6-7).
After convergence (line 10) a global model selection chooses
the best subset of hypotheses from the set, finds a partitioning for these proxies and returns the result. In Fig. 2 some
intermediate results after two, four and six iterations on the
bunny are shown. Our method chooses different sets of primitives in these iterations such that local minima are indeed
effectively avoided until it finally converges after ten iterations.
5. Initial hypotheses
In the first phase of the algorithm an initial set of hypotheses
(R0 , P 0 ) has to be determined. This set will form the basis for the remaining iterations of the algorithm that seek the
final surface approximation. The challenge in this phase is
to find a suitable trade-off between the size of the generated
set and the restrictions imposed on the following steps by
the limited number of hypotheses. Therefore it is important
c 2009 The Author(s)
Journal compilation c 2009 The Eurographics Association and Blackwell Publishing Ltd.

that the initial hypotheses included in the set are not entirely
random but fulfill certain minimal criteria to justify inclusion. However, these criteria should be kept as unrestrictive
as possible.
As creating an initial set of redundant hypotheses is also
a fundamental prerequisite for other model selection based
range-image segmentation algorithms, it is not surprising
that Stricker and Leonardis [SL95] already observed that
these contradicting requirements can be well addressed in
a RANSAC approach. They give a very general method for
generating a set of hypotheses that is suitable in very different application scenarios. We found that in our case it is sufficient to combine the results of several runs of traditional
RANSAC-based shape detection [SWK07] that were executed with varying parameters to form the initial set of hypotheses. The RANSAC method generates hypotheses using
all considered types of primitives, i.e. planes, spheres, cylinders, cones and tori. At the same time it ensures that each
detected primitive has a sufficiently large support region and
selects only the most promising from the huge number of
randomly generated hypotheses. In our experiments we use
parameters in the RANSAC that roughly reflect the desired
approximation error and combine the results of ten runs to
form the initial set.
6. Model selection
Given a set of hypotheses (R, P) it is the task of the model
selection stage to extract an optimal subset that minimizes
Eq. (1), i.e. find a binary vector b of length |(R, P)| that
specifies the selection (bi = 1) or absence (bi = 0) of a proxy
(Ri , Pi ) respectively, such that
E(b) =

∑

biC(Ri , Pi )

(7)

(Ri ,Pi )∈(R,P)

is minimized. Thus, in contrast to variational shape approximation, the model selection does not have a built-in constraint that enforces the entire surface to be covered by proxies. Indeed, model selection intentionally has the option of
not choosing a model for some parts of the input surface if
an approximation of these parts is too expensive in terms
of the selection criterion. This trade-off is controlled by the
three parameters α, β and γ. Therefore, however, we can not
directly minimize Eq. (7) (b = 0 will always have zero cost)
but have to restate the problem in terms of savings gained
by the selected models. It is then the goal of the selection
to maximize these savings. The savings for a given proxy
(Ri , Pi ) are defined as follows:
V (Ri , Pi ) = L(Ri |∅) − L(Ri |Pi ) − L(Pi )
=

∑

w j (γ − αd(p j , Pi )2 ) − β|Pi |

(8)

p j ∈Π(Ri )

However, simply maximizing the sum ∑i biV (Ri , Pi ) ignores
the overlap between the different hypotheses and would
therefore yield suboptimal results. On the other hand, taking

1990

B. Li & R. Schnabel / Variational Surface Approximation and Model Selection

into account the true overlap between all the proxies would
be computationally infeasible. We therefore resort to an approximation of the overlap that only considers pairwise intersections of proxies. With this approximation the problem
can be stated as a quadratic boolean expression
1
M(b) = bT Vb
(9)
2
with a symmetric matrix V defined as follows (this formulation was first used by Leonardis et al. [LGB95]):


−v12 · · · −v1N
2v1
 −v12
2v2
· · · −v2N 


V=
(10)

..
..
..
..


.
.
.
.
−v1N −v2N · · · 2vN
where vi = V (Ri , Pi ) and vi j approximates the excess savings attributed to the area of overlap Ri j = Ri R j between
proxies i and j:
vi j = −L(Ri j |∅) +
+

α
2

∑

1
max(V (Ri j , Pi ),V (Ri j , Pj ))
2

wk max(d(pk , Pi )2 , d(pk , Pj )2 ) (11)

pk ∈Π(Ri j )

Optimization of Eq. (9) is known to be NP-hard, however,
as noted by Schindler et al. [SSW08], one can exploit the
submodular nature of the problem to formulate a relatively
efficient branch-and-bound search that - while not guaranteeing a global optimum - proves to give satisfactory results
in practice and outperforms the simple greedy search originally proposed by Leonardis et al. [LGB95]. It is also important to note that V is in general sparse and only those nonzero entries have to be computed that actually are accessed
during the branch-and-bound search.
7. Partitioning
In the partitioning stage our method closely follows the approach formulated by Cohen-Steiner et al. [CSAD04] and
Wu and Kobbelt [WK05]. For completeness we will give
a short summary of the algorithm here but refer to these
original works for a more detailed description. Similarly to
Lloyd’s method, variational shape approximation consists of
two stages, partitioning and refitting, which are repeated alternatingly. A single iteration of the algorithm consists of the
partitioning stage followed by the fitting. In the fitting stage
each proxy’s parameters are estimated given its currently
corresponding partition Ri . Similar to Wu and Kobbelt we
always use least-squares minimization for parameter estimation. We further select the optimal type of primitive to represent the current region Ri . To this end we use a RANSAC algorithm on Ri to generate initial estimates for all the considered types of primitives, compute the least-squares fits and
choose the type of primitive with lowest cost.
The second stage of the algorithm is then responsible for
refining the partitions Ri . To this end a distortion minimizing

flooding assigns each triangle (or point if dealing with pointclouds) to the best fitting proxy, but at the same time enforces
connectivity of the regions Ri . For each proxy the flooding
originates in the best fitting triangle and the different regions
are grown by drawing neighboring triangles from a global
priority queue. Since for any proxy the flooding originates
only in a single, best fitting seed triangle, the partitioning
can easily deal with an initial set of proxies that may contain
overlapping regions (as is the case after the model selection).
The flooding will then automatically resolve the ambiguity
in the overlap regions.
8. Refined algorithm
In the outline of the method presented in Algorithm 1 we
have not yet explicitly specified how to detect convergence.
Moreover, in the form presented in Algorithm 1 our method
is still quite inefficient. In this section we will fill these gaps
and discuss convergence as well as two vital optimizations
to increase the efficiency of our approach.
8.1. Convergence
In principle, the method in Algorithm 1 converges if the entire set of hypotheses (R, P) reaches a state of equilibrium.
However there are three issues with this definition of convergence:
• It may take an extremely large number of iterations to
reach convergence on the entire set
• During most of the iterations, proxies are refined that will
not get selected into the final representation (see line 10
in Algorithm 1)
• Convergence cannot be guaranteed
While we currently cannot prove convergence for our refined
algorithm, we can at least circumvent the first two of these
problems by testing for convergence on the set of proxies
returned by a global model selection. Thus, instead of waiting for the entire set (R, P) to stabilize, we test for convergence of Partitioning(ModelSelection(R, P)) in line 9 of
Algorithm 1. In practice we say the selection converged if
after an iteration the set of selected proxies remained unchanged and the cost of this selection (as defined by Eq. (1))
varied less than a user specified factor.
Of course restricting the test for convergence only on this
globally selected subset implies that some of the ability of
our algorithm to avoid local minima gets lost - after all it
is quite possible that a proxy gets selected into this subset
only after having been refined many times - but fortunately
in our experiments we did not observe any degradation in the
quality of the generated minima.
8.2. Performance optimizations
We suggest two strategies to increase the efficiency of Algorithm 1: The first one is based on pruning unused proxies
c 2009 The Author(s)
Journal compilation c 2009 The Eurographics Association and Blackwell Publishing Ltd.

B. Li & R. Schnabel / Variational Surface Approximation and Model Selection

1991

from the global set of hypotheses (R, P) and the second reduces the number of inner loop iterations required to refine
(R, P).
Pruning For each proxy (Ri , Pi ) we monitor whether it gets
selected during the refinement of any of the other hypotheses, i.e. if (Ri , Pi ) is part of any of the sets (T j , Q j ) =
ModelSelection(Pj , R j , (R \ R j , P \ Pj )) for j = i. If a proxy
is not included in any of these sets for a given number of
iterations (we use two in our implementation), we assume
that it is redundant and, given the remaining proxies in the
global set, of no merit to the approximation of the surface
S and can thus be safely removed from the global set of
hypotheses. Due to the large amount of redundancy in the
initial set, in practice the number of pruned proxies will usually be large only during the first iterations but, depending
on the input surface and the size of the initial set, in general
removes 50%-80% of all hypotheses.
Proxy refinement The second optimization is based on the
observation that the sets (Ti , Qi ) and (T j , Q j ) for two different proxies are either identical or at least extremely similar
if (R j , Pj ) ∈ (Ti , Qi ) and (Ri , Pi ) ∈ (T j , Q j ). Thus, in each
iteration of the inner loop in Algorithm 1 we do not only
update the proxy (Ri , Pi ) but all the proxies contained in the
set (Ti , Qi ) and then skip the refinement iterations for these
proxies respectively. We found this optimization to reduce
the number of required iterations in the inner loop by 30%50%.
It is quite clear that, as was the case for the convergence
test, the same objection concerning susceptibility to local
minima may be raised for these two optimizations as well.
However, again we empirically found no adverse effects of
these strategies.
9. Evaluation
When comparing our method with variational shape approximation we consider two different settings: First we use suitable parameter settings in our method in order to simulate
the behavior of Wu and Kobbelt’s approach. But it is also
possible to use our MDL cost function in the variational surface approximation, so that we also give comparisons on that
basis. In this case we let our method automatically determine the number of primitives and then compare the result
to that of VSA using that same number. Please note that teleportation is always used in VSA to get better placements of
shapes.
In order to simulate the cost function of the original VSA,
the parameters in the MDL criterion should be set to α = 1,
β = 0 and γ must be large enough so that approximating any
point will always yield a benefit. We found a value of 10
times the bounding box diagonal to be sufficient in all cases.
In Fig. 2 we compare our result to that of VSA on the
c 2009 The Author(s)
Journal compilation c 2009 The Eurographics Association and Blackwell Publishing Ltd.

Figure 3: Approximation of the horse model. Left column:
original model. Middle column: Result of our method. Right
column: Result of VSA. 200 primitives were used in the approximation. Our method achieves significantly lower error
and better recovers symmetries.

bunny model using a user specified number of primitives
(31), the parameter settings described above and the L2,1
norm. While for this model our method only achieves a
marginal improvement in the overall approximation error
(about 1%) our result appears visually more appropriate as
it better captures the symmetries of the surface, especially in
the area of the head.
A similar comparison is demonstrated in Fig. 3 on the
horse model using 200 primitives. In this case our method
achieves a significant improvement in the approximation error (the error of VSA is 2.5 times as large). The superior
approximation of our method is reflected in a higher degree
of symmetry of the primitives (e.g. on the neck and the back)
as well as better recovery of structures in the head area.
For the result of Fig. 4 we used our method to automatically determine an appropriate number of proxies. In this
case we base the choice of the parameters in the MDL criterion on the following intuition: We always set γ = 1. Then β
can be seen as controlling the number of points a proxy has
to subsume in order to become beneficial. For instance, a
sphere has four parameters and therefore has to approximate
at least 4β points in order to be worthwhile (The choice of
β in general is quite subjective and in our experiments we
always use β = 10 as we found this to give a reasonable
trade-off on all our models). However, the degree to which
each point is credited to the proxy depends on the approximation error and is controlled by the parameter α. Intuitively
α controls the desired error of the resulting approximation.
In practice, if we desire an average approximation error of ε

1992

B. Li & R. Schnabel / Variational Surface Approximation and Model Selection

(a) Input model

(b) β = 3

(e) Input model (f) ε = .001B

(c) β = 10

(d) β = 50

(g) ε = .003B

(h) ε = .015B

Figure 5: Top row: Results on original rocker-arm model
for varying settings of β. Our method selects 69 (b), 29 (c),
17 (d) primitives; Bottom row: Results on rocker-arm model
with synthetic Gaussian noise σ = 0.3%B added. For different ε values, 51 (f), 34 (g), 28 (h) primitives are selected.
Figure 4: Approximation of the fertility model. Top row:
Input model. Middle row: Our result. Bottom row: Result of
VSA. The number of used primitives (50) was automatically
determined by our approach. Our approximation has lower
cost and better captures the structure of the input model, e.g.
at the legs of the woman.

we set α = 3ε12 . Note however that the algorithm does not
guarantee this error but instead finds a trade-off between
achieving the error and the complexity of the representation. For the fertility model in Fig. 4 we used ε = .006B
where B denotes the length of the bounding box diagonal
(We use the L2 norm). Our method then automatically selected 50 proxies. To compare our result to that of VSA we
replaced the original cost function in VSA with our MDL
criterion and executed VSA using 50 as the predetermined
number of primitives. The result of our method has lower
cost (about 5%) and again achieves a high degree of symmetry in the representation. Moreover our approximation better represents the area of the woman’s legs which suggests
that our algorithm can indeed find better placements for the
proxies and can better capture the underlying surface using
the same number of primitives.
Fig. 5 illustrates the effect of different parameter settings
on our method. The top row depicts three results for varying settings of β on the rocker-arm model (ε = .001B in all
cases). As expected β affects the level of detail of the approximation and larger values of β lead to coarser approximations composed of fewer primitives. In the bottom row
artificial Gaussian noise with σ = .003B was added to the
rocker-arm model. Results for varying settings of ε are de-

Figure 6: Automatic determination of the number of proxies. Our method successfully determines the correct number
of primitives (53). Please see text for details.
picted while β = 10 is kept fixed. If ε is smaller than the
actual noise scale some oversegmentation occurs. If ε equals
the noise scale most details are reliably recovered on a scale
comparable to that of the results on the clean model. For a
choice of ε larger than the noise scale a coarser approximation is computed accordingly.
For the results of Fig. 1 we used the L2,1 norm and our
method automatically selected 54 proxies. We achieve about
10% lower cost than VSA and our result is clearly superior.
Especially in the interior our global selection is able to determine the correct placement of proxies, whereas VSA gets
stuck in a suboptimal solution. Also note that our method assigns proxy types consistently, even though the model contains some noise - this is a direct consequence of the model
selection trade-off.
In order to evaluate the quality of the automatically selected number of primitives we can do the following: We execute VSA using the MDL cost function and incrementally
add additional primitives while recording the cost achieved
for each number. One would expect the cost to be high in
c 2009 The Author(s)
Journal compilation c 2009 The Eurographics Association and Blackwell Publishing Ltd.

B. Li & R. Schnabel / Variational Surface Approximation and Model Selection

Model
Rolling stage
Bunny
Horse
Fertility
Rocker-arm (avg.)
Neptune

TT
39
46
289
173
37
94

TI
1
1
2
2
1
3

TM
16
19
124
70
15
38

TP
22
26
163
101
21
53

Table 1: Timings for our method on different models (in
minutes). TT gives the total time. TI is the time for generation
of the initial set. TM is the time required for model selection
and TP that for partitioning.

the beginning when there are still too few proxies to faithfully describe the surface and then to decrease for each added
primitive. But after a while the cost should stop decreasing
and then rise again as the gain of each new primitives can
no longer outweigh its cost in terms of the representation
complexity. This behavior can indeed be observed in Fig. 6
where we used the bunny model. Since our method achieves
approximations of equal merit on the bunny model we used it
to automatically select a proper number of primitives for the
same set of parameters (ε = .01B). As expected our method
selects 53 primitives which is indeed at the turning point of
the curve.
Finally, for the neptune model in Fig. 7 our method automatically selected 110 primitives (using ε = .001B and L2
norm). Compared to VSA our method achieves 4% lower
cost which is clearly reflected in a more detailed representation of the features in the area of the upper part of the body.
Again we believe this is due to the fact that our method has
more freedom in the placement of proxies and can indeed
evaluate the global effect of different partitionings.

10. Conclusion
We have presented a novel algorithm that combines variational surface approximation with model selection. This
combination is in fact a joint global optimization of the partitioning of the input surface as well as the types and number
of used shape proxies. As demonstrated, compared to previous approaches, our method achieves at least similar approximation quality but is often able to find superior representations. Especially when an automatic trade-off between
model complexity and approximation quality is desired our
method’s full potential becomes apparent. A current limitation of our approach is the runtime performance. On the
models shown in this paper our method takes up to 5 hours
to compute the results (see Table 1 for details). Therefore
finding further performance optimizations is one of the primary goals in our future research. We further plan to evaluate
the merit of our method in applications such as compression
and symmetry detection in the future.
c 2009 The Author(s)
Journal compilation c 2009 The Eurographics Association and Blackwell Publishing Ltd.

1993

Acknowledgments
Bao Li is supported by the China Scholarship Council
(CSC). This work is partially supported by the National
Natural Science Foundation of China under Grant No.
60773020. The bunny model is courtesy of Stanford University. The rolling stage, horse, fertility, rocker-arm and
neptune models are courtesy of the AIM@SHAPE Shape
Repository.
References
[Aka73] A KAIKE H.: Information theory and an extension of the
maximum likelihood principle. In Second International Symposium on Information Theory (Budapest, 1973), Akademiai Kaidó,
pp. 267–281.
[AS98] AGARWAL P. K., S URI S.: Surface approximation and
geometric partitions. Journal of Computing 27, 4 (1998), 1016–
1035.
[BA02] B URNHAM K. P., A NDERSON D. R.: Model Selection
and Multi-Model Inference: A Practical Information-Theoretic
Approach. Springer, 2002.
[BHG06] BAB -H ADIASHAR A., G HEISSARI N.: Range image
segmentation using surface selection criterion. IEEE Transactions on Image Processing 15, 7 (2006), 2006–2018.
[BK01] B OTSCH M., KOBBELT L. P.: Resampling feature and
blend regions in polygonal meshes for surface anti-aliasing.
Computer Graphics Forum 20, 3 (2001).
[BKV∗ 02] B ENKÖ P., K ÓS G., V ÁRADY T., A NDOR L., M AR TIN R. R.: Constrained fitting in reverse engineering. Computer
Aided Geometric Design 19, 3 (2002), 173–205.
[CK08] C HIOSA I., KOLB A.: Variational multilevel mesh clustering. In Shape Modeling International (2008), pp. 197–204.
[CSAD04] C OHEN -S TEINER D., A LLIEZ P., D ESBRUN M.:
Variational shape approximation. ACM Trans. on Graph. 23, 3
(2004), 905–914.
[DSP90] DARRELL T. J., S CLAROFF S., P ENTLAND A. P.: Segmentation by minimal description. In ICCV (1990), pp. 112–
116.
[FB81] F ISCHLER M. A., B OLLES R. C.: Random sample consensus: a paradigm for model fitting with applications to image analysis and automated cartography. Communications of the
ACM 24, 6 (1981), 381–395.
[FEF97] F ITZGIBBON A. W., E GGERT D. W., F ISHER
R. B.: High-level CAD model acquisition from range images.
Computer-aided Design 29, 4 (1997), 321–330.
[GGK02] G OTSMAN C., G UMHOLD S., KOBBELT L.: Simplification and compression of 3d meshes. In Proceedings of the
European Summer School on Principles of Multiresolution in Geometric Modelling (PRIMUS) (2002), pp. 319–361.
[GH97] G ARLAND M., H ECKBERT P. S.: Surface simplification
using quadric error metrics. In SIGGRAPH (1997), pp. 209–216.
ˇ
[GVSS00] G USKOV I., V IDIM CE
S CHRÖDER P.: Normal meshes.
pp. 95–102.

K., S WELDENS W.,
In SIGGRAPH (2000),

[GWH01] G ARLAND M., W ILLMOTT A. J., H ECKBERT P. S.:
Hierarchical face clustering on polygonal surfaces. In SI3D
(2001), pp. 49–58.
[HDD∗ 93] H OPPE H., D E ROSE T., D UCHAMP T., M C D ONALD
J., S TUETZLE W.: Mesh optimization. In SIGGRAPH (1993),
vol. 27, pp. 19–26.

1994

(a) Input model

B. Li & R. Schnabel / Variational Surface Approximation and Model Selection

(b) Our result

(c) Result of VSA

(d) Input model

(e) Our result

(f) Result of VSA

Figure 7: Results on the neptune object. Our method automatically selected 110 primitives and recovers more features at lower
cost than VSA.
[Hop96] H OPPE H.: Progressive meshes. In SIGGRAPH (1996),
pp. 99–108.

[Sch78] S CHWARZ G.: Estimating the dimension of a model. The
Annals of Statistics 6 (1978), 461–464.

[HY01] H ANSEN M. H., Y U B.: Model selection and the principle of minimum description length. Journal of the American
Statistical Association 96, 454 (2001), 746–774.

[SDK09] S CHNABEL R., D EGENER P., K LEIN R.: Completion
and reconstruction with primitive shapes. Computer Graphics
Forum 28, 2 (2009), 503–512.

[KL04] K VERH B., L EONARDIS A.: A generalisation of model
selection criteria. Pattern Anal. Appl 7, 1 (2004), 51–65.

[She01] S HEFFER A.: Model simplification for meshing using
face clustering. Computer-Aided Design 33, 13 (2001), 925–934.

[KT96] K ALVIN A. D., TAYLOR R. H.: Superfaces: Polygonal
mesh simplification with bounded error. IEEE Comput Graphics
Appl 16, 3 (1996), 64–77.

[SL95] S TRICKER M., L EONARDIS A.: Exsel++: A general
framework to extract parametric models. In Computer Analysis of Images and Patterns, 6th International Conference (1995),
vol. 970, pp. 90–97.

[KVLS99] KOBBELT L. P., VORSATZ J., L ABSIK U., S EIDEL
H.-P.: A shrink wrapping approach to remeshing polygonal surfaces. Computer Graphics Forum 18, 3 (1999), 119–130.
[LB87] L EONTARITIS I. J., B ILLINGS S. A.: Model selection
and validation methods for nonlinear systems. Int. J. Control 45,
1 (1987), 311–341.
[LBM02] L EONARDIS A., B ISCHOF H., M AVER J.: Multiple
eigenspaces. Pattern Recognition 35, 11 (2002), 2613–2627.
[LGB95] L EONARDIS A., G UPTA A., BAJCSY R.: Segmentation
of range images as the search for geometric parametric models.
International Journal of Computer Vision 14, 3 (1995), 253–277.

[SSGH01] S ANDER P. V., S NYDER J., G ORTLER S. J., H OPPE
H.: Texture mapping progressive meshes. In SIGGRAPH (2001),
pp. 409–416.
[SSW08] S CHINDLER K., S UTER D., WANG H.: A modelselection framework for multibody structure-and-motion of image sequences. International Journal of Computer Vision 79, 2
(2008), 159–177.
[SWG∗ 03] S ANDER P. V., W OOD Z. J., G ORTLER S. J., S NYDER J., H OPPE H.: Multi-chart geometry images. In Symposium
on Geometry Processing (2003), vol. 43, pp. 146–155.

[Llo82] L LOYD S. P.: Least squares quantization in PCM. IEEE
Transactions on Information Theory 28, 2 (1982), 129–136.

[SWK07] S CHNABEL R., WAHL R., K LEIN R.: Efficient ransac
for point-cloud shape detection. Computer Graphics Forum 26,
2 (June 2007), 214–226.

[LSS∗ 98] L EE A. W. F., S WELDENS W., S CHRÖDER P.,
C OWSAR L., D OBKIN D.: MAPS: Multiresolution adaptive parameterization of surfaces. In SIGGRAPH (1998), pp. 95–104.

[Tur92] T URK G.: Re-tiling polygonal surfaces.
Graphics 26, 2 (1992), 55–64.

[MK05] M ARINOV M., KOBBELT L.: Automatic generation of
structure preserving multiresolution models. Comput. Graph. Forum 24, 3 (2005), 479–486.
[MK06] M ARINOV M., KOBBELT L.: A robust two-step procedure for quad-dominant remeshing. Computer Graphics Forum
25, 3 (2006), 537–546.
[PLH∗ 05] P OTTMANN H., L EOPOLDSEDER S., H OFER M.,
S TEINER T., WANG W.: Industrial geometry: recent advances
and applications in CAD. Computer-Aided Design 37, 7 (2005),
751–766.
[PR98] P OTTMANN H., R ANDRUP T.: Rotational and helical surface approximation for reverse engineering. Computing 60, 4
(1998), 307–322.
[Ris78] R ISSANEN J.: Modeling by shortest data description. Automatica 14 (1978), 465–471.

Computer

[VHB08] VANCO M., H AMANN B., B RUNNETT G.: Surface reconstruction from unorganized point data with quadrics. Comput.
Graph. Forum 27, 6 (2008), 1593–1606.
[VMC97] V ÁRADY T., M ARTIN R. R., C OX J.: Reverse engineering of geometric models - an introduction. Computer-aided
Design 29, 4 (1997), 255–268.
[WB68] WALLACE C. S., B OULTON D. M.: An information
measure for classification. The Computer Journal 11, 2 (1968),
185–194.
[WK05] W U J., KOBBELT L.: Structure recovery via hybrid variational surface approximation. Computer Graphics Forum 24, 3
(2005), 277–284.
[YLW06] YAN D.-M., L IU Y., WANG W.: Quadric surface extraction by variational shape approximation. In Geometric Modeling and Processing (2006), vol. 4077, pp. 73–86.

c 2009 The Author(s)
Journal compilation c 2009 The Eurographics Association and Blackwell Publishing Ltd.

