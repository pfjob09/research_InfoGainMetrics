DOI: 10.1111/j.1467-8659.2007.01030.x

COMPUTER GRAPHICS

forum

Volume 27 (2008), number 1 pp. 1–12

Real-Time GPU Silhouette Refinement using Adaptively
Blended B´ezier Patches
C. Dyken1,2 , M. Reimers1 and J. Seland1
1 Centre

of Mathematics for Applications, University of Oslo, Norway
of Informatics, University of Oslo, Norway
johan.seland@gmail.com

2 Department

Abstract
We present an algorithm for detecting and extracting the silhouette edges of a triangle mesh in real time using
Graphical Processing Units (GPUs). We also propose a tessellation strategy for visualizing the mesh with smooth
silhouettes through a continuous blend between B´ezier patches with varying level of detail. Furthermore, we
show how our techniques can be integrated with displacement and normal mapping. We give details on our GPU
implementation and provide a performance analysis with respect to mesh size.
Keywords: Silhouette, Triangle Mesh, GPU, B´ezier Patch
ACM CCS: I.3.5 [Computational Geometry and Object Modeling]: Curve, Surface, Solid and Object Representations, Geometric algorithms, Languages, Systems, 1.3.3 [Three-Dimensional Graphics and Realism]: Viewing
algorithms

1. Introduction

mesh geometry and shading normals. These patches are in
the subsequent section tessellated adaptively using the silhouetteness to determine the local level of detail. The result
is a ‘watertight’ mesh with good geometric quality along the
silhouettes, which can be rendered efficiently. We continue by
discussing details of our GPU implementation in Section 6,
and show how to integrate our approach with normal and
displacement mapping. Thereafter, in Section 7, we compare
the performance of our GPU implementation with several
CPU-based methods, before we conclude.

Coarse triangular meshes are used extensively in real-time
rendering applications such as games and virtual reality systems. Recent advances in graphics hardware have made it possible to use techniques such as normal mapping and per pixel
lighting to increase the visual realism of such meshes. These
techniques work well in many cases, adding a high level of
detail to the final rendered scene. However, they can not hide
the piecewise linear silhouette of a coarse triangular mesh.
We propose an effective Graphical Processing Units (GPUs)
implementation of a technique similar to the one proposed by
two of the authors in [DR04], to adaptively refine triangular
meshes along the silhouette, in order to improve its visual
appearance. Since our technique dynamically refines geometry at the vertex level, it integrates well with pixel-based
techniques such as those mentioned above.

2. Previous and related work

We start by reviewing previous and related work in the following section before we introduce our notation and recall
the silhouetteness classification method that was introduced
in [DR04]. In Section 4, we discuss the construction of a cubic B´ezier patch for each triangle in the mesh, based on the

Silhouette extraction. Silhouette extraction has been studied extensively, both in the framework for rendering soft
shadows and for use in nonphotorealistic-rendering. Isenberg
et al. [IFH*03] provide an excellent overview of the tradeoffs involved in choosing among the various CPU-based
silhouette extraction techniques. Hartner et al. [HHCG03]
benchmark and compare various algorithms in terms of runtime performance and code complexity. For comparison,
we present runtime performance for our method within this

c 2007 The Authors
Journal compilation c 2007 The Eurographics Association and
Blackwell Publishing Ltd. Published by Blackwell Publishing,
9600 Garsington Road, Oxford OX4 2DQ, UK and 350 Main
Street, Malden, MA 02148, USA.

Submitted April 2006
Revised November 2006
Accepted January 2007

1

2

C. Dyken et al. / Real-Time GPU Silhouette Refinement using Adaptively Blended B´ezier Patches

framework in Section 7. Card and Mitchell [CL02] propose
a single pass GPU assisted algorithm for rendering silhouette edges by degenerating all nonsilhouette edges in a vertex
shader.
Curved geometry. Curved point-normal triangle patches
(PN-triangles), introduced by Vlachos et al. [VPBM01], do
not need triangle connectivity between patches, and are therefore well suited for tessellation in hardware. An extension
allowing for finer control of the resulting patches was presented by Boubekeur et al. [BRS05] and dubbed scalar tagged
PN-triangles. A similar approach is taken by van Overveld
and Wyvill [vOW97], where subdivision was used instead
of B´ezier patches. Alliez et al. describe a local refinement
technique for subdivision surfaces [ALS03].
Adaptivity and multiresolution meshes. Multiresolution
methods for adaptive rendering have a long history, a survey is given by Luebke et al. [LWC*02]. Some examples are
progressive meshes, where refinement is done by repeated
triangle splitting and deletion by Hoppe [Hop96], or triangle
subdivision as demonstrated by Pulli and Segal [PS96] and
Kobbelt [Kob00].
GPU techniques. Global subdivision using a GPU kernel
is described by Shiue et al. [SJP05] and an adaptive subdivision technique using GPUs is given by Bunnel [Bun05]. A
GPU friendly technique for global mesh refinement on GPUs
was presented by Boubekeur and Schlick [BS05], using pretessellated triangle strips stored on the GPU. Our rendering
method is similar, but we extend their method by adding
adaptivity to the rendered mesh.
A recent trend is to utilize the performance of GPUs for
nonrendering computations, often called General-Purpose
Computing on GPUs (GPGPU). We employ such techniques extensively in our algorithm, but forward the description of GPGPU programming to the introduction by
Harris [Har05]. An overview of various applications in

which GPGPU techniques have successfully been used
is presented in Owens et al. [OLG*05]. For information
about OpenGL and the OpenGL Shading Language, see
the reference material by Shreiner et al. [SWND06] and
Rost [Ros06].
3. Silhouettes of triangle meshes
We consider a closed triangle mesh with consistently oriented triangles T 1 , . . . , T N and vertices v1 , . . . , vn in R3 . The
extension to meshes with boundaries is straightforward and
is omitted for brevity. An edge of is defined as ei j = [vi ,
v j ] where [·] denotes the convex hull of a set. The triangle
normal nt of a triangle T t = [vi , v j , vk ] is defined as the
normalization of the vector (v j − vi ) × (vk − vi ). Since our
interest is in rendering , we also assume that we are given
shading normals, nti , nt j , ntk associated with the vertices of
T t . The viewpoint x ∈ R3 is the position of the observer and
for a point v on , the view direction vector is v − x. If n is
the surface normal in v, we say that T is front facing in v if
(v − x) ·n ≤ 0, otherwise it is back facing.
The silhouette of a triangle mesh is the set of edges where
one of the adjacent triangles is front facing while the other is
back facing. Let vi j be the midpoint of an edge ei j shared by
two triangles T s and T t in . Defining f i j : R3 → R by
f i j (x) =

vi j − x
· ns
vi j − x

vi j − x
· nt ,
vi j − x

(1)

we see that ei j is a silhouette edge when observed from x in
the case f i j (x) ≤ 0.
Our objective is to render
so that it appears to have
smooth silhouettes, by adaptively refining the mesh along the
silhouettes. Since the resulting silhouette curves in general
do not lie in , and since silhouette membership for edges is
a binary function of the viewpoint, a naive implementation
leads to transitional artifacts: The rendered geometry depends
discontinuously on the viewpoint. In [DR04], a continuous

Figure 1: A dynamic refinement (left) of a coarse geometry (center). Cracking between patches of different refinement levels
(top right) is eliminated using the technique described in Section 5 (bottom right).
c 2007 The Authors
Journal compilation c 2007 The Eurographics Association and Blackwell Publishing Ltd.

C. Dyken et al. / Real-Time GPU Silhouette Refinement using Adaptively Blended B´ezier Patches

3

Figure 2: From left to right: A triangle [vi , v j , vk ] and the associated shading normals ni , n j and nk is used to define three
cubic B´ezier curves and a corresponding cubic triangular B´ezier patch F. The sampling operator Si yields tessellations of the
patch at refinement level i.

0<fij (x )< βij

fij (x)< 0

4. Curved geometry

fij (x)> βij
φ

0<fij (x )< βij

φ
ns

fij (x)< 0
[ v i , v j]

nt

Figure 3: Values of f i j in (1) looking along the edge ei j with
the transitional region φ marked gray.

We assume that the mesh and its shading normals are sampled from a piecewise smooth surface (it can however have
sharp edges) at a sampling rate that yields nonsmooth silhouettes. In this section, we use the vertices and shading
normals of each triangle in to construct a corresponding
cubic B´ezier patch. The end result of our construction is a
set of triangular patches that constitutes a piecewise smooth
surface. Our construction is a variant of the one in [DR04],
see also [VPBM01].
For each edge ei j in , we determine a cubic B´ezier curve
based on the edge endpoints vi , v j and their associated shading normals:

silhouette test was proposed to avoid such artifacts. The silhouetteness of ei j as seen from x ∈ R3 was defined as
⎧
⎪
⎨1
αi j (x) = 1 −
⎪
⎩
0

if f i j (x) ≤ 0;
f i j (x)
βi j

if 0 < f i j (x) ≤ βi j ;

(2)

if f i j (x) > βi j ,

where β i j > 0 is a constant. We let β i j depend on the local
geometry, so that the transitional region define a ‘wedge’
with angle φ with the adjacent triangles (see Figure 3). This
amounts to setting β i j = sin φ cos φ sin θ + sin2 φ cos θ ,
where θ is the angle between the normals of the two adjacent
triangles. We also found that the heuristic choice of βi j =
1
works well in practice, but this choice gives unnecessary
4
refinement over flatter areas.
The classification (2) extends the standard binary classification by adding a transitional region. A silhouetteness
α i j ∈ (0, 1) implies that ei j is nearly a silhouette edge. We
use silhouetteness to control the view dependent interpolation
between silhouette geometry and nonsilhouette geometry.

Ci j (t) = vi B03 (t) + ci j B13 (t) + c ji B23 (t) + v j B33 (t),
where Bi3 (t) = 3i t i (1 − t)3−i are the Bernstein polynomials,
see e.g. [Far02]. The inner control point ci j is determined
as follows. Let T s and T t be the two triangles adjacent
to ei j and let nsi and nti be the shading normals at vi
belonging to triangle T s and T t , respectively. If nsi =
nti , we say that vi is a smooth edge end and we determine
2v +v
(v −v )·n
its inner control point as ci j = i 3 j − j 3i si nsi . On the
other hand, if nsi = nti , we say that vi is a sharp edge end and
(v −v )·t
let ci j = vi + j 3i i j ti j , where ti j is the normalized cross
product of the shading normals. We refer to [DR04] for the
rationale behind this construction.
Next, we use the control points of the three edge curves
belonging to a triangle [vi , v j , vk ] to define nine of the ten
control points of a cubic triangular B´ezier patch of the form
F=

3
blmn Blmn
.

(3)

l+m+n=3
6
3
= l!m!n!
u l v m w n are the Bernstein-B´ezier polyHere Blmn
nomials and u, v, w are barycentric coordinates, see
e.g. [Far02]. We determine the coefficients such that

c 2007 The Authors
Journal compilation c 2007 The Eurographics Association and Blackwell Publishing Ltd.

4

C. Dyken et al. / Real-Time GPU Silhouette Refinement using Adaptively Blended B´ezier Patches

dyadic barycentric coordinates
Im =

Figure 4: The surfaces resulting from the center control
point rule (4) (left) and (5) (right), applied to a tetrahedron
with one normal vector per vertex. The difference is marginal,
although the surface to the right can be seen to be slightly
flatter.

b300 = vi , b210 = ci j , b120 = c ji and so forth. In [VPBM01]
and [DR04] the center control point b111 was determined as
b111

3
(ci j + c ji + c jk + ck j + cki + cik )
=
12
1
− (vi + v j + vk ).
6

(4)

We propose instead to optionally use the average of the inner
control points of the three edge curves,
b111 =

1
(ci j + c ji + c jk + ck j + cki + cik ).
6

(5)

This choice allows for a significantly more efficient implementation at the cost of a slightly ‘flatter’ patch, see Section 6.4 and Figure 4. This example is typical in that the
patches resulting from the two formulations are visually almost indistinguishable.

(i, j, k)
: i, j, k ∈ Z+ , i + j +k = 2m .
2m

A tessellation Pm of the parameter domain P0 and a
map f : P0 → Rd , gives rise to a continuous approximation Sm [ f ] : P0 → Rd of f that is linear on each triangle of
Pm and agrees with f at the vertices of Pm . For example,
Sm [F] maps a triangle [pi , p j , pk ] in Pm linearly to a triangle
[F(pi ), F(p j ), F(pk )] in R3 . It is clear that the collection of
all such triangles forms a tessellation of F. We will in the
following call both the map Sm [F] and its image Sm [F](P0 )
a tessellation. A piecewise linear map Sm [ f ] can be evaluated
at a point p ∈ P0 as follows: Let T = [pi , p j , pk ] be a triangle in Pm containing p and let (u i , u j , u k ) be the barycentric
coordinates of p with respect to T. Then p = u i pi + u j p j +
u k pk and
Sm [ f ](p) = u i f (pi ) + u j f (p j ) + u k f (pk ).

In the previous section we defined a collection of cubic B´ezier
patches based on the mesh and its shading normals. We
next propose a strategy for tessellating these patches adaptively for rendering. We let the tessellation level (which controls the number of triangles produced) depend on the local
silhouetteness so that silhouettes appear to be smooth, while
retaining the coarse geometry away from the silhouettes. We
avoid ‘cracking’ by ensuring that the tessellations of neighboring patches meet continuously (see Figure 1).
The parameter domain of a triangular B´ezier patch F is a
triangle P0 ⊂ R2 . We can refine P0 to form a triangle mesh P1
by splitting each edge in half and forming four new triangles.
A further refinement P2 of P1 is formed similarly, by splitting
each triangle in P1 in four new triangles, and so forth. The
mth refinement Pm is a triangle mesh with vertices at the

(7)

Given two tessellations Ps and Pm and two integers s ≤ m,
the set of vertices of Ps is contained in the set of vertices of
Pm and a triangle of Pm is contained in a triangle of Ps . Since
both maps are linear on each triangle of Sm [Ss [ f ]] and agrees
at the corners, the two maps must be equal in the whole of P0 .
This implies that a tessellation can be refined to a finer level
without changing its geometry: Given a map f : P0 → Rd ,
we have a corresponding tessellation
Sm [Ss [ f ]] = Ss [ f ].

(8)

We say that Sm [Ss [ f ]] has topological refinement level m and
geometric refinement level s. From the previous result we can
define tessellations for a noninteger refinement level s = m
+ α where m is an integer and α ∈ [0, 1). We refine Sm [ f ] to
refinement level m + 1 and let α control the blend between
the two refinement levels,
Sm+α [ f ] = (1 − α)Sm+1 [Sm [ f ]] + αSm+1 [ f ].

5. Adaptive tessellation

(6)

(9)

See Figure 5 for an illustration of noninteger level tessellation.
The sampling operator Sm is linear, i.e. Sm [α1 f 1 + α2 f 2 ] =
α1 Sm [ f 1 ] + α2 Sm [ f 2 ] for all real α 1 , α 2 and maps f 1 , f 2 . As
a consequence, (8) holds for noninteger geometric refinement
level s.
Our objective is to define for each triangle T = [vi , v j , vk ]
a tessellation T of the corresponding patch F adaptively with
respect to the silhouetteness of the edges ei j , e jk , eki . To that
end we assign a geometric refinement level si j ∈ R+ to each
edge, based on its silhouetteness as computed in Section 3.
More precisely, we use s i j = Mα i j where M is a user defined
maximal refinement level, typically M = 3. We set the topological refinement level for a triangle to be m = max{s i j ,
s jk , s ki } , i.e. our tessellation T has the same topology as
Pm . Now, it only remains to determine the position of the

c 2007 The Authors
Journal compilation c 2007 The Eurographics Association and Blackwell Publishing Ltd.

C. Dyken et al. / Real-Time GPU Silhouette Refinement using Adaptively Blended B´ezier Patches

5

Note that s(p) is in general a real value and so (9) is used in
the above calculation. The final tessellation is illustrated in
Figure 6.
The topological refinement level of two neighboring
patches will in general not be equal. However, our choice
of constant geometric refinement level along an edge ensures that neighboring tessellations match along the common
boundary. Although one could let the geometric refinement
level s(p) vary over the interior of the patch, we found that
taking it to be constant as in (10) gives good results.
6. Implementation

Figure 5: To tessellate a patch at the noninteger refinement
level s = 1.5, we create the tessellations S1 [F] and S2 [F],
and refine S1 [F] to S2 [S1 [F]] such that the topological refinement levels match. Then, the two surfaces are weighted
and combined to form S1.5 [F].

We next describe our implementation of the algorithm. We
need to distinguish between static meshes for which the vertices are only subject to affine transformations, and dynamic
meshes with more complex vertex transformations. Examples of the latter are animated meshes and meshes resulting
from physical simulations. We assume that the geometry of
a dynamic mesh is retained in a texture on the GPU that
is updated between frames. This implies that our algorithm
must recompute the B´ezier coefficients accordingly. Our implementation is described sequentially, although some steps
do not require the previous step to finish. A flowchart of the
implementation can be found in Figure 7.
6.1. Silhouetteness calculation
Silhouetteness is well suited for computation on the GPU
since it is the same transform applied to every edge and since
there are no data dependencies. The only changing parameter
between frames is the viewpoint.

Figure 6: Composing multiple refinement levels for adaptive
tessellation. Each edge have a geometric refinement level,
and the topological refinement level is dictated by the edge
with the largest refinement level.
vertices of T . We use the sampling operator Ss with geometric refinement level varying over the patch and define the
vertex positions as follows. For a vertex p of Pm we let the
geometric refinement level be
s(p) =

sqr
max{si j , s jk , ski }

if p ∈ (pq , pr );
otherwise,

(10)

where (pq , pr ) is the interior of the edge of P0 corresponding
to eqr . Note that the patch is interpolated at the corners vi , v j ,
vk . The vertex v of T that corresponds to p is then defined as
v = Ss(p) [F](p) = Sm Ss(p) [F] (p).

(11)

If the mesh is static we can pre-compute the edgemidpoints and neighboring triangle normals for every edge
as a preprocessing step and store these values in a texture on
the GPU. For a dynamic mesh we store the indices of the
vertices of the two adjacent triangles instead and calculate
the midpoint as part of the silhouetteness computation.
The silhouetteness of the edges is calculated by first sending the current viewpoint to the GPU as a shader uniform,
and then by issuing the rendering of a textured rectangle into
an off-screen buffer with the same size as our edge-midpoint
texture.
We could alternatively store the edges and normals of
several meshes in one texture and calculate the silhouetteness of all in one pass. If the models have different model
space bases, such as in a scene graph, we reserve a texel in a
viewpoint-texture for each model. In the preprocessing step,
we additionally create a texture associating the edges with
the model’s viewpoint texel. During rendering we traverse
the scene graph, find the viewpoint in the model space of the
model and store this in the viewpoint texture. We then upload
this texture instead of setting the viewpoint explicitly.

c 2007 The Authors
Journal compilation c 2007 The Eurographics Association and Blackwell Publishing Ltd.

6

C. Dyken et al. / Real-Time GPU Silhouette Refinement using Adaptively Blended B´ezier Patches

Current
Geometry

Silhouetteness

Triangle
refinement

viewpoint
Start new frame

Calculate
geometry

Calculate
silhouetteness

Determine
triangle
refinement

Render
unrefined
triangles

Render patches

Issue rendering
of refined
triangles

Extract
triangle data

Extract
edge data

Build histopyramids

Triangle data

Edge data

Triangle
histopyramid

Edge histopyramid

Figure 7: Flowchart of the silhouette refinement algorithm. The white boxes are executed on the CPU, the blue boxes on the
GPU, the green boxes are textures, and the red boxes are pixel buffer objects. The dashed lines and boxes are only necessary for
dynamic geometry.
6.2. Histogram pyramid construction and extraction
The next step is to determine which triangles should be refined, based on the silhouetteness of the edges. The straightforward approach is to read back the silhouetteness texture
to host memory and run sequentially through the triangles to
determine the refinement level for each of them. This direct
approach rapidly congests the graphics bus and thus reduces
performance. To minimize transfers over the bus we use a
technique called histogram pyramid extraction [ZTTS06] to
find and compact only the data that we need to extract for
triangle refinement. As an added benefit the process is performed in parallel on the GPU.
The first step in the histogram pyramid extraction is to select the elements that we will extract. We first create a binary
base texture with one texel per triangle in the mesh. A texel is
set to 1 if the corresponding triangle is selected for extraction,
i.e. has at least one edge with nonzero silhouetteness, and 0
otherwise. We create a similar base texture for the edges, setting a texel to 1 if the corresponding edge has at least one
adjacent triangle that is selected and 0 otherwise.
For each of these textures we build a histopyramid, which is
a stack of textures similar to a mipmap pyramid. The texture
at one level is a quarter of the size of the previous level.
Instead of storing the average of the four corresponding texels
in the layer below like for a mipmap, we store the sum of
these texels. Thus each texel in the histopyramid contains the
number of selected elements in the subpyramid below and
the single top element contains the total number of elements
selected for extraction. Moreover, the histopyramid induces
an ordering of the selected elements that can be obtained by

traversal of the pyramid. If the base texture is of size 2n × 2n ,
the histopyramid is built bottom up in n passes. Note that for
a static mesh we only need a histopyramid for edge extraction
and can thus skip the triangle histopyramid.
The next step is to compact the selected elements. We create a 2D texture with at least m texels where m is the number
of selected elements and each texel equals its index in a 1D
ordering. A shader program is then used to find for each texel
i the corresponding element in the base texture as follows. If
i > m there is no corresponding selected element and the texel
is discarded. Otherwise, the pyramid is traversed top-down
using partial sums at the intermediate levels to determine the
position of the ith selected element in the base texture. Its
position in the base texture is then recorded in a pixel buffer
object.
The result of the histopyramid extraction is a compact representation of the texture positions of the elements for which
we need to extract data. The final step is to load associated
data into pixel buffer objects and read them back to host
memory over the graphics bus. For static meshes we output
for each selected edge its index and silhouetteness. We can
thus fit the data of two edges in the RGBA values of one
render target.
For dynamic meshes we extract data for both the selected
triangles and edges. The data for a triangle contains the vertex
positions and shading normals of the corners of the triangle.
Using polar coordinates for normal vectors, this fit into four
RGBA render targets. The edge data is the edge index, its
silhouetteness and the two inner B´ezier control points of that
edge, all of which fits into two RGBA render targets.

c 2007 The Authors
Journal compilation c 2007 The Eurographics Association and Blackwell Publishing Ltd.

7

C. Dyken et al. / Real-Time GPU Silhouette Refinement using Adaptively Blended B´ezier Patches

6.3. Rendering unrefined triangles
While the histopyramid construction step finishes, we issue
the rendering of the unrefined geometry using a vertex buffer
object (VBO). We encode the triangle index into the geometry
stream, for example as the w-coordinates of the vertices. In
the vertex shader, we use the triangle index to do a texture
lookup in the triangle refinement texture in order to check if
the triangle is tagged for refinement. If so, we collapse the
vertex to [0, 0, 0], such that triangles tagged for refinement
are degenerate and hence produce no fragments. This is the
same approach as [CL02] uses to discard geometry.
For static meshes, we pass the geometry directly from the
VBO to vertex transform, where triangles tagged for refinement are culled. For dynamic meshes, we replace the geometry in the VBO with indices and retrieve the geometry for
the current frame using texture lookups, before culling and
applying the vertex transforms.
The net effect of this pass is the rendering of the coarse geometry, with holes where triangles are tagged for refinement.
Since this pass is vertex-shader only, it can be combined with
any regular fragment shader for lightning and shading.
6.4. Rendering refined triangles
While the unrefined triangles are rendered, we wait for the
triangle data read back to the host memory to finish. We can
then issue the rendering of the refined triangles. The geometry
of the refined triangles are tessellations of triangular cubic
B´ezier patches as described in Section 4 and 5.
To allow for high frame-rates, the transfer of geometry to
the GPU, as well as the evaluation of the surface, must be handled carefully. Transfer of vertex data over the graphics bus
is a major bottleneck when rendering geometry. Boubekeur
and Schlick [BS05] have an efficient strategy for rendering
uniformly sampled patches. The idea is that the parameter
positions and triangle strip set-up are the same for any patch
with the same topological refinement level. Thus, it is enough
to store a small number of pre-tessellated patches Pi with
parameter positions Ii as VBOs on the GPU. The coefficients of each patch are uploaded and the vertex shader is
used to evaluate the surface at the given parameter positions.
We use a similar set-up, extended to our adaptive watertight
tessellations.
The algorithm is similar for static and dynamic meshes,
the only difference is the place from which we read the coefficients. For static meshes, the coefficients are pre-generated
and read directly from host memory. The coefficients for a
dynamic mesh are obtained from the edge and triangle readback pixel pack buffers. Note that this pass is vertex-shader
only and we can therefore use the same fragment shader as
for the rendering of the unrefined triangles.
The tessellation strategy described in Section 5 requires
the evaluation of (11) at the vertices of the tessellation Pm

of the parameter domain of F, i.e. at the dyadic parameter
points (6) at refinement level m. Since the maximal refinement
level M over all patches is usually quite small, we can save
computations by pre-evaluating the basis functions at these
points and store these values in a texture.
A texture lookup gives four channels of data, and since
a cubic B´ezier patch has ten basis functions, we need three
texture lookups to get the values of all of them at a point.
If we define the center control point b111 to be the average
of six other control points, as in (5), we can eliminate it by
distributing the associated basis function B 111 = uvw/6 =
μ/6 among the six corresponding basis functions,
3
3
3
Bˆ 300
= u 3 , Bˆ 201
= 3wu 2+μ, Bˆ 102
= 3uw2+μ,
3
3
3
(12)
Bˆ 030
= v 3 , Bˆ 120
= 3uv 2+μ, Bˆ 210
= 3vu 2+μ,
3
3
3
3
2
2
Bˆ 003 = w , Bˆ 012 = 3vw +μ, Bˆ 021 = 3wv +μ.

We thus obtain a simplified expression
F=

bi jk Bi jk =

bi jk Bˆ i jk

(13)

(i, j,k)=(1,1,1)

involving only nine basis functions. Since they form a partition of unity, we can obtain one of them from the remaining
eight. Therefore, it suffices to store the values of eight basis
functions, and we need only two texture lookups for evaluation per point. Note that if we choose the center coefficient as
in (4) we need three texture lookups for retrieving the basis
functions, but the remainder of the shader is essentially the
same.
Due to the linearity of the sampling operator, we may express (11) for a vertex p of P M with s(p) = m + α as
v = Ss(p) [F](p) =

bi jk Ss(p) [ Bˆ i jk ](p)
i, j,k

=

bi jk ((1 − α)Sm [ Bˆ i jk ](p) + αSm+1 [ Bˆ i jk ](p)).
i, j,k

(14)
Thus, for every vertex p of P M , we pre-evaluate
3
3
Sm [ Bˆ 300
](p), . . . , Sm [ Bˆ 021
](p) for every refinement level
m = 1, . . . , M and store this in a M × 2 block in the texture. We organize the texture such that four basis functions
are located next to the four corresponding basis functions of
the adjacent refinement level. This layout optimizes spatial
coherency of texture accesses since two adjacent refinement
levels are always accessed when a vertex is calculated. Also,
if vertex shaders on future graphics hardware will support
filtered texture lookups, we could increase performance by
carrying out the linear interpolation between refinement levels by sampling between texel centers.
Since the values of our basis function are always in in the
interval [0, 1], we can trade precision for performance and
pack two basis functions into one channel of data, letting
one basis function have the integer part while the other has
the fractional part of a channel. This reduces the precision

c 2007 The Authors
Journal compilation c 2007 The Eurographics Association and Blackwell Publishing Ltd.

8

C. Dyken et al. / Real-Time GPU Silhouette Refinement using Adaptively Blended B´ezier Patches

Figure 8: The left image depicts a coarse mesh using normal mapping to increase the perceived detail, and the right image
depicts the same scene using the displacement mapping technique described in Section 6.5.
to about 12 bits, but increases the speed of the algorithm by
20% without adding visual artifacts.
6.5. Normal and displacement mapping
Our algorithm can be adjusted to accommodate most regular
rendering techniques. Pure fragment level techniques can be
applied directly, but vertex-level techniques may need some
adjustment.
An example of a pure fragment-level technique is normal
mapping. The idea is to store a dense sampling of the object’s
normal field in a texture, and in the fragment shader use the
normal from this texture instead of the interpolated normal
for lighting calculations. The result of using normal mapping
on a coarse mesh is depicted in the left of Figure 8.
Normal mapping only modulates the lighting calculations,
it does not alter the geometry. Thus, silhouettes are still piecewise linear. In addition, the flat geometry is distinctively visible at gracing angles, which is the case for the sea surface in
Figure 8.

vertex shader of Section 6.4. However, care must be taken to
avoid cracks and maintain a watertight surface.
For a point p at integer refinement level s, we find the
triangle T = [pi , p j , pk ] of Ps that contains p. We then find
the displacement vectors at pi , p j , and pk . The displacement
vector at pi is found by first doing a texture lookup in the
displacement map using the texture coordinates at pi and then
multiplying this displacement with the interpolated shading
normal at pi . In the same fashion we find the displacement
vectors at p j and pk . The three displacement vectors are then
combined using the barycentric weights of p with respect to
T, resulting in a displacement vector at p. If s is not an integer,
we interpolate the displacement vectors of two adjacent levels
similarly to (9).
The result of this approach is depicted to the right in
Figure 8, where the cliff ridges are appropriately jagged and
the water surface is displaced according to the waves.

7. Performance analysis

The displacement mapping technique attacks this problem by perturbing the vertices of a mesh. The drawback is
that displacement mapping requires the geometry in problem
areas to be densely tessellated. The brute force strategy of
tessellating the whole mesh increase the complexity significantly and is best suited for off-line rendering. However, a
ray-tracing like approach using GPUs has been demonstrated
by Donnelly[Don05].

In this section, we compare our algorithms to alternative
methods. We have measured both the speedup gained by moving the silhouetteness test calculation to the GPU, as well as
the performance of the full algorithm (silhouette extraction
+ adaptive tessellation) with a rapidly changing viewpoint.
We have executed our benchmarks on two different GPUs to
get an impression of how the algorithm scales with advances
in GPU technology.

We can use our strategy to establish the problem areas of
the current frame and use our variable-level of detail refinement strategy to tessellate these areas. First, we augment the
silhouetteness test, tagging edges that are large in the current
projection and part of planar regions at gracing angles for refinement. Then we incorporate displacement mapping in the

For all tests, the CPU is an AMD Athlon 64 running at
2.2 GHz with PCI-E graphics bus, running Linux 2.6.16 and
using GCC 4.0.3. The Nvidia graphics driver is version 87.74.
All programs have been compiled with full optimization
settings. We have used two different Nvidia GPUs, a 6600
GT running at 500 MHz with eight fragment and five vertex

c 2007 The Authors
Journal compilation c 2007 The Eurographics Association and Blackwell Publishing Ltd.

9

C. Dyken et al. / Real-Time GPU Silhouette Refinement using Adaptively Blended B´ezier Patches

10k
7800 GT
6600 GT
Brute
Hierarchal

10k

Frames pr. sec

Silhouette extractions pr. sec

100k

1k
100
10
100

1k
10k
Number of triangles

100k

(a) The measured performance for brute force CPU silhouette extraction, hierarchical CPU silhouette extraction,
and the GPU silhouette extraction on the Nvidia GeForce
6600GT and 7800GT GPUs.

Static mesh
Uniform
Static VBO
Dynamic mesh

1k
100
24
10
1
100

1k
10k
Number of triangles

100k

(b) The measured performance on an Nvidia GeForce
7800GT for rendering refined meshes using one single static
VBO, the uniform refinement method of [BS05], and our algorithm for static and dynamic meshes.

Figure 9: Performance measurements of our algorithm.
pipelines and a memory clockspeed of 900 MHz, and a 7800
GT running at 400 MHz with 20 fragment and seven vertex pipelines and a memory clockspeed of 1000 MHz. Both
GPUs use the PCI-E interface for communication with the
host CPU.
Our adaptive refinement relies heavily on texture lookups
in the vertex shader. Hence, we have not been able to perform
tests on ATI GPUs, since these just recently got this ability.
However, we expect similar performance on ATI hardware.
We benchmarked using various meshes ranging from 200
to 100k triangles. In general, we have found that the size of a
mesh is more important than its complexity and topology, an
observation shared by Hartner et al. [HHCG03]. However,
for adaptive refinement it is clear that a mesh with many
internal silhouettes will lead to more refinement, and hence
lower frame-rates.

7.1. Silhouette Extraction on the GPU
To compare the performance of silhouette extraction on the
GPU versus traditional CPU approaches, we implemented
our method in the framework of Hartner et al. [HHCG03].
This allowed us to benchmark our method against the hierarchical method described by Sander et al. [SGG*00], as
well as against standard brute force silhouette extraction. Figure 9a shows the average performance over a large number
of frames with random viewpoints for an asteroid model
of [HHCG03] at various levels of detail. The GPU measurements include time spent reading back the data to host
memory.

Our observations for the CPU based methods (hierarchical
and brute force) agree with [HHCG03]. For small meshes that
fit into the CPU’s cache, the brute force method is the fastest.
However, as the mesh size increases, we see the expected
linear decrease in performance. The hierarchical approach
scales much better with regard to mesh size, but at around 5k
triangles the GPU based method begins to outperform this
method as well.
The GPU based method has a different performance characteristic than the CPU based methods. There is virtually no
decline in performance for meshes up to about 10k triangles. This is probably due to the dominance of set-up and
tear-down operations for data transfer across the bus. At
around 10k triangles we suddenly see a difference in performance between the eight-pipeline 6600 GT GPU and the
20-pipeline 7800 GT GPU, indicating that the increased floating point performance of the 7800 GT GPU starts to pay off.
We also see clear performance plateaus, which is probably
due to the fact that geometry textures for several consecutive
mesh sizes are padded to the same size during histopyramid
construction.
It could be argued that coarse meshes in need of refinement
along the silhouette typically contains less than 5000 triangles
and thus silhouetteness should be computed on the CPU.
However, since the test can be carried out for any number
of objects at the same time, the above result applies to the
total number of triangles in the scene, and not in a single
mesh.
For the hierarchical approach, there is a significant preprocessing step that is not reflected in Figure 9a, which makes

c 2007 The Authors
Journal compilation c 2007 The Eurographics Association and Blackwell Publishing Ltd.

10

C. Dyken et al. / Real-Time GPU Silhouette Refinement using Adaptively Blended B´ezier Patches

it unsuitable for dynamic meshes. Also, in real-time rendering applications, the CPU will typically be used for other
calculations such as physics and AI, and can not be fully utilized to perform silhouetteness calculations. It should also
be emphasized that it is possible to do other per-edge calculations, such as visibility testing and culling, in the same
render pass as the silhouette extraction, at little performance
overhead.

7.2. Benchmarks of the complete algorithm
Using variable level of detail instead of uniform refinement
should increase rendering performance since less geometry
needs to be sent through the pipeline. However, the added
complexity balances out the performance of the two approaches to some extent.
We have tested against two methods of uniform refinement. The first method is to render the entire refined mesh
as a static VBO stored in graphics memory. The rendering
of such a mesh is fast, as there is no transfer of geometry
across the graphics bus. However, the mesh is static and the
VBO consumes a significant amount of graphics memory.
The second approach is the method of Boubekeur and Schlick
[BS05], where each triangle triggers the rendering of a
pre-tessellated patch stored as triangle strips in a static VBO
in graphics memory.
Figure 9b shows these two methods against our adaptive
method. It is clear from the graph that using static VBOs is
extremely fast and outperforms the other methods for meshes
up to 20k triangles. At around 80k triangles, the VBO grows
too big for graphics memory, and is stored in host memory,
with a dramatic drop in performance. The method of [BS05]
has a linear performance degradation, but the added cost of
triggering the rendering of many small VBOs is outperformed
by our adaptive method at around 1k triangles. The performance of our method also degrades linearly, but at a slower
rate than uniform refinement. Using our method, we are at 24
FPS able to adaptively refine meshes up to 60k for dynamic
meshes, and 100k triangles for static meshes, which is significantly better than the other methods. The other GPUs show
the same performance profile as the 7800 in Figure 9b, just
shifted downward as expected by the number of pipelines and
lower clock speed.
Finally, to get an idea of the performance impact of various parts of our algorithm, we ran the same tests with various
features enabled or disabled. We found that using uniformly
distributed random refinement level for each edge (to avoid
the silhouetteness test), the performance is 30–50% faster
than uniform refinement. This is as expected since the vertex shader is only marginally more complex, and the total
number of vertices processed is reduced. In a real world scenario, where there is often a high degree of frame coherency,
this can be utilized by not calculating the silhouetteness for

every frame. Further, if we disable blending of consecutive
refinement levels (which can lead to some popping, but no
cracking), we remove half of the texture lookups in the vertex shader for refined geometry and gain a 10% performance
increase.

8. Conclusion and future work
We have proposed a technique for performing adaptive refinement of triangle meshes using graphics hardware, requiring just a small amount of preprocessing, and with
no changes to the way the underlying geometry is stored.
Our criterion for adaptive refinement is based on improving the visual appearance of the silhouettes of the mesh.
However, our method is general in the sense that it can
easily be adapted to other refinement criteria, as shown in
Section 6.5.
We execute the silhouetteness computations on a GPU. Our
performance analysis shows that our implementation using
histogram pyramid extraction outperforms other silhouette
extraction algorithms as the mesh size increases.
Our technique for adaptive level of detail automatically
avoids cracking between adjacent patches with arbitrary refinement levels. Thus, there is no need to ‘grow’ refinement levels from patch to patch, making sure two adjacent
patches differ only by one level of detail. Our rendering
technique is applicable to dynamic and static meshes and
creates continuous level of detail for both uniform and adaptive refinement algorithms. It is transparent for fragmentlevel techniques such as texturing, advanced lighting calculations, and normal mapping, and the technique can be
augmented with vertex-level techniques such as displacement
mapping.
Our performance analysis shows that our technique gives
interactive frame-rates for meshes with up to 100k triangles.
We believe this makes the method attractive since it allows
complex scenes with a high number of coarse meshes to be
rendered with smooth silhouettes. The analysis also indicates
that the performance of the technique is limited by the bandwidth between host and graphics memory. Since the CPU
is available for other computations while waiting for results
from the GPU, the technique is particularly suited for CPUbound applications. This also shows that if one could somehow eliminate the read-back of silhouetteness and trigger
the refinement directly on the graphics hardware, the performance is likely to increase significantly. To our knowledge there are no such methods using current versions of the
OpenGL and Direct3D APIs. However, considering the recent evolution of both APIs, we expect such functionality in
the near future.
A major contribution of this work is an extension of the
technique described in [BS05]. We address three issues:
evaluation of PN-triangle type patches on vertex shaders,

c 2007 The Authors
Journal compilation c 2007 The Eurographics Association and Blackwell Publishing Ltd.

C. Dyken et al. / Real-Time GPU Silhouette Refinement using Adaptively Blended B´ezier Patches

adaptive level of detail refinement and elimination of popping
artifacts. We have proposed a simplified PN-triangle type
patch which allows the use of pre-evaluated basis-functions
requiring only one single texture lookup (if we pack the
pre-evaluated basis functions into the fractional and rational
parts of a texel). Further, the use of a geometric refinement
level different from the topological refinement level comes
at no cost since this is achieved simply by adjusting a texture coordinate. Thus, adaptive level of detail comes at a very
low price.
We have shown that our method is efficient and we expect
it to be even faster when texture lookups in the vertex shader
become more mainstream and the hardware manufacturers
answer with increased efficiency for this operation. Future
GPUs use a unified shader approach, which could also boost
the performance of our algorithm since it is primarily vertex bound and current GPUs perform the best for fragment
processing.

11

[Don05] DONNELLY W.: GPU Gems 2. Addison Wesley
Professional 2005, ch. 8 Per-Pixel Displacement Mapping
with Distance Functions.
[DR04] DYKEN C., REIMERS M.: Real-time linear silhouette enhancement. In Mathematical Methods for Curves
and Surfaces: Tromsø 2004 (2004), Nashboro Press,
pp. 135–144.
[Far02] FARIN G.: Curves and Surfaces for CAGD. Morgan Kaufmann Publishers Inc., 2002.
[Har05] HARRIS M.: GPU Gems 2. Addison Wesley Professional, 2005, ch. 31 Mapping Computational Concepts
to GPUs.
[HHCG03] HARTNER A., HARTNER M., COHEN E.,
GOOCH B.: Object space silhouette algorithims. In Theory and Practice of Non-Photorealistic Graphics: Algorithms, Methods, and Production System SIGGRAPH
2003 Course Notes (2003).

Acknowledgments
We would like to thank Gernot Ziegler for introducing us to
the histogram pyramid algorithm. Furthermore, we are grateful to Mark Hartner for giving us access to the source code
of the various silhouette extraction algorithms. Finally, Marie
Rognes has provided many helpful comments after reading an
early draft of this manuscript. This work was funded, in part,
by contract number 158911/I30 of The Research Council of
Norway.

References
[ALS03] ALLIEZ P., LAURENT N., SCHMITT H. S. F.:
Efficient
view-dependent refinement of 3D meshes using
√
3-subdivision. The Visual Computer 19 (2003), 205–
221.
[BRS05] BOUBEKEUR T., REUTER P., SCHLICK C.: Scalar
tagged PN triangles. In Eurographics 2005 (Short Papers)
(2005).
[BS05] BOUBEKEUR T., SCHLICK C.: Generic mesh refinement on GPU. In Proceedings of the ACM SIGGRAPH/EUROGRAPHICS Conf. on Graphics Hardware
(2005), pp. 99–104.

[Hop96] HOPPE H.: Progressive meshes. In ACM SIGGRAPH 1996 (1996), pp. 99–108.
[IFH*03] ISENBERG T., FREUDENBERG B., HALPER N.,
SCHLECHTWEG S., STROTHOTTE T.: A developer’s guide
to silhouette algorithms for polygonal models. IEEE
Computer Graphics and Applications 23, 4 (July-August
2003), 28–37.
√
[Kob00] KOBBELT L.: 3-subdivision. In Proceedings of
the ACM SIGGRAPH 2000 (2000), pp. 103–112.
[LWC*02] LUEBKE D., WATSON B., COHEN J. D., REDDY
M., VARSHNEY A.: Level of Detail for 3D Graphics. Elsevier Science Inc., 2002.
[OLG*05] OWENS J. D., LUEBKE D., GOVINDARAJU N.,
¨
HARRIS M., KRUGER
J., LEFOHN A. E. PURCELL T. J.:
A survey of general-purpose computation on graphics
hardware. In Eurographics 2005, State of the Art Reports
(August 2005), pp. 21–51.
[PS96] PULLI K., SEGAL M.: Fast rendering of subdivision
surfaces. In ACM SIGGRAPH 1996 Visual Proceedings:
The art and interdisciplinary programs (1996).
[Ros06] ROST R. J.: OpenGL(R) Shading Language. Addison Wesley Longman Publishing Co., Inc., 2006.

[Bun05] BUNNELL M.: GPU Gems 2. AddisonWesley Professional, 2005, ch. 7 Adaptive Tessellation of Subdivision Surfaces with Displacement
Mapping.

[SGG*00] SANDER P. V., GU X., GORTLER S. J., HOPPE
H., SNYDER J.: Silhouette clipping. In SIGGRAPH 2000
(2000), pp. 327–334.

[CL02] CARD D., L. MITCHELL J.: ShaderX, Wordware,
2002, ch. Non-Photorealistic Rendering with Pixel and
Vertex Shaders.

[SJP05] SHIUE L.-J., JONES I., PETERS J.: A realtime GPU
subdivision kernel. ACM Trans. Graph. 24, 3 (2005),
1010–1015.

c 2007 The Authors
Journal compilation c 2007 The Eurographics Association and Blackwell Publishing Ltd.

12

C. Dyken et al. / Real-Time GPU Silhouette Refinement using Adaptively Blended B´ezier Patches

[SWND06] SHREINER D., WOO M., NEIDER J., DAVIS T.:
OpenGL(R) Programming Guide. Addison Wesley Longman Publishing Co., Inc., 2006.

[VPBM01] VLACHOS A., PETERS J., BOYD C., MITCHELL
J. L.: Curved PN triangles. In ACM Symposium on Interactive 3D 2001 graphics (2001).

[vOW97]
VAN OVERVELD K., WYVILL B.: An algorithm
for polygon subdivision based on vertex normals. In Computer Graphics International, 1997. Proceedings (1997),
pp. 3–12.

[ZTTS06] ZIEGLER G., TEVS A., TEHOBALT C., SEIDEL
H.-P.: GPU Point List Generation through Histogram
Pyramids. Tech. Rep. MPI-I-2006-4-002, Max-PlanckInstitut f¨ur Informatik, 2006.

c 2007 The Authors
Journal compilation c 2007 The Eurographics Association and Blackwell Publishing Ltd.

