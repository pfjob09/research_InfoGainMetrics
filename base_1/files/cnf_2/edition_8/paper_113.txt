Eurographics/ IEEE-VGTC Symposium on Visualization 2008
A. Vilanova, A. Telea, G. Scheuermann, and T. Möller
(Guest Editors)

Volume 27 (2008), Number 3

Interactive Visualization of Multimodal Volume Data
for Neurosurgical Tumor Treatment
Christian Rieder1,2 , Felix Ritter1 , Matthias Raspe2 , and Heinz-Otto Peitgen1
1 MeVis

Research GmbH, Center for Medical Image Computing, Bremen, Germany
Graphics Working Group, University of Koblenz-Landau, Germany

2 Computer

Teaser Figure: Left: Brain, visualized using silhouettes, the lesion’s spatial depth is displayed using a ring. Center: Combined
rendering of brain tissue, skull and fiber tracts using a cutting plane. Right: The virtual path (cyan) from the entry point to the
region of interest. The two crossed lines represent the diameter of the virtual cylinder.
Abstract
We present novel interactive methods for the visualization of multimodal volume data as used in neurosurgical
therapy planning. These methods allow surgeons to explore multimodal volumes and focus on functional data
and lesions. Computer graphics techniques are proposed to create expressive visualizations at interactive frame
rates to reduce time-consuming and complex interaction with the medical data. Contributions of our work are the
distance-based enhancements of functional data and lesions which allows the surgeon to perceive functional and
anatomical structures at once and relate them directly to the intervention. In addition we propose methods for
the visual exploration of the path to the structures of interest, to enhance anatomical landmarks, and to provide
additional depth indicators. These techniques have been integrated in a visualization prototype that provides
interaction capabilities for finding the optimal therapeutic strategy for the neurosurgeon.
Categories and Subject Descriptors (according to ACM CCS): J.3 [Life And Medical Sciences]: Health; I.4.10
[Image Presentation]: Volumetric;

1. Introduction
The brain is one of the vital parts of the human body.
However, essential functionality such as motor activity or
speech can be derogated by pathological tissue, e.g. tumors. Depending on the severity of the damage, neurosurgery is necessary to treat the lesion. Planning such a neurosurgery involves multimodal data of different protocols
and parametrizations to identify functional areas and find
the optimal access path to the lesion. The goal of neuroc 2008 The Author(s)
Journal compilation c 2008 The Eurographics Association and Blackwell Publishing Ltd.
Published by Blackwell Publishing, 9600 Garsington Road, Oxford OX4 2DQ, UK and
350 Main Street, Malden, MA 02148, USA.

surgery planning is to find an access path to the lesion while
minimizing the damage to vital and healthy tissue. In order
to achieve this, functional data such as functional magnetic
resonance imaging data (fMRI: for detection of activation
areas) or diffusion tensor imaging data (DTI: for reconstruction of fibers) has to be combined with anatomical data from
MRT or CT devices. Usually, the surgeon analyzes the available data on a slice-by-slice basis, while mentally merging
the multimodal images in three dimensions. The visualization of multimodal data in a combined form would improve

1056

Rieder et al. / Interactive Visualization of Multimodal Volume Data for Neurosurgical Tumor Treatment

recognition and the knowledge of where risk structures are
located.
In our neurosurgical prototype, we carefully combine recent visualization methods and add new visualization techniques that were requested by medical experts to facilitate
the exploration of multimodal volume data. The value of
this paper lies in the structure that we present for the development of effective multimodal neurosurgical planning systems. With regard to neurosurgeons, whose traditional field
of work is not computer science, we chose techniques that
enable the visualization of medical data with minor interaction requirements and that facilitate the fast recognition
of structures of interest. Particularly, the therapeutic strategy strongly depends on the visualization of risk structures
as well as anatomical details along the trajectory. We show
in this article in which directions future surgical planning
applications might emerge to achieve high acceptance in the
neurosurgical domain. The technical contributions of our paper are:
• Distance-based combination of transfer functions for lesion accentuation. By enhancing the rendering of pathological structures we are able to attenuate anatomical details that are far away from the lesion. Particularly, contrast enhanced tumors can be emphasized without the
need of a segmentation mask.
• Distance-based enhancement of functional data. The idea
is to show only functional data located close to structures
of interest because structures far away from the lesion are
of less importance for surgery planning. We propose the
reduction of the saturation for MRI data and outline distant fiber tracts.
• Increasing depth perception. We introduce the distance
ring which indicates the location of a structure in view
direction and add a three-dimensional coordinate system.
These techniques are combined with distance color blending to improve the perception of spatial depth of anatomical and functional structures.
• Defining superficial landmarks. We add a threedimensional coordinate system to trace back the lesion
in opaque volume rendering. An intuitive mechanism to
remove the skull enables the user to examine the brain’s
anatomy. These tools simplify the recognition of landmarks which can be transferred into the operation site.
• Visualization of the access path. The use of a virtual access path in our application enables the surgeon to determine an optimal incision point fast and easily without the
need of traditional cutting tools. The proposed technique
enables the combined rendering of anatomical and functional data along the trajectory.
2. Related Work
2.1. Multimodal Volume Data for Visualization
Rößler et al. [RTF∗ 06] describe a GPU-based multi-volume
framework for the visualization of functional brain images.

The framework uses the graphics hardware for interactive
visual exploration of the data and for generating of highquality visual representation. We extend the proposed solutions for overlapping multiple volumes in our work. Wilson
et al. [WLM02] show that the visualization of multimodal
volumes can help to improve the understanding of volumetric medical data. The use of illustrative techniques [BG05]
in addition to transparency in multi-volume visualization
provides information which is not available in single, traditional volume rendering. In this framework, different rendering styles can be applied for each volume which is also
the basis of our framework. Cutting-tools are powerful and
general utilities for the visualization of multimodal volume
data [MFOF02]. In their paper, Manssour et al. verify that
cutting tools can reveal additional diagnostic information. In
our work, one key feature is a geometric cutting tool which
allows to explore a virtual access path.
2.2. Enhancement of Medical Structures
Bruckner et al. [BGK06] and Viola et al. [VFSG06] propose
alternatives to geometric clipping techniques for volume visualization. The developed techniques allow for perceiving
context information by exploring the interior of a data set
without requiring prior segmentation. Because we are using
a segmented brain volume we are able to simplify the adjustment of parameters for the visual exploration. Ebert et
al. [ER00] introduce the concept of volume illustration and
describe illustration motifs in [SES05]. In their works methods for feature, depth and orientation enhancement are presented. In our application we leverage the techniques boundary enhancement, silhouettes [CMH∗ 01] and distance color
blending. Tappenbeck et al. [TPD06] present distance as
a second dimension for transfer function definition. They
compute a distance volume by slice-based selection of distance ranges. We compute the distance from a single point to
every voxel as proposed in [ZDT04]. Additionally, the distance from every voxel to a given line is computed in order
to enhance medical structures along a trajectory.
2.3. Computer Assisted Neurosurgical Planning
Beyer et al. [BHWB07] introduce an application for neurosurgical planning with high-quality interactive multimodal
volume rendering. They use raycasting for multi-volume
rendering and describe the required data and memory management. Skull peeling is presented as an extension of the
opacity peeling algorithm introduced by Rezk-Salama et
al. [RSK06] using registered CT and MRT data. In our work,
we do not rely on CT data and use the information of MRT,
fMRT and DTI data. Thus, the opacity peeling algorithm
would not be straightforward to use due to the difficult adjustment of parameters. Also, we base the discussions of our
methods and their combination as well as their parameterization on the medical requirements. Köhn et al. [KWK∗ 07]
present an application with integrated tools for functional
c 2008 The Author(s)
Journal compilation c 2008 The Eurographics Association and Blackwell Publishing Ltd.

1057

Rieder et al. / Interactive Visualization of Multimodal Volume Data for Neurosurgical Tumor Treatment

data analysis together with automatic skull stripping, vessel
extraction and manual segmentation of lesions or risk structures. In our work, we use this application for medical data
analysis, registration, and segmentation.

to a two-dimensional transfer function [KKH02]. We perform the computation of the distance dvoxel from every voxel
p voxel to the ROI on the graphics hardware. The distance is
used to specify the second dimension of the two-dimensional
transfer function.

3. Visualization of Multimodal Volume Data

The maximum distance value rROI as well as the transfer function’s opacities and colors can be specified by the
user. The Teaser Figure (left) shows that the tumor is rendered opaque and the tissue of the brain transparent, (middle) shows the opaque rendering of the brain tissue and the
clipped skull.

Typical medical applications for multimodal neurosurgical
planning display the medical data in a single viewport. Because functional data such as fMRI or DTI data are located in
the brain itself, these data cannot be explored simultaneously
with anatomical data. Therefore, physicians have to use cutting tools to explore the volume. The problem with using
cutting tools is the high degree of interaction that is typically required. Also, the advantage over MPR (Multi Planar
Reformatting) views is small, because in both views the visualization of functional and anatomical data is difficult due
to occlusion issues and has to be integrated mentally, sliceby-slice.
3.1. Dual Views for internal and external Volume Data
In our work we present dual views for visualizing multimodal volume data. The internal view (see Figure 7 (a)) is a
general view of all internal data such as fMRI activation volumes, DTI fiber tracts and the lesion, which are actually hidden by the brain and the skull. For this purpose, we choose a
transfer function which hides the skull and reduces the brain
to contours. Now all functional data as well as lesions can be
displayed without using any cutting tools.
Since functional data are related to anatomical regions and
anatomical structures are almost hidden in the first view, we
use a second viewport to visualize the brain and the skull
opaque, as well as the functional data. In this viewport,
the anatomical details are rendered using volume lightingand boundary enhancement [ER00] to get a better threedimensional perception (see Figure 7 (b)). The functional
data must still be visualized by using cutting tools because
the brain and skull occlude the brain tissue (see Teaser Figure (middle)). These two views are coherent. Every point in
the internal view has a corresponding point in the external
view.
The connection between the two viewports and the usage
of our cutting tools are discussed in Section 4.

3.3. Distance-based Enhancement of Functional Data
3.3.1. Enhancement of fMRI data
There are some issues using fMRI activation volumes, however. First, a plausible color coding is challenging. Traditionally, positive fMRI activation areas are colored red and
the negative green. Also, most applications use red as a signal color for lesions like tumors. Thus, red structures can be
mixed up easily, because of the same color and similar structure. Second, some of the activation areas are unimportant
for the diagnosis and only cause a more complex visualization. Both problems are displayed in Figure 1 (a), where the
functional data can easily be mistaken for the lesion.
Thus, in our prototype we use the color purple for lesions
to be distinguished from fMRI data. Also, we fade out the
color’s saturation of the fMRI structures depending on the
distance d f MRI to the ROI by computing the length from every voxel to the ROI using a shader program (see Figure 1).

(a)

(b)

Figure 1: In (a) the tumor is colored red, as the fMRI data
(without color blending d f MRI = max), in (b) the tumor is
colored purple whereas the saturation of the fMRI data is
reduced (d f MRI = 15).

3.2. Distance-based Combining of Transfer Functions
for Lesion Enhancement
In our application we integrated MPR views (see Figure 7),
too, because most physicians are used to work with this kind
of view. In the MPR views, a point of interest pROI can be
specified by clicking, e.g. at the lesion. The radius rROI defines the spherical region of interest (ROI). We combined
a transfer function for visualizing opaque lesion structures
with a transfer function for visualizing transparent anatomy
c 2008 The Author(s)
Journal compilation c 2008 The Eurographics Association and Blackwell Publishing Ltd.

3.3.2. Enhancement of DTI data
White matter DTI data are mostly visualized as fiber
tracts [VZKL05] for neurosurgical intervention planning. To
create fiber tracts the user has to define a ROI from which
the fiber tracking algorithm starts the reconstruction. After
this reconstruction, the user has few possibilities in reducing
unimportant fibers that are far away from the ROI, which can

1058

Rieder et al. / Interactive Visualization of Multimodal Volume Data for Neurosurgical Tumor Treatment

increase the complexity of the visualization (see Figure 2
(a)). Techniques, such as fiber bundle selection [BBP∗ 05],
allow to enhance fiber bundles but do not enable the attenuation of fiber bundles far away from the ROI.
We chose a similar strategy as in the fMRI data enhancement to hide fibers, which are not important for diagnosis.
By defining a maximum distance dDT I around the ROI, we
change the representation method for fibers with a distance
larger than the maximum. These fibers are just visualized as
outlined silhouettes (see Figure 2 (b)) using a shader program. This is an easy and fast method to show only the diagnostically relevant DTI data, because less interaction is required. Furthermore, our technique can easily be combined
with techniques such as fiber bundle selection as well as fiber
clustering [OW07].

(a)

the clicked ROI. The axes run parallel to the three main directions of the volume data and end at the hull of the brain. If
the head of the patient is not properly aligned, the coordinate
system has to be justified manually. An algorithm performs a
texture lookup into the mask volume of the brain. If the position is inside the brain, the axes will be displayed, if outside,
the axes will be hidden.
In combination with the distance color blending, the perception of the spatial depth is improved. Figures 2–3 show
the three-dimensional coordinate system. In comparison to
Figure 1 (a) the spatial localization of the tumor is facilitated
by the displayed coordinate system (Figure 1 (b)).
3.4.3. Distance Ring
At some orientations, however, the perception of the spatial depth becomes difficult because one of the axes could
be hidden by other structures or because of the perspective
distortion. For example, in Figure 3 (a) the axis in view direction is not visible. It is difficult to decide if the tumor is
more at the front or at the back side of the volume.

(b)

Figure 2: (a) Brain with reconstructed fiber tracts, displayed
entirely (dDT I = max); (b) reduced to silhouettes in dependence (dDT I = 31) of the distance to the ROI (b).

3.4. Depth Perception
In the internal view, we observed some difficulties with correctly perceiving spatial depth. By visualizing the brain as
contours, the user loses the perception of depth which can
yield a difficult association of the functional data with its
anatomic region.
3.4.1. Distance Color Blending
By using a color gradient from a warm color in the front to
a cool color in the back of the volume, the spatial depth can
be intensified. The computation is done in a fragment shader
where the front voxel of the volume is assigned the warm
color and the back voxel the cold color in view direction,
respectively. The color values between back and front are
computed using linear interpolation. We use this technique
in the internal views (Figures 1–3) to visualize the brain.
3.4.2. Three-Dimensional Coordinate System
The distance color blending alone does not allow for perceiving an optimal spatial depth. Therefore, we added a threedimensional coordinate system to the internal view. The center of the coordinate system is defined as the center point of

(a)

(b)

Figure 3: (a) If one of the axes is not visible, the perception
of the spatial depth is difficult. (b) The ring is more than half
closed (dring = 0.64), so the ROI is near the center of the
brain at the back side in view direction

To solve this issue, we propose an additional visualization aid to further intensify spatial information. We introduce an instrument called the distance ring. The distance
ring is a simple ring which indicates the location of the ROI
in the view direction. At minimal distance dring = min in
view direction, i.e. the ROI is at the nearest point inside the
brain, the distance ring is completely open. If the distance
dring = max, the distance ring is completely closed. The ring
closes clockwise between dring = min and dring = max. Figure 4 illustrates the computation of the distance ring.
The computation is performed in a fragment shader by
tracing two rays through the brain mask volume (from ROI
to back and from ROI to front): while intensity > 0:
ptesti+1 = ptesti + (vvray cstep )
c f ronti+1 = c f ronti + cstep
where ptest is the position to be tested, v ray is the view direction, cstep is the current step size and c f ront is the amount of
c 2008 The Author(s)
Journal compilation c 2008 The Eurographics Association and Blackwell Publishing Ltd.

Rieder et al. / Interactive Visualization of Multimodal Volume Data for Neurosurgical Tumor Treatment

1059

4.2. Visualization of Path to Structure of Interest

front [0]

position [0..1]

back [1]

Figure 4: Computation of the distance ring. Two rays are
traced through the volume from the ROI to the backside and
frontside along the view direction. The steps are counted to
compute the distance of the ROI.

steps to the front side of the brain. The computation of cback
is analogous.
The normalized distance dring of the ROI is the inverse
of the maximum distance c f ront + cback multiplied with the
amount of steps of the front ray c f ront :
dring[0..1] = (c f ront + cback )−1 c f ront
With the value dring we compute the closed ring in a second
shader. A value of 0.0 means the ring is completely open, a
value of 1.0 means the ring is closed and values between 0.0
and 1.0 close the ring clockwise from 0 to 360 degrees (see
Figure 3 (b)).
4. Virtual Intervention Planning
In Section 3.1 we described the dual views, the internal view
and the external view. The methods and visualizations we
propose in the following sections are for internal views only.
These visualizations allow to explore functional data as well
as lesions which often cannot be distinguished from other
tissue. While the neurosurgeon can explore the functional
data during planning, he cannot utilize this information during the intervention, as no visual landmarks can be derived
from the anatomy at the operating field. For this reason, we
introduce the second view, the external view.
4.1. Defining Superficial Landmarks
In the external view we are able to connect functional data
and lesions with anatomic cerebral structures such as gyri
and sulci (ridges and fissures in the brain’s surface). To support navigation, we added a three-dimensional coordinate
system to the external view as well. By evaluating the exit
points of the axes and repainting the points onto the patients
skull before surgery, the neurosurgeon is able to mentally
reconstruct the invisible ROI during surgery.
c 2008 The Author(s)
Journal compilation c 2008 The Eurographics Association and Blackwell Publishing Ltd.

In general, neurosurgical interventions are performed using
an operation microscope. Because the operation microscope
and the operation field have to be in line, we propose a virtual access simulation – the virtual path – which can be interactively modified by the user. The virtual path is a simple
cylinder geometry from the incision point to the ROI. Since
functional data far away from the path are of minor interest, we extend the distance-based enhancement of functional
data (discussed in Section 3.3). Therefore, we additionally
attenuate functional data depending on the distance from every voxel to the trajectory. Thus, the neurosurgeon is able to
explore the optimal path to the structure of interest.
4.2.1. Path in the Internal View
In the internal view, the path is visualized as a thin line from
the incision point to the target of the surgery. At the incision
point there are two orthogonal lines which define the diameter of the virtual cylindric path. Therefore, it is possible to
search a path which avoids contact with functional structures
like fMRI activation areas.
The internal view gives an overview of all internal data
but not the precise location of the anatomical region. The
Teaser Figure (right) shows the virtual path (cyan) from an
entry point to the ROI.
4.2.2. Path in the External View
In the external view, the path is visualized as a tubular cutting geometry through the volume of the head. If the path is
moved in another view, the virtual path will be updated automatically. This path offers the possibility of exploring the
exact thickness and direction of the surgery access. If there
are functional data, such as fiber tracts or activation regions
along this path, the neurosurgeon can see them through the
path and is able to modify the access direction. If there is
no critical region visible, this path to the structure of interest
may serve as an access route for the surgical intervention.
4.2.2.1. Computing the Path The cylindric path has a well
defined geometric object that allows the identification of any
voxels which are cut by the cylinder. The voxels that are located inside the cylinder will be discarded in the shader code
(see Figure 5).
A cylinder is defined by its length and radius. The length
v length of the cylinder is the line from the incision point
p incision of the skull’s surface to the center point p ROI of
the ROI. The incision point is marked by clicking onto the
skull. The first hitpoint is retuned by tracing a ray through
the volume. The radius cradius is defined by the user. For
every voxel, the distance to the intersection of the perpendicular line p cut point with the center line of the cylinder is
computed by solving the following equation:
pcut point = (((ppvoxel − pROI ) · vˆlength )ˆvˆlength ) + pROI

1060

Rieder et al. / Interactive Visualization of Multimodal Volume Data for Neurosurgical Tumor Treatment

interactively to visualize the anatomy of the brain. Since a
volume mask of the brain is available, we are able to use
per-tag-shading [LKP06] and to discard voxels of the skull.
A shader program computes the distance between any voxel
and the camera. By starting at a given distance threshold,
voxels are discarded from the view (see Figure 7 (b)).

Pincision
Pcutpoint
Cradius
PROI
Pvoxel

4.2.3. Path in MPR Views

Figure 5: Computation of the cylindric path from entry point
to region of interest.

In the fragment shader, all voxels p voxel whose distance
d = ||ppvoxel − p cut point || to the cut point p cut point is less than
the radius of the cylinder cradius will be discarded. Figure 6
and Figure 7 show the access path from the incision point to
the ROI.
4.2.2.2. Visualization of the Path For a better threedimensional perception and the enhancement of important
landmarks in the external view, we have implemented lighting and boundary enhancement techniques. By using lighting and cutting planes, however, artifacts can appear in the
volume. Since we use the gradient of the voxels for the lighting computation, we are not able to get correct results in homogenous regions of the volume where the gradients are ill
defined. In order to cut a volume we have to transfer normals of the cutting geometry into the cutting surfaces of the
volume (consistent shading [WEE03], see Figure 6).

(a)

(b)

Figure 6: The cylindrical cut geometry without (a) and with
consistent lighting (b). The visibility of anatomical details is
superior with consistent shading.

4.2.2.3. Additional Landmarks for Incision Point For
neurosurgeons, landmarks at the skull as well as landmarks
at the brain itself are particularly interesting. If the neurosurgeon opens the skull and removes pieces of the bone, the
brain is visible. To accurately place the cut, landmarks of
well-known brain structures are very important.
Therefore, we also add functionality to remove the skull

In Section 3.2 we have discussed the additional integration
of MPR views in our application. Since we display the virtual access path in the internal and external view, we extend
the MPR views by adding a virtual cylinder. The cylinder allows the neurosurgeon to evaluate the path through the brain
by slicing. Functional data such as activation areas and fibers
are displayed altogether because attenuation is not required.
5. Results
We frequently discussed the proposed multimodal visualization techniques for neurosurgical therapy planning with
three neurosurgeons and two neuro-radiologists, medical experts with substantial experience. The dual views allow to
observe internal structures such as functional regions and lesions together with external structures and landmarks as the
surface of skull and brain. Although we display the data in
two different viewers, this concept has been well perceived
by the medical experts because of the possibility of an initial
observation of the functional data at minor interaction.
The distance based methods for attenuating anatomic details and for enhancing related functional structures enable
the neurosurgeons to observe internal data without the need
of slicing which was again received helpful. The coordinate
system as well as the distance ring provide additional depth
indicators. However, not all of the medical experts understood the distance ring intuitively. After illustrating its usage, the neurosurgeons deemed the distance ring very helpful for depth recognition particularly with regard to the standard medical views (axial, coronal, sagittal).
The detailed exploration was performed focussing on the
opaque rendering of the external view. The neurosurgeons
regarded the virtual access path as the major feature for
surgery planning because of the possibility to find the trajectory to the lesion with respect to risk structures. For the
medical experts the verification and fine-tuning of the virtual
incision point was easy to achieve. Also, the visualization of
the gyri and sulci as well as the skull’s anatomy helps to
recognize landmarks which let the access path transfer into
the operation site. In particular cases, the MPR views helped
the neurosurgeons to examine details of risk structures along
the access path. The neurosurgeons tested our prototype and
emphasized the high importance of multimodal volume rendering for neurosurgical therapy planning because it enables
them to see risk structures extracted from different modalities along the virtual trajectory, e.g. fiber tracts combined
with anatomical structures as lesion and brain tissue.
c 2008 The Author(s)
Journal compilation c 2008 The Eurographics Association and Blackwell Publishing Ltd.

Rieder et al. / Interactive Visualization of Multimodal Volume Data for Neurosurgical Tumor Treatment

5.1. Implementation
We implemented the previously discussed methods with the
rapid prototyping system MeVisLab using the OpenShading
Language (GLSL) and image-processing modules. Our visualization prototype has been developed as an extension of
an existing software platform for neurosurgical planning and
monitoring where the raw image data are loaded and the preprocessing is performed. The segmentation of the brain was
created by a semi-automatic watershed transformation, the
data sets were aligned using inter-sequence co-registration.
The resulting multimodal data are directly read into our prototype where the visualization is performed using a slicebased direct volume renderer. The data sets are loaded into
the GPU memory and fused with blending functions.
5.2. Performance
All our methods achieve interactive frame rates. Figure 8
shows the average frame rates of the internal and external
view (both 512x512 pixel) by performing a 360 degree rotation on a Mac Pro 2.66 GHz with 4 GB RAM and an ATI
Radeon X1900 graphics card. The size of the MRT data set
is 256x256x162 pixel and the size of the fMRI data set is
36x48x20 pixel.
6. Conclusions
This paper presents methods for visualizing multimodal volume data for neurosurgical tumor treatment which make use
of modern graphics accelerators to allow interactive frame
rates. The suggested methods for visualization allow the
neurosurgeon to improve the neurosurgical planning. We believe the virtual access path could become an integral part
of preoperative planning and promises to impact therapeutic
decisions in neurosurgery.
Acknowledgments
The authors wish to thank Horst Hahn, Alexander Köhn,
Florian Weiler, Dr. med. H.-H. Görge and Dr. med. Stephan
Felber. Data used in this article are courtesy of Invivo Diagnostic Imaging, FL, and Lahey Clinic Burlington, MA.
References
[BBP∗ 05] B LAAS J., B OTHA C. P., P ETERS B., VOS
F. M., P OST F. H.: Fast and reproducible fiber bundle
selection in DTI visualization. In Proc. of IEEE Visualization (2005), pp. 59–64.
[BG05] B RUCKNER S., G RÖLLER M. E.: VolumeShop:
An Interactive System for Direct Volume Illustration. In
Proc. of IEEE Visualization (2005).
[BGK06] B RUCKNER S., G RIMM S., K ANITSAR A.:
Illustrative Context-Preserving Exploration of Volume
Data. IEEE Trans. on Visualization and Computer Graphics 12, 6 (2006), 1559–1569.
c 2008 The Author(s)
Journal compilation c 2008 The Eurographics Association and Blackwell Publishing Ltd.

1061

[BHWB07] B EYER J., H ADWIGER M., W OLFSBERGER
S., B ÜHLER K.: High-Quality Multimodal Volume Rendering for Preoperative Planning of Neurosurgical Interventions. IEEE Trans. Vis. Comput. Graph. 13, 6 (2007),
1696–1703.
[CMH∗ 01] C SÉBFALVI B., M ROZ L., H AUSER H.,
K ÖNIG A., G RÖLLER E.: Fast Visualization of Object
Contours by Non-Photorealistic Volume Rendering. Computer Graphics Forum 20, 3 (2001).
[ER00] E BERT D., R HEINGANS P.: Volume illustration:
non-photorealistic rendering of volume models. In Proc.
of IEEE Visualization (2000), pp. 195–202.
[KKH02] K NISS J., K INDLMANN G., H ANSEN C.:
Multi-Dimensional Transfer Functions for Interactive
Volume Rendering. IEEE Trans. on Visualization and
Computer Graphics 8, 3 (2002), 270–285.
[KWK∗ 07] K ÖHN A., W EILER F., K LEIN J., KONRAD
O., H AHN H. K., P EITGEN H.-O.: State-of-the-Art
Computer Graphics in Neurosurgical Planning and Risk
Assessment. In Proc. of Eurographics Short Papers and
Medical Prize Awards (2007), pp. 117–120.
[LKP06] L INK F., KOENIG M., P EITGEN H.-O.: MultiResolution Volume Rendering with per Object Shading.
In Proc. of VMV (2006), pp. 185–191.
[MFOF02] M ANSSOUR I. H., F URUIE S. S., O LABAR RIAGA S. D., F REITAS C. M. D. S.: Visualizing Inner
Structures in Multimodal Volume Data. In Proc. of IEEE
SIBGRAPI (2002), pp. 51–58.
[OW07] O’D ONNELL L. J., W ESTIN C.-F.: Automatic
Tractography Segmentation Using a High-Dimensional
White Matter Atlas. In IEEE Trans. On Medical Imaging (2007).
[RSK06] R EZK -S ALAMA C., KOLB A.: Opacity peeling
for direct volume rendering. In Computer Graphics Forum (2006), vol. 25(3), pp. 597–606.
[RTF∗ 06] R ÖSSLER F., T EJADA E., FANGMEIER T.,
E RTL T., K NAUFF M.: GPU-based Multi-Volume Rendering for the Visualization of Functional Brain Images.
In Proc. of SimVis (2006), pp. 305–318.
[SES05] S VAKHINE N., E BERT D. S., S TREDNEY D.: Illustration Motifs for Effective Medical Volume Illustration. IEEE Comput. Graph. Appl. 25, 3 (2005), 31–39.
[TPD06] TAPPENBECK A., P REIM B., D ICKEN V.:
Distance-Based Transfer Function Design: Specification
Methods and Applications. In Simulation und Visualisierung (2006), pp. 259–274.
[VFSG06] V IOLA I., F EIXAS M., S BERT M., G RÖLLER
M. E.: Importance-Driven Focus of Attention. In IEEE
Trans. on Visualization and Computer Graphics (2006).
[VZKL05]

V ILANOVA A., Z HANG S., K INDLMANN G.,

1062

Rieder et al. / Interactive Visualization of Multimodal Volume Data for Neurosurgical Tumor Treatment
25 fps

L AIDLAW D. H.: An Introduction to Visualization of Diffusion Tensor Imaging and its Applications. In Visualization and Image Processing of Tensor Fields. SpringerVerlag, 2005, pp. 121–153.

24 fps
20 fps

15 fps

[WEE03] W EISKOPF D., E NGEL K., E RTL T.: Interactive Clipping Techniques for Texture-Based Volume Visualization and Volume Shading. IEEE Trans. on Visualization and Computer Graphics (2003), 298–312.

10 fps

9 fps

13 fps

12 fps

12 fps

+ fMRI

+ DTI

9 fps
5 fps

0 fps
brain

[WLM02] W ILSON B., L UM E. B., M A K.-L.: Interactive Multi-volume Visualization. In Proceedings of ICCS
(2002), pp. 102–110.

+ ring

+ fMRI

+ DTI

brain + access path + skull

Figure 8: Average frame rates of the internal view (left)
and external view (right), with additional rendering features
from left to right, respectively. The computation of the access
path reduces performance by a factor of two. All other methods have negligible influence on the rendering performance.

[ZDT04] Z HOU J., D ÖRING A., T ÖNNIES K. D.: Distance based enhancement for focal region based volume
rendering. In BVM (2004), pp. 199–203.

(a)

(c)

12 fps

10 fps

9 fps

(b)

(d)

(e)

Figure 7: The three implemented views. In (a) the internal view shows the functional data and the presented techniques for enhancing the perception of the spatial depth. Figure (b) displays the corresponding external view with synchronized perspective.
Each MPR view (c-e) shows a slice of the volume data, the virtual access path and functional as well as anatomical data.

c 2008 The Author(s)
Journal compilation c 2008 The Eurographics Association and Blackwell Publishing Ltd.

