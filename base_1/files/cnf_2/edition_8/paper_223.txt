DOI: 10.1111/j.1467-8659.2008.01194.x

COMPUTER GRAPHICS

forum

Volume 27 (2008), number 8 pp. 2178–2187

Mapping Highly Detailed Colour Information on Extremely
Dense 3D Models: The Case of David’s Restoration
M. Dellepiane, M. Callieri, F. Ponchio and R. Scopigno
Visual Computing Lab, ISTI-CNR, Pisa, Italy
dellepiane@isti.cnr.it

Abstract
The support of advanced information technology (IT) to preservation, restoration and documentation of Cultural
Heritage (CH) is becoming a very important goal for the research community. Michelangelo’s David was one
of the first applications of 3D scanning technology on a highly popular work of art. The subsequent restoration
campaign, started in 2002 and concluded in 2004, was also a milestone for the adoption of modern scientific
analysis procedures and IT tools in the framework of a restoration process. One of the focuses in this restoration
was also methodological, i.e. to plan and adopt innovative ways to document the restoration process. In this paper,
we present the results of an integration of different restoration data (2D and 3D datasets) which has been concluded
recently. The recent evolution of HW and SW graphics technologies gave us the possibility to interactively visualize
an extremely dense 3D model which incorporates the colour information provided by two professional photographic
campaigns, made before and after the restoration. Moreover, we present the results concerning the mapping, in
this case on the 2D media, of the reliefs produced by restorers to assess and document the status of the marble
surface before the restoration took place. This result could lead to new and fascinating applications of computer
graphics for preservation, restoration and documentation of CH.
Keywords: colour projection, texture mapping, image registration
ACM CCS: I.3.7 [Computer Graphics]: Colour, shading, shadowing and texture

1. Introduction
Michelangelo’s David is one of the most popular art icon of
our age, a rather old friend who deserves cure. The statue
life was not so easy as one can imagine, since several accidents and the passing of time left traces on its surface. The
statue was always kept under control and subject to several
restoration actions in the past. At the end of last century,
a major restoration action was planned to allow it to begin
the new millennium with an improved look and a complete
assessment of its conservation conditions. The restoration
planned was a light one, mostly focused on the removal of
dust, spots and other deposits accumulated in the years on
its surface, and on the replacement of the plaster fillings of
some fractures (e.g. the ones filling the small gaps of the fragments of the arm broken in XV cent.). Therefore, no major
change of the shape was planned, but just a selective cleaning
which should have changed its surface appearance. Neverc 2008 The Authors
Journal compilation c 2008 The Eurographics Association and
Blackwell Publishing Ltd. Published by Blackwell Publishing,
9600 Garsington Road, Oxford OX4 2DQ, UK and 350 Main
Street, Malden, MA 02148, USA.

theless, the restoration was preceded by an intense and very
complete set of scientific investigations, aimed at making a
severe screening of the statue conditions [BFMS04]. The interest of the curators to run a complete scientific assessment
of the statue condition, together with the availability of a
digital 3D model of the statue (scanned by the Stanford’s
Computer Graphics Group in the framework of the Digital
Michelangelo project [LPC∗ 00]), made it possible to adopt
a number of ICT technologies to both analyse and document
the statue conditions and the restoration action [BFMS04,
CCG∗ 04].
In particular, the David restoration project (started in Florence in 2002 and terminated in 2004) was a milestone for
the definition and development of solutions which qualify
a modern restoration, by integrating a number of different
scientific approaches under the same global focus (IT was
just one of those disciplines). Among other tasks, we were

2178

This paper was selected from the Cultural Heritage Stream
of Eurographics 2007

M. Dellepiane et al. / Mapping Colour data and Reliefs on David

asked to document the status of the statue before and after the
restoration in a manner which should be both rigorous and
able to transmit the information to the experts and the public
in a simple and intuitive way. The opportunity to experiment
modern visual data management approaches was immediately evident. The starting point was the 3D model produced
by the Digital Michelangelo project (a surface model, 56M
triangles, acquired with triangulation-based laser scanning
technology). As the restoration was mostly a cleaning task
and perceptible modifications of the shape of the artwork
were not forecasted, we did not plan a new 3D scan after the
conclusion of the restoration work. The changes were going
to occur mostly in terms of different appearance of the surface. For this purpose, a high quality photographic essay of
the pre- and post-restoration condition was the starting point
and one of the major sources of data (see Section 4). Moreover, another important piece of information was the analysis
of the status of the surface done by the chief restorer, i.e. a
clear characterization of the degradation status done on the
entire surface extension. The restoration supervisor asked
for an innovative approach to replace the classical textual
report (usually written around a few images and drawings).
For this purpose, a joint group composed by the restoration
supervisor, the restorers and the IT staff discussed several
options and agreed on the approach described in Section 5.
Unfortunately, at that time the only possibility was to implement it through the drafting of several manual reliefs. The
following step was how to manage all those data (a huge
3D model, around 150 high-resolution images and several
hundreds of reliefs) in an interactive manner, possibly using a 3D approach to data presentation. Due to the limits in
algorithms or hardware resources, interactive visualization
of highly dense 3D and 2D data has become possible only
recently. This has given us the possibility to process most
of the data acquired and to present them interactively. The
basic components, that only recently have become a robust
technology, are the ones needed to build up and render a 3D
model with highly detailed geometric and colour information. With highly detailed we mean more than 50M faces
and more than 200M texture data. But we still have some
limitations in managing some of the available data, i.e. the
line-based reliefs whose mapping on 3D geometry is still
complex. The solutions devised to present the data are presented in Sections 6 and 7. Finally, conclusions and some
remaining issues are illustrated in Section 8.

2179

a major source of digital data to represent the CH artifacts
of interest and to support to the work of experts for several
applications, like preservation, documentation, prototyping,
visualization [BCC∗ 05, BRM∗ 02, LPC∗ 00, STH∗ 03]. Beyond the classical uses which focus on visual presentation,
other approaches have been proposed [PSS05] to help in a
very concrete way the restoration process, or to provide comprehensive database for diagnostic and restoration purposes
[GPCM05]. A comprehensive survey of the many different
approaches proposed to integrate 3D data representation in
the framework of CH management goes well beyond the
scope of this paper. We give in the following just a few
citations of representative papers which focus on the main
technical instruments needed to cope with 3D models and
colour data. How to map efficiently and accurately a set of
2D images on a 3D model is a classical research topic, where
intense research has been done in the last years. Several approaches have been proposed [Bau02, BMR01, CCS02], all
aiming to produce a realistic texture map from a set of photos. The major issues are usually how to build up an optimal
parameterization of the surface on a texture space, and how
to integrate the multiple and redundant 2D data (many input images) into a common texture space. Other approaches
focus on more accurate techniques to gather the reflectance
properties of the object material [Goe04], therefore going
beyond the naive apparent colour gathered with digital photography. Unfortunately, all these methods work very well
when we have a small number of 2D views, simple geometry
and/or controlled illumination. More recently, new solutions
have been proposed to manage the alignment of a big number of photos on a 3D geometry [FDG∗ 05] and to compute
weighted colour values from all these samples [CCCS07].
These solutions have been already applied in the context of
CH related projects (see e.g. [BCC∗ 06]).
The evolution of inexpensive GPUs and the birth of new
algorithms for the visualization of extremely dense 3D models [BK03, CGG∗ 05, Pri00, RL00] led to the possibility
to display colour by assigning a colour value to each vertex of the geometry (colour per-vertex), rather than building up several textures, mapped to a high-resolution 3D
mesh [BGB∗ 05, DBH00, DPF01]. These approaches have
two positive advantages: they do not require a parameterization on a texture space and encode colour information in a
more space-efficient manner on all those cases where the 3D
model resolution is approximately the same as the colour data
resolution.

2. Related Work
A number of projects regarding the use of new technologies
in Cultural Heritage (CH) have been presented in recent years
(see the many symposia and conferences focusing on this domain). Among the general IT domain, 3D computer graphics
has a consolidated reputation as being one of the major IT
tools for the study and management of CH artifacts. More
specifically, 3D scanning [BR02] is nowadays accepted as

3. The 3D Model
The Stanford’s Digital Michelangelo project [LPC∗ 00] produced a huge amount of different data (3D models, 2D RGB
and UV images). The result of the scanning campaign was a
very detailed 3D model (56 million triangles, reconstructed
from 4000 range images using a distance field with 1-mm
cell size). The Digital Michelangelo project acquired also

c 2008 The Authors
Journal compilation c 2008 The Eurographics Association and Blackwell Publishing Ltd.

2180

M. Dellepiane et al. / Mapping Colour Data and Reliefs on David

Figure 1: Examples schema of the photographic campaign, describing the coverage of the set of photos.
data on the surface colour, but those data were not useable
for our purposes both for some apparent contamination from
an UV light source used while taking the RGB images and
for the specific needs of the restoration documentation (two
nearly identical set of views were requested be taken, both
before and after the restoration, from known positions on
the scaffolding built around the statue). The evolution of the
scanning technology would have permitted nowadays to have
a slightly better sampling resolution and an higher resolution
final model. Unfortunately, the cost of scanning again such a
large surface from a scaffolding was considered too expensive for the limited restoration project finances. The available
Stanford’s 3D data quality was considered sufficient for the
purposes of the restoration and documentation.

4. Photographic Acquisition
To obtain a concrete and accurate visual survey of the status of the surface, a high-resolution photographic survey of
the David was performed by a professional photographer
(Studio Rabatti and Domingie, Florence). The photographic
sampling was done according to the specifications defined

jointly by the IT staff and the restoration supervisor (a graphic
representation of the planned photo survey is shown in
Figure 1). Photos have been taken in two different periods
(before the start of the restoration and at the very end), requiring around one complete week of work each. The amount
of 2D data collected (61 images, respectively 1920 × 2560
to document the pre-restoration status; 68 images, respectively 2336 × 3504 for post-restoration status) was about
800 Mpixels. Some sample images from both sets are shown
in Figure 2.

5. Restorers’ Analysis: How to Take Trace of the
Condition of a Complex Surface?
The survey of the conservation status of the surface was one
of the requested documents which should have been produced
in the restoration process. The problem was how to plan that
survey in order to make it possible the integration of the data
produced with the digital data (2D or 3D). Nowadays, the
more direct solution could be to design a tool which allows
the restorer to draw the survey directly on the 3D model, i.e.
using a painting/drafting system to make the relief directly

c 2008 The Authors
Journal compilation c 2008 The Eurographics Association and Blackwell Publishing Ltd.

M. Dellepiane et al. / Mapping Colour data and Reliefs on David

2181

Figure 2: Examples of images from the pre- and postrestoration campaign.

onto the 3D model. Four years ago, the status of the technology did not allow us to even consider this approach. Another
hard constrain was the limited experience of the restorers
with IT and CG technology, and therefore this solution was
immediately abandoned. The approach followed is therefore
based on a manual relief drafting, followed by a digitization
phase and a final mapping. The restorers have performed a
precise graphic survey on the status of the David’s surface.
They drew very accurate annotations on the high resolution
photos (the ones from the photographic essay, see previous
section), covering all the surface of the David. These annotations describe in a very detailed manner the presence of:
(i) imperfections in the marble (small holes or veins); (ii)
deposits and strains (e.g. brown spots or the traces of straining rain); (iii) surface consumption; and (iv) traces of the
Michelangelo’s workmanship. These annotations have been
drawn by the restorers on transparent acetate layers positioned onto each printed images, using different colour to
indicate the same phenomena in the different sheets. Therefore, we have four different graphic layers for each one of the
61 high-resolution photos (documenting the pre-restoration
status). An example of the graphic relief is shown in
Figure 3.
These graphic reliefs on A3 acetate sheets have been
scanned (using a commercial A3 flatbed 2D scanner), registered on the corresponding RGB image (the roto-translation
needed to have a correct matching between each relief and
the corresponding digital image), and saved at the same resolution of the corresponding RGB image.

Figure 3: An example of an image of the photographic set
with the corresponding (b) imperfections, (c) deposits and
(d) consumption reliefs.
sic’ 2D mapping of the reliefs on the corresponding 2D RGB
images (implemented using web-based technologies), and
(ii) mapping of the RGB data (pre- and post-restoration images) on the digital 3D model. The 2D mapping was chosen
as an easy way for experienced and unexperienced users
to access the photographic and reliefs archive, and also because at restoration time there were several constraints to the
projection and visualization of colour on 3D models. More
recently, new techniques and tools made it possible to map
all the images and visualize dense geometry interactively. In
the next subsections, we describe the two different visualization approaches and, very briefly, the new solutions recently
proposed and used to build up the mapping.
6.1. Mapping reliefs on 2D images

6. Data Mapping
The amount of high quality data described in the previous
sections was really a valuable documentation of the restoration process. In order to visualize, analyse and compare data
with a paperless mode, two approaches were chosen: (i) ‘clas-

An intuitive Web-based system was created, that can be delivered either on DVD or on Internet. (Due to copyright issues,
the material is now distributed only on DVD.) Following
the scheme provided by the photographic campaign, the user
can choose any of the provided views, and then visualize the

c 2008 The Authors
Journal compilation c 2008 The Eurographics Association and Blackwell Publishing Ltd.

2182

M. Dellepiane et al. / Mapping Colour Data and Reliefs on David

post-restoration images. A possible solution to this problem
is sketched in Section 7, i.e. after mapping the RGB data to
the 3D model, as shown in Section 6.

6.2. Mapping RGB Data on the 3D Model
There are two main issues related to the projection of the
colour information on a 3D model:
(i)

(ii)
Figure 4: A screenshot of the web based system to visualize
reliefs mapped on 2D images.

The alignment of each photo in the set to the 3D model.
This action corresponds to the estimation of the intrinsic and extrinsic camera parameters. In most cases, the
parameters are not known in advance;
The creation of a set of rules to calculate an interpolated colour value assigned to each vertex of the model,
taking into account the weighted contribution of all the
photos which project on the same surface location.

Both tasks imply the manipulation of a huge amount of data,
and have to be performed with the minimum human intervention, as fast as possible to reduce personnel costs. The issue
of registering uncalibrated images to a 3D model has been
discussed in several papers [JC04, KNZI02, LWG97]. Completely automatic registration can be achieved only under
particular assumptions (e.g. [LHS00]), otherwise user intervention is necessary. Algorithms which estimate parameters
need some correspondences between the image and the 3D
model. After this approximate selection, an error minimization method is applied to find the best possible alignment.
We developed a tool which allows users to load both the
3D model and all the photos, creating an alignment process whose data (correspondences coordinates, parameters
of aligned images) are saved in an xml file.
Figure 5: Images of the same portion of the statue, taken
before and after restoration: in this case the position of the
camera is different.

corresponding photo and, selectively upon his/her choice, the
superimposed reliefs related to imperfections, deposits and
deteriorations (see Figure 4). Images can be visualized with
different zooming factors, so the high detail can be appreciated at its best. A screenshot of the system is shown in
Figure 4: in this case, the deposits relief is superimposed to
the selected image.
It’s also possible to load the corresponding photo taken after the restoration. Unfortunately the position of the camera
in the two acquisition campaign usually was slightly different (an example is shown in Figure 5), because it was really
impossible to shoot the post-restoration images from exactly
the same views used in the pre-restoration campaign. These
small view differences are not a problem for a human observer, but make it impossible to superimpose the pre- and
post-restoration images, or to superimpose the reliefs to the

One of the most useful features is the possibility to set correspondences not only between a photo and the 3D model,
but also between photos (image-to-image correspondences),
using the overlapping image sections. These image-to-image
correspondences are used by the alignment application to
infer new correspondences with the 3D model. This was particularly useful for the David case, because in some parts
of the statue (abdomen, legs, back), it was very hard to find
geometric features to set correspondences to the 3D model
(see Figure 6). On the contrary, the small spots on the marble
surface were used to find robust image–to–image correspondences in the overlapping parts of images and in a very fast
way. A comprehensive presentation of all the features of the
alignment tool is contained in [FDG∗ 05].
Once calibration data have been estimated (see Figure 7),
we have to reconstruct the colour information as a weighted
average of all the overlapping images and to project it onto
the 3D model. As previously stated, texture mapping could
not be used without severe sub-sampling of images. Hence,
because a very dense 3D models is provided, colour per

c 2008 The Authors
Journal compilation c 2008 The Eurographics Association and Blackwell Publishing Ltd.

M. Dellepiane et al. / Mapping Colour data and Reliefs on David

2183

Figure 6: Screenshot of our Image Alignment tool with an example of partially overlapping RGB images (red circles indicate
an image-to-image correspondence).

Figure 7: Screenshot of our Image Alignment tool: an example of an image aligned to the 3D model.
vertex is the more proper choice to preserve both geometric
and colour detail.
Knowing the camera projection parameters, it is easy to
determine if (and where) a point on the surface does map
inside any of the source photos. In this way, it is possible

to assign the colour, taken from the corresponding location
on the 2D photo space, to a point onto the surface. The
real problem is when, due to the redundancy of the photo
sampling, the same surface point can take the colour from
many sources images. To solve this, we developed a system
able to evaluate the quality of each contributing pixel using

c 2008 The Authors
Journal compilation c 2008 The Eurographics Association and Blackwell Publishing Ltd.

2184

M. Dellepiane et al. / Mapping Colour Data and Reliefs on David

yse the appearance of the statue before and after restoration
from any arbitrary point of view. Interactive visualization is
made possible by the multi-resolution technique presented in
[CGG∗ 05]; built over this data representation approach, the
Virtual Inspector tool provides a framework which allows the
easy inspection and virtual manipulation of a complex and
highly detailed 3D model.

Figure 8: Example of a weight mask (on the right) calculated
from the photo on the left. The weights represent the quality of
each pixel, expressed as floating point value (in the image on
the right, the weights are rendered using grey values, white
being the highest quality for this photo).
various metrics and able to compute the appropriate colour
using a weighted mean. The mapping tool, starting from the
set of input RGB photo, the 3D model and the calibration
data, automatically creates a weighting mask for each photo
that represent a per-pixel quality. The weight is calculated
as the combination of three main metrics, which measure for
each pixel: how orthogonally the surface is sampled (angle
between surface normal and view direction); how far is the
surface from the camera (distance from viewpoint); and how
far is the pixel from image borders and object discontinuities (geodesic distance from borders and silhouettes, areas
of minimal quality). An example of the mask calculated for
the given photo is shown in Figure 8. The colour value assigned to each vertex is a weighted sum of the contributions
from all images. With this weighting mask, we can efficiently
use all the redundancy present in the source images to reduce
illumination artifacts and incoherence between different images, while at the same time maintaining the blurring effect
as low as possible. Another important issue was the need to
deal with a big amount of geometric and colour data: both
the 3D model and the photographic dataset were too big to
be kept in main memory. Given the characteristics of locality
and modularity of the blending and mapping algorithm, it
was easy to develop an out-of-core strategy able to deal with
such large datasets. More precise explanation of all the features of the mapping tool can be found in [CCCS07]. After
the colour projection we obtained two 56 Million triangles
coloured models. Two possible uses of these 3D models are
shown in the next section.
7. Advantages of Improved Visualization
The most intuitive use for the two 3D models is interactive
visualization, which gives the user the possibility to anal-

A screenshot of the application is shown in Figure 9. The
pre- and post-restoration models are shown on the left and
right side, respectively. The user can easily change the model
position and the illumination, in order to frame arbitrary
points of view. The main differences in the marble surface
conditions can be seen in a very intuitive way. Another interesting possibility is to render the model from arbitrary points
of view. For example, we could use the camera parameters
estimated for a photo being part of the pre-restoration set and
render the post-restoration model from the corresponding
camera position. In this way, we can obtain an image of the
restored model which is perfectly aligned to the starting prerestoration photo, resolving the issue mentioned previously
in Section 6. An example of this particular mapping is shown
in Figure 10, where the left-most image is taken from the prerestoration set and the central image is the corresponding one
from the post-restoration set. It can be easily observed that
the point of view is slightly different, and superimposition
is impossible. The right side image is a rendering of the 3D
model with post-restoration colour from the camera parameters estimated for the left side image. Now, this syntectic
image could be very useful not only for superimposition of
re-restoration reliefs but also to try to reproduce a similar
illumination condition, which was slightly different between
the two sets.

8. Conclusions and Future Work
In this paper, we chose the David as a representative case
to show that the advance of new IT and CG technologies
can continuously provide new means to support restoration
and documentation of CH. The possibility to map a large
set of RGB images on a very detailed 3D model can be
very useful not only in terms of documentation and visual
comparison, but also for the support of the restoration: for
example, the restorer could directly work on the coloured
3D model to sketch reliefs, spot particular points, extrapolate indications about the material. One weak point of our
current colour management approach on 3D models is the
dependency from the quality of the photo set; if the photo set
doesn’t cover parts of the geometry, no colour value can be
assigned to the corresponding vertices. New texture synthesis approaches have been recently proposed for filling texture
gaps, and could be included in the approach here presented
to synthesize plausible values for the missing surface regions
(but it has to mentioned that in CH management curators are
usually against any value which is synthesized rather than
sampled). Moreover, lighting conditions can influence the

c 2008 The Authors
Journal compilation c 2008 The Eurographics Association and Blackwell Publishing Ltd.

M. Dellepiane et al. / Mapping Colour data and Reliefs on David

2185

Figure 9: Screenshot of the Virtual Inspector visualization tool.

Figure 10: Left: one of the images of the pre-restoration set;
centre: the corresponding image in the post-restoration set;
right: rendering of post-restoration 3D model from camera
position of pre-restoration image.
final result: if the photos are taken under different illumination, or when there is insufficient overlapping to blend the
different colour samples, a colour discontinuity will be visible after projection on the 3D mesh. Some examples about
these aliasing are shown in Figure 11. Some solutions to these
issues can be: a more careful photographic acquisition (i.e.
under a controlled illumination) and the adoption of more sophisticated techniques to estimate illumination and material
features from the acquired photos.

Figure 11: Example of imperfections on the coloured model,
due to the quality of the input photo set: leftwards, black
parts are surface regions which were not covered by any
photo; rightwards, the colour jump on the chest is due to
different illumination and insufficient overlapping between
photos.
Acknowledgements
We would like to acknowledge the important contributions
given in the design of the tools presented here by Franca
Falletti, the Director of the Galleria dell’Accademia Museum and mainly responsible for the restoration together

c 2008 The Authors
Journal compilation c 2008 The Eurographics Association and Blackwell Publishing Ltd.

2186

M. Dellepiane et al. / Mapping Colour Data and Reliefs on David

with Mauro Matteini of ICVCB-CNR; the restorers are
Cinzia Parnigoni and Agnese Parronchi. The David 3D model
is courtesy of the Digital Michelangelo Project, Stanford
University. The colour images of the David model have
been produced by Rabatti and Domingie Photographers and
Galleria dell’Accademia, Florence, Italy. We gratefully acknowledge the financial support of the ‘Friends of Florence’
association.

References
[Bau02] BAUMBERG A.: Blending images for texturing 3D
models. In BMVC 2002 (2002), Canon Research Center
Europe, pp. 404–413.
[BCC∗ 05] BALZANI M., CALLIERI M., CAPUTO G., CIGNONI
P., DELLEPIANE M., PINGI P., PONCHIO F., SCOPIGNO R.,
TOMASI A., UCCELLI F.: Using multiple scanning technologies for the 3D acquisition of torcello’s basilica. In
International Workshop 3D-ARCH’2005 – 3D Virtual Reconstruction and Visualization of Complex Architectures,
August 22–24, 2005, Mestre-Venice, Italy (2005), pp. 24–
31.
[BCC∗ 06] BARACCHINI C., CALLIERI M., CORSINI M.,
DELLEPIANE M., DERCKS U., KEULTJES D., MONTANI C.,
SCOGNAMIGLIO M., SCOPIGNO R., SIGISMONDI R., WOLF
G.: Starting the cenobium project: The cloister of monreale (sicily) revealed. In VAST 2006 Conference Proceedings (November 2006), M. IOANNIDES, D. ARNOLD,
F. NICCOLUCCI, K. MANIA (Eds.), pp. 100–110.
[BFMS04] BRACCI S., FALLETTI F., MATTEINI M., SCOPIGNO
R.: Exploring David: Diagnostic Tests and State of Conservation. Giunti Editore, 2004.
[BGB∗ 05]

BORGEAT L., GODIN G., BLAIS F., MASSICOTTE P.,
LAHANIER C.: Gold: Interactive display of huge colored
and textured models. ACM Transactions on Graphics 24,
3 (2005), 869–877.

[BK03] BOTSCH M., KOBBELT L.: High-quality point-based
rendering on modern GPUs. In Proceedings of Pacific
Graphics (2003), pp. 335–343.
[BMR01] BERNARDINI F., MARTIN I., RUSHMEIER H.: Highquality texture reconstruction from multiple scans. IEEE
Transactions on Visualization and Computer Graphics 7,
4 (2001), 318–332.
[BR02] BERNARDINI F., RUSHMEIER H. E.: The 3D Model
Acquisition Pipeline. Computer Graphics Forum 21, 2
(2002), 149–172.
[BRM∗ 02] BERNARDINI F., RUSHMEIER H. E., MARTIN I.,
MITTLEMAN J., TAUBIN G.: Building a digital model of

Michelangelo’s Florentine Pieta’. IEEE Computer Graphics & Applications 22, 1 (2002), 59–67.
[CCCS07] CALLIERI M., CIGNONI P., CORSINI M., SCOPIGNO
R.: Masked photo blending: Mapping dense photographic
dataset on dense 3D models. Computer & Graphics 32, 4
(2008), 464–473.
[CCG∗ 04] CALLIERI M., CIGNONI P., GANOVELLI F., IMPOCO
G., MONTANI C., PINGI P., PONCHIO F., SCOPIGNO R.: Visualization and 3D data processing in David restoration. IEEE
Computer Graphics & Applications 24, 2 (2004), 16–21.
[CCS02] CALLIERI M., CIGNONI P., SCOPIGNO R.: Reconstructing textured meshes from multiple range rgb maps.
In 7th International Fall Workshop on Vision, Modeling,
and Visualization 2002 (Erlangen (D), November 20–22,
2002), IOS Press, pp. 419–426.
[CGG∗ 05] CIGNONI P., GANOVELLI F., GOBBETTI E., MARTON
F., PONCHIO F., SCOPIGNO R.: Batched multi triangulation.
In IEEE Visualization 2005 (2005), pp. 27–35.
[DBH00] DOLLNER J., BAUMMAN K., HINRICHS K.: Texturing
techniques for terrain visualization. In IEEE Visualization
(2000), pp. 227–234.
[DPF01] DUMONT R., PELLACINI F., FERWERDA J. A.:
A perceptually-based texture caching algorithm for
hardware-based rendering. In Eurographics Workshop on
Rendering (2001), pp. 249–256.
[FDG∗ 05] FRANKEN T., DELLEPIANE M., GANOVELLI F.,
CIGNONI P., MONTANI C., SCOPIGNO R.: Minimizing user
intervention in registering 2D images to 3D models. The
Visual Computer 21, 8–10 (2005), 619–628.
[Goe04] GOESELE M.: New Acquisition Techniques for Real
Objects and Light Sources in Computer Graphics. PhD
thesis, Universit¨at Saarbr¨ucken, 2004.
[GPCM05] GIUNTA G., PAOLA E. D., CASTIGLIONE B. M.
V., MENCI L.: Integrated 3D-database for diagnostics and
documentation of milan’s cathedral fac¸ade. In CIPA XX
International Symposium (Torino, Italy, September 2005),
pp. 56–61.
[JC04] JANKO Z., CHETVERIKOV D.: Photo-consistency based
registration of an uncalibrated image pair to a 3D surface model using genetic algorithm. In Proceedings of
the 3D Data Processing, Visualization, and Transmission
(3DPVT’04) (Washington, USA, 2004), IEEE Computer
Society, pp. 616–622.
[KNZI02] KURAZUME R., NISHINO K., ZHANG Z., IKEUCHI K.:
Simultaneous 2D images and 3D geometric model registration for texture mapping utilizing reflectance attribute.
In ACCV2002 (2002), pp. 99–106.

c 2008 The Authors
Journal compilation c 2008 The Eurographics Association and Blackwell Publishing Ltd.

M. Dellepiane et al. / Mapping Colour data and Reliefs on David

[LHS00] LENSCH H., HEIDRICH W., SEIDEL H.: Automated
texture registration and stitching for real world models. In
Proceedings of 8th Pacific Graphics 2000 Conference on
Computer Graphics and Application (Los Alamitos, CA,
2000), IEEE, pp. 317–327.
[LPC∗ 00] LEVOY M., PULLI K., CURLESS B., RUSINKIEWICZ
S., KOLLER D., PEREIRA L., GINZTON M., ANDERSON S., DAVIS
J., GINSBERG J., SHADE J., FULK D.: The digital michelangelo project: 3D scanning of large statues. In Siggraph
2000, Computer Graphics Proceedings (2000), AKELEY
K., (Ed.), Annual Conference Series, ACM Press/ACM
SIGGRAPH/Addison Wesley Longman, pp. 131–144.
[LWG97] LEVENTON M., WELLS W., GRIMSON W.: Multiple
view 2D-3D mutual information registration. In DARPA97
(1997), pp. 625–630.
[Pri00] PRINCE C.: Progressive Meshes for Large Models of
Arbitrary Topology. Master’s thesis, Department of Com-

2187

puter Science and Engineering, University of Washington,
Seattle, August 2000.
[PSS05] PERAL R., SAGASTI D., SILLAUREN S.: Virtual
restoration of cultural heritage through real-time 3D models projection. In VAST 2005 Conference Proceedings
(Pisa, Italy, November 2005), pp. 86–91.
[RL00] RUSINKIEWICZ S., LEVOY M.: QSplat: A multiresolution point rendering system for large meshes. In Computer
Graphics Proceedings, Annual Conference Series (SIGGRAPH 00) (July 24–28, 2000), ACM Press, pp. 343–
352.
[STH∗ 03] STUMPFEL J., TCHOU C., HAWKINS T., DEBEVEC P.,
COHEN J., JONES A., EMERSON B.: Assembling the sculptures of the parthenon. In VAST 2003 (Brighton, UK,
November 5–7, 2003), D. ARNOLD A. C., NICCOLUCCI F.,
(Eds.), Eurographics, pp. 41–50.

c 2008 The Authors
Journal compilation c 2008 The Eurographics Association and Blackwell Publishing Ltd.

