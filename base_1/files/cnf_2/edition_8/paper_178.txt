Pacific Graphics 2008
T. Igarashi, N. Max, and F. Sillion
(Guest Editors)

Volume 27 (2008), Number 7

Reconstructing 3D Shape, Albedo and Illumination from a
Single Face Image
S. F. Wang1 and S. H. Lai1
1 Department

of Computer Science, National Tsing Hua University, Taiwan

Abstract
The morphable model has been employed to efficiently describe 3D face shape and the associated albedo with
a reduced set of basis vectors. The spherical harmonics (SH) model provides a compact basis to well approximate the image appearance of a Lambertian object under different illumination conditions. Recently, the SH and
morphable models have been integrated for 3D face shape reconstruction. However, the reconstructed 3D shape
is either inconsistent with the SH bases or obtained just from landmarks only. In this work, we propose a geometrically consistent algorithm to reconstruct the 3D face shape and the associated albedo from a single face
image iteratively by combining the morphable model and the SH model. The reconstructed 3D face geometry can
uniquely determine the SH bases, therefore the optimal 3D face model can be obtained by minimizing the error
between the input face image and a linear combination of the associated SH bases. In this way, we are able to
preserve the consistency between the 3D geometry and the SH model, thus refining the 3D shape reconstruction
recursively. Furthermore, we present a novel approach to recover the illumination condition from the estimated
weighting vector for the SH bases in a constrained optimization formulation independent of the 3D geometry.
Experimental results show the effectiveness and accuracy of the proposed face reconstruction and illumination
estimation algorithm under different face poses and multiple-light-source illumination conditions.
Categories and Subject Descriptors (according to ACM CCS): I.3.7 [Computer Graphics]: Virtual reality

1. Introduction
Human face modeling from images is a very popular topic
with many applications, such as facial animation, face recognition, model-based facial video communication, etc. Aside
from geometry information, intensity variation of a face image provides very important information for the 3D surface.
However, it is difficult to utilize the photometric information
for 3D face reconstruction under different lighting conditions. The problem is even more complicated to reconstruct
a 3D face model from a single image acquired under unknown lighting condition. In this paper, we propose a robust
3D face model reconstruction algorithm from a single image under unknown light condition. Our algorithm integrates
the geometric and photometric information for the 3D face
model reconstruction based on a prior 3D eigenhead model
as well as the spherical harmonic basis in a consistent way.
In addition, we also present a novel algorithm to estimate
c 2008 The Author(s)
Journal compilation c 2008 The Eurographics Association and Blackwell Publishing Ltd.
Published by Blackwell Publishing, 9600 Garsington Road, Oxford OX4 2DQ, UK and
350 Main Street, Malden, MA 02148, USA.

the illumination condition simply from the estimated coefficients of the spherical harmonic bases.
1.1. Related works
A robust representation of a human face image is very crucial in various fields in computer vision. It should be able to
represent face images for a person under different lighting
conditions. For the 2D case, the synthesis of photo-realistic
human face images under different lighting conditions has
been proposed in the past. There are also several previous
works proposed for face recognition under different illumination conditions. The idea of modeling 3D faces and the
associated textures are applied to model the variations of a
human face, which can help to generate more realistic synthesis results.
Model-based statistical techniques have been widely used
for robust human face modeling. Most of the previous 3D

1730

S.F. Wang & S.H. Lai / Robust 3D Face Reconstruction

face reconstruction techniques require more than one face
image to achieve satisfactory 3D human face modeling. Although there are several different approaches for 3D reconstruction from a single image, such as shape from focus and
shape from texture, these approaches are not well suited for
3D face reconstruction due to very limited texture information in the human face images. Another approach for 3D
face reconstruction from a single image is to simplify the
problem by using a statistical head model as the prior. For
example, Atick et al. [AGR96] combined the shape from
shading constraint with the prior eigenhead model to reconstruct a 3D face model by minimizing the corresponding energy function. Recently, Blanz and Vetter [BV99] proposed
an algorithm for 3D face model reconstruction by minimizing an energy function of discrepancies between the face
image and the corresponding image rendered from a morphable 3D head model under a suitable illumination condition. Later, this technique was successfully applied to face
recognition [BV03] and achieved a high recognition rate under the assumption of known lighting direction. However,
these methods are quite computationally expensive since not
only the 3D head model but also the illumination conditions
are involved in the energy minimization problem.
In practice, the lighting direction is difficult to estimate
from an image, especially for multiple light sources. Fortunately, the images of a fixed-pose Lambertian object under
variable lighting can be described by a three-dimensional
linear subspace when shadow is not considered [Hal94,
ZY99]. The previous works [Hal94, AMU97, BK98, Sha99,
ZY99] also shows that the computation of full illumination
field is not necessary, because it can be represented by a lowdimensional subspace. Recently, spherical harmonics (SH)
was proposed [RH01a, RH01b, BJ03] to describe the intensity variations of a surface under different illuminations. It
has been shown that the intensity images of a Lambertian
surface under a wide variety of illumination conditions can
be well approximated by only nine SH basis functions. Furthermore, Ramamoorthi proposed a method [Ram02] to determin a linear subspace with dimension less than nine for
representing images of a Lambertian object under different
lighting conditions based on spherical harmonics.
More recently, Lee et al. [LHK05] built a subspace of
all possible face images of a 3D face under different lighting conditions from several real images by using spherical
harmonics and achieved high face recognition rate based
on this subspace. In addition, Zhang et al. [ZWS04] proposed to combine the Morphable model and SH basis to resolve the problem of pose and illumination variations for
face recognition. Later, they extended this work to build
SHBMM [ZWS05, ZS06], which was used to synthesize delit or re-lit face images, and also achieve a high recognition
rate. Note that, in their work [ZWS05, ZS06], the facial geometrical shape model and the appearance image model were
trained separately. Therefore, the spherical harmonic bases
are not computed from the associated 3D face shape model

but from the training image samples instead. This may break
the relationship between 3D face geometry and the spherical harmonics, thus the consistency between the 3D shape
model and the associated spherical harmonics is not preserved. In this paper, we propose a different way to combine
the morphable model and spherical harmonics to preserve
their consistency for 3D face reconstruction from a single
image.
1.2. Contribution
In this paper, we propose a novel algorithm for reconstructing the 3D face model from a single image based on using
a prior 3D eigenhead model and the associated facial texture PCA model learned from a set of 3D face models. In
addition, we employ the spherical harmonic (SH) basis corresponding to the 3D face model to establish the link between the recovered 3D model and the input face image.
Our algorithm recovers a 3D face model and its texture map
from a single image by considering 3D face shape, face texture map, and the associated image appearance under general illumination condition altogether. Furthermore, we also
present a novel method to estimate the directions of multiple
light sources from the estimated coefficients of the spherical harmonic bases. The main contributions of this paper are
listed as follows:
1. We integrate 3D statistical head model and SH bases in
a consistent way to describe geometric and photometric
variations under unknown arbitrary illumination conditions.
2. We incorporate the face geometry, silhouette and illumination information into the problem of 3D shape and appearance reconstruction from a single image so that it is
well constrained.
3. We propose a novel optimization approach to determining multiple light sources from the estimated SH weighting vector without knowing the original 3D structure.
2. Morphable Model and Spherical Harmonics
Illumination
In this section, we will first briefly describe the morphable
model used for 3D face model reconstruction from a single face image. On the other hand, spherical harmonic bases
[BJ03] have been used to approximate the face images of
a 3D face model under different illumination conditions.
The morphable model and spherical harmonic bases are employed in our algorithm to approximate a 3D face model with
a small number of parameters and the corresponding face
images under different lighting conditions, respectively.
2.1. Morphable Model
Morphable model provides the prior knowledge of neutral
3D face geometry as well as the texture. Similar to [BV99],
the geometry of a face model can be represented as S =
(x1 , y1 , z1 · · · , xN , yN , zN ) ∈ 3N and the appearance can be
c 2008 The Author(s)
Journal compilation c 2008 The Eurographics Association and Blackwell Publishing Ltd.

1731

S.F. Wang & S.H. Lai / Robust 3D Face Reconstruction

(b)

(a)

Figure 1: (a) Nine hemispheres represent the lighting fields of SH basis. The red and green colors represent positive and
negative values, respectively, in spherical harmonics. (b) The nine 3D faces represent the corresponding illuminations after
intensity normalization.
represented as a vector T = (r1 , g1 , b1 · · · , rN , gN , bN ) ∈ 3N
, where N is the total number of vertices in a 3D model.
Therefore, the geometry and texture of a 3D face model can
be approximated by a mean and a linear combination of several eigenhead basis vectors:
m

S(α) = S + ∑ αi si
i=1
m

By concatenating the nine spherical harmonic bases for all
the N 3D points into the matrix B(λ, n) ∈ N×9 , we can
approximate the image of a 3D model under arbitrary illumination conditions with a linear combination of the bases
as Imodel = Bw, where w ∈ 9 is a 9-dimensional weighting
vector. An example of the first nine spherical harmonic bases
for a 3D head model is shown in Fig. 1.

(1)

T (β) = T + ∑ βi ti

3. Three-Dimensional Face Reconstruction

i=1

where S and T are the mean shape and texture vector, si and ti
are the i-th eigen-shape basis and the i-th eigen-texture basis
of the morphable model, respectively, and α = [α1 , · · · , αm ]
and β = [β1 , · · · , βm ] contain the shape and texture coefficients, respectively, to represent the 3D head model.

In this section, the main algorithm to reconstruct a 3D face
model from a single image under unknown light condition
will be described in details. The first step is to initialize all
the parameters, includes pose, shape, texture, and illumination coefficients, and the second step iteratively refines all
the parameters.

2.2. Spherical Harmonic Bases
Spherical harmonic bases [BJ03] have been used to approximate the images of a 3D model under a wide variety of lighting conditions. These bases could be determined by the surface normal n and the albedo λ. In this case, the albedo λ can
be approximated by the texture part of the morphable model
T (β) in Eq. (1). It is easier to describe the basis if we write it
as a function of x, y, z instead of the angle of spherical coordinates. Let (nx , ny , nz ) denote the unit normal vector at the
corresponding 3D point, λ denote the vector containing the
albedos of the object and the operator .* denote the elementwise product. With the notation used in [ZWS05], the first
nine spherical harmonic bases for the image intensity at a
3D point are given bellow:
3
√λ , be11 =
4π λ. ∗ nx ,
4π
3
3
λ. ∗ nz ,
λ. ∗ ny , be10 = 4π
= 4π
o
5
5
λ. ∗ ny nz ,
= 3 12π λ. ∗ ny nz , b22 = 3 12π
e
5
3
5
= 3 12π λ. ∗ nx nz , b22 = 2 12π λ. ∗ (nx nx − ny ny )
3
λ. ∗ (2nz nz − nx nx − ny ny )
= 12 4π

b00 =
bo11
bo21
be21
b20

(2)
c 2008 The Author(s)
Journal compilation c 2008 The Eurographics Association and Blackwell Publishing Ltd.

3.1. Initialization
For the initialization of 3D model, we first manually select
19 feature points and then estimate the shape parameters by
minimizing the geometric distance of the landmark features.
The minimization problem is given by:
n

∑
f ,R,t,α
min

u j − (P f Rxˆ j (α) + t)

(3)

j=1

where u j denotes the coordinate of the j-th feature point in
2D image, P is an orthographic projection matrix, f is the
scaling factor, R denotes the 3D rotation matrix, t is the
translation vector, and xˆ j (α) denotes the j-th reconstructed
3D feature point that is determined by the shape parameter
vector α as follows
m

j

xˆ j = x j + ∑ αl sl

(4)

l=1

According to different reflection properties between face
feature area and skin area, we defined these two areas for
more accurate texture and lighting estimation. The face feature area Ω f and skin area Ωs are shown in Fig. 2. Since face
skin is sensitive to lighting variations, the coefficients of the

1732

S.F. Wang & S.H. Lai / Robust 3D Face Reconstruction

Levenberg Marquardt (LM) optimization algorithm [Lev44]
to accomplish the process. The following gives the procedure of the optimization process:
1. Estimate the texture coefficients β with the other parameters f , R,t, α, and w fixed with their current estimated values. This is accomplished by minimizing the re-projected
intensity error in the face feature area Ω f , which can be
written as follows:

Figure 2: The blue points denote the vertices of the model.
The left picture shows the face feature area Ω f , and the right
one shows the face skin area Ωs .
SH bases are estimated by minimizing the image intensity
errors in the skin area. On the other hand, the estimation of
the texture (λ) parameters is based on minimizing the intensity errors in the face feature area, which contains most
texture variations in the face.
The face appearance under different lighting conditions
can be approximated by the weighted sum of SH bases given
in the following equation
I≈

9

9

i=1

i=1

∑ bi wi = λ ∑ b˜ i wi

(5)

T

soluction w1 = 4πTT I . We fix the estimated value for w1 and
T T
then estimate the texture parameter vector β and w2 , ..., w9
by solving the following energy minimizing problem with
the pixels selected in the skin area Ωs .
9

n

∑

β,w2 ...w9 i=1

Ii −

∑ (w j bij )

∑

β i∈Ω
f

i
i
Iinput
− Imodel
(β) f ,R,t,α,w

(6)

j=1

m

˜
Recall that b = λb˜ = T (β)b˜ = (T¯ + ∑ βi ti ) · b.
i=1

3.2. Iterative Refinement
From the previous section, we can obtain the initialized parameter values for f , R,t, λ, β, and w corresponding to the
face pose, shape, texture and illumination condition. From
these initialized parameters, we can iteratively refine them to
converge to the optimal 3D face shape and face texture by integrating the geometrical and photometrical information altogether in the energy minimization framework. We apply

(7)

i
where Iinput
denote the i-th pixel value of the source face
i
image, and Imodel
is the synthesized face image with the
given parameter setting at the corresponding i-th pixel location.
2. Estimate the pose ( f , R,t) and shape parameters α given
the texture and illumination coefficients by minimizing a
cost function containing the re-projected intensity error
and the geometry distance including features and silhouette [WL06] altogether. The integrated cost function is
formulated as follows.

arg min (εEI + (1 − ε)(E f p + Ec ))

where I denotes the pixel intensity value of a 3D vertex under a lighting weight vector w, bi is the i-th SH basis with
bi = λb˜ i and b˜ is formed by putting the nine SH bases of
each vertex without λ as a row in it. However, the ambiguity between w and λ will lead to inaccurate estimation of the
texture parameter in λ. To resolve this problem, we estimate
the texture parameters based on the following scheme. Since
the coefficient w1 to the first SH basis is the scale of albedo,
which can be considered as the intensity of a vertex under
ambient light with different lighting magnitude. We employ
the mean texture λ (i.e. T in Eq. (1)) and estimate w1 by findλ
w1 = I, which leads to the
ing the least-square solution of 4π

min

arg min

f ,R,t,α

(8)

where
EI =

∑

i
i
Iinput
− Imodel
(β, w) f ,R,t,α

i∈Ωs

Ef p =

∑

uiinput − uimodel ( f R(S¯i +

m

∑ α j sij ) + t)

j=1

i∈ f p
th
Ec = Kq∈C
( min q − p )
I
p∈C p j

(9)
Note that EI denotes the error function of intensity in the
skin area Ωs , E f p denotes the 2D distance between image feature points and re-projected points, and Ec a modified one-way Hausdorff distance obtained from the K-th
largest value of the minimum distance between the extracted face contour point set CI in the image and the reprojected face contour curve C p j from the 3D model. We
use a fractional value f to determine an appropriate value
K to be K = f |CI | and f = 0.9 in our implementation.
3. Update the lighting weight vector w with the leastsquares solution for the linear system in Eq. (5) with the
equations selected in the skin area Ωs and increase ε by
0.1 if ε ≤ 1. Note that the SH bases are computed from
the current estimation for the parameters f , R,t, α, and β.
4. Repeat step (1) to step (3) until the difference of the error
energy function values or the differences of the parameter values between two consecutive iterations are smaller
than pre-defined thresholds.
Note that ε in step 2 is initialized as 0.5 and incremented
by 0.1 in each iteration to gradually increase weighting on
the reconstructed appearance.
c 2008 The Author(s)
Journal compilation c 2008 The Eurographics Association and Blackwell Publishing Ltd.

1733

S.F. Wang & S.H. Lai / Robust 3D Face Reconstruction

4. Illumination estimation
Since the SH bases can well approximate the lighting conditions, including multiple light sources, of a Lambertian object, the coefficients of the SH bases for an image are directly
related to the corresponding light sources, which are surface
independent. To obtain more light source information in advance, we propose to estimate the intensities and directions
of light sources from the estimated lighting weight vector w
only. Combining this illumination estimation technique with
the above 3D face model and albedo reconstruction algorithm, we are able to reconstruct the 3D shape, albedo, and
illumination from a single face image.
4.1. Lambertian Model
Lambertian law states that the material reflects light uniformly in all directions, which means the apparent brightness of a surface to an observer is the same regardless of
the viewing direction. Lambertian reflectance is often used
as a model of diffusion reflection, and it can be calculated
by taking the dot product of surface normal and light source
direction. In computer graphics, the intensity of diffusely reflected light can be written by
I = max(0, < λn, >)

(10)

where I is the intensity, λ is the albedo, n and denote the
normalized normal direction and light source direction, respectively.
According to [BJ03], the kernel of spherical harmonics
acts as a low-pass filter with accumulated 99.22% approximation of the energy in the first nine components. Therefore,
the high-frequency components of the illumination (e.g. critical points in [ZY00, ZY01]) have little effect, which is the
limitation of the approximation with the spherical harmonics bases. Therefore, the estimations of light source direction and magnitude are important for recovering the highfrequency components.
4.2. Light Sources Estimation
With the nonnegativity of light, the linear relation in Eq. (10)
is valid only when all the normal vectors are active (i.e. the
dot product of n and is positive). Therefore, a 3D object
with N vertices, the intensity of the i-th vertex illuminated
under m multiple light sources can be formulated as the summation of the lighting with an active parameter δi j , i.e.
Ii = ∑mj=1 δi j (ni · j ), i = 1, ..., N
1, i f ni · l j ≥ 0
δi j =
0,
elsewise

(11)

With known SH weighting vector w, we can estimate the
possible lighting energy by using a pre-built hemisphere.
Since the hemisphere covers all possible normal directions,
the information of original 3D surface is no more important here. We assumed that the possible light source directions are on this hemisphere, and therefore an area Aact exists where vertices on it are fully exposed from all light
c 2008 The Author(s)
Journal compilation c 2008 The Eurographics Association and Blackwell Publishing Ltd.

Aact

(a)

(b)

Figure 3: (a)All possible directions of light sources can be
covered by a hemisphere, and so as all possible normal directions of visible surface. (b) The image of intensity on a
hemisphere shown in left top is lighted by three different
light sources (right top). The active area Aact is shown in the
bottom row with vertices on it fully exposed from all light
sources.
sources(see Fig. 3). The additivity of illumination naturally leads to the additivity of w, and also the additivity of
light source vectors i . The summed lighting vector Σ =
∑mj=1 j = [ x , y , z ]T ∈ 3×1 can be first estimated by solving the following linear equation.
BAact · w = IAact = NAact

Σ

(12)

where NAact = [n1 , n2 , n3 ]T ∈ 3×3 are normal vectors randomly selected on Aact , and the corresponding bases of
spherical harmonics can be obtained by using Eq. (2) which
is formed as BAact = [b1 , b2 , b3 ]T ∈ 3×9 . In order to decompose the summed lighting vector Σ , we formulate this problem as a constrained optimization problem which minimizes
the 2-norm of the illumination error on the hemisphere, i.e.
minimize
subject to

Iall − ∑mj=1 δ j . ∗ (Nall · j )
∑mj=1

j

=

(13)

Σ

where all the normal vectors uniformly distributed on the
hemisphere cover all possible normal directions and they can
be represented by Nall = [n1 , n2 , ..., nN ]T ∈ N×3 , and the
corresponding active parameters under j-th light source can
be represented as a vector δ j = [δ1 j , δ2 j , ..., δN j ]T ∈ N×1 .
In our implementation, we employ the sequential quadratic
programming method, which solves a quadratic programming subproblem at each iteration, to find the best light
source condition from the SH coefficients w. The magnitude
of each light source can be obtained by calculating the norm
of each light vector, i.e. j
5. Experimental Results
In this section, we show some experimental results of applying the proposed 3D face model reconstruction algorithm
to demonstrate its performance. The experiments were all
conducted on a P4 2.8G PC with 1024MB RAM and the
proposed method was implemented in C++ Language with
OpenGL for displaying. In our unoptimized implementation,

1734

S.F. Wang & S.H. Lai / Robust 3D Face Reconstruction

Input
Image

Output
3D Face
Models

(a) 15 individuals under 15 illuminations

(b) 12 individuals under 12 illuminations

Figure 4: The upper row are 15 synthesized individuals under 15 different illuminations generated from FaceGen [Sin], and 12
individuals under 12 different light conditions from CMU-PIE [SBB03]. The second row shows the corresponding reconstructed
3D faces with the coreesponding albedos.
Table 1: The standard deviations of the first 15 eigen shape
coefficients α.
σ1
51.8
σ9
22.6

σ2
36.1
σ10
21.7

σ3
30.8
σ11
20.8

σ4
28.6
σ12
20.4

σ5
25.8
σ13
19.5

σ6
24.8
σ14
18.7

σ7
23.9
σ15
18.3

σ8
22.8
-

Table 2: Average mean and standard deviation of pairwise
distances for synthesized and real images.
average
Initial
Refined

Synthesized (225)
mean
std
104.6
75
98.4
68.1

Real Images (144)
mean
std
105.4
63.5
95.7
56.7

the reconstruction process of eah 3D face takes about 2 minutes.
5.1. Robustness and Accuracy
For 3D head reconstruction, three issues are investigated to
demonstrate the robustness of our iterative face reconstruction algorithm. The first two experiments demonstrate the
convergence of the estimated shape under different illumination conditions and different poses. The third experiment
shows the accuracy of the reconstructed shape coefficients

by using synthesized images with known shape coefficients.
In the following experiments, we use the first 15 shape coefficients α to reconstruct the 3D faces and the corresponding
standard deviations are shown in Table 1.
5.1.1. Convergence under different illuminations
In this experiment, totally 369 face images are used to measure the reconstruction accuracy, including 15 synthesized
images generated by FaceGen software [Sin] under 15 different illuminations and 12 real images from CMU-PIE
database under 12 different lighting conditions. All the testing images are shown in Fig. 4, and it also shows the reconstructed 3D faces under different poses and illumination
conditions. We compute the pairwise-distances di ( j, k) between the shape parameter vectors α computed from different face images under different illumination conditions ( j
and k ) for the i-th individual.
j

di ( j, k) = αi − αki

(14)

Table 2 summarizes the average mean and standard deviation of these pairwise Euclidean distances between the estimated shape parameters α before and after the refinement
step of our algorithm. Obviously, the average distance between each α vector after the refinement step is smaller than
that without refinement, and similarly the average standard
deviation is also smaller after the refinement. This shows the
c 2008 The Author(s)
Journal compilation c 2008 The Eurographics Association and Blackwell Publishing Ltd.

S.F. Wang & S.H. Lai / Robust 3D Face Reconstruction

Figure 5: The first row is the testing images generated from
FaceGen [Sin] with different poses. The second row shows
the images rendered from the reconstructed 3D face model
by using the proposed algorithm.
Table 3: Error measurement of estimated and ground truth
shape parameters.
αest − αtrue
Initial
Refined

Syn #1
121.677
120.584

Syn #2
141.007
93.075

Syn #3
411.219
80.884

Syn #4
181.511
91.605

convergence property of our proposed method under various
illumination conditions.
5.1.2. Convergence under different Poses
We reconstruct the 3D face models from the synthesized images to demonstrate that our method is also robust to various poses. The testing images and reconstructed face models
are shown in Fig. 5. Similarly, the pairwise-distances di ( j, k)
between the shape parameter vectors α computed from different face images with different poses (p j and pk ) for the
i-th individual can also be defined as Eq. (14). The average
d( j, k) and standard deviation std(d( j, k)) of the pairwise
distances for recovered shape parameters α’s from images at
different poses also decrease from (avg: 156.16, std: 53.87)
to (avg: 83.47, std: 20.62) after the iterative refinement. This
experiment demonstrates the convergence of the proposed
method against pose variations.
5.1.3. The accuracy of estimated shape coefficients
Although the previous experiments demonstrate the convergence of our algorithm, the correctness of convergence direction is still unjustified. In this experiment, we attempt to
show the accuracy of final estimated coefficients. Four synthesized 3D face models shown in the first row of Fig. 6 are
generated from our system with known shape coefficients
and the second row shows the rendered images for the reconstructed 3D face models under the same lighting condition.
In the initial step, the geometry of 3D face is obtained only
from several feature points without taking the appearance
or illumination into account, which is similar to the scheme
used in [ZWS05, ZS06]. For comparison, the distances between the estimated shape coefficients and ground truths are
given in Table 3 and the distances are decreased significantly
after the refinement step except the first test image. It is because the initialized solution for the shape parameter is quite
c 2008 The Author(s)
Journal compilation c 2008 The Eurographics Association and Blackwell Publishing Ltd.

1735

Figure 6: The first row shows the synthesized images with
known shape coefficients. The second row shows the images
rendered from the reconstructed face models under the same
lighting.
close to the true solution for this particular example, thus the
refinement process does not improve too much in this case.
Our algorithm can perform well even the initial solution is
far from the true solution, e.g. the case Syn #3. These experiments demonstrate that the proposed method converges
well to the true solution and reconstructs the 3D face models
robustly.
5.2. Illumination Estimation
The experiments were conducted on several real images
from the CMU-PIE database. We reconstruct the 3D face
model from a single image by using the proposed algorithm
described in section 3. Therefore, the information of shape,
albedo, and the lighting weight vector w of spherical harmonic bases can be obtained during the reconstruction process. As shown in Fig. 7, the 3D face models are estimated
from a single image (first column) with different poses under different illumination conditions. Regardless of the original 3D geometry, we built the light field on a hemisphere to
cover all possible normal directions by using the estimated w
(second column). The directions and magnitudes of multiple
light sources (third column) can be estimated by using the
proposed method described in section 4. In this experiment,
we set the number of light sources m = 4 and Aact is simply
selected as a small region at the center of the hemisphere.
The information of illumination can be used to synthesize
images under more realistic illumination condition from the
estimated light sources (fourth column).
6. Conclusion
In this paper, we presented a robust algorithm to reconstruct
3D face model and its texture from a single 2D face image
under arbitrary head pose and illumination condition. We integrate the morphable face model and spherical harmonics to
describe the geometric and photometric variations for human
faces with low-dimensional subspaces. During the reconstruction process, the consistency between the 3D shape and
the spherical harmonics is preserved and the experimental
results also demonstrate the convergence and robustness of
our algorithm. In addition, we also proposed a novel method

1736

S.F. Wang & S.H. Lai / Robust 3D Face Reconstruction

[LHK05] L EE K. C., H O J., K RIEGMAN D.: Acquiring
linear subspaces for face recognition under variable lighting. PAMI 27, 5 (2005), 684–698.
[Ram02] R AMAMOORTHI R.: Analytic pca construction
for theoretical analysis of lighting variability in images of
a lambertian object. PAMI 24, 10 (2002), 1–12.
[RH01a] R AMAMOORTHI R., H ANRAHAN P.: An efficient representation for irradiance environment maps.
SIGGRAPH (2001).
[RH01b] R AMAMOORTHI R., H ANRAHAN P.: A signalprocessing framework for inverse rendering. SIGGRAPH
(2001), 117–228.

Figure 7: Application of the modeling of 3D faces to synthesize images under more realistic illumination condition
from the estimated light sources. First column: original input
images. Second column: the estimated spherical harmonic
lighting field. Third column: the estimated light source directions and the normalized weight of each light source. Fourth
column: reconstructed 3D faces under the illumination of the
estimated light sources in a frontal view.
to estimated the illumination condition, including multiple
light directions and their magnitudes, from the estimated
spherical harmonics coefficients without knowning the object geometry.
References
[AGR96] ATICK J., G RIFFIN P., R EDLICH A.: Statistical
approach to shape from shading: reconstruction of 3d face
surfaces from single 2d images. Computation in Neurological Systems 7, 1 (1996).
[AMU97] A DINI Y., M OSES Y., U LLMAN S.: Face
recognition: The problem of compensating for changes in
illumination direction. PAMI 19, 7 (1997), 721–732.

[SBB03] S IM T., BAKER S., B SAT M.: The cmu pose, illumination, and expression database. PAMI (2003), 1615–
1618.
[Sha99] S HASHUA A.: On photometric issues in 3d visual
recognition from a single 2d image. IJCV (1999), 99–
122.
[Sin]

S INGULAR: http://www.facegen.com/modeller.htm.

[WL06] WANG S., L AI S.: Efficient 3d face reconstruction from a single 2d image by combining statistical and
geometrical information. ACCV (2006), 427–436.
[ZS06] Z HANG L., S AMARAS D.: Face recognition from
a single training image under arbitrary unknown lighting
using spherical harmonics. PAMI 28, 3 (2006), 351–363.
[ZWS04] Z HANG L., WANG S., S AMARAS D.: Pose invariant face recognition under arbitrary unknown lighting using spherical harmonics. Biometric Authentication
Workshop (2004).
[ZWS05] Z HANG L., WANG S., S AMARAS D.: Face synthesis and recognition from a single image under arbitrary
unknown lighting using a spherical harmonic basis morphable model. CVPR 2 (2005), 209–216.

[BJ03] BASRI R., JACOBS D.: Lambertian reflectance and
linear subspaces. PAMI 25, 2 (2003), 218–233.

[ZY99] Z HAO L., YANG Y.: Theoretical analysis of illumination in pca-based vision systems. Pattern Recognition 32, 4 (1999), 547–564.

[BK98] B ELHUMEUR P., K RIEGMAN D.: What is the set
of images of an object under all possible illumination conditions? IJCV 28, 3 (1998), 245–260.

[ZY00] Z HANG Y., YANG Y.: Illuminant direction determination for multiple light sources. CVPR 1 (2000),
269–276.

[BV99] B LANZ V., V ETTER T.: A morphable model for
the synthesis of 3d-faces. SIGGRAPH (1999).

[ZY01] Z HANG Y., YANG Y.: Multiple illuminant direction detection with application to image synthesis. PAMI
23, 8 (2001), 915–920.

[BV03] B LANZ V., V ETTER T.: Face recognition based
on fitting a 3d morphable model. In Quarterly of Applied
Mathematics 25, 9 (2003), 1063–1074.
[Hal94] H ALLINAN P.: A low-dimensional representation
of human faces for arbitrary lighting conditions. CVPR
(1994), 995–999.
[Lev44] L EVENBERG K.: A method for the solution of
certain non-linear problems in least squares. In Quarterly
of Applied Mathematics 2, 2 (1944), 164–168.

c 2008 The Author(s)
Journal compilation c 2008 The Eurographics Association and Blackwell Publishing Ltd.

