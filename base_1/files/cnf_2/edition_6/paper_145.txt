DOI: 10.1111/j.1467-8659.2010.01743.x
Eurographics Symposium on Rendering 2010
Jason Lawrence and Marc Stamminger
(Guest Editors)

Volume 29 (2010), Number 4

Interactive Editing of Lighting and Materials
using a Bivariate BRDF Representation
Pitchaya Sitthi-Amorn1

Fabiano Romeiro2

1 University

of Virginia

Todd Zickler2

2 Harvard

Jason Lawrence1

University

Abstract
We present a new Precomputed Radiance Transfer (PRT) algorithm based on a two dimensional representation of
isotropic BRDFs. Our approach involves precomputing matrices that allow quickly mapping environment lighting,
which is represented in the global coordinate system, and the surface BRDFs, which are represented in a bivariate
domain, to the local hemisphere at a surface location where the reflection integral is evaluated. When the lighting
and BRDFs are represented in a wavelet basis, these rotation matrices are sparse and can be efficiently stored and
combined with pre-computed visibility at run-time. Compared to prior techniques that also precompute wavelet
rotation matrices, our method allows full control over the lighting and materials due to the way the BRDF is
represented. Furthermore, this bivariate parameterization preserves sharp specular peaks and grazing effects that
are attenuated in conventional parameterizations. We demonstrate a prototype rendering system that achieves
real-time framerates while lighting and materials are edited.
Categories and Subject Descriptors (according to ACM CCS): I.3.7 [Computer Graphics]: Three-Dimensional
Graphics and Realism

1. Introduction
Specifying the materials and lighting in a virtual scene is a
key step in the design process, and this task is easier if the
designer can see the effect of their edits at interactive rates.
However, achieving this type of interactive control while
supporting a wide range of materials is a challenge due to the
multi-dimensionality of the bidirectional reflectance distribution function (BRDF), and the high computational cost of
evaluating the reflection integral at each pixel in each frame.
To address this problem, there have been many techniques
developed for interactive and real-time rendering of static
scenes under distant-environment lighting. These methods
decouple the task into an off-line pre-computation phase and
an on-line rendering phase, and they variously trade: on-line
rendering time; accuracy; generality of materials; on-line editability; pre-computation time; and storage cost.
We present a method that prioritizes editability, generality and accuracy. In particular, it enables interactive editing
of both lighting and isotropic materials, and it does so without restricting the BRDFs to a particular analytic form. This
provides advantages over existing approaches, which place
tighter restrictions on the space of allowed materials, or prioritize the editing of either lighting or reflectance.
A key to our approach is the use of a bivariate representation of isotropic BRDFs. Although an isotropic BRDF is
c 2010 The Author(s)
Journal compilation c 2010 The Eurographics Association and Blackwell Publishing Ltd.
Published by Blackwell Publishing, 9600 Garsington Road, Oxford OX4 2DQ, UK and
350 Main Street, Malden, MA 02148, USA.

defined over a three-dimensional domain, recent work has
shown that these functions can be “projected” onto a properly chosen 2D domain without significantly reducing fidelity [SAS05, RVZ08]. We show that by representing reflectance as a tabulated function on such a 2D domain,
one can achieve interactivity without restricting the BRDF
to be a combination of 1D radially-symmetric functions
[GKD07, KM00, SZC∗ 07] or of some other analytic form.
We achieve full control over lighting, viewpoint, and
BRDFs at interactive framerates by incorporating this material model into a wavelet-based pre-computation scheme that
is motivated by previous studies [NRH03, NRH04, SM06,
WNLH06]. Our approach is to precompute two sets of matrices. The first is that of Wang et al. [WNLH06], and consists
of one matrix per surface normal to allow mapping the global
lighting sphere to the local hemisphere at any pixel. The second set consists of one matrix per view direction and allows
an analogous mapping from the bivariate BRDF domain. By
computing and applying these matrices in the wavelet domain, the reflection integral over each local hemisphere is
computed efficiently as a “triple product” [NRH04] between
the lighting, BRDF and local visibility function.
An important benefit of our approach over prior work is
that the bulk of the required precomputation—computing the
two matrix sets—is only done once and does not need to

1461

1462

Sitthi-Amorn et al. / Interactive Editing of Lighting and Materials

be repeated for each scene. Moreover, besides the restriction to isotropic materials that exhibit half-vector symmetry [RVZ08], it does not limit the space of materials that can
be navigated at run-time. It is able to capture specular peaks
and grazing angle effects with high accuracy, and it allows
flexible, “non- parametric” material editing while simultaneously varying viewpoint and scene lighting.
2. Related Work
As mentioned above, a number of techniques have been proposed to give some level of interactive control over lighting
and materials in a virtual scene, and these differ in priorities.
Kˇrivánek and Colbert [KC08] enable complete online editability, including viewpoint, geometry, lighting, and materials; and they do so without pre-computation. This efficiency comes with reduced accuracy and generality of materials, because BRDFs are restricted to analytic forms that
can be sampled efficiently, and visibility is approximated.
Pre-filtering approaches [Gre86, KM00, GKD07] achieve
high on-line framerates by representing isotropic BRDFs as
weighted sums of 1D (“radially-symmetric”) functions that
can be convolved with the lighting sphere offline. Two recent
examples are [GKD07], which couples this with approximate visibility to render glossy surfaces at rates up to 1kHz,
and [SZC∗ 07], which integrates this into an interactive system that simulates a degree of indirect illumination.
The efficiency of pre-filtering approaches comes at the
expense of accuracy and editability. The limited accuracy
stems from the fact that radially-symmetric functions are
not flexible enough to capture arbitrary specular highlights
and common grazing angle effects (see [NDM05, SAS05]).
The limited editability stems from the need to pre-convolve
each lighting sphere against each radially-symmetric function, which means that online lighting and material changes
are restricted to being combinations of pre-selected sets.
Other methods enable a broader range of material edits
while maintaining interactivity. Ben-Artzi et al. [BAOR06,
BAERD08] demonstrate systems that allow editing BRDFs
in real-time under complex lighting at a fixed viewpoint,
both with and without indirect lighting. These systems do
not allow runtime changes to lighting or viewpoint.
Cheslack-Postava et al. [CPWAP08] present a method
with similar goals to this paper (i.e., joint editing of lighting,
viewpoint and materials) that operates very differently. Their
method merges light-cuts and visibility-cuts, and it has the
advantage of simulating indirect illumination in exchange
for additional geometry-dependent pre-computation. However, the approach does not consider the distribution of energy in the BRDF domain during refinement of the lighting,
and this can lead to inaccuracies for glossy materials.
The class of methods that is most related to ours algorithmically consists of techniques that employ wavelet-based
representations to allow real-time changes in viewpoint and
lighting [NRH03, NRH04, SM06, WNLH06]. A key limitation of these existing approaches is that they require a significant pre-computation step for each BRDF that is to be

θh

n

l h v

θd

Figure 1: A bivariate BRDF. Assuming the BRDF is unchanged by rotations of the input and output about the surface normal and halfway vector leads to a bivariate domain
defined by two angles, (θh , θd ). Right: The gold metallic
paint BRDF from the MERL/MIT database depicted as an
RGB image over this domain.
accessible at runtime, and this limits material edits to selecting from among a pre-chosen set [WNLH06].
In this paper, we demonstrate a wavelet-based system that
supports a broad range of materials, while still enabling edits to viewpoint and lighting. We do so by employing a bivariate reflectance model, discretizing the spheres of view
and normal directions, and pre-computing appropriate sets
of matrices that can be combined with visibility at runtime.
3. A Relighting Algorithm Using a 2D BRDF
It has recently been shown that many analytic and measured isotropic BRDFs can be projected from their three dimensional domain onto an appropriate two dimensional domain without significant image effects [RVZ08]. This is interpreted geometrically by first reparameterizing the BRDF
in terms of the halfway vector (bisector of the input and output directions) and the difference vector (input direction expressed with respect to the halfway vector) [Rus98]. Then,
as illustrated in Figure 1, in addition to ignoring the dependence on φh —which follows from the isotropy—we also ignore the dependence on φd . In this way, we lose a degree of
freedom that corresponds to rotating the input and output directions around the halfway vector, and the result is a 2D representation† that can be visualized as in the right of Figure 1.
Specular peaks appear at low θh values (left edge), grazing
effects appear at large θd values (bottom-left corner), and
retro-reflection appears at small θd values (top edge).
Invariance to changes in φd , or “half-vector symmetry”,
can be seen as a generalization of reciprocity and bilateral symmetry, which already imply periodicity conditions
φd → φd + π and φd → π − φd [Rus98,Rom10]. While many
BRDFs do not exhibit half-vector symmetry exactly, there
is evidence to suggest that it can often be enforced without
incurring noticeable rendering artifacts. For example, for all
but a few of the materials in the MERL/MIT BRDF database,
it is hard to distinguish between images rendered using the
† This 2D (θ , θ ) parameterization is homeomorphic to the ασh d
parameterization of Stark et al. [SAS05]. See [RVZ08].

c 2010 The Author(s)
Journal compilation c 2010 The Eurographics Association and Blackwell Publishing Ltd.

1463

Sitthi-Amorn et al. / Interactive Editing of Lighting and Materials
Y
n

X

Rn

Z

ROTATED ENVIRONMENT
n

<

VISIBILITY
θh
n

t

θd

s

Wv
BRDF

<

ENVIRONMENT

,

WARPED BRDF

Figure 2: System overview. The per-normal matrices Rn and per-view matrices Wv convert wavelet coefficients for the lighting
and BRDF, which are defined on the global sphere and the bivariate domain respectively, into corresponding wavelet coefficients
in the local hemisphere, which is parametrized with a hemi-octrahedral map [PH03]. In this common local frame, the final pixel
value is given as the inner product of the BRDF coefficients and the combined lighting and visibility coefficients.

full 3D isotropic domain and those rendered using a bivariate
reduction, even though the reduction typically incurs a significant (≥ 10%) relative RMS BRDF error [RVZ08]. Furthermore, for some of the materials that can be visually distinguished, the differences can be partially attributed to noise
in the original 3D data [RVZ08, Rom10]. We include our
own comparisons in Section 4.
3.1. Rewriting the Reflection Integral
Figure 2 provides an overview of our approach and serves as
a guide for this section. At each pixel, with surface normal
n, local view direction v and scene location p, our goal is to
compute the exitant radiance I given by the weighted integral
of incident lighting L, surface BRDF f , and visibility V :
Z

In,v,p =

Ln (ω) fv (ω)(n · ω)Vp (ω)dω.

this yields
Ln (ω) = ∑ L˜ i ∑ Rn,ki ρk (ω) = ∑
i

k

k

∑ Rn,ki L˜ i

ρk (ω). (2)

i

In other words, the wavelet coefficients of the local lighting
Ln can be computed from the coefficients of the global light˜ This is the same
ing L˜ through the matrix Rn as Ln = Rn L.
observation made by Wang et al. [WNLH06].
Similarly, we express the desired slice of the foreshortened BRDF fv (ω)(n · ω) in terms of a Haar basis over the
local hemisphere {ρk } that is connected to a Haar basis over
the bivariate BRDF domain {ψ j }. This transformation de1
pends on v so we write ψ j (x) = (n·ω)
∑k Wv,k j ρk (ω). This
leads to

(1)

Ω

Here, Ω is the upper hemisphere defined by the normal, Vp
and Ln are the visibility and lighting in this local coordinate
system, fv is a slice of the BRDF obtained by fixing the local view vector to v. In our notation, f (l, v) = fv (ω) with
l = ω, and subscripts of In,v,p denote dependence on surface
normal, local view direction, and position.
We express the local lighting Ln (ω) in terms of an orthonormal Haar wavelet basis {φi } for the global environment map (the sphere of light directions ω parameterized
with an octahedral map [PH03]) by first expressing the
global environment map in terms of this basis: L(ω ) =
∑i L˜ i φi (ω ). Accounting for the change of basis between the
global frame and local frame gives φi (ω ) = ∑k Rn,ki ρk (ω),
where {ρk } is the Haar basis for the local hemisphere, and
c 2010 The Author(s)
Journal compilation c 2010 The Eurographics Association and Blackwell Publishing Ltd.

fv (ω)(n·ω) = ∑ f˜j ∑ Wv,k j ρk (ω) = ∑
j

k

k

∑ Wv,k j f˜j

ρk (ω),

j

(3)
or in terms of wavelet coefficients, fv = Wv f˜, with foreshortening included in vector fv .
Substituting these expressions into the reflection integral
and expressing visibility in terms of a Haar basis as well
yields
In,v,p = ∑ ∑ ∑ Ln,i fv, jVp,kCi jk .
i

j

(4)

k

Here, {Vp,k } are the wavelet coefficients of the visibility,
˜ i , Wv, j = (Wv f˜) j , and
Ln,i = (Rn L)
Z

Ci jk =

ρi (ω)ρ j (ω)ρk (ω)dω
Ω

(5)

1464

Sitthi-Amorn et al. / Interactive Editing of Lighting and Materials

are the tripling coefficients [NRH04], which are fixed and
pre-computable.
Finally, it is advantageous to rewrite the sum in Eq. 4
by factoring out the BRDF coefficients fv and collapsing
the lighting, visibility, and tripling coefficients into reduced
lighting and visibility coefficients denoted (Ln ⊕Vp ) j :
In,v,p = ∑(Ln ⊕Vp ) j fv, j .

(6)

6. On-line (per frame, per pixel): Compute inner product
(Ln ⊕ Vp )T (Wv f˜) for normal and view direction at each
˜ (GPU-pixel shader)
pixel using M most significant (Rn L).
One option we have implemented is approximating full
scene visibility with ambient occlusion [Fer04] similar to
Wang et al. [WNLH06]. This allows replacing steps 5 and
˜ and (Wv f˜).
6 with the inner product of (Rn L)

j

MERL Gold metallic paint

2%

1%

0%
43.88

Ground Truth

64x64

Ground Truth

64x64

Ground Truth

64x64

43.11

32x32

Cook-Torrance

3.2. A Hybrid GPU/CPU Algorithm
Accelerating wavelet-based PRT methods with graphics
hardware is complicated by the memory restrictions of
GPUs and their limited support of sparse matrix arithmetic.
Because of this, prior work has either computed the triple
product in Eq. 4 entirely on the CPU [NRH04] or ignored
visibility and computed the product of lighting and BRDFs
on the CPU before reconstructing the reflection integral at
each vertex at runtime [WNLH06]. We seize on the recent
ability to perform more general-purpose GPU computations
using NVIDIA’s CUDA framework. However, we still encounter memory limitations that require the CPU for some
operations.
˜ and (Wv f˜) are sparse, we do not
Although vectors (Rn L)
know ahead of time which elements will be significant. To
address this, we first compute all coefficients over the set of
normal and view directions, and then for each normal we
˜ and compute the reduced lighting
sort the coefficients (Rn L)
and visibility coefficients (Eq. 7) only at the largest M val˜ At each pixel during runtime, we compute an
ues of (Rn L).
inner product (Eq. 6) to produce the final value. Although
computing (Ln ⊕ Vp ) is parallel, we cannot store the entire
set of visibility coefficients on the GPU and compute them
on the CPU instead. We also observe that it is more efficient
˜ on the CPU.
to sort the coefficients (Rn L)
In summary, our relighting algorithm is:
1. Pre-process (only once): Compute matrices Rn , Wv over a
predetermined set of normal and view directions. (CPU)
2. Pre-process (per scene): Compute visibility maps and
their wavelet coefficients at each mesh vertex. (GPU)
3. On-line (per frame, worst case): Compute wavelet coefficients f˜ and products (Wv f˜) over the set of view directions. (GPU-CUDA)
4. On-line (per frame, worst case): Compute wavelet coeffi˜ over the set of normal direccients L˜ and products (Rn L)
˜ (CPU)
tions. (GPU-CUDA). Sort coefficients (Rn L).
5. On-line (per frame, per vertex, worst case): Compute reduced lighting and visibility coefficients (Eq. 7) for M
˜ (CPU)
most significant (Rn L).

4. Implementation Details and Results
We sample global and local directions using octahedral and
hemi-octrahedral maps [PH03, ED08], respectively. The bivariate BRDF domain is sampled uniformly in θd and according to a square root function of θh that places more samples near specular peaks (this is the same approach used in
the MERL/MIT database [MPBM03]). Matrices Rn and Wv
are represented using 32-bit floats and stored in GPU memory in compressed sparse row format after zeroing entries
˜ and (Wv f˜)
below a threshold of 10−5 . The products (Rn L)
are stored as dense and sparse matrices, respectively.
Our prototype system allows rotating the environment
map and three different methods for editing BRDFs: loading
from the MERL/MIT database, adjusting the parameters of a
Cook-Torrance BRDF that is then sampled over the bivariate
domain, and manipulating free-form functions of θh and θd .

52.57

48.07

32x32

Cook-Torrance

This expresses the reflection integral as a dot product between lighting/visibility coefficients and BRDF coefficients.
It limits the processing required for changes to the viewpoint or BRDF because the lighting/visibility coefficients
need only be updated when lighting is varied. An expression
for (Ln ⊕ Vp ) j is in the Appendix, and a detailed derivation
is in an associated technical report [SARZL10].

54.26

50.42

32x32

Figure 3: Rendered images and PSNR figures using a bivariate BRDF representation at two different resolutions for
three different materials. The reference images were computed using the original BRDF and the method described
in the paper. The middle and right columns contain images rendered using the same off-line technique but with the
BRDFs represented in the square-root-warped bivariate domain sampled at resolutions of 642 and 322 , respectively.
The Cook-Torrance materials corresond to microfacet distributions with RMS of 0.15 and 0.8.

c 2010 The Author(s)
Journal compilation c 2010 The Eurographics Association and Blackwell Publishing Ltd.

1465

Sitthi-Amorn et al. / Interactive Editing of Lighting and Materials

20 %
N: 16x16

10 %

0%

N: 64x64

GROUND TRUTH

V: 32x32

V: 16x16

Figure 4: Rendered images and PSNR figures for different view and normal sampling rates. A reasonable trade-off between
accuracy and performance is obtained by sampling the normal directions and view directions at 322 and 642 , respectively.

In the last case, the BRDF is the product of these curves, and
we maintain separate θd curves for each RGB channel. In all
cases, the wavelet coefficients f˜ and L˜ are computed from
scratch any time the BRDF or lighting changes. All results
were generated using an Intel Core I7 3.4GHz CPU with
6GB of memory running Windows Vista and equipped with
a NVIDIA 285 GTX graphics card with 2GB of memory.
We evaluated our system using several 3D models of varying geometric complexity, many different analytic and nonparametric BRDFs of varying gloss, and environment maps‡
with different frequency characteristics. First, we measured
the impact on the resulting image quality of using a bivariate
representation of the BRDFs. Figure 3 shows images rendered using a bivariate BRDF representation at different resolutions. In all of the results we report, the ground truth images were generated by evaluating the reflection integral at
each pixel using a dense grid of 2562 samples uniformly distributed over the local hemisphere. Figure 3 shows a comparison of these reference images to those generated using the
same off-line procedure but with a bivariate representation
of the BRDF sampled at different resolutions in place of the
original. A more thorough analysis of this bivariate representation is provided by Romeiro et al. [RVZ08] and includes
similar comparisons over the entire MERL/MIT database.
These results indicate that a bivariate BRDF sampled at 322

‡ http://www.debevec.org/probes
c 2010 The Author(s)
Journal compilation c 2010 The Eurographics Association and Blackwell Publishing Ltd.

results in an accurate approximation even for very shiny materials (e.g., measured gold) and we used that setting in the
remaining results.
We also measured the quality/performance trade-offs associated with the various sampling resolutions and the parameter M that determines the number of terms in the final inner product. In all cases, we sampled the sphere of
global light directions at 642 , the hemisphere of local directions (for lighting, visibility and reflectance) at 322 , and the
square-root-warped bivariate BRDF domain at 322 . Higher
sampling rates had a marginal effect compared to adjusting
the sampling rates of the view and normal directions.
Figure 4 shows images rendered off-line using different
resolutions for the normal and view directions (this is equivalent to using all of the terms in the sum in Eq. 4). This scene
contains the nickel BRDF from the MERL/MIT database
illuminated by the St. Peter’s environment. We report the
peak signal to noise ratio (PSNR) of each image measured
with respect to a reference image in the lower right hand corner. These images show that the normal sampling rate has a
greater influence on image quality than the view sampling
rate, although reasonably high resolutions for both are required to reproduce sharp features in the final appearance.
We choose to sample the view at 642 and the normal at 322
as a good trade-off between quality and performance, and
we use these resolutions in the remaining results.
Figure 5 shows two sets of images rendered online at interactive rates using different numbers of terms (M) for the

1466
Model
Hebe
Teapot
Table

Sitthi-Amorn et al. / Interactive Editing of Lighting and Materials

# Faces
128K
187K
212K

# Verts
68K
88K
115K

Changing Changing Changing
View
Light
BRDF
23/17
4/8
19/14
15/13
3/7
12/11
14/11
2/7
11/11

Table 1: Model sizes and framerates. The framerates are
measured in frames per second and each pair corresponds
to the version of our algorithm that computes full visibility
(left) and ambient occlusion (right).

final inner product. The reported framerates correspond to
changing viewpoint. The scene is illuminated by the Grace
Cathedral environment, the ground plane is perfectly diffuse, and the teapot’s appearance is modeled using relatively glossy (top row) and more diffuse (bottom row) CookTorrance BRDFs. We see that low values of M miss important features in the lighting and visibility, while increasing M beyond 128 produces only moderate improvements.
(Note that the PSNR with respect to the reference image is
not guaranteed to monotonically decrease because a different metric is applied when choosing the M most significant
wavelet terms.) We found that a value of M = 128 provides
a good trade-off between speed and quality.
At these normal and view resolutions, Rn and Wv require
roughly 400MB of combined storage and are approximately
3% and 6% sparse, respectively. Although this is a large
amount of storage, the precomputation is decoupled from the
scene geometry, lighting, and materials. This means that it is
only computed once and is shared by all environment maps
and BRDFs in any one scene. We terminate the wavelet lifting scheme at R = 3 levels because we found that further
refinements do not improve image quality and make Rn and
˜ and (Wv f˜) require
Wv less sparse. The dense matrices (Rn L)
roughly 16MB and 64MB, respectively. In terms of precomputation time, we perform Step 1 in Section 3.2 using unoptimized Matlab code, which takes roughly 10 hours. Step 2
is performed on the GPU and requires 5-10 minutes for the
scenes we tested, and the remaining steps are performed at
run-time. We leverage hardware support for texture filtering
to perform bilinear interpolation of (Wv f˜).
Figure 6 shows renderings of a complex scene with multiple analytic and non-parametric BRDFs. Please see the accompanying video for interactive versions of these results
with complex material edits. Table 1 reports the sizes of the
scenes we used along with the framerates for changing viewpoint alone, changing lighting, and changing BRDF with
M = 128 and a 1024 × 786 framebuffer. We report framerates for both versions of our algorithm: full wavelet visibility
and ambient occlusion. The slight drop in performance when
changing viewpoint and BRDF for ambient occlusion is due
to the fact that this technique requires performing bilinear in˜ whereas wavelet visibility
terpolation over the vectors (Rn L)
requires interpolating between only three vectors of wavelet
coefficients at the vertices of each triangle.

5. Conclusion
We demonstrated a system capable of interactive manipulation of viewpoint and material properties while preserving
the accuracy of important reflectance effects. The precomputation involves only per-normal rotation matrices Rn and
per-view warp matrices Wv , so the system successfully decouples precomputation from the set of materials and environments that can be navigated at runtime. The only restriction is that the materials be accurately representable on a
bivariate domain—a restriction that is reasonable for most
known isotropic BRDFs [RVZ08].
While our prototype system is limited to direct lighting,
it provides a strong argument for considering the bivariate
BRDF model in other systems that account for some degree of indirect lighting. For example, our approach could
be used to improve the system of Sun et al. [SM06] by eliminating the need for precomputation for each BRDF. Both
Sun et al. [SZC∗ 07] and Ben-Artzi et al. [BAERD08] observe that the low-frequency nature of indirect lighting allows one to exploit coarse approximations of BRDFs. One
approach may be to approximate such “indirect BRDFs”
with a low-dimensional linear subspace of bivariate BRDFs,
which could improve accuracy at an acceptable cost.
More generally, the bivariate representation should be
considered for cut-based methods [WFA∗ 05, CPWAP08]
and any other systems that can be restricted to isotropic materials. This representation should improve efficiency with a
minimal loss of accuracy, and it is likely to help speed the
development of realistic real-time rendering systems.
Appendix: Reduced lighting and visibility coefficients
In what follows, we derive an expression for the reduced
lighting and visibility coefficients (Ln ⊕ Vp ) j that appear in
Eq. 6. We refer the interested reader to an associated technical report [SARZL10] which gives a more detailed derivation.
Let R be the number of levels in the wavelet decomposition, and let r denote the level of an individual basis function within this decomposition (r ∈ [0, 1, . . . , R −
1] and increases from coarse to fine). The Haar basis
consists of one scaling function and three detail functions. We denote wavelet coefficients with either a single
index variable (i, j, or k as
in Eq. 4) or, for detail coefficients, using [s, M] where s spec[s,01]
[s,10]
[s,11]
ifies the wavelet square and M ∈
{01, 10, 11} indicates the type of basis function as shown
right. Furthermore, for detail coefficient j we denote by j+
and j− the coefficients at its right and left neighbors in the
same wavelet square according to the ordering on the right
(e.g., if j refers to [s, 01] then j+ and j− refer to [s, 10] and
[s, 11], respectively.) Finally, S and D are the set of scaling
and detail coefficients in the entire decomposition, respectively.
With this notation in hand, the reduced lighting and visibility coefficients can be expressed as:
c 2010 The Author(s)
Journal compilation c 2010 The Eurographics Association and Blackwell Publishing Ltd.

1467

Sitthi-Amorn et al. / Interactive Editing of Lighting and Materials

20 %

10 %

31.78

25.22

TERMS: 32 FPS: 50

30.44

23.08

TERMS: 32 FPS: 50

31.27

TERMS: 64 FPS: 28

TERMS: 256 FPS: 8

30.18

TERMS: 128 FPS: 15

0%

31.55

TERMS: 128 FPS: 15

TERMS: 64 FPS: 28

GROUND TRUTH

29.91

TERMS: 256 FPS: 8

GROUND TRUTH

Figure 5: Rendered images and PSNR figures for different numbers of wavelet terms in the final dot product (values of M). The
framerates listed below each image correspond to changing only the viewpoint. The teapot’s appearance is modeled using the
same Cook-Torrance BRDFs as in Figure 3. We choose 128 terms as a good trade-off between performance and accuracy.

Figure 6: Images computed at interactive rates with our relighting algorithm. These scenes contain high-resolution complex
geometry, high-frequency lighting, and multiple measured and non-parametric materials.

(Ln ⊕Vp ) j = G j +

2−R Ln, jVp, j
Kn,p, j

j∈S
j∈D

(7)

where

References
[BAERD08] B EN -A RTZI A., E GAN K., R AMAMOORTHI
R., D URAND F.: A precomputed polynomial representation for interactive BRDF editing with global illumination. ACM Transactions on Graphics 27, 2 (2008).
[BAOR06]

Gj =

∑

(sign( j, j )2(r−r ) )Ln, j Vp, j ,

j ∈P( j)

B EN -A RTZI A., OVERBECK R., R A R.: Real-time brdf editing in complex
lighting. In ACM Transactions on Graphics (Proc. ACM
SIGGRAPH) (2006).
MAMOORTHI

[CPWAP08]

and

C HESLACK -P OSTAVA E., WANG R., A K O., P ELLACINI F.: Fast, realistic lighting
and material design using nonlinear cut approximation.
ACM Transactions on Graphics (Proc. ACM SIGGRAPH)
(2008).
ERLUND

Kn,p, j = 2−R+r (Ln, j+ Vp, j− + Ln, j− Vp, j+ ) +
2−R+r (Ln, j psum(Vp , j) +Vp, j psum(Ln , j)).
Here, P( j) denotes the set of basis functions overlapping ρ j
at finer levels, r denotes the level of coefficient j , psum
is the parent sum operator described by Ng et al. [NRH04]
which sums coefficients of all basis functions overlapping
the wavelet square associated with j, and sign is the sign
of the coarser basis function j in the region that the finer
function j occupies.
c 2010 The Author(s)
Journal compilation c 2010 The Eurographics Association and Blackwell Publishing Ltd.

[ED08] E NGELHARDT T., DACHSBACHER C.: Octahedron Environment Maps. In Proc. Vision, Modeling, and
Visualization (2008).
[Fer04] F ERNANDO R.: Ambient occlusion. In GPU
Gems: Programming Techniques, Tips and Tricks for
Real-Time Graphics. Pearson Higher Education, 2004.
[GKD07]

G REEN P., K AUTZ J., D URAND F.: Efficient

1468

Sitthi-Amorn et al. / Interactive Editing of Lighting and Materials

reflectance and visibility approximations for environment
map rendering. Computer Graphics Forum 26, 3 (2007),
495–502.
[Gre86] G REENE N.: Environment mapping and other applications of world projections. IEEE Computer Graphics
and Applications 6, 11 (1986), 21–29.
ˇ
[KC08] K RIVÁNEK
J., C OLBERT M.: Real-time shading
with filtered importance sampling. In Eurographics Symposium on Rendering (2008).

[KM00] K AUTZ J., M C C OOL M.: Approximation of
glossy reflection with prefiltered environment maps. In
Proc. Graphics Interface (2000), pp. 119–126.

[SZC∗ 07] S UN X., Z HOU K., C HEN Y., L IN S., S HI J.,
G UO B.: Interactive relighting with dynamic BRDFs.
ACM Transactions on Graphics (Proc. ACM SIGGRAPH)
26, 3 (2007).
[WFA∗ 05] WALTER B., F ERNANDEZ S., A RBREE A.,
BALA K., D ONIKIAN M., G REENBERG D.: Lightcuts:
a scalable approach to illumination. ACM Transactions
on Graphics (Proc. ACM SIGGRAPH) 24, 3 (2005).
[WNLH06] WANG R., N G R., L UEBKE D.,
H UMPHREYS G.: Efficient wavelet rotation for environment map rendering. In Eurographics Symposium
on Rendering (2006), pp. 173–182.

[MPBM03] M ATUSIK W., P FISTER H., B RAND M.,
M C M ILLAN L.: A data-driven reflectance model. ACM
Transactions on Graphics (Proc. ACM SIGGRAPH) 22, 3
(2003).
[NDM05] N GAN A., D URAND F., M ATUSIK W.: Experimental analysis of brdf models. Eurographics Symposium
on Rendering (2005), 117–126.
[NRH03] N G R., R AMAMOORTHI R., H ANRAHAN P.:
All-frequency shadows using non-linear wavelet lighting approximation. ACM Transactions on Graphics
(Proc. ACM SIGGRAPH) 22, 3 (2003), 376–381.
[NRH04] N G R., R AMAMOORTHI R., H ANRAHAN P.:
Triple product wavelet integrals for all-frequency relighting. ACM Transactions on Graphics (Proc. ACM SIGGRAPH) 23, 3 (2004), 477–487.
[PH03] P RAUN E., H OPPE H.: Spherical parametrization and remeshing. ACM Transactions on Graphics
(Proc. ACM SIGGRAPH) 22, 3 (2003), 340–349.
[Rom10] ROMEIRO F.: Efficient Reflectance Models for
Vision and Graphics. PhD thesis, Harvard University,
2010.
[Rus98] RUSINKIEWICZ S.: A new change of variables
for efficient BRDF representation. Eurographics Rendering Workshop (1998).
[RVZ08] ROMEIRO F., VASILYEV Y., Z ICKLER T.: Passive reflectometry. In Proc. European Conference on
Computer Vision (2008).
[SARZL10] S ITTHI -A MORN P., ROMEIRO F., Z ICKLER
T., L AWRENCE J.: Factoring Lighting, Visibility, and Bivariate Reflectance for Interactive Editing. Tech. Rep.
CS-2010-9, Department of Computer Science, University
of Virginia, 2010.
[SAS05] S TARK M., A RVO J., S MITS B.: Barycentric parameterizations for isotropic BRDFs. IEEE Transactions
on Visualization and Computer Graphics 11, 2 (2005),
126–138.
[SM06] S UN W., M UKHERJEE A.: Generalized wavelet
product integral for rendering dynamic glossy objects.
ACM Transactions on Graphics (Proc. ACM SIGGRAPH)
25, 3 (2006).
c 2010 The Author(s)
Journal compilation c 2010 The Eurographics Association and Blackwell Publishing Ltd.

