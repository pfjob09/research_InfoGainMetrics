DOI: 10.1111/j.1467-8659.2009.01703.x
Eurographics/ IEEE-VGTC Symposium on Visualization 2010
G. Melançon, T. Munzner, and D. Weiskopf
(Guest Editors)

Volume 29 (2010), Number 3

Effective Techniques to Visualize
Filament-Surface Relationships
A. Kuß, M. Gensel, B. Meyer, V. J. Dercksen, and S. Prohaska
Zuse Institute Berlin (ZIB)

Abstract
Combined visualizations of filamentous structures and surrounding volumetric objects are common in biological
and medical applications. Often, the structures’ spatial relationships remain unclear to the viewer. In this paper,
we discuss and evaluate techniques to emphasize spatial relationships. We concentrate on the visualization of
transparent objects and intersecting lines. Among various techniques, participants of an exploratory user study
preferred coloring of lines, marking of line-surface intersections by glyphs, and the combination of both. These
techniques were additionally evaluated in a confirmatory study in which participants were asked to judge whether
a filament runs through a transparent structure. We found that the evaluated techniques significantly improve the
participants’ performance in terms of the number of correct responses and response time. The best performance
was found for the combination of line coloring and intersection glyph display.
Categories and Subject Descriptors (according to ACM CCS): Computer Graphics [I.3.6]: Methodology and Techniques – Interaction Techniques—; Life and Medical Sciences [J.3]: Biology and Genetics—

1. Introduction

The presentation of surrounding context structures can help
to reduce this problem. While opaque surfaces of surrounding or neighbouring structures may occlude a large fraction
of those tubes, transparent surface rendering can reduce this
problem. Unlike other occlusion reduction techniques, such
as cut-away views or exploded views, transparency does not
hide or spatially transform any structures [Int96]. Transparency, however, has specific deficiencies. First, intersection points of tubes and transparent structures are hard to
see. Second, whether a tube passes through or by a volumetric structure is often unclear.

Visualizations of filamentous structures together with neighbouring or surrounding volumetric objects are common in
biological and medical applications. For example, a neurobiologist wants to present a newly acquired insect nerve cell
within a 3D brain model, or a radiologist wants to present
brain nerve fibers to a patient. Questions of interest in such
cases are: What trajectory does a neuronal fiber take? and
Which brain regions does it connect? Does it overlap with
other neurons, indicating potential connections?
Such questions could be answered by effective visualization techniques that allow a user to determine which part of
a filament is contained within a particular volumetric object,
where a filament enters or leaves a volumetric object, and
the relative depth of filaments with respect to each other.

Techniques that accentuate trajectories of lines within
transparent objects could alleviate these limitations. This
raises the question of which technique is most effective in
this situation to support the understanding of spatial relationships. So far, user studies on line visualization methods concentrate on depth and shape perception of multiple
tubes [MMYK06, WB08]. These studies demonstrate that
lighting effects enhance perception. To our knowledge, the
perception of filament trajectories through surrounding objects, however, has not been analyzed in a study.

Illuminated tubes and transparent surface rendering are
established methods, but their effectiveness for answering
questions like the above is limited. Compared to simple
polyline visualization, illuminated tubes provide better depth
perception and differentiation. Nevertheless, understanding
how the tubes are exactly embedded in space can be difficult.
c 2010 The Author(s)
Journal compilation c 2010 The Eurographics Association and Blackwell Publishing Ltd.
Published by Blackwell Publishing, 9600 Garsington Road, Oxford OX4 2DQ, UK and
350 Main Street, Malden, MA 02148, USA.

1003

1004

A. Kuß et al. / Effective Techniques to Visualize Filament-Surface Relationships

(a)

(b)

Figure 1: (a) Standard filament and surface visualization of three nerves in a bee brain. (b) The filaments are colored by their
surrounding surfaces. Additionally, ring-shaped glyphs are placed at filament-surface intersections indicating, for example,
registration errors. To improve the perception of which line lies in front of another, a halo effect is used.
We address this question in two steps. First, we present
the results of an exploratory user study, focusing on neurobiological data (see Related Work and Section 3). The preferred techniques are the coloring of lines and the marking
of line-surface intersections by glyphs. Figure 1 illustrates
how these two techniques enhance a visualization. We then
address the question of how effective the two preferred techniques, coloring and glyphs, are to determine whether a filament runs through an object. Section 5 presents the results
of a second, confirmatory user study, in which we evaluated
how well line coloring and glyphs at line-surface intersections support users to relate line segments to transparently
rendered, surrounding objects.
2. Related Work
Filamentous structure visualization is used in several research fields, such as neuroscience [dHCMP08], flow
visualization [ZSH96], vessel visualization [OP05], and
DTI [MSE∗ 06]. In general, the developed methods try to
find a compromise between speed and quality [MPSS05].
Recently, knowledge from perception theory is increasingly
exploited to improve the visualizations.
The most obvious and also the fastest way to visualize
filamentous structures is the rendering of simple polylines.
In the fast approach of [ZSH96], polylines are illuminated to
improve the perception of depth and spatial relations. Simple
polylines, however, ignore possible thickness differences of
the filamentous structures. Better suited for a realistic visualization is the rendering of lines using tubes or convolution
surfaces [OP05]. Unfortunately, in practice these approach
are often too slow. Other approaches approximate tube rendering using textured triangle strips or rectangular primitives [MSE∗ 06, SGS05]. They provide high visual quality
and rendering speed, but artifacts can occur for lines with
high curvature or at branching points. [IG97] assign different hues to line elements for a better distinction of adjacent
and overlapping lines. They further use halos, which visually

enhance depth discontinuities, thereby clarifying the 3D spatial organization of line elements. [BPKW03] enhance perception of spatial relations between fibers, other than relative
depth, based on geometric similarity measures like end point
proximity. In [WB08], it was shown that shadows improve
scene layout perception as well as large-scale feature perception for scenes made up of streamtubes. [RHD∗ 06] evaluated hatching on surfaces and hatched shadows. They conclude that both techniques improve the perception of depth
and shape and the comparison of depth distances for complex tubular structures.
Presenting filament visualizations together with their surrounding or neighbouring context structures depends to a
large extent on solving the occlusion problem. Techniques
for occlusion reduction are, for example, cut-away views,
ghosted views, and exploded views [VG05]. Unfortunately,
these techniques tend to remove parts of the data, resulting
in visualizations that increase the viewer’s mental load. Another way to address the occlusion problem is transparency,
which has the advantage of displaying all relevant structures
together with unmodified shape. The primary disadvantage
is that understanding the shape and location of a transparent surface is difficult, because ordinary shape and depth
cues of shading and occlusion are less pronounced [IFP95].
To overcome these limitations, [IFP95] display ridge and
valley lines on transparent surfaces. [DWE02] propose a
view-dependent transparency rendering method based on
rules defined in books for technical or scientific illustrations. In BrainGazer [BoG∗ 09], the occlusion of surfacebased anatomical structures (including nerves) by surrounding volume-rendered image data is reduced by increasing the
image transparency at spatially important surface edges.
User studies that evaluate the perceptual quality of visualization methods are becoming an important part of the
visualization method development process. Studies exploring subjective parameters, such as personal preferences or
taste, often use questionnaires or interviews (see [TIP05] for
c 2010 The Author(s)
Journal compilation c 2010 The Eurographics Association and Blackwell Publishing Ltd.

A. Kuß et al. / Effective Techniques to Visualize Filament-Surface Relationships

a good example that evaluates hybrid visualization methods
in medicine). In other studies, participants have to perform
specific tasks under varying conditions to show a method’s
advantage [BCFW08]. An example for a visual search task
experiment is presented in [BALP09], who evaluated four
emphasis techniques for structures in medical visualizations.
More related to our work are the studies of [RHD∗ 06]
and [WB08]. The former showed that distance-encoded
shadows and surface visualizations significantly influence
the perception of spatial depth. Here, participants were asked
to specify the correct order of marks on vascular structures,
or to determine the depth distance order between vascular
segments. [WB08] found out that global shadowing influences the spatial perception of multiple lines. They asked
participants to identify whether a certain filament lies in
front of another one using varying shadowing methods.

1005

3.1. Standard visualization of surfaces and filaments
We first establish a standard rendering method to which we
will compare the enhanced visualization methods.
In our standard visualization, the volumetric objects are
rendered as transparent surfaces. Transparency is a straightforward way to deal with occlusion in multi-object scenes,
without the need to transform or discard data as with cutaway or exploded views. Additional feature lines [IFP95]
are not used, because we assume that line structures on the
surface as well as inside the surface are too distractive. The
same applies to shadows cast by the filaments, which are
not used either. Filamentous structures are displayed by illuminated tubes, which support the perception of shape and
depth [MSE∗ 06]. Because the surfaces of our illuminated filaments are not sufficiently large, we do not place textures on
them, as described in [RHD∗ 06].

3. Methods for Visualizing Spatial Relationships

To improve the standard visualization, we evaluate the following visualization techniques:

In this section, we propose techniques to visualize the spatial relationships between filamentous structures with potentially complex branching patterns and surrounding volumetric structures. These methods emphasize, in particular, the
containment of a filament in a volumetric structure, entry
and exit points and the relative depth of different filaments.

1.
2.
3.
4.

The volumetric structures are given as triangulated surfaces. A surface is closed, but not necessarily manifold. It
may consist of multiple sub-surfaces called materials, each
having a distinct color. The filamentous structures are given
as a set of 3D vertices connected by piece-wise linear segments. These polylines can be connected at the branching
points, thus forming a graph structure.

(a)

(c)

(b)

(d)

Figure 2: Examples for visualization methods. (a) Filamentsurface intersections are emphasized using green cylinders.
(b) Filaments outside the surface are colored white; filaments inside are colored dark grey. (c) The filament segments are colored according to their surrounding material.
(d) Depth-dependent contrast enhancement (halo).
c 2010 The Author(s)
Journal compilation c 2010 The Eurographics Association and Blackwell Publishing Ltd.

Glyph-based, explicit visualization of intersection points.
Filament coloring according to its surrounding materials.
Filament color modulation according to depth.
Depth-based contrast enhancement.

3.2. Glyph-based visualization of intersection points
The explicit representation of the entry and exit points is a
straightforward way to visualize whether a filament passes
through a volume. To efficiently compute these intersection
points, all segments and all surface triangles are inserted into
an octree. For all octree leaves containing at least both a triangle and a segment, the intersection point is computed using the method described in [Eri05].
The intersection points are visualized using different types
of glyphs. We propose discs and cylinders oriented along the
intersecting segment (see Figure 2(a)). Alternatively, rings
can be drawn around the intersection points and projected
onto the intersected surface to accentuate its curvature 6(b).
This is achieved by sampling a number of points on a circle
on the plane defined by the intersected triangle, and shifting
each point onto the closest point on the surface. The points
are then connected by computing a locally shortest path on
the mesh as described in [PPP06] and [Lam08].
3.3. Filament coloring according to surrounding
material
Color is a powerful visual feature that can be used to show
differences between objects, but also to group them visually. We propose to color each filament segment according to
the color of its surrounding surface. This approach visually
groups filamentous and volumetric structures. We will refer
to this technique as material coloring. The color of each segment in a graph of connected polylines is computed as fol-

1006

A. Kuß et al. / Effective Techniques to Visualize Filament-Surface Relationships

lows. First, the intersection points with the surfaces are computed and inserted into the polylines. Second, the color of an
arbitrary end point is determined by performing a point containment query [Eri05] to find the surrounding surface and
its color. Starting from the end point, the graph is traversed,
switching colors at each intersection point, using the material information of the intersected triangles (see Figure 2(c)).
As an alternative to material coloring, each segment can be
assigned one of two colors depending on whether a segment
is contained in any of the surfaces. This method, computed
similarly, is called binary coloring (see Figure 2(b)).

3.4. Filament color modulation according to depth
In [TMC∗ 91], depth perception is shown to be enhanced by
certain color gradients. This is particularly true for saturation gradients, but also for intensity gradients. The reason
is that these effects occur in natural scenes [War08]. Atmospheric scattering renders distant colors less saturated than
closely viewed ones. Gradients in hue may or may not affect depth-perception. For example, a red-green hue gradient, which does not occur in natural scenes, does not affect depth perception [TMC∗ 91]. On the other hand, a technique commonly used in painting is to modulate the colors
of remote objects towards the background, which usually is
blue [ER01]. We mimic this effect by modulating the color
of all opaque objects in the scene with a depth-dependent
color map. The color of transparent objects is, however, not
changed. In Figure 3(c) an example is presented.

4. Exploratory User Study
To obtain an indication which of the techniques presented in
Section 3 support the understanding of spatial relationships,
we conducted an exploratory unsupervised user study. The
participants were asked to rate the effectiveness of visualizations in a printed questionnaire [Gen09].
To reduce the volume of the questionnaire, it was divided
into two main parts. The first part concentrated on material
coloring, binary coloring, and the additional display of intersection glyphs. For the coloring techniques, we were interested in ratings. To evaluate the potential of additional glyph
display, we wanted the participants to compare the coloring
techniques to the glyph display and to the combination of
coloring and glyphs. In the second part, we concentrated on
ratings for red-to-blue and yellow-to-red modulation according to depth and on ratings for halos.
We hypothesized:
• Material coloring is best to emphasize through which
structures a filament passes, because of visual grouping
of line and surface colors.
• Glyphs perform best for intersection detection since their
distinctiveness draws attention exactly to these points.
• The combination of material coloring and glyphs does not
perform better than their single use for trajectory and intersection detection respectively.
• Halos improve the understanding of relative filament location, since they clarify depth order at line-line crossings.
• Red-blue depth coloring improves depth perception since
it adds an additional depth cue occurring in natural scenes.

3.5. Depth-based contrast enhancement

4.1. Participants

To enhance the contrast for better perception of, in particular, thin filamentous structures and their relative depths, we
use a halo method based on the work by [LCD06] (see Figure 2(d)). In the original method, a spatial importance function (SIF) is defined as the difference between the depth
buffer values and a low-pass filtered copy of the depth buffer.
The SIF has large absolute values along edges where a depth
difference occurs. By modulating the image color using the
SIF, a halo-like appearance is created. A disadvantage of
the original method is, however, that the filter response is
skewed by background depth buffer fragments having the
maximum z-value (1.0), which happens frequently for thin
structures. In this case, the depth difference for a pair of
crossing lines needs to be relatively large for a halo to appear.
We, therefore, chose to leave out any background fragments
when computing the filter response. Another undesired aspect of the original method is that the computed SIF-values
are much smaller for far away objects than for close objects,
due to the non-linear z-values in the depth buffer after perspective division. To increase the contrast for distant objects,
the z-values used for computing the SIF are relinearized by
inverting the perspective division.

We asked 29 participants, of whom 13 were visualizationand graphics-educated, 8 were potential users (neurobiologists), and 8 were non-experts, to fill out the questionnaire.
4.2. Stimuli
The stimuli were static visualizations of a bee brain model’s
substructures. The geometry featured several overlapping
surfaces, and ramified line structures (nerve fibers). It was
rendered in two ways, as overview and as closeup. Closeups
were only generated for the questionnaire’s first part. Apart
from a standard visualization of the scene (see Section 3.1),
the proposed modifications (3.2-3.5) were applied alone and
in combination to create the different stimuli. Examples for
different stimuli are shown in Figure 3.
4.3. Procedure
The questionnaire consisted of 13 tasks. Each task was composed of several questions regarding 1–4 associated stimuli.
The participants were asked to rate or to compare the stimuli
according to the questions.
c 2010 The Author(s)
Journal compilation c 2010 The Eurographics Association and Blackwell Publishing Ltd.

A. Kuß et al. / Effective Techniques to Visualize Filament-Surface Relationships

(a) Standard visualization.

(b) Application of halo effect.

1007

(c) Depth-coding yellow to red color gradient.

Figure 3: Example images from the first user study. Participants were asked to rate if (b), compared to (a), improves the
recognition whether filaments lie behind or in front of each other. In (c) they were asked to rate to the quality of depth perception.
The questions underlying the ratings or comparisons
were: (1) Is the relative location of lines clear, in other words
is it clear which line lies behind or in front of another line?
(2) How well can you identify if lines lie inside, outside, or
behind an object? (3) Is it clear where a line starts and
ends and which objects it traverses? (4) How well do you
recognize the intersections of lines and surfaces? (5) How
well is the perception of depth? (6) How well can you estimate distances between lines? A selection of these questions
was posed at each task. The questionnaire’s first part concentrated on questions (1) to (4) . The second part concentrated
on question types (1), (2), (5), and (6).
For the rating tasks, we used overview visualizations as
stimuli and presented a 6-point Likert scale (very bad to very
good) for rating. For the comparison tasks a 6-point Likert
scale ranging from not at all better to much better was used.
4.4. Results
We analyzed the rating data by testing for significant differences among the visualization techniques including the
standard stimulus. Figure 5 shows the ratings for the standard visualization and the combination of material coloring
and halos. The data resulting from the image comparison
tasks is presented as descriptive statistical analysis. For an
overview of the results see Figure 4.
Rating data.
Kolmogorov-Smirnov tests showed that not all results were
normally distributed. We used the Wilcoxon signed-rank test
for further analysis. We present the values z(i) of the Z statistic below a predefined significance level α. (i) indicates the
related question type (see Section 4.3).
We pairwise compared material coloring, binary coloring, and standard visualization using a Bonferroni-corrected
α = 0.017. Material coloring versus standard: Material coloring of filaments received statistically significantly better
ratings for all selected questions (z(1) = 2.77, z(2) = 2.69,
z(3) = 2.67, z(4) = 4.00). Binary coloring versus standard: Binary coloring received significantly better ratings
c 2010 The Author(s)
Journal compilation c 2010 The Eurographics Association and Blackwell Publishing Ltd.

(z(2) = 2.36, z(3) = 2.39, z(4) = 3.71), except for understanding relative line location. Material coloring versus binary coloring: Material coloring was significantly better for
relative line location and trajectory detection (z(1) = 2.28,
z(3) = 2.98). For the detection of intersection points and inside/outside location, the same effect could be observed, but
was not significant.
Depth coloring was pairwise compared with α = 0.017.
Yellow-red coloring versus standard: Yellow-red coloring
significantly improved the perception of relative line location (z(1) = 4.22) and line distance estimation (z(6) = 2.35).
Red-blue coloring versus standard: Red-blue coloring
performed significantly better for relative line location
(z(1) = 3.62). Yellow-red coloring versus red-blue coloring:
No colormap was significantly better than the other.
Halos versus standard: With α set to 0.05, halos achieved
a significantly better performance for relative line location,
inside/outside line location and overall depth perception
(z(1) = 4.39, z(2) = 2.38, z(5) = 4.69).
Comparison data.
The following description lists the results of the comparison
between material coloring and intersection glyphs, as well
as additional benefit gained by their combined application.
The comparisons were performed using both overview and
closeup visualizations.
For inside/outside line location detection, 69% preferred
material coloring over glyphs (17%). This preference raised
to 79% over 17% in closeups. 71% (86% in closeups) rated
the combination of both techniques to be more efficient than
their single usage.
Material coloring was also preferred over glyphs for line
trajectory detection (86% versus 11%). In closeups, the ratio
was 69% for material coloring versus 10% for glyphs. An
additional improvement for coloring combined with glyphs
has been stated by 81% and 89%, respectively.
The use of glyphs was favored for the detection of intersection points by 59% of the participants whereas only
31% favored material coloring for this task. In closeups,

1008

A. Kuß et al. / Effective Techniques to Visualize Filament-Surface Relationships

Figure 4: Overview of the exploratory study’s rating and comparison tasks with visualization techniques in rows and question
types in columns. Neglected technique-question combinations are grayed out. 0s represent no improvements over the standard.
The + symbols are used to indicate enhancements when applying the technique. Each time a technique was preferred, the
number of + is increased. For example, regarding object traversal, binary and material coloring performed better than the
standard visualization (both receiving a +); in direct comparison, material was preferred over binary coloring (leading to ++).
glyphs were also preferred over material coloring (55% versus 24%). Additional benefit by using both techniques together was observed by 67% in overview visualizations and
by 93% in closeups.
4.5. Discussion
The results met most of our expectations. In general, the applied visualization methods improved the perception of line
location and depth.
The answers differed between the groups of participants.
Overall, the non-expert participants’ answer variance was
much higher than the variance of the other groups. They also
favored the methods, but, compared to the votes of neurobiologists or graphics users, they assigned lower rankings.
This may be due to the lack of experience of the participants,
and the complexity of scenes and tasks.
We did not expect the combination of line coloring and
intersection glyphs to be favored for all performed tasks, because we thought that glyphs might sometimes hide important information or might be distracting. However, the improvement of the combined techniques in closeups might
be a sign that our thought of distraction is not completely
wrong. Interestingly, the combination seems to add more to
the result than its single parts. The overall very good ratings for material coloring and its preference over glyphs was
surprising. Halos as well as depth-dependent color modulation received good rates. The expected preference of redblue depth coloring was not substantiated by the study.
Given these findings, we further investigated the potential
of material coloring and the favored ring glyphs at intersections. We were especially interested in the combined use of
both techniques. We wanted to know if the combination performs better than the single techniques for the task of judging whether a filament runs through a structure.
5. Confirmatory User-Study
We designed a second study to recheck and strengthen our
findings. The study concentrated on the techniques that had

Figure 5: Visualization rating. Average rating for standard
visualization (top) compared to average rating for a visualization using a combination of material coloring and halos
(bottom). Bar colors represent question types from Figure 4.
been preferred in the exploratory study, namely material coloring, intersection glyphs, and the combination of both. We
limited the task to identifying a line’s trajectory. This reduced the complexity of the study while concentrating on a
commonly performed task in neuroscience applications. We
used static scenes, because we were mainly interested in the
influence of the emphasizing techniques on perception. Using static scenes should also allow us to infer how suitable
the techniques are for 2D media, like print or web.
Our study followed a one-factorial design in which the
variations of visualization techniques were the factor’s levels. They were given by a standard visualization (see Section 3.1 and Section 5.2) and visualizations that resulted
c 2010 The Author(s)
Journal compilation c 2010 The Eurographics Association and Blackwell Publishing Ltd.

A. Kuß et al. / Effective Techniques to Visualize Filament-Surface Relationships

from adding either one or both of the emphasizing techniques. Using a within-subject design, we presented different scenes of varying factor levels to our participants. In the
scenes, the participants had to specify whether a filament
runs through a certain structure or not. Naturally, the study’s
independent variables were the factor’s levels. Its dependent
variables were the number of correct responses and response
times. Control variables were the participants’ experience in
visualization and computer graphics, their age, gender, and
potential color vision deficiencies. Our null hypothesis H0
stated that the techniques had no influence on the dependent variable. Our alternative hypothesis H1 = ¬H0 stated
that they had significant influence on the test results.
5.1. Participants
48 participants (17 females, 31 males) participated in our
study. The participants’ age ranged from 24 to 55. Four participants had a red-green color vision deficiency. 30 percent
claimed that they had much experience with visualization
and computer graphics. 40 percent responded to have average experience in this field; 30 percent had little experience.

1009

were moved to δ and −δ respectively. A practical value for
δ was 0.8; we rejected intersecting surfaces.
The filament was generated by performing a modified random walk. Starting with vertex v0 at position
(3 sign(x1 ) δ, 0, 2 δ), with x1 being the first surface’s xcoordinate, the filament was extended with each iteration towards the bounding box center of the next surface:
vi+1 = vi + s . The vectorial increment s = d + r of each iteration was given by its directional part d and a random
vector r. The directional part was defined as the vector to
the next bounding box center, divided by a subdivision factor that was set to 10. The random vector was scaled to
a length of |r| = 0.7 d . When the current filament vertex vi was within the vicinity of the bounding box center
b, b − vi < 3 d , the next surface’s center was chosen as
target. According to v0 , the filament’s terminal point was
placed at (3 sign(x3 ) δ, 0, −2 δ) (x3 was the third surface’s
x-coordinate). Finally, we smoothed the filament.
For each factor level, we selected eight different stimuli in which the filament ran through the red structure and
eight different stimuli in which it did not. This resulted in
2 × 4 × 8 = 64 trial stimuli, each presenting a unique scene.

5.2. Stimuli
Our baseline stimuli, the first factor level, were scenes that
consisted of three volumetric objects represented by surfaces
and one filament, displayed in perspective projection (see
Figure 6(a)). The surfaces had an organic and mostly convex
shape. They had neither deep indentations nor strong concavities. We assigned different color values to the surfaces
according to the color recommendations from [WGM∗ 08].
To reduce the generation of false colors, we chose opposite
hues from the hue wheel for the first two surfaces, specifically cyan and red. For the third surface, we chose the neutral
color grey. We used transparency rendering with an opacity value of 0.3 for all surfaces. The filament was visualized
1
as a white tube of constant diameter (approximately 30
of
the average surface object diameter). Its shape was elongated
while containing several curves. The filament could intersect
0, 1, 2 or all surfaces. To create visualizations for the remaining factor levels, we additionally applied intersection glyphs,
material coloring, or both (Figure 6). The participants were
asked: Does the filament run through the red structure?
The scenes were automatically generated. The main idea
was to place the three surfaces randomly on a regular
3×3×3 grid. The red target surface was always placed at
the center. The first and third surface were placed in the front
and back plane respectively. For each scene, three surfaces
s1,2,3 were randomly chosen from 31 different surface models. The surfaces were scaled such that the longest side of
their bounding box equaled 1. The first surface’s center was
translated to the origin. The two other surfaces’ centers were
translated in the xy-plane to a position randomly chosen out
of the eight standard positions {−δ, 0, δ}2 \ (0, 0); in z, they
c 2010 The Author(s)
Journal compilation c 2010 The Eurographics Association and Blackwell Publishing Ltd.

5.3. Procedure
Our testing application was a stand-alone Adobe Flashbased executable (see supplementary material for a webbased version), presenting a textual study introduction, a
number of example tasks, and the actual test questions to
the user. The application stored the responses and response
times in a MySQL database. The testing application was presented on a 24” LCD monitor at 1600 × 1200 resolution, adjusted to an aspect ratio of 4:3. The stimuli’s resolution was
1136 × 816 pixels. Participants were seated an average of 60
cm away from the monitor. The testing room’s light conditions were controlled by blinds.
The test started with questions about the participant’s age,
color blindness and visualization/computer graphics experience. After an explanation of the visualization techniques
and the task, seven training runs were performed. Each task
started with the presentation of a stimulus for exactly one
second, followed by a screen showing the question, yes and
no radio buttons, and a Continue button. The user had to select an answer with the mouse and click Continue to advance
to the next question. The answering time was not limited,
but we asked the participants to respond as quickly as possible. The recorded response time was the time the participant
needed to select an answer and click the Continue button,
starting from the moment the stimulus disappeared. During
the introduction and the training session, participants were
allowed to ask questions. After the training, the real experiment, consisting of 64 stimuli, started. The same 64 stimuli
were presented in random order to each participant to avoid
potential bias due to a particular fixed stimuli sequence. For

1010

A. Kuß et al. / Effective Techniques to Visualize Filament-Surface Relationships

(a)

(b)

(c)

(d)

Figure 6: Example stimuli. (a) Baseline visualization. (b) Intersection points of tube and volumetric structures are displayed
using rings. (c) Tube coloring by surrounding material. (d) Combined intersection display and coloring by material.
each stimulus, the participants had to decide whether the filament runs through the red structure. A complete study was
performed in about 10 minutes. We tested the application
with eight participants. They helped us to improve the explanation and to define the number of training runs.

5.4. Results
From the study, we received 3072 total trials with 768 trials for each factor level. The average number of correct responses for all trials and all participants was 52.6 of 64; the
average response time was 2.5 seconds. We excluded the results of one participant whose number of correct responses
differed more than four times the standard deviation from
the mean (37 correct responses). Figure 7 shows the distribution of overall correct responses and average response times
for all participants. It also presents the average number of
correct responses and the average response times for each
technique with their 95% confidence intervals.
Using a Kolmogorov-Smirnov test, we found that part of
our data were not normally distributed. The distributions of
correct responses per technique were mostly left-skewed.
Cubic as well as square transformation could not normalize the data. The response times were mostly right-skewed
and were, even after a logarithmic tranformation, not normally distributed. We used the non-parametric Friedman test
to evaluate whether the factor visualization technique influenced the number of correct responses and the response
time. To analyze each technique’s influence, we performed
pairwise comparisons of mean ranks according to [BLB90].
Evaluation of Correct Responses
The Friedman test showed a statistically significant influence
of the visualization techniques on the number of correct responses (F(3,138) = 111.5, p 0.005). We can reject H0 and
assume H1 . Compared to the standard visualization, participants performed better when intersection glyphs, material
coloring, or the combination of both (all p
0.05) were
used. A significant difference was also found for the combination of intersection glyphs and material coloring compared
to the single use of material coloring (p < 0.05) and the single use of glyphs (p
0.05). The effect between intersection glyph display and material coloring was not significant.

Evaluation of Response Times
The response times were significantly influenced by the different visualization techniques (F(3,138) = 34.3, p 0.005);
H0 can be rejected. The pairwise comparison showed no significant difference between the standard visualization technique and the usage of intersection glyphs. Also, the difference between material coloring and the technique combination was not significant. In contrast, we found significant differences (p 0.05) between the standard visualization and
the remaining techniques (material coloring and the combination of material coloring and intersection glyphs). The
difference between intersection glyphs and material coloring was also significant (p 0.05).
Figure 8 summarizes the results of the pairwise comparisons for correct responses and response times. Presented are
the absolute differences d between the rank means that resulted from the Friedman test. The critical difference dcrit
for α = 0.05 is 0.745.

Figure 8: Absolute mean rank differences between the stimuli variations. A value above dcrit = 0.745 (highlighted in
green) is statistically significant.

Evaluation of Control Variables
We also analyzed the potential influence of our control variables age, gender, color deficiency, and visualization or computer graphics experience. We found no significant influence
of the control variables on the number of correct answers or
the response times.
5.5. Discussion
Our study results show that the visualization techniques support the user in determining whether a filament runs through
a transparent structure. Both accuracy and speed are improved by the techniques. The best performance is achieved
for the combination of coloring and glyphs.
c 2010 The Author(s)
Journal compilation c 2010 The Eurographics Association and Blackwell Publishing Ltd.

1011

A. Kuß et al. / Effective Techniques to Visualize Filament-Surface Relationships

(a)

(b)

(c)

(d)

Figure 7: Number of correct responses and response times for all participants. (a) The diagram shows the absolute frequency
of participants for the percentaged number of correct responses. (b) Average response times per participant ranged between
1.3 and 5.3 seconds. We show the absolute frequency of people having a certain average response time. (c) Average number of
correct responses with 95% confidence intervals for each tested visualization technique. (d) Average response times together
with their 95% confidence intervals for each tested visualization technique.
Some interesting observations can be made from the pairwise comparisons of the techniques. First of all, for our
test stimuli, there is no significant accuracy difference between glyphs and coloring. Apparently, both visual cues allow the user to group objects and to understand spatial relationships with similar precision. The result from the exploratory study, in which the participants always preferred
the coloring, could not be confirmed. However, glyphs do
not help to perform the tasks faster. Compared to the standard visualization, a significant improvement of response
time was only found for material coloring and the combination of techniques. This result suggests that the information
conveyed by glyphs is less obvious and that it requires more
time to be processed. Although there is no speedup between
single coloring and the combination of techniques, the latter
helps to increase the accuracy. This might be due to the increased attention that is drawn to the regions of interest by
the combined techniques and the ease of grouping structures
and filaments by color.
Several participants of the second study suggested to color
the glyphs according to the surface they are lying on. We
think that this technique variation is worth being analyzed.
For our experiment, we preferred one constant eye-catching
glyph color to ensure the detection of glyphs.
The material coloring technique depends on the selection
of appropriate structure colors which is a difficult task. Interesting filament regions could be overlooked when the coloring is not sufficiently rich in contrast. For example, yellow
on an otherwise white tube might not be detected. We chose
the color values for our volumetric structures according to
the color rules in [WGM∗ 08]. These rules perform best for
two or at most three overlapping or nested transparent structures. If more structures are used, false colors may occur.
We used highly simplified scenes for our second study.
This allowed the automatic, reproducible generation of comparable images, while minimizing potential impact of scene
properties that are not considered in the study design, like
c 2010 The Author(s)
Journal compilation c 2010 The Eurographics Association and Blackwell Publishing Ltd.

object geometry or number of lines, on perception. A disadvantage of this approach is that this task is simpler than real
tasks in medical or biological applications. An evaluation
of the techniques in more realistic scenes is desirable. Such
scenes have a higher number of volumetric structures and
filaments as well as branching filaments of various lengths.
Questions could be how the techniques perform for different
filament lengths or how the number of intersection points
influences accuracy. We think that (self-)occlusion of glyphs
might be a problem in scenes with a high number or densely
bundled intersection points. On the other hand, we think that
material coloring on its own might not be sufficiently obvious for very short traversals.
6. Conclusion
We evaluated several visualization techniques to improve
the perception of spatial relationships between filaments and
surrounding transparent structures. Two separate user studies proved some techniques to be very effective for this task.
Based on the first study’s results, we recommend the usage of halos and depth-based color modulation to enhance
the relative depth perception of filaments. The second study
showed that the correctness of recognized filament-surface
traversings significantly improves when filaments are colored according to their surrounding materials and glyphs are
shown at the intersection points. These techniques also accelerate the recognition time. We recommend their usage in
combined visualizations of filaments and surrounding surface structures, especially in the biomedical field.
Acknowledgements
We would like to thank Edwin P. Scholte, Magic Bullet BV,
Netherlands, for his technical support in creating the user
study Flash application. We would also like to thank Anja
Kühnlein for reviewing our statistics. Furthermore, we thank
everyone who participated in the user studies.

1012

A. Kuß et al. / Effective Techniques to Visualize Filament-Surface Relationships

References
[BALP09] BAER A., A DLER F., L ENZ D., P REIM B.:
Perception-based Evaluation of Emphasis Techniques Used in 3D
Medical Visualization. In Proceedings of the Vision, Modeling,
and Visualization Workshop (VMV ’09) (2009).
[BCFW08] BARTZ D., C UNNINGHAM D., F ISCHER J., WALL RAVEN C.: State-of-the-Art of the Role of Perception for Computer Graphics. In Proceedings of the 29th Annual Conference
Eurographics (EG 2008) (2008), pp. 65–86.
[BLB90] B ORTZ J., L IENERT G. A., B OEHNKE K.: Verteilungsfreie Methoden in der Biostatistik. Springer-Verlag Berlin Heidelberg New York, 1990.

[MSE∗ 06] M ERHOF D., S ONNTAG M., E NDERS F., N IMSKY
C., G UENTHER G REINER: Hybrid Visualization for White Matter Tracts using Triangle Strips and Point Sprites. IEEE Transactions on Visualization and Computer Graphics 12, 5 (2006),
1181–1188.
[OP05] O ELTZE S., P REIM B.: Visualization of Vasculature with
Convolution Curfaces: Method, Validation and Evaluation. IEEE
Transactions on Medical Imaging 24, 4 (2005), 540–548.
[PPP06] P OLTHIER K., P REUSS E., P INKALL U.: Locally Shortest Paths on Triangle Meshes. Personal communication, 2006.
[RHD∗ 06] R ITTER F., H ANSEN C., D ICKEN V., KONRAD V ERSE O., P REIM B., P EITGEN H.-O.: Real-Time Illustration
of Vascular Structures. IEEE Transactions on Visualization and
Computer Graphics 12, 5 (2006), 877–884.

[BoG∗ 09] B RUCKNER S., Ł OLTÉSZOVÁ V., G RÖLLER M. E.,
˚
H LAD UVKA
J., B ÜHLER K., Y U J., D ICKSON B.: BrainGazer
– Visual Queries for Neurobiology Research. IEEE Transactions on Visualization and Computer Graphics 15, 6 (2009),
1497–1504.

[SGS05] S TOLL C., G UMHOLD S., S EIDEL H.-P.: Visualization
with Stylized Line Primitives. In Proceedings of IEEE Visualization 2005 (2005), pp. 695–702.

[BPKW03] B RUN A., PARK H.-J., K NUTSSON H., W ESTIN
C.-F.: Coloring of DT-MRI Fiber Traces Using Laplacian
Eigenmaps. In Proceedings of the 9th International Conference on Computer Aided Systems Theory - (EUROCAST) (2003),
pp. 518–529.

[TIP05] T IETJEN C., I SENBERG T., P REIM B.: Combining Silhouettes, Surface, and Volume Rendering for Surgery Education
and Planning. In Proceedings of the Eurographics / IEEE VGTC
Symposium on Visualization (2005), Brodlie K., Duke D. J., Joy
K. I., (Eds.), Eurographics Workshop Series, pp. 303–310.

DE H ERAS C IECHOMSKI P., M ANGE R., P E A.: Two-Phased Real-Time Rendering of Large Neuron Databases. In Proceedings of the International Conference
on Innovations in Information Technology (2008), pp. 712–716.

[TMC∗ 91] T ROSCIANKO T., M ONTAGNON R., C LERC J. L.,
M ALBERT E., C HANTEAU P.-L.: The Role of Colour as a
Monocular Depth Cue. Vision Research 31 (1991), 1923–1390.

[dHCMP08]
TERNIER

[DWE02] D IEPSTRATEN J., W EISKOPF D., E RTL T.: Transparency in Interactive Technical Illustrations. Computer Graphics Forum 21, 3 (2002), 317–325.
[ER01] E BERT D., R HEINGANS P.: Volume Illustration: NonPhotorealistic Rendering of Volume Models. IEEE Transactions
on Visualization and Computer Graphics 7, 3 (2001), 253–264.
[Eri05] E RICSON C.: Real-Time Collision Detection. Morgan
Kaufmann, 2005.
[Gen09] G ENSEL M.: Visualisierungsmethoden zur Verdeutlichung der räumlichen Beziehungen zwischen linien- und
flächenartigen Strukturen am Beispiel neurobiologischer Daten.
Diploma thesis, Freie Universität Berlin, 2009.
[IFP95] I NTERRANTE V., F UCHS H., P IZER S.: Enhancing
Transparent Skin Surfaces with Ridge and Valley Lines. In
Proceedings of the 6th Conference on Visualization ’95 (1995),
pp. 52–59.
[IG97] I NTERRANTE V., G ROSCH C.: Strategies for Effectively
Visualizing 3D Flow with Volume LIC. In Proceedings of the
8th Conference on Visualization ’97 (1997), pp. 421–424.

[VG05] V IOLA I., G RÖLLER M. E.: Smart Visibility in Visualization. In Proceedings of Eurographics Workshop on Computational Aesthetics in Graphics, Visualization and Imaging (2005),
pp. 209–216.
[War08] WARE C.: Visual Thinking for Design. Interactive Technologies. Morgan Kaufmann, 2008.
[WB08] W EIGLE C., BANKS D. C.: A Comparison of the Perceptual Benefits of Linear Perspective and Physically-Based Illumination for Display of Dense 3D Streamtubes. IEEE Transactions on Visualization and Computer Graphics 14, 6 (2008),
1723–1730.
[WGM∗ 08] WANG L., G IESEN J., M C D ONNELL K. T., Z OL LIKER P., M UELLER K.: Color Design for Illustrative Visualization. IEEE Transactions on Visualization and Computer Graphics 14, 6 (2008), 1739–1754.
[ZSH96] Z ÖCKLER M., S TALLING D., H EGE H.-C.: Interactive Visualization of 3d-Vector Fields using Illuminated Stream
Lines. In Proceedings of the 7th Conference on Visualization ’96
(1996), pp. 107–ff.

[Int96] I NTERRANTE V.: Illustrating Transparency: Communicating the 3D Shape of Layered Transparent Surfaces via Texture.
PhD thesis, University of North Carolina at Chapel Hill, 1996.
[Lam08] L AMECKER H.: Variational and Statistical Shape Modeling for 3D Geometry Reconstruction. PhD thesis, Freie Universität Berlin, Fachbereich Mathematik und Informatik, 2008.
[LCD06] L UFT T., C OLDITZ C., D EUSSEN O.: Image Enhancement by Unsharp Masking the Depth Buffer. ACM Transactions
on Graphics 25, 3 (2006), 1206–1213.
[MMYK06] M ELEK Z., M AYERICH D., Y UKSEL C., K EYSER
J.: Visualization of Fibrous and Thread-like Data. IEEE Transactions on Visualization and Computer Graphics 12, 5 (2006),
1165–1172.
[MPSS05] M ALLO O., P EIKERT R., S IGG C., S ADLO F.: Illuminated Lines Revisited. In Proceedings of IEEE Visualization
2005 (2005), pp. 19–26.

c 2010 The Author(s)
Journal compilation c 2010 The Eurographics Association and Blackwell Publishing Ltd.

