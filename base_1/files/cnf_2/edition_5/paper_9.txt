DOI: 10.1111/j.1467-8659.2010.01837.x

COMPUTER GRAPHICS

forum

Volume 30 (2011), number 1 pp. 127–138

On Neighbourhood Matching for Texture-by-Numbers
Eliyahu Sivaks and Dani Lischinski
The Hebrew University of Jerusalem, Israel
{sivaks, danix}@cs.huji.ac.il

Abstract
Texture-by-Numbers is an attractive texture synthesis framework, because it is able to cope with non-homogeneous
texture exemplars, and provides the user with intuitive creative control over the outcome of the synthesis process.
Like many other exemplar-based texture synthesis methods, its basic underlying mechanism is neighbourhood
matching. In this paper we review a number of commonly used neighbourhood matching acceleration techniques,
compare and analyse their performance in the specific context of Texture-by-Numbers (as opposed to ordinary
unconstrained texture synthesis). Our study indicates that the standard approaches are not optimally suited for
the Texture-by-Numbers framework, often producing visually inferior results compared to searching for the exact
L2 nearest neighbour. We then show that performing Texture-by-Number using the Texture Optimization framework
in conjunction with an efficient FFT-based search is able to produce good results in reasonable running times and
with a minimal memory overhead.
Keywords: texture-by-numbers, texture synthesis, energy minimization, example-based rendering, texture
optimization, image analogies
ACM CCS: Computer Graphics [I.3.3]: Picture/Image Generation—Computer Graphics [I.3.7]: ThreeDimensional Graphics and Realism—color, shading, shadowing, and texture

retargeting, stitching, etc., may also be posed as a TbN task
(see Figures 2 and 7 for some examples).

1. Introduction
The ability to synthesize a texture from an exemplar is a useful operation, which has enjoyed considerable research attention in the past decade. Although many of the resulting texture
synthesis approaches are able to produce impressive results
when applied to homogeneous texture exemplars, larger nonhomogeneous exemplars still pose a challenge. Furthermore,
most existing approaches provide the user with only limited
control over the result.

Most recent exemplar-based texture synthesis methods use
neighbourhood matching as the basic mechanism underlying
the synthesis process. Given a neighbourhood centred around
a pixel in the generated image, one seeks the most similar
neighbourhood in the input exemplar, where similarity is
usually measured by the L2 (SSD) distance between the two
neighbourhoods. Thus, neighbourhood matching is equivalent to a nearest neighbour search in a high-dimensional
feature space. This search constitutes the computational bottleneck of these texture synthesis algorithms. A variety of
techniques have therefore been used to perform this search
quickly. A number of researchers (e.g. [WL00, HJO*01,
KEBK05]) proposed using various tree-based approximate
nearest neighbour algorithms. These techniques typically
employ PCA to reduce the dimension of the search space.
Another class of acceleration schemes is based on coherence
[Ash01, TZL*02, BSFG09].

Texture-by-Numbers (TbN), originally proposed in the
Image Analogies framework [HJO*01] is an elegant mechanism both for coping with non-homogeneous texture exemplars, and for intuitive creative control. By annotating the
input exemplar with a label map and specifying a desired
arrangement of these labels, the texture synthesis process is
guided to create a corresponding result, as demonstrated in
Figure 1. Thus, TbN may be used to synthesize complex nonhomogeneous compositions in an intuitive manner. Multiple
modern high-level image editing tasks, such as inpainting,
c 2010 The Authors
Computer Graphics Forum c 2010 The Eurographics
Association and Blackwell Publishing Ltd. Published by
Blackwell Publishing, 9600 Garsington Road, Oxford OX4
2DQ, UK and 350 Main Street, Malden, MA 02148, USA.

127

128

E. Sivaks & D. Lischinski / Neighbourhood Matching for Texture-by-Numbers

Figure 1: Texture-by-Numbers example: Aragonese. Left: The input image (top) and the corresponding label map (bottom,
produced using mean-shift segmentation). Right: Result (top) produced using the user supplied label map (bottom).
rowing the context in such a manner is necessary, since most
example-based texture synthesis results that one encounters
in the literature are typically produced in an unconstrained
manner from relatively small and mostly homogeneous exemplars. In contrast, in the TbN context we are primarily interested in highly constrained synthesis from larger images,
which consist of multiple visually distinct textured regions,
and expect the results to look like plausible images, rather
than like textures.

Figure 2: Inpainting via Texture-by-Numbers. Left: Input
image and its label map below, differentiating between the
foreground object (antenna) and the background. Right: result produced with a target label map containing only the
background label everywhere.

Some of these acceleration techniques were developed for
the general task of finding approximate nearest neighbours
in high-dimensional spaces (e.g. [MA06, ML09]), and for
the most part have been applied and tested in the context
of texture synthesis. In this paper we discuss some of the
commonly used techniques and examine their performance
(in terms of time, memory and quality of results) in the more
specific context of the TbN framework. We argue that nar-

Our study reveals that most of the standard acceleration techniques sometimes produce results that are visibly inferior to ones obtained by an exhaustive search of
the nearest L2 neighbour. We then describe a new TbN
synthesis algorithm, based on texture optimization, which
finds near-optimal matching neighbourhoods efficiently using FFT-based convolutions and coarse-to-fine refinement.
The optimization-based TbN algorithm is demonstrated to
produce better results that those produced by previous TbN
approaches, whereas the proposed search scheme consistently succeeds in producing results that are of comparable
quality to those produced with exhaustive nearest-neighbour
search, in addition to being memory efficient.
In the remainder of this paper we first review some
previous work in the area of example-based texture synthesis, and then focus of the suitability of the existing

c 2010 The Authors
Computer Graphics Forum c 2010 The Eurographics Association and Blackwell Publishing Ltd.

E. Sivaks & D. Lischinski / Neighbourhood Matching for Texture-by-Numbers

neighbourhood matching approaches for the TbN scenario
(Section 3). In Section 4 we describe the optimization-based
TbN algorithm and an accelerated FFT-based ANN scheme.
In Section 5 we experiment with this algorithm using different neighbourhood sizes and compare between several
different ANN schemes, as well as compare its results to
previous TbN methods.
2. Texture Synthesis and Texture-by-Numbers
This work falls within the realm of example-based texture
synthesis. A complete review of example-based texture synthesis methods is outside the scope of this paper, and we refer
the reader to the excellent survey by Wei et al. [WLKT09].
TbNs falls into the class of non-parametric texture synthesis
methods, which include pixel-based methods [EL99, WL00],
patch-based methods [EF01, KSE*03], optimization-based
methods [KEBK05] and appearance-space texture synthesis [LH06]. Pixel/patch based methods are able to reproduce a wide variety of textures by growing the texture one
pixel/patch at a time. Optimization-based methods evolve
the texture as a whole, by minimizing a suitably defined objective function. This typically improves the quality of the
results (compared to pixel/patch-based approaches) and also
makes the synthesis more controllable.
Most of the above methods do not cope well with nonuniform texture exemplars, which cannot be modelled by a
stationary Markov Random Field (MRF) model. A common
approach is to handle such textures with the aid of control
maps, sometimes referred to as label maps or feature maps
[Ash01, HJO*01, LH06, RCOL09]. In the Image Analogies
framework [HJO*01], these label maps also provide the user
with an important means of control over the desired outcome.
The idea, referred to as Texture-by-Numbers (TbN), is to augment the input exemplar with a label map, where regions
with distinct texture are typically assigned different labels.
A suitable label map may be painted manually by the user,
or created automatically using unsupervised image segmentation. To synthesize a new image, the user provides a target
label map, indicating how the different textures should be
arranged in the resulting image, as demonstrated in Figure 1.
A variety of additional high-level image editing tasks may be
reformulated in the TbN framework: for example, removing
a foreground object by inpainting (Figure 2), or performing
digital photomontage (Figure 7, bottom example).
The original Image Analogies work [HJO*01] builds upon
Ashikhmin’s coherent texture synthesis algorithm [Ash01],
combining it with Wei and Levoy’s [WL00] MRF-based approach, and generalizing these methods to the image analogies framework. More recently, Kwatra et al. [KEBK05]
introduced an EM-like optimization-based approach for texture synthesis, which generally performs better than earlier
pixel/patch-based methods. Thus, in this work we chose to
conduct our neighbourhood matching experiments within an
optimization-based TbN framework, which is an adaptation

129

of [KEBK05]. An alternative optimization-based approach is
the CMS (constrained minimization synthesis) algorithm described by Ramanarayanan and Bala [RB07]. They extend the
patch-based graphcut synthesis approach of [KSE*03] into a
global constraint minimization problem, which supports the
Image Analogies framework, including TbN. We compare
the results of these different approaches in Figure 7.

3. Neighbourhood Matching
The heart and the computational bottleneck of most MRFbased texture synthesis algorithms is the neighbourhood
matching operation, where the input exemplar is searched
for neighbourhoods that are the closest to a given neighbourhood in the generated result, where distance is typically
measured using the L2 -norm. Thus, each neighbourhood may
be viewed as a point in a high-dimensional (number of neighbourhood pixels times the number of channels) space, and
the goal is to find the nearest neighbour to a given query
point.

3.1. Tree-based search
Wei and Levoy [WL00] used tree-structured vector quantization (TSVQ) [GG92] to find an approximate nearest neighbour in logarithmic time. In this approach the points extracted
from the input exemplar are hierarchically clustered, and the
centroid of each cluster is stored at the corresponding tree
node. Given a query point, one descends the tree based on
the distance between the point and the centroids at the tree
nodes. Note that even if no quantization takes place, finding
the true nearest neighbour in a single descent is not guaranteed. Backtracking may be used to improve the search, but at
the cost of longer query times.
Several later methods also used tree-based search techniques, albeit with different data structures. Hertzmann
et al. [HJO*01] report somewhat better performance than
TSVQ using the approximate-nearest-neighbour (ANN) library [MA06], which is based on kd-trees, whereas Kwatra et
al. [KEBK05] use a hierarchy of clusters where each level is
computed using k-means (with k = 4). Since finding approximate nearest neighbours in high-dimensional feature spaces
is of much interest in many different fields, such algorithms
are the subject of ongoing research. In particular, Muja and
Lowe have recently released the FLANN library [ML09]
which simultaneously searches in multiple randomized kdtrees and/or hierarchical k-means trees, provides automated
parameter selection, and is reported to provide an order of
magnitude speedup over previously available software. Thus,
although this library has not yet been used for texture synthesis or TbN, we use it in our experiments in this paper as
the representative of tree-based methods.
Tree-based schemes have the drawback that they require
a non-trivial amount of pre-processing to construct the tree

c 2010 The Authors
Computer Graphics Forum c 2010 The Eurographics Association and Blackwell Publishing Ltd.

130

E. Sivaks & D. Lischinski / Neighbourhood Matching for Texture-by-Numbers

data structures (and to compute the principal components,
when dimensionality reduction is required). Note that a different data structure is necessary for each neighbourhood
size, and it is impossible to dynamically change the priorities
of different types of neighbourhoods during the synthesis
process. The memory overhead due to these data structures
can be very significant, if the input exemplar is large, as will
be demonstrated later.
3.2. Coherence-based search
Another alternative to speed up neighbourhood matching is
to make use of image coherence [Ash01, TZL*02, BSFG09].
In particular, a scheme known as k-coherence [TZL*02] is
considered by some as highly effective in terms of quality
and speed [WLKT09]. This scheme assumes that neighbourhoods centred around adjacent pixels in the synthesized result
often match adjacently centred neighbourhoods in the input
image. The input image is first pre-processed to identify for
each pixel k − 1 other pixels in the input which have the most
similar neighbourhood, forming a similarity set of size k (a
parameter of the scheme). Thus, instead of a tree structure,
one obtains a flat collection of similarity sets indexed by locations in the input. During synthesis each pixel is searching for
matches in the similarity sets determined by its already synthesized neighbours. Thus, the search takes constant, rather
than logarithmic time.
There are two drawbacks which k-coherence might suffer from. One is the excessive pruning of the search space
when k is small. The other is the pre-processing time: a knearest-neighbours search must be performed for each exemplar pixel. If the exemplar is sufficiently large, for example,
comparable in size to the output, like in the examples shown
in this paper, the pre-processing cost may be high to the point
that it offsets the saving achieved by the k-coherence scheme
during subsequent synthesis. In contrast, our optimizationbased TbN framework performs a nearest-neighbour search
at a much sparser set of locations. One could conceivably
reduce the k-coherence pre-processing costs by a sparse sampling of the input exemplar, but this would result in further a
priori pruning of the search space.
The PatchMatch algorithm, recently proposed by Barnes
et al. [BSFG09], also utilizes image coherence. Given two
images it quickly constructs a nearest neighbour field (a map
from the pixels of one image to their approximate nearest
neighbours in the second image) by starting from a random
guess and propagating good matches to neighbouring pixels.
A potential drawback of this method is that it may get stuck
in local minima. To reduce the chances of this happening,
random searches are performed in addition to propagating
matches. PatchMatch is capable of providing a reasonable
approximation of the nearest-neighbour field very fast, but
further improvements in accuracy, which we found to be
necessary for the TbN task, are difficult to achieve, even with
additional random searches and iterations.

3.3. TbN-specific challenges
Although the neighbourhood matching techniques mentioned earlier typically produce adequate texture synthesis
results, we argue that the TbN framework presents these
methods with several specific challenges. First, it is important to understand that TbN’s main appeal lies in its ability to
take as input entire images, rather than homogeneous texture
samples, and produce plausible images as result. Although
relatively small neighbourhoods are often sufficient to synthesize a homogeneous texture, when synthesizing an entire
image, larger neighbourhoods are often needed to reproduce
a plausible higher level structure: it is not enough for each
small patch in the synthesized result to closely resemble one
in the input image, since the arrangement of small elements
often has a semantic meaning, even when these elements
belong to what might be considered a homogeneous texture
region. This is demonstrated in Figure 5, which will be further discussed in Section 5.
Increasing the size of the neighbourhood poses a problem
for the tree-based acceleration schemes mentioned earlier,
because the dimensionality of the search grows quadratically
with the diameter of the neighbourhood, although the number of points in the training set (the input image) remains
the same. High dimensionality of the original search space
does not necessarily imply that the space inherent to the
nearest-neighbour problem is large as well. To our knowledge, all of the texture synthesis methods that perform dimensionality reduction of the search space employ PCA for
this task (e.g. [HJO*01, KEBK05, LH06, KFCO*07]). These
methods typically reduce the dimensionality down to 20–30,
because they use the kd-tree based ANN library, which is
reported to work best up to about 20 dimensions [MA06].
Thus, we decided to conduct an experiment to examine the
impact of PCA dimensionality reduction on the accuracy of
subsequent nearest-neighbour search.
In most of our experiments we found that to produce satisfactory results, neighbourhood sizes between 11 × 11 and
27 × 27 were needed. Consequently for images with four
channels (three colour channels and a label channel) the dimension of the search is between 484 and 2916. Thus, we
chose to use 11 × 11 neighbourhoods in our experiment.
Given an input image (shown in Figure 4, the corresponding label map can be found in Supporting Information), we
extract for each pixel its 11 × 11 neighbourhood, and blur
one quarter of the neighbourhood. This models the situation
where part of the pixel’s neighbourhood is constrained, or
has already been well reconstructed by the synthesis process
so far, although the remaining part resembles (but does not
match exactly) the existing image input neighbourhoods.
Given these perturbed neighbourhoods as input, exhaustive search without dimensionality reduction almost always
manages to find and return the original image location from
which the neighbourhood was extracted. To examine the

c 2010 The Authors
Computer Graphics Forum c 2010 The Eurographics Association and Blackwell Publishing Ltd.

131

E. Sivaks & D. Lischinski / Neighbourhood Matching for Texture-by-Numbers
Table 1: The impact of PCA dimensionality reduction on the accuracy of exhaustive nearest neighbour search. The experiment was
performed on the image in Figure 4 using 11 × 11 × 4 neighbourhoods.

Dimensions
Correct %
Memory (MB)

100
484
100
1058

99.5
234
98.9
511

99
173
96.9
378

97
101
86.9
220

95
74
70
161

90
38
12
81

100%
7000

Memory Requirements (MB)

PCA %

8000

99.5%

6000
5000

99%
4GB

4000
3000

2GB

2000

95%
90%

1000

effect of PCA dimensionality reduction on the accuracy of
the search we subjected the original neighbourhoods to a
variety of PCA projections (progressively reducing the dimension of the search space). The same PCA projections
were applied to the perturbed (partially blurred) neighbourhoods. Table 1 shows in each column the accuracy of the
PCA projection (as the percent of the total spectrum retained
by each projection), the resulting reduced dimension of the
feature space, the percent of the image pixels for which the
correct match was recovered (using exhaustive search), and
the memory necessary to store the exemplar’s feature points
(without accounting for any overheads due to the search data
structure). The results show that reducing the dimensionality from 484 to 38 results in 88% of the searches failing to
recover the optimal match that would have been found if no
dimensionality reduction took place. In other words, there is
a significant reduction in the accuracy of the neighbourhood
matching that results just from reducing the dimensionality,
even before any approximate nearest neighbour schemes are
applied.
Although this experiment clearly shows that the matching
accuracy suffers from dimensionality reduction with PCA,
we wanted to check whether such amounts of inaccurate
matches already lead to visible artefacts, and discovered this
is indeed the case. This is demonstrated in Figure 4, which visualizes the resulting matches (nearest neighbour field) using
pseudocolour. Each nearest neighbour field is then used to
reconstruct the image in two different ways: (i) mean reconstruction, which averages at each pixel all of the overlapping
matched neighbourhoods (middle column); and (ii) centre
pixel reconstruction, which assigns each pixel the value at
the centre of the best matching neighbourhood returned by
the search. The visualization reveals that these errors indeed
result in visible artefacts: blur in mean reconstruction, and
noise in centre pixel reconstruction.
Another difficulty associated with the desire to use large
neighbourhoods with tree-based acceleration data structures
is their large memory footprint. These data structures store
the input feature vectors explicitly (storing only the corresponding image locations is time-inefficient since then each
feature vector must be retrieved and PCA-projected every
time it is accessed by the search procedure). Figure 3 plots

0

0

97%

5

10

15

20
25
Window Size

30

35

40

Figure 3: Memory requirements for storing the feature vectors of a 640×430 (0.35MP) image as function of window
size. The percentage next to each line is the percent of the
spectrum preserved by the corresponding PCA projection.
the memory requirements for storing the feature vectors extracted from the 640 × 430 image in Figure 4 as a function
of neighbourhood (window) size. The plots reveal that for
windows around 25 × 25 around 1GB of RAM would be
required for this image, even after significant PCA dimensionality reduction, and before accounting for the overhead
of the tree data structure itself.
4. Texture-by-Numbers via Optimization
Our goal is now to compare several nearest-neighbour
schemes in the context of their intended application—TbNs.
As pointed out earlier, we conduct our experiments within a
new optimization-based TbN, which we found better suited
for the task than the original Image Analogies framework
[HJO*01] or the CMS algorithm [RB07]. Thus, in this section we describe this optimization-based approach, followed
by a number of experimental comparisons in Section 5.
Our approach is based on the EM-like texture optimization framework of Wexler et al. [WSI04] and Kwatra et al.
[KEBK05]. The original algorithm proceeds from coarse to
fine resolution. At each resolution it alternates between two
main steps: the M-step, which matches the neighbourhoods
in the synthesized result X to those in the input exemplar Z,
and the E-step, which estimates new values for the pixels in
X based on the matches found in the M-step.
Our adaptation of this algorithm for TbN is given in pseudocode in Algorithm 1. Several changes were necessary:
First, we need to incorporate the label maps into the optimization process, such that the synthesis would be guided
and constrained by these maps. We do this by adding the
label map as a soft constraint channel in addition to the
three colour channels, both for the input exemplar Z, and
the synthesized result X. Thus, when matching a given

c 2010 The Authors
Computer Graphics Forum c 2010 The Eurographics Association and Blackwell Publishing Ltd.

132

E. Sivaks & D. Lischinski / Neighbourhood Matching for Texture-by-Numbers

Figure 4: Visual impact of PCA dimensionality reduction. The top four rows correspond to PCA projections that preserve
the following percent of the spectrum (top to bottom): 100%, 97%, 95% and 90%. The left column visualizes the recovered
nearest-neighbour field by using the x coordinate as the green channel and the y coordinate as the red one. The bottom row
shows a comparison between zoomed-in sub-windows.

c 2010 The Authors
Computer Graphics Forum c 2010 The Eurographics Association and Blackwell Publishing Ltd.

133

E. Sivaks & D. Lischinski / Neighbourhood Matching for Texture-by-Numbers
Algorithm 1: Texture-By-Numbers via Optimization
1:
2:
3:
4:
5:
6:
7:
8:
9:
10:
11:
12:
13:
14:
15:

for pyr = MaxPyramidLevel:-1:1 do
if pyr = MaxPyramidLevel then
XRGB {pyr}⇐ Random
else
XRGB {pyr}⇐ Upsample(XRGB {pyr +1})
end if
for all ws in WindowSizeList{pyr} do
repeat
XC ⇐ constraint {pyr}
zp ⇐ nearest neighbor of xp in Z, ∀p ∈ X†
X ⇐ ReconstructMode(X†; {zp })
prev
until zp = zp , ∀p ∈ X †
end for
X{pyr}⇐ X
end for

neighbourhood in X to the neighbourhoods in Z (M-step,
line 10), we take into account not only the colours of the
pixels, but their labels as well. However, unlike the colour
channels of X (denoted X RGB ), the constraint channel of X
(denoted X C ) is reset at each iteration to the initial target
label map (line 9). Parameter w controls the weight of the
colour channels (relative to the constraint channel) in the
evaluation of the L2 norm. Typical values are in [0.1, 3].
This scheme allows some flexibility in the labels assigned
in transition regions, rather than enforcing them as a hard
constraint. This flexibility is important when no exact match
can be found. Reseting the constraint channel at the end of
each iteration limits the deviation from the original label
constraints. Another difference from the original texture optimization method is that, rather than averaging the values
of overlapping neighbourhoods covering each pixel in the
E-step (line 11), we use the mode of this set of values. This
idea (originally proposed by [WSI07]) reduces blur in the
result.
As in the original texture optimization framework, not every neighbourhood in X participates in the M-step. Rather,
only a subset of the neighbourhoods X † (chosen so that there
is still sufficient overlap) is used. The optimal spacing between these neighbourhoods depends on the particular image.
In the results shown in this paper we used a spacing of sW
pixels, where W is the width of the neighbourhood and s is
a sparsity factor in the range [0.15, 0.4]. This significantly
reduces the number of nearest-neighbours queries compared
to performing the search at every pixel: for example, for s =
0.25 and W = 27, the number of nearest-neighbour queries
is 2% of the output image size.
Perhaps the most important parameter in our approach
are the neighbourhood (window) sizes used as the synthesis
proceeds. At each pyramid level we start with larger window
sizes to capture large structures and then gradually reduce

the size to conceal seams and smooth the transitions between
the larger elements. At the three coarsest pyramid levels we
start with 7 × 7 windows and go down to down to 3 × 3. On
finer levels window sizes range from 27 × 27 down to 13 ×
13. The impact of window size on TbN will be discussed in
the next section.
To perform the M-step (line 11) we have experimented
with tree-based approximate nearest neighbour schemes using the FLANN library [ML09], as well as with PatchMatch
[BSFG09]. In addition, we implemented a new scheme to
perform a more exact nearest neighbour search. The most
efficient method for computing the exact nearest neighbour
is obtained by rewriting the computation in terms of convolutions, which may be computed efficiently using the Fast
Fourier Transform (FFT), as proposed in [KSE*03]. For
completeness, we will describe this approach in more detail below. However, rather than using this scheme as is, we
achieve a considerable speedup by applying it at a coarser
level of the input exemplar, and then refining the results to
obtain a highly accurate approximate nearest neighbour at
higher resolutions.
FFT-based search. Let xp denote the vector formed by concatenating the values of the neighbourhood centred at pixel p
in the synthesized image X. Similarly, let zq denote the vector corresponding to the neighbourhood centred at pixel q in
the input image Z. Given xp , the nearest L2 neighbourhood
in Z is given by
NN(xp , Z) = argminq∈Z xp − zq
= xp

2
2

+ argminq∈Z

2
2

zq

2
2

− 2 xp · zq

2

.
(1)

Note that the first term above does not depend on q, whereas
the term zq 22 does not depend on p, and thus may be precomputed once per input image. The remaining term xp ·
zq 2 may be evaluated for all possible positions q by convolving the input image Z using xp as the convolution kernel. The computational cost of a single FFT-based search is
O(N log N ), where N is a number of pixels in Z. The total
cost of the entire M-step is hence O(M · N log N ), where M
is a number of searches, which is significantly smaller then
the size of X due to sparsity factor s.
Further acceleration. As shown earlier, finding the nearest
neighbour for a query patch Q in an image Z boils down
to computing the convolution Q∗Z and searching the result
for the global minimum. Rather than performing the convolution and the search using the full resolution of Q and Z,
we perform the convolution using downsampled versions Q
and Z . The downsampling factor is typically between 1/4
and 1/6 in each dimension. Next, we search for the k smallest local minima of Q ∗Z . Finally, we go back to the full
resolution image Z and search the vicinity (window of size

c 2010 The Authors
Computer Graphics Forum c 2010 The Eurographics Association and Blackwell Publishing Ltd.

134

E. Sivaks & D. Lischinski / Neighbourhood Matching for Texture-by-Numbers

Table 2: Timings and parameters for the results shown in this paper.
The IA and CMS images for the Aragonese example are included in
the supplementary material.

Runtime (min)
Size

IA

CMS

Our

w

s

462×320
436×320
426×568
305×328
768×1024
675×1102

7
2
2
−
−
27

2
3
3
−
−
20

5
5
5
2
22
16

0.3
0.2
0.1
5
0.7
0.2

0.25
0.25
0.25
0.4
0.25
0.4

Image
Arc
Gog rock
Bronze
Frankenface
Antenna
Aragonese

Parameters

2W ) around each of these k locations for the neighbourhood
that best matches Q.
Of course, it is possible that because of the downsampling
none of the k local minima of Q ∗Z lie sufficiently close to
the global minimum of Q∗Z. To reduce the chance of this
being the case, we downsample the exemplar image Z twice,
using staggered lower resolution grids. If the global minima of both downsampled versions match, we only search
around that location in the full resolution image. Otherwise,
we search around all the different local minima locations
from both images. Using this strategy with k = 8 local minima, we found that we obtain the true global minimum (i.e.,
the same result that would have been obtained by a full
search) for about 95% of the queries, while speeding up the
query time by a factor up to 20 ×, compared to linearly
searching for a global minimum in Q∗Z. The cost of an Mstep then becomes O(M · k · nlog n), where n is the size of
the searched vicinity.
It should be noted that because the above approach performs the search by computing convolutions on the fly,
it requires virtually no memory overhead on top of storing the input exemplar and the synthesized result image
pyramids.

5. Comparisons
We have implemented the TbN algorithm described in the
previous section in Matlab, which calls a mex library written
in C++ for each of the compared nearest-neighbour search
techniques. In our FFT-based search, all the FFT transforms
are done using the FFTW library. Figures 1, 2 and 7 show a
variety of results produced using this approach. Timings and
some other relevant statistics are reported in Table 2. Some
additional results may be found in the Supporting Information. All times are were measured on a dual-core 3.00 GHz
CPU with 4 GB of RAM.
Figure 5 demonstrates the importance of using large window sizes when using TbN to synthesize realistic images.

The results in the left column were generated using a fixed
window size of 7 × 7, whereas the results in the other two
columns were generated larger window sizes (specified in
the Figure). As can be seen, larger window sizes tend to include more fine detail in the textures, typically yielding more
realistic results.
Figure 6 compares between several different nearest neighbour schemes in the context of our optimization-based
TbN approach. Specifically, we compare exhaustive search
(A)–(C) (with and without the effects of PCA dimensionality reduction), our FFT-based approximate search (D), treebased ANN using the FLANN library [ML09] (E), and PatchMatch [BSFG09] (F). We have not included k-coherence in
this comparison, since for an input exemplar of this size (675
× 1102) the number of k-nearest-neighbours queries that
would be necessary to perform in the pre-processing step
alone already exceeds the total number of nearest neighbour
queries that are done in the course of the entire execution of
our optimization-based TbN algorithm.
It took our approach 16 min to generate the result in (D),
which uses our FFT-based search. Although this result is not
identical to the one produced by exhaustive search (A), we
find the visual quality of the two results to be comparable.
When either FLANN or PatchMatch are used it is possible
to obtain a result faster, with the exact time depending on the
parameter settings of these two methods. Thus, to produce a
meaningful and fair comparison, we adjusted the parameters
for both FLANN and PatchMatch to obtain the best result
that these schemes could produce within the same time as our
scheme (16 min). Specifically, the parameter in FLANN with
the most direct impact on the accuracy of the search is the
number of tree traversals (backtracking) allowed for a single
search. To produce the result shown in (E) this parameter was
set to 300. As may be seen in the zoomed-in images below
the visual quality of this result is somewhat inferior to ours,
because structures are less well preserved. A result of higher
quality may be obtained by increasing the above parameter
further, but at the expense of additional computation time.
The PatchMatch result (F) exhibits some discontinuities and
some artefacts are visible along the transition between the
castle and the sky. The reason for these artefacts is that the
method is stuck in a local minimum. PatchMatch uses random
sampling to escape local minima, but in this case we were
not able to escape it even after considerably increasing the
number of random samples.
It should be noted that the result achieved using FLANN
(E) does come very close to the quality of the exhaustive
search using 99% PCA. Thus, FLANN does an excellent job
in the PCA-truncated search space. Unfortunately, without
PCA, the dimensionality is too high for FLANN to handle.
Letting FLANN run using its default parameters produces a
result four times faster, but the visual quality is noticeably
inferior. When PatchMatch is run using its default parameters
a result visually similar to (F) is obtained.

c 2010 The Authors
Computer Graphics Forum c 2010 The Eurographics Association and Blackwell Publishing Ltd.

E. Sivaks & D. Lischinski / Neighbourhood Matching for Texture-by-Numbers

135

Figure 5: Impact of window size on TbN synthesis results. The images shown in the top row are a zoomed-in view on a portion
of the result shown in Figure 1; the bottom row images are taken from a result in the supplementary material. All these images
were generated with our approach using FFT-based search and the same window sizes for the three coarsest levels ( [7 × 7]
– [3 × 3]), but using different window sizes for the finer levels, whose ranges is listed above each column. Although the target
label arrangement is met in all three cases, using smaller window sizes leads to excessive smoothing and loss of certain fine
details, undermining the realism of the result.
Finally, in Figure 7 we compare our optimization-based
TbN algorithm to the previous TbN approaches of Image
Analogies (IA) [HJO*01] and CMS [RB07]. The IA and the
CMS images in the example Arc were produced by the original authors, whereas those in the examples Gog and Bronze
were generated using code provided by the original authors,
after we have experimented with various combinations of parameters to produce the best looking results. Because all three
methods compared here are very different from each other, it
was not possible to arrange a comparison with identical parameter settings. Additional comparisons and the parameters
used to produce each result are included in the Supporting
Information.
In general, we observe that since IA looks at fairly small
neighbourhoods, and generates the image in scanline order,
it often fails to faithfully reproduce textured regions containing larger features than the used neighbourhood size. This
can be seen, for example in the Bronze example. As for the

CMS method, as acknowledged in [RB07], in areas of transition between different labels it tends to generate each of the
adjoining regions independently. As a result, transitions between regions with different texture often do not look natural.
This may be seen well in examples such as Arc and Bronze
the Arc and Bronze examples, where objects look flat, rather
than three-dimensional. Another drawback of CMS may be
observed in the Gog example, where it generates a large uniformly textured element (the sky) using large patches with a
visible seam between them.
In contrast, our approach is able to faithfully reproduce
large structures, and manages to better convey the threedimensional nature of the synthesized shapes. In addition
to the comparisons with IA and CMS, we also show the
Frankenface example from the digital Photomontage work
[ADA*04], performed using the TbN framework. Here, the
TbN algorithm is modified slightly to fix only the stitch region
after copying and pasting the faces.

c 2010 The Authors
Computer Graphics Forum c 2010 The Eurographics Association and Blackwell Publishing Ltd.

136

E. Sivaks & D. Lischinski / Neighbourhood Matching for Texture-by-Numbers

Figure 6: Comparison between different nearest neighbour schemes in the context of the same TbN algorithm and task. All of
the results shown are generated using our optimization-based TbN method with the same window sizes, and the only difference
is in the nearest-neighbour search. A zoomed in portion is shown under each result. The parameters of (E) and (F) were set up
so as to fit into the same time budget as (D): 16 min.

c 2010 The Authors
Computer Graphics Forum c 2010 The Eurographics Association and Blackwell Publishing Ltd.

E. Sivaks & D. Lischinski / Neighbourhood Matching for Texture-by-Numbers

137

Figure 7: Our TbN results. The top three examples include a comparison with Image Analogies (IA) and with CMS, a Digital
Photomontage instance is at the bottom.
c 2010 The Authors
Computer Graphics Forum c 2010 The Eurographics Association and Blackwell Publishing Ltd.

138

E. Sivaks & D. Lischinski / Neighbourhood Matching for Texture-by-Numbers

6. Conclusions
We have analysed, discussed and compared a variety of
example-based texture synthesis acceleration schemes from
the standpoint of the TbN framework. A new TbN approach
was then presented, that uses an approximation to exact
convolution-based nearest neighbor search. A comparison
of our results with previous methods demonstrates the visual
quality of the proposed approach. The obvious drawback of
this approach is its computational cost, which is still quite
high despite the use of FFT to speed up the computation of
convolution and our coarse-to-fine acceleration strategy. It
would be interesting to experiment with a GPU-based implementation of this approach, since we believe it is well suited
for it.
We hope that this paper would stimulate further research
of better approximate nearest neighbour methods, that would
be better suited for the large neighbourhoods characteristic
to the TbN task. Another important direction is to explore
additional neighbourhood similarity metrics, which are better
correlated with human visual perception than the L2 norm.
References
[ADA*04] AGARWALA A., DONTCHEVA M., AGRAWALA M.,
DRUCKER S., COLBURN A., CURLESS B., SALESIN D., COHEN
M.: Interactive digital photomontage. ACM Transactions
on Graphics 23 (2004), 294–302.
[Ash01] ASHIKHMIN M.: Synthesizing natural textures. In
Proceedings of Symposium on Interactive 3D Graphics
(Durham, NC, USA, 2001), Research Triangle Park, pp.
217–226.
[BSFG09] BARNES C., SHECHTMAN E., FINKELSTEIN A.,
GOLDMAN D. B.: Patchmatch: A randomized correspondence algorithm for structural image editing. ACM Transactions on Graphics 283, 24 (2009), 1–11.
[EF01] EFROS A. A., FREEMAN W. T.: Image quilting for texture synthesis and transfer. In Proceedings of SIGGRAPH
2001 (2001), pp. 341–346.
[EL99] EFROS A. A., LEUNG T. K.: Texture synthesis by
non-parametric sampling. In Proceedings of ICCV ’99 2
(1999), pp. 1033–1038.
[GG92] GERSHO A., GRAY R. M.: Vector Quantization and
Signal Compression. Kluwer Academic Publishers, Massachusetts, 1992.

Transactions on Graphics 24, 3 (Proc. SIGGRAPH 2005)
(2005), 795–802.
[KFCO*07] KOPF J., FU C.-W., COHEN-OR D., DEUSSEN O.,
LISCHINSKI D., WONG T.-T.: Solid texture synthesis from 2d
exemplars. ACM Transactions on Graphics (Proceedings
of SIGGRAPH 2007) 26, 3, 2 (2007), 1–9.
[KSE*03] KWATRA V., SCHO¨ DL A., ESSA I., TURK G., BOBICK
A.: Graphcut textures: image and video synthesis using
graph cuts. ACM Transactions on Graphics 22, 3 (Proc.
SIGGRAPH 2003 ) (2003), 277–286.
[LH06] LEFEBVRE S., HOPPE H.: Appearance-space texture
synthesis. ACM Transactions on Graphics 25, 3 (Proc.
SIGGRAPH 2006 ) (2006), 541–548.
[MA06] MOUNT D. M., ARYA S.: ANN: A library for approximate nearest neighbor searching. http://www.cs.umd.edu/
mount/ANN/, 2006.
[ML09] MUJA M., LOWE D. G.: Fast approximate nearest
neighbors with automatic algorithm configuration. In Proceedings of International Conference on Computer Vision
Theory and Applications (VISAPP’09) (Lisboa, Portugal,
2009), INSTICC Press, pp. 331–340.
[RB07] RAMANARAYANAN G., BALA K.: Constrained texture
synthesis via energy minimization. IEEE Transactions
on Visualization and Computer Graphics 13, 1 (2007),
167–178.
[RCOL09] ROSENBERGER A., COHEN-OR D., LISCHINSKI D.:
Layered shape synthesis: automatic generation of control
maps for non-stationary textures. ACM Transactions on
Graphics 28, 5 (2009), Article 107.
[TZL*02] TONG X., ZHANG J., LIU L., WANG X., GUO B.,
SHUM H.-Y.: Synthesis of bidirectional texture functions
on arbitrary surfaces. ACM Transactions on Graphics 21,
3 (Proc. SIGGRAPH 2002 ) (2002), 665–672.
[WL00] WEI L.-Y., LEVOY M.: Fast texture synthesis using
tree-structured vector quantization. In Proceedings of the
27th Annual Conference on Computer Graphics and Interactive Techniques (SIGGRAPH ’00) (New York, NY,
USA, 2000), ACM Press/Addison-Wesley Publishing Co.,
pp. 479–488.
[WLKT09] WEI L.-Y., LEFEBVRE S., KWATRA V., TURK G.:
State of the art in example-based texture synthesis. Eurographics 2009 State of The Art Report, April 2009.

[HJO*01] HERTZMANN A., JACOBS C. E., OLIVER N., CURLESS
B., SALESIN D. H.: Image analogies. In SIGGRAPH ‘01:
Proceedings of the 28th Annual Conference on Computer Graphics and Interactive Techniques (New York,
NY, USA, 2001), ACM Press, pp. 327–340.

[WSI04] WEXLER Y., SHECHTMAN E., IRANI M.: Space-time
video completion. Proceedings of CVPR 2004 1 (2004),
120–127.

[KEBK05] KWATRA V., ESSA I., BOBICK A., KWATRA N.:
Texture optimization for example-based synthesis. ACM

[WSI07] WEXLER Y., SHECHTMAN E., IRANI M.: Space-time
completion of video. IEEE Transactions on Pattern Analysis and Machine Intelligence 29, 3 (2007), 463–476.

c 2010 The Authors
Computer Graphics Forum c 2010 The Eurographics Association and Blackwell Publishing Ltd.

