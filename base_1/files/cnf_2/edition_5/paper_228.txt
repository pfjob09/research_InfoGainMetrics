DOI: 10.1111/j.1467-8659.2011.02066.x

COMPUTER GRAPHICS

forum

Volume 30 (2011), number 8 pp. 2354–2366

Visualisation Techniques for Using Spatial Augmented Reality
in the Design Process of a Car
Christoffer Menk1 , Eduard Jundt1 and Reinhard Koch2
1 Volkswagen

Group Research, Wolfsburg, Germany
{christoffer.menk, eduard.jundt}@volkswagen.de
2 Institute of Computer Science, Christian-Albrechts-University of Kiel, Germany
rk@mip.informatik.uni-kiel.de

Abstract
If spatial augmented reality is used in the design process of a car, then one of the most important issues is that the
virtual content is projected with a very high visual quality onto the real object, because based on this projection
design decisions are made. Especially, the visualised colours on the real object should not be distinguishable
from corresponding real reference colours. In this paper, we introduce a new approach for the augmentation of
real objects which is able to match the requirements of a design process. We present a new rendering method
with ray tracing which increases the visual quality of the projection images in comparison to existing methods.
The desired values of these images have further to be adjusted according to the material, the ambient light and
the local orientation of the projector. For this purpose, we develop a physically based computation which exactly
determines the corresponding projection intensities for these values by using three-dimensional lookup tables at
every projector pixel. Since not all of the desired values can be represented with an intensity of the projector, an
adjustment has to be computed for these values. Therefore, we conduct a user study with design experts who work
in the automotive industry and use the results to propose a new adjustment method for such values. Finally, we
compare our methods to existing procedures and conclude which ones are suitable for the design process of a car.
Keywords: virtual and augmented reality, ray tracing, radiometric compensation, projector-camera-systems
ACM CCS: I.3.3 [Computer Graphics]: Picture/Image Generation—I.4.8 [Image Processing and Computer
Vision]: Scene Analysis—I.4.9 [Image Processing and Computer Vision]: Applications.

1. Introduction
The automotive industry uses a lot of virtual content for
designing, developing and assessing new components of a
car. This virtual content is traditionally visualised by using a
monitor, projection wall or CAVE. However, real objects, e.g.
hardware mockups, are still used and preferred in most steps
of the design process, because the designer has a more realistic assessment of the components in reality. Therefore, spatial
augmented reality is interesting for such a process, because it
is a technique, where projectors are used to visualise the virtual content directly on the real object. Thus, the number of
required hardware mockups as well as the number of design
iterations could significantly be reduced by using one basic
real object and projected virtual contents. In such a scenario,
c 2011 The Authors
Computer Graphics Forum c 2011 The Eurographics
Association and Blackwell Publishing Ltd. Published by
Blackwell Publishing, 9600 Garsington Road, Oxford OX4
2DQ, UK and 350 Main Street, Malden, MA 02148, USA.

the virtual content represents different colours, variants or
arrangements of components and has only small geometric
deviations to the geometry of the real object. Therefore, a
tracking of the designer is not absolutely necessary, but it is
even more important that the content is presented with a high
visual quality. Especially, the colours appearing on the real
object should be realistic, because based on this projection
design decisions are made. For this purpose, it is necessary to
account for the ambient light, the material, the colour model
and the local orientation of the projector. We address all these
issues by applying a new method which uses a physicallybased computation with ray tracing. This method is able to
achieve a visual quality which is sufficient for the design
process (Figure 1).

2354

C. Menk et al. / Spatial Augmented Reality in the Design Process

2355

Figure 1: Images taken with a real camera from a brown real object (a) which is augmented with a projector: (b,c,d)
Our physically-based method is used to visualise one uniform colour on the brown real object. The projected colour is not
distinguishable from the corresponding real reference colour which is marked with a white circle.
1.1. Related work
Raskar et al. [RWLB01] presented the idea of shader lamps,
where projectors are used to project additional graphical content onto a real object. There are two main issues for spatial
augmented reality applications: (1) A projection image of the
virtual content has to be created which is seen undistorted by
an observer, when it is projected onto the real object. (2) This
projection image has further to be radiometrically compensated according to the surface reflectance, the ambient light,
the illumination of the projector and of course the perception
of the observer.
Generation of projection images: The projection images
can be created with a two-pass rendering approach using
projective textures which was introduced by Raskar et al.
[RWC∗ 98]. The projective textures step of the two-pass rendering approach can be replaced with an image warping.
In this case, a camera is placed in the viewing position of
the observer. The information for the warping is determined
by a detection of the projector pixels with structured light
techniques. This approach was used in applications where
the geometry of the scene is unknown [NPGN03, GPNB04,
BEK05]. A distributed rendering system, which is able to
compute the projection images for multiple projectors and
moving projection surfaces, was presented in [YSN∗ 10]
All described approaches can be applied in real-time, but
are likely to produce visible artefacts, because the pixels of
the observer image and that of the projection image have

different and varying sampling rates on the real object (Figures 2(a–c)). These artefacts can be minimised to some degree by choosing a higher resolution of the observer image
(Figure 2(d)) or if the projection surface is flat, by selecting
an optimal viewing position (Steele et al. [SJY08]).
Radiometric compensation: Raskar et al. [RWLB01] considered the reflectance of a neutral surface and the local orientation of the projector to the real object, but no ambient
light or colour adjustment was taken into account. Nayar
et al. [NPGN03] projected onto arbitrary flat surfaces by using a radiometric model which minimises the effects of the
surface imperfections. The colour mixing between each projector and corresponding camera pixel was described with a
3 × 3 colour mixing matrix. This matrix can be represented
unnormalised and expanded with a fourth row to account for
the ambient light [YHS03]. The radiometric model was enhanced by Grossberg et al. [GPNB04] by using the fact that
the non-linear projector response is the same for all projector
pixels. The described techniques create clipping artefacts if
a value is out of the projection range [BIWG08] and additionally, no indirect illumination between the projector pixels
was considered. One way to extend the range of projectable
values is to use multiple projectors as proposed by Bimber
et al. [BEK05] or a transparent film [BCK∗ 05].
Other techniques consider besides the projection surface
also the content for the radiometric compensation of the projection image. Wang et al. [WSOS05] applied an error metric according to the human perception to compensate gray

Figure 2: (a) Viewing position of projector: Real object which should be augmented with graphical content; (b) Observer image
with the desired virtual content which is used to produce the projection image; Projection image which is computed with the
two-pass rendering approach from an observer image with (c) the same resolution as the projector and (d) a four times higher
resolution than that of the projector; (e) Projection image computed with our approach using the projector resolution.
c 2011 The Authors
Computer Graphics Forum c 2011 The Eurographics Association and Blackwell Publishing Ltd.

2356

C. Menk et al. / Spatial Augmented Reality in the Design Process

projection images. A more complex photometric adaptation
was proposed by Ashdown et al. [AOSS06], where a luminance and chrominance fitting was applied according to
certain specified properties. Their work considers both, a radiometric model of the system and the content of the image,
but is not applicable to real-time applications. A radiometric
compensation technique which preserves a maximum of luminance and contrast and runs in real-time was proposed in
[GB08].
Wetzstein and Bimber [WB07] proposed a technique
which additionally considers the global illumination by computing the full light transport between projector and camera.
They used a global scaling factor which was derived from
the average luminance of the projection image. Light transport matrices between multiple projectors and a camera and
an energy minimisation method were also applied to change
the physical appearance of deteriorated objects [ALY08].
The light transport was captured in both applications with
the technique proposed by Sen et al. [SCG∗ 05]. The drawback is that it takes several hours to capture all information.
Sheng et al.[SYC10] presented a method which interactively
minimises the difference between the desired and actual illumination for a setup with multiple projectors, but no ambient
light or colour model of the projectors was considered.
The described techniques store the relation between projection intensities and resulting colours on the real object in
two captured images or in a colour mixing matrix for every single pixel. These approaches are not accurate enough
for colour critical applications. Therefore, traditional colour
profiling techniques are able to replace this matrix with a
complex three-dimensional lookup table (3D LUT) for the
characterisation of monitors [KHM10] or projectors which
display content onto a planar screen [TCH∗ 08]. For these
traditional displays, it is sufficient to measure the 3D LUT
for a limited number of pixels over the monitor or screen and
to interpolate the 3D LUT for all other pixels.
This procedure is not applicable to our scenario, because
the projector displays the content onto a complex real object
and therefore, a 3D LUT would have to be captured for every
single projector pixel. This would be time-consuming and
would require a lot of memory, especially if spectral values
are used. Furthermore, the captured information contains for
both of the techniques, namely 3D LUT and colour mixing
matrix, the surface reflectance, the colour and depending on
the technique also the ambient light. The information has
thus to be recaptured, if the position of the projector or the
real object is exchanged.

1.2. Main contributions and overview
We describe in Section 2, a technique for the generation of
projection images with ray tracing which directly creates the
necessary information for every pixel of the projection image

(Figure 2(e)) and therefore, does not create the described
visual artefacts (Section 1.1).
Instead of measuring the 3D LUTs for every single pixel,
we measure a 3D LUT once for one single pixel and use
a physically based computation to determine the individual
3D LUTs for every other projector pixel (Section 3). Our
approach has the advantage that real objects can be easily
exchanged and the projector can be moved without measuring the 3D LUT of the projector again. Furthermore, it
achieves a high accuracy so that projected colours are not
distinguishable from real reference colours (Figure 1).
The visualisation of real reference colours on the real object is only possible, if they are inside the gamut of each
projector pixel. Colours out of range have to be mapped into
the corresponding gamut (Section 3.2.2). In our scenario, the
gamut of each projector pixel varies over the complete real
object due to the different influences of ambient light, real
object and projector. Furthermore, the projected content is
seen by an observer under these influences in contrary to a
presentation on a traditional display. To account for these
influences, we conduct a user study where design experts are
asked to adjust colours and use the results to create a new
adjustment method (Section 3.3). This method is, in contrast
to the methods in [AOSS06, GB08], scalable so that it is able
to meet the individual preferences of every designer. Finally,
a second user study is performed to evaluate which methods
are suitable for the design process of a car (Section 4).
2. Generation of projection images
For the rendering techniques, which are described in this section, the geometric relationships between the projector, the
real object and the observer have to be known. For this purpose, we determine the intrinsic parameters of the projector
as described in [MK10]. The calibrated projector is geometrically registered to the real object by shifting a cross-hair to
known 3D coordinates [RWLB01]. These correspondences
between 2D and 3D coordinates are used to compute the pose
of the projector to the real object. The viewing position of
the observer is defined for automotive scenarios, but could
also be tracked with an optical measurement system. There
are also other geometric registration techniques, but since
this is a well-discussed topic in research, we do not further
describe it in this paper and the interested reader is referred to
[BIWG08]. An evaluation of geometric registration methods
can be found in [MJK10].
The information of the geometric registration is used to
create a projection image of the virtual content which appears undistorted to the observer, when it is projected onto
the real object. Such a projection image can be created from
an observer image by using the two-pass rendering approach
with projective textures. The approach is sketched in Figure 3(a) and can lead to visible artefacts in the projection
image as mentioned in Section 1.1. The problem is that the

c 2011 The Authors
Computer Graphics Forum c 2011 The Eurographics Association and Blackwell Publishing Ltd.

C. Menk et al. / Spatial Augmented Reality in the Design Process

2357

projection image with our proposed method, but also by using ray tracing to account for global illumination effects like
reflections which are important for automotive applications.
Since automotive applications use ray tracing to create such
high quality images, our approach can easily be integrated
into existing software.

3. Radiometric compensation
We use a physically-based rendering software and thus, the
projection image, whose creation was described in the previous section, consists of radiance values L. These values
describe the desired radiance on the surface of the real object. Therefore, the local orientation of the projector to the
real object, the ambient light, the material of the real object
and the colour model of the projector have to be considered
to create projection intensities which result in the desired
radiance values L on the real object.

3.1. Material and ambient light

Figure 3: Principle of generating a projection image.
information for a projector pixel like p1 has to be interpolated from the corresponding pixels of the observer image.
The quality of the projection can be increased by choosing a
higher resolution for the observer image.

In this paper, we consider two real objects with different
materials which are shown in Figures 1(a) and 4(a) as a
projection surface. These real objects are used in a design
process of a car and are made of a gray or brown diffuse material. The spectral reflectance of the surface is determined
by taking measurements on different positions on the surface
of the real objects with a spectrophotometer. The average of
these measurements is used as the overall surface reflectance.

2.1. Rendering approach with ray tracing
Our new approach is sketched in Figure 3(b) for two projector pixels p1 and p2 . We trace for every projector pixel
the ray towards the real object and compute the intersections
with the projection surface at p1 and p2 . Then, the rays from
the observer viewing position towards the intersections are
derived. The ray tracing process is started with rays like r2
on the virtual content. Note that also a super-sampling for the
complete area of the intersections at p2 can be performed and
used to compute the value for the corresponding projector
pixel p2 . An advantage is that our approach does not need
an observer image and that the ray tracing is done for every
projector pixel so that no unnecessary information is computed. Our approach leads to equal sampling rates on the real
object for the observer and projection image and therefore,
achieves a higher visual quality than the two-pass rendering
approach with projective textures.
A big advantage of the two-pass rendering approach without ray tracing is that it can be used in real-time, but in the
design process of a car the visual quality is more important.
The visual quality is not only increased by generating the

Figure 4: (a) Image captured with a real camera and (b)
physically-based rendering of the real object, which is placed
on a black box; (c) Comparison between measured and rendered radiance values on nine positions on the real object
which are marked with a white circle in (a).

c 2011 The Authors
Computer Graphics Forum c 2011 The Eurographics Association and Blackwell Publishing Ltd.

2358

C. Menk et al. / Spatial Augmented Reality in the Design Process

The ambient light is measured and integrated into the computation as proposed in [MK10]: A high dynamic range (HDR)
map is taken of the surrounding environment and is scaled to
match the true radiance values of the scene. The scaling factor is determined by taking measurements of the environment
with a spectroradiometer. Finally, the captured environment
is mapped onto the room geometry and is used as a light
source in our rendering.
This method allows us to compute renderings which consist of the ambient light values on the real object for arbitrary
projector or observer positions. An example for a rendering
of the real object compared to the real scene is shown in Figure 4. The comparison between measured and rendered radiance values shows that there are only small and neglectable
differences between reality and computation. Similar results
are obtained with the brown real object.

3.2. Computation of projection values
The relation between radiance values on the real object and
projection intensities is described in our approach by using
a 3D LUT for every single projector pixel. This table is built
from measurements of intensity combinations of the different
channels. Previous works did not consider such a complex
model, because the storage of such a table for every single
pixel would require a lot of memory, e.g. using a 12 × 12 ×
12 grid, a resolution of 1400 × 1050 pixels and a precision of
16-bit, would require 5.1 GB. Our idea is to use a physicallybased computation and thus, it is sufficient that the 3D LUT is
only stored for one pixel (3.3 MB), because the 3D LUTs for
all other pixel of the projector are computed by incorporating
the material, the ambient light and the local orientation of the
projector. This idea is sketched in Figure 5 and is explained
in this section.
The projector, whose intrinsic parameters are calibrated in
advance, is geometrically registered to the real object. Then,
a spectroradiometer is used to measure the spectrum Lv (p,
I, λ) of different projection intensities I = (R, G, B) at a
specific projector pixel p for wavelengths λ from 380 to 780
nm with a step size of 1 nm (Figure 5, step 1). The projection
intensities I are created by dividing the RGB intensity axes
into arbitrary steps. The influences of different step sizes are
evaluated in Section 4. We use the estimated pose of the
projector and the geometry of the real object to transform
the measurements Lv (p, I, λ) from the measuring position
to the projection centre which results in the values Lc (I, λ)
(Figure 5, step 2). This is shown in Eq. 1, where np denotes
the normal of the surface at pixel p, rp is the normalised
vector from pixel p towards the real object with distance dp
and m(p, λ) is the reflectance of the diffuse material for a
specific wavelength λ.
Lc (I , λ) =

Lv (p, I , λ) π dp2
−rpT np m(p, λ)

(1)

Figure 5: Idea of using a physically-based computation to
determine the projectable radiance values. The derived values Lc (I, λ) can also be used to compute the projectable
values on the brown real object.

Note that the measurements are taken without ambient
light. Otherwise, an additional measurement of the ambient
light spectrum has to be taken and subtracted from Lv (p, I,
λ). The values of the ambient light which were computed in
Section 3.1 cannot be used for this purpose, because they are
represented in a 3D colour space. It is very important that
the derived values Lc (I, λ) are independent of the material,
the ambient light and the local orientation of the projector
whereas the orientation is represented by the distance dp and
the ray rp towards the pixel p on the real object. Therefore,
the derived values can be used in a scenario where the real object is exchanged, the projector changes position or different
ambient light is used without measuring the projection intensities again. This is sketched in Figure 5, where the values
Lc (I, λ) are also used to compute the projectable spectrum at
arbitrary pixels on the brown real object. For this purpose,
Eq. 1 is extended to compute the resulting spectrum L(q, I,
λ) of an intensity I at an arbitrary pixel q which is shown in
Eqs. 2 and 3.
L(q, I , λ) =

Lc (I , λ) −rqT nq m(q, λ)

L(q, I , λ) = Lv (p, I , λ)

π dq2
−rqT nq m(q, λ) dp2
−rpT np m(p, λ) dq2

(2)

(3)

The values L(q, I, λ) for an arbitrary pixel q should be
directly computed by using Eq. 3. If Eqs. 1 and 2 is applied
one after another, then this will lead to numerical problems,

c 2011 The Authors
Computer Graphics Forum c 2011 The Eurographics Association and Blackwell Publishing Ltd.

2359

C. Menk et al. / Spatial Augmented Reality in the Design Process
Table 1: Deviation between measured and computed radiance values if Eq. 3 is used with spectral or XYZ values: The Lv (p, I, λ)
values are measured on the gray real object for intensities I = (R,
G, B) with R, G, B ∈ {0, 50, . . . , 200, 255} and used to compute the
corresponding values L(q, I, λ) on the brown real object.
Spectral

CIE XYZ

Average
0.002 [Wm2 /sr] ( E∗ = 0.6) 0.008 [Wm2 /sr] ( E∗ = 4.9)
Maximum 0.004 [Wm2 /sr] ( E∗ = 1.3) 0.015 [Wm2 /sr] ( E∗ = 8.8)

because the values for Lc (I, λ) will get very large. We are
trying to use spectral values as long as possible to achieve a
higher accuracy. This is also the reason why we do not use a
calibrated HDR camera to take the measurements. The difference between a computation of Eq. 3 with spectral versus
CIE XYZ values is shown in Table 1. Note that there is no
deviation between these computations if the materials m(p,
λ) and m(q, λ) would be equal, because the other factors are
equal for all wavelengths.
So far, we have computed the projectable spectrum for
different intensities at specific positions on the real object
(Figure 5, step 3). These values are now converted into the
CIE XYZ space, because the values of the desired result and
the ambient light are not in the spectral domain (Figure 5, step
4). Since the projectable values also depend on the present
ambient light, this light has to be added (Eq. 4). The ambient
light was computed in Section 3.1 and x, y and z are the CIE
standard observer functions.

λ

y(λ)L(q, I , λ)dλ + Yamb (q)

Y (q, I ) =

If a desired value XYZdes (q) for a pixel q is inside the gamut,
then it is included by the computed 3D grid GXYZ (q). The coordinates of the value inside this grid can be determined
by using tetrahedral division and barycentric coordinates
[Hun92]. The tetrahedral division is applied to the 3D grid
GXYZ (q) of XYZ values (X(q, I), Y(q, I), Z(q, I)), which describe the projectable values for a specific pixel q. Note that
every point of this grid corresponds to a certain projection
intensity I = (R, G, B) and a tetrahedron of this grid is formed
by four values (X(q, Ii ), Y(q, Ii ), Z(q, Ii )) with i ∈ {0, 1, 2, 3}.
The barycentric coordinates α, β and γ of a desired value
XYZdes (q) corresponding to a tetrahedron can be computed
by using Eq. 5, where Xi = X(q, Ii ), Yi = Y(q, Ii ) and Zi =
Z(q, Ii ).
⎛
⎞
⎛ ⎞
Xdes (q) − X0
α
⎟
−1 ⎜
⎝β ⎠ = MXY
(5)
Z ⎝ Ydes (q) − Y0 ⎠
γ
Zdes (q) − Z0
⎛

(4)

X1 − X0

⎜
MXYZ = ⎝ Y1 − Y0
Z1 − Z0

X2 − X0
Y 2 − Y0
Z2 − Z0

X3 − X0

⎞

⎟
Y3 − Y0 ⎠ (6)
Z3 − Z0

If the barycentric coordinates α, β and γ are inside [0, 1]
and α + β + γ
1, then the desired colour value is inside
the tetrahedron and Eq. 7 can be used to determine the final
intensity Ides (q) = (Rdes (q), Gdes (q), Bdes (q)).
⎛ ⎞ ⎛ ⎞
α
R0
Ides (q) = MRGB ⎝β ⎠ + ⎝G0 ⎠
(7)
B0
γ
⎛

x(λ)L(q, I , λ)dλ + Xamb (q)

X(q, I ) =

3.2.1. Handling values inside the gamut

R1 − R0

R2 − R0

R3 − R0

⎞

⎜
MRGB = ⎝ G1 − G0

G2 − G0

⎟
G3 − G0 ⎠ (8)

B1 − B0

B2 − B0

B3 − B0

λ

Z(q, I ) =

z(λ)L(q, I , λ)dλ + Zamb (q)
λ

The computed values (X(q, I), Y(q, I), Z(q, I)) for the projected intensities I represent a 3D grid of XYZ values for
every projector pixel q on the real object. These grids are different for every pixel q and represent the gamut. We denote
these grids as GXYZ (q) (Figure 5, step 5). Additionally, we
have for every projector pixel a desired value XYZdes (q) =
(Xdes (q), Ydes (q), Zdes (q)), which was created during the rendering of the projection image as described in Section 2.1.
Such a desired value does not need necessarily to be represented by an intensity of the projector, because the projectable
values depend on the ambient light, material and local orientation of the projector. Therefore, the next sections describe
how an intensity can be found which is a good choice for the
representation of the desired value.

Since it is very time-consuming to compute the barycentric coordinates for all created tetrahedrons, we implemented
a bounding box approach so that not all tetrahedrons have to
be tested for an inclusion of the desired value. Note that the
interpolation between the measurements is an approximation, because the projection values are non-linearly related.
The error caused by this approximation gets smaller as more
measurements are made which results in a finer resolution
of the grid GXYZ (q) for a pixel q. Instead, the relation of the
projection intensities could also be made more linear by optimising the grid structure [TCH∗ 08] or by using a gamma
correction for each colour channel.
3.2.2. Handling values outside the gamut
There are several intents of handling colours outside the
gamut which are known from traditional displays. For our

c 2011 The Authors
Computer Graphics Forum c 2011 The Eurographics Association and Blackwell Publishing Ltd.

2360

C. Menk et al. / Spatial Augmented Reality in the Design Process

scenario, we consider in a first step the relative colorimetric rendering intent which maintains the exact relationship
between colours inside the gamut while colours outside the
gamut are clipped. This intent is adapted for our scenario with
two methods which describe the mapping of colours outside
the gamut while values inside the gamut are computed with
the 3D LUT method as described in the previous section.
E∗ − Min: The idea behind this approach is very simple: Values which are outside the gamut are visualised by
choosing a projectable value which has the smallest E∗
distance. For this purpose, the grid, representing the gamut
of the corresponding projector pixel, is converted to the CIE
LAB colour space which results in the values LAB(q, I) =
(L∗ (q, I), a∗ (q, I), b∗ (q, I)), where (L∗ , a∗ , b∗ ) are the coordinates of the CIE LAB colour space. The desired colour
value XYZdes (q) is also transformed to this colour space and
is denoted as LABdes (q) = (L∗des (q), a∗des (q), b∗des (q)). The CIE
LAB colour space has the advantage that it is perceptually
uniform. Thus, the Euclidean distances E∗ between different values in this colour space are equally perceived by an
observer. We want to find the projection intensity which has
the smallest distance to the desired value LABdes (q). This is
described in Eq. 9.
min E ∗ (q, I ) = min LAB(q, I ) − LABdes (q)
I

I

2

(9)

A simple approach would be to create the projection values for all discrete intensities I by interpolating between the
values of the transformed grid GLAB (q) and to search for the
projection value with the smallest E∗ . Since the desired
value is outside the grid, an elaborate approach is to interpolate the projection values at the boundary of the grid and to
determine their distance towards the desired value.
E∗ab − Min: This approach is very similar to the one
described above, but it neglects the lightness L∗ (q, I) and
only finds an intensity which has the smallest distance in
terms of the chromaticity coordinates a∗ (q, I) and b∗ (q, I)
which is described in Eq. 10.
min
I

∗
ades
(q) − a ∗ (q, I )

2

∗
+ bdes
(q) − b∗ (q, I )

2

(10)

Figure 6: Setup for our user study. The design experts should
replicate the real colour checker by choosing appropriate
projection intensities. The colours with a white circle are
inside the gamut and are therefore the only colours which
can be exactly represented by a projection intensity.

Therefore, we conduct a user study with 10 design experts,
working in the automotive industry, to see how they would
adjust such values. Additionally, the methods proposed in
the previous section, namely E∗ − Min and E∗ab − Min,
should be evaluated in comparison to the designer’s choice.
The setup for the experiment is shown in Figure 6: A real
colour checker, which tiles are measured with a spectroradiometer, and a ceiling of a colour checker were attached to
the brown real object. A projector was used to visualise the
computed or selected colours onto the ceiling of the colour
checker. The design experts should use a colour dialog to
select the most satisfying colour for every tile of the colour
checker. The following steps were conducted by every expert:
1. For every tile, the expert should select the most satisfying colour. The current tile for selection was randomly chosen by the program. When all projection
intensities for the tiles were selected, the expert had
the chance to adjust the overall appearance.

The minimum distance is determined by constructing a
ray from the desired value towards the boundary of the corresponding grid GLAB (q) whereas the points on the ray have
a varying lightness value, but the same chromaticity coordinates as the desired value. This can lead to a projection image
which creates values with good chromaticity coordinates on
the real object, but the overall luminance may be different
from the desired one.

2. In this step, one tile of the colour checker was chosen
and three projected colours were randomly shown to
the expert: own choice and result from E∗ − Min
and E∗ab − Min. The expert should evaluate all three
projected colours with a value from 1 to 7 where 7
means that he is totally satisfied with the visualisation
in reference to the corresponding tile of the real colour
checker. This step was repeated for all tiles of the
colour checker.

3.3. First user study

3. The overall visualisation of the projected colour
checker was rated in this step. The complete three
colour checkers ( E∗ − Min, E∗ab − Min and own
choice) were projected in random order and the

The previous section proposed two of many different possibilities how values outside the gamut could be handled.

c 2011 The Authors
Computer Graphics Forum c 2011 The Eurographics Association and Blackwell Publishing Ltd.

2361

C. Menk et al. / Spatial Augmented Reality in the Design Process
Table 3: Results from rating the overall appearance (step 3).

Figure 7: Images taken with a real camera from: (a) our
∗
setup; (b) E − Min which is equal to GLA(0;1;1); (c)
∗
Eab − Min; (d) GLA(1;0.2;0); (e) GLA(0.15;0;1); (f) Result of first user study from one expert and (g) the average of
the results of all experts; The visualisations of the different
colour checkers are shown to the design experts in a final
user study.
Table 2: Average ratings in the user study (step 2). The boldface
numbers indicate tiles that are inside the gamut of the corresponding
projector pixels and every number corresponds to the average of the
ratings for one tile of the projected colour checker (Figure 6). The
∗ indicates if the values are statistically significantly higher than a
rating of 5 with p = 0.05 and df = 9.
User’s choice
4.8
6.0∗
2.0
4.7
E∗ − Min

3.5
4.3
3.0
4.0

3.0
2.3
5.4
2.5

4.8
4.2
4.9
1.5

4.7
5.1
2.9
1.1

5.4
5.5∗
4.9
1.6

5.1
5.4∗
3.3
1.1

5.3
5.7∗
5.1
2.6

3.5
5.3∗
2.2
1.3

Computed average of all tiles: 3.7
5.1
5.7∗
2.2
6.4∗

E∗ab − Min

3.6
3.2
3.0
4.7

6.0∗
3.3
3.8
6.6∗

4.3
5.5∗
3.9
6.2∗

3.7
3.2
5.8∗
3.6

Computed average of all tiles: 4.5
3.2
5.8∗
1.8
6.4∗

6.1∗
3.2
2.4
6.4∗

4.0
5.5∗
3.1
6.1∗

2.8
2.2
5.5∗
4.8

Computed average of all tiles: 4.2

design expert should judge how the overall appearance satisfies him. Examples for these colour checkers are shown in Figures 7(b), (c) and (f) .

∗

∗

User selection

E − Min

Eab − Min

4.4 (σ = 1.07)

3.7 (σ = 1.06)

4.1 (σ = 1.29)

els. Note that for these colours, the E∗ab - and E∗ − Min
methods compute an identical projection intensity, because
they both use the 3D LUT method for colours inside the
gamut. These colours got a very good rating with a significantly higher value than 5 (p = 0.05 and df = 9) whereas a
rating of 5 can be seen as a minimum acceptable level for a
usage in the design process. Therefore, our 3D LUT method
is able to visualise colours inside the gamut with an acceptable high quality. The results show further that the 10 design
experts gave the best ratings to the E∗ − Min method when
only one tile was shown (step 2), which can be seen in the
ratings for all single tiles and the computed average value of
these ratings in Table 2. This is not surprising, since the E∗
metric works in a perceptual space.
When the experts rated the overall appearance of the complete projected colour checker (step 3), then the E∗ − Min
method got the lowest rating which can be seen in Table 3.
However, these overall values cannot be absolutely compared
due to their large standard deviation σ , but we noticed that
7 of the 10 design expert gave a higher rating to their own
choice compared to E∗ − Min. Therefore, we took a look
at the values which were selected by the different experts
and ask them about their ratings. It was surprising that the
chosen colours of the first and fourth step have only small
deviations. Furthermore, it could be seen that the experts
tried to preserve the chromaticity coordinates of the desired
colours. Some of the designers also adjusted colours which
are inside the gamut and tried to preserve the relative lightness between the colours and stated that they did not like
the visualisation of the blue colours which got too purple
with the E∗ − Min method. Thus, the choice of the designers corresponds more to a perceptual colorimetric rendering
intent than to a relative one (Section 3.2.2). Therefore, we
propose a new method which tries to preserve the chromaticity coordinates of the colours and the relative lightness of the
real colour checker. Furthermore, this method is scalable so
that each designer can adjust the result to fit his individual
preferences. This method is explained in the next section and
should get a higher rating for the overall appearance which
is further examined in a second user study (Section 4.3).
3.4. Global lightness adjustment (GLA)

4. Step 1. was repeated.
The different ratings of all design experts are presented in
Table 2. The boldface ratings illustrate if the corresponding
colour is inside the gamut of the corresponding projector pix-

We present a scalable method, denoted as global lightness
adjustment (GLA), which extends the E∗ − Min method
by computing an adjustment for all lightness coordinates
of the desired values. After the adjustment, the values

c 2011 The Authors
Computer Graphics Forum c 2011 The Eurographics Association and Blackwell Publishing Ltd.

2362

C. Menk et al. / Spatial Augmented Reality in the Design Process

which are out of the projection range are handled with the
E∗ − Min method (Section 3.2.2) and values inside the
projection range are computed by using the 3D LUT method
(Section 3.2.1). The adjustment can be modulated with three
different weights c1 , c2 and c3 to match the designer’s personal preferences. We abbreviate this method with GLA(c1 ;
c2 ; c3 ) in the following sections. The weights are used to
compute a global scale factor Sg and a global additive value
Ag . Both values are used to adjust the lightness L∗ (q) of all
pixels q so that the relative lightness between all desired
values is preserved. The function used for the adjustment is
∗
shown in Eq. 11, where Ldes is the average lightness value
of all pixels q. In a first step, the minimum L∗min (q) and maximum lightness values L∗max (q) for every desired value of a
pixel q according to the grid GLAB (q) are determined. This is
done by using ray tracing. In a second step, the adjustment is
computed by minimising the distance for all pixels q which
is shown in Eq. 12.
∗

∗

f (q) = L∗des (q) − Ldes Sg + Ldes + Ag
[c1 g(q) + c2 |f (q) − Ag | + c3 Ag ]

min

Sg ,Ag

g(q) =

(11)

(12)

q

0

L∗min (q) ≤ f (q) ≤ L∗max (q)

∗

Figure 8: The lightness values L are adjusted with the proposed GLA method for different weights.

is used as our ray tracer, because it can compute HDR projection images with radiance values. The rendering of the
observer image takes 12 and of the ambient light 3 min on
two Intel Xeon X5570 processors, but could be improved by
using a newer ray tracing software. All other computations
are done with MATLAB on a single processor. The radiometric compensation of the created projection images takes
about 3 min for the virtual content (Figure 9 ) and 20 s for the
colour checker (Figure 7). The compensation of the colour
checker takes less time, because it covers a smaller area of
the projection image.

h(q) otherwise

h(q) = min{|L∗min (q) − f (q)|, |L∗max (q) − f (q)|}
The function g(q) describes the distance from the adjusted
value towards the gamut of the projector pixel q. The second
and third term compute the distance towards the original values and consider separately the scaling Sg and shifting Ag of
the values. These terms can be adjusted by the three weights
c1 , c2 , c3 which can be interpreted as follows: The first weight
c1 determines how important it is that the values are inside
the gamut. c2 denotes how strong the relative lightness between each value should be preserved and the last weight.
c3 determines how important it is that the original values are
maintained. These weights can be defined by a designer to
account for his personal preferences and we found that these
weights are easier to handle than directly choosing the scale
factor and additive value. An example for a fitting with different weights can be seen in Figure 8. These weights are
also used for our final user study. If weights of c1 = 0, c2 =
1, c3 = 1 are chosen, then the values are not adjusted and
this would correspond to the E∗ − Min method presented
in Section 3.2.2. Results from the different approaches which
are also used for a final user study are visualised in Figure 7.

4. Results
The experiments are performed with a Canon Xeed SX6 projector which has a resolution of 1400 × 1050 pixels. The
physically-based rendering software RADIANCE [War94]

4.1. Generation of projection images
The scenario for our setup is shown in Figure 9(a). The virtual content, which should be projected onto the real object,
is rendered under the recorded ambient light to increase the
visual appearance. We render for our experiments observer
images with a scale factor between 1.0× and 4.0× according to the projector resolution for the two-pass rendering
approach and compare the results to our ray tracing method.
The computed projection images are visualised on a real
object to see their final appearance and captured with a real
camera (Figure 9). The extracted details of the results clearly
show that our approach achieves a better visual result than
the approach with projective textures if the observer image
has the same resolution as the projector (1.0×). The results
show that if a 2.0 times higher resolution is used for the observer image that this might not lead to a projection image
with a very high quality. An observer image with a 4.0 times
higher resolution is necessary to achieve a result equivalent
to the result of our ray tracing approach using the projector
resolution (1.0×). Furthermore, if we render with our method
a projection image with a scale factor of 2.0 which results
in a super-sampling, then we will get a visual quality which
is not achieved by any scale factor of the projective textures
approach. In summary, the results show that there will always
be a loss in the visual quality if the two-pass rendering approach is applied, because the information for the projection
image is interpolated from the observer image.

c 2011 The Authors
Computer Graphics Forum c 2011 The Eurographics Association and Blackwell Publishing Ltd.

C. Menk et al. / Spatial Augmented Reality in the Design Process

2363

Figure 10: Measured and averaged accuracy of the different
approaches for visualising eight different colours on the two
real objects. The measurements are taken on nine different
positions on each of the real objects, which results in 72
measurements for each method on the corresponding object.

3D LUT method and the method which uses a colour mixing
matrix [GPNB04]. The intensities are also computed without
the consideration of ambient light or the local orientation of
the projector, to examine the influences of these components.
Furthermore, we also choose different grid sizes for our 3D
LUT method to evaluate their influences on the accuracy.

Figure 9: Final results captured with a real camera. The
projection images are computed by (b–d) using the two-pass
rendering approach with projective textures or (e, f) our new
proposed method which uses ray tracing. The resolution is
defined with a scale factor according to the projector resolution (1400 × 1050 pixels).

4.2. Projection of real colours
This section evaluates the accuracy of our 3D LUT approach
to visualise colours which are inside the gamut of the projector and compares it to the method using a colour mixing
matrix. The experiment is conducted with both real objects
which are shown in Figures 1(a) and 11(a). As described in
Section 3.2, the gamut of each projector pixel depends on
the material, the ambient light and the local orientation of
the projector. Therefore, we determine for every real object
eight, randomly selected, CIE XYZ values which are inside
the gamut for most of the projector pixels. A big advantage
of our method is that a real object can be easily exchanged
without measuring the 3D LUT of the projector again. Thus,
we measure different projection intensities for one pixel on
the brown real object and use our physically based approach
to compute the projectable values at all other pixels as well
as for all pixels on the gray real object. The projection intensities are determined with two methods: Our proposed

A spectroradiometer is used to measure the eight chosen
CIE XYZ values which are inside the gamut of the projector
on nine different positions on the real object, which results in
72 measurements for each method on the corresponding object. We use the same positions on the real object which were
already used for the comparison of the ambient light [Figure 4(a)]. We compare these measured values to the desired
CIE XYZ values and are therefore able to give a statement
about the accuracy of the different methods. The measured
results are presented in Figure 10 and visual results where
a real reference colour should be visualised on the complete
real object are captured by a camera and shown in Figure 11.
The results clearly show that our approach with a 3D LUT
performs very well, since the average E∗ value is equal
to 1.0 and 0.95 for both models. The projected colours are
not distinguishable from each of the eight desired values,
because a E∗ of 2.3 is denoted as the just noticeable difference [ST97] and also the maximum values are below this
threshold. Furthermore, the result shows that the E∗ value
gets larger as the size of the grid gets smaller. Also the local
orientation and ambient light have great influences on the
result. Thus, it is necessary that these components are taken
into account for the design process of a car. The approach
using a colour mixing matrix achieves good results for the
gray object with an average value of E∗ = 2.4, but on the
brown object the average value is with E∗ = 5.6 very large.
The accuracy of this approach depends on the desired value,
since the matrix assumes a linear relationship after gamma
correction. The result of the approach using a colour mixing matrix might be good enough to adjust a video, but if
the projection should represent real reference colours, then

c 2011 The Authors
Computer Graphics Forum c 2011 The Eurographics Association and Blackwell Publishing Ltd.

2364

C. Menk et al. / Spatial Augmented Reality in the Design Process
Table 4: Results from the second user study where the design experts rated the different adjustment methods. The boldface numbers
indicate the best result from the three specified weights of the GLA
methods.
Average
∗
GLA(0;1;1)
GLA
GLA
Eab - Colors 1. of user
∗
Method [ E − Min] (0.15;0;1) (1;0.2;0) Min
study choices
Rating

Average
Std. dev.

Figure 11: Images taken with a real camera from the results;
(a) Real object which is used in the design process of a car. A
colour which is equivalent to a real reference colour (white
circle) is projected with different methods onto real object:
(b) 3D LUT (12 × 12 × 12) where no local orientation or (c)
no ambient light is considered; (d,e,f) Colour mixing matrix;
(g, h, i) 3D LUT (12 × 12 × 12) with consideration of all
influences. Note that the colour checker is illuminated with
a second light source to lift the reference colours into the
gamut of the projector. Please zoom in to see more details.
this method is not sufficient. In summary, it can be seen that
our 3D LUT approach with a physically based computation
performs very well and can be used for a design process in
the automotive industry, because it can accurately represent
colours which are inside the gamut.
4.3. Second user study
This user study was conducted two weeks after the first user
study (Section 3.3), because the participants should not remember their colour choice and ratings. We conducted this
study to see what adjustment methods should be applied to
colours out of range and which ones are suitable for the design process of a car. For this purpose, colour checkers which
are adjusted with different methods and projected onto the
real object are shown to the 10 design experts. Images of
these colour checkers can be seen in Figure 7 where Figure 7(f) is always replaced with the colour checker which
the expert made in the first user study. The expert should rate
how he is satisfied with the result compared to the real colour
checker. The rating is a value between 1 and 7, where 7 is
the best value. The complete result of this study is shown in
Table 4.
If we only consider each method for itself, then the best
rating with a value of 4.5 is achieved with the average values

7
5
5
4
4
3
5
3
4
4

3
3
4
5
5
5
3
3
3
2

1
4
2
4
3
6
6
5
5
5

4
3
3
2
2
3
3
2
4
4

6
2
6
6
2
6
4
4
5
4

7
5
2
4
2
2
5
7
6
5

4.4
1.2

3.6
1.1

4.1
1.7

3.0
0.8

4.5
1.6

4.5
2.0

of all colour checkers which were created by the design
experts in the first study and the individual choice of every
expert. However, some of the experts also give a very low
value to their created colour checker from the first user study.
In contrary to the first study, the E∗ − Min method achieves
a higher rating, with a value of 4.4, and the E∗ab − Min a
lower value of 3.0. However, the average values for all of
these methods do not give a clue about what method would be
the best choice, because they have large standard deviations.
This is also the case if we take a look at the overall ratings for
different weights of our proposed GLA method. The result
shows that every design expert has his own preferences for
the adjustment of colours and therefore, one adjustment for
all experts is not sufficient. However, it can be seen that at
least one of the three tested specifications of weights of the
GLA methods gets a rating which is higher than 5. So our
proposed method does not always achieves the highest rating,
but is able to get a rating which is acceptable with a value
of 5 for the design process. Therefore, our method is able to
meet the different preferences of the design experts. Since the
weights were chosen by us, an evaluation has to be conducted
if a higher rating could be achieved when the design experts
where able to adjust the weights by themselves.

5. Conclusions and future work
We examined in this paper the use of spatial augmented reality for the design process of a car. For this purpose, we
presented a new rendering technique which creates the projection images with ray tracing. This method does not interpolate the values for the projection image and therefore,
achieves a higher visual quality than existing approaches.
Furthermore, we used a physically-based computation to

c 2011 The Authors
Computer Graphics Forum c 2011 The Eurographics Association and Blackwell Publishing Ltd.

C. Menk et al. / Spatial Augmented Reality in the Design Process

determine the projectable values at every projector pixel on
the real object by incorporating the ambient light, the material and the local orientation of the projector. The projectable
values were represented with a 3D LUT which was computed
with our approach for every single projector pixel, since the
storage of such a table for every pixel would require too
much memory. An advantage of our method is that the real
object or the position of the projector can be changed without measuring the colours of the projector again. This is an
important issue, because in a design process of a car, a lot of
different real objects are illuminated with the same projector
and viewed under the same ambient light. Our physicallybased 3D LUT method is able to exactly visualise colours,
which are inside the gamut of the projector so that they are
not distinguishable from a real reference colour. In our experiments, our approach achieves maximum and average E∗
values which are below the perceivable threshold of 2.3 and
thus, is suitable for a scenario in the automotive industry.
Since a lot of colours are outside the gamut of the projector,
an adjustment has to be computed. We conducted a user study
to see what adjustments a design expert would make. The results were used to propose a new scalable method which preserves the chromaticity coordinates and adjusts the lightness
before the corresponding projection intensity is computed.
This method performed well in a second user study, because
it can be modulated by three weights to meet the designer’s
personal preferences.
Future work has to evaluate if these weights are suitable for a designer to adjust the overall appearance. Furthermore, our proposed method has to be extended to be
applicable to multiple projectors which can enhance the
gamut. For this purpose, we are currently implementing
our proposed method on the graphics card to increase the
performance.

References
[ALY08] ALIAGA D. G., LAW A. J., YEUNG Y. H.: A virtual
restoration stage for real-world objects. In SIGGRAPH
Asia ’08: ACM SIGGRAPH Asia 2008 papers (New York,
NY, USA, 2008), ACM, pp. 1–10.
[AOSS06] ASHDOWN M., OKABE T., SATO I., SATO Y.: Robust content-dependent photometric projector compensation. In CVPRW ’06: Proceedings of the 2006 Conference
on Computer Vision and Pattern Recognition Workshop
(Washington, DC, USA, 2006), IEEE Computer Society,
p. 6.
[BCK∗ 05] BIMBER O., CORIAND F., KLEPPE A., BRUNS E.,
ZOLLMANN S., LANGLOTZ T.: Superimposing pictorial artwork with projected imagery. IEEE MultiMedia 12, 1
(2005).
[BEK05] BIMBER O., EMMERLING A., KLEMMER T.: Embed-

2365

ded entertainment with smart projectors. Computer 38, 1
(2005), 48–55.
[BIWG08] BIMBER O., IWAI D., WETZSTEIN G., GRUNDHO¨ FER
A.: The visual computing of projector-camera systems.
Comput. Graph. Forum 27, 8 (2008), 2219–2245.
[GB08] GRUNDHOFER A., BIMBER O.: Real-time adaptive radiometric compensation. IEEE Transactions on Visualization and Computer Graphics 14 (January 2008), 97–108.
[GPNB04] GROSSBERG M. D., PERI H., NAYAR S. K.,
BELHUMEUR P. N.: Making one object look like another:
Controlling appearance using a projector-camera system.
IEEE Computer Society Conference on Computer Vision
and Pattern Recognition 1 (2004), 452–459.
[Hun92] HUNG P.-C.: Tetrahedral division technique applied
to colorimetric calibration for imaging media. In Annual
Meeting IS and T (May 1992), pp. 419–422.
[KHM10] KOCH J., HENRICH N., M¨ULLER S.: Spatial color
confidence for physically based rendering settings on lc
displays. In GRAPP ’10: International Conference on
Computer Graphics Theory and Applications (Angers,
France, 2010), Springer.
[MJK10] MENK C., JUNDT E., KOCH R.: Evaluation of geometric registration methods for using spatial augmented
reality in the automotive industry. In 15th International
Workshop on Vision, Modeling and Visualization (Siegen,
Germany, 2010).
[MK10] MENK C., KOCH R.: Physically-based augmentation
of real objects with virtual content under the influence
of ambient light. In Proc. IEEE International Workshop
on Projector-Camera Systems (San Francisco, CA, USA,
2010).
[NPGN03] NAYAR S. K., PERI H., GROSSBERG M. D. N. B. P.:
A projection system with radiometric compensation for
screen imperfections. In Proc. of International Workshop
on Projector-Camera Systems (2003).
[RWC∗ 98] RASKAR R., WELCH G., CUTTS M., LAKE A., STESIN
L., FUCHS H.: The office of the future: a unified approach
to image-based modeling and spatially immersive displays. In SIGGRAPH ’98: Proceedings of the 25th annual conference on Computer graphics and interactive
techniques (New York, NY, USA, 1998), ACM, pp. 179–
188.
[RWLB01] RASKAR R., WELCH G., LOW K.-L.,
BANDYOPADHYAY D.: Shader lamps: Animating real
objects with image-based illumination. In Proceedings
of the 12th Eurographics Workshop on Rendering
Techniques (London, UK, 2001), Springer-Verlag, pp.
89–102.

c 2011 The Authors
Computer Graphics Forum c 2011 The Eurographics Association and Blackwell Publishing Ltd.

2366

C. Menk et al. / Spatial Augmented Reality in the Design Process
∗

[SCG 05] SEN P., CHEN B., GARG G., MARSCHNER S. R.,
HOROWITZ M., LEVOY M., LENSCH H. P. A.: Dual photography. In ACM SIGGRAPH 2005 Papers (New York, NY,
USA, 2005), ACM, pp. 745–755.

rendering system. In SIGGRAPH ’94: Proceedings of the
21st annual conference on Computer graphics and interactive techniques (New York, NY, USA, 1994), ACM, pp.
459–472.

[SJY08] STEELE R. M., JAYNES C., YANG R.: Reducing resolution loss in two-pass rendering by optimal view directions
and display-surface partitioning. In PROCAMS ’08: Proceedings of the 5th ACM/IEEE International Workshop on
Projector camera systems (New York, NY, USA, 2008),
ACM, pp. 1–8.

[WB07] WETZSTEIN G., BIMBER O.: Radiometric compensation through inverse light transport. In PG ’07: Proceedings of the 15th Pacific Conference on Computer Graphics and Applications (Washington, DC, USA, 2007), pp.
391–399.

[ST97] SHARMA G., TRUSSELL H. J.: Digital color imaging. IEEE Transactions on Image Processing 6 (1997),
901–932.
[SYC10] SHENG Y., YAPO T. C., CUTLER B.: Global illumination compensation for spatially augmented reality. Computer Graphics Forum 29 (May 2010), 387–396(10).
[TCH∗ 08] THOMAS J.-B., COLANTONI P., HARDEBERG J. Y.,
FOUCHEROT I., GOUTON P.: An inverse display color characterization model based on an optimized structure. In
Color Imaging XIII: Processing, Hardcopy, and Applications (San Jose, USA, Jan. 2008), vol. 6807, SPIE.
[War94] WARD G. J.: The radiance lighting simulation and

[WSOS05] WANG D., SATO I., OKABE T., SATO Y.: Radiometric compensation in a projector-camera system based
properties of human vision system. In IEEE International Workshop on Projector-Camera Systems (Washington, DC, USA, 2005), IEEE Computer Society, p. 100.
[YHS03] YOSHIDA T., HORII C., SATO K.: A virtual color
reconstruction system for real heritage with light projection. In VSMM ’03: Proceedings of International Conference on Virtual Systems and Multimedia (2003), pp. 161–
168.
[YSN∗ 10] YAPO T., SHENG Y., NASMAN J., DOLCE A., LI E.,
CUTLER B.: Dynamic projection environments for immersive visualization. In Proc. of IEEE International Workshop on Projector-Camera Systems (2010), pp. 1–8.

c 2011 The Authors
Computer Graphics Forum c 2011 The Eurographics Association and Blackwell Publishing Ltd.

