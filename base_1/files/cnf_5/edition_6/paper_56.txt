Rapid-prototyping as a Vehicle for Drawing in Three Dimensions
Stuart Mealing
University of Plymouth, UK
SMealing@plym.ac.uk
Abstract
This paper proposes a novel drawing medium
developed with the use of rapid-prototyping technology.
It presents a medium for enabling the capture of threedimensional gestural marks and for their subsequent
realization in solid form. These proposals are
contextualised with an outline of the progress and
rationale of an ongoing project which uses the
technology to explore objective drawing in three
dimensions.

1. Introduction
The inaugural project of the Feral Drawing
Research Group at Plymouth University in Exeter was to
develop experiences of drawing in three-dimensional
space using rapid-prototyping equipment and its
peripherals. The five project researchers pursued
individual investigations and pooled their findings to
arrive at a consensus view of the medium’s potential.
This has led to in an inter-university collaboration which
aims to develop a cross-disciplinary visualisation tool
that exploits the novel medium.
One strand of the investigation, described here,
considered the effect on the objective drawing process of
the extra degrees of freedom offered by a drawing tool
which could be manoeuvred in three-dimensions rather
than being constrained to its traditional operation upon a
two-dimensional plane. Drawing in this context is
understood to be the use of gestural, goal-directed markmaking to create representations of the external real
world.

2. The technology and equipment
Rapid prototyping (RP) enables a virtual model,
created using a 3D computer modelling application, to be
easily output as a three-dimensional object. Data for the
model can be created within the modelling application or
can be input from an external source such as a 3D
digitiser. The process is typically used in industry to
bypass expensive mould-making processes in the

Proceedings of the Computer Graphics, Imaging and Vision: New Trends (CGIV’05)
0-7695-2392-7/05 $20.00 © 2005 IEEE

realisation of a prototype object and, since object data is
readily transmitted, the 3D realisation can occur at a
distant site.
The 3D modelling software used was form.Z from
auto.des.sys running on both Mac and PC platforms. This
is a solid (CSG) modeller, which is necessary for the
production of a final solid model, and uses a standard
surface representation (b-rep) on screen.
The RP machine used for this project was a Prodigy
Plus from Stratasys Inc. which produces objects in
acrylonitrile butadiene styrene (ABS) using a fused
deposition modelling (FDM) system. When object data is
sent to the RP machine two types of structure are built:
the object itself in ABS, and a body of material which
supports the developing object in the correct position
while the construction process is underway (fig 1).

Figure 1. Object (white) and its support structure
The necessary support structure is calculated by the
software and, being water soluble, is washed away at the
end of the building process to leave the freestanding
object. This machine can build complete models up to
203x203x305mm, or larger models can be constructed in
multiples thereof.

Figure2. The digitizing arm in conventional use
The digitiser used to collect 3D data for the
modelling software was a G2 Microscribe from
Immersion Ltd. which has a pointer mounted at the end
of a triple-jointed arm (fig 2). This allows smooth
movement of the pointer by hand within a space, limited
by the arm’s dimensions, equal to a one metre sphere.
The XYZ position of the tip of the pointer is transmitted
at all times to the computer, recorded at user-defined
increments, and plotted on screen. For our purposes the
software was set to join consecutive XYZ points into a
line which effectively maps the progress of the drawing.
The operator can therefore grip the pointer in the same
way as a pencil and ‘draw’ with it within its sphere of
operation.

3. From line to object
The 3D line which is a record of the movement of
the digitising pen has no ‘real’ thickness and needs to be
fattened before it can be converted into an object. It is
therefore subject within the software to a ‘sweeping’
process, whereby a two-dimensional user-defined section
is ‘swept’ along the length of the line at right angles to it.
The resultant model is saved in Standard
Triangulation Language format (STL) which is then
diagnosed for potential modeling errors such as missing
layers and incomplete or intersecting lines which could
affect the integrity of the model. If present, these artifacts
are most commonly acquired in the course of Boolean
operations on the model. The model is then ‘sliced’ by
software which generates the layers required by the RP
machine and the slices checked visually for artifacts. The
final version is finally converted internally by the RP
machine to a CMB file and the 3D model laid down in a
gradual sequence of passes.

4. Drawing in 3D
Objective drawing traditionally involves making
marks on a 2D surface to stand for an external 3D reality.
This key part of the drawing process is effectively the
manifestation of an intellectual viewing transform, a

Proceedings of the Computer Graphics, Imaging and Vision: New Trends (CGIV’05)
0-7695-2392-7/05 $20.00 © 2005 IEEE

typical function of which is to find representation for the
Z dimension in an XY plane.
The use of the digitizing arm, which invites
movement of the drawing tool in all three spatial
dimensions, appears to offer new freedom by relieving
the user of the need to undertake this transformation. In
practice, however, it becomes clear that a radical
paradigm shift occurs. The experience of years of
drawing in 2D has to be unlearnt. (It should be pointed
out that all researchers working on the project are
experienced in drawing but that it is intended, once the
interface is refined, to test it on naïve users such as
young children who are not burdened with
preconceptions about existing languages of drawing.)
The initial temptation of the experienced drawer is
to artificially confine movement of the digital drawing
tool to an imaginary 2D plane and continue with the
familiar transform process. This clearly avoids any
exploitation of the new medium. The constraint which is
at the heart of traditional drawing languages is removed
by the digital arm but the usual rationale for producing a
drawing goes with it. It is necessary to re-evaluate the
reason for objective drawing before using the new
medium.
Drawing imaginary 3D forms proved instinctive,
though too easily literal - it was tempting to merely
outline the surfaces of the imagined form in all its three
dimensions. At the same time, the physical
representation of the 3D aerial marks on a 2D monitor
screen was typically enigmatic, although they have the
ability to be manoeuvred in real-time in the virtual 3space of the screen.

4.1 Self portraiture
In the early stages of the investigation therefore,
drawn marks were made in response to my own
imagined 3D head sited within the limits of the digitizing
arm, and the drawn marks were qualified by reference to
the matching image in an adjacent mirror. Mental and
visual excursions between the aerial mark-making space
and the reference mirror proved, however, to disturb the
clarity of sense of spatial positioning within the drawing
arena. It was possible to hold a fairly accurate mental
image of the accretion of virtual marks only as long as
the space they occupied was concentrated upon
exclusively.
Checking the mirror was a distraction as was, to a
lesser extent, checking the screen image. It is interesting
to note therefore, that whilst realtime feedback is the
essence of conventional drawing it proved to be a
hindrance here. Alternative devices for viewing the
virtual drawing (such as head-up displays) might in
future provide different, less intrusive, realtime feedback.
Some researchers introduced objects into the
digitizing space to provide consistent data points. These
could be included in the drawing by digitizing them in
the conventional way (i.e. by recording contact with key

points on the object) or they could act as reference points
to help avoid getting lost in virtual space. I soon found
that including my glasses – on my head not in the
digitizing space – provided a firmer, more easily
imagined reference point for my attempts at selfportraiture.
The drawing gestures I made to stand for my head
slowly came to resume some of their previous freedom.
Since, however, the imagined representation from which
I was drawing fitted within the available drawing space,
the strokes tended to be as if traced over the head’s
surface, an issue which would not arise if the subject was
outside that arena. The relaxation that came with
increased familiarity and from the acceptance of a
different drawing intention allowed the virtual marks to
regain an expressive, as well as literal, element (fig 3).
Figure 3. Drawn head

Figure 4. Swept head

4.2 Locating the drawing
When working with the equipment described one is
forced to question where the drawing exists – in digitiser
space, on the monitor screen, in the model data file, on a
paper printout, in a 3D animation, or as a rapidprototyped model? Is the drawing two-dimensional,
three-dimensional or, given its occurrence and potential
display over time, four-dimensional? I choose to think of
the ‘true’ drawing existing in the data and that all else is
an alternative representation. This is obviously
problematic since, in that form, it is not visible and the
alternative view that it should exist in sensory space is
understandable.
One can also ask when the drawing exists. Does the
drawing exist in the gestures that create it or in one of the
subsequent forms that it can take? Whilst it is not new to
distinguish between the act of drawing and the record it
leaves behind, the process used here serves to heighten
one’s awareness of the issue. In particular,
acknowledgement of the delay between gesture and 2D
or 3D hardcopy is unavoidable.

4.3 The post-gestural phase

Figure 5. Rendered head

Proceedings of the Computer Graphics, Imaging and Vision: New Trends (CGIV’05)
0-7695-2392-7/05 $20.00 © 2005 IEEE

It has been noted that the representation of the path
of movements made by the drawing tool is a single
virtual line and that this needs modification before it can
be translated into a 3D object in the real world. This is
accomplished by ‘sweeping’ (fig 4) with a specified
section which can be oval, rectangular, or any other
shape, of any scale. The section can be varied for
different lines within the drawing and can also be varied
along a single sweep path. Creation of the section and its
subsequent employment in the sweeping process is
carried out in the modelling application. The swept form
can be rendered at this stage to give the appearance of a
solid object (fig 5) and sent to the rapid-prototyper to
produce a real world model (fig 6).
Significantly, the drawing process has now been
extended beyond the phase of gestural mark-making. A

the former. In the case of the image in figureseven, a
ratio of at least 1:100.

5. Constraints

Figure 6. Real world model of head drawing
post-gestural phase is required to give substance and
form to the virtual mark-path if it is to have an existence
beyond its minimal representation on the monitor screen.
Other characteristics of the drawing, or of its 2D
representation and subsequent 3D realization, can be set
or changed after the gestural creation phase. Virtual lines
can be moved or edited, sweep sections can be modified
and rendering parameters – such as colour, texture, depth
cueing, virtual lighting etc. – together with the rendering
method itself are all addressable. Whist many of these
changes can be made to all computer-based imagery, and
in many traditional print processes, in this case the
drawing does not fully ‘exist’ until these paramenters
have been defined, either explicitly or by default.

As with most digital systems there are constraints
on the operation of the process. The data accumulated
from the digitiser when used this way can be vast and
experience determined an optimum sensitivity setting for
positional measurement. This reflected the trade-off
between accuracy, line length and allocated memory and
tended to be satisfactory when the pointer’s position was
captured at increments of between one and five mm. A
longer line required a greater increment and it was found
that a number of short lines could be captured more
easily than a single long line. This determined, to some
extent, the drawing style used but matched that of a
traditional drawing where the pencil is regularly lifted
from the surface of the paper. The data storage method
used by a CSG modeller later in the process also has
memory implications.

Figure 8. Lines with connectors

Figure 7. Head with varied sections and colours
This drawing process therefore offers an
unaccustomed mixture of spontaneity and post-gestural
manipulation, the latter potentially lasting far longer than

Proceedings of the Computer Graphics, Imaging and Vision: New Trends (CGIV’05)
0-7695-2392-7/05 $20.00 © 2005 IEEE

A profound consequence of having the 3D drawing
made up of a number of lines is apparent at the RP stage.
Whilst the individual lines are held in the correct spatial
relationship in the virtual world of the computer model,
gravity is not so supportive. A real world model of the
virtual drawing would consist of an untidy heap of lineobjects unless there was some intervention to keep them
in the correct alignments required by the original
drawing.
Several solutions offered themselves, most
obviously that the complete 3D drawing could be
embedded in a block of clear resin. To achieve this,
however, the line-objects would still have to be held in
the correct positions by some mechanism, and if the
mechanism exists then the resin is functionally redundant
(though perhaps still desirable for protective or aesthetic

purposes). Initially this problem was overcome by
adding connections between the drawn lines in the
computer model so that they were held in fixed
relationships (fig 8). These connecting lines were swept
with a different cross-section to the lines constituting the
3D drawing but they were found to interfere visually in
the final object and, if thin, were very fragile.
A subsequent solution was to connect the lineobjects with stainless steel connector rods which fitted
into sockets cut from the virtual line-objects in the
computer model using Boolean processes. For strength
each connection point was reinforced with a spherical
nodule added to the computer model. The use of clear
Perspex rods as connectors was considered since they
would largely vanish in a resin-embedded model but
their flexibility was problematic. The relatively narrow
section used to sweep the 3D lines, desirable to retain
their identity as lines, also presented rigidity problems in
ABS and was later alleviated by using an alternative RP
machine which generated polycarbonate models.

6. Developments
The alternative outputs of this novel drawing
process are all driven by the same data, currently the
original point-by-point XYZ positional data plus that
added in the post-gestural phase. If the drawing was
developed traditionally – i.e. with the tool moving in a
2D plane and the user left responsible for achieving the
viewing transform – then the additional, untapped data
stream offered by movement in the Z dimension could be
mapped to a non-spatial parameter such as scale of the
sweep section or colour.
A current collaborational development of the project
involves the derivation of further data streams relating to
acceleration, speed and smoothness of gestural
movement, with the aim of mapping them in realtime to
those parameters currently set in the post-gestural phase.
This is seen in the context of a motion capture resource
which extends the scale and variety of gesture possible
and a system which visualizes the result in realtime.

Conclusions
The process described here produces a threedimensional record of a time-based gestural activity, in
this case objective drawing. The initial screen
representation of the drawing is interesting on its own,
having the ability to be rotated in all directions (fig 9),
and viewed from any point within or without the drawing
itself, thus developing an unexpected relationship
between viewer and object.
Such activities have normally been recorded in two
dimensions using media such as traditional drawing or
still photography (e.g. fig 10) which strip out from the
original experience one spatial dimension and the
temporal dimension. Alternatively time-based media
such as film can be used to retain the temporal dimension
but they abandon a spatial dimension.

Proceedings of the Computer Graphics, Imaging and Vision: New Trends (CGIV’05)
0-7695-2392-7/05 $20.00 © 2005 IEEE

Figure 9. Head drawing at three points in its rotation

interactively or as an animation. These options therefore
offer the observer a fresh way of looking at the activity, a
fresh viewpoint from which to consider it.
Matisse, amongst others, talked of ‘study by means
of drawing’ [2], of comprehending the world through
drawing. By offering a different viewing point this rich
new drawing methodology offers the chance of revealing
a different world. [3]

Acknowledgements
I am pleased to acknowledge the value of advice
from Martin Woolner, Director of <make> [4] and of
discussion with colleagues also working on the project:
Martin Woolner, Polly Macpherson, Jo Davies and Tavs
Jørgensen.

References
[1]
[2]

Figure 10. Picasso drawing in space [1]
[3]

This process retains all the spatial dimensions and,
as such, provides a novel visualization tool. Its output
freezes the spatial movement that has occurred over a
period of time into a single object. Alternatively the
drawing itself can be viewed on a 2D screen either

Proceedings of the Computer Graphics, Imaging and Vision: New Trends (CGIV’05)
0-7695-2392-7/05 $20.00 © 2005 IEEE

[4]

Gjon Mili. Stringer. 1949
J. Elderfield. The drawings of Henri Matisse. ACGB,
London. 1984.
S. Mealing. On drawing a circle. In Computers & Art
(2nd ed). Intellect. 2002.
An innovative research centre established at the
University of Plymouth in 2004 to support the creative
industries in the development of products and artifacts.

