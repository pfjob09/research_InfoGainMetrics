Visualisation within a Multisensorial Surgical Planner
G J Clapworthy, M Krokos, R Mayoral, R Liang, D Podgorelec
Department of Computing & Information Systems, University of Luton, UK
email: gord~n.clapworthy@luton,ac.uk
Abstract
lXis paper describes the visualisation components
associated with a new environment for the pre-operative
planning of total hip replacement. The system has a
multisensorial immersive interface (stereoscopic display,
several six-degrees-of-freedom tracking technologies,
speech recognition and control, and haptic feedback) and
includes advanced software visualisation and evaluation
modules for bath planning the operation and evaluating
the likely outcomes.

Keywords: virtual reality, pre-operative planner, total hip
replacement, multimodaVmultisensoria1interface

1. Introduction
Technological developments are increasingly allowing
more sophisticated approaches to be adopted in medical
applications. In particular, immersive environments have
started to be applied in the training of clinical personnel
[ 1J, while VR techniques have already been used in neuro
[2], craniofacial [3], and orthopaedic surgery [4].
Total hip replacement (THR)is an operation that is
extremely common nowadays. particularly in light of the
ageing population. In general, it is a straightforward
procedure, but in a number of cases, pathologies or
deformity mean that special care has to be taken.
Pre-operative planning is a fundamental phase in THR
surgery [5], most particularly in these special cases, and
the advantage of using a 3D environment for it bas been
clearly demonstrated [6]. A number of different THR
planning systems have been developed in recent years
[4,7,8]. However, while they frequently take advantage of
3D graphics in their displays, navigation within these
systems is mostly achieved by using a two-degrees-offreedom mouse and a flat screen for pseudo-30
interaction, which severely limits the farms of
interactivity that can be achieved.
At present, no pre-operative planner includes soft
tissue modelling and, when planning the placement of the
cup and stem components, usually the femur and the
ileum are visualised separately. Another limitation is the
lack of biomechanical evaluation of the achieved position.

Proceedings of the Computer Graphics, Imaging and Vision: New Trends (CGIV'05)
0-7695-2392-7/05
$20.000 2005 I E E l

The aim of the Multisense project is to take a radically
different approach to the problem. It combines different
sensorial devices (haptics, speech, stereoscopic
visualisation, and six-degrees-of-freedom tracking) in a
unique VR environment for pre-operative planning. The
specific demonstrator for this approach, THR, was
selected because it affords opportunities to test the
efficacy of various combinations of these technologies;
indeed, orthopaedic surgery as a whole is an area which
could benefit greatly from their deployment.
Thus, while the project (and thus this paper) currently
focuses on a specific clinical application, the effectiveness
of the approach, after validation, will also be of great
relevance to other orthopaedic and medical applications.
In Section 2, below, we describe the various stages of
THR surgery and aftercare. Section 3 is devoted to the
development of a patient-specific model which enables
the surgeon to investigate, in 3D, an accurate
representation of the patient's anatomy. Section 4
describes the planning environment and Section 5 gives
an overview of the system implementation. Section 6
describes some of the validation activities that will take
place, and the paper is summarised in Section 7.

2. Total Hip Replacement
This section describes THR surgey for cementless
components so that the various aspects of the system
developed can be put in context.
In THR, the surgeon seeks to access the proximal part
of the femur (thigh bone) and the. cavity in the ileum
(pelvic bone) in which the head o f the femur sits - the
acetabulum. To do this, an incision is made in the skin of
the thigh, and metal retractors are put in place at the lip of
this incision to keep it open. Each prosthesis manufacturer
will have a recommended procedure for fitting the
prosthesis and this will include defining the position of
the initial incision.
However, in Multisense, we need to take account of
special cases where the patient presents particular
problems to the surgeon, perhaps because of physical
abnormality. The surgicaI planner is even more valuable
in such cases than in a standard THR, which is why it is

cGM
PUTE R
SOCIETY

important that a patient-specific anatomical model is
available for the planning.
The surgeon then attempts to move past the various
muscles that are blocking access to the site of the surgery.
This is normally performed by retracting the muscles
individually, with assistants using retractors to hold back
muscles already displaced. In cases where retraction of a
muscle is not suitable, it may be cut to allow the operation
to continue - cuts take place along the direction of the
muscle fibres.
Once suitable access is achieved, the head of the
femur is removed by a saw cut at the selected position.
The skin incision must be large enough to allow access by
the instnunent and for the removal of the, by now
superfluous, bone.
A reamer is used to prepare the interior of the femur to
receive the prosthesis and the interior of the acetabulum
to receive the cup that is to be inserted into the ileum.
The prosthesis is inserted into the stump of the femur.
The placement should be solid, so planning where it will
sit is an important aspect of the operation. The cup is
inserted into the ileum and the prosthesis is fitted against
it. Apart from a general restoration of tissue to its
previous position and a closing of the skin incision, the
operation is now complete.
It is essential that the position of the head of the
prosthesis relative to the cup does not create excessive
strain on muscles and other tissue during subsequent
movement of the patient. Thus, an important part of the
planning relates to ensuring that the way in which the new
joint moves is suitable to the anatomy of the patient.

Figure 1. Poor muscle contrast in CT scans

In the MML, a technician can scale a generic muscle
anatomy atlas to fit the patient's skeletal anatomy. For
this, a musculo-skeletal model of the lower limb has been
developed using the Visible Human dataset (VH) [9].
From these data, the surfaces of all of the most important
bones, muscles and tendons have been extracted to create
a complete representation of the hip joint.
These data are used, together with the VH muscle
surfaces, as input for the muscle surface registration
environment in which the shape of each muscle can be
properly adapted to the patient-specific anatomy (Fig. 2).

3. Creation of subject-specific model
As the soft tissue in the region of the operation is a
factor that has to be considered in planning the operation,
the implemented system needs an anatomical model that
is an accurate representation of the musculo-skeletal
apparatus of the patient. Ideally, CT and MRI scans of the
patient hip joints would be available, from which the CT
data would provide the skeletal anatomy and the outer
body shape, and the MRI data would provide the muscle
and ligament anatomy. However in TRR, because of cost
implications, standard clinical practice requires only a CT
scan of the patient to be taken for planning purposes.
Unfortunately in CT images, the X-ray attenuation for
muscle is similar to that of surrounding soft tissues (Fig.
l), thus making it difficult to identify the boundaries of
the individual muscles automatically. Further, there are no
landmarks within the soft tissue on which to apply normal
registration methods.
In order to provide a complete musculo-skeletal model
of the patient, a pre-processing unit, called the Muscle
Modelling Laboratory (MML), has been developed.

Proceedings of the Computer Graphics, Imaging and Vision: New Trends (CGIV'OB)
0-7695-2392-7/05
$20.00 0 2005 IEEE

Figure 2. Muscle registration module

,

The individual VH-based muscle models are
processed in two stages. In the first stage, a global
transformation is applied to the VH model based o ' the
registration of the data sets from the landmarks mentipned
in Section 2. This transformed model of the muscile is
~

P

C~~PUTER
SOCIETY

now embedded in the space of the patient's CT data so
that it can be compared to the corresponding muscle of
the patient.
For this comparison, we consider synthetic slices of
the patient CT data that are perpendicular to the slicing
axis, that is, these slices are at an angle to the real slices
captured in the original medical images. For most muscles
this slicing axis is the straight line joining the muscle
insertion points - this is discussed in Krokos et al. [lo].
On these slices is superimposed a contour representing
the boundary of the transformed VH model that is
embedded in the patient data space. We can thus see the
shape of the transformed VH muscle and compare it to the
shape of the patient muscle in that slice.
The MML allows the user to apply, in a synthetic
slice, a set of simple geometric deformations to the VH
contour to try to match the contour to the patient muscle
shape. While the lack of contrast does not allow the shape
of the patient muscle to be extracted automatically (which
is why we are following this procedure), a trained
technician can determine the boundary by eye from the
slice displayed.
This process takes place successively in a number of
slices along the length of the muscle. These slices are
selected by the user by rapidly scanning through the slices
to identify particular features that it will be important to
match. By storing the overall deformations applied to the
successive contours considered and using these to define
deformations that must be applied to the VH surface
model previously created, a patient-specific surface model
can be generated.
There are four distinct transformations: Position (Pop),Translation (T-Op),Rotation (R-Op) and Scaling (Sop).The P-op translates the contour to a suitable overall
position in the slice. The T-Op translates the coordinate
system origin to a position around which the subsequent
operations will occur. The R-Op rotates (+/- 90) a contour
around this new origin to align the major boundary
features. Finally, the S-Op is performed along the four
axial directions, independently, to determine the final
shape. Operations are applied in the order listed to ensure
that the user follows a unique path to achieve the desired
shape. Because this form of scaling is non-affine, it
always has to be performed last.
Further details of the Muscle Modelling Laboratory
(MML) can be found in Krokos et al. [lo].

4. The pre-operative planning environment
Once the data of the patient have been prepared and
imported into the planning environment, the user can
perform different actions and move between different
software states. If desired, these transitions can be
instigated by voice command, which is useful if the
surgeon has both hands occupied in other tasks.

Proceedings of the Computer Graphics, Imaging and Vision: New Trends (CGIV'O5)
0-7695-2392-7/05 $20.00 0 2005 IEEE

4.1. Surgical access
In the first phase of the planning, the user estimates
the surgical access. This modality is useful to ensure that
a particular anatomical feature is visible/reachable during
surgery, in particular when using minimally invasive
approaches. The surgeon can visualise the patient's outer
skin (and, using transparency, the muscles and the
skeleton, also) and mark the line of incision on the
external surface. At this point, the user can retract the skin
to inspect the muscles behind (Fig. 3).
The only issue with the incision is its position - there
is no problem of tissue damage in retracting the skin, so
including a haptic component is unnecessary. The skin
retraction is implemented as a simple operation in which
the surgeon indicates the ends of the incision and then
completes the incision by pressing a button.
The retracted shape of the incision has been designed
to reflect the shapes captured from images of real
operations. The outline has straight-line parts, which
correspond to where the retractors are placed, and the
ends of the incision are cusped. Between these, the shape
is mostly concave, but points of incision are present in
some cases. There is some parametric control that allows
the shape to be tuned to the expected behaviour of the
patient's skin in terms of the concavity of the curved
portions of the outline.
The details of how this procedure is implemented can
be found in Liang et al. [ll].

Figure 3. Skin retraction

Once the skin incision has been completed, the
surgeon can decide to cut or to retract each muscle as he
develops the pathway to the operation site. During the
retraction, the muscle shape i s deformed interactively and
force feedback is given to the user in order to understand
if there is muscle damage and if it is possible to retract the
muscle sufficiently to provide access to the acetabular
capsule (Fig. 4).

COMPUTER
SOCIETY

Within the muscle retraction, the main responsibilities
of the visual subsystem are to:
0
show the correct position of the tool (retractor)
test for collision between tool and surface
0
trigger state changes based on collisions
0
perform muscle deformation.
Figure 4 shows an example of the intended visual
result of the muscle retraction. The tool is shown pulling
one of the muscles away, and the head of the femur is
visible as a result of the surgical access created.

To compute the depth of penetration, the time of first
contact is determined. The real position of the retractor is
known only at discrete time instants, so a certain type of
motion for the retractor has to be assumed. We assume
constant translational and rotational velocities.

Figure 5. The active volume defined by the tool

R

Figure 4. Muscle retraction module
Two visualisation components were developed to
handle these tasks: a collision detection module and a
deformation module.
Collision detection determines when contact occurs
between the retractor and the muscles, and as input for the
deformation algorithm. To ensure that no collisions are
missed, Continuous, rather than Discrete, Collision
Detection is employed in our application. It also allows
for effective computation of the time of first contact and
the contact state of all colliding objects [12].
When collision occurs, a set of displacement vectors
can be computed to deform the affected region of the
muscle so that it remains in contact with the tool, while
avoiding penetration. This simulates the effect of using
the tool to pull aside a certain region of the muscle.
In our implementation, the retractor defines an active
volume as it moves. The face of the retractor used for
deformation is tracked, and two consecutive positions of
this face define the caps of an active volume. Four more
surfaces, based on the displacement of the retractor, are
used to close the volume. If, at any time, this volume
encloses part of the current muscle, then collision and
penetration have occurred. The penetration depth can be
calculated from the position of the retractor within the
muscle. Fig. 5 shows the active volume as the tool moves:
the tool has encountered an object on its path, and a
corresponding penetration depth results.

A fast first step is used to rule out the need to create
the active volume. The penetration depth indicates by
how much the muscle should be deformed to keep muscle
and tool in contact, while avoiding penetration. The result
of the collision detection is a list of surface mesh vertices
together with their corresponding displacement vectors.
This is passed to the deformation as input.
The deformation module is implemented as a direct
manipulation of a free-form deformation (DMFFD). At
the end of the procedure (when the bones are visible
within the access), the visualisation represents what the
surgeon would see in the operating theatre. Further details
of the integration of haptics and visualisation in the
context of this application are given in Mayoral et al. [13].

Proceedings of the Computer Graphics, Imaging and Vision: New Trends (CGIV'05)

0-7695-2392-7/05
$20.00 0 2005 IEEE

4.2. Prosthesis positioning
Having selected a prosthetic component (both in type
and size), the user moves to the prosthesis positioning
phase. During this, a two-handed interaction is available:
one hand is used to control the viewing position and the
other to perform the six-degrees-of-freedom positioning
of the components. Naturally, during the course of a twohanded interaction, the availability of voice control is
particularly useful.
At any time during the positioning, the surgeon can
check a series of functional indicators: the feasibility of
the planned position, the extension of bone-implant
contact in cementless components, the primary stability of
cementless components, the range of motion of the
operated joint, the limb lengtheningkhortening after joint
reduction, the balancing of soft tissues, and the alteration
of articular muscle moment arms (Fig. 6). The specific
visualisation algorithms implemented are integrated with
force feedback for some of the above-mentioned
biomechanical indicators, such as the range of motion, the

C~MPUTER
SOCIETY

feasibility of the planned position, and the primary
stability evaluation.

I
Figure 6. Range of motion evaluation module

4.3. Surgical planning
Once the pose of the prosthetic components is defined,
the surgeon can ask the system to compute the neck
resection plane and the insertion path of the reamer (Fig.
7). Once the surgical planning is accepted, the system
generates a model of the post-operative anatomy on which
the surgeon can perform final verification and inspection.

Well known toolkits, adopted in this work, are VTK
[I41 for visualisation, ITK [15] for segmentation and
registration, and VXL [I61 for numerical algorithms.
Single libraries are at too low a level for the efficient
development of a complex application, since this often
implies that a base implementation has to be extended
with new application modules. For this reason, several
application frameworks have recently been developed.
Application frameworks have a sense of
completeness, in that they are able to run by themselves,
without any further work. One example is ParaView [17],
used in fluid dynamics and general scientific visualisation
problems. Another is the Julius framework [18], which
was developed specifically for medical applications, but
which provides also a limited number of visualisation
modalities. Both are based on VTK, and Julius is also
based on Qt library, which is not Open Source under
Windows. Neither of these provides multimodal support.
The pre-operative planner for THR presented in this
paper has been developed on top of the Multimod
Application Framework (MAF) [ 191. MAF is an Open
Source application framework built on top of the VTK,
ITK and wxwindows libraries and other Open Source and
cross-platform software.
During the development of the current application, the
MAF was extended to introduce support for multimodal
interaction and provided with hrther visualisation
algorithms. The hardware implementation of the
multimodaV multisensorial system is presented in Fig. 8.

r--

Figure 7. Neck resection module

5. System implementation
Developing a system as complex as the one described
here requires that many basic algorithms and technologies
are integrated into a single system. In recent years, a
number of Open Source librariesltoolkits have been
developed, which provide a foundation for applications in
many fields.

Proceedings of the Computer Graphics, Imaging and Vision: New Trends (CGIV'O5)
0-7695-2392-7105 $20.00 0 2005 IEEE

Figure 8. The multimodal system implementation

To address the intensive computational needs of the
multimodal system and the different update rates required
by the different devices (the speech subsystem produces
input at the rate of a few seconds, graphics modules at the
rate of 10-30msec and haptic devices at the speed of less
than 1 msec), the architecture is based on networked
dedicated machines. Compared to using a single machine,
this multi-threaded approach has some advantages:
minimum coupling between local rates running on

COMPUTER
SOCIETY

different machines, more consistent rates for critical
processes such as the haptic servo inpudfeedback control,
and provision of functionally separate, extensible and reconfigurable control of the different input feedback
subsystems.
However, the synchronisation requirements between
the various subsystems implemented on the different
machines do increase. This has been directly addressed by
the MAF. In our system, a dedicated graphics server is
used to perform the graphics rendering; the low servo
control and the inpuufeedback coordination of the haptic
subsystem are managed by the haptic server; while a third
server is responsible for the control of the speech
subsystem. The communication between the various
machines is performed using a TCP/IP protocol interface.

6. Validation
Specific validation studies are being undertaken using
the following quantitative metrics: capabilities not
provided by existing systems, inherent accuracy, time
required to perform the task, global accuracy in
performing the given task, intra-operator and interoperators repeatability, and learning curve.
The different technologies integrated into the system
have been independently validated with relevant but
unambiguous tasks. The software modules providing
quantitative indicators on the realised planning were also
tested to assess the achievable accuracy and repeatability.

7. Conclusion
Pre-operative planning is a fundamental phase in
THR, Helping the surgeon to acquire a more accurate
mental model of the 3D relationships of the various
tissues in the operational area for the specific patient can
greatly increase the likelihood of a successful outcome.
However, the user interface in most surgical planning
systems is mostly restricted to the use of a mouse and a
flat (2D) screen. In this work, the application of a
multimodal/multisensorial interface in pre-operative
planning was presented. The interface was realised using
advanced visualisation algorithms, with the integration of
different interface units, including stereoscopic displays,
haptics and speech. It is believed that benefits can be
gained from the use of this multimodal/multisensorial
interface in all aspects of medical planning and training
including the time required to perform a task, accuracy
and repeatability in performing the task, and improved
efficiency and efficacy o f training.

Acknowledgements
This work was supported by the Multisense project
(IST-2001-34121) of the Information Society
Technologies Programme of the European Commission.

Proceedings of the Computer Graphics, Imaging and Vision: New Trends (CGIV‘OS)
0-7695-2392-7/05 $20.00 0 2005 IEEE

References
[I] H.D. Dobson, R.K. Pearl, C.P. Orsay, M. Rasmussen, R.
Evenhouse, Z. Ai, G. Blew, F. Dech, M.I. Edison, J.C.
Silverstein and H. Abcarian, “Virtual reality: new method
of teaching anorectal and pelvic floor anatomy”, Dis Colon
Rectum 2003;46(3):349-352
[2] M.A. Spicer and M.L. Apuzzo, “Virtual reality surgery:
neurosurgery and the contemporary landscape”,
Neurosurgery 2003;52(3):489495; dscussion 496-497
[3] S. Hassfeld and J. Muhling, “Computer assisted oral and
maxillofacial surgery--a review and an assessment of
technology”, Int J Oral Maxillofac Surg 2001;30( 1):2-13
[4] H. Handels, J. Ehrhardt, W. Plotz and S.J. Poppl,
“Computer-assisted planning and simulation of hip
operations using virtual three-dimensional models”, Stud
Health Techno1 Inform 1999;68:686-689
[5] C.G. Schizas, B. Parker and P.-F. Leyvraz, “A study of
pre-operative planning in CLS total hip arthroplasty”, Hip
International 1996:6:75-8 1
[6] M. Viceconti, R. bttanzi, B. Antonietti, S. Pademi, R.
Olmi, A. Sudanese and A. Toni. “CT-based surgical
planning software improves the accuracy of THR
preoperative planning“, Medical Engineering & Physics
2003; 25(5):371-377
[7] S. Nishihara, N. Sugano. T. Nishii, H. Tanaka, H.
Yoshikawa and A. Ochi, “Comparison of the fit and fill
between the Anatomic Hip femoral component and the
VerSys Taper femoral component using virtual
implantation”, J Olthop Sci 2003;8(3):352-360
[8] B. Jaramaz, A.M.r. DiGioia, M. Blackwell and C. Nikou,
“Computer assisted measurement of cup placement in total
hip replacement”, Clin Orthop 1998;354:70-81
[9] National Library of Medicine, Visible Human project,
btta:/huww.nlm.nih.nov/researcb/visible/visiblehwnao.h a
[lo] M. Krokos, D. Podgorelec, G.J.Clapworthy, D. Testi and
M. Viceconti, “Patient-specific muscle models for surgical
planning”, Proc. MediViz 05,2005 (to appear)
[I I] R. Liang, G.J. Clapworthy, .M. Krokos and R. Mayoral,
“Real-time predefined shape cutaway with parametric
boundaries”, Proc. Computer Graphics, Imaging & Vision,
CGIVOS, IEEE Computer Society Press, 2005 (to appear)
[I21 S. Redon, “Continuous collision detection for rigid and
articulated bodies”, ACM SIGGRAPH Course Notes, 2004
[I31 R. Mayoral, N.G. Tsagarakis, G.J. Clapworthy, R. Liang.
D.G. Caldwell, “Integration of haptic and visual modalities
in a total hip replacement planning system”, Proc. MediViz
05, IEEE Computer Society Press, 2005 (to appear)
[I41 Visualization Tool Kit, Kitware Inc, httw://www.vtk.org
[I51 Insight Tool Kit, Kitware Inc., ~ttn://ww.itkgLe
[ 161 VXL collection of C++ libraries, The TargetJr Consortium
DUWdOc-xv

[I71 httD://www.Darav ew
i . org
[ 181 httD://www.iulius.car.de
[I91 M. Viceconti et al., “Multimod Application Framework”,
Roc. Information Visualisation, W-04, pp 15-20,2004

CGMPUTER
SOCIETY

