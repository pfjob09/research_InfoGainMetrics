Learning Texture Classiﬁer for Flooded Region Detection in SAR Images
Shiqing Zhang, Hanqing Lu
National Laboratory of Pattern Recognition
Institute of Automation, Chinese Academy of Sciences
P.O. Box 2728 Beijing China 100080
email: {sqzhang,luhq}@nlpr.ia.ac.cn
Abstract
In this paper a new texture-based change detection
approach is proposed to identify the ﬂooded regions in
SAR images. The main novelty of our approach is that
the most distinctive texture information is automatically
learned from the training set. Forty texture features, which
are extracted from a pair of bi-temporal SAR images, are
used to construct the weak classiﬁer pool. After AdaBoost
training, a strong classiﬁer is optimally combined by a
small subset of the candidate weak classiﬁers. The experimental results demonstrate the effectiveness of the proposed
approach.

1. Introduction
The greenhouse effect, because of the continuous increase of the earth temperature, directly results in ﬂoods and
other natural disasters. To monitor these disasters, image
processing techniques could be used. But there usually exist heavy clouds on the ﬂooded region, which may affect the
image data acquisition of ordinary sensors. Therefore Synthetic Aperture Radar (SAR), which can capture qualiﬁed
image data under different air and illumination conditions,
is playing an important role in ﬂood monitoring.
Usually the monitor of the ﬂood is based on the detection of
the changed water areas. There are several kinds of methods
proposed for this kind of change detection. In several classical techniques, much attention has been paid on the difference image generated by calculating the absolute values
of the difference between the corresponding pixels in two
images. Large values in the difference image show the dissimilarity of the two areas and indicate changes, so thresholding the difference image at a speciﬁc value becomes a
straightforward idea. Each pixel in the difference image,
which has an intensity value that is larger than a threshold, is labeled as changed, while the rest are considered to
be unchanged. Although several methods [10] have been

proposed to choose an appropriate threshold, thresholding
is still sensitive to the noise and illumination changes and
as a result is not suitable for applications in complex environments, for example detecting changes of waters in SAR
images.
In recent years, more and more efforts have been made
to exploit the texture information contained in SAR images. Rather than considering information restricted within
a pixel, texture features are extracted from pixels in a region, which are less sensitive to the noise that is very common in remote sensing images. Many change detection
methods [1, 5, 6] presented recently are based on the texture differences between two images. Although these methods vary from one to another, they all tend to use more texture features than before to obtain higher accuracy. In fact
there are some drawbacks to use too many texture features.
Usually more texture features mean more information, but
too many texture features will not only increase the complexity of computation but also place a heavy burden on selecting the appropriate ones used in classiﬁcation. How to
select a minimum subset of the features, which is suitable
for change detection applications, becomes an open problem. Traditional feature selection methods such as PCA,
ICA cannot maximize interclass separability in the lower
dimensional subspace [11]. In our work the AdaBoost algorithm, which has been proved to be very successful in
selecting features in face detection and recognition problems, is employed to choose the texture features with the
best discriminability from all the forty ones. Based on these
selected textures we build up a strong classiﬁer to detect the
ﬂooded areas in the bi-temporal SAR images.
This paper is organized as follows: In section 2 we will
give an overlook of the whole work. Section 3 will give a
detailed description of the texture features used in our work.
We will present the AdaBoost algorithm and the strong classiﬁer used in change detection in section 4. Experimental
results and comparison are given in section 5. Finally, this
paper is concluded in section 6 with discussions.

Proceedings of the Computer Graphics, Imaging and Vision: New Trends (CGIV’05)
0-7695-2392-7/05 $20.00 © 2005 IEEE

2. Overlook of the work

signed. We call the classiﬁer a ”weak” one because we
do not expect high accuracy. Thresholding is adopted
to make a rough separation of the changed and unchanged pixels.

To detect the ﬂooded areas in two SAR images, our
ﬂooded areas detection algorithm(see Figure 1) is made up
of ﬁve steps: 1)preprocessing of the SAR images, 2)texture feature extraction, 3)weak classiﬁer design, 4)construction of the strong classiﬁer using the AdaBoost algorithm,
5)change detection and identiﬁcation of ﬂooded regions.

• Construction of the strong classiﬁer using the AdaBoost algorithm: The basic idea of boosting is
to combine several weak classiﬁers to a strong one.
In this step, the AdaBoost algorithm is employed to
choose several suitable classiﬁers from all the forty
weak ones and the ﬁnal strong classiﬁer is made up
of a linear combination of them.
• Change detection and identiﬁcation of ﬂooded regions: Using the strong classiﬁer learned from the AdaBoost algorithm, the change detection result is satisfying. But not all of the changes are made by the ﬂood,
some of them can be due to other factors. In order to
gain a desired result, postprocessing should be made
to validate the real inundated regions. In this step, two
prior-knowledge based strategies are adopted to identify the ﬁnal result.

3 Texture feature description

Figure 1. Flooded region detection algorithm.

• Preprocessing of the SAR images: Because registration and radiometric normalization have been done
in previous work, we only need to concentrate on the
speckle noise in the SAR images. In our work Most
Homogeneous Region Filter [13] is adopted to reduce
the speckle noise.
• Texture feature extraction: In this step we deﬁne
four kind texture features to detect changes in the bitemporal SAR images. They are the Kullback-Leibler
distance between the local neighborhood pixel intensity distributions, the mean, variance, and median differences of the local neighborhood pixel intensity. Because we do not know the best neighborhood window
size for the change detection application, each kind of
texture feature is extracted with ten different window
sizes, ranging from 3 × 3, 5 × 5,· · ·, to 21 × 21. Therefore forty texture features are extracted from the bitemporal SAR images.

In SAR images water areas and land areas are usually
quite different. There are two major differences between
water areas and land areas, brightness and roughness. Water areas are much darker and smoother than land areas. So
in changed areas both the brightness and the roughness of
the areas vary a lot, while in unchanged areas there are not
very signiﬁcant differences between two images. We found
that the mean, variance, and median of the pixel intensity
in the spatial neighborhood in the bi-temporal SAR images
can express the differences of brightness and roughness.
For a given point p = (u, v) in the image, let ωN denotes the N × N spatial neighborhood. The N 2 points
within the neighborhood of the ith image are labeled as
(i)
(i)
(i)
(i)
{x1 , x2 , · · · , xN 2 −1 , xN 2 } , where i ∈ {1, 2}. The mean,
variance and median of the pixel intensity can be written as
1
µi = 2
N
σi2

1
= 2
N

N2

N2

(i)

xj ,

(1)

j=1

(i)

(xj − µi )2 ,

(2)

j=1
(i)

medi = medianj∈(1,2,···,N 2 ) {xj }.

(3)

To describe the texture difference, a measurement of the difference is deﬁned as

• Weak classiﬁer design: For each texture feature we
get from two SAR images, a weak classiﬁer is de-

Proceedings of the Computer Graphics, Imaging and Vision: New Trends (CGIV’05)
0-7695-2392-7/05 $20.00 © 2005 IEEE

D(f1 , f2 ) = 1 −

2·f1 ·f2
,
f12 + f22

(4)

wherefi ∈ {µi , σi2 , medi }, i ∈ {1, 2}. It is obvious that
D(f1 , f2 ) equate to 0 when f1 = f2 , which shows the similarity between f1 and f2 , while D(f1 , f2 ) reaches a much
larger value when f1
f2 or f2
f1 , which indicates a
difference.
In order to make full use of the information in each pixel’s
local neighborhood, we take into consideration the statistical distribution of the intensity histogram in the neighborhood and choose a measurement called Kullback-Leibler
distance to describe the difference, which can be expressed
as follows [4].
Let H1 and H2 be the intensity histogram of the N × N
spatial neighborhood in two SAR images. Let P1 and P2 be
the discrete probability laws of H1 and H2 . The KullbackLeibler divergence is deﬁned as
K(P1 , P2 ) =
i

P2 ({xi })
P2 ({xi }).
log
P1 ({xi })

(t)
t (ht , d ) =

(6)

Therefore four kind texture features are extracted,
D(µ1 , µ2 ), D(σ1 , σ2 ), D(med1 , med2 ), D(P1 , P2 ). Because for each kind of texture feature we do not know the
most suitable neighborhood window size that can lead to
the best discriminability, four texture features are extracted
with different neighborhood window sizes. In our work ten
kinds of window sizes are adopted, ranging from 3 × 3,
5 × 5,· · ·, to 21 × 21. Finally forty texture features are extracted from two SAR images.

4 Methodology
4.1 The AdaBoost algorithm
The intrinsic purpose of boosting is to combine several
weak classiﬁes to a strong one that can get better accuracy
than any weak one. The AdaBoost algorithm, a sequential
forward search procedure using the greedy selection strategy, has overcome some practical difﬁculties that earlier
ones hold [7].
For a two class classiﬁcation problem, the AdaBoost
algorithm can be expressed as follows [8].
Initially we have a training set S of N examples
(x1 , y1 ), (x2 , y2 ), · · · , (xN , yN ), where yi ∈ {+1, −1} is
the class label of the corresponding examples . In our approach “1” stands for change and “−1” denotes no change.
In AdaBoost algorithm (see Figure 2) each example (xi , yi )

N

(t)

di I(yi = ht (xi )).

(7)

i=1

After selecting the weak classiﬁer ht , we have to update its
weight αt to minimize the loss function deﬁned as
N

G(αt ) =

t

exp{−yi (
i=1

(5)

One may notice that in most of the time K(P1 , P2 ) =
K(P2 , P1 ), in other words, the Kullback-Leibler divergence
is not symmetric. A symmetric distance can be achieved by
deﬁning the Kullback-Leibler distance as
D(P1 , P2 ) = K(P1 , P2 ) + K(P2 , P1 ).

(t)

is associated with a weight deﬁned as di at the tth iteration. At each iteration step t, examples that are misclassiﬁed get higher weights in the next iteration according to the
error incurred by the weak learner ht , in other words more
attention is paid on the examples that are hard to classify.
The weak classiﬁer is required to produce a small weighted
empirical error deﬁned by

αj hj (xj ))}.

(8)

j=1

A strong classiﬁer that is made up of a linear combination
of several weak classiﬁers can be deﬁned as
T

HT (x) =

αt ht (x).

(9)

t=1

The ﬁnal classiﬁer is presented as
H(x) = sign[HT (x)].

(10)

4.2 Weak classiﬁer design
In our work forty texture features are extracted from two
SAR images, consequently we have to design a classiﬁer
for each of them. It is found that both the Kullback-Leibler
distance and the difference of the mean, variance and median get a low value when there is no change while a high
one when there is a change. Because very high accuracy is
not necessary in weak classiﬁer design, thresholding, a simple approach with relatively low computation complexity, is
adopted in weak classiﬁer design. For the ith texture feature
a threshold thri is obtained by minimize the error rate in the
training examples. The corresponding weak classiﬁer hi (x)
is deﬁned as:
hi (x) =

+1 if x > thri
.
−1 if x ≤ thri

(11)

4.3 Change detection implementation
The training set of the AdaBoost algorithm is two SAR
images with a size of 512×512 and a corresponding groundtrue image of the changed areas used as a reference map.
For each pair of points having the same coordinate in two

Proceedings of the Computer Graphics, Imaging and Vision: New Trends (CGIV’05)
0-7695-2392-7/05 $20.00 © 2005 IEEE

1. Input:
S = {(x1 , y1 ), (x2 , y2 ), · · · , (xN , yN )}
where yi ∈ {+1, −1}
number of the iteration T
2. Initialization:
(1)
for all i = 1, 2, · · · , N
di = N1
3. Iteration:
For t = 1, · · · , T
• Obtain weak classiﬁer ht : x → {+1, −1}
• Calculate the weight training errors
(t)
N
t =
i=1 di I(yi = ht (xi ))

t

of ht :

• Update weights:
αt = 12 log 1−t t
(t+1)

(t)

= di exp{−αt yi ht (xi )}

di

=

(t+1)
di
N
(t+1)
d
i=1 i

• Break when
αt =

t

= 0 or

t

αt

N

t=1

4. Output:
H(x) = sign[

≥ 12 , set T = t − 1,

αt
T
t=1

5 Experimental results
5.1 Data description

di

(t+1)

likely be done by the noise that is very prevalent in SAR
images.
Second, it is common knowledge that ﬂooded regions were
land area before the ﬂood and were water areas when the
ﬂood happened. As we know water areas are darker and
smoother that land areas, both the mean and variance of the
intensity values in the ﬂooded regions should move from
low to high. In our work regions that do not change from
land to water are excluded from the ﬁnal identiﬁcation result of the ﬂooded regions.

αt ht (x)]

In order to evaluate the performance of the method proposed in this paper, we consider two pairs of bi-temporal
SAR images of Red River, Vietnam on August 24, 1996
and August 14, 1999. One is used as training set while another is used as test set. Since registration and radiometric
normalization have been done in previous work, we only
need to focus on denoising. Most Homogeneous Region
Filter [13] is adopted to reduce the speckle noise.

Figure 2. The AdaBoost algorithm [3].
images, forty texture features are extracted from the bitemporal SAR images. Each weak classiﬁer is constructed
based on a single texture feature to obtain a minimum error rate in training set. After that we employ the AdaBoost
algorithm to combine weak classiﬁers into a strong one,
which will be used in change detection. For the test set
we also need to do the texture extraction work and use the
strong classiﬁer we got to label each pixel as either changed
or unchanged.

(a) image on August 24, 1996 (b) image on August 14, 1999

4.4 Identiﬁcation of ﬂooded regions
In last step, a strong classiﬁer has been implemented by
using the AdaBoost algorithm and the change detection result (In our work it is presented as a change image.) is
achieved with the help of that classiﬁer. But it is obvious
that not all the changes in the image are made by the ﬂood.
Some of them are made by other reasons, which we are
not interested in. Several strategies have been proposed to
identify the real inundated regions. In our work, two priorknowledge based approaches [9] have been adopted.
First, we are interested in changed areas with relative large
size, so too small regions are eliminated from the change
image. That is because connected regions with very small
amount of pixels and some single isolated pixels are more

(c) ground-truth map

Figure 3. Images of Red River used as training
set.
We use one pair of images, both of which have a size of
512×512, in our training step. The changed and unchanged
areas are labeled by a manual analysis of the two SAR images to form a reference map. The two SAR images and the

Proceedings of the Computer Graphics, Imaging and Vision: New Trends (CGIV’05)
0-7695-2392-7/05 $20.00 © 2005 IEEE

achieves a signiﬁcant improvement. The combination of the
selected weak classiﬁer provides an accurate classiﬁcation
of the changed areas and the result is less susceptive to the
noise.

Table 1. The qualitative comparison of the
proposed method with two thresholding
methods.
(a) image on August 24, 1996 (b) image on August 14, 1999

Method
Method*
Method**
Proposed

False
alarms
18841
44137
5356

Miss
alarms
23053
7960
751

Overall
errors
41894
52097
6107

Overall
errors(%)
9.06
11.27
1.32

Method* : Thresholding based on Bayesian decision theory.
Method**: Thresholding using a K-means cluster approach.

(c) ground-truth map

Figure 4. Images of Red River used as test
set.

ground-truth map of the changed and unchanged areas used
as the training set are shown in Figure 3. The test set consisting of another pair of SAR images, which have a size of
680 × 680, and the ground-truth map is shown in Figure 4.

(a) Thresholding based
Bayesian decision theory

on(b) Thresholding using a Kmeans cluster approach

5.2 Change detection result and performance
comparison
In all the forty texture features, ﬁve of them are selected by using the AdaBoost algorithm and consequently
the strong classiﬁer is constructed by a linear combination
of the ﬁve weak classiﬁers. In order to show that our method
is more robust to the noise that is very prevalent in SAR
images, change detection results of two methods based on
thresholding as well as the result of our approach are shown
Figure 5. One method proposed in [2] detects changes in
the difference image by a global threshold in terms of the
Bayesian decision theory. Another method [12] adopts a Kmeans cluster approach to choose the appropriate threshold.
It is obvious that the proposed method is less sensitive to the
noise and results in a more reliable outcome.
The qualitative analysis of the accuracy provided by proposed method is compared with that exhibited by the two
thresholding approaches in Table 1. The table gives the
numbers of the false alarms (i.e. unchanged pixels classiﬁed
as changed ones) and the miss alarms (i.e. changed pixels
classiﬁed as unchanged ones) brought by both our method
and two thresholding approaches. Apparently our method

(c) Our approach

Figure 5. Change detection result comparison.

5.3 Flooded regions extraction result
For we are only interested in changed areas that are made
by the ﬂood, changed regions caused by other factors are removed by using the two strategies mentioned in section 4.
The ﬁnal identiﬁcation result of the inundated regions is
show in Figure 6.

Proceedings of the Computer Graphics, Imaging and Vision: New Trends (CGIV’05)
0-7695-2392-7/05 $20.00 © 2005 IEEE

(a) ﬂooded regions map

(b) ﬂooded regions map to
the original non-ﬂooded image
(white: ﬂooded regions)

Figure 6. Flooded regions extraction result.

6 Conclusions
This paper proposes a new change detection algorithm
based on multi-texture information to identify the ﬂooded
regions in SAR images. Unlike traditional change detection methods, which rely only on a limited amount of texture features because of the difﬁculty in selecting suitable
ones with the best discriminability, forty texture features
are extracted from every two SAR images and are used to
construct the weak classiﬁer pool. Instead of using PCA
or ICA, which cannot lead to a maximum interclass separability in the lower dimensional subspace, we adopt the
AdaBoost algorithm, which has been proved to be quite effective in selecting features in face detection and recognition problems and has hardly been used in remote sensing
change detection, in our method. With the help of the AdaBoost algorithm we build up a strong classiﬁer combined
by a small subset of the candidate weak classiﬁers to detect
the ﬂooded areas in the bi-temporal SAR images.
Experimental results show that the classiﬁer is quite efﬁcacious in detecting changes in SAR images and conﬁrm
the validity of the proposed approach. Although the result
is rather encouraging, some further work can still be done.
For example, in our work, texture features are based on the
basic statistics of the local pixel intensity. In fact more texture features, such as some wavelet-based texture features,
can be added into our method and may bring an even better
performance.

[3] Y. Freund and R. E. Schapire. A decision-theoretic generalization of on-line learning and an application to boosting.
Journal of Computer and System Sciences, 51(1):119–139,
1997.
[4] J. Inglada. Change detection on sar images by using a parametric estimation of the kullback-leibler divergence. In Proceedings of the 29th Geoscience and Remote Sensing Symposium, IGARSS, volume 6, pages 4104–4106. Toulouse,
France, 2003.
[5] L. Li and M. K. Leung. Robust change detection by fusing
intensity and texture differences. In Proceedings of the 4th
Computer Vision and Pattern Recognition, volume 1, pages
777–784. Hawaii, USA, 2001.
[6] L. Li and M. K. Leung. Integrating intensity and texture
differences for robust change detection. IEEE Transactions
on Image Processing, 11(2):105–112, 2002.
[7] S. Z. Li, L. Zhu, Z. Zhang, A. Blake, H. Zhang, and
H. Shum. Statistical learning of multi-view face detection.
In Proceedings of the 7th European Conference on Computer Vision, pages 67–81. Copenhagen, Denmark, 2002.
[8] R. Meir, Gunnar, and R¨atsch. An introduction to boosting
and leveraging. pages 118–183. Artiﬁcial Intelligence Advanced lectures on machine learning, 2003.
[9] W. Peng, C. Pan, and V. Prinet. Unsupervised change detection for ﬂood analysis in sar images. In Proceedings of the
6th Asia Conference on Computer Vision, volume 1, pages
652–657. Jeju Island, Korea, 2004.
[10] P. L. Rosin. Thresholding for change detection. In Proceedings of the 6th International Conference on Computer
Vision, pages 274–279. Bombay, India, 1998.
[11] S. Theodoridis and K. Koutroumbas. Pattern Recognition
Second Edition. Academic Press, 2003.
[12] F. Wang. A knowledge-based vision system for detecting
land changes at urban fringes. IEEE Transactions on Geoscience and Remote Sensing, 31(3):136–145, 1993.
[13] Y. Wu and H. A. Maitre. Smoothing speckled synthetic aperture radar images by using maximum homogeneous region
ﬁlters. Optical Engineering, 31(8):1785–1792, 1992.

References
[1] M. Borchani, F. Cloppet, V. Atalay, and G. Stamon. Change
detection in aerial images. In Proceedings of the 1st Canadian Conference on Computer and Robot Vision, pages 354–
360. Ontario, Canada, 2004.
[2] L. Bruzzone and D. F. Prieto. Automatic analysis of
the difference image for unsupervised change detection.
IEEE Transactions on Geoscience and Remote Sensing,
38(3):1171–1182, 2000.

Proceedings of the Computer Graphics, Imaging and Vision: New Trends (CGIV’05)
0-7695-2392-7/05 $20.00 © 2005 IEEE

