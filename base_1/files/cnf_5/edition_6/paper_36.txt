Optimal Adaptive Multistage Image Coding
Golamali Rezai-Rad
Iran University of Science & Technology
Fax: +98217454055
Email: rezai@iust.ac.ir
ABSTRACT
In this article, we discuss an optimization technique of
transform image coding in the form of a multistage
procedure in which the error signal resulting from the
quantization of the previous stage is input to the following
stage. Multistage transform coding thus involves transform
domain quantization in a number of stages such that each
stage attempts to correct the error in the previous stage. In
the technique discussed in this article, the bits are allocated
to the pixels of each stage when the number of stages and
the total bit rate are given.
Keyword: optimization technique, multistage coding.
Figure 1. Block diagram of multistage image transform coding.

1. Introduction

There are different kinds of quantizers such as optimum
mean square (Lloyd-max) and uniform optimal quantizer
[1]. The optimum mean square quantizer is used in this
article. Suppose ekij and êkij are the input and the output of
the optimum mean square quantizer. They have the
following properties [2].
(1)
E (ekij ) E (eˆkij ) o E (ekij  eˆkij ) E (e( k 1) ij ) 0

The method to be discussed in this article involves optimal
adaptive multistage transform coding with a fixed total
number of bits per pixel and a fixed number of stages. It is
optimal in the sense that it minimizes the total final
reconstruction error with the given total number of bits and
stages. The statistics of the coefficients in different stages
are used to optimize the division of the total number of bits
among different stages. The adaptivity introduced does not
significantly add to the complexity of the coding system
since it utilizes the information that is necessary for any
kind of multistage transform coding. Simulation results
have shown a considerable percentage decrease in
reconstruction error in a large number of test images. In
addition, the remaining error image is more noise- like than
the error image in one stage coding, especially with reduced
error around the edges. Smooth areas of the image look
smoother with multistage coding than one stage coding as
well. These are believed to be the main reasons why
multistage transform coding gives subjectively more
pleasing results than one stage coding at the same bit rate.
There are a number of subjective and objective error
measures to quantify the quality of image reconstruction,
but the mean square error (MSE) is the most widely used.
The MSE is also the measure in this article to be used to
compare experimental results. The experimental results will
also be discussed in terms of subjective performance.

E (ekij eˆkij )

>

2
E (eˆkij
) o E eˆkij (ekij  eˆkij )

@

0

(2)

(3)
>1  f k (bkij )@V
Vˆ
The following equation can be derived from Eqs. (1), (2)
and (3):
2
2
>1  f k (bkij )@V kij2 k=1,2,…,n-1 (4)
E (ekij eˆkij ) E (eˆkij
) Vˆ kij
2
kij

2
kij

Referring to fig.1, the final reconstructed image is formed
by taking the inverse transform of (Ê0+ Ê 1+…+ Ê n-1).
Therefore the mean square error (MSE) is given by
1 N 1 N 1
2
(5)
MSE
E >e  (eˆ  eˆ  ...  eˆ
)@
N2

¦¦
i 0

0ij

0 ij

1ij

( n 1) ij

j 0

Using Eq. (2) and the fact that the average value of the
coefficients in each stage, excluding the DC coefficient of
the first stage, is zero, the following is obtained at stage k:
2
2
(6)
E (ekij  eˆkij ) 2 V (2k 1) ij V kij
 Vˆ kij

>

@

Applying Eq. (6) to stage k+1, we have

>

E (e( k 1)ij  eˆ( k 1)ij ) 2

@

V (2k 1)ij  Vˆ (2k 1)ij

(7)

V kij2  Vˆ kij2  Vˆ (2k 1)ij

2. The MSE

By iterating Eq. (7) and used Eq. (4), the MSE for n stages
becomes

The block diagram for adaptive multistage transform
coding is shown in Fig.1. The transform coefficients of the
first stage are assumed to have little correlation so that they
are quantized and coded independently with an optimal bit
map for the first stage to be considered. The two
dimensional error signals resulting from the first stage
quantization is fed to the second stage and subsequently
quantized and coded with another optimal bit map. This
procedure is continued for the given total number of stage.

MSE

1 N 1 N 1 2
¦¦ V 0ij f0 (b0ij )  V 12ij  f1 (b1ij )  1  ...
N2 i 0 j 0

>

(8)

@

 V (2n 1)ij  f n 1 (b( n 1) ij )  1

Eq. (8) is the objective function that is to be minimized in
order to achieve the minimum mean square error. The
procedure of bit allocation in order to minimize this
function is given in the next section.

1

Proceedings of the Computer Graphics, Imaging and Vision: New Trends (CGIV’05)
0-7695-2392-7/05 $20.00 © 2005 IEEE

2- Calculate the marginal return, ǻkij, which is the
reduction in the total final error given by Eq. (8)
if 1 bit is assigned to the coefficient ekij , for
k=0,1, and i,j=1,…,N.
3- Allocate one bit to the coefficient ekij which
has the largest marginal return ǻkij.
4- If the total number of assigned bits is equal to
or greater than the total number of bits, stop;
otherwise go to step 2 to decide for the next bit.

3. Error Models and Optimal Bit Allocation
In general, an analytic expression for the quantizer error is
desirable. Usually, such an expression is given in terms of
the variance of the input sequence to the quantizer, the
number of bits (or the number of levels) used for
quantization, and some parameters that depend on the
distribution of the input. In the case of the optimum mean
square (Lloyd-Max) quantizer, the MSE is usually
expressed in the form of

V kij2 f k (bkij )

where

f k (bkij ) a

If ties happen in step 3, the same procedure is repeated
among the coefficients which have the same value for ǻkij
by assigning another bit to these coefficients and looking
for the winner.
The above procedure for bit allocation can be applied to
find the bit map that minimize the total final reconstruction
error for the multistage transform coding if the multiclass
adaptive method is not used for each stage. In deriving the
estimated total final error given in Eq. (8), we assume that
the coefficient ekij is the resulting error of quantizing the
coefficient e(k-1)ij. On the other hand, if the multiclass
adaptive method is used, the class map of each stage is
possibly different, so the above assumption does not hold.
For multiclasses, we introduce another method of
optimization to minimize the total error. In this method, we
first derive a relation between the total average rate R, and
the average rate for each stage RK, K=0,...,n-1.
When the average rate of each stage is known, the bit
allocation procedure for each stage can be done
independently. It is also possible to use different number of
classes for the following stages since the spectra in those
stages are more flat than the first stage.
First we will find the relation between R and Rk , k=0, …,
n-1 for n=2 (two stages). Then, we will show that for n3
the procedure is straightforward. For n=2, the problem is

function of is bkij and the probability density function (pdf)
of the input signal to the quantizer. One such expression for
f k (bkij ) for Gaussian distribution is given by [12].
­°1.32(2 1.74 bkij ) for bkij around 2
(9)
®
1.96 bkij
) for bkij around 5.17
°¯2.21(2
Another approximate model in the case of Gaussian
distribution is given by [9].
­2 1.57bkij
for bkij d 2.32
°°
(10)
f k (bkij ) ® 2.698 2 2bkij
for bkij t 2.32
° 2b kij
 0.8532) 3
¯° (2
Some other error functions have been reported for both
Gaussian and Laplacian distributions in Ref. [2] and are
given in table 1.
f k (bkij )

Table 1. The error model for Gaussian and Laplacian distribution of
the form fk (bkij) = A2-Bbkij given in Ref. [2].
Distribution

0  bkij  2.32

2.32  bkij  5.17

5.17  bkij  9

A

B

A

B

A

B

Gaussian

1

1.5047

1.5253

1.8274

2.2573

1.9626

Laplacian

1

1.1711

2.0851

1.7645

3.6308

1.9572

­
°min imize
°
®
°subject to
°¯

All of the above models are either for the gaussian or the
Laplacian distribution. In practice, the input to the quantizer
usually has neither Gaussian nor Laplacian distribution
exactly but some distribution closes to one of them.
Having the error models for each stage, the total final error
given in Eq.(8) can be minimized through an optimal bit
allocation procedure.

1
N2
1
N2

The variances

N 1

N 1

i 0

j 0

N 1

N 1

i 0

j 0

¦ ¦ >V

f 0 (b0ij )  V 12ij  f 1 (b1ij )  1

0 ij

 b1ij

¦ ¦ >b
V 1ij2

@

2
0 ij

@

(11)

R

depend on the bits b0ij allocated to the

first stage, which is not known in advance. In order to get
around this problem, we will first assume that the variance

Coefficients in each stage usually have different
variances, and their variances are also different
from stage to stage. Therefore, different number
of bits should be assigned to each coefficient. The
major constraint that should be satisfied is that
the total number of bits is fixed. In this article, we
use marginal analysis described in Ref. [3] to
develop an optimal method with integer number
of bits. The piecewise error models given in
Table 1 are strictly convex functions and
guarantee that the global minimum is achieved.
Here, we give the steps for bit allocation with 2
stages. The steps involved in bit allocation
according to marginal analysis are as follows:
1- Set bkij =0, for k=0, 1 and i, j =0, 1, N-1.

of the coefficients of both stages,

2
V 0ij

and

V 1ij2

, for i,j =1,

…, n-1, are available. Based on this , we will derive the
optimal bit rates for two stages. Once the rates are known,
the new values of

V 1ij2

will be computed. The process is

iterated with these new values until the optimum point is
reached. In practice, we found that two or three iterations
are sufficient.
In the analysis, we will assume that b0ij and b1ij are
continuous. Since we are looking for an analytical
expression for the rates R0 and R1, the error functions f0(.)
and f1 (.) must be known, The piecewise functions given in
Table 1 can be used for marginal analysis bit allocation, but
it is not easy to use them in the above minimization
problem. Instead, we try to approximate these functions
with another function in the form of fk(bkij) = 2-Bkbkij ,for k

2

Proceedings of the Computer Graphics, Imaging and Vision: New Trends (CGIV’05)
0-7695-2392-7/05 $20.00 © 2005 IEEE

= 0,1. We choose the single parameter Bk such that the
proposed function is the closest approximation to the
corresponding piecewise model in the least mean square
sense. Figs. 2 and 3 show the approximation for particular
Bk. It is observed that the fit is very close. The problem can
now be restated in the following form:
­
°min imize
°
®
°subject to
°¯

1
N2

N 1

N 1

i 0

j 0

N 1

N 1

i 0

j 0

¦ ¦

1
N2

>V

2
0 ij

¦ ¦ >b

0 ij

2

 B0 b0 ij

 b1ij



 V 12ij 2

@

 B1b1ij

@

1

4. Results
The multistage transform coding technique discussed above
was applied to a set of different images of sizes 128×128,
256×256 and 512×512, shown in fig. 4. All images were
quantized with 8 bits (256 levels.) The number of stages
used were either 2 or 3. The two-dimensional DCT was
used as the unitary transform. Coding was carried out with
a block size of 16×16. We compared multistage transform
coding with one stage coding. The adaptive coding
tachnique of Chen and Smith [5] with 4 classes was used
for each stage. The total rates used were 1.0, 0.5 and 0.25
bits per pixel (bpp).
For the first stage, the optimum mean square error quantizer
was used with the Laplacian distribution for the AC
coefficients and the Gaussian distribution for the DC
coefficients. The optimum mean square quantizer with
Gaussian distribution for all the coefficients was used for
the second stage. This choice was based on the statistical
tests explained in Sec. 3.
For two stages with one class (without using Chen and
Smith adaptive method), the total number of bits were
allocated according to the marginal analysis method
discussed in Sec.3 to minimize the total final error function
given by Eq.8). For this case, two schemes are possible.

(12)

R

Using the Lagrange multiplier method [4] for this
optimization problem, it is easy to show that
§ V 02ij ·
§ B ·º
B1
1 ª
(13)
b0ij
b1ij 
«log 2 ¨ 2 ¸  log 2 ¨¨ 0 ¸¸» .
¨
¸
B0
B0 «¬
© B1 ¹»¼
© V 1ij ¹
By taking the summation over i and j of both sides of
Eq.(3), and defining
1 N 1 N 1
(14)
S0
¦ ¦ log 2 V 02ij
N2 i 0 j 0
and
1 N 1 N 1
(15)
S
log V 2
1

N2

¦¦
i 0

2

1ij

j 0

we obtain
R0

§ B0 · º
B1
1 ª
R1 
« S 0  S1  log 2 ¨¨ ¸¸»
B0
B0 ¬
© B1 ¹¼

Either the variances of the second stage

(16)

= V 0ij2 f0 (b0ij), or we can start from initial rates for the first

1
N2

N 1

N 1

¦¦
i 0

and second stages and then iterate once the variances of the
second stage are known. Our experiments showed that the
second scheme is not as efficient as the first scheme. In
addition, the first scheme is much better of computational
cost. Therefore, we chose the first scheme.
For the two stage multiclass adaptive method, we used
Eq.(19) to allocate the total bits between two stages. In this
case, we started with the initial rates R0 = R and R1= 0. This
choice was based on our observation that, for optimum rate
division, R0 is usually greater than R1.
In most cases one or two iterations were sufficient to get the
optimum rates R0 and R1.
In all simulations, 8 bits were allocated to the DC
coefficients of the first stage. Thus, in computing S0 with
Eq. (14), the variance of the DC coefficient was not
included in the sum. For the same reason, 8/N2, which is the
average bit rate of the DC coefficient at the first stage was
subtracted from R in Eq. (19). For the second stage, the DC
coefficients have on average close to zero, which is easily
justified by Eq. (1).
Table 2 shows the numerical results. In this table we
included the optimum rates for each stage. In the case of
two stages, the multistage transform coding resulted in as
much as 14.65% improvement for one class and 11.54%
improvement for 4 classes. Fig. 5 shows some of the
reconstructed images using multistage image transform
coding with different rates for both one and multiclasses.
The corresponding one stage coding results are also shown
for comparison. It is observed that the results of multistage
coding are more preferable than the results of one stage
coding.

(17)

b0ij

j 0

and
1 N 1 N 1
(18)
¦ ¦ b1ij
N2 i 0 j 0
Using the fact that R0 + R1 = R, the average rate for the first
stage becomes
ª
§ B ·º
B1
1
(19)
R
R
S  S  log ¨ 0 ¸
R1

0

«
B0  B1 ¬

B0  B1

0

1

2

¨ B ¸»
© 1 ¹¼

Then, R1 is found as R-R0.
Extending the above procedure to the case n = 3 is easy.
Suppose we can approximate the error function model of
the third stage by f2 (b2ij) = 2-B2b2ij, for some B2 (see Sec.
2.5.) Then, similar to Eq. (2.16), the following equation is
derived:
R1

§ B1
B2
1 ª
R2 
« S1  S 2  log 2 ¨¨
B1
B1 ¬
© B2

·º
¸¸»
¹¼

(20)

where
R2

N 1

N 1

i 0

j 0

1
N2

¦¦

1
N2

¦¦

b2ij

(21)

log 2 V 22ij

(22)

and
S2

can be

estimated by the known variances of the first stage by V 1ij2

where

R0

V 1ij2

N 1 N 1
i 0

j 0

The above procedure can be generalized to any number of
stages. Once the average bit rates for each stage are known,
the bit allocation for each stage can be done independently
by using marginal analysis or any other techniques for any
desired number of classes

3

Proceedings of the Computer Graphics, Imaging and Vision: New Trends (CGIV’05)
0-7695-2392-7/05 $20.00 © 2005 IEEE

Table 2. Simulation results for multistage transform coding

6. Conclusions
Both theoretical and experimental results indicate that
optimal adaptive multistage image transform coding is quite
effective in reducing mean square reconstruction error over
what is possible with one stage transform coding.
Optimality is achieved by the minimization of the total final
error using marginal analysis. This minimization
determines how to allocate bits to the coefficients in each
stage. After the first stage, the pdf of the coefficients appear
to be either Gaussian or uniform. The reconstruction of the
quantized image is obtained by adding together the
quantized transform coefficients from all the stage and
computing a single inverse transform of the results. Further
improvements in the techniques described are expected to
reduce reconstruction error more.
In this article, we considered MSE as the performance
criterion. However, the difference images indicate that the
reconstruction errors are more noise-like in multistage
coding than it one stage coding, with especially reduced
errors at the edges. The smooth regions are also smoother.
These are believed to be the reasons why the reconstructed
images with the multistage method are subjectively much
more preferable than the reconstructed images with the one
stage method at the same bit rate.

We also tested three stages, at the total rate of 0.5 bpp with
using 4 classes, the original image girl 256 shown in Fig. 4.
The results showed 13.88% improvement over one stage.
This is 5.33% more than the improvement with two stages,
and the same type of improvement is expected for other
cases.

5. Discussion
As mentioned in Sec. 4, a large number, but not all, of
coefficients in the second stage have a pdf close to
Gaussian. Since one kind of pdf is usually assumed during
quantization, we chose the Gaussian pdf in Secs. 3 and 4.
Even though, more than one choice of pdf is possible, it
increases the overhead information that should be known
during decoding. Thus, for one kind of pdf assumption, we
have the error of mismatch between the assumed pdf and
the real pdf for some coefficients. This error was
experimentally studied by Mauersberger [6]. The reported
results show that the error resulting from using Gaussian
quantizer for a random variable with Laplacian pdf is more
than the error resulting from using Laplacian quantizer for a
random variable with Gaussian pdf (assuming the same
variance and number of levels.) In practice, the total error
depends on the number of mismatch cases. For the third
stage in multistage image transform coding, our statistical
tests showed that the coefficients have a mixture of
uniform, Gaussian and Laplacian pdf. Again, since more
than half of them have Gaussian pdf, we used the Gaussian
quantizer. We are investigating further how the mismatch
error can be minimized for multistage image transform
coding. One possible solution is to use a bit allocation
method that can be adapted to any kind of probability
density function for coefficients and where the error
function can be calculated iteratively. Specifically, we are
studying the implementation of the method given by
Shoham and Gersho [7] for this problem.
It must be mentioned that the multistage procedure
discussed in this article will slightly increase the overhead
information. The main part of overhead information is the
bit map. For the optimal multistage image transform
coding, we assume that the total number of bits (or the
corresponding total average rate) is fixed. When the total
rate is divided between stages, more number of pixels per
stage assume zero bits. Thus, the overhead information is
not doubled.

Figure 2. Approximation of the error model of Gaussian pdf given in
Table 2 with Bk=1.52 in the form of fk(bkij)=2-Bkbkij

Figure 3. Approximation of the error model of Gaussian pdf given in
Table 2 with Bk=1.23 in the form of fk(bkij)=2-Bkbkij

4

Proceedings of the Computer Graphics, Imaging and Vision: New Trends (CGIV’05)
0-7695-2392-7/05 $20.00 © 2005 IEEE

[7] Y. Shoham and a. Gersho, “Efficient Bit allocation for an
Arbitrary Set of Quantizers,” IEEE Transactions on Acoustics,
Speech, and Signal Processing, Vol. 36, No. 9, September 1988.
[8] A. Segall, “Bit Allocation and Encoding for vector sources,”
IEEE Transactions on Information Theory, , Vol. 22, No. 2, pp.
162-16987, March 1976.
[9] R. C. Wood, “On Optimum Quantization,” IEEE Transactions
on Information Theory, Vol. 15, No. 2, pp. 248-252, March 1996.

Figure 4. Original Image a: 128×128 b, c: 256×256

Figure 4. Reconstructed image of: (a) 256×256 for one stage coding
with rate 0.5 bpp and 1 class (b) 256×256 for two stage coding with
rate 0.5 bpp and 1 class (c) 256×256 for one stage coding with rate 0.5
bpp and 4 class (d) 256×256 for two stage coding with rate 0.5 bpp and
4 class

Refrences
[1] J. Max, “Quantization for minimum Distortion,” IRE
Transactions on Information Theory, Vol. 6, pp. 7-12, March
1960.
[2] A. K. Jain, Fundamentals of Digital Image Processing,
Prentice-Hall, New Jersey, 1989.
[3] B. Fox, “Discrete Optimization via Marginal Analysis,”
Management Science, Vol. 13, No. 3, pp. 210-216, November
1966.
[4] D. Luenberger, “Linear and Non-linear Optimization,”
Academic Press, 1986.
[5] W. H. Chen and H. Smith, “Adaptive Coding Of Monochrome
and Color Images,” IEEE Transactions on Communications, Vol.
25, No. 11, pp. 1285-1292, Novamber 1977.
[6] W. Mauersbereger, “Experimental Results on the Performance
of Mismatched Quantizers,” IEEE Transactions on Information
Theory, Vol. 25, No. 4, July 1979.

5

Proceedings of the Computer Graphics, Imaging and Vision: New Trends (CGIV’05)
0-7695-2392-7/05 $20.00 © 2005 IEEE

