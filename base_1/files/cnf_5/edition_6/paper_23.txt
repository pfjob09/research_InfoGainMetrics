Disturbance-rejecting Method for Cooperative Object Pose Estimation
from Binocular Images
Yang Shang, Qifeng Yu, Zhihui Lei, Lichun Li
Lab 108, Dept. of Astronautics, National Univ. of Defence Technology,
Changsha, Hunan 410073, P. R. China
(shanman~1977@,sina.com}
Abstract
A disturbance-rejecting method for measuring a
cooperative object’s pose from binocular images is
presented. The presented method optimizes the
parameters of the objectS pose and modiJies some
measure system parameters simultaneously by bundle
adjustment based on initial values. Experiments data
show that the method converges quickly and stably, gives
accurate results and dos not demand accurate initial
values. Especially, when the measure system parameters
are disturbed, this method still gives accurate results.
Keywords--- Disturbance-rejecting, Binocular,
Cooperative object pose, Bundle adjustment

paper uses three or more cooperative target points to
estimate a cooperative object’s pose based on binocular
images. The method solves initial values first and then
optimizes the object’s pose parameters by bundle
adjustment. Some measure system parameters are
modified simultaneously to solve the problem fetched
from the disturbance on the cameras’ pose relative to the
robot. Experiments data show that the presented method
converges quickly and stably, gives accurate results and
dos not demand accurate initial values. Especially, if the
measure system parameters are disturbed, this method
still gives accurate results while monocular method and
directly linear intersection method can not give accurate
results.

2. Principle and calculation
1. Introduction

2.1. Measure system and imaging model

In the field of intelligent robots with visual function,
to estimate the objects’ pose from images is needed.
Researchers presented many methods to measure a
cooperative or uncooperative object’s pose from
monocular or binocular images[1-1 11.
What we really want in the measurement is the
object’s pose relative to the robot but not to the cameras
fixed on the robot. So the cameras’ accurate pose relative
to the robot must be known. The general method is to
calibrate these system parameters accurately after
installing the cameras on the robot. Then during the
applications, the cameras’ pose to the robot must be
stable or the cameras’ movement relative to the robot
must be controlled and so the cameras’ present pose to
the robot is known accurately. But, in some applications,
especially if the robot has to work in vibratory
environment or the robot has to move acutely, the pose
relationship between the cameras and the robot can not
be controlled accurately. Monstrous errors will be
fetched from these system parameters’ disturbance as
shown by the experiments data in this paper. This will
make the results unbelievable.
The presented disturbance-rejecting method in this

The measure system in this method is shown in Fig.
1. O G - X G Y d G is the object coordinate system.
(x&,Y~i,&i) is the i-th cooperative target point Pi‘s
object coordinate. O,X,Y,Z, is the reference coordinate
system fixed on the robot. The parameters to describe the
object’s pose relative to the robot are the translation
TzGB) and the rotation angles
parameters (TXGB,TyGB,

(AXGBJY G ~ Z G B ) .
Object

Fig. I Measure system

The imaging model used is described by the
following collinear equations,

means the left camera's
Where the subscript
parameters and means the right camera's parameters.
(Cx,Cy) is the coordinate of the cameras' principal points.
Fx and Fy are the cameras' effective focal lengths. 6x
and 6 y are the lens distortion. r r r a are the cameras'
rotation matrices' elements which are combinations of
the cameras' rotation angles relative to the reference
coordinate system, Ao, AI and A2's trigonometric
functions. And To, TI and T2are the cameras' translation
parameters relative to the reference coordinate system.
All these measure system parameters can be calibrated
previously. Many methods can be chosen for
calibration[9, 12-17]. In the experiments of this paper,
lots of control points are used to calibrate the measure
system parameters.
In Eq. (l), (XB,YB,ZB)is the cooperative target
points' reference coordinate. (xL,yL)and ( X R J R ) are the
target points' projection on the left image and on the
right image respectively. The relationship between
(,YE, YB,ZB) and the target point's
object coordinate
(XG,*G,ZG)is,

1

xB

=

'0GBxG

'B

=

'3GBXG

' B

= ' 6 G B X G + '7GB'G

optimize the parameters to be solved based on the bundle
constraints to reach accurate results.
In the presented method, besides the object's pose
parameters TXGB,TYGB,TZGBand AXGB,AYGB,AZGB,the
right camera's rotation angles relative to the robot AOR,
AIR, A2R and its Y direction translation parameter T I Rare
chosen to be adjusted to solve the disturbance problem.
Analyse and experiments show that when the rotation
angles and the distance between the two cameras are
disturbed, the results of linear intersection will be
effected badly. To adjust AOR, A I R and AZR can
compensate the disturbance on the rotation angles
between the two cameras. And to adjust TIR can
primarily compensate the disturbance on the distance
between the two cameras when the two cameras are
installed primarily along the OBYB direction as Fig. 1.
By substituting Eq. (2) into Eq. (l), non-linear
condition equations on the above values to be adjusted
are obtained, (Only the condition equation corresponded
to the first equation of Eq. (1) is shown following)
4 x L (TXGB, ~ y mGGB,
,
~ x m~ ,Y c ~w z mAOR, AIR A,, ,T R ) = 0 (3)
Expend the non-linear condition equations into
Taylor series and choose the first terms, linear correction
equations are obtained, (Only the correction equation
corresponded to the first equation of Eq. (1) is shown
followina)
9

9

+ 5 G B ' G + ' 2 G B Z G + 'XGB
"4GB

*G

"5GB'G

+ TYGB

+ '8GBZG

+ TZGB

(2)

Where TXGB, T ~ G Band TZGB are the object's
translation parameters and T O G r r a G B are a rotation
matrix's elements which are combinations of the object's
rotation angles AXGB,AYGBand AZGB.

2.2. Solving the initial values of the object pose
A direct method to solve the object's pose
parameters' initial values is linear intersection. By
substituting Eq. (2) into Eq. (l), linear equations with
the unknown rOGrraGB and TXGB, T y ~ a , T z G B are
obtained. If there are three or more target points, the
equations can be solved linearly and the object's
rotation angles can be obtained by decomposing the
rotation matrix. In this step, all the measure system
parameters are taken as known.

2.3. Solving the object pose and some measure
system parameters by bundle adjustment
Bundle adjustment is a kind of observed data
processing method widely used in photogrammetry,
surveying and mapping[ 18-21]. Bundle adjustment

Where PTXGB, PTYGB, PTZGB, PAXGB, PAYGB, PAZGB, PAOR,
PAIR,PAZRand ,uT]R are the corrections of the values to be
adjusted. Solve the correction equations and use these
corrections to modify the values to be adjusted. Then
substitute the modified values into the condition
equations and the correction equations. Iterate the above
course until it stably converges to final results. When
there are three or more cooperative target points, this
binocular bundle adjustment with the object pose and the
chosen measure system parameters to be modified can be
realized based on initial values.

3. Verified experiments
Each of the CCD cameras used in the experiments
has 1376X 1036 pixels. Each pixel's width is 4.65 pm.
And the focal lengths are 15mm. The distance between
the two cameras is 0.8 meter. A discal object is installed
on a precision six-degree movable-rotary table. The table
controls the object's movement and gives real data of the
object's pose parameters. This cooperative object is
shown in Fig. 2. Where the 5 X 5 crosses in the center of
the disk are used for previous calibration. The four
crosses installed on the top, bottom, left and right side of
the disk respectively are the cooperative target points
used to measure the object's pose. The top and the

bottom target points stretch 114mm out of the disk. The
left and the right target points stretch 40mm out of the
disk. The distance between the top and the bottom target
points is 210mm. And the distance between the left and
the right target points is also 210mm.

Tab.4 Statistical data of
binocular bundle adjustment results with
disturbed measure system parameters
TXGB
TYGB
TZGB
AXGB
AYGB
AZGB
fl

u

-0.04
0.16

-0.03
0.06

0.03
0.08

-0.005
0.017

-0.008
0.019

0.017
0.015

Tab.5 Statistical data of
monocular bundle adjustment results with
disturbed measure system parameters
TXGB
TYGB
TZGB
AXGB
AYGB
AZGB
P
0

1.34
2.01

12.45
23.03

-9.65
26.13

0.02
0.450

0.119
0.477

0.227
0.512

Tab.6 Statistical data of
binocular linear intersection results with
disturbed measure system parameters
TXGB
-45.93
u 113.76

fl

Fig. 2 Cooperative object used in experiments

In the experiments, methods of binocular bundle
adjustment, monocular bundle adjust and binocular linear
intersection are used respectively to measure the object's
pose with steady measure system parameters or with
disturbed measure system parameters. Tab. 1-6 are the
statistical data of lots of experiments results. Where the
unit of translation parameters errors is mm. And the unit
of rotation angles errors is . ,LL is mean error. And ois
mean square error. In the experiments, the distance
between the object and the cameras is about 2 to 3 meters.
In the experiments with measure system parameters
disturbed, disturbance with mean square error of 0.5" is
added in the right camera's rotation angles. And
disturbance with mean squre error of lmm is added in
the right camera's translation parameters.
O

Tab.1 Statistical data of
binocular bundle adjustment results with
steady measure system parameters
TXGB
TYGB
TZGB AXGB
AYGB
AZGB
fl
0

0.03
0.12

-0.01
0.05

0.01
0.08

-0.003
0.014

0.014
0.017

0.018
0.016

Tab.2 Statistical data of
monocular bundle adjustment results with
steady measure system parameters
fl
0

TXGB
0.08
0.23

TYGB
-0.06
0.06

TZGB
0
0.08

AXGB
-0,001
0.019

AYGB
0.016
0.016

AZGB
-0.021
0.017

Tab.3 Statistical data of
binocular linear intersection results with
steady measure system parameters
TZGB AXGB
AYGB
AZGB
TXGB
TYCB
P
0

0.09
0.28

-0.03
006

0.02
0.08

-0.002
0.016

0.020
0.027

-0.019
0.031

TYGB
-6.48
12.01

TZGB

AXGB

AYGB

4.39
13.18

-0.110
0.272

0.121
0.676

AZGB
0.098
0.301

Conclusions
From the experiments results, following conditions
are reached.
1). When the measure system parameters are stable,
results of binocular bundle adjustment are better than the
results of monocular bundle adjustments, especially on
TxGB. Binocular bundle adjustment is also better than
binocular linear intersection, especially on TXGB.A y c B
and AZGB.
2). When the measure system parameters are
disturbed, errors of monocular bundle adjustments and
binocular linear intersection results are very large. While
results of binocular bundIe adjustment are still good as
the measure system parameters are not disturbed.
Binocular bundle adjustment avoids the badly effect
fetched from the disturbance of measure system
parameters.
3). The presented method does not need the initial
values be very accurate. Experiments and simulated data
show that when the objective-distance is great and the
measure system parameters are disturbed, results of
linear intersection are very large, even unbelievable.
While the binocular bundle adjustment taken the linear
intersection results as initial values still gives accurate
results.
4). The presented method is stable and converges
quickly. Generally, less than ten times iterative is enough.

Acknowledgements
Thanks go to Mr. Chen Yanshan, Ms. Zhang Chao,
Mr. Li Wenjun, Ms. Zhang Shuqin, Mr. Jia Jingcheng,
Mr. Chuang Jiayou, Mr. Pan Zhigang, Mr. Mai Miao, Mr.
Chen Hao and Beijing Institute of Target & Environment
Features for their help in the experiments.
This project is financially supported by the National

Natural Science Foundation of China (NO. 10472133)

References
[I] Brodia T. J., Chellappa R. Estimating the kinematics and
structure of a rigid object from a sequence of monocular images.
IEEE Trans PAMI, 13:497-512. 1991.
[2] Huang Y M, Zhou S A, Wang L X, et al. Optical
measurement of object aerocraft position and pose. Journal of
Astronautics, 14( 1):97-103. 1993.
[3] Mukundan R, Narayanan R V R, Philip N K. A vision based
attitude and position estimation algorithm for rendezvous and
docking. Journal of Spacecraft Technology,4(2):60-67. 1994.
[4] Gregory D Hager, Chang Wen-Chung. Robot Hand-eye
Coordination Based on Stereo Vision. IEEE Control Systems
Magazine, 15 (1): 30-39. 1995.
[5] M. A, Abidi, T. Chandra. A new efficient and direct solution
for pose estimation using quadrangular targets: Algorithm and
evaluation. IEEE Trans. on Pattern Analysis and Machine
Intelligence, 17(5): 534-538. 1995.
[6] K. Kanatani, N. Ohta. Optimal robot self-localization and
reliability evaluation. European Con$ Computer Vision, 796-808.
Freiburg, 1998.
[7] Chang C C, Tsai W H. Reliable Determination of Object Pose
from Line Features by Hypothesis Testing. IEEE Transactions on
Pattern Analysis and Machine Intelligence, 21(12): 1235-1241.
1999.
[8] Kim B H, Roh D K, Lee J M, et al. Localization of a mobile
robot using images of a moving target. Proceeding ofthe 2001
IEEE International Conference on Robotics & Automation, 253258. Seoul, Korea, 2001.
[9] Yu Q F, Lu H W, Liu X L. Exact Measurement and Motive
Measurement Based on Images. Beijing: Science Press. 2002.
[lo] Hao Y M, Zhu F, Ou J J. 3D visual methods for object pose
measurement. Journal of Image and Graphics, 7A(12): 12471251.2002.
[ll] Yang Shang, Qifeng Yu, Xiaohu Zhang. Analytical method
for camera calibration from a single image with four coplanar
control lines. Applied Optics, 43(28):5364-5369.2004,

[12] R. Y . Tsai. A versatile camera calibration technique for
high-accuracy 3D machine vision metrology using off-the-shelf
TV cameras and lenses. IEEE Journal of Robotics and
Automation, 3(4): 232-344. 1987.
[I31 J. Weng, P. Cohen, and M. Hemiou. Camera calibration
with distortion models and accuracy evaluation. IEEE Trans. on
Pattern Analysis and Machine Intelligence, 14(10):965-980.
1992.
[14] Z. Zhang. A flexible new technique for camera calibration.
Technical Report MSR-TR-98-71, Microsoft Corporation,
Washington. 1998.
[15] Quan T H,Yu Q F. High-accuracy calibration and correction
of camera system. Acta Automatca Sinica, 26(6):748-755. 2000.
[ 161 Qiu M L, Ma S D, Li Y. Overview of camera calibration for
computer vision. Acta Automatca Sinica, 26(11): 43-55. 2000.
[17] Gong C H, Yuan J X, Ni J. A self-calibration method for
robotic measurement system. Transaction of the ASME Journal
of Manufacturing Science and Engineering, 122 (1) : 174-181.
2000.
[18] Wang Zhizhuo. Principles of Photogrammetry. Beijing:
Surveying & Mapping Press. 1979.
[I91 S . Granshaw. Bundle adjustment methods in engineering
photogrammetry. Photogrammetric Record, 10(56):181-207.
1980.
[ZO] Wang Zhizhuo. Principles of Photogrammetry (with Remote
Sensing) . Wuhan : Wuhan Technology University of Surveying
and Mapping Press . 1990.
[21] Bill T, Philip M, Richard H, Andrew F. Bundle adjustment A modem synthesis. In K Triggs, A. Zisserman, and A. Szeliski,
editors, Vision Algorithms: Theory and Practice, LNCS, Springer
Verlag: 298-375. 2000.

