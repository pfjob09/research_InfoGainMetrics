2009 Sixth International Conference on Computer Graphics, Imaging and Visualization

A Fast Method for Real-time Computation of Approximated Global Illumination
Weiwei Lv∗† , Jian Lu∗ , Xuehui Liu∗ , Enhua Wu‡∗
Key Laboratory of Computer Science, Institute of Software,
Chinese Academy of Sciences, Beijing, China
Email: Weiweilv, Lujian, Lxh@ios.ac.cn; EHWu@umac.mo
† Graduate University of the Chinese Academy of Sciences, China
‡ Department of Computer and Information Science, University of Macau, Macau
∗ State

precisely, but only plausible. Moreover, for most applications
the one-bounce indirect light is enough[3]. Based on this
idea, we present a fast method for real-time rendering approximate global illuminations of dynamic scenes under area
light sources. Direct illumination is rendered with the original well-tessellated models by the convolution soft shadow
algorithms. At the same time, three textures are generated
which are color map, normal map and world position map
for pixels which are visible from the light source. A quasirandom sampling method is used to generate samples from
these three textures as the pixel light sources for the indirect
illumination. For each of these pixel lights, simplified scene
which was generated in the preprocess step is rendered with
shadow maps method as indirect illumination. At last we
blend the direct illumination image with all the indirect
illumination images to get the final result. The advantage
of this method is that we can dramatically improve the
geometry complexity of the scenes while rendering in realtime, because the indirect illumination which used to be
the bottle-neck of the whole system is now rendered with
simplified models for the shadow maps generation pass.
Furthermore, with the help of modern graphics hardware,
it is easy to render a relatively simple scene thousands of
times in one second.

Abstract—We present a fast method for real-time computation of approximated global illumination for fully dynamic
scenes under area light sources. To accelerate the computation,
we use simplified models to calculate the indirect illumination,
while render the direct illumination with original complex
models. After direct illumination is computed with convolution soft shadow maps algorithm, color, position and normal
textures are generated, from which a Halton quasi-random
sampling method is used to produce the pixel lights for the
second bounce. Our testing models show that thousands of
passes can be rendered with the simplified scenes in one second
for the indirect illumination, and it can dramatically improve
the frame rate for relatively complex scenes. Final image is
generated by blending direct image and all indirect images.
Keywords-soft shadow; global illumination; indirect illumination;

I. I NTRODUCTION
Global illumination is an important and challengeable
research field of realistic graphics. Compared with local
illumination it needs not only to compute the impact of the
light source to the objects of the scene, but also to calculate the inter-reflections among these objects. Traditional
solutions are the ray tracing and radiosity algorithms[1],
but none of these two methods can be implemented in
real-time. The challengeable problem of real-time global
illumination rendering is how to quickly determine whether
two points are mutually visible or not. The visibility test is
the most time-consuming part of the algorithms and it cues
where is shadowed in the scene. Although traditional shadow
algorithms such as shadow volumes and shadow maps[2]
can quickly render the shadow effect of direct light sources
and are widely used in industry especially the shadow
maps algorithm, they are only suit for point light sources.
For area light sources, there is an area called penumbra
between umbra and bright areas. Common methods to render
such soft shadows are the extensions of shadow volume
and shadow maps algorithm. All these make the real-time
rendering of global illumination for dynamic scenes difficult.
We assume that direct illumination takes the dominant role
of the final global illumination rendering while indirect illumination is just a low frequency phenomenon. The most obvious character of indirect illumination is the inter-reflection
among diffuse objects so it does not need to be rendered
978-0-7695-3789-4/09 $25.00 © 2009 IEEE
DOI 10.1109/CGIV.2009.24

II. R ELATED W ORK
The focus of this paper is how to render global illumination for dynamic scene under area light sources, so
the related fields relate to real-time soft shadow rendering
and global illumination including pre-computed radiance
transfer.
Soft shadow rendering: Assarsson[4][5] first extends the
traditional shadow volume method to area light sources, but
his method has the same disadvantages with shadow volume
algorithm. Rendering efficiency is widely limited by the
complexity of scene geometry so it can not be used in industry. Back-projection[6][7] method takes the shadow maps
as a discrete representation of the whole scene and back
projects the potential occluding pixels to the light source to
compute the visibility. It has serious light leak problems and
its efficiency is influenced by the size of the penumbra area.
Pre-filtered image space methods[8][9] need to compute the
62

average occlusion depth by searching the potential occluding
pixels and are still not fast enough. Convolution soft shadow
map algorithm[10] computes the average occlusion depth
in constant time by de-composing the binary value depth
comparison function into a series of basis functions. So the
rendering efficiency is highly improved and we adopted it
as the direct illumination rendering in this paper although it
is just an approximating method.
Global illumination: After radiosity algorithm is proposed, many methods have been presented to improve its
efficiency. Instant radiosity[11] uses virtual point lights
(VPLs) which are sampled by the quasi-random sampling
method to accelerate the indirect illumination rendering.
But for area light sources it needs a large amount of light
sampling to decrease the artifacts of direct illumination. For
large scenes it can not be rendered in real-time. Laine[12]
proposed an incremental method which only updates some
of the VPLs each frame, so this method can only be used
for static scenes. Imperfect shadow maps[13] used points to
approximate the scene to accelerate the generation of shadow
maps for hundreds of VPLs. But it needs to reconstruct the
shadow map by another pass to approximate the occlusion.
Approximating global illumination: This type of
methods is benefit from modern graphics hardware.
Dachsbacher[3][14] firstly uses the multiple render target
(MRT) technique to generate color, normal and position
maps while rendering direct illumination. Pixel lights are
sampled from these textures and are used to generate
indirect illumination. But he does not take the visibility
between pixels into account. The concept of anti-radiance
is proposed to make up the visibility problem[15]. Ambient
occlusion[16] is another type of approximating method to
solve the spherical light. Bunnell[17] extends it to render
indirect light by approximating the scene using circle splat.
Pre-computed radiance transfer (PRT): PRT[18][19][20]
is a quick solution of the rendering equation[21] by decomposing the equation into a series of orthogonal basis functions. The original method can only be used in static scenes.
Zhou[22] extends it to dynamic scenes by using the triple
product algorithm[23]. Ren[24] further advances it in a more
complicated math fields for dynamic scenes. Iwasaki[25] and
Wang[26] extend it to indirect light rendering.

with the simplified models which needs hundreds rendering
passes. Totally, the new method includes the following steps
and Fig. 1 shows the total rendering pipeline.
• Step 1: Pre-processing: For a complex scene, we first
simplify the models into coarse ones. Both the two
types of models are inputted to the system as data
source.
• Step 2: Direct illumination rendering: Render the direct
illumination using the convolution soft shadow maps
algorithm[10] which is also a two-pass method. Meanwhile, color, normal and world position textures are
generated in the first pass. Note that original welltessellated models are used for rendering in this step.
• Step 3: Pixel lights generation: A quasi-random sampling method is used to generate hundreds of pixel
lights from the three textures got in the previous step.
• Step 4: Indirect illumination rendering: For each of the
pixel lights, we render the scene using the traditional
hard shadow maps algorithms. This step is the bottleneck of the whole system, so we use the simplified
coarse models as the input data. A low-resolution
shadow map is used in this step since small artifact
is not obvious to the final image.
• Step 5: Blending: The direct illumination image generated in Step 2 and all indirect images generated in Step
4 are blended into the final result.
A. Direct Illumination under Area Light Source
Soft shadow will be generated under area light sources
and itself is a hard problem for rendering. Considering the
time consumption of indirect illumination rendering, we
must choose a fast soft shadow rendering method for direct
illumination and here we adopt the convolution soft shadow
maps algorithm[10] which is a prefiltering method. In the
practical implementation the resolution of the shadow map
we generated is 512x512 and a 4 order convolution is used.
The summed area table (SAT) filtering method is employed
to generate plausible result, although SAT is relatively timeconsuming compared to mipmaps filtering whose result
is not well enough for direct illumination rendering. The
difference is that our method generates not only the depth
map in the first pass but also the color, normal and world
position maps for the pixels which are visible from the light
source. All these pixels are the potential light sources for the
next bounce process and we call it pixel light. Each pixel
light’s position is provided by the position maps and so are
directions and colors which are obtained from the normal
and color maps in the same way. This method has some
similarities with reflective shadow maps[3], but the main
difference is that we consider the visibility in the indirect
illumination rendering process. Additionally, this step only
need two passes rendering and there is no performance
problem for modern graphics hardware, so we render the
original well-tessellated models in this step. Fig. 2.A shows

III. A PPROXIMATED G LOBAL I LLUMINATION
The main target of this paper is to try to do real-time
approximating global illumination for dynamic scenes with
GPU. We find that the indirect illumination in the final
image is weak and it is largely represented as the interreflection among objects. It does not need to be rendered
precisely and once bounce is enough for most applications.
This is the basic idea of our paper. So we proposed a
hybrid method which consists of two rendering processes:
the direct illumination rendering with the original welltessellated models and the indirect illumination rendering

63

Figure 1.

The rendering pipeline of our method.

will generate distortion when the triangle number of the
scene is low. This is opposite to our simplifying method.
Luckily for models with several thousand triangles this
method does not generate artifacts. Finally, when indirect
illumination is finished all these images are blended to the
direct image. Fig. 2.C is the image of the sphere scene with
only indirect illumination and Fig. 2.D is the approximated
global illumination image.
Deferred shading method: Hard shadow maps algorithm
is a two pass rendering method, so for n pixel lights we
need to render the scene 2n times. This is a bottle-neck
problem. Luckily with the help of modern graphics hardware
we can render thousands frames per second for models
with thousands of triangles. This hybrid method has one
limitation which is that there may be some discontinuities
in the final image if the difference between the simplified
models and the original models is large. To improve image
quality we can also use deferred shading technique. In the
second pass of direct illumination, two additional textures
which are the world position and normal of the pixels visible
from camera view are generated. For indirect illumination,
we can use the simplified methods only to generate the
shadow maps and the image is renderer with the position
and normal textures like deferred shading technique. The
efficiency of this method is mainly limited by the resolution
of screen.

the direct illumination and Fig. 2.B.1∼2.B.3 are the three
textures generated.
B. Pixel Lights Generation
After the previous step three textures are generated which
are color, normal and position maps. A quasi-random sampling method is implemented to get the pixel lights from
the three textures. Here we use the 2D Halton sequence to
sample n pixel lights:xi = (φ2 (i), φ3 (i)),i ∈ [0, n), where φ
is the radical inverse function[11]. Fig. 2.B.7 shows the 1024
Halton sampling points. One thing should be noticed that the
three textures generated in the previous step are located in
the GPU. But our sampling method is executed in CPU,
so the first thing we need to do is to read the data back
from GPU to CPU. As well known this read-back process
is time-consuming. Our solution is to only read back data
while necessary. We read the data back only when light or
scene changes, instead of reading them back every frame.
C. Indirect Illumination Rendering
Hybrid method: Indirect illumination rendering is the most
time-consuming part and it determines the efficiency of the
whole system. Again, we point that the indirect illumination
is a low frequency phenomenon and it is not necessary to
be rendered precisely. For some applications the indirect
illumination generated by thousands of triangles is enough.
Here we first use the quadric error metric[27] to simplify
the complex models into about several thousand triangles,
such as the Beethoven models in Fig. 4 and the furniture
models in Fig. 5. During the rendering we load the original
complex models and the simplified models in the same time
and use the simplified ones to generate indirect effect. Fig.
2.B.4 ∼ Fig. 2.B.6 shows three of the indirect images.
Another problem is that common shadow maps method
used the projective projection which will cull the objects
out which are located out of the field of view. But for the
indirect light, the light direction may cover the whole hemisphere. Here we use the paraboloid mapping[28] to generate
shadow maps. Since it is not a linear projection type, it

IV. R ESULTS AND D ISCUSSIONS
A. Results
We implemented our algorithm with Direct3D 10 and
HLSL. Table 1 lists the statistical data of our test scenes
which is run on a common computer with 2.4GHz CPU and
NVIDIA GTX 280 GPU. The triangle number of original
scene and simplified scene is listed in the second and third
column. The shadow map resolution of direct illumination is
512x512 and the resolution of screen for deferred shading
method is 800x800. We list the rendering frame rate for
different indirect shadow map resolution from 256 to 1024
to make comparison for both hybrid method and deferred

64

Figure 2. The sphere scene. Image A has only direct illumination with soft shadows. Image B shows the color (B.1), normal (B.2) and position (B.3)
textures in the top row. Three indirect illumination images (B.4∼B.6) are also provided in the second row. B.7 is the quasi-random sampling points. Image
C is rendered with only indirect illumination and image D is the final result rendered with our method.

shading method. The sphere and Torus Knot scene are not
simplified since we can do real-time rendering for these
simple scenes.
Fig. 3 is the Torus Knot scene which is a dynamic
scene. In the scene, the Torus Knot rotates around its center
axis and we can render it with global illumination in realtime. The top-right detail images show the images generated
in the opposite direction for the same frame. From the
images (such as Fig. 2.C and 2.D) we can find the indirect
shadows generated by the green and purple wall to the model
while reflective shadow maps[3][14] can not deal with the
visibility for indirect illumination. Fig. 4 is the Beethoven
scene in which the original model is about 120K triangles
and the simplified model is about 8.9K. Direct illumination
is generated with the detail model and indirect light is
generated with simplified model. The detail images on the
top-left corner are rendered with only direct illumination.
Fig. 4.A is generated with deferred shading method and the
other images are generated with hybrid method. Fig. 4.D
is rendered in line mode. Fig. 5 is the furniture scene. The
detail images on the top-left corner are the images rendered
with only direct light from the same viewpoint. From Fig.
5.B and Fig. 5.C we can find the indirect shadow effect
caused by the light bounce form the wall to the sofa and the
floor.

tea table has some artifacts which are caused by the hard
shadow maps artifacts. A direct solution is to increase the
filter size to generate much larger penumbras to simulate a
large area light source, but we did not do that to show the
problems here. Hybrid method may have some differences
with images rendered with origin detail models since we
only use simplified models to do indirect illumination. But
this can be made up by the deferred shading method.
(2)Influence of shadow map resolution for indirect illumination
The indirect light has only a little impact on the final
image which is blended with direct image and the n indirect images, so single shadow map will not influence the
final result too much. Fig. 6 proves our idea by gradually
increasing the resolution of shadow maps. We can see that
there is no clear improvement in the final image quality
while the resolution increases from 256x256 to 1024x1024.
But from table 1 we can find that the rendering efficiency
will greatly decrease from 512x512 to 1024x1024. So in this
paper we use the resolution of 256x256 if there is no special
specification.
(3)Influence of the pixel lights number
The number of pixel lights has a great impact on the
quality of the final image and it also determines the rendering efficiency. When the number of pixel lights increases
to double, the frame rate will decreases to almost half of
before. According to our test, we can get good result with
256 samples which are the practical numbers used in this
paper. Fig. 7 shows the influence of the pixel light number
to the final result.
(4)Sampling strategy of pixel lights
Here we get the indirect light positions by sampling the
three textures generated in the direct illumination pass. This
is an image space sampling method which can reduce the
time of finding intersections with scene compared to object
space method. But the three textures are generated according
to the light position, so the probability is proportional to
covering area of each object, which may produce some

B. Discussions
(1)Advantages: Our method is very fast because we use
the simplified models to render the indirect illumination
which used to be a bottle-neck problem. Since each frame
we generate the shadows using shadow maps method we
can easily simulate fully dynamic scenes. This method can
also render multiple bounces indirect luminance but this will
reduce the efficiency.
Disadvantages: Since we use the convolution soft shadow
maps algorithm to render the direct illumination, our method
has the same disadvantages with it, such as the discontinuity
of shadow edges. In Fig. 5 the soft shadow generated by the

65

Table I
T HE STATISTICAL PERFORMANCE DATA
Scene

Original Scene

Simplified Scene

Sphere
Torus Knot
Beethoven
Furniture

3.4K
4.4K
120K
60K

\
\
8.9K
3.4K

Figure 3.

Hybrid Method(fps)
256
512
1024
27∼35 22∼29 11∼13
30∼35 21∼26 10∼12
25∼28 20∼24 10∼11
29∼37 22∼28 10∼12

Deferred Shading(fps)
256
512
1024
18∼22 15∼18
8∼9
18∼21 15∼18
8∼9
17∼19 14∼16
8∼9
17∼21 14∼17
8∼9

Torus Knot scene. Four frames of the rotating Torus Knot are listed.

Figure 4. The Beethoven scene. Top-left detail images are rendered with only direct illumination. Image A is rendered with deferred shading method.
Others are rendered with the hybrid method. Image D is displayed in line mode.

Figure 5.

The furniture scene rendered with hybrid method. Top-left detail images are rendered with only direct illumination.

66

Figure 6.

Figure 7.

Sphere scene with different solutions of indirect illumination shadow map. The number of pixel lights is 256 for these images.

Sphere scene with different sample number of pixel lights. The shadow map resolution of indirect illumination is 512x512.

artifacts in some situation. Especially when the object is
large in world space, but with small projection on the light
plane, this will produce wrong result. In Fig. 1 the two walls
and the ground are the same size in world space, but in the
three textures the ground’s area is less than the two walls,
so the sampling number is less than the two walls too. As
a result, the influence of the ground to the final image is
small.

ACKNOWLEDGMENT
This project is supported by National Fundamental
Research 973 Projects (2002CB312102, 2009CB320802),
NSFC (60573155) & Grant of University of Macau.
R EFERENCES
[1] P. Dutre, P. Bekaert, K. Bala, “Advanced Global Illumination”,
A.K. Peters Ltd., 2003.
[2] J.M. Hasenfratz, M. Lapierre, N. Holzschuch, “A Survey
of Real-time Soft Shadows Algorithms”, Computer Graphics
Forum, vol. 22, no. 4, pp.753-774, 2003.

V. C ONCLUSION
A fast approximated global illumination for dynamic
scenes under area light sources is presented. Convolution
soft shadow maps algorithm is used to generate direct
illumination with the original well-tessellated meshes. Indirect pixel lights are generated in image space. For indirect
illumination, simplified meshes are used to render with
paraboloid shadow maps algorithm, so we can deal with
scenes with large geometry complexity. For the future work,
we hope to improve the sampling quality of pixel lights
in image space and generate the samples just in the GPU
instead of CPU.

[3] C. Dachsbacher and M. Stamminger, “Reflective Shadow
Maps”, In Proceedings of the Symposium on Interactive 3D
Graphics and Games, pp.203-213, 2005.
[4] U. Assarsson, T. Akenine-Moller, “A Geometry-based Soft
Shadow Volume Algorithm using Graphics Hardware”, ACM
Transactions on Graphics, vol. 22, no.3, pp.511-520, 2003.
[5] U. Assarsson, M. Dougherty, M. Mounier, T. AkenineMoller, “An Optimized Soft Shadow Volume Algorithm with
Real-time Performance”, In Proceedings of the ACM SIGGRAPH/EUROGRAPHICS conference on Graphics hardware,
San Diego, California, pp.33-40, 2003.

67

[6] G. Guennebaud, L. Barthe, M. Paulin, “Real-time Soft Shadow
Mapping by Backprojection”, In Proceedings of Eurographics
Symposium on Rendering (EGSR), Nicosia, Cyprus, pp.227234, 2006.

[21] J. Kajiya, “The Rendering Equation”, In ACM SIGGRAPH
Computer Graphics, vol. 20, no. 4, pp.143-150, 1986.
[22] K. Zhou, Y. Hu, S. Lin, B. Guo, H.Y. Shum, “Precomputed
Shadow Fields for Dynamic Scenes”, ACM Transactions on
Graphics, vol. 24, no. 3, pp.1196-1210, 2005.

[7] G. Guennebaud, L. Barthe, M. Paulin, “High-quality Adaptive
Soft Shadow Mapping”, Computer Graphics Forum, vol. 26,
no. 3, pp.525-534, 2007.

[23] R. Ng, R. Ramamoorthi, P. Hanrahan, “Triple Product
Wavelet Integrals for All-frequency Relighting”, ACM Transactions on Graphics, vol. 23, no. 3, pp.477-487, 2004.

[8] A. Lauritzen, “Summed-area Variance Shadow Maps”, GPU
Gems 3. Boston: Addison-Wesley, pp.157-182, 2007.

[24] Z. Ren, R. Wang, J. Snyder, K. Zhou, X. Liu, B. Sun, et al.,
“Real-time Soft Shadows in Dynamic Scenes Using Spherical
Harmonic Exponentiation”, ACM Transactions on Graphics,
vol. 25, no. 3, pp.977-986, 2006.

[9] R. Fernando, “Percentage-Closer Soft Shadows”, In ACM
SIGGRAPH 2005 Sketches, pp.35, 2005.
[10] T. Annen, Z. Dong, T. Mertens, P. Bekaert, H.P. Seidel,
J. Kautz, “Real-time, All-frequency Shadows in Dynamic
Scenes”, ACM Transactions on Graphics, vol. 27, no. 3, pp.18, 2008.

[25] K. Iwasaki, Y. Dobashi, F. Yoshimoto, T. Nishita, “Precomputed Radiance Transfer for Dynamic Scenes Taking into
Account Light Interreflection”, In Proceedings of the Eurographics Symposium on Rendering, pp.35-44, 2007.

[11] A. Keller, “Instant radiosity”, In ACM SIGGRAPH, pp.49-56,
1997.

[26] R. Wang, J. Zhu, G. Humphers, “Precomputed Radiance
Transfer for Real-time Indirect Lighting using A Spectral Mesh
Basis”, In Eurographics Symposium on Rendering, pp.13-21,
2007.

[12] S. Laine, H. Saransaari, J. Kontkanen, J. Lehtinen, T. Aila,
“Incremental Instant Radiosity for Real-Time Indirect Illumination”, In Proceedings of Eurographics Symposium on
Rendering, pp.277-286, 2007.

[27] M. Garland and S. Heckbert, “Surface Simplification using
Quadric Error Metrics”, In ACM SIGGRAPH, NY, USA,
pp.209-216, 1997.

[13] T. Ritschel, T. Grosch, M.H. Kim, H.P. Seidel, C. Dachsbacher, J. Kautz, “Imperfect Shadow Maps for Efficient Computation of Indirect Illumination”, In SIGGRAPH Asia, Singapore, pp.1-8, 2008.

[28] S. Brabec, T. Annen, H.P. Seidel, “Shadow Mapping for
Hemispherical and Omnidirectional Light Sources”, In Proceedings of Computer Graphics International (CGI), pp.397408, 2002.

[14] C. Dachsbacher and M. Stamminger, “Splatting Indirect Illumination”, In Proceedings of the Symposium on Interactive
3D Graphics and Games, pp.93-100, 2006.
[15] C. Dachsbacher, M. Stamminger, G. Drettakis, F. Durand,
“Implicit Visibility and Antiradiance for Interactive Global
Illumination”, ACM Transactions on Graphics, vol. 26, no. 3,
pp.1-10, 2007.
[16] S. Zhukov, A. Iones, G. Kronin, “An Ambient Light Illumination Model”, Proceedings of Rendering Techniques, 1998.
[17] M. Bunnell, “Dynamic Ambient Ocllusion and Indirect
Lighting”, In GPU Gems2: Programming Techniques for
High-Performance Graphics and General-Purpose Computation, Addision-weseley Professional, pp.223-233, 2004.
[18] P. Sloan, J. Kautz, J. Snyder, “Precomputed Radiance Transfer
for Real-time Rendering in Dynamic, Low-frequency Lighting
Environments”, ACM Transactions on Graphics, vol. 21, no.
3, pp.527-536, 2002.
[19] R. Ng, R. Ramamoorthi, P. Hanrahan, “All-frequency Shadows Using Non-linear Wavelet Lighting Approximation”,
ACM Transactions on Graphics, vol. 22, no. 3, pp.376-381,
2003.
[20] Z. Ren, K. Zhou, “A Survey on Real-Time Rendering Algorithms for Dynamic Scenes under Complex Environment
Lighting”, Journal of Computer-Aided Design & Computer
Graphics, vol. 20, no. 8, pp.957-967, 2008.

68

