2009 Sixth International Conference on Computer Graphics, Imaging and Visualization

Super-Resolution using Regularized Orthogonal Matching Pursuit based on
Compressed Sensing Theory in the Wavelet Domain
Na Fan
Department of Electronic Engineering, East China Normal University, Shanghai, China 200241
fanna.cn@gmail.com
sub-pixel accuracy.
From the aspect of graphics, researchers generate HR
images by learning high-frequency signals from training
images (a.k.a. dictionaries, prior knowledge, or example
images) with the hope of transferring statistical
characteristics from HR training image patches to LR images
for magnification, e.g. [6-11]. Such single-frame SR is also
referred to as image hallucination or upsampling.
Nevertheless, these probabilistic models are not feasible to
predicate further minutiae of real-world scenes unless the
input LR image still reserves certain trail of the minutia. As
an instance, Figure 1(a) is an input LR image, and Figure 1(b)
is its corresponding original HR image, where there is a
freckle above the bridge of the girl’s nose. The freckle
completely disappears in the 4X magnified image Figure 1(c)
output by the algorithm in [10]. Failing to recover tiny
objects in the scene is inevitable, as long as the objects are
smaller than a 4×4 image patch and does not lie on any
sampling point of the downsampled LR image. This
interesting phenomenon asserts that any SR scheme cannot
replace the functionality of microscopes.

Abstract
A wavelet based compressed sensing Super Resolution
algorithm is developed, in which the energy function
optimization is approximated numerically via the
Regularized Orthogonal Matching Pursuit. The proposed
algorithm works well with a smaller quantity of training
image patches and outputs images with satisfactory
subjective quality. It is tested on classical images commonly
adopted by Super Resolution researchers with both generic
and specialized training sets for comparison with other
popular commercial software and state-of-the-art methods.
Experiments demonstrate that, the proposed algorithm is
competitive among contemporary Super Resolution methods.

1. Introduction
Shot noise owing to the corpuscular nature of photons,
sets a limitation on pixel size reduction. This is because the
variance of photon distribution is augmented as a result of
the decrease of the area per pixel and the amount of light
available for each pixel in an imaging system. This inherent
limitation hinders ultra-high spatial resolution imaging from
the hardware perspective, in respect that, higher resolution
demands larger number of pixels per unit area i.e. smaller
pixel size. When the imported light quota for each pixel
approaches the shot-noise limit, the effect of shot noise
becomes evident and degrades image quality severely. It also
explains why a camera cannot be upgraded or developed into
a microscope. The optimally limited pixel size is estimated at
about 40 μm2 for a 0.35 μm CMOS process. The
contemporary image sensor technology has almost reached
this level, which urges and expedites the advancement of
software solutions for promoting image resolution level.
Since the seminal work by Andrews [1] for single-frame
Super Resolution (SR) and Tsai et al. [2] for multiple-frame
SR, SR has been an intensively investigated topic for the
computer vision / image processing community (see [3-5] for
some recommended surveys). The original intention of SR is
to reconstruct a single High Resolution (HR) image from a
sequence of Low Resolution (LR) images aligned in
978-0-7695-3789-4/09 $25.00 © 2009 IEEE
DOI 10.1109/CGIV.2009.90

(a)
(b)
(c)
Figure 1. (a) LR image for input (b) Original HR image (c) 4X
magnification of (a) by the method in [10].

Donoho introduced the concept of image restoration
with the wavelet transform [12], in which an image degraded
by a filter is restored. A limitation of wavelet transform is its
inability to efficiently represent various degraded
convolution filters, but it can be efficiently done in Fourier
domain. Neelamani et al. [13] combined these two
transforms together yielding a technique popularly known as
Fourier-Wavelet Regularized Deconvolution (ForWaRD).
349

The proposed example-based single-frame HR
algorithm in this paper shares similar advantage with
ForWaRD where it reconstructs HR images in the wavelet
domain, meanwhile deconvolving the signal in Fourier
domain. The difference is that the Compressed Sensing
Theory (CST) is employed to solve the inverse equation for
missing signal values. In this way, our method is more
general than Neelamani’s, because it is also capable to
handle uncertainties due to down-sampling by assuming the
sparsity of the signal in the wavelet domain.
The rest of the manuscript is arranged as follows:
Section 2 is about wavelet transform of an image; Section 3
formulates the SR problem in accordance with CST and
solves it numerically with Regularized Orthogonal Matching
Pursuit (ROMP); Section 4 presents experimental results;
Section 5 comments on conclusion and points out possible
future work.

f ,ψ 1j ,k = ∫

\2

⎛ 2 ( k1 +1) 2
=2 ⎜ ∫
⎜ 2− j k
1
⎝
−j

−

∫

∫

f ( x1 , x2 )dx1dx2

2− j k2

2− j ( k2 +1/ 2)

⎞
f ( x1 , x2 )dx1dx2 ⎟
⎟
⎠

3. Compressed Sensing Resolved by ROMP
The dogma of signal processing maintains that a signal
must be sampled at a rate at least twice its highest frequency
in order to be represented without error. However, in
practice, data are often compressed soon after sensing,
trading off signal representation complexity (bits) for some
error, e.g. JPEG image compression in digital cameras. This
is wasteful of valuable sensing resources. Over the past few
years, the CST has begun to emerge, in which the signal is
sampled and simultaneously compressed at a greatly reduced
rate.
In the local example-based SR context, the goal is to
recover the HR image patch signal h from its LR
measurement l, provided that h has a sparse representation in
terms of a basis B. B is a dictionary and each of its column is
an image patch aligned from HR example images:
l = Dh = DBk
(1)
where D is the operator for downsampling. Intuitively, the
assumption of the existence of sparse representation with
respect to training image patterns is rational because the HR
image is supposed to delineate a real-world scene instead of
a chaotic random signal and should resemble its priors.
Theoretically speaking, the Restricted Isometry Condition
(RIC)in [14] states that, as long as every set of s columns of
B forms approximately an orthonormal system, every
s-sparse vector k can be exactly recovered from its
measurements Bk as a unique solution to the convex
optimization problem (L1).
In most occasions, the dictionary B is over-complete,
leading to infinite number of coefficients k satisfying Eq.(1).
An objective energy function is defined upon k to evaluate its
fitness for the sparsity assumption and the LR measurement:

The univariate orthonormal Haar basis is

j, k ∈ Z

The bivariate tensor-product orthonormal Haar basis

{ψ } , j ∈ Z, k = (k1 , k2 ) ∈ Z 2 and e=1,2,3 is given by
e
j ,k

ψ 1j ,k ( x1 , x2 ) = 2 j φ (2 j x1 − k1 )ψ (2 j x2 − k2 ) ,
ψ 2j ,k ( x1 , x2 ) = 2 jψ (2 j x1 − k1 )φ (2 j x2 − k2 ) ,
ψ 3j ,k ( x1 , x2 ) = 2 jψ (2 j x1 − k1 )ψ (2 j x2 − k2 ) .
f ∈ L2 (\ 2 ) , we have the

∑

( k2 +1/ 2)

And that of type 2 and 3 can be computed in the very
similar way, and is not listed due to the limited space.

x ∈ [0,1]
0
1 otherwise

f ( x) =

∫

2− j k1

x ∈ [0,1/ 2)
⎧1
⎪
ψ ( x) = ⎨ −1 x ∈ [1/ 2,1]
⎪⎩0
otherwise

wavelet representation

−j

2− j ( k1 +1) 2− j ( k2 +1)

{

Modeling an image as a function

f ( x1 , x2 )φ (2 j x1 − k1 )ψ (2 j x2 − k2 )dx1dx2

j

The univariate orthonormal Haar basis is used to
calculate a series of wavelet coefficients from a fixed
number of measurements. The univariate Haar scaling
function φ and wavelet ψ are given by

ψ j ,k = 2 j / 2ψ (2 j x − k )

∫∫

−∞ −∞

2. Wavelet Representation

φ ( x) =

∞ ∞

= 2j

f ( x)ψ 1j , k ( x)dx

f ,ψ ej ,k ψ ej , k .

e, j ,k

The wavelet coefficient associated with a Haar wavelet
of type 1 can be computed as follows

min w || k ||1 + || EB ' k − El ||22

(2)

where B '=DB, the downsampled LR dictionary
corresponding to B, and E is an linear operator for feature
extraction. Customarily, E is chosen as a high-pass filter,
which is mainly due to the fact that, from a perceptual
350

|<l, bi>| where bi is the ith column of B '. Once the largest
coefficient of k is identified, a least-square problem is
resolved assuming it is the only non-zero coefficient. The
new estimate for k is utilized to compute the estimated
original HR signal h and subtract it from Bk. This process is
iterated, using the residual signal to find the next largest
coefficient of k. By iterating s times, an s-sparse
approximated representation is acquired.
A limitation of OMP is its weaker guarantee of exact
recovery compared to non-approximate L1 norm methods
[14]. To overcome this, an improved OMP named
Regularized Orthogonal Matching Pursuit (ROMP) is put
forward in [14]. It recovers u=3 coefficients in a single
iteration, thereby making it more robust to meet the RIC. The
ROMP algorithm for our application is summarized as
follows:
the forward matrix F ← EB ', the backward matrix F* ← F-1
the set I⊂{1,2,...,n} includes the indices of non-zero
coefficients in k, I ← ø
the residual signal r ← l
while r≠0 {
maxenergy ← 0
C ← the set of s largest magnitude coefficients of F*r
sort C in non-increasing order
for x = 0 to s {
y ← largest index where C(y)≥C(x)/2 and y − x < u
En ← fenergy(C(x..y))
if En > maxenergy {maxenergy ← En; Cmax←{x,x+1,...,y};}
}
I ← I∪Cmax
j ←find the vector of I coefficients best matching the LR
measurement l: argmax || l − Fv ||2

viewpoint, the Human Vision System is more sensitive to
high frequency content of an image. The high frequency
components of the LR image are also arguably the most
significant information to predict the lost high frequency
components of the HR image. Freeman et al. [6] use a
high-pass filter to extract the edge information from the LR
input patches as the feature. Sun et al. [9] use a set of
Gaussian derivative filters to extract the contours in the LR
patches. Chang et al. [11] use the first-order and
second-order gradients of the patches as the representation.
We also use the first-order and second-order derivatives as
the feature for the LR patch. While simple, these features
turn out to work very well. To be precise, the four 1-D filters
used to extract the derivatives are:

f1 = [ −1, 0,1],

f 2 = f1T

f 3 = [1, 0, −2, 0,1],

f 4 = f 3T

Applying these four filters, four descriptive feature
vectors are obtained for each patch, which are concatenated
as one vector as the final representation of the LR patch.
As given by Lagrange multipliers, the weight w in Eq.(2)
balances the importance of the sparsity of k and the
conformance of the recovered signal to the observed LR l.
Minimizing the energy function Eq.(2) individually for
each image patch does not guarantee smoothness among
adjacent patches. The inter-patch smoothness is enforced
using a one-pass technique similar to that of [7]. The patches
are processed in raster-scan order in the image, from left to
right and top to bottom. Eq.(2) is added with the penalty of
the discrepancy between the interpolated HR patch Bk and
the previously computed adjacent HR patches:

min w1 || k ||1 + || EB ' k − El ||22 + w2 || OBk − P ||22 (3)

v:supp (v)=I

where the matrix O fetches the region of overlap between the
current patch under consideration and previously
interpolated HR patches, and P is the previously interpolated
HR image patches on the overlap. w1 and w2 are weighing
factors, and are set to be 1 in all of the experiments in this
paper.
4×4 patches in LR images are considered locally each
time together, with overlap of 1 pixel between adjacent LR
patches, corresponding to 4M×4M patches with overlap of M
pixels between adjacent HR patches, where M is the
magnification ratio. In order to increase the incoherence
between B ' and l, the descriptive features by f1, f2, f3 and f4 are
not extracted directly from the 4×4 LR patch, but from the
4M×4M HR patches downsampled by bicubic interpolation.
Although the L1 norm optimization is remarkably faster
than that of the L0 norm, it may still be computationally
expensive by reason of the absence of a polynomial-time
algorithm for linear programming [14]. A more efficient and
approximate optimal method to solve Eq.(3) is Orthogonal
Matching Pursuit (OMP) [15], the main idea of which is to
find the coefficient of k with the largest magnitude by
projecting l onto each column of B' and selecting the largest

recompute the residual signal r ← l − Fj
}

4. Experimental Results
For performance evaluation, the proposed algorithm is
compared with the traditional bicubic interpolation (the
bicubic resampling tool in Adobe Photoshop), Freeman’s
method (our own implementation of the algorithm described
in [7]), Fattal’s method (obtained directly from the author
[8]), Huang’s method (code delivered from the author [10]),
and 4 commercial software. All programs run on an Intel
Pentium Dual-Core T3200 2.0GHz. Twenty 768×512
example images displayed in Figure 3 are taken to generate
4M×4M HR image patches as the dictionary.
A predominance of our algorithm is that, it needs a smaller
amount of training image patches by adaptively collecting
the relevancy to each patch. Figure 2 plots the sparsity of 100
randomly chosen patches of the test image Boy in 3X
magnification. Note that the recovered coefficients are always
sparse with less than 40 nonzero entries, yet the sparsity is an

351

N umber of S uppor ts

40
35
30
25
20
15
10
5
0

1

11

21

31

41

51
61
71
81
91
100
Patch Index
Figure 2. Number of nonzero coefficients in the sparse representation computed from 100 patches of the test image Boy in 3X magnification.

intrinsic property depending on the scene correlation of an
image patch. Furthermore, we empirically discovered that,
the support of the recovered coefficients is neither a superset
nor a subset of the K nearest neighbors [11], which implies
that, the selected patches are more informative leading to
more faithful texture reconstruction.
In what follows, both subjective visual evaluation and
objective quantitative measurement are presented. The Peak
Signal-to-Noise Ratio (PSNR) is used as an objective
indicator to measure image quality, which is defined by

⎛
⎞
⎜
⎟
2
255
⎟
PSNR = 10 × log ⎜
cols rows
1
⎜
⎟
2
⎜ cols × rows ∑ ∑ e (i, j ) ⎟
i =1 j =1
⎝
⎠
where “cols” and “rows” are the column and row numbers of
the image, respectively, 255 is the maximum value for pixel
intensity, and e(i, j) is the difference between the real and
computed images at pixel location (i, j).
Table 1. Average PSNR over the 3 channels of each method for
noise-free 2X magnification (in dB)
Lena
Peppers
Boy
Boat
Bicubic
39.72
40.20
34.41
34.58
40.22
40.74
36.05
37.79
Freeman’s
39.38
40.25
35.17
38.03
Fattal’s
39.63
40.09
35.87
38.21
Huang’s
Proposed
40.32
39.88
35.49
37.96
Table 2. Average PSNR over the 3 channels of each method in
noise-free 3X magnification (in dB)
Lena
Peppers
Boy
Boat
Bicubic
33.39
34.08
28.41
28.58
34.06
34.21
30.04
32.67
Freeman’s
33.17
33.96
30.15
31.80
Fattal’s
33.52
34.41
29.87
32.21
Huang’s
Proposed
33.39
34.73
29.54
32.53
Table 3. Average PSNR over the 3 channels of each method in
noise-free 4X magnification (in dB)
Lena
Peppers
Boy
Boat
Bicubic
30.70
31.29
26.25
26.11
30.15
31.73
27.26
29.29
Freeman’s
29.94
31.33
26.54
30.13
Fattal’s
30.26
31.69
26.32
29.85
Huang’s
Proposed
30.56
32.03
26.71
29.68

Figure 3. Twenty 768×512 example images for the generic training
set. The images are numbered from left to right, top to bottom, of
which the 7, 8, 9, 10 and 14th images are selected to form the
specialized training set to SR the image Boat

The resulted PSNR in 2X, 3X and 4X magnification are
listed in Table 1-3, from which it is seen that, our algorithm is
competitive among the state-of-the-art methods on the basis
of objective image quality metrics and relatively superior
towards large magnification ratio. Figure 4 illustrates the LR
image for input and its corresponding output by our algorithm,
bicubic interpolation and popular commercial software.
Figure 5 and 6 depict in close-up the results of the image Boat
for 2X and 3X magnification respectively. Due to the limited
space, only the mask part of the boat is cropped from the
entire HR image and presented in full size. It is shown that,
the proposed algorithm produces visually pleasing HR
images with fine details at edges while synthesizing plausible
texture and shine at the water ripple region.

5. Concluding Remarks
Because it is not possible to engender information from a
null basis, non-example-based single-frame SR methods such
as the bilinear and cubic spline interpolation are not capable
to achieve satisfactory performance. The rationale of some
example-based SR methods is to learn transformed raw image
patches, while some others learn more generalized statistics,
352

or make use of a hybrid of the two. Their ingenerate traits are
consequently diverse: Some methods produce better results
for natural scenes, whereas some for printed material; some
create drawing-like and aesthetically comfortable HR output
whereas some deliver photo-like HR images with relatively
higher Peak Signal-to-Noise Ratio. The preference between
subjective and objective performance depends on different
circumstances and usage cases.
The application of CST to other signal sampling or
dimensionality reduction problems, such as Color Filter
Array interpolation, video compression etc. might be
promising.

References
[1]
[2]
[3]
[4]
[5]

[6]
[7]
[8]
[9]
[10]
[11]
[12]

H. C. Andrews, and B.R. Hunt, Digital Image Restoration, NJ:
Prentice-Hall, 1977.
R. Y. Tsai, and T. S. Huang, Multiframe image restoration and
registration, Advances in Computer Vision and Image Processing, vol.
1, pp. 317-339, 1984.
S. C. Park, M. K. Park, and M. G. Kang, Super-resolution image
reconstruction: a technical overview, IEEE Signal Processing
Magazine, 20(3): 21-36, 2003.
S. Baker, and T. Kanade, Limits on super-resolution and how to break
them, IEEE Transactions on Pattern Analysis and Machine
Intelligence, 24(9): 1167-1183, 2002.
S. Farsiu, D. Robinson, M. Elad, and P. Milanfar, Advances and
challenges in super-resolution, International Journal of Imaging
Systems and Technology, 14(2): 47-57, 2004.

[13]
[14]
[15]

W. T. Freeman, E. C. Pasztor, and O. T. Carmichael, Learning
low-level vision, International Journal of Computer Vision, 40(1):
25-47, 2000.
W. T. Freeman, T. R. Jones, and E. C. Pasztor, Example-based super
resolution, IEEE Computer Graphics & Applications, 22(2): 56-65,
2002.
R. Fattal, Image upsampling via imposed edge statistics, ACM
Transactions on Graphics, 26(3): 95, 2007.
J. Sun, N.N. Zheng, H. Tao, and H.Y. Shum, Image hallucination with
primal sketch priors, Proceedings of IEEE Conference on Computer
Vision and Pattern Recognition, vol. 2, pp.729-736, 2003.
Y. Z. Huang, and Y.J.Long, Super-resolution using neural networks
based on the optimal recovery theory, Journal of Computational
Electronics, 5(4): 275-281, 2006.
H. Chang, D. Y. Yeung, and Y. Xiong, Super-resolution through
neighbor embedding, Proceedings of IEEE Conference on Computer
Vision and Pattern Recognition, vol. 1, pp.275-282, 2004.
D. L. Donoho, Nonlinear solution of linear inverse problems by
wavelet-vaguelette decomposition, Applied and Computational
Harmonic Analysis, 2: 101-126, 1995.
R. Neelamani, H. Choi, and R. Baraniuk, Forward: Fourier-wavelet
regularized deconvolution for ill-conditioned systems, IEEE
Transactions on Signal Processing, 52(2): 418-433, 2004.
D. Needell, and R. Vershynin, Uniform uncertainty principle and signal
recovery via regularized orthogonal matching pursuit, Foundations of
Computational Mathematics, 9(3): 317-334, 2009.
J. A. Tropp, and A. C. Gilbert, Signal recovery from random
measurements via orthogonal matching pursuit, IEEE Transactions on
Information Theory, 53(12): 4655-4666, 2007.

Figure 4. A subjective visual comparison among the proposed algorithm, bicubic interpolation, and four kinds of commercial software:
Genuine Fractals (www.ononesoftware.com), FocalBlade (www.thepluginsite.com), PhotoKit (www.pixelgenius.com) and PhotoZoom
(www.benvista.com).

353

(a)

(b)

(c)

(d)

(e)
(f)
(g)
(h)
Figure 5. Boat’s mast 2X magnification (from left to right, top to bottom): (a) The entire true HR image (5X downsampled), (b) The true
HR image cropped from (a), (c) Input (2X magnified), (d) The bicubic spline in Adobe Photoshop, (e) Freeman’s method, (f) Huang’s
method, (g) The proposed algorithm with generic training set, (h) The proposed algorithm with specialized training set

(a)

(b)

(c)

(d)
(e)
(f)
Figure 6. Boat’s mast 3X magnification (from left to right, top to bottom): (a) Input (3X magnified), (b) Bicubic spline in Adobe Photoshop,
(c) Freeman’s method, (d) Huang’s method, (e) The proposed algorithm with generic training set, (f) The proposed algorithm with specialized
training set

354

