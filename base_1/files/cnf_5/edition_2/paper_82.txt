2009 Sixth International Conference on Computer Graphics, Imaging and Visualization

Integrated Tourist Navigation System
Haomian Wang, Weiwei Cui, Hong Zhou, Yingcai Wu, Huamin Qu
The Hong Kong University of Science and Technology, Hong Kong
{whaomian,weiwei,zhouhong,wuyc,huamin}@cse.ust.hk
Abstract

and detailed 3D models for a city or even a small area, not
to mention the tremendous space and bandwidth requirements to store and transmit these 3D models. Recently,
Google Earth and Microsoft Virtual Earth provide platforms for users to create, store, and share their 3D building models in the world. More and more 3D computergenerated building models have been released to the public. It becomes a matter of time that we will have 3D models for many areas of the world and these models will become available for tourist navigation systems.
It will be very desirable that tourist navigation systems
can provide both 2D maps and 3D models. Then users can
use the map to find the route and the 3D models to identify
their locations and find their destination buildings. Some
commercial tourist navigation systems can now display a
2D-map view and a 3D-model view side by side. There
are several drawbacks to render 2D map and 3D models
in dual-screen systems. First, browsing a dual-screen for
long time may lead to visual fatigue because users have
to switch between different windows, which will increase
the interaction burden. Second, tourist navigation systems
are widely embedded into mobile devices which always
have very small screens. Thus, applying dual-screen in
such small windows cannot clearly render 2D maps and
3D models simultaneously. Finally, some navigation systems are used for time-critical wayfinding tasks, e.g., car
navigation. Dual-screen systems may cause mental stress
for drivers because they have to frequently change from
one view to another and register these two views in their
minds while a decision has to be made within seconds.
In this paper, we investigate how to seamlessly blend
2D maps and 3D models into one display. We propose
two methods, i.e., overlay-style blending and Escher-style
blending. Overlay-style blending renders maps and 3D
models into different layers which are then composed into
one display window. Some visualization techniques are
developed to add visual cues to indicate occluded routes
and buildings. For Escher-style blending, we map 3D
scenes onto Moebius style curved surfaces so that some
focus+context style visualization can be achieved. Our displayed images are visually pleasant and can be easily understood by users. Our methods take advantages of both

Tourist navigation systems have used digital maps to
provide users with location and route information for a
long time. However, without detailed 3D building models, users may miss important turns at some intersections
and have problems to find their target buildings. With the
advent of Google Earth and Microsoft Virtual Earth, 3D
models of buildings in major cities worldwide can be conveniently created and shared. In this paper, we present
two methods, i.e., overlay-style blending and Escher-style
blending, to seamlessly integrate 2D maps and 3D buildings into a tourist navigation system. We also provide useful visual cues indicating occluded roads and buildings.
Our solutions can be applied to other navigation systems
such as interactive city guide maps.
Keywords— 3D map, navigation system, multi-perspective,
information graphics

1 Introduction
Nowadays, tourist navigation systems equipped with
GPS are widely available in various mobile devices, such
as cell phones and car navigation systems, and can show
tourists interactive digital maps. Maps provide important
information for tourists, such as locations, routes, and landmarks. With maps, tourists can conveniently find the route
from a source location to a destination location and also
obtain information about the intersections and landmarks
along their trips. However, it often happens that tourists
still get lost because of the lack of detailed 3D information about the road environment, landmarks, or destination
buildings. For example, if a user looks for a hotel in a
neighborhood and the map tells that he/she has already arrived at the destination, but the user looks around and finds
many buildings. The user has no idea which building is
his/her target. In another scenario, a user goes along a road,
but he/she is not sure whether it is the right road suggested
by the map. Some 3D models of the destination building
and landmark buildings along the route can greatly help
users identify their locations, make decisions at intersections, and find their destinations.
Only a few years ago, it is hard to get satellite images
978-0-7695-3789-4/09 $25.00 © 2009 IEEE
DOI 10.1109/CGIV.2009.45

497

(a)

(b)

(c)

Figure 1: Integration of 2D maps and 3D models: (a) two separate windows; (b) overlay-style integration; (c) Escher-style
integration.

pressed to almost 2D shapes and thus become unrecognizable. Grabler et al. [3] proposed a technique to generate
tourist map by placing landmarks onto 2D maps. But the
generated tourist map will miss a lot of 3D building models. Benjamin and Rainer. [9] presented an evaluation of a
mobile pedestrian navigation system (PNS) prototype, and
suggested that augmented reality is more suited for route
presentation in PNS.

2D maps and 3D models and integrate them into one window which can be displayed in a small screen for tourist
navigation. Since both methods need to overlay 2D maps
onto the empty space between 3D building models, much
empty space around the roads is required. Thus we develop an algorithm to group buildings. Our algorithm can
pack each block of buildings as tightly as possible, while
keeping their relative positions. Besides facilitating overlaying 2D maps, grouping buildings to gain more empty
space around roads can improve the visibility of the roads
and the clarity of the whole city’s structure.
Our major contributions lie in:

Multi-Perspective Images Blending 2D maps with orthogonal projection and 3D models with perspective projection into a single image is a multi-perspective image
(MPI) generation problem. MPIs have been used by artists
for many centuries [8, 10, 11]. How to automatically generate MPIs has also been studied recently. Rademacher and
Bishop proposed multiple-center-of-projection images [6]
which can be generated by moving a virtual strip camera
through the scene. Vallance and Calder [8] summarized the
concept and previous realizations of MPIs in nature, art and
visualization, and then presented a simple API to facilitate
MPI rendering. Agrawala et al. [1] proposed a technique to
generate artistic MPIs. They attached local cameras to the
scene geometry and constrained the cameras to generate
appropriate projections for a variety of artistic effects. Yu
and McMillan proposed a framework for multi-perspective
rendering based on General Linear Cameras (GLC) [11].
Jobst et al. [4] enhanced virtual spatial relations in 3D environments by using view-port variations, which modified
perspective and orthographic views in a progressive and
degressive way.

• We study the problem of seamlessly blending 2D
maps and 3D models into one window for tourist
navigation systems, and propose two blending methods, i.e., overlay-style and Escher-style blending.
• We propose a robust algorithm for grouping buildings based on the image seam carving technique,
which can facilitate the application of our blending
methods.
• We also designed several visual cues indicating occluded routes and buildings.

2 Previous Work
Tourist Navigation System Some proposed tourist navigation systems display 2D maps and 3D models into two
separate windows, e.g., TellMarisGuide system [5]. However, as pointed out by Takahashi et al. [7], showing information into two separate windows may cause mental
distress to users. To overcome this problem, they proposed a car navigation system without occlusion by distorting landmarks such as mountains so that routes will
always be visible for users. Their system works well for
rural landscapes. But for urban settings, some routes may
be totally blocked by many tall buildings. If their algorithms are applied, these buildings will be severely com-

3 Possible Solutions
Users often want to get the following information from a
tourist navigation system: Current location and its neighbor area; Routes; Landmarks and destination buildings;
Directional changes of the route at intersections.
Sometimes 2D information such as the whole route and
498

the layout of the neighborhood is more important for users,
while 3D models may be more useful in other scenarios. Tourists usually have problems at the intersections of
routes because they have to make decisions about which
road to take and which turn to make. In this situation, both
2D information such as the layout of the intersections and
the names of different roads, and 3D information such as
the landmark buildings at the intersection are useful to help
users make decision.
As we mentioned before, a simple solution is to put
2D maps and 3D models into two separate windows. This
method is quite effective for non-time-critical tasks. However, in time-critical tasks such as making decision in an
intersection using a car navigation system, this may cause
problems because it takes time for users to switch between two windows. Furthermore, if tourist navigation
systems are used in mobile devices with small screens,
dual-window displays are also not a good solution.
We can also just put 3D landmark buildings onto 2D
maps and directly render them. However, if the map and
3D models are rendered by perspective projection from a
viewpoint on the ground, the far area will be compressed
or occluded and becomes indiscernible. If they are rendered from a viewpoint above the landscape (e.g., bird’seye view), then the scene perceived by users is quite different from what rendered from the navigation system.
Another possibility is to directly generate a multiperspective image using previous methods and then register the map with the distorted view and display them
together into one window. This is a workable solution.
However, there are some challenges for the integration of
2D maps and 3D models. First, many multi-perspective
rendering methods introduce severe distortions which may
be unfamiliar to users. Second, maps are not only another projections of 3D scenes, but also abstractions of 3D
scenes. How to guarantee smooth transition from maps to
3D scenes has not been well addressed by previous MPI
generation methods. In the following sections, we introduce our techniques to attack these problems.

(a)

(b)

(c)

(d)

Figure 2: Results of grouping buildings: (a) The original
building block; (b) The 3D building block is discretized
to a 2D image; The red lines are two horizontal seams and
one vertical seam; (c) The result of the 2D image after seam
carving; (d) The result of the 3D building block according
to (c).
The image seam carving technique [2] is used to downsize an image by carving out some trivial information in
the image. In our grouping algorithm, the trivial information is the empty space between the buildings in the block.
By carving such empty space, the buildings will be packed
together more tightly, and their relative positions will be
maintained. For a given building block, we first discretize
the 3D building block to a 2D image, the pixels that belong
to empty space are assigned 0 (white), the pixels which are
covered by the buildings are assigned 1 (black) (see Fig.
2(b)).
The building grouping algorithm is an iterative process.
For each step, we find the optimal seam to carve. The cost
of each seam can be defined as C(s) = ∑ni=1 V (pi ), where
V (pi ) is the assigned value of pixel pi in a seam containing
n pixels. Then the optimal seam sˆ is defined as
n

C(s)
ˆ = min C(s) = min ∑ V (pi )

4 Grouping Buildings

s

s

(1)

i=1

We use dynamic programming to compute the optimal
seam. After computing the optimal seam, we remove all
pixels in the optimal seam. One major difference from [2]
is that each seam in our grouping algorithm can remove
more than one pixel for each row or column (Fig 2(b)).
Fig. 2(c) and 2(d) are the grouping results.
After the building grouping process, the buildings in the
blocks are packed more tightly, which gains more empty
space. The overlay-style blending method can now be
more effectively applied in our system.

The 2D map may become too small or be occluded if directly overlaid on the roads between 3D building models.
However, it is not easy to find enough empty space between
the 3D building models due to the high building density.
To create more empty space around roads and preserve the
relative positions of buildings, we develop a grouping algorithm based on the image seam carving technique [2].
We assume that the whole city is divided into blocks by the
roads. Our grouping algorithm is applied to each block and
maintains the block boundaries.
499

5 Overlay-Style Blending

plane. This is especially useful if users walk along a road
without any landmark buildings. Then the map can become more opaque and occupy a larger area in the display
window (Fig. 3c).

In this section, we discuss how to put maps and 3D
models into different layers of a single display window
and transparency is exploited to show both informations
to users. The style is similar to augmented reality.

(a)

5.3 Visual Cues
The intersection of the roads often poses special challenges for users. How to indicate the direction and angle
of the turn that users should make is worth study. We can
display the building which is just in front of the route as
transparent. Similarly, for the landmark buildings that are
blocked by tall buildings in front of users, they can be put
onto the map and then rendered into the transparent layer.
Then users can have a big picture about the location and
shapes of these buildings. Another solution is that when
the landmark buildings are within a certain range, all the
buildings blocking the landmark building will be displayed
as transparent (Fig. 3d).

(b)

6 Escher-Style Blending

Figure 3: Overlay-style integration: (a) Simple overlay; (b)
Multi-perspective map; (c) Smart overlay; (d) Visual cues
showing a blocked landmark building.

Inspired by one of Escher’s famous paintings (Fig. 4c),
we propose to map the 3D scene onto planes and Moebius
curved surfaces and then display them from a single viewpoint (Fig. 4b). Then some part of the 3D scene will be
rendered as a map style while other parts will be more like
3D perspective view.

5.1

6.1 Moebius Curved Surface

(c)

(d)

Simply overlay

Fig. 4 illustrates the motivation of our approach. Fig. 4a
top shows traditional two window views. However, these
two windows cannot be easily merged into one window.
Therefore, we rotate these two windows (Fig. 4a bottom)
so that the moving directions can now be easily aligned.
Then we overlap the windows based on the moving direction and integrate them into one window. However, the
viewpoint of the 3D perspective view is not from users. To
solve this problem, we rotate and stretch the perspective
area so that the buildings in the near area are now rendered
from the users’ viewpoint (Fig. 4b). The result is similar
to Escher’s painting (Fig. 4c). Thus, this method is named
Escher-style integration.
Next, we introduce an algorithm to efficiently implement this method. We first determine the area to be rendered into the display window and then divide the area into
three regions (Fig. 5a): a 3D model region, a 2D map region, and a transition region. We then render the map region onto a plane in the top-left corner of the display window using orthogonal projection and the 3D models in the
bottom-right corner (Fig. 5b) using perspective projection.
We now need to design a curved surface to connect these
two regions and then map the transition region onto it. We
first compute the 3D bounding box of the 3D models and
then connect the corners of the map plane and the corners

We can simply render the map as transparent and then
overlay the map over perspectively rendered 3D models.
Fig. 3a illustrates this idea. However, we find that it does
not work well because these two views use different projections and it looks strange to directly put them together.
Another problem is that it is not easy to determine a suitable transparency value for the map layer. A too high transparency value makes the map unreadable while a too low
value blocks the 3D scenes. To solve these two problems,
we introduce smart overlay in the next subsections.

5.2

Smart overlay

We can fold the map into two regions: one for orthogonal projection and another for perspective projection (Fig.
3b). The perspective projection region is registered with
the road while the orthogonal projection floats over the
road to provide more information (Fig. 1b).
The transparency value of the map can be dynamically
adjusted. If users approach an intersection, then the map
will become more opaque so users can quickly determine
which road to take. If a landmark building or the destination building is approaching, the map will become more
transparent so users can have a clear view of the building.
Another visualization technique we use is to dynamically
adjust the angle and size of the orthogonal projection map
500

(a)

(b)

(c)

Figure 4: Motivation for Escher-style integration: (a) Traditional two windows view(top) and rotate two windows(bottom);
(b) Merge two windows in (a) by mapping them onto a Moebius curved surface; (c) Escher’s painting.
of the bottom plane of the 3D bounding box using a spline
surface (Fig. 5c). Because the map plane and the bottom plane of the bounding box are perpendicular to each
other, the curved surface will twist like a Moebius strip.
The shape of the spline surface can be easily adjusted by
control points showed as the red dots in Fig. 5c. After
that, the texture of the transition region is mapped onto the
curved surface.

6.2

are showed in Fig. 1b and Fig. 3. The results for Escherstyle integration are showed in Fig. 1c. From the results
we can see that smart overlay and enhanced visual cues
can provide much more information about routes and 3D
models without introducing distortion while Escher-style
integration can generate visually pleasant images and can
provide a much broader field of view. Overlay-style integration and Escher-style integration can be combined together to complement each other’s strengths. Overlay-style
integration can clearly show users the near area without
distortion while Escher-style integration is good at showing the context information. However, overlay-style integration lowers the visibility of both maps and 3D buildings. But the distortion introduced by multi-perspectivestyle integration may be distracting to some users. These
two methods can be used together and mixed into one display window. For the routes and intersections which are
very close to the user’s location, their information can be
displayed using overlay-style integration. The overall layout and routes far away from users can be presented using
Escher-style integration. Fig. 6a shows an image which
integrates these two methods. We can also introduce two
map planes and generate some images like Fig. 6b, which
can provide a more balanced view.

Smooth Transition between 2D Map and 3D
Scene

After the mapping, certain areas such as the near area
will contain 3D models while other areas (i.e., the map region and transition region) will only show 2D maps. We
need to guarantee a smooth transition between the 2D map
regions and 3D model region. Otherwise, some poppingout effect will occur. To solve this problem, we add the
buildings to the curved surface and gradually change their
sizes. We connect the corners of the map plane and the
corners of the top plane of the 3D bounding box. Then we
get another twisted spline surface which is showed as the
transparent one in Fig. 5d. After that, we put the buildings
on the bottom curved surface but heights of these buildings
will be bounded by the top curved surface. The size of a
building is now determined by its position on the bottom
curved surface. The closer it is to the 3D model region, the
larger its size becomes. By this way, we can guarantee that
the sizes of the buildings change gradually and a smooth
transition between the map and 3D scene can be achieved.

8 Conclusions
In this paper, we proposed several techniques to integrate 2D maps and 3D models into a tourist navigation
system. The first approach overlays a transparent map over
3D model view and the multi-perspective map can be intelligently displayed based on the environment. The second approach is inspired by Escher’s painting. 3D models and 2D maps co-exist into one display by mapping the
landscape onto a Moebius-style curved surface. We also
discussed how to add visual cues to help users perceive
blocked routes and buildings in overlay-style integration
and how to guarantee smooth transitions in Escher-style

7 Experiments and Discussions
We conducted experiments with a real city map and 3D
models of about 5,000 buildings on a Pentium(R) 4 3.2GHz
PC with 2GB RAM and an NVIDIA Geforce 7900 GS
GPU with 256MB RAM. We first registered the map and
3D models. Then we tested the different ways to integrate
them together. In all examples in this paper, real time rendering is achieved. The results for overlay-style blending
501

(a)

(b)

(c)

(d)

Figure 5: Implementation of Escher-style integration: (a) The area to be displayed is divided into three regions; (b) The
map region and the 3D model region are rendered by orthogonal projection and perspective projection respectively. The
bounding box of the 3D model region is also computed; (c) A curved surface is constructed to connect the map plane and
the bottom plane of the bounding box; (d) Another curved surface connects the map plane and the top plane of the bounding
box. The 3D models in the transition regionwill be bounded by these two surfaces.

(a)

(b)

Figure 6: (a) Mixing overlay-style blending and Escher-style blending; (b) Combining two Escher-style views.
integration. To gain more empty space for the overlaystyle blending method, we design a building grouping algorithm, which can pack each block of buildings as tightly
as possible and maintain their relative positions. Our methods can be used in other navigation or GIS systems.

[5] Katri Laakso, Ove Gjesdal, and Jan Rasmus Sulebak. Tourist information and navigation support by using 3d maps displayed on
mobile devices. In Proceedings of HCI in Mobile Guides, pages
34–39, 2003.
[6] Paul Rademacher and Gary Bishop. Multiple-center-of-projection
images. In Proceedings of ACM SIGGRAPH, pages 199–206, 1998.

9 Acknowledgments

[7] Shigeo Takahashi, Kenichi Yoshida, Kenji Shimada, and Tomoyuki
Nishita. Occlusion-free animation of driving routes for car navigation systems. IEEE Trans. Vis. Comput. Graph, 12(5):1141–1148,
2006.

We would like to thank Kai-Lun Chung and Baoquan
Chen for their contributions to the system. We also thank
the anonymous reviewers for their valuable comments.
This work is partially supported by grant HK RGC CERG
618705.

[8] Scott Vallance and Paul Calder. Multi-perspective images for visualisation. Conferences in Research and Practice in Information
Technology, 11:69–76, 2002.

References
[1] Maneesh Agrawala, Denis Zorin, and Tamara Munzner. Artistic
multiprojection rendering. Proceedings of the Eurographics Workshop on Rendering Techniques, pages 125–136, 2000.
[2] Shai Avidan and Ariel Shamir. Seam carving for content-aware image resizing. ACM Trans. Graph., 26(3):10, 2007.

[9] Benjamin Walther-Franks and Rainer Malaka. Evaluation of an
augmented photograph-based pedestrian navigation system. In Proceedings of the international symposium on Smart Graphics, pages
94–105, 2008.

[3] Floraine Grabler, Maneesh Agrawala, Robert W. Sumner, and Mark
Pauly. Automatic generation of tourist maps. ACM Trans. Graph.,
27(3):11, 2008.

[10] Daniel N. Wood, Adam Finkelstein, John F. Hughes, Craig E.
Thayer, and David H. Salesin. Multiperspective panoramas for cel
animation. In Proceedings of ACM SIGGRAPH, pages 243–250,
1997.

[4] Markus Jobst and J¨urgen D¨ollner. Better perception of 3d-spatial relations by viewport variations. In Proceedings of the international
conference on Visual Information Systems, pages 7–18, 2008.

[11] Jingyi Yu and Leonard McMillan. A framework for multiperspective rendering. Proceedings of the Eurographics Workshop on Rendering Techniques, pages 61–68, 2004.

502

