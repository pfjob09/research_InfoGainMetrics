2009 Sixth International Conference on Computer Graphics, Imaging and Visualization

Artwork-based 3D Ink Style Modeling and Rendering*
Meijun SUN1, Tian TIAN2, Jizhou SUN3
School of Computer Science and Technology
Tianjin University
Tianjin, China
1
sun.meijun@yahoo.com.cn, 2tuipe-fox@hotmail.com, 3jzsun@tju.edu.cn
rendering mechanism. That is the contour of each object is
found to help modeling by a flexible surface inflation
technique; and artistic style analysis is done to help the
process of multi-layer rendering. Our goal is to interpret 2D
input to 3D so that we can obtain a 3D scene with a specific
style of Chinese Paintings input. It is a challenge to
accomplish this goal because of the complexity of the art
medium and three-dimension requirement. The basic idea
behind our system is described in Figure1.

Abstract—A novel system for automatic three-dimensional
ink-style rendering is presented. The goal for the whole is to
transmit the Chinese painting style to three-dimension models.
In this system, the input artwork is first segmented into several
regions used for modeling and artistic style analysis: 1) region
contours and skeletons is found to build three-dimension
models by surface inflation technique, 2) art style attributes
from regions, such as color, texture and stroke width, are
analyzed to maintain the artistic style coherence. In addition,
surface features on 3D models are extracted to guide the
process of Ink-style rendering. We inherit the traditional
multi-layer rendering model and modify it to generate more
flexible stylized results.
Keywords-non-photorealistic rendering; image segmentation;
3D model feature; 3D modeling; multi-layer rendering

I.

INTRODUCTION

Non-photorealistic rendering (NPR) is a powerful
technique for generating images in the manner of artistic
styles such as painting [1], [2], [3], pen and ink [5], [6], [7],
[13], [28] stippling [8], [9], and sketching [12]. In recent
years, a large number of approaches on NPR [10], [15] have
been proposed. Many of these earlier stage approaches
concentrated on generating still images. Several interesting
systems and methods [4], [11], [14], [19], [21], [22], [27],
[30], [31] are later designed for rendering 3D scenes in a
variety of artistic styles. References [4] and [30] present a set
of algorithms for multi-layer rendering mechanism.
Recently, a new research field is emerged, whose goal is to
reuse the artistic style in one input painting and apply them
in another so that the later one holds the similar style with
the input. This idea has been developed well in 2D field [3],
[26], but few from 2D to 3D.
Ink-Wash Chinese Painting is one of the traditional
paintings. Simulating the style of them is not trivial. In this
paper, we first show the image segmentation method suitable
for Ink-Wash Paintings. After this step, available objects are
achieved. Usually, objects in Chinese painting are either
strokes used to paint contours or textures used to paint
interiors. Therefore, these segmented objects are grouped
into two classes – thinning objects and non-thinning objects
– and they offer different types of style information which
correspond to different rendering modules in multi-layer
rendering separately. In addition, these objects give us the
useful information to build 3D models and guide multi-layer

Figure 1. Framework of our research.

The main contributions of this paper are as follows: 1)
we present a complete ink-style transferring system from a
2D artwork input to a 3D scene. This system can offer
flexibility in NPR stylization and maintain the coherence
between 2D input and 3D rendering results. 2) We also
modified the multi-layer rendering mechanism, not rendering
the simple ink-wash painting-like results, but based on a
specific input painting. 3) We inherit and deduce the
rendering parameters extracted from the input rather than the
user-specified.
The rest of this paper is organized as follows: Section2
reviews the related work. The image object segmentation and
artistic style analysis in 2D input are presented in Section3.
The 3D modeling technique is described in Section4. The
modified multi-layer rendering mechanism is introduced in

*Supported by National 863 Projects key subject "Core Techniques for Collabrative Flow Managment" (2006AA12A105); Tianjin Key Projects in the
National Science & Technology Pillar Program "Air Traffic Flow Management System And Application Technology" (08ZKFGX04100)

978-0-7695-3789-4/09 $25.00 © 2009 IEEE
DOI 10.1109/CGIV.2009.84

89

Section5. Section6 displays the experimental results. And the
conclusion and future works are given in Section7.
II.

segmentation. These objects are grouped into two classes –
thinning regions and non-thinning regions, and their features
are analyzed separately in Section3.2. Then the contour of
each object will be used in 3D modeling in Section4. And
other analysis results will be transmitted to rendering
mechanism in Section5.

RLATED WORK

Research problems in concern and methodologies used in
this paper are related to several technical fields, among
which include image segmentation, artistic style analyzing,
3D modeling and NPR rendering. We try to emphasize some
work most related to what we propose. The references below
should be taken as examples of related work, not as the
complete list of work in the cited areas.
For a general introduction to image segmentation, see
[24], [32], [33]. There have been a lot of segmentation
algorithms. Some are based on the color space, and some
combine with other information such as neighbor pixels.
Readers are referred to [19], [20], [22], [25] for introduction
to 3D modeling. Recent researches have been able to
produce precise models as we need.
Stylistic analysis is a core task for 3D interpretation from
2D input. And the related work has been done in recent years.
In 2001, an article published by Herzmann et al. [3]
describes a new system for processing images by “image
analogies”. In 2005, Dahua Lin and Xiaoou Tang [26]
propose a novel system called Coupled Space Learning to
learn the relations between different spaces and use them to
infer the images from one style to another style. Another
article published by Grabli et al. [27] introduces a procedural
approach to non-photorealistic line drawing from 3D models.
Ming Te Chi and Tong Yee Lee [30] presents a framework
for Interactive, three dimensional stylized painterly rendering
in 2006. Chung Ren Yan et al. [31] introduces a novel
technique to generate painterly art maps (PAMs) for 3D
non-photorealistic rendering in 2008. All these researches
mentioned above enlighten our system.

A. Image Objects Segmentation
Image segmentation involves splitting the image into
meaningful parts, i.e. objects. There are a lot of techniques
for accomplishing this [33]. Some simple methods cannot be
used in the image segmentation system, since the spatial
information of the pixels are not taken into account in this
method, but would rather focus on the pixel colors only.
Thus a more suitable method [34], termed “region
growing”, involves selecting seed pixels in the image, and
growing regions from these seed pixels by adding
neighboring pixels which are similar to those in the region
until no further pixels can be added or another separate
region is encountered. This method has an advantage that the
spatial information of each pixel is actively considered,
together with the color information. The result of region
growing contains many small regions. Usually, these small
regions are unavailable and usefulness so that we merge
them to one of their larger regions. For each region, if its
area is smaller than a minimum threshold, we merge it to one
of its neighbors with closest perceptual distance color. Figure
2a shows an example result of this segmentation algorithm.
B. Artwork Style Analysis
This is a core part in our whole system for 3D ink-style
rendering. After segmentation, we obtain available objects in
the artwork. In this section we will first present several style
analysis methods which are used in every segmented object.
Then these objects are classified into two groups – thinning
objects and non-thinning objects.

ARTWORK PROCESSING

III.

This section is the preparation for our later works. In
Section3.1, we achieve available objects after image

(a)

(b)

(c)

(d)

Figure 2. (a) Origin. (b) The segmented result. (c) Contour finding. (d) 3D modeling.

We choose an effective thinning algorithm based on
binary images, which fit for distilling the skeletons of works
of Chinese calligraphy and paintings [44]. The skeletons
produced by this algorithm nor only have good symmetry
and connectedness, but it records the width of each pixel on
the skeletons.This is an effective method except for pin lines
which is not allowed. To solve this problem, we use the
method in [35] to eliminate these pin lines as Figure3 shown.

Contour Extracting
We first confirm the candidate points on the contour.
Assumed that p is a point of region R, its 4-connected
domain is p1, p2, p3, and p4. If there is a point in its
4-connected domain is not in R, p is a candidate point and a
candidate of contour points. We achieve a set of candidate
points, remarked as B. We sort all the points in B to get the
contours. See Figure 2c.
Skeleton Extracting
90

'

Δs = M c − M c

(a)

(b)

∑ (L
'

c

− Lc

) + (u
2

'
c

− uc

) + (v
2

'
c

− vc

)

2

2π r

(6)
in which r = 1.
Texture Extracting
Texture is very important to communicate the minds of
painters. Three main problems have to be solved clearly: 1)
what kind of texture stroke to be used; 2) where to paint
textures on 3D model surface; 3) how to display these
textures, for example, horizontal, slant or straight.
To make out the first problem, the texture samples are
extracted from an artwork. We use JSEG algorithm [32] to
segment the objects into details. The reason for choosing this
algorithm is that it can maintain the “texture pattern” as a
whole. Then, we collect all the samples into a set, called Stex,
as shown in Figure5.

(c)

Figure 4. (a) A thinning object. (b) The skeleton with pin lines. (c) The
skeleton after cutting pin lines.

Width Information
Now we have enough information to get width of an
object. In the process of skeleton extracting, the width of
each point in skeleton pi is calculated as follow function:

Widthi = 2 × Dist ( pi , C ) − 1

2π r =

(1)

where Dist(pi,C) is the minimum distance from point pi to
the contour C. Then, we compute the average width for
region R:
LR

Widthavg =

∑ Width

i

LR ,

(2)

Figure 5. Texture sets examples.

i =1

IV.

where LR is the length of skeleton in region R. After last
three stages, we can certify that whether an object is thinning
or not through this function:
RatioR = LR Widthavg .

In Ink-Wash paintings, rocks, trees and animals are the
most often used contents to express the mind of painters. In
most conditions, they are symmetrical. In addition, such
Chinese paintings typically value the expression of the
artistic conception far beyond precisely conveying the
appearance of the painted subjects. Therefore, it is not
necessary to build precise models in our system. Taking this
into account, we introduce a surface inflation technique [19]
to build models. Its main idea is to inflate the region
surrounded by a 2D closed initial stoke drawn by the user to
construct a plausible 3D polygonal surface. The algorithm
inflates the closed stroke in both directions with the amount
depending on the width of the region; that is, wide areas
become fat, and narrow areas become thin. In detail, it first
determine the axes of the closed planar stroke using the
chordal axis introduced in [45]; then elevate the vertices of
the axes by an amount proportional to their distance from the
stroke; finally, construct a polygonal mesh wrapping the axes
and the polygon in such a way that sections form ovals.
Here, the closed initial stroke drawn by the user is
replaced by the contour extracted in Section 3. User can
change the thickness and precision of models by controlling
two parameters: one is the number of sampling to contour.
The more points the user samples in the contour, the smarter
models will be built. This technique is flexible and
controllable to construct vary of symmetrical models. Figure
3d and Figure6 show us the modeling result based on surface
inflation technique.

(3)

If RatioR ≤ Threshold , this region is a thinning object.
Otherwise, it is a non-thinning one.
If the object is thinning, the width and skeleton are two
important features used in 3D rendering. If the object is
non-thinning, we need to extract other two features. One is
color, the other is texture.
Color Extracting
We analyze color in LUV [33] color
space. The colors are greatly rich in
Chinese paintings, such as ochre, vermilion,
gamboges, and kermes and so on. The first
step is to build standard ink color tables by
shooting real ink color samples. They are
described as (Tc, Mc) in which Tc is the
color type and Mc is the LVU mapping Figure 4. Ink.
table for all the pixels in the unit circle in color samples, as
the function below. See Figure 4.
M c = {( pixi , ( L , u , v ) ) pixi ∈ Cr} .

(4)

Next, the similar method is used to sample the color in
the segmented objects and construct another mapping table
as follows:
'

Mc =

{( pix , ( L, u, v ) ) pix ∈ Cr ' } .
i

i

3D MODELING

(5)

Finally, the least square between Mc’ and Mc is calculated
as follows to determine the Tc in standard color table used to
3D rendering:

Figure 6. Modeling results.

91

V.

INK STYLE RENDERING

Many of rendering mechanisms have been proposed in
NPR field. The traditional method is stroke-based
multi-layer procedural rendering [39], based on a brush
profile model and stroke making mechanism which is
effective but requires a lot of user-specified parameters. The
multi-layer rendering model includes silhouette rendering
and interior rendering. See Figure7. In our system, all the
style parameters are gained from an input. Therefore, we
have to modify the multi-layer rendering mechanism using
simple and efficacious algorithms.
This section is based on the work above. Figure8 gives a
modified 3D ink-style rendering system. The input has
offered enough information to finish 3D modeling and style
parameters deducing. Surface features on models are needed
to guide rendering procedure. Meanwhile, those style
parameters are transmitted to new multi-layer rendering.
Note that according to style analysis results, we change the
rendering mechanism and partition the interior rending into
two parts: texture rendering and ink color rendering. There

Figure 8. Modified 3D ink style rendering framework.

B. Texture Rendering
It has been argued that procedural texture rendering is
related to three problems in Section3.2, and first one has
been made out. We present the other two plans here.
Distribution
Texture distribution tells us where to paint textures on 3D
model surface. In our experience, the distribution or density
of a texture is always controlled to emphasize the shading of
objects. For example, the density of texture might be higher
when closer to the silhouette or dark areas. Depth variation
shows the concave and convexity on model surface.
Computing the gradient of the depth variation combined with
normal change to reveal the variety of the surface. OpenGL
is used to offer the depth and normal information.
Orientation
Once making sure where to place these textures, we have
to decide how to display them. The texture follows the
orientation of the surface to convey the 3D form of the
surface. Girshick et al. [41] noted that the principal
directions of curvature might communicate the surface shape
well. However, all these approaches are based on parametric
surface. Turk [42] offers a curvature approximation to
compute a polygonal surface. This algorithm is perfected by
[30], [43] to make the curvature smoother.
All the three problems have been solved now, but it is
another problem to keep texture rendering results coherence
in frames when 3D models rotate or scale. The best way to
solve it is to mapping textures on model surface directly.
Therefore, we use curvature, depth and normal information
to instruct procedural mapping.
The appropriate distribution and orientation of texture
have been analyzed to generate the desired texture on the
rendering models. Reference [46] enlightens us well. We
project the depth, normal and curvature to a plane separately
to make them images. We first compute the probability of
texture appearance of a pixel on the rendering image. The
probability of texture appearance is related to normal and
depth in the image. The function is:

Figure 7. The traditional rendering for NPR.

are three layers now. In addition, we rule that parameters in
non-thinning regions are used in color rendering and texture
rendering, while those in thinning regions in silhouette
rendering. This is because non-thinning regions are often
with more artistic styles in an artwork, such as textures and
colors, while thinning regions are often with less.
A. Silhouette Rendering
The traditional silhouette rendering is based on the
stroke-based method. It first builds a brush model [4] to
express the brush profile. And a stroke making mechanism
[40] is used to decide the path of the brush movement. These
methods are effective. In order to make the feature analysis
results available, we propose other algorithms.
It has been mentioned above that the parameters in
thinning object, such as the average width, are used in
silhouette rendering. The main idea is to make a texture used
for mapping on 3D model surfaces. In detail, the brush area
in texture map is proportional to the average width. And we
set the middle of average width to the center of texture map.
The texture coordinates (u,v) is equal to(0, cos(N∙V)), in
which N is the normal of each vertex in 3D models and V the
viewer vector. The result is displayed in Figure 9b.

92

P ( pix ) = ω ⋅ (1 − N ⋅ V

)

dis

+ rand ,

(7)

where ω is the desired appearing weight, N is the normal
vector and V is viewing direction. dis is the scattered degree
which determines the density of texture. Let dis = ωD∙Depth,
where ωD is the desired scattered weight. The smaller the dis
is, the sparser the scattering of texture will be. The rand is a
random factor that creates non-uniform textures. Then, an
appearance threshold TP is chosen, and if P(pix)>TP, a
texture centered at p is mapped using the following mapping
function. Note that a texture sampling set has existed; we can
choose one in it randomly to avoid single expression.
In OpenGL, the movement of objects is controlled by a
matrix. Therefore, we design a mapping matrix here:
M = T ( x , y ) ⋅ R (θ + φ ) ⋅ S ( s , t ) .

(b)

(c)
Figure 9. (a) Ink color rendering. (b) Silhouette rendering.
(c) Combining results.

VI.

(8)

Here, we display variety of rendering results. Proved by
our experiments, the modified rendering framework can
accomplish the rendering based on an artwork input well
(Figure 10 and Figure 11).

In the function above, the scale vector (s,t) is inversely
proportional to the camera distance. The texture is then
rotated to align the orientation angle θ with a deviation angle
ϕ which allows identical styles of texture to be generated in
different directions. θ is given byθ = tan-1(cy∕cx), where
(cy∕cx) is a 2D vector obtained in curvature direction
projecting.

VII. CONCLUSION AND FUTURE WORKS
A novel system for Chinese ink-style transferring from
an input artwork to a 3D scene is proposed. It successfully
generates many additional Ink-Wash styles. In contrast to
other previous 3D NPR researches, the proposed rendering
mechanism is guided by the features in artwork rather than
traditional user-specified parameters. It means that some
automatic learning and style transfer techniques are used to
reduce the manual effort. Therefore, we can construct a
scene of ink-style virtual world maintaining the coherence to
an input famous painting.
Several feature works will be performed and described as
follows. For example, we will investigate better modeling
methods to enhance our system. We may consider fractal
modeling techniques [36], [37], [38] which can build
unsymmetrical models with more inflexible. In addition,
some extra work in the proposed system will be done in the
near future, such as analyzing other more complex textures
and constructing our ink-color library and texture library.

C. Color Rendering
Artists usually use few tones of colors when painting the
interior area in a Chinese painting process. We first quantize
the original models rendered in Gouraud shading into four
color image by follows:

⎧ 0.1
⎪⎪0.4
deg ree _ mat = ⎨
⎪0.7
⎪⎩1.0

⎫
0.55< dif ≤ 0.8 ⎪
⎪.
⎬
0.25< dif ≤ 0.55 ⎪
dif ≤ 0.25 ⎪
⎭

RESULTS

dif > 0.8

(9)

Then, the color probability distributions are calculated
and made to a 1D texture. We smooth it and use it to map
color on 3D models. Last, a 5x5 Box Filter is applied to each
pixel of whole image to blur sharp borders. Figure 9a
displays the results.
After the three layers rendering process, we combine
these results together. See Figure 9c.

ACKNOWLEDGMENT
This paper was not possible without the support and
encouragement of people. We would especially like to thank
Zheng Wang and Xiujin Wang for their invaluable advice in
the development of the framework. Thanks also go to Bin
Yu, Zhaowei Ding and Yamei Zhao for discussions about
other work that has been done in this area.

(a)

(a)

(b)

(c)

93

(d)

(e)
Figure 10. Fish. (a) Origin. (b) Segmentation. (c) Contour extracting. (d) 3D modeling. (e) Fish rendering results from different viewer directions.

(a)

(b)

(c)

(d)

(e)

(a)

(b)

(c)

(d)

(e)
Figure 11. Modified 3D ink style rendering based on an artwork input. (a) Artworks.
(b) Segmentation. (c) Contour extracting. (d) 3D modeling. (e) Rendering results for the input artwork.
[3]

REFERENCES
[1]
[2]

B. J. Meier, “Painterly rendering for animation,” Proc.
SIGGRAPH’96, 1996, pp. 477-484.
C.J. Curtis, S.E. Anderson, J.E. Seims, K.W. Fleischer, and D.H.
Salesin, “Computer-Generated watercolor,” Proc. SIGGRAPH’97,
1997, pp. 421-430.

[4]

94

A. Hertzmann, C. E. Jacobs, N. Oliver, B. Curless, and D.H.
Salesin, “Image analogies,” Proc. SIGGRAPH’01, 2001, pp.
327-340.
D. L. Way and Z. C. Shih, “The synthesis of rock textures in
Chinese landscape painting,” Computer Graphics Forum, Sep. 2001,
vol. 20, no. 3, pp. 123-131.

[5]
[6]
[7]
[8]

[9]
[10]
[11]

[12]
[13]
[14]
[15]
[16]
[17]
[18]
[19]
[20]
[21]

[22]
[23]
[24]
[25]

B. Wang, W. Wang, H. Yang, and J. Sun, “Efficient example-based
painting and synthesis of 2D directional texture,” IEEE Trans.
Visualization and Computer Graphics, 2004, pp. 266-277.
M. Salisbury, C. Anderson, D. Lischinski, and D.H. Salesin,
“Scale-dependent reproduction of pen-and-ink illustrations,” Proc.
SIGGRAPH’96, 1996, pp. 461-468,
O. Deussen, T. Strothotte, “Computer-generated pen-and-ink
illustration of trees,” Proc. SIGGRAPH’03, 2003, pp. 13-18.
A. Lu, C.J. Morris, J. Taylor, D.S. Ebert, C. Hansen, P. Rheingans,
et al., “Illustrative interactive stipple rendering,” IEEE Trans.
Visualization and Computer Graphics, Apr./June 2003, vol. 9, no. 2,
pp. 127-138.
Pastor, B. Freudenberg, and T. Strothotte, “Real-time animated
stippling,” IEEE Computer Graphics and Applications, July/Aug.
2003, vol. 23, no. 4, pp. 62-68.
L. Markosian, M.A. Kowalski, D. Goldstein, S.J. Trychin, J. F.
Hughes, and L.D. Bourdev, “Real-time non-photorealistic
rendering,” Proc. SIGGRAPH’97, 1997, pp. 415-420.
A. Lake, C. Marshall, M. Harris, and M. Blackstein, “Stylized
rendering techniques for scalable real-time 3D animation,” Proc.
Int’l Symp. Non-photorealistic Animation and Rendering’00, 2000,
pp. 13-20,
E. Praun, H. Hoppe, M. Webb, and A. Finkelstein, “Real-time
hatching,” Proc. SIGGRAPH’01, 2001, pp. 581-593.
D. Cornish, A. Rowan, and D. Luebke, “View-dependent particles
for interactive non-photorealistic rendering,” Proc. Graphics
Interface Conf. (GRIN’01), 2001, pp. 151-158.
R.D. Kalnins, L. Markosian, B.J. Meier, M.A. Kowalski, J.C. Lee,
P.L. Davidson, et al., “WYSIWYG NPR: Drawing strokes directly
on 3D models,” Proc. SIGGRAPH’02, 2002, pp. 755-762.
Simon Schofield, “Non-photorealistic rendering”, PhD thesis,
Middlesex University, England, 1994.
W. Xiujin, S. Jizhou, “Simulating for Chinese paintings based on
image analogies”, Proc. Virtual Reality and its Application in
Industry (VRAI’03), 2003, pp. 157-161.
C. Ching, A. Ergun. “Two methods for creating Chinese painting”,
Proc. The 10th Pacific Conference on Computer Graphics and
Applications (PG’02), Beijing, 2002, pp. 403-413.
X. Songhua, X. Yingqing, K. Singbing, “Animating Chinese
paintings through stroke-based decomposition”, ACM Transactions
on Graphics, vol. 25, no. 2, 2006 pp. 239-267, April.
T. Igarashi, S. Matsuoka, H. Tanaka, “Teddy: A sketching interface
for 3D freeform design”, Proc. ACM Trans. SIGGRAPH’99, 1999,
pp. 409-416.
Igarashi, Hughes, “Smooth meshes for sketch-based freeform
modeling”, Proc. ACM Symposium on Interactive 3D Graphics,
ACM I3D, Monterey 2003, pp. 139-142.
L. B. Kara, Chris M. D'Eramo, K. Shimada, “Pen-based styling
design of 3D geometry using concept sketches and template
models”, Proc. ACM Symposium on Solid and Physical Modeling
(SPM’06), ACM Press, New York, NY, USA, 2006, pp. 149-160.
C. Yang, D. Sharon and M. D. Panne, “Sketch-based modeling of
parameterized objects”, Proc. The 2nd Eurographics Workshop on
Sketch-Based Interfaces and Modeling, Dublin, 2005, pp. 63-72.
W. T. Freeman, J. B. Tenenbaum and E. Pasztor, “Learning style
translation for the lines of a drawing”, ACM Journal Name, vol. 5,
no. n, 2003, pp. 33-46.
D, Comaniciu, P. Meer, “Mean shift: A robust approach toward
feature space analysis”, IEEE Trans. on Pattern Analysis and
Machine Intelligence, 2002, vol. 24, no. 5, pp. 603-619.
P. Decaudin, “Geometric deformation by merging a 3D-object with
a simple shape”, Proc. Graphics Interface (GI’96), May 1996, pp.
50-60.

[26]
[27]

[28]
[29]
[30]
[31]
[32]
[33]
[34]
[35]
[36]
[37]

[38]

[39]
[40]
[41]

[42]
[43]
[44]
[45]
[46]

95

D. Lin, X. Tang, “Coupled space learning for image style
transformation”, Proc. The 10th IEEE International Conference on
Computer Vision (ICCV’05), vol. 2, 2005, pp. 1699-1706.
S. Grabli, F. Durand, E. Turquin, F. Sillion, “Density measure for
line-drawing simplification”, Proc. the 12th Pacific Conference on
Computer Graphics and Applications (PG’04), Oct. 2004, pp.
309-318.
P. S. Michael, T. W. Michael, F. H. John, “Orientable textures for
image-based pen-and-ink illustration”, Proc. SIGGRAPH, Computer
Graphics, ACM Press, August 1997, pp. 401-406.
H. Nick, T. Isenberg, F. Ritter, “OpenNPAR: A system for
developing, programming, and designing non-photorealistic
animation and rendering”, Pacific Graphics 2003, pp. 424~428.
M. T. Chi, T. Y. Lee, “Stylized and abstract painterly rendering
system using a multiscale segmented”, IEEE Trans. Visualization
and Computer Graphics, vol. 12, no.1, 2006, pp. 61~73.
C. R. Yan, M. T. Chi, T. Y. Lee, “Stylized rendering using samples
of a painted image” IEEE Transactions on Visualization and
Computer Graphics, vol. 14, no. 2, 2008, pp. 468-481.
Y. Deng, B. Manjunath, and H. Shin, “Color image segmentation,”
Proc. IEEE Conf. Computer Vision and Pattern Recognition
(CVPR’99), June 1999, .pp. 446-451.
Pal N, Pal S. “A review on image segmentation techniques”, Pattern
Recognition 1993, Dec. 1993, pp. 74-94.
A. D. Cheok, et al. “Humanistic Oriental art created using
automated computer processing and non-photorealistic rendering”,
Computer and Graphics, 2003, vol. 31, pp. 280-291.
Z. Min Jin, Image Analysis, QTinghua Press, Beijin, 2005, pp.
74-101.
C. I. Fetita, and F. Preteux, “Bronchial tree modeling and 3D
reconstruction”, Proceedings of SPIE - The International Society for
Optical Engineering, 2000, vol. 4121, pp. 16-29.
Yokoya, Naokazu, Yamamoto, Kazuhiko, Funakubo, Noboru,
“Fractal-based analysis and interpolation of 3D natural surface
shapes and their application to terrain modeling”, Proc. Computer
vision, graphics, and image processing (CGIV’05), Jun. 2005, vol.
46, no. 3, pp. 284-302.
L. Xi Kui, Y. Si Rong, “3D dynamic modeling method for railway
route selection in virtual environment based on fractal technology”,
Zhongguo Tiedao Kexue/China Railway Science, March 2005, vol.
26, no. 2, pp. 44-48.
C. Chan, E. Akleman, “Two methods for creating Chinese
painting”, Proceedings of the 10th Pacific Conference on Computer
Graphics and Application (PG’02), Beijing, 2002, pp. 403-414.
S. Strassmann, “Hairy brushes.” Computer Graphics (Proc.
SIGGRAPH’86), August 1986, vol. 20no. 4, pp. 225-232.
A. Girshick, V. Interrante, et al. “Line direction matters: An
argument for the use of principal directions in 3D line drawings”.
Proceedings of the first international symposium on NPAR, June
2000, pp. 43–52.
G. Turk, “Re-tiling polygonal surfaces”, Computer Graphics, July
1992, vol. 26, no. 2, pp. 55–64.
L. Shiqing, C. Youping, Y. Chuming and Z. Zude, “Approach of
solving vertex curvature for triangular mesh model”, Application
Research of Computers, June 2007, vol. 24, no. 6, pp. 107~109.
T. Yao,I. Z. Xizhe, W. Zhengxun, “An algorithm for Distilling the
skeletons of the works of Chinese Calligraphy”, Journal of
Engineering Graphics, 2006, no. 5, pp. 98-104.
L. Prasad. “Morphological analysis of shapes”, Proc. CNLS,
Newsletter, July 1997, vol. 139, pp. 1-18.
Mower, James E., “Automating landscape illustration with pen and
ink style rendering”, Cartography and Geographic Information
Science, January 2009, vol. 36, no. 1, pp. 117-128.

