A simple and quick method for rendering underwater optical effect
Qin Bo , Liu Kai , Xie Cui
Computer Science Department, Ocean University of China, Qingdao 266100, China
{qinbo@ouc.edu.com, liukai779@163.com, xiecuidlmu@sohu.com}
Abstract
Underwater optical effect simulation is an important
part of simulating natural scene. However, computing
these effects is difficult and time-consuming, since light
refracts when passing through waves. To address the
problem, this paper proposes a simple and quick method
for rendering underwater scenes, including the shafts of
light refracted by the dynamic water surface, caustics
caused by the effects of light and shadows beneath the
creatures in the water. The method simplifies the
Iwasaki’s method to save the computation-time by an
eye-irrelative method calculating the intensities of the
illumination volumes with parts of intersection points of
Iwasaki’s. As the experiment results show that our
method got a high frame rate with an acceptable quality
for real-time applications.
Keywords--- Real-Time Rendering, Illumination
Volumes, Eye-irrelative

1. Introduction
Simulating realistic scenes is one of the most
attractive fields in computer graphics. The rendering of
underwater optical effect is one of the essential
components for simulating realistic natural scenes, such
as the shafts of light refracted by the water surface
passing through the water, caustics caused by the effects
of light and shadows beneath the wandering creatures in
the water. In 2002, Iwasaki et al [1] presented an
efficient method for rendering the underwater optical
effect using graphics hardware. According to the location
of the eye, sub illumination volumes are defined for
displaying shafts of light and rendering caustics. So this
method has to spend lots of time to calculate the vertices
of tetrahedrons. In this paper, we use another simple
method modified the Iwasaki’s to save the computationtine using an eye-irrelative method for calculating the
intensities of the illumination volumes with only parts of
the points used in Iwasaki's method. Thus our method
could accelerate the rendering speed and the rendering
quality is acceptable for real-time application.

Computer Graphics, Imaging and Visualisation (CGIV 2007)
0-7695-2928-3/07 $25.00 © 2007

2. Previous work
Plenty of methods for rendering optical effects
underwater have been proposed through the years.
Displaying shafts of light is one of the most important
parts of simulating the scattering of light underwater; so
many methods have been proposed to illuminate the
underwater optical effect. Known as a common method,
ray tracing including forward ray tracing and backward
ray tracing appeared in 80’s 20 century, which need to
calculate the intersection points between the viewing ray
and the objects. Therefore it is very time-consuming.
Szirmay-kalos L. et al. [2] proposed an approximate raytracing method based on the GPU. Jensen and
Christensen [3] displayed caustics and shafts of light
using photon maps. Though it can display the interactive
in the complicated scenes, the method does not be fit for
real-time rendering. Tin-Tin Yu et al. gave us a good
application based on photon mapping [4]. In 1994,
Nishita and Nakamae [5] presented a method for
displaying caustics, shafts of light, and the color of the
water by using an accumulation buffer. The water
surface was subdivided into meshes and illumination
volumes were defined. The advantage of this method is
to deal with free-form surfaces, but it took several
minutes to simulate the image since the accumulation
buffer used was not a graphics hardware buffer and the
intensities of the illumination volumes at each scan plane
have to be calculated. Kei Iwasaki and Dobashi [1]
extended the method Nishita presented. The sub volumes
were divided into three tetrahedrons, and calculated the
intensities of each vertex of the tetrahedrons. By using
graphics hardware this method can be used in rendering
great scenes.
Realistic water-caustics is a vital component in
rendering underwater scenes. Jensen [3] used photon
mapping to handle arbitrary geometry and added support
for volume caustics and participating media. Shinya et al.
[6] proposed an algorithm for displaying caustics. They
calculated the illumination distribution on the surface in
advance by using grid pencil tracing. However
calculating the distribution on the water surface is very
complicated and time-consuming due to the interactive
of the reflected light and refracted light on the surface.

Johannes Günther et al. [7] presented a detailed analysis
of the performance on rendering caustics using photon
mapping. But as mentioned above photon mapping
couldn’t overcome its inherent shortcomings. Watt [8]
developed backward beam tracing using the illumination
map and caustic triangle. This method can also deal with
the situation of polygonal objects. Larsen et al. [9]
simulates photon mapping, using GPU accelerated final
gathering. Josh Barczak et al. [10] used hierarchical
structure over the refracting objects to show caustics
appearance. Stam[11] presented a method of creating
caustics texture. Iwasaki [12] described how to render
caustics by dividing the objects into slices. Christoffer
Sandberg [13] presented a method for rendering caustics
using caustic-volumes which is faster than photon
mapping and ray tracing, which is more dynamic than
Pre-generated caustic textures and scales better than the
volume-based method presented by Iwasaki et al. [1][12].
However, their method did not render the shafts of
refraction light through the water volume.
In order to get higher frame-rate than better quality,
we modify the method described by Iwasaki et al. [1].
For reducing the computation-time, we use an eyeirrelative method to render the shafts of light and the
caustics due to the reflected and refracted light
converged and diverged dynamic underwater. Then, we
create the shadows with the shadow volume technique, a
common method, which has been used in many cartoon
movies. The result is acceptable for real-time
applications.
The structure of this paper is as follows: in Section
3.1 the method of creating the water surface mesh is
presented, whereas in Section 3.2 the method of
calculating the position of shafts of light is analyzed.
Section 3.3 presents the eye-irrelative method of
rendering illumination volume. In Section 3.4 the method
of rendering caustics is given. Experiment results are
shown in Section 4. Section 5 discusses the conclusions
and future work.

3 Overview of our method
3.1 Creating water surface mesh
The water surface is a continuous surface as shown
in figure 1. There are lots of methods for water surface
model. For simulating more reality water surface, we
adopt the statistical wave model of FFT transform [14].
And the formula is as following:
~

h( x, t ) = ∑ h (k , t )e

ikx

------------- (1)

k

Where H is the height at time t of the lattice point
of the water surface mesh. The wave vector is calculated
by the following equation:
~

∗

iw ( k )t
− iw ( k )t
~
~
h (k , t ) = h0 (k )e + h0 (− k )e

Computer Graphics, Imaging and Visualisation (CGIV 2007)
0-7695-2928-3/07 $25.00 © 2007

---- (2)

Via changing from frequency domain to spatial
domain, we could achieve the realistic ocean water
height.

Figure 1 The water surface mesh

3.2. Calculating Shafts of light

r
n

ω

θ

θ

θ

P
P

r
m
α

h

2

1

2

β

h

1

'

l

1

l

2

Figure 2 Calculating the intersection of the
refracted light and the water floor
The light reaches to the lattice point of water surface
mesh after the light emitted from the sun. The light is
reflected and refracted on the surface, and parts of the
light are culling and clamping due to the water. The
reflected beam is sent back to the sky. The beam as
shown in figure 2 refracts at each lattice point of the
water surface and then transmits to the bottom of the
water. As to calculate the intensity of the refracted beam,
we should at first calculate the position of the initial
point and the terminal point of the beam. The initial point
is the lattice point of the water surface. The position of
the lattice point of the water surface is given in equation
2. So we should work out the position of the intersection
in figure 2 which is also the terminal point.
The direction of incident ray is calculated using
Snell's Law as showing below.

sin α

sin β

=γ

-------------------- (3)

Where α is the angle of incidence, while β is the
angle of refraction, γ is refractive index of the medium.
The index of water is 1.33, here γ =1.33.
Here are the equations.
→

P

P

1

→

cos α = n • m

P

sin α = 1 − cosα

tanθ 1 = h2

θ

l

P

the triangle

2

on the water along the y axis.

l

2

is the distance between

the sun and the lattice point on the water along the x axis.
According to the equations above, the direction of
the refracted light is calculated as below.

(

tan θ = tan Π + β − α − θ 1
2

)

P and
along x axis. The point P ( x, y , z )
corresponded with the surface point P .

distance between the lattice point
'

l

is the

1

the point

P

'

is the point

Based on those above equations, the position of the
intersection between the refracted light and the water
floor is achieved. Here is the equation of the coordinates
of the intersection point
coordinate of the point

P' .

z

p

equals to the z

P.
---------------- (4)

2

3

'

'

2

3

I

p

'

'

'

1

2

3

PPP

have been calculated.

P is calculated using the following equation.

(λ ) = T (θ i ,θ t )(I sun (λ )δ (θ i ,θ t ) + I sky (λ,θ i)) -- (5)

Where T (θ ,θ ) is the Fresnel transmittance from
i
t
angle of θ to θ and δ (θ ,θ ) is a function that takes the
i

t

t

value 1 as the direction of the refracted light is
coincident with the direction of the viewing ray, and is 0
as it is not. I sky (λ , i ) stands for the skylight.

θ

Due to the light is exponential attenuated in the
water; the illumination of the refracted light can be
approximated linearly. The illumination of the
intersection point P ' is calculated as following.

=

pi ∗ φ ∗ cos ω

Where

Ip

------------------ (6)

is the illumination on the lattice point of
i

,

for example, the vertices positions of

Computer Graphics, Imaging and Visualisation (CGIV 2007)
0-7695-2928-3/07 $25.00 © 2007

φ is

0.2. ω is the angle between

→

P P and the normal n of the point on water surface (see
'

'

'

point

from 0 to 1.0, here

3

1

and

water calculated by equation 5, φ is the flux ratio ranges

are the intersection points of the refracted
light and the water floor. Take the illumination volume
1

3

sun

i

,

PP PPP P

2

refraction in the air, so that the sunlight is considered as
direct ray. In Figure 3 the illumination I of each lattice

IP I

refracted vector at each point of the mesh. P1 P2 P3 are
the lattice points of the water surface separately, and
2

1

i

In Iwasaki’s method the eye position should be
considered, but in our method we simplify the method
and do not consider the location of the eye. In figure 3
the illumination volume is defined by sweeping the

'

3

Now we should calculate the intensity of each point.
As shown in figure 3, the incident light reaching the
water surface is composed of two components: direct
sunlight and skylight. In our method consider the
sunlight in existence and regard the skylight as ambient
light. Suppose that the illumination of the sunlight
is I (λ ) and do not concern with the reflection and

'

3.3. Rendering illumination volume

'

PPP

i

= tan θ ∗ h1

1

2

'

p

Suppose the bottom of water is flat.

P ,P ,P

'

Figure 3 An Illumination volume

→
Here m
is the direction of the incident light, n is the
normal direction of the lattice point on the water surface.
h is the distance between the sun and the lattice point

⎧ x = l1 + l 2
⎪
⎨y = 0
⎪z =
zp
⎩

P
P

2

→

1

'

1

θ =θ 2 + β − Π 2

l

3

2

= Π − α −θ 1

2

2

figure 2). ω denotes that how much refracted light enter
into the water.
Having got the illumination of each point, we render
each side of the illumination volume by using Gouraud
shading method. Take the side P P P' P' for example, we
1

3

1

3

have calculated the illumination of each vertices point.
Then the illumination intensity is interpolated along each
segment of the side P P P' P' . And the illumination of
1

3

1

3

the points in the side can be achieved. The location of the
eye in the water is not considered in our method.

,Δ

and Δ

PPP ,

3.4. Displaying Caustics

points in Δ

Light is reflected and refracted on the water surface,
where after the refraction and ambient light is converged
and diverged due to light scattering by suspended
particles in the water. The light creates the patterns
called caustics on the freeform object. Jensen proposed
photon map to achieve the distribution of photons on
object surface, which results a perfect effect. But this
method is too time-consuming to display the under water
scene on time. With the development of graphics
hardware, Gouraud shading color blending and Z-buffer
algorithm can all be performed by hardware, which
accelerates the rendering. So while rendering caustics
this technology could be applied in our method.
After rendering the illumination shafts of light, it is
much easier to render the caustics underwater. Here our
rendering consists of three phases, first step is the
computation of the intersections between shafts of light
and the surface of the receiver object, second one is to
calculate the intensities we need, the last step is
rendering caustics using the graphics hardware.

we can use Gouraud shading method to render the
beautiful caustics underwater.

P

P

P

P

1

1

P

4

P

3

'

P

1

P
P

'

1

'

P

P

4

P

'

2

3

ΔP

'

'

3

4

PP

'

P

1

'

P

2

'
3

'

'

P

2

Figure 5 An underwater scenery

P
'

P

4

'
3

Figure 4 Two illumination volumes combine a
prism
The position of vertices points in the first step can
be got from the formula (2) and formula (4). And the
illumination of each point in the quadrilateral of
'
'
'
'
P P P P (see figure 4) has been given in the formula
1

2

3

4

in (6). As in figure 4, we combine two illumination
volumes into one prism. Suppose the most brightness
point in the quadrilateral of P' P' P' P' is P . And P is
1

2

3

4

closer to the most brightness one point of
and

P

'
4

'

p

=

'

'

2

3

. We give the equation of calculating the

illumination of

I

'

1

P ,P ,P

'

'

P

as follows.
'

'

'

'

'

(r1 ∗ P1 + r 2 ∗ P2 + r 3 ∗ P3 + r 4 ∗ P4)

r

Here

'
i

(r + r + r + r )
'

'

'

'

1

2

3

4

(7)

is the illumination of the point P' .
i

P

Figure 6 Scenic without caustics
'
i

stands for the position of each point P ' . There’s no
i

intersection of the point between the quadrilateral of
'
'
'
'
P P P P and the eye, so that the illumination of the
1

2

3

4

point is zero. According to the illumination of the

Computer Graphics, Imaging and Visualisation (CGIV 2007)
0-7695-2928-3/07 $25.00 © 2007

'

4

Figure 5 shows the whole scenery underwater with
some float grasses, goldfishes and three sharks. The
shafts of light, shadows and caustics are rendered. In
contract, Figure 6 shows the scenic without caustics.
Figure 7 gives the underwater scene seeing from the
bottom to the water surface. Figure 8 shows the weak
caustics on a shake and submarine opposite to the strong
caustics shown in Figure 5.

'

P

4

'

1

4. Experiments and Results

3

P

1

P

'

PPP

P

2

3

3

2

2

4

'

'

'

'

P

1

P

3

P

P

2

'

1

PPP

rendering the shafts of light and the caustics due to the
reflected and refracted light converged and diverged
dynamic underwater. The shadows are created through
the shadow volume, a common method, which has been
used in many cartoon movies. We have shown that the
method performs well with high frame rate even running
with low performance PCs. We can achieve better effects
by using high-end hardware available on home consumer
market to accelerate calculation.
In future work, we aim to increase the rendering
speed by using the GPU which could do the vertex
programming. Also, we would like to create a more
nature effect by improving on the interaction between the
shadows and the caustics.

Figure 7 Water surface seeing from the bottom

References
[1]

[2]
[3]

[4]
[5]
[6]

Figure 8 Weak caustics and shadow

[7]

We create the underwater scenery on a desktop PC
(Pentium III) 512M memory with NVIDIA Geforce5200.
The image sizes of these figures are all the same,
1024*768. The mesh size of the water surface is 32*32,
so there are 32*32 illumination volumes for rendering.
The computation-time of Figure 5 is 10 frames per
second, and Figure 6 without caustics is 16 frames per
second. The rendering of water surface in Figure 7 is 16
frames per second. The time of pretty caustics in Figure
8 is 19 frames per second. However in Iwasaki’s method,
the fastest computation-time could arrive 2.92 seconds.
Our method could save much computation-time in
rendering.

[8]

5. Conclusion and Future Work
In this paper, we have presented a method that
modifies the Iwasaki’s method for creating the
underwater optical effect. This method is irrelative with
the eye position and save much computation-time for

Computer Graphics, Imaging and Visualisation (CGIV 2007)
0-7695-2928-3/07 $25.00 © 2007

[9]
[10]
[11]
[12]

[13]
[14]

Kei Iwasaki, Yoshinori Dobashi and Tomoyuki Nishita.
An efficient method for rendering underwater optical
effects using graphics hardware. In Computer Graphics
forum, pages 701-711.2002.
Szirmay-Kalos L., ASZÓDI B., LAZÁNYII and
Premecz M.. Approximate ray-tracing on the GPU with
distance impostors. In Computer Graphics Forum.
H.W.Jensen and P.H.Christensen. Efficient simulation of
light transport in scenes with participating media using
photon maps. In Proc.SIGGRAPH’98, pages 311320.1998.
TinTinYu, John Lowther and ChingKuang Shene.
Photon Mapping made easy. SIGCSE’05.
T.Nishita and E.Nakamae. Method of displaying optical
effects within water using accumulation-buffer. In
Proc.SIGGRAPH’94, pages 373-380.1994.
M.shinya, T.Saito and T.Takahashi. Rendering
techniques for transparent objects. In Proc. Graphics
Interface’89, pages173-181.1989.
Johannes Günther, Ingo Waldy and Philipp Slusallek.
Realtime caustics using distributed Photon Mapping. In
EUROGRAPHICS Symposium on Rendering. 2004.
M.Watt. Light-Water interaction using backward beam
tracing. In Computer Graphics, pages 173-181. 1990.
Larsen B. D., Christensen N. Simulating photon mapping
for real-time applications. In EUROGRAPHICS
Symposium on Rendering. 2004.
Josh Barczak and Marc Olano. Interactive shadowed
caustics using hierarchical light volumes.
J.Stam. Random caustics: natural textures and wave
theory revisited. In Technical Sketch SIGGRAPH’96,
page151. 1996.
Kei Iwasaki, Yoshinori Dobashi and Tomoyuki Nishita.
A fast rendering method for refractive caustics due to
water surfaces. In EUROGRAPHICS 2003. Volume 22,
Number 3. 2003.
http://www.ce.chalmers.se/~uffe/xjobb/caustics.pdf
Jason L. Mitchell. Real-Time Synthesis and rendering of
ocean water. 2005.

