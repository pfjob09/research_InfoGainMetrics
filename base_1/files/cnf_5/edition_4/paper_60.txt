Facial Expression as an Implicit Customers’ Feedback and the Challenges
Zolidah Kasiran and Saadiah Yahya (Dr)
Faculty of Information Technology & Quantitative Science
Universiti Teknologi MARA,
Shah Alam, Malaysia
zolid808@salam.uitm.edu.my, saadiah@tmsk.uitm.edu.my
Abstract
The human face is rich of information and plays
important roles in daily communication such as
expressing the emotions nonverbally. Facial
expression comes in all varieties. Some are intense
and sustained while others are subtle and fleeting.
Much progress has been made to build computer
systems that recognize facial expression for human
computer interaction such as affective computing
which apply the automatic facial recognition
techniques in human computer interaction where the
main idea is that the computer could better adjust its
behavior to user’s current emotion. Other possible
area that could use the advance technology of Facial
expression recognition system is the customer
satisfaction measurement. The expression of
customer being served at the counter is captured to
evaluate the satisfaction of the customer. This
multimedia approach of customer satisfaction
measurement is an alternative of the conventional
way of collecting customers’ response.
Keywords:
satisfaction

Facial

Expression,

Customers’

1. INTRODUCTION
In social interaction, face is playing an important
role. Social psychology researches had agreed that
among the three mediums in communication, facial
expression is the one that is always active. Mehrabian
[1] indicated that the verbal part of a message
contributes only for 7 percent to the effect of the
message as a whole; the vocal part contributes for 38
percent, while facial expression of the speaker
contributes for 55 percent to the effect of the spoken
message.
Psychologists Paul Ekman and Friesen in 1978
had come with a method to classifying muscle

Computer Graphics, Imaging and Visualisation (CGIV 2007)
0-7695-2928-3/07 $25.00 © 2007

movement to measure the facial expression. This
method, which later became the mostly used in
classifying facial movement in behavioral science, is
called Facial Action Coding System (FACS). Most of
the research work on Facial Expression Recognition
refers to the Facial Action Coding System. Paul
Ekman [2], believed that basic emotion is universal,
though he challenge those who can claim otherwise.
The universality of emotion expression proposed by
(Ekman,1999) was supported by various researchers.
The study of emotion universality [3] using American
and Indian to recognize emotion expression of 45
selected pictures had convinced that
there is
existence of universality in emotion expression.
People from different backgrounds display similar
expression in respond to similar stimuli [4], but it is
reasonable to expect local variations. Thus Ekman
suggested that extreme positions regarding the
universality of emotion are incomplete. Seven Basic
emotions established are; happy, sadness, anger,
surprise, fear, disgust, and contempt.

2. RELATED WORK
The research, facial expression analysis received
significant attention with the wide range of
commercial application and more feasible
technologies available. All the existing methods for
automated facial expression recognition are mainly
based on three steps: face acquisition, facial
extraction and facial expression identification from
the observed facial image or image sequence.
The works of facial expression analysis has
evolved from recognizing expression in static image
to video and in simple background to complex
background with different pose and illumination
changes. Facial feature extraction is another
challenging step and most of the works in extracting
facial feature employed either motion-based method
or deformation of face. Motion-based[[5, 6] method
focuses directly on the occurring changes in the face

due to the facial expression while deformationbased[[7-9] have to rely on neutral face images or
face model in order to extract facial features that are
relevant to facial action. The processing of the facial
feature could be done either locally or holistically
where the face is process by focusing on facial
feature areas that are prone to changes or the whole
face to the latter.
[10] performs real-time emotion classification
using automatic machine learning algorithms. The
real-time system developed uses a model based nonrigid face tracking algorithm to extract motion
features that serve as input to a classifier used for
recognizing the different facial expressions. [11]
work has been focused towards developing a tool for
animators, which will enable quick and easy
generation of draft scenes whereby an animated
character or characters may undergo several
transitions between emotions. The approach adopted
in this work is to provide an `expression space’,
which an animator can navigate, and as they move
throughout this space, a new sequence corresponding
to the selected emotion is synthesized and generated
automatically.
The works of facial expression had been
implement in many area such as security, biometric,
robotic and Human Computer Interaction and [12]
had suggest the ideal system that all of stages of
facial expression analysis are to be performed
automatically from face detection to facial expression
information extraction and facial expression
classification. The characteristics of automatic facial
expression classifier are also mentioned as in Table 1
and Table 2.
Table 1: General Characteristic of automatic facial
expression classifier

1
2
3
4
5
6
7
8
9
10
11
12
13

Characteristic
Automatic facial image acquisition
Subjects of any age, ethnicity and outlook
Deals with variation in lightning
Deals with partially occluded faces
No special markers/ make-up required
Deals with rigid head motions
Automatic Face detection
Automatic facial expression data extraction
Deal with inaccurate facial expression data
Automatic facial expression classification
Distinguishes all possible expression
Deals with unilateral facial changes
Obeys anatomical rules

Computer Graphics, Imaging and Visualisation (CGIV 2007)
0-7695-2928-3/07 $25.00 © 2007

Table 2: Characteristic of automatic facial
expression classifier in Behavioral
Science and HCI
1.
2.
3
4.
5.
6.
7.

Characteristic
Distinguishes all 44 facial actions
Quantifies facial action codes
# interpretation categories unlimited
Features adaptive learning facility
Assigns quantified interpretation labels
Assign multiple interpretation labels
Features real time processing

Researcher [13] is an active researcher in facial
expression area and she evaluates few face
recognition and facial expression recognition
techniques under various resolutions. The author
found that the combination of technique gave a better
result and the lowest resolution that the technique can
still perform is 36x48.

3.
FACIAL
EXPRESSION
SATISFACTION LEVEL

AND

Recent advances in image analysis and pattern
recognition open up the possibility of automatic
detection and classification of emotional and
conversational facial signals. Possible area that could
use the advance technology of Facial expression
recognition system is the customer satisfaction
measurement. The expression of customer being
served at the counter is captured to evaluate the
satisfaction of the customer. This multimedia
approach of customer satisfaction measurement is an
alternative of the conventional way of collecting
customers’ response.
Quality measurement and improvement have
been an important agenda in many organizations to
stay competitive. A good quality measurement needs
a good instrument and most of the literature on
quality service measurement is based on customer’s
perception, which is translated into numbers using
likert scale. Perception is very subjective and
complicated to be translated into numbers. Thus it is
important to have a new way of collecting
information that is more precise and scientific to
make performance measurement more meaningful.
The objective of this work is to measure the
satisfaction level of the new students during the
registration process using their facial expressions.
Five parties were involves during the registration of

new students at INTEC, UITM; Admission &
Record, Bursary, Accommodation and Sponsor. The
students were informed that their picture would be
taken during the registration process for academic
research purposes. The video was captured during the
last transactions of the registration process, which is
at the sponsors counter. To ease the registration
process, the setup of the registration counters was
arranged such that all involved parties for the
registration were placed at the ad hoc registration
venue, located at INTEC Multipurpose Great Hall.

4. CHALLENGES OF COLLECTING
USER SATISFACTION BASED ON
FACIAL EXPRESSION
Facial expression recognition system may be
able to classify intangible values like customer
satisfaction. The system involve seven steps namely;
identifying the best technique in facial expression,
acquiring a library of images for system training,
installing
the
appropriate
camera
and
hardware/software at the identified location for the
data collection, capturing the images in the real
environment (as the customer is being served at the
counter), storing the captured images in the database,
processing the images, and store the processed result
in the database. Figure 1 illustrate the process of
image processing.

frontal view of facial features which are eye brows
and eyes, while [16] works focus on recognizing
facial expression in profile image sequence.
Multistate face component models have been
developed by [17] to handle different head pose.
Different states head pose have to use different face
component model to ensure the robustness of the
systems. For example, a lip model of the front face
does not work for a profile face.
Based on the different appearances of different
components, different geometric models are used to
model the component’s location, shape, and
appearance. Each component employs a multistate
model corresponding to different component states.
For example, a three state lip model is defined to
describe the lip states whether it is opened, closed,
and tightly closed. A two state eye model is used to
model opened and closed eye. There is one state for
brow and cheek. Present and absent are use to model
the states of the transient facial features. Seven head
states (left, leftfront, front, rightfront, right, down,
and up) are shown in Figure 2.

Figure 2: Multistate Face Model

Figure 1: Sequence Image processing
In facial expression analysis, mouth and eyes
features are playing an important role and both
features should be visible in order to extract the
correct expression. [14, 15]works focus on upper and

Computer Graphics, Imaging and Visualisation (CGIV 2007)
0-7695-2928-3/07 $25.00 © 2007

Most of data collections for the available
databases are set up in the laboratory where the facial
expressions were not spontaneous. Though few
researchers have been conducting the research on the
spontaneous behavior., their work ([18],[19],[20])
collect the data by recording the subject while there
were interviewed on a selected topic in controlled
environment but the subjects were free to move their
heads and out-of plan head was presents during the
discourse.
Affective computing which apply the automatic
facial recognition techniques is getting more attention

([21],[22],[9],[23]). The main idea of affective
computing is that the computer could better adjust its
behavior to user’s current emotion. In this usercentered research, the data were collected by
mounting the camera on the computer monitor and
user’s facial expression was captured during user
interaction with the systems. Affective computing
have little challenges in collecting the data because
user is always facing the monitor while using the
systems and thus frontal or near frontal view is not so
hard to obtain.
Facial expression application for spontaneous
behavior such as at the counter service of student
registration may have problem in data collection due
to physical counter set up and the lighting. On the
normal counter service, staff on duty was seated
behind a table while the customers (student) who was
being served was either sitting down or standing up.
When the customer is seated in front of the staff, the
staff may obstruct the customer. Hence the frontal
view is not possible. While when the customer is
standing up forces the customer (student) to look
down at the table and makes the image capturing very
difficult. During the service, both student and staff
were moving their head and obstructing the camera
from capturing the student’s face as shown in figure 3
(a).
The images in the database set up from
laboratory making sure that the face is not occluded
by the subject’s hair as in figure 3 (b). Though the
down-front face state have been mentioned by [17],
in real environment , subjects tend look down that
make it hard to track the mouth and eyes (figure 3 (c
)-(e)).

(a)

(b)

(d )

(e)

c

Figure 3: (a)-(b) subject was facing front but
occluded by the staff (c)-(e) subject were
facing down

Computer Graphics, Imaging and Visualisation (CGIV 2007)
0-7695-2928-3/07 $25.00 © 2007

5.

CONCLUSION

The facial expression recognition has attracted
intense attention from various group of computer
vision research team and many techniques had been
developed and many areas of application could
benefit from it. Nevertheless, this area is still need a
lot of experiments due to many challenges faced in
real life application. There are many unresolved
issues need more attention. In this paper, the effort
of facial expression capturing in the real environment
regarding the head state model has been elaborated.
The challenges and difficulties encountered when
performing the experimentation were also
highlighted. The issues of natural subtle expression
are also other challenges that should be study more.
This work should be able to substantiate the holistic
customer satisfaction study from the facial expression
perspective rather than from the conventional
customer satisfaction survey. The finding may benefit
all enterprises that are concerned with their customer
satisfaction in order to ascertain good management of
supply chain and hence sustain strategic advantages
and competitiveness.
6.

REFERENCES

1.

Mehrabian, A., Nonverbal Communication. 1972,
Chicago: Aldine Atherton Inc.

2.

Ekman, P., Basic Emotion, in Handbook of Cognition
and Emotion. Su, T.D.a. M.Power(Eds.), Editor. 1999,
John Wiley & Sons, Ltd: Sussex, UK.

3.

Ahalya Hejmadi, R.J.D., Paul Rozin, Exploring Hindu
India Emotion Expression: Evidence for Accurate
Recognition by Americans and Indians. Psychological
Science, 2000. 11(3).

4.

Abigail A Marsh, H.A.E., Nalini Ambay, NonVerbal
"Accents": Cultural Differences in Facial Expressions
of Emotion. Psychological Science, 2003. 14(4).

5.

Masahiro Nishiyama, H.K., Takatsugu Hirayama,
Takashi Matsuyama. Facial Expression representation
based on timing structures in faces. in IEE Int'
workshop on Analysis Modeling of faces and Gestures.
2005.

6.

Lee, K.K.C., Human expression and Intention via
motion analysis:Learning, recognition and ystem
implementation, in Graduate School. 2004, The
Chinese University of Hong Kong.

7.

Pantic M, R.L.J.M. An expert system for multiple
emotional classification of facial expressions. in IEEE

International Conference on Tools with Artificial
Intelligence,. 1999.

20. Zeng, Z., Spontaneous emotional facaial expression
detection. Journal of Multimedia, 2006. 1(5).

8.

Fadi Dornaika, F.D. Simultaneous facial action
tracking and expression recognition using particle
filter. in Internation Conference on Computer Vision.
2005.

21. Amr Goneid, R.E.K. Facial Feature Analysis of
Spontaneous Facial Expression. in 10th International
Artificial Intelligent Conferences. 2002.

9.

Zhihong Zeng, J.T., Ming Liu, Tong Zhang, Nicholas
Rizzoto, Zhenqiu Zhang. Bimodal HCI-related Affect
Recognition. in International Conference Multimodal
Interfaces. 2004. State College, PA, USA.

10. Nicu Sebe, Y.S., Erwin Bakker, Michael Lew,Ira
Cohen ,Thomas Huang. Towards Authentic Emotion
Recognition. in International conference on System,
Man and Cybernetic. 2004.
11. Lisa Gralewski, N.C., Barry Thomas, Colin Dalton.
Statistical synthesis of facial expressions for the
portrayal of emotion. in International Conference on
Computer Graphics and Interactive Techniques in
Australia and Southe East Asia. 2004.
12. Pantic Maja, a.L.J.M.R. Self-adaptive Expert System
for Facial Expression Analysis. in International
Conference on System, Man and Cybernetic. 2000b.
13. Tian, Y. Evaluation of Face Resolution for Expression
Analysis. in IEEE Wokshop on face Processing in
Video (FPIV'04). 2004. Washington DC.
14. Ashish Kapoor, Y.Q., Rosalind W Picard. Fully
automatic upper facial action recognition. in IEEE Int'
workshop on Analysis and Modeling of Faces and
Gestures. 2003.
15. Takeo Kanade, Y.T., T. Kanade, J. F. Cohn and
Jeffrey F. Cohn. Comprehensive Database for Facial
Expression Analysis. in Fourth IEEE International
Conference on Automatic Face and Gesture
Recognition. 2000.
16. Pantic M, I.P., Rothkrantz L.J.M. Facial action
recognition in Face profile image sequence. in IEEE
Int Conf on Multimedia and Expo. 2002. Laussane.
17. Yingli Tian, T.K., Jeffrey F Cohn, Multistate based
facial feature tracking and detection. 1999.
18. M. S. Bartlett, J.R.M., G. Littlewort, B. Braathen,
Frank M. G., Claudia Lainscsek,Ian Fasel, Javier
Movellan. Fully automatic facial action recognition in
spontaneous behavior. in 7th Int. Conference on
Automatic Face & Gesture Recognition. 2006.
19. Jeffrey F Cohn, P.E., Measuring Facial Action by
Manual Coding, Facial EMG, and Automatic Facial
Image Analysis, in Handbook of nonverbal behavior
research methods in the effective sciences, R.R.K.S.
J.A Harrigan, Editor. 2004, Oxford: NY.

Computer Graphics, Imaging and Visualisation (CGIV 2007)
0-7695-2928-3/07 $25.00 © 2007

22. Lesley Axelrod, K.H. E-motional advantage:
Performance and satisfaction gains with affective
computing. in HCI 2005. 2005.
23. Abdolhossein Sarrafzadeh, H.G.H., Chao Fan, Scott P
Overmyer. Facial Expression Analysis for Estimating
Learner's Emotional State in Intelligent Tutoring
Systems. in IEEE Conference on Advanced Learning
Technologies(ICALT'03). 2003.

