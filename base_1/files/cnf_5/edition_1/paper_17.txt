2011 Eighth International Conference Computer Graphics, Imaging and Visualization

Distributed Fusion Filter on Images with Time Delays
Vladimir Shin
Department of Information and Statistics,
Gyeongsang National University
Jinju, South Korea
Email: vishin@gnu.ac.kr

Seokhyoung Lee, Hyuksang Kwon
School of Information and Mechatronics
Gwangju Institute of Science and Technology
Gwangju, South Korea
Email: {lee-sh, hyuksang}@gist.ac.kr

Abstract — This paper focuses on a distributed image
fusion filtering algorithm and fusion formulas for time
delayed multiple pixels received from multiple sensors
(cameras). Since local cross-covariances between images
are important values to implement fusion formulas, we
present exact formulas for cross-covariances which are a
vital factor for calculating matrix weights in image
processing. Subsequent analysis of the proposed fusion
algorithm is presented through a typical example
demonstrating the effectiveness of the proposed fusion
algorithm.

However, in multisensory environment, the
implementation of the above filtering equations using the
augmented measurement vector is computationally
expensive, especially when the system dimension is high
and the delayed time is large. Thus, distributed filtering
process and the fusion of the local estimates are required
for saving computational resources. To achieve the
distributed fusion filtering, the specific architectures and
techniques for data fusion are discussed in [5, 6].
Furthermore the explicit formulas for finding the best
linear combination of the local estimates are developed
and presented in [7-9].

Keywords--- image processing, fusion filter, time-delay

I. INTRODUCTION

In the above fusion formulas, the cross-covariances
are important factors for estimation fusion. Regarding to
this fact, one trial carried out using covariance
information without time delays in [10]. Thus, this paper
provides exact equations for the local cross-covariances
with time delays. Therefore, the main purpose of this
paper is to propose a general fusion estimation algorithm
and to apply it to degraded images in the implementation.

Recently, estimation problems for an image and
signal processing or system control with uncertainties
have been investigated widely, and the Kalman filter is
well known as an optimal solution to the estimation
problem in a stochastic sense on linear systems having
uncertainties [1]. However, since the Kalman filter is
applicable only to linear systems without time-delays, it
is subsequence issue to solve estimation problems for
linear systems with time-delays.

This paper is organized as follows. In Section 2, the
problem is setting and the main goal is presented as a
general class of linear systems. In Section 3, a filtering
problem for one observation is considered, and the
specific filtering equations with time delays are given. In
Section 4, fusion filtering using matrix weighted fusion
formula is dealt with. The exact equations of local crosscovariances are presented. A typical example for an
image processing demonstrating the concrete accuracies
and effectiveness of the discussed fusion filtering are
presented in Section 5. Finally, a brief conclusion is
given in Section 6.

Regarding to this issue, as a typical problem,
integrations of time delay for images of moving scenes
or real-time transmitted images are an interesting issue.
In general, when the scene is moving or transmitted for a
long distance with respect to image sensors or
corresponding detectors, the resulting image is likely to
be blurred. To solve this problem, one approach via a
hardware design was discussed in [2].
To this end, as a software approach, the
development of an efficient image processing algorithm
for time-delayed (degraded) images is an attractive issue.
As a classical approach for optimal filtering of time
delay systems, several filtering equations were discussed
and derived for continuous or discrete time systems [3,
4].

978-0-7695-4484-7/11 $26.00 © 2011 IEEE
DOI 10.1109/CGIV.2011.24

II. PROBLEM STATEMENT FOR LINEAR SYSTEMS
The system with time-delays considered is described
by the state vector difference equation:
98

M

x( k +1) = ∑F( k − h) x( k − h) + w( k) , k = 0,1,...,

i =1,..., N, respectively. The details are given in the next
section.

(1)

h=0

where x ( k ) ∈\n is an unknown state, F( k ) ∈ \n×n is a
time-varying

transition

matrix,

III. FILTERING VIA ONE OBSERVATION

x( 0) ~ `( x0,P0 ) and

Let us consider the system (1) and a local sensor
(observation) (2), i.e., y(i) ( k) , where the index “ i ” is

w ( k ) ∈\ is a zero-mean white Gaussian noise with
n

fixed. Then, the local estimate can be represented by the
following filtering equations [4, 12]:

covariance Q( k) .

Next, N sensor models are given by
M

xˆ (i) ( k | k −1) = ∑F( k − h −1) xˆ (i) ( k − h −1| k −1),

Li

y(i) ( k) = ∑H(i) ( k−d) x( k−d) +v(i) ( k) , i =1,...,N,

(2)

xˆ (i) ( k| k) = xˆ (i) ( k| k −1) + G(i)
0 ( k) ×

d=0

y ( k) ∈\
(i)

where

mi

(i)

measurement, H
matrix, v

(i )

represents

( k) ∈\

(k) ∈ \

mi ×n

the

i-th

sensor

is the i-th measurement

(

xˆ (i) ( k − h | k) = xˆ (i) ( k − h | k −1) + G(i)
h ( k) ×

(

)

The main problem is to optimally estimate the
unknown state x( k) using all sensor measurements

{

}

(5)

Li
⎤
⎡ (i)
(i)
(i)
⎢y ( k) − ∑H ( k − d) xˆ ( k − d| k −1) ⎥ ,
d=0
⎦
⎣

)

noise with covariance R(i) ( k) , and cov w( k) , v(i) ( k) = 0
(i)
(j)
and cov v ( k) ,v ( k) = 0, i ≠ j.

(4)

Li
⎤
⎡ (i)
−
y
k
H(i) ( k −d) xˆ (i) ( k −d| k −1) ⎥ ,
(
)
∑
⎢
d=0
⎦
⎣

is a zero-mean white Gaussian

mi

(3)

h=0

where Gh ( k) , h = 0,1,...,M is a gain matrix, and formed
by
(i)

N

Y( k) = y(i) ( l) , l =1,...,k .

Li

G(i)h ( k) =∑P(ii) ( k−h,k−d|k−1) H(i) ( k−d) ×

i=1

Generally, there are two fusion estimation
approaches commonly used to process the measured data.
If a central processor directly receives all sensor
measurement data Y( k) and processes them in real time,
the corresponding result is known as the centralized
fusion filtering (CFF) [5, 11]. However, the CFF has
several drawbacks, such as heavy computational burdens
and requiring big memory sources, especially when
n, N  1 [11].
The second approach is called distributed fusion
filtering (DFF), in which every local sensor is attached to
a local processor. In this approach, the processor
estimates the state of a system based on its own
measurement y(i) ( k) , and then transmits its local

T

d=0

−1

⎤
⎡
(i)
(ii)
(i)T
(i)
⎢ ∑ H ( k−d1) P ( k−d,k
1 −d2 |k−1) H ( k −d2 ) +R ( k) ⎥ ,
⎦
⎣d1,d2=0
Li

(6)

where P(ii) ( k1,k2 | k) is an auto-covariance matrix, i.e.,

P(ii) ( k1,k 2 | k )  cov {x (i) ( k1 | k ) , x (i) ( k 2 | k )} ,
x (i) ( k1 | k )  x ( k ) − xˆ (i) ( k1 | k ) , k1,k2 ≤ k.

(7)

Moreover, the specific equation for P(ii) ( k1,k2 | k) ,

k1,k2 ≤ k and the time-update equations are given by

estimates xˆ (i) ( k| k) to the fusion centre. After that, the

fusion centre estimates the object based on received local
estimates.
Due to the drawbacks of the CFF, this paper focuses
on DFF for the system (1) and (2). Before presenting the
DFF, it is needed to explain how local estimates
xˆ (i) ( k| k) , i =1,...,N are obtained based on y(i) ( k) ,

P(ii) ( k − h1,k − h2 | k) = P(ii) ( k − h1,k − h2 | k −1)
Li

(i)
(ii)
− G(i)
h1 ( k) ∑H ( k − d) P ( k − d,k − h2 | k −1) ,
d=0

99

(8)

P(ij) ( k,k| k) = P(ij) ( k,k| k −1) −G0(i) ( k) S0(i) ( k)

M

P(ii) ( k−h,k+1|k) = ∑P(ii) ( k−h,k−h1 |k) FT ( k−h1),

(j)
(i)
(ij)
(j)
−S(j)
0 ( k) G0 ( k) + G0 ( k) T ( k) G0 ( k) ,
T

h1=0

P(ii) ( k+1,k+1|k) =

M

∑ F( k−h ) P( ) ( k−h ,k−h |k) F ( k−h )
ii

1

T

1

2

2

(9)

T

T

(12)

Li

(i)
(ij)
S(i)
m ( k) = ∑H ( k −d) P ( k −d,k −m| k −1),

h1,h2=0

d=0

+Q( k) .

Li

Lj

T(ij) ( k) = ∑∑H(i) ( k −di ) P(ij) ( k −di ,k −dj | k −1) H(j) ( k −dj ) ,
T

di =0dj =0

(ii)

where P

( h, j|0) = P0 , h, j = 0,−1,−2,...,M, M = max {M, Li } .

P(ij) ( k − hi ,k − hj | k) = P(ij) ( k −hi ,k − hj | k −1)
T

()
()
(i)
(j)
(j)
(ij)
−G(i)
hi ( k) Shj −Shi Ghj ( k) + Ghi ( k) T ( k) Ghj ( k) ,
T

Then, using the above filtering equations (3)-(9), we
have N local estimates xˆ (1) ( k| k) ,…, xˆ (N) ( k| k) and

T

M

i

j

(13)

P( ) ( k − h,k +1| k) = ∑P( ) ( k − h,k − d| k) FT ( k − d),
ij

corresponding error-covarinaces P(11) ( k,k|k) ,...,P(NN) ( k,k|k) .

ij

d=0

Based on these values, DFF is presented below.

P( ) ( k +1,k +1| k) =

M

ij

∑ F( k −d ) ×

(14)

1

d1,d2 =0

P( ) ( k − h,k − d2 | k) FT ( k − d2 ) + Q( k) .
ij

IV. DISTRIBUTED FUSION FILTERING
Considering N local estimates xˆ(1) ( k|k) ,...,xˆ( N) ( k| k)

and corresponding error-covariance P(11) ( k,k| k) ,…,

To reduce the computational burden of (12)-(14), an
approximation approach is presented in the next
subsection.

P(NN) ( k,k| k) , the distributed fusion estimate xˆ DFF ( k | k )
is determined using the following fusion formula with
matrix weights [7, 8]:

V. A SIMULATION EXAMPLE
N

ˆ (i)
xˆ DFF ( k | k ) = ∑C(i)
k x ( k | k ),
i=1

N

∑C

(i)
k

Let us consider a monochromatic image, 640 x 480
pixels and 256 grey levels. To apply the fusion filer to
this example, we consider only vertical pixels; that
means, 1 ≤ k ≤ 480 . Observations can be taken flexibly
by horizontal pixels as a neighbour [10]. Then, we
assume the following system model (image model):

(10)

= In ,

i=1

I n is an n×n identity matrix, C (i)
k , i = 1,..., N
are n ×n matrix weights defined as

where

−1
T −1
C k = ( D T Px,k
 D ) D Px ,k , D = [ I n ... I n ] ,
−1

T

x ( k +1) = 0.8x ( k) + 0.2x ( k −1) ,

(11)

y(1) ( k) = 0.9x ( k) + v(1) ( k) ,

⎡()
⎤ nN×nN ,
where Ck = ⎡C(k1) ...C(kN) ⎤∈\n×nN , Px,k
 = P ( k,k|k) ∈\
⎣
⎣
⎦
(ij)
( i)
( j)
P ( k,k| k) = cov x ( k| k) ,x ( k | k) ,

i ≠ j.

{

}

ij

(2)

y

⎦
i, j = 1,..., N ,

(15)

( k) = 0.6x ( k) + 0.4x ( k −1) + v ( k) ,
(2)

where x ( 0) ~ ` (172.34, 1838.73) can be obtained from
an original image,

(i)

In order to compute the matrix weights C k , the

v(i) ( k ) ~ ` ( 0,110) , i = 1,2 , are

observation noises.
Based on the model (15), we obtain 2 images below
as an observation.

local cross-covariances P(ij) ( k,k | k ) , i, j = 1,..., N , i ≠ j in
(11) are required. Subsequently, the specific equations
for the cross- covariance P(ij) ( k,k | k ) are given by

100

Figure 1: Image information from

y(1) ( k )

Figure 3: Resulting Image from Fusion Filter (CFF)

Figure 2: Image information from

y(2) ( k )

Figure 4: Resulting Image from Fusion Filter (DFF)

Figures 1 and 2 show the individual image
observations including image (transmission) noises.
Obviously, we can observe the image information from
y(2) ( k ) is highly degraded because of time delay.

2

PkCFF = E ⎡⎣ x ( k ) − xˆ CFF ( k | k ) ⎤⎦ ,

Using the image model (15), the fusion estimates
(pixels), xˆ CFF ( k | k ) and xˆ DFF ( k | k ) based on CFF and
DFF are obtained using computer computations,
respectively. Figures 3 and 4 show the fusion images
based on the fusion filters, CFF and DFF. As compared
with image observations (Fig. 1 and 2) and fused images
(Fig. 3 and 4), it is surely verified that Figures 3 and 4
are improved. However, there are difficulties to compare
specific performances between CFF and DFF via seeing
Figures 3 and 4.

DFF
k

P

(16)

2

= E ⎡⎣x ( k ) − xˆ DFF ( k | k ) ⎤⎦ .

In Figure 5, we observe that the MSE of CFF, PkCFF
is lower than PkDFF . This means, PkCFF is obviously more
accurate than PkDFF , since PkCFF uses all the image
information both 2 images without information loss.
However, since CFF requires big computational memory,
DFF can be sometimes useful and practical approach on
this kind of image processing problems. Therefore, we
conclude that CFF and DFF are helpful for time delayed
images or image observations, and DFF is more
applicable in real-time implementation.

For this reason, to compare the performances
(accuracies) of fusion estimates xˆ CFF ( k | k ) , xˆ DFF ( k | k ) ,
the corresponding two mean square errors (MSEs) are
considered, i.e.,

101

Figure 5: MSEs of

xˆ CFF ( k | k )

and

xˆ DFF ( k | k )

VI. CONCLUSIONS
In this paper, a distributed image fusion filtering
algorithm and fusion formulas for time delayed multiple
pixels received from multiple sensors (cameras) is
considered. Since local cross-covariances between
images are important values to implement fusion
formulas, we present exact formulas for crosscovariances which are a vital factor for calculating
matrix weights in image processing. Subsequent analysis
of the proposed fusion algorithm is presented using a
simulation example supporting the effectiveness of the
proposed fusion algorithm.

REFERENCES
[1]

C. K. Chui, and G. Chen, Kalman Filtering with Real-Time
Applications, Berlin: Springer-Verlag, 1987.

102

[2]

G. Lepage, J. Bogaerts, and G. Meynants, “Time-DelayIntegration Architectures in CMOS Image Sensors,” IEEE
Trans. Eletron Devices, vol. 56, no. 11, pp. 2524-2533, 2009.

[3]

H. Kwakernaak, “Optimal Filtering in Linear Systems with
Time Delays,” IEEE Trans. on Automatic Control, vol. 12, no.
2, pp. 169-173, 1967.

[4]

R. Priemer, and A. G. Vacroux, “Estimation in Linear Discrete
Systems with Multiple Time Delays,” IEEE Trans. on
Automatic Control, vol. 14, no. 4, pp. 384-387, 1969.

[5]

Y. Bar-Shalom, and X. R. Li, Multi-target Multi-sensor
Tracking: Principles and Techniques, Storrs: YBS Publishing,
1995.

[6]

X. R. Li, Y. M. Zhu, J. Wang et al., “Optimal Linear
Estimation Fusion - Part I: Unified Fusion Rules,” IEEE Trans.
on Information Theory, vol. 49, no. 9, pp. 2192-2208, 2003.

[7]

V. Shin, Y. Lee, and T. Choi, “Generalized Millman's Formula
and its Applications for Estimation Problems,” Signal
Processing, vol. 86, no. 2, pp. 257-266, 2006.

[8]

J. Zhou, Y. Zhu, Z. You et al., “An Efficient Algorithm for
Optimal Linear Estimation Fusion in Distributed Multisensor
Systems,” IEEE Trans. on Systems, Man, and Cybernetics, vol.
36, no. 5, pp. 1000-1009, 2006.

[9]

Y. M. Zhu, Multisensor Decision and Estimation Fusion,
Boston: Kluwer, 2002.

[10]

M. J. Garcia-Ligero, A. Hermoso-Carazo, and J. Linares-Perez,
“Derivation of Centralized and Distributed Filters using
Covariance Information,” Computational Statistics and Data
Analysis, vol. 55, no. 1, pp. 312-323, 2011.

[11]

A. G. O. Mutambara, Decentralized Estimation and Control for
Multisensor Systems, Boca Raton: CRC Press, 1998.

[12]

J. Mishra, and V. S. Rajamani, “Least-Squares State Estimation
in Time-Delay Systems with Colored Observation Noise: An
Innovation Approach,” IEEE Trans. on Automatic Control, vol.
20, no. 1, pp. 140-142, 1975.

