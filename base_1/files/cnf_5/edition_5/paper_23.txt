Locating the Optic Disc in Retinal Images
Mira Park, Jesse S. Jin, Suhuai Luo
School of Design, Communication and IT
University of Newcastle
{mira.park@newcastle.edu.au}
Abstract
We present a method to automatically outline the
optic disc in a retinal image. Our method for finding the
optic disc is based on the properties of the optic disc
using simple image processing algorithms which include
thresholding, detection of object roundness and circle
detection by Hough transformation. Our method is able
to recognize the retinal images with general properties
and the retinal images with variance of unusual
properties since the parameters of our method can be
flexibly changed by the unusual properties.
Keywords--- retinal image, optic disc, thresholding,
roundness, Hough Transformation

2. Related work
The problem of optic disc detection has rarely
received unique attention. It has been investigated as a
precursor for other issues, for example as identifying a
starting point for blood vessel segmentation [2,3]. It has
also been investigated as a general retinal image
segmentation, for instance into separate identifications of
arteries, veins, the nerve, the fovea, and lesions [3,8,9].
In this paper, we only focus on the optic disc.
There are three approaches to detect the optic disc as
follows:
•

1. Introduction
The optic nerve is one of the most important organs
in human retina. The central retinal artery and central
retinal vein emanate through the optic nerve, supplying
the upper layers of retina with blood. The optic nerve
also serves as the conduit for the flow of information
from the eye to the brain [1]. The portion of the optic
nerve that is visible in the retinal fundus is called the
optic disc. Therefore, detection of the optic disc (OD) is
an essential step in the automatic analysis of digital
colour fundus images.
Fundus imaging is a common clinical procedure
used to record an observation of the retina. In this paper
we describe a process to automatically locate the optic
disc in retinal images. Such a process could be used for
automating patient screening, eye orientation tracking,
image
sequence
registration,
and
automatic
measurements for treatment evaluation or diagnosis.
The optic disc appears towards the left or right side
of the images as a circular area, roughly one-sixth the
width of the image in diameter, brighter than the
surrounding area, as the convergent area of the blood
vessel network. In the image of a healthy retina, all these
properties (shape, colour, size, convergence) help
contribute to the identification of the disc. Therefore we
base our method of optic disc detection upon finding the
visible properties.

•

•

Geographic approach: This approach is mainly
based on the information provided by the vessel
structure, i.e., the fact that all retinal vessels
originate from the OD. In [12], an OD tracking
technique was developed for OCT (Optical Coherent
Tomography) images, using a tiered scheme based
on the Hough transform, eigenimage analysis and
geometrical analysis based on a vasculature model.
In [13], an original vessel segments fuzzy
convergence algorithm was proposed to identify the
position of the optic nerve image as the focal point
of the blood vessels network. In this approach, the
vessel information is most important than the
features of OD itself and the computational
complexity is very high.
Model based approach: This approach is based on a
model of the geometrical directional pattern of the
retinal vascular system, and implicitly embeds the
information on the OD position as the point of
convergence of all vessels. Niemeijer [15] used 100
images for modelling retina vessel structure and
Foracchia [14] used a representative subset of 20
images from the 81 test images. Therefore, the
performance of their methods is very much depends
on the models and the methods are not flexible
enough to manage unexpected images.
Image feature-based approach: This approach is
based on its specific round shape and relatively high
brightness, as compared to the rest of the fundus
image.
Kaupp
[6]
used
split-and-merge

Proceedings of the International Conference on Computer Graphics, Imaging and Visualisation (CGIV'06)
0-7695-2606-3/06 $20.00 © 2006

1

Input image
(22_training.tif)

2

5

Segment with initial T Fill the gaps between
the close neighbours

Mark the object with
R > 0.3

3

6

Segment with
updated T

Fill the gaps between
the close neighbours

4

Segment with
updated T

Hough Transform
with radius 30

R = 0.49

Hough Transform
with radius 40

7

Fill the gaps between
the close neighbours

Candidates of OD

Best candidate of OD

Figure 1. Detection of OD

segmentation,
followed
by feature
based
classification. The features used for classification
include region intensity and shape. A similar
approach was taken in [7], in which the
segmentation was accomplished using matched
spatial filters of bright and dark blobs. However, the
optic disc segmentation was not clearly mentioned
in both papers since their aims were the vessel
measurement. In [10], the nerve was detected using
the transform of gradient edges into a Hough space
describing circle. A similar method is described in
[11]. However, the image features of OD show a
large variance that makes the methods brittle,
particularly in the presence of retinal disease.
The characteristics of OD are still very attractive, so
we propose an OD detection method which only uses the
OD properties. We prevent to use vessel information for
reducing the complexity and we also obtain some useful
parameters from the input image for the managing of the
image feature variances.

3. Methods
This algorithm identifies the optic disc as the round
shape focal area with brightness. Our method first
searches for several areas with a high intensity variation
to localise OD and selects all rounded areas from the
several areas. It then estimates the OD-contour by
employing the Hough transform on the edges of the
rounded areas. The Hough transform detects number OD

candidates which are outlined by circles. Finally, the best
candidate, which has a higher intensity, is selected as OD
of the image. Our method detects the optic disc as a
circle consisting of an OD centre and a radius while
other methods produce only a point that can be used as
the OD centre (see Figure 1).

3.1. Repeated-threshold
One of the simplest and the powerful methods to
segment is through thresholding. It is useful in
discriminating objects from the background in many
classes of scenes. An image contains an object, which
has homogeneous grey level and a background with a
different grey level, usually possesses a bimodal
histogram. The image can be segmented into two
different regions by simple thresholding.
In its simplest form, thresholding is a point-based
operation that assigns the value of 0 or 1 to each pixel of
an image based on a comparison with some global
threshold value T.

­1, if f ( x, y ) ≥ T
f T ( x, y ) = ®
¯0, if f ( x, y ) < T
The central question in threshold segmentation is the
selection of a threshold value. This is typically done
interactively, based on a visual inspection of the result.
Our thresholding in this paper is dynamically chosen
from the input image. The threshold (T) is automatically
chosen by the following process

Proceedings of the International Conference on Computer Graphics, Imaging and Visualisation (CGIV'06)
0-7695-2606-3/06 $20.00 © 2006

1.

2.

3.
4.
5.

6.
7.

8.

9.

Select an initial estimate for T
The Otsu’s method[18] produces optimal 1st
and 2nd thresholding value in the range [0, 1]
values and the 1st thresholding value will just
threshold the whole eye ball part since we do
not mask the eye ball part from the background.
The most optic disc can be thresholded at (1st
value + 2nd value)/1.5, so our initial T is (1st
value + 2nd value)/1.5
Segment the image using T.
This produces two Groups: G1, pixels with
value  T and G2, with value <T
Take objects from G1
Remove all objects containing fewer than 30
pixels in G1
Fill the gaps between the close neighbours or
fill the holes in the objects
Only considers the graylevel pixel value, so it
can leave ‘gap’ or ‘holes’ in segmented objects
Compute an area (Ar) and roundness (Ro) (see
the next section) of each object.
Find at least one object which satisfy the
following conditions
(maximum_radius (100 pixels)2 × ʌ)  Ar
and Ar  (minimum_radius (20 pixels)2 × ʌ)
and Ro  0.3
If there is no such object, increase or decrease T
if (maximum_radius (100 pixels)2 × ʌ) < Ar
T = T+0.05
if Ar > (minimum_radius (20 pixels)2 × ʌ)
or Ro <0.3
T= T-0.05
Repeat steps 2 to 8 until T stabilises

3.2. Roundness Measurements
Measurement of roundness requires 360° traces of
the workpiece made with a turntable-type instrument or a
stylus-type instrument. A least squares fit of point on the
trace to a circle define the parameters of noncircularity of
the workpiece. A diagram of the measurement method is
shown in Figure 2.

P
ǻ

angle Ĭ-Į

Y R

A least squares circle fit to data at equally spaced
angles gives estimates of P-R, the noncircularity, where
R = radius of the circle and P=distance from the centre of
the circle to the trace [4].

3.3. Circle finding using Hough Transform
Our method referenced some code in [5]. We apply
the Hough transform on the detected rounded object
which obtained from the previous step. We implicitly
choose the radii of the optic disc candidates as 30 pixels
and 40 pixels. These radii can be flexibly changed when
the object is too big. For example, the distance (D) from
centre to closest boundary of the object is bigger than 50
pixels, the algorithm assigns D-10, D, D+10 pixels as a
radius, and if D is bigger than 100, the algorithm simply
assigns 90 and 100 pixels as a radius. The algorithm
filled the accumulator array corresponding to each of the
above radii, where each array composed of cells for the
(x,y) coordinates of the centre of the potential circle
(boundary of the disc). The default size of the cells was
chosen to be 4×4 pixels to function to find a circle
computes the transform. For each edge pixel, it first runs
through a sequence of x-values and computes the
corresponding y-values for that radius. It then runs
through a sequence of y-values and computes the
corresponding x-values for that radius. The sequence of
x-values varies from x(edge-pixel)-radius/cos(45)) to
x(edge-pixel)+(radius/cos(45)). The same is true for the
sequence of y-values. The two sequences are so
processed because as the points reach the x(y)-axis, we
get the same y(x)-values for different x(y)-values, for
points lying on the circle corresponding to the Hough
transform. This choice of sequences does not let any bias
to be introduced because of choice of an x or a y
sequence.
Once the Hough transform image for a particular
radius is computed, it is adjusted to lie between 0 and 1
and thresholded, so as to leave only those points with
high probability of being the centres. We mark a circle
with a threshold value of 0.67. The resulting point-sets
are then labelled with different regions. The centroids of
each region are considered as centres of the detected
optic discs. The output image is computed by drawing
circles with these points as centres and the matched
radius as the radius, and adding this to the input images.

3.4. The best candidate selection

Į (a,b)

0
Trace

LS circle

The circles are the optic disc candidates, and we
simply choose the highest average intensity since the
characteristic of optic disc is brighter than other areas.

Figure 2. The trace and Y, the distance form the spindle
centre to the angle.

Proceedings of the International Conference on Computer Graphics, Imaging and Visualisation (CGIV'06)
0-7695-2606-3/06 $20.00 © 2006

Figure 3. Examples of detected ODs

4. Results
A Matlab prototype implementing the described
method was realised. An evaluation of the proposed
procedure was performed using the public database
(www.isi.uu.nl/Reserch/Database) [17]. The database
includes 40 fundus images of the DRIVE data set (45°
field of view and 584×565 pixels. The DRIVE dataset
obtained from a diabetic retinopathy screening program
in The Netherlands. The dataset was composed of the 20

training images and the 20 test images, but we randomly
selected 5 images from the training set for training of our
algorithm and we tested our algorithm with 35 test
images. Our method runs took on average 4 seconds for
each image on a mid-size PC (1 MHz Intel Pentium IV
CPU and 1 GB RAM).
In this paper the performance of the OD detection
methods was evaluated based on the determined OD
location with regard to the manually segmented optic
disc. The segmented optic discs consisted of a
centerpoint and a radius (see Figure 3).

Proceedings of the International Conference on Computer Graphics, Imaging and Visualisation (CGIV'06)
0-7695-2606-3/06 $20.00 © 2006

The success rate was 90.25%. This was a remarkable
result since we only use the features of the optic disc,
and a method in [16] achieved 89% of correct
identification on the DRIVE dataset which is the same
dataset we have used in this paper.

Conclusions
We have presented a method to automatically
outline the optic disc in a retinal image. Our method for
finding the optic disc is based upon simple image
processing algorithms which include thresholding,
detection of object roundness and circle detection by
Hough transformation. Unlike model based method, our
method is able to recognize the retinal images with
general properties and the retinal images with variance of
unusual properties since the parameters of our method
can be flexibly changed by the unusual properties of
input images.
The computational complexity of Hough
transformation highly depends on the number of edge
pixels and the number of radii to be matched. The
number of edge pixels and the number of radii can be
significantly reduced by the technique of detecting round
objects only.

[11] Barrett S., Naess E. and Molvik T., Employing the
Hough Transform to locate the optic disk, Biomedical
Sciences Instrumentation, 37:81-86, 2001
[12] Koozekanani D., Boyer C., Roberts C. and Katz S.
Tracking the optic nerve in OCT video using dual
eigenspaces and an adaptive vascular distribution model,
IEEE Conf. Computer Vision and Pattern Recognition,
1:1934-1941, 2001
[13] Hoover A. and Goldbaum M., Locating the optic nerve in
a netinal image using the fuzzy convergence of the blood
vessels, IEEE Trans. Med. Imag, 22:951-958, 2003
[14] Foracchia M., Grisan E. and Ruggeri A., Detection of
vessel caliber irregularities in color retinal fundus images
by means of a matched filter response, IEEE Trains,
Med. Imag, 19:203-210, 2000
[15] Niemeijer M., Ginneken B. and Haar F., Automatic
detection of the optic disc, fovea and vascular arch in
digital color photographs of the retina, in Proceedings of
the British Machine Vision Conference, 109-118, 2005
[16] Niemeijer M., Ginneken B., Loog M. and Abramoff
M.D., Comparative study of retinal vessel segmentation
methods on a new publicly available database, SPIE
Medical Imaging, 5370:648-656, 2004
[17] http://www.isi.uu.nl/Research/Databases/DRIVE/
DRIVE: Digital Retinal Images for Vessel Extraction
[18] Otsu, N., "A Threshold Selection Method from GrayLevel Histograms," IEEE Transactions on Systems, Man,
and Cybernetics, Vol. 9, No. 1, 1979, pp. 62-66

References
[1]

Oyster C. The human Eye: Structure and Function,
Sinauer Associates Publishing, 1999
[2] Tamura S., Okamoto Y. and Yanashima K. ZeroCrossing Interval Correction in Tracking Eye-Dundus
Blood Vessels, in Pattern Recognition, 21(3):227-233,
1988
[3] Tolias Y. and Panas S. A Fuzzy Vessel Tracking
Algorithm for Retinal Images Based on Fuzzy
Clustering, IEEE Transaction on Medical Imaging,
17(2):263-273, 1998
[4] Reeve P. Charles, Calibration Designs for Roundness
Standards, NBSIR, 79-1758:21, 1979
[5] www.cc.gatech.edu/~kwatra/computer_vision/coins.html
[6] Kaupp A., Dolemeyer A., Wilzeck R. Schlosser R. Wolf
S. and Meyer-Ebrecht D., Measuring Morphological
Properties of the Human Retinal Vessel System Using a
Two-Stage Image Processing Approach, IEEE
international Conference on Image Processing, 431-435,
1994
[7] Goldbaum M., Moezzi S., Taylor A., and Chatterjee S.,
Boyd J., Hunter E. and Jain R., Automated Diagnosis and
Image Understanding with Object Extraction, Object
Classfication, and Inferencing in Retinal Iamges, IEEE
International Conference on Image Processing, 695-698,
1996
[8] Pinz A., Bernogger S., Datlinger P. and Kruger A.,
Mapping the Human Retina, IEEE Transactions on
Medical Imaging, 17(4):606-619, 1998
[9] Akita K. and Kuga H., A Computer Method of
Understanding Ocular Fundus Images, Pattern
Recognition, 15(6):431-443
[10] Tamura S., Okamoto Y. and Yanashima K., ZeroCrossing Internal Correction in Tracing Eye-Fundus
Blood Vessels, Pattern Recognition, 21(3):227-233, 1988

Proceedings of the International Conference on Computer Graphics, Imaging and Visualisation (CGIV'06)
0-7695-2606-3/06 $20.00 © 2006

