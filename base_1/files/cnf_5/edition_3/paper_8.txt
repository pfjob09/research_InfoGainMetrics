Fifth International Conference on Computer Graphics, Imaging and Visualization
Visualisation

A Stochastic ARG Matching Based Video Scene Search System with a Sketch
Query Interface
Naoto Nakamura, Shigeru Takano, and Yoshihiro Okada
Graduate School of Information Science and Electrical Engineering, Kyushu University,
744 Motooka, Nishi-ku, Fukuoka, 819-0395 JAPAN
{n-naka, takano, okada}@i.kyushu-u.ac.jp
algorithm, the system can find the user’s required video
scenes represented as ARGs accurately.
Figure 1 shows the configuration of our proposed
system. As the preprocessing, the system extracts keyframes, which mean scene-change (cut-change) frames,
from a video using a modified method of a chi-square
test [2] between the color distributions of two adjoining
frame images of the video. Since an ARG is a good
expression for representing the structural feature of
multimedia contents, each of the scene-change frame
images is segmented into several main-color regions and
furthermore decomposed into several layers, and an
ARG is constructed from the layers. The ARG is used as
the feature information of the scene. When you want to
search your required video scene, you make a sketch
image as your query. This sketch image is also
segmented and layerized to be represented as an ARG.
Sketch interface is intuitive and suitable for entering a
query of the video scene search. Hence, we implemented
a sketch interface for that. Finally the system measures
similarity between a query image and each scene-change
frame images of the video using a stochastic ARG
matching method, and then the system outputs video
scenes similar to the sketch query image. To achieve
good results, it is important to choose effective
combinations of feature values to be used as attributes of
ARGs in the ARG matching process. We describe what
kinds of features of a video scene are used as attributes
of vertices and edges of an ARG in the stochastic ARG
matching.

Abstract

This paper proposes a video scene search system with
a sketch query interface, whose search algorithm is
based on a stochastic ARG (Attributed Relational Graph)
matching. In this system, using the sketch query
interface, the user can enter a sketch image as his/her
query intuitively for searching scenes of a video. As its
preprocessing, the system divides a video into several
different scenes by extracting scene-change (cut-change)
frames using a kind of chi-square test between color
distributions of two adjoining frame images of the video.
For searching the user’s required scenes similar to
his/her entered sketch query image, the system
decomposes each of the scene-change frame images into
some layers and an ARG is constructed from the layers.
The ARG is used as the feature of the scene for the
similarity search. Each sketch image entered as a query
is also decomposed into layers and represented as an
ARG. Hence, the system finds scenes of the video similar
to the user’s sketch image entered as his/her query by a
stochastic ARG matching algorithm.
Keywords--- Video scene search, ARG, stochastic
ARG matching, chi-square test, sketch interface

1. Introduction
The hard disk video recording has become very
common recently and many video contents have already
been stored as digital media files on computers. In this
situation, we need any tool to efficiently and accurately
find required videos from so many files. When searching
a required video, usually we have to specify several
scenes (frame images) included in the video. So, in this
paper, we propose a video scene search system that
enables the user to find his/her required videos including
scenes similar to a sketch image entered as the query
using a sketch query interface. In our system, the user
can enter query scenes as sketch images intuitively, and
as our system employs a stochastic ARG (Attributed
Relational Graph) matching [8] as a video scene search

978-0-7695-3359-9/08 $25.00 © 2008 IEEE
DOI 10.1109/CGIV.2008.56

Figure 1 Configuration of video scene search
system

55

3. Scene-change frame extraction
For reducing computational cost, we extract
significant key-frames from a video that mean scenechange (cut-change) frames. Our system employs an
extraction method based on chi-square test proposed in
the paper [2]. In this method, the following evaluation
function based on chi-square test is used to calculate
similarity between two adjoining video frames:
{H c ( f 1 , j ) − H c ( f 2 , j )}2
H c ( f1 , j)
j=0
63

∑
Figure 2 Screen image of the system

(1)

where f 1 and f 2 are target video frames and H c ( f i , j )
is the histogram of numbers of pixels each belongs to j th color level in the frame f i . The actual calculation in
[2] is performed as follows: Each histogram of (1)
consists of 64 gray levels. Each of two adjoining video
frames is separated into 4 x 4 blocks and the evaluation
function (1) is applied to the 16 pairs of two
corresponding blocks of the two frames. The summation
of eight smaller values chosen from the 16 evaluation
function values is treated as the similarity between f 1
and f 2 . If this value is larger than a specific threshold
value, we consider that any scene change occurs between
f 1 and f 2 . According to [2], this method is not only
more accurate rather than other methods but also robust
against partial noise.
In our system, the segmentation of a scene-change
frame image for generating its ARG is performed using
H (hue) component of the HSV color system, and then
the calculation of the function (1) is also performed
concerning the H component instead of the gray color
levels. Each histogram of (1) consists of 64 levels of H
values, and H c ( f i , j ) is the histogram of numbers of

Figure 2 shows a screen image of the system.
“Sketch Dialog” is the input interface of the system. In
this dialog, the user sketches a query image using “Line”
or “Brush” and so on. “Video Window” shows focused
video scene and the user can operate this system using
“Operation Dialog”. After the user executes a search
operation, his/her required scenes will be shown in
“Thumbnail Dialog” as results of the search.
The remainder of this paper is organized as follows.
First of all, Sec. 2 describes related work. Sec. 3
explains details of the scene-change frame extraction
algorithm. We explain the stochastic ARG matching
method and the ARG construction process to generate an
ARG from a video frame image in Sec. 4 and Sec. 5,
respectively. Sec. 6 shows experimental results and
discusses about them. Finally we conclude the paper in
Sec. 7.

2. Related works
There have been many methods for the video scene
search so far. Sivic and Zisserman proposed a video
scene search method using local region descriptor to
represent objects in a video frame [6][7]. This local
region descriptor is invariant about the viewpoint. They
adopted a text retrieval technique for the video scene
search system using the concept of “visual words”.
For the contents-based multimedia data processing,
structural information of contents is very important and
Attributed Relational Graph (ARG) is often used to
represent it. Kim et al. put features of content in a node
of an ARG, and proposed a novel ARG matching method
[1]. In this method, they used two kinds of the nested
structure of earth mover’s distance (EMD), called the
inner EMD and outer EMD. This matching method has
robustness against noise.
Park et al. construct ARGs using line features of a
face image, and proposed a person authentication system
using them [5]. Papic et al. express an alphabet by a
certain ARG, and proposed a character recognition
system which is robust against changes of the cameraangle [4]. There are very few matching methods using a
stochastic matching method [8] to measure similarity
between local parts of ARGs.

pixels each belongs to j -th H value in the frame f i .
Since it is well-known that the H component of a video
frame is robust against the lighting condition, we can
obtain good performance as shown in Figure 3.
Obviously we can find several peaks of evaluation values
of video frames regarded as scene-change frames. Figure
4 also shows examples of scene-change frame extraction.

Figure 3 Evaluation values

56

G t is not similar to G s . The unary features of G s and
G t are denoted by Yi s , 1 < i < N , and Ykt , 1 < k < M ,

respectively, and the binary ones of G s and G t are
denoted by Yijs , 1 < i, j < N and Yklt , 1 < k , l < M
respectively.
We
define
two
vectors:
s
t
Y s = (Y1s ,...,YNs ,Y11s ,Y12s ,...YNN
) and Y t = (Y1t ,...,YMt ,Y11t ,Y12t ,...YMM
) . Let
s
t
s
p(Y | Y , H p = h) be the probability of transforming G
into G t . The similarity measure of G s and G t is defined
by

S (G s , G t ) =

p(Y t | Y s , H p = 1)
p(Y t | Y s , H p = 0)
t

.

s

To calculate the probability p(Y | Y , H p = h) , we
need two transformation processes: vertex copy process
(VCP) and attribute transformation process (ATP).

~t

t

In VCP, a copy G of G is made. The vertices of

~
G s are mapped into the vertices of G t only when
H p = 1 . We denote this mapping by X , referred to as
correspondence matrix, whose elements are 0 or 1 . Let
xik be an element of X . xik = 1 means that the i -th
~t
s
vertex of G is mapped into the k -th vertex of G . To
s
obtain a one-to-one correspondence between G and
~t
G , the constraints ∑ xik ≤ 1, ∑ xik ≤ 1 are
i

k

required:
ATP is a process that changes the attributes on the

~t

vertices of G into other attributes. An example of
VCP, ATP and X is shown in Figure 5.
Figure 4 Examples of scene-change frame
extraction

4. Stochastic ARG matching
Our system employs a stochastic ARG matching
method [8] to measure the similarity between two video
frame contents. We start with the definition of the ARG.
Figure 5 ARG Matching Process
Definition. An ARG is a triple G = (V , E, A) , where V is
the vertex set, E is the edge set, and A is the attribute
set that contains a unary attribute ai assigned to each

t

s

For the detail of calculation of p(Y | Y , H p = h) ,
see the paper [3] or [8].

vertex ni ∈ V and a binary attribute aij assigned to each
edge eij = (ni , n j ) ∈ E .

5. ARG construction

To define the similarity measure between two graphs
G s and G t , we introduce some notations. Let H p

As previously explained, our search system finds the
user required video scenes similar to a sketch image
entered as his/her query using the stochastic ARG
matching method. Scene-change frames of a video are
represented as ARGs and a sketch image entered as a

denote a binary random variable according to two
hypotheses: The hypothesis H p = 1 means that G t is
similar to G s , and the hypothesis H p = 0 implies that

57

user’s query is also represented as an ARG. In our
system, the construction method of ARG consists of
three steps, a segmentation step, a layerization step and a
construction step.
The segmentation step is carried out based on the
color information of a video frame. We use HSV
components of each pixel. The pixels which have a
smaller value of the S component than a certain threshold
value are regarded as achromatic color pixels, and
classified into “BLACK”, “GRAY”, and “WHITE”,
according to their V values. Other pixels are classified
into 5 representative colors, according to their H values.
In this step, each frame image is segmented into eight
color regions.
After the segmentation, the system decomposes the
already segmented image into several layers. We call this
step “layerization”. In this step, we adopt the concept of
degree of circle (DoC) used to determine which of any
two adjoining regions among segmented regions is the
upper. DoC of a region is calculated by the next
expression:

e = 4π

S
,
l2

Original image

Segmented image

0 ≤ e ≤ 1,

which S is the area size and l is the boundary length of
a region, respectively. DoC means the complexity of a
region. Using DoC, the system generates several layers
from an image by treating each segmented region of the
image as each different layer. Overview of layerization is
shown in Figure 6. Figure 7 also shows an example of
layerization.

Layers
Figure 7 Example of layerization
Here, you can obtain a graph by regarding segmented
regions as its vertices and the upper-lower relationships
as its edges like a tree, and if you assign feature values to
the corresponding region as its attributes, the graph
becomes a kind of an ARG like shown in Figure 8. This
is called “construction step”. For the detail of the above
ARG construction, see the paper [3].

(a) A is a candidate of lower layer, and B is a candidate
of upper layer. A’ is the union of the two candidates.
DoC of A’ is bigger than that of A. Then, there is an
upper-lower relationship between A and B. A is updated
to A’.
(b) DoC of A is bigger than that of A’. In this case,
there is not any relationships between A and B. A is not
updated to A’.

Figure 8 ARG construction

6. Experiments

Figure 6 Overview of layerization

We performed experiments of video scene search
using our proposed system. In the segmentation process,
we employed Red (H=0.0), Yellow (H=0.1), Green
(H=0.35), Blue (H=0.67) and Purple (H=0.84) as five

58

representative colors. Experimentally, we chose the H
component value, the area size, the center position, the
boundary length, the DoC value and the spread of a
segmented region as unary attributes, and the ratio
between two region area sizes as a binary attribute. The
spread of a region means the average distance among
pixels in the region from its center position. For learning
covariance matrices used for the stochastic ARG
matching, we used 100 attribute pairs obtained from 30
training images. The number of vertices of an ARG
represents the complexity of the corresponding image.
To reduce the computational cost, the system does not
compare a query ARG and each ARG in the database
when the difference of the two vertices numbers of them
exceeds a given threshold value. Similarly, the system
does not compare ARGs when the distance between the
two color histograms of them exceeds a given threshold
value. We used a 30 minutes (1 frame/sec.) video as a
sample, and extracted 299 scene-change frames from the
video using the extraction method described above.
As for evaluation of video scene search method, it is
difficult to make database, so general evaluation method
(recall, precision, and so on) does not exist. Hence, in
this paper, we only show several examples of scene
search. Examples of scene-change frames are shown in
Figure 9, and experimental results are shown in Figures
10, 11, 12 and 13. “Query” is a sketched image entered
by the user as his/her query. Each search time is shown
with the each figure. About these results, it is said that
our scene search system can find scenes having the
object structure similar to the query image. The
segmentation method we used has robustness against the
V component value change because of the property of
HSV color system, so our search system is robust against
the lighting condition of video frames.
Our search system needs huge calculation time
because it is well-know problem that the computational
cost of the stochastic ARG matching method is very
high. However, by employing one of the indexing
techniques, it is possible to reduce the search time. We
are implementing such an indexing technique.

…

…

…

…

…

…

…

…

…

…

…

…

Query

The 1st result

The 2nd result

The 3rd result

The 4th result

(Search time : 1.1 sec.)
Figure 10 Result 1

Query

The 1st result

The 2nd result

The 3rd result

The 4th result

(Search time : 2.7 sec.)

Figure 9 Examples of scene-change frames

Figure 11 Result 2

59

7. Conclusions
In this paper, we proposed a video scene search system
with a sketch query interface, whose search algorithm is
based on a stochastic ARG matching. In our system, the
user can enter query scenes as sketch images intuitively,
and as our system employs a stochastic ARG (Attributed
Relational Graph) matching as a video scene search
algorithm, the system can find the user’s required video
scenes represented as ARGs accurately. In this paper, we
also showed experimental results of the system. To
achieve good results using the stochastic ARG matching,
it is important to choose appropriate features as attributes
of an ARG. We indicated effective combinations of
features for video scene search system experimentally.
The proposed system needs huge computational cost
because a stochastic ARG matching needs large number
of calculations for probability distributions. Hence, as
feature works, we are supposed to improve the system
performance by employing any faster stochastic ARG
matching algorithm and any indexing technique.

Query

The 1st result

The 2nd result

The 3rd result

The 4th result

References
[1]

(Search time : 9.0 sec.)
Figure 12 Result 3

[2]

[3]

[4]

Query

[5]

[6]

The 1st result

The 2nd result
[7]

[8]

The 3rd result

The 4th result

(Search time : 1.0 sec.)
Figure 13 Result 4

60

Kim, D. H., Yum, I. D., Lee, S. U., “A New Attributed
Relational Graph Matching Algorithm Using the Nested
Structure of Earth Mover's Distance”, Proceedings of the
17th International Conference on Pattern Recognition
(ICPR 2004), Vol. 1, pp. 48-51, Aug. 2004.
Nagasaka, A. and Tanaka, Y., “Automatic Video
Indexing and Full Video Search for Object
Appearances”, Visual Database System II, pp. 113 – 127,
1992.
Nakamura, N., Takano, S., and Niijima, K., “Video
Scene Retrieval Based on The Layerization of Images
and The Matching of Layer-trees”, Proceedings of Image
and Vision Computing New Zealand 2005 (IVCNZ
2005), pp. 449-454, 2005.
Papic, V., Djurovic, Z. and Kovacevic, B., “OCR Based
on ARG Matching Algorithm”, Proceedings of The Sixth
World Congress on Intelligent Control and Automation
2006 (WCICA 2006), Vol.2, pp. 10445-10449, 2006.
Park, B., et al., “Face Recognition Using Face-ARG
Matching”, IEEE Transactions on Pattern Analysis and
Machine Intelligence, Vol. 27, No. 12, pp. 1982-1988,
December, 2005.
Sivic, J. and Zisserman, A., “Video Google: A Text
Retrieval Approach to Object Matching in Videos”,
Proceedings of the 9th IEEE international conference on
computer vision (ICCV 2003), pp. 1470-1477, 2003.
Sivic, J. and Zisserman, A., “Efficient Object Retrieval
from Videos”, Proceedings of the 12th European Signal
Processing Conference (EUSIPCO 04), pp. 1737-1740,
2004.
Zhang, D. and Chang, S., “Stochastic Attributed
Relational Graph Matching for Image Near-duplicate”,
Columbia University ADVENT Technical Report 2062004-6 Columbia University, 2004.

