2012 Ninth International Conference on Computer Graphics, Imaging and Visualization

Thai Font Type Recognition using SIFT
Pitchaya Jamjuntr, Natasha Dejdumrong
Department of Computer Engineering
King Mongkut’s University of Technology Thonburi
Bangkok, 10140, Thailand
{ pitchayajam@yahoo.com, natasha@cpe.kmutt.ac.th}
Abstract
That is used to check the matching with the MFU
template. They compared the similarity of those features
between the test character and the most frequently used
characters. Viles and Carlos [3] proposed the method
analyze the texture characteristics from document
images. They used the invariant moment technique to
extract the features from text images. It can identify the
text by applying standard statistical classifiers. The
results of this method can lower the number of operation.
The level of classification is average of 95% with noise
over the image. Cruz et al [4] proposed a new optical
font recognition to identify and classify font features.
They took the scanned document as an image which
contains several types of fonts. The identification does
not work on each letter. In this method, the features were
extracted by using fourth and third order moments. They
studied on the common-used fonts in Spanish are 8
types. Each font has four styles that become totally 32
fonts. They used statistical methods are used to identify
and classify font features and the accuracy rate of font
recognition is 100% with clean image. Zhu, et al. [5]
proposed a new texture analysis which identifies text as
texture. After blocks of text were created, they used
Gabor filtering technique to analyze textured images.
The method is test on 14,000 samples which contains 24
frequently used Chinese fonts (6 typefaces combined
with 4 styles) and 32 frequently used English fonts (8
typefaces combined with 4 types). The success
recognition rate is average 99.1%. This method is robust
on image with noise. Abuhaiba [6] proposed an
algorithm for a priori Arabic optical font recognition.
They used their method to recognize the fonts from some
common Arabic words. Generally, neighbor noncommon Arabic words were the same font on the same
textual material.They applied A decision tree to
recognize Arabic fonts by using 48 features. These were
extracted by using horizontal projections, Walsh
coefficients, invariant moments, and geometrical
attributes. They test on 36 fonts of Arabic. The overall
accuracy rate is 90.8% and 100% in some fonts. The
average time consuming was for recognitions process is
approximately 0.30 seconds. Borji, and Hamidi [7]
proposed a Persian font recognition by applied global
texture analysis. They used Gabor filter to identifying
the fonts on the text image by using Weighted Euclidean

This paper presents a Thai font type recognition on
Thai document by using Scale-invariant feature
transform (SIFT) . The features are extracted by Scaleinvariant feature transform (SIFT) that is widely used in
image processing. Sift is an algorithm for detecting local
features in order to find similar objects. Our system
contains ten fonts and ten text images in each font. We
use ten text images each font total one hundred images
for our experiment. Our results show accuracy for
97.37% for ten Thai fonts.
Keywords--- Scale-invariant feature transform ,
Font type recognition.

1. Introduction
In recent years, many researches have been done to
optical character recognition (OCR). As we can see
commercial software has been sold in many brands.
OCR is a part of the automatic document analysis.
However, Multi-fonts documents are more challenge to
be analyzed by automatic system because character is
different shape in different fonts. The font researches
have begun for over ten year so a few researches have
been done on optical font recognition (OFR). Optical
font recognition can be adapted in several ways in
document processing. Firstly we need to convert normal
document to vector format. The system need to recognize
character and font type in order to reconstruct document.
Another sample is to check an official document for
correct font.

2. Related work
There are several existing methods for font
recognition. A.W. Zramdini and R. Ingold [1] proposed
optical font recognition based on five features from
projection profile and used Bayesian classifier for
recognition process. The accuracy is between 89%-92%.
Lin et al [2] introduced a method that can identify font
types of the characters, the most frequently characters
and character and handwriting character on the
document. They used the density of black pixels in the
area of a character block, projection profile and the
modified skeleton template to extract Chinese features.
978-0-7695-4778-7/12 $26.00 © 2012 IEEE
DOI 10.1109/CGIV.2012.23

57

occured in some alphabet with some font face, such as
“ไฟสัญญาณ͇ in Tahoma.

Distance classifier and SVM classifier are for
classification process. The experiments were test on
seven frequently used Persian typefaces combined with
four styles (28 fonts). The results show the accuracy of
85% by using Weighted Euclidean Distance classifier
and 82% by using SVM classifier. R.Ramanathan et al
[8]
proposed a method for Optical Character
Recognition in English font. The method was based on
global texture analysis. They applied support vector
machines to identify various fonts. The Gabor filters
were used to extract the features from block of text
image.The experiment was tested on six English
fonts.The results of SVM classifier shows an average
accuracy of 93.54%.Khosravi and Kabir [9] applied
Sobel-Robel feature extraction for Arabic font
recognition. This method extracted the gradients in 16
directions from the document. This method is less time
consuming than Gabor filter extraction. The result shows
faster 50 time compare to Gabor filter extraction. The
accuracy of recognition rate is 94.14%. By ignoring
similar fonts, the accuracy increases to 96.5%.Moussa, et
al[10]. proposed a method for Arabic font recognition
that used global texture analysis. This method extracted
the feature by using fractal geometry, and the feature
extraction does not depend on the document contents.
They take the text image as a texture that techniques
BCD (box counting dimension) and DCD (dilation
counting dimension) were used to extract these features.
The average recognition rates are approximately 96.2%
by K nearest neighbor and 98% by radial basic function.
Experimental results are also included in the robustness
of the method against written size, skew, image
degradation and resolution.

“ไฟสัญญาณ͇
Notice that the lower-right part of ญ also consist
of the vowel “ ”, Making it more difficult to identify.

3.2. Scale-Invariant Feature Transform. (SIFT)
SIFT is an approach use to extract features of input
images with its key features, which are invariance to
scale, rotation, illumination and affine. The SIFT
algorithm consists of 4 major stages[12] :
Stage 1) Scale-space extrema detection : The first stage
starts with blurring the image with Gaussian function for
each octave. Each octave has different blur levels called
“scale”. For each blur level starting from the actual level
and gradually increase σ (scale parameter), resulting in
getting image more blur then repeat through each octave
, having size of the next octave be reduced by half.
Stage 2) Keypoint Localization : From the previous
stage, blurred images with different scale is generated.
This stage is divided into 3 mini-steps. The First step is
to have those blurred imagegs calculated Difference of
Gaussion (DoG) , or the difference of the blurred images
in order to reduce chance of generating keypoints. Those
keypoints may not distinct enough after scaling, that is
make it scale invariance. Step 2 is to find
extrema/minima based on the result of DoG images by
individually analysing through each pixel with its
nearest-neighbours on the current scale, and also the one
above and below it. And the last step is to filter the
obtained keypoints by removing low contrast features,
edges and corners using Harris Corner Detector to ensure
only useful keypoints are selected.

3.1 Thai font Type.
Unlike English , Thai font has its own challenge in
both OCR and OFR fields, this is not because only its
unique characteristics but also its complexity of usage.
The Font itself is categorized into Consonants, Vowels,
Tone Marks, and Special Symbols[11]. The sentence is
distributed into 4 levels in order to process.

Stage 3) Orientation Assignment : This stage is about
assigning an orientation to each filtered keypoint. First,
the calculation is required to obtain the magnitude and
orientation of each keypoints. Then a 36 bins-histogram
of orientation is formed to store the magnitude and
direction around the keypoint (each 10 degree). Any
histogram peak with its height above 80% of the highest
peak then split into a new keypoint which has the same
scale and location but it’s orientation is the same as the
other peak. This stage ensures rotation invariance.
Stage 4) Keypoint descriptor : This final stage is going to
generate a feature vector for each keypoint. First, a 16 x
16 window is created around the keypoint. each of the
small 4 x 4 windows is grouped into a big window. until
now, there are 4 x 4 big windows which each window
have a small 4 x 4 window in it. Gradient magnitudes
and orientations are calculated within each 4 x 4
windows and these orientations are stored into a
histogram.

Figure 1. Thai Alphabets
Moreover, when combining alphabets into a
sentence, there is some chance that overlapping may be

58

3.3. The proposed method
SIFT is now used in this proposed system because of
its robustness to scaling, rotation, illumination and affine
that makes SIFT has advantages over other OFR
methods. With SIFT, a recognition can be performed
correctly without pre-processing even the testing image's
attribute is difference from the database image.
SIFT algorithm is also fast enough to use in a large
database because SIFT use Difference of Gaussian,
which is an approximation method instead of Laplacian
of Gaussian, which is an actual calculation. Therefore
this process can cut down the major calculation time.

 Figure 4. illustrate samples of recognition under
the circumstance of different text, same font, different
size.

4. Experiment Result
A set of 100 text testing images and 100 database
text images is used to test the performance of the system.
The image set were arbitrarily adjusted to ensure the
system stability, including font weighting, rotation, and
font sizing
The result of the experiments shows that, if the
number of matched keypoints is more than the selected
threshold, that is 30, then it is a correct matched, which
means the font of two training images are similar. The
5000 tests are performed on 100 testing text images with
100 database text images of 10 system Thai fonts and
achieved a overall recognition rate of 97.37%.

Figure 5. illustrate samples of recognition under
the circumstance of different text, different font,
same size.Only 1 keypoint was matched.

Figure 5. illustrate samples of recognition under
the circumstances of different text, same font and same
size. Many keypoints were matched.

Figure 2. illustrate samples of recognition under
the circumstance of same text, same font, different size.

Figure 3. illustrate samples of recognition
under the circumstance of same text, same font, rotated
by 35 degree.

59

[6]

Thai Font Types

Recognition
Rate

Angsana New

97.26

Cordia New

96.18

Tahoma

97.22

Kodchiang UPC

97.65

Jasmine UPC

98.41

Dilenia UPC

97.48

Iris UPC

98.05

Lily UPC

97.32

Microsoft Sans Serif

96.55

Freesia UPC

97.65

Abuhaiba, Ibrahim , Arabic Font Recognition using Decision
Trees Built from Common Words, Journal of Computing and
Information Technology - CIT 13, 2005, 3, 211–223.
[7] A. Borji, and M. Hamidi, Support Vector Machine for Persian
Font Recognition, World Academy of Science, Engineering and
Technology 28, 2007.
[8] R. Ramanathan, K.P. Soman, L. Thaneshwaran, V. Viknesh, T.
Arunkumar, and P. Yuvaraj, "A Novel Technique for English
Font Recognition Using Support Vector Machines", in Proc.
ARTCOM, 2009, pp.766-769.
[9] Khosravi, H. and Kabir, E. Farsi font recognition based on SobelRoberts features. In Proceedings of Pattern Recognition Letters.
2010, 75-82.
[10] Sami Ben Moussa, Abderrazak Zahour, Abdellatif Benabdelhafid,
Adel M. Alimi,” New features using fractal multi-dimensions for
generalized Arabic font recognition,” Pattern Recognition
Letters,Volume 31 Issue 5, April, 2010.
[11] Chularat Tanprasert and Thaweesak Koanantakool, “Thai OCR :
A Neural Network Application”, IEEE ENCON - Digital Signal
Processing Applications, 1996.
[12] David G. Lowe, “Distinctive Image Features from Scale-Invariant
Keypoints”, International Journal of Computer Vision, 2004.

Table 1. shows recognition rate for each testing
font in percentage.

ŝ. Conclusions
In this paper, a SIFT algorithm is used to match
images. The results conclude that OFR using SIFT
algorithm can be robust to font weight, font size and
angle variance. The overall recognition rate obtained is
not 100% that is 97.37 %. This may cause from another
factor such as combination of the phrase.

References
[1]

[2]

[3]

[4]

[5]

A.W. Zramdini and R. Ingold, "Optical Font Recognition from
Projection Profiles", presented at Electronic Publishing, 1993,
pp.249-260.
Lin et al, Chinese text distinction and font identification by
recognizing most frequently used characters, Image and Vision
Computing,Volume 19, Issue 6, 15 April 2001, Pages 329-338.
Viles and Carlos, Font Recognition by Invariant Moments of
Global Textures, Very Low Bit-Rate Video-Coding 2005,
(VLBV05) International Workshop, 15-16 September 2005.
Cruz et al, High-order statistical texture analysis––font
recognition applied, Pattern Recognition Letters Volume 26, Issue
2, 15 January 2005, Pages 135-145.
Zhu et al, Font Recognition Based on Global Texture Analysis,
Graph Algorithms and Computer Vision Volume 23 , Issue 10
(October 2001) Pages: 1192 – 1200.

60

