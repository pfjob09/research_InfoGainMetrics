Development of an Immersive VR Display System for 3D Digital Art
Ryu, Chung-Ryul, Cho, Yoon-Ho, Chai, Young-Ho
Chung-Ang University
{ryu@daum.net, yhcho@cau.ac.k , yhchai@cau.ac.kr}

Abstract
In this paper, a new 3D digital art and an immersive
VR display system are presented. A 3D drawing interface
and a real time object modeling, which is using auto 3D
strokes, are implemented for 3D digital art. One 3D stroke
makes some part of the object in one movement. This 3D
modeling method has an advantage in representing
complex objects quickly. 2D mouse interface is not
appropriate for this kind of 3D stroke modeling task, so
3D virtual environment system with 3D wand interface is
realized in this study. And an infrared camera-tracking
device is used. Since the user viewpoint and wand are
tracked, the user can see different screen display at
various points of view and interact with objects directly.
Keywords--VR, Camera Tracking, 3D Digital Art

with a tracking device which tracks down the users
location, but for artists to work in the system or spectators
to interact with the work, wireless tracking is required for
free movement for the user and the space occupied by the
system must be ideal.

2. Research on 3D Digital Art
2.1. CavePainting
CavePainting[1](Figure 1) realized by CaveTM is a
system that allows drawing in 3D space with input tools
similar to real art tools such as 2D brushes and paint pots.
Not only engineers construct the system and utilize it but
also actual artists like Daniel Keefe used the CavePainting
system for creative work.

1. Introduction
Recently more attention is paid to digital art which is
combined with art and engineering. Digital art is art forms
such as sculpture, painting, installation art etc completed
through digital media. The biggest characteristic of digital
art is that the spectators do not just observe but really
cohere with the work. What is more, artists make work
together with the spectators. This kind of work is called
‘interactive art’. For this reason digital art is not for just a
few spectators but more for the masses and active
spectators. In other words the artist is no longer only a
producer but also a curator.
Among this form, 3D digital art combined with the
immerse VR display system stands out since it
simultaneously maximizes the users visual immersion and
can produce interactive action with the work in various
ways.
Projection type immerse VR display system has various
display devices and the display system is not solely used
by itself, but requires development of a combined system
needing related display tools according to the fitting
application program and equipment. Also all of the
currently used immerse VR display system is combined

Figure 1 Cave Painting

2.2 ConFIGURING the CAVE
ConFIGURING the CAVE[2] is a digital art work
realized in the CAVE, and is constructed by the subject of
body and outer space. In the center of the CAVE stands a
5 ft multi-joint wooden doll. Spectators can freely adjust
the wooden doll’s position, and this position is calibrated
by a mechanic tracking device. Every time a participant
adjusts the wooden doll’s position, the data is delivered to
the server and the visual of CAVE changes.

Proceedings of the International Conference on Computer Graphics, Imaging and Visualization (CGIV’04)
0-7695-2178-9/04 $20.00 © 2004 IEEE

2.3 Haptic Painting through 3D VR Brushes
This system allows the user to paint oil paintings on the
desktop using a haptic device (PHANToM)[3]. Using the
haptic device as a brush, the user can perceive a feeling
that the brush is touching the canvas, hence feel like
painting a real oil painting. Furthermore, painting through
a computer is convenient that modification is easier than
real painting. Through the palette on the monitor the user
can choose the size and shape of brush and paint color,
and also mix colors. But being realized on the desktop, a
weak point is that the immersion lacks a bit.

Figure 2 Window projection model

2.4 Hiding Spaces

sG 

Hiding Spaces[4] is a work that realizes the ambiguity
of an abstract painting on the 3D space of the CAVE. On
the screen of CAVE, 2D background and 3D object
coexists.
The movement of a user wearing position tracking 3D
glasses enables the user to continuously see new 3D
abstract paintings on his every step. The artist purposely
realizes this kind of ambiguous visual expression on
CAVE, and by connecting the user’s movement to the
visual, attempts to bring up the same interest as when
someone looks at an abstract painting.

3. Development of an Immersive VR Display
System for 3D Digital Art

y  

Figure 3 Stereo projection on dual screens
Figure 3 is a figure indicating the stereo visual range
projected on this system’s dual screen from an upper point
of view. By using window projection, even if the user’s
viewpoint changes the projected plane is fixed thus there
is no distortion on the visual located on the border of the
two screens. However, if we cannot locate the precise spot
for the left and right eye, the human viewpoint and
projection datum point’s location will differ resulting in
distortion of the screen border.

3.1 Development of a Dual Display System
By fixing the projection plane to a certain position and
changing the visual by adjusting the viewpoint nearer or
further, the Window Projection Model can project more
flexibly than the Camera Model. This method creates an
immersive VR display system navigation-like effect. The
core benefit of the Window Projection[5] is that the point
of view and placement of the projection plane is flexible.
For implementation, we need to use the glFrustum( )
projection function provided at OpenGL and have the
ability to find the 4 Clipping volume values for left, right,
bottom, and up according to the change of viewpoint.
Thus, if the user moves from the center of the screen
frame by the size of d, e, f (Figure 2), the screen
parameters can be evaluated as in equation (1).

§ (a − 2d ) (a + 2d ) (b − 2 f ) (b + 2 f ) ·
¨¨ −
¸¸
,−
,
,
© 2(c − e) 2(c − e) 2(c − e) 2(c − e) ¹

Figure 4 Passive stereo system [7]
By constructing a passive stereo system and using 2
LCD projectors as shown in Figure 4 allows us to use only
the visual of the gray colored sector. As the characteristic
of a projector, if a visual projected from 2 projectors are
not horizontal, it will not be projected in the exact same
shape on one screen. Thus, if we put Lens Separation as l,
Projector Distance as d, angle as ɂ , we are only using
(

(1)

d tan θ - l
) × 100(%)
d tan θ
of the projector’s resolution. In this case,

by using a projector that has lens shift functions, adjust the
upper projector’s projected visual down and the lower
projector’s projected visual up, and we now can use the
whole resolution of the projectors.

Proceedings of the International Conference on Computer Graphics, Imaging and Visualization (CGIV’04)
0-7695-2178-9/04 $20.00 © 2004 IEEE

Thus if we attach an infrared filter in front of the
camera lens, the camera can only sense infrared rays.
SONY XC-HR50 cameras were used in this system, and
can sense rays that range up to approximately 1000nm. If
we attach a filter that intercepts rays under 930nm, the
camera only senses rays ranging around 960nm as shown
in Figure 6.

Figure 5 Dual projection system
Figure 5 is a 3D plan of a Dual Display System
developed during this research. Using the rear screen used
in rear projection methods, the user can interact with the
visual on the screen without interference of the user and
projection visual. Using 4 lens shift function installed
LCD projectors to project the stereo visual we were able
to utilize the whole 100% visual of the upper and lower
projector. And for larger visuals shot from short distances
the short-focus lens are attached. The image is projected
on the screen by reflecting the projector’s visual through
an optical surface mirror, resulting in largely reduced
system occupation space.

3.2 Tracking System using Infrared Camera

Figure 7 Before (left) and after (right).‫ٻ‬
In the infrared tracking system, targets are reflection
markers. In the tracking range, clothes or other materials
also reflect a little amount of infrared rays, but the
reflection marker reflects the most. Thus, infrared light
coming from the infrared filtered camera is only brightly
reflected on the reflection marker as shown in Figure 7.
The center of the 2D markers calculated from each
camera can be converted to pl & pr of each camera’s
coordinate system by the camera’s internal parameters. If
pl & pr are the camera coordinates of a point P’ projected
on the image plane by each camera, using coordinates pl &
pr and expression (2) we can calculate the camera standard
coordinates of point P˅ [9].
apl − bRT pr + c( pl × RT pr ) = T

(2)

#

Figure 6 Principal of infrared filter [8]
In the immerse VR display system, for interaction of
the visual on the screen and user, the user’s 3D positioning
information is required. There are various kinds of
position tracking devices that can obtain a user’s
positioning information according to the method. Among
these devices, wireless camera tracking has been intensely
researched lately for the aspect that it enables free
movement to the user for it does not have a wire
connected to the sensors. In this research, we try to obtain
the user’s 3D information by utilizing 2 black & white
CCD cameras. Regular CCD cameras can sense not only
the visible ray range (400nm ~ 700nm) but also the
infrared ray range (over 700nm).

a, b, c are unknown constants, R is the camera’s
rotation matrix and T is the camera center’s movement
vector.
At this time, the camera calibration is not precise, so as
in Figure 8 vector l & vector r do not exactly meet at one
point. So P˅ , the central point of the minimal distance
between the two lines becomes the 3D coordination of the
marker.

Figure 8 3D position by triangulation

Proceedings of the International Conference on Computer Graphics, Imaging and Visualization (CGIV’04)
0-7695-2178-9/04 $20.00 © 2004 IEEE

Camera tracking is unable when the tracking object
goes out of range or when an object interferes between the
camera and the tracking object. But momentary
disappearance or interference of the marker can be
compensated to a certain amount by using marker location
estimation. For marker movement estimation, this research
uses change vector [10].
In the tracking system of our research, an algorithm
that verifies if the user is in tracking range and that
automatically sorts and initializes each markers location is
included. This system automatically initiates the marker’s
location whenever the user enters the tracking range or the
marker’s position is lost during tracking. There are 4
infrared reflection markers that can be tracked in the
tracking system. 2 are attached to the polarizing glasses
and 2 are attached to the wand. So, even if each marker’s
3D location can be calculated, an algorithm that can
distinguish where each marker is attached to is needed.
Distance between each marker is used for this distinction
[11]. The distance between the markers attached to the
polarizing glasses and wand are 17cm and 9.5cm
respectively as shown in Figure 9. Each marker’s 3D
location is calculated, and two markers having a distance
of 17cm are recognized as the ones attached to the
polarizing glasses and two having 9.5cm as attached to the
wand.
‫ٻ‬

The system features developed on this research are;
• Tracking Server : Pentium 2GHz, 512M, Oxygen
GVX1 Pro, Meteor-2/Multi Channel.
• 2 Display Computers : Pentium 2.4GHz, 512M,
ATI Radeon 9700 PRO.
• 3D Display : 4 SHARP XG-P20XDs, 4
Polarizing Glasses, REPOS Rear Screen/2 Optical
Surface Mirrors.
• 2 Infrared Cameras : G SONY XC-HR50,
Infrared Filter, Infrared LED, DC Power Source.
• Polarizing Glasses, Wand(Infrared Reflection
Marker Attached).
• Programming Language, Library : VC++ 6.0,
OpenGL, Matrox MIL-Lite 7.1.
‫ٻ‬

For position tracking using the camera, relative
distance between the cameras and a tracking object is
required according to tracking range, and the camera
should be positioned at a location where it can track the
object clearly without being interfered. The tracking
system realized in this research is installed on the upper
part of the dual display system. Figure 11 is the
combination of a display system and tracking system
developed in this research. The tracking server and display
server are connected by TCP/IP and the tracking data is
sent to the display server.
‫ٻ‬

Figure 9 Polarizing glasses and wand
Figure 10 shows the screen when a tracking program is
run on a tracking server. Each of the 4 tracked markers are
sorted and indicated as a square box. Since it calculates
the 3D location data at a rate of 30 times a second, it has
the ability of real-time tracking.
‫ٻ‬

Figure 11 Immersive VR display system
Figure 10 Tracking Images

Proceedings of the International Conference on Computer Graphics, Imaging and Visualization (CGIV’04)
0-7695-2178-9/04 $20.00 © 2004 IEEE

4. 3D Digital Art Realization (VISCAN)
4.1 Interface
VISCAN is a 3D digital art production tool
implemented using the immersive VR display system
developed in this research. VISCAN is a drawing tool
enabling 3D drawing, and unlike conventional 3D drawing
tools based on 2D, the user can draw 3D drawings directly
on 3D space and can observe the visual from different
angles by moving around. The wand is used as a brush and
indicator, and the wireless mouse is used as an input
device. VISCAN is not only designed for painting with the
brush but also voluminous 3D modeling.

In this research, various types of 3D strokes being
available broadened the selection range for expressing,
and also presented a speedy real-time object modeling
method. Generally 3D modeling took long processing time
since it had to realize each and every one of the polygons.
However, in this research one 3D stroke produces a part of
the object. The produced part is selected by the menu and
according to the part’s characteristics the expression
method of the stroke changes. This kind of expression is
produced by a combination of the user’s intention and the
automatic object characteristic expression.
‫ٻ‬

G

Figure 12 Initial display of VISCAN
Figure 12 shows VISCAN’s initial display. Resolution
is 2048*768, and the left 1024*768 range of display is
displayed on the left screen and the right 1024*768 range
of display on the right screen. The function menu for
selecting brushes or other functions is indicated by the
icons on the left side of Figure 12, and the palette menu
for selecting colors are on the right side. Each menu exists
in 3D space, so in order to select a menu the user must
touch the menu on the screen with the wand.

4.2 Drawing using 3D Polyhedron
In drawing using 3D polyhedron (Figure 13), user can
draw box, sphere, and cylinder shaped basic figures and
depth polygons and objects in bodies of revolution.
‫ٻ‬

Figure 14 Drawing by basic 3D strokes

.
Figure 15 Flower drawing by auto 3D strokes
This type of 3D modeling enables easy and fast
expression of objects with complicated shapes. 3D strokes
are divided by basic 3D strokes using brushes, color
pencils, and volume vectors etc (Figure 14) and auto 3D
strokes that express an object with complicated shapes in
one stroke (Figure 15).

Figure 13 Drawing by polyhedron
Figure 16 Auto 3D stroking process

4.3 Drawing using 3D Strokes
3D stroke is a 3D object that is produced by the wand
moving through 3D space. Traditional brush strokes were
expressed on 2D planes, but 3D strokes are capable
through the immersive VR display system.

For auto 3D strokes, the expression of the stroke differs
by the object being drawn while the user moves with the
wand. When the user wants to draw a flower, as shown in
Figure 16, the bud and the petal is automatically drawn as
the user draws the stem.

Proceedings of the International Conference on Computer Graphics, Imaging and Visualization (CGIV’04)
0-7695-2178-9/04 $20.00 © 2004 IEEE

Figure 17 Basic strokes vs. auto 3D strokes

immersion, and interaction between spectator and work.
As above, 3D digital art through immersive VR display
system is a new form of digital art having high
development potentials in this media and digital era.
Parts that should be researched further on afterwards
are, making it attractive enough for normal artists to
approach this kind of new media, and developing easy but
exquisite and various 3D stroke and brushwork methods in
order to fulfill message delivery intentions.

6. References
[1]

D. Keefe, D. Acevedo. "CavePainting: A Fully Immersive
3D Artistic Medium and Interactive Experience", Proc. of
the 2001 Symposium on Interactive 3D Graphics, pp. 8593, 2001.

[2]

A. Hegedues, B. Lintermann, "ConFIGURING the CAVE",
Collection of the NTT InterCommunication Center, Tokyo,
Japan, 1996.

[3]

B. Baxter, V. Scheib, V, M.C. Lin and D. Manocha.
"DAB: Interactive Haptic Painting with 3D Virtual
Brushes", Proc. of SIGGRAPH 2001, pp. 461–468, 2001.

[4]

Cynthia B. Rubin and Daniel Keefe. "Hiding spaces: A
cave of elusive immateriality", SIGGRAPH 2002
Conference Abstracts and Applications, pp. 192, 2002.

[5]

Nam Sang-Hoon, "Development of a immerse VR display
system supporting free placement of multi-screen ",
Chung-Ang University Masters Thesis, 2001.

[6]

M. Woo, J. Neider, T.Davis, "OpenGL Programming
Guide", Addison-Wesley Publishing Co. 1997.

[7]

J. Leigh, G. Dawe, J. Talandis, E. He, S. Venkataraman,
J .Ge, D. Sandin, and T. DeFanti, "Agave : Access Grid
Augmented Virtual Environment", Proc. of the Access
Grid Retreat, 2001.

[8]

K. Dorfmuller and H. Wirth, "Real-Time Hand and Head
Tracking for Virtual Environments Using Infrared
Beacons", Proceedings LNAI 1537, Heidelberg: Springer,
pp. 113-127, 1998.

[9]

Emanuele Trucco, Allessandro Verri, Introductory
Techniques for 3-D Computer Vision, Prentice-Hall, pp.
162-163, 1998.

Figure 18 Drawing by compound stroking
The user can select the shape of the bud and petal, and
the drawn direction is random, so expression is diverse
even when the same type of flower is selected. ‫ٻ‬
In case of plants and leaves, the user can draw each leaf
using the basic 3D stroke in brush form or just use the
auto 3D stroke to produce the object quickly. (Figure 17)
Figure 18 is a scenery drawing using auto 3D stroke on
VISCAN.

5. Conclusions
In this research, an immersive VR display system for
digital art is developed and 3D digital art examples are
implemented.
The display system was produced by the use of two
perpendicular screens that widens the user’s visible angle
and broadens the space the user interacts with the visual.
The camera tracking system using infrared rays tracks the
user’s viewpoint and wand’s 3D location at a rate of 30
times per second. Through the automatic location tracking
initialization process, the camera tracking system enables
continuous tracking when the user enters the tracking
range or when marker tracking fails. The user’s 3D
location data obtained from the tracking server is sent to
the 2 different display servers through TCP/IP, and each
display server produces a 3D visual for the left and right
eye respectively. The screen produces a visual apt to the
user’s viewpoint movement and the user interacts with the
screen’s visual using the wand.
Through the system developed in this research, 3D
digital art such as VISCAN was implemented. The system
was also able to satisfy the artist’s intention delivery,

[10] K. Dorfmuller, "Robust tracking for augmented reality
using retro reflective markers", Computers & Graphics,
vol. 23, no. 6, pp. 795-800, 1999.
[11] Trogemann, B. Graffmann, J. Piesk, "3D-Tracking: Image
Based Reconstruction of Camera Parameters for Mixed
Reality Postproduction", Proc. of the 98 European SMPTE
Conference on Imaging Media, Cologne, 1998.

Proceedings of the International Conference on Computer Graphics, Imaging and Visualization (CGIV’04)
0-7695-2178-9/04 $20.00 © 2004 IEEE

