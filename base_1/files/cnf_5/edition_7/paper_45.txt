A New Based-on-Artificial-Intelligence Framework for Behavioral Animation
of Virtual Actors
Andres Iglesias
Dep. of Applied Mathematics,
University of Cantabria, SPAIN
iglesias@unican.es

Abstract
The realistic animation of the behavior of virtual
actors emulating human beings has been a very
dynamic field of research during the last few years. A
major goal is to create a behavioral system for the
virtual actors so that they behave as realistic as
possible. Among the large number of different
techniques to solve this problem, those based on
Artificial Intelligence (AI) do represent a powerful
(but not well explored yet) approach. In this paper, we
present a new framework for behavioral animation of
virtual actors. The framework applies several
Artificial Intelligence techniques (neural networks,
expert systems, fuzzy logic, K-means) to build a
sophisticated behavioral system so that the actors can
take intelligent decisions by themselves. The paper
describes the general framework, its main components
and how these AI techniques have been effectively
applied to this purpose. Some programming issues,
the main steps of the simulation flow and some
illustrative examples are also analyzed in this paper.

1. Introduction
The realistic simulation and animation of the
behavior of virtual actors emulating human beings has
attracted much attention during the last few years [18,12-17]. Most of this interest has been motivated by
its remarkable applications to the entertainment
industry, specifically in movies and video games.
However, the range of potential applications also
includes Architecture, Science, advertising and others.
A major challenge in behavioral animation is the
construction of a framework able to integrate the
different techniques required for the realistic simulation
of virtual humans. Among them, we can include those
for perception, motion control, 3D rendering and
animation,
goal selection, action execution,
communication between actors, their interaction with

Francisco Luengo
Department of Computer Science,
University of Zulia, VENEZUELA
fluengo@cant.net

the environment, etc. The goal is to provide the virtual
actors with a high degree of autonomy, so that they can
evolve freely, with a minimal input from the animator.
In addition, this animation is expected to be realistic;
in other words, the virtual actors must behave
according to reality from the point of view of a human
observer.
A number of different approaches have been
proposed to fulfill the previous requirements [4,67,9,12-17]. However, while the quality of pictures has
been dramatically improved during the recent years,
relatively little effort has been placed upon the
simulation of the human cognitive processes (learning,
memory, recognition, etc.) By contrast, this is the
primary goal of the Artificial Intelligence (AI) field.
Because of that, some recent papers have proposed the
application of AI techniques to this purpose [7,9].
In this paper we propose a unified framework that
provides all features mentioned above. On one hand, it
allows animators to create a virtual world in which
virtual actors evolve autonomously in a very realistic
way. On the other hand, the framework incorporates
several AI techniques so that the virtual actors can
perform actions on the basis of intelligent decisions.
The structure of this paper is as follows: in Section
2 we describe the architecture of the framework and
some programming issues. The simulation flow is
described in detail in Section 3. Section 4 describes
briefly some illustrative examples available at Internet.
The main conclusions of this work close the paper.

2. Framework architecture
2.1. Graphical, physical and behavioral
systems
Due to its inherent complexity, it is convenient to
decompose the proposed framework into simpler
components, which can be rather assigned to one of the
following sytems (see Figure 1):

Proceedings of the International Conference on Computer Graphics, Imaging and Visualization (CGIV’04)
0-7695-2178-9/04 $20.00 © 2004 IEEE

• the graphical or renderer system: it accounts for
the rendering and animation of the three-dimensional
environment and its physical elements, their geometry,
motion and animation and possible interaction among
all objects and actors.
• the physical system: it comprises the physical
routines of the virtual actors (motion, perception, etc.)

• the behavioral system: it provides the actors with
emotions, feelings, thoughts, needs and beliefs (about
themselves, others or the environment). Depending on
their particular values, different plans will be designed
at this system in order to accomplish actors' goals.

Physical System

Renderer System

3D Environment
(7)

Motion
subsystem

Behavioral System
Internal States Subsystem

Goals Subsystem

(5)

(6)

Anxiety

Tiredness

(4)
Knowledge Motor

Sensors

Knowledge Updater

(1)

Perception
subsystem

(2)

Analyzer
subsystem

Open GL (GLUT)
Visual C++

Visual C++

VIRTUAL WORLD

Boredom

Knowledge
Buffer

Memory Area

(3)

Prolog (Amzi!)

Knowledge
Basis

Request Manager

VIRTUAL ACTOR

Figure 1. Scheme of a general framework for behavioral animation
In Figure 1 a dashed line is used to enclose those
modules associated specifically with the virtual actor.
From the figure it is clear that the graphical system
does not depend on the virtual actors, just as it
happens in reality. At their turn, each virtual actor is
comprised of the physical and the behavioral systems,
as shown in Figure 1. Reasons for this decomposition
become clear by simply realizing about our ability to
distinguish between what we are physically and
mentally: we can easily assign any physical object of
the 3D world (even our own body itself) to the
physical system, while our emotions, beliefs, feelings
or thoughts can be assigned to the behavioral system.
This separation is also extremely useful from a
computational point of view. On one hand, it allows
the programmer to focus on the specific module to deal
with at one time. Clearly, it makes no sense to worry
about the motion graphical routines when you are
modifying the behavioral ones, and vice versa. On the
other hand, specialized programming tools can be
independently applied to each module (see Section
2.2). In addition, each system can be broken up into
smaller subsystems, associated at its turn with more
specific routines. In particular, the physical system
includes the perception subsystem and the motion
subsystem, while the behavioral system includes the
analyzer, the knowledge motor, the internal states and
the goal subsystems.
An important consequence of this multilevel
organization is that performance of the framework is
drastically optimized. For instance, it is possible to

reuse the behavioral system for different virtual worlds.
This leads to the concept of adaptation: a realistic
simulation of a human being implies that such a
system must be able to perform adjustments by itself
in order to adapt to the changing environment.
Similarly, different behavioral systems can be applied
to the same virtual world. This leads to the concept of
individuality: no two virtual actors are exactly the
same as they have their own individual personality. In
computational terms, this means that each virtual actor
has his/her own behavioral system, which is different
than that of anybody else.

2.2. Programming issues
Regarding the implementation, the graphical tasks
for the renderer system have been performed by using
Open GL with GLUT (Open GL Utility Toolkit) for
the higher-level functions (windowing, menus, or
input) while we have used Microsoft Visual C++ v6.0
to assure the best performance. Another reason for this
choice is the excellent integration of Open GL with the
C++ layer. This combination has also been used for
the user interface, while Visual C++ has been the tool
chosen for the physical system as well.
By contrast, the behavioral system has been
implemented in Prolog. In particular, all routines have
been implemented in the programming environment
“Amzi! Prolog” (developed in C language). At our
experience, Amzi! Prolog is an excellent tool to
generate optimized code that can easily be invoked

Proceedings of the International Conference on Computer Graphics, Imaging and Visualization (CGIV’04)
0-7695-2178-9/04 $20.00 © 2004 IEEE

from C/C++ via Dynamic Link Libraries (DLLs),
providing an optimal communication between the
physical and the behavioral systems for standalone
applications. Furthermore, this choice provides a good
solution for TCP/IP communication protocols for
distributed environments.
The simulation framework described in this paper
can be implemented on a single CPU platform by
creating a dynamic list of classes associated with the
virtual actors. The communication between those
classes and the behavioral system is achieved via DLLs
to optimize the running speed. For virtual scenarios
containing a large number of actors and objects, the
alternative of distributed systems that associate each
processor with a particular actor (or groups of them)
could lead to a substantial saving of time. In this case,
the communication is performed via sockets and TPC/
IP connection. Note also that many AI techniques,
such as neural networks, are especially suited for
parallelization. Combination of parallel computing and
distributed environments provides the best rates for
efficiency in terms of computational requirements.

3. Simulation flow
In this section we analyze the simulation flow,
which is sketched in Figure 1. Basically, we classify
the tasks into four groups: environment recognition,
knowledge adquisition, goal definition and action
planning and execution.

3.1. Environment recognition
At the first step, a virtual world is generated and
the virtual actors are placed within. This virtual world
comprises two kinds of objects to interact with: static
objects and smart objects. By smart objects we mean
those objects whose shape, location and/or status can
be modified over time, as opposed to the static ones.
For example, a music box or a traffic light are smart
objects, simply because they might be turned on/off or
red/yellow/green, while a wall or a tree are static
objects. This concept, already used in previous
approaches [12,14] with a different meaning, has
shown to be extremely helpful to define the
interactions between the virtual actors and the objects.
In order to interact with the 3D world, the virtual
actors must identify the different world's elements,
regardless their nature (smart objects, static objects,
other actors) and properties (location, status, etc). To
this purpose, each virtual actor has a perception
subsystem that includes a set of individual sensors to
analyze the environment in order to capture relevant
information (step (1) of Figure 1). In other words, it
captures the geometry of the virtual world as it is
actually done by the human beings through their
senses, in which this perception subsystem is based

on. A virtual actor placed in any arbitrary position is
able to explore the environment and recognize the
different elements (either actors or objects) around.
This recognition includes the determination of
distances and positions of the different objects of the
scene, so that the actor can move in this environment,
avoid the obstacles, identify other virtual actors and
take decisions accordingly (the reader is referred to the
movies described in Section 4 for a better illustration
about the recognition and motion algorithms). Each
actor can see the objects placed just in front and
beside, but not the objects placed behind (although the
actor can eventually turn left/right and see the objects,
as any human being actually does). Further, each actor
has a predefined vision range (given by a distance
threshold value determined by the user during the
initialization step), and hence, objects far away from
the actor are considered to be visible only if the
distance from the actor to the object is less than such
threshold value; otherwise, the object becomes
invisible. Note that eagle eye, near-sighted or blind
individuals can easily be simulated in this scheme.
All this information is subsequently sent to the
analyzer subsystem (2), where it is processed by using
a representation scheme based on biological concepts
such as chromosome and gene. Each object of the 3D
world is represented by a chromosome, that is, a
collection of multi-component sequences that comprise
single fields called genes. Each sequence corresponds
to a certain characteristic of the object. The sequences
are sorted according to a hierarchical structure. In this
work, we consider that chromosomes are composed of
four sequences, from the most general to the most
specific one:
• the first sequence consists of three genes that
account for objects, animals and people,
• the second sequence, also with three genes, adds
more information about general characteristics, such as
the kind of object, animal or person. For example, the
category “person” is subsequently subdivided into
“kid”, “adult” and “elderly”,
• the third sequence consists of one gene and is
associated with the status, size or gender (for object,
animal or person, respectively),
• the last sequence comprises five genes to store the
object's ID, in order to identify any specific element
within its own class.
This representation has proven to be extremely
useful for identification. Given a pair of elements A
and B and a sequence j, there is a distance function to
determine how close these elements are. It is defined as
1/k |Ai j -Bi j|, where Ai j denotes the ith gene at
sequence j for the chromosome A. The sum applies for
all genes at such sequence j. This simple expression
provides a quite accurate procedure to classify objects
at a glance, by simply comparing them sequentially at
each depth level.

Proceedings of the International Conference on Computer Graphics, Imaging and Visualization (CGIV’04)
0-7695-2178-9/04 $20.00 © 2004 IEEE

3.2. Knowledge adquisition
Once new information is attained and processed by
the analyzer, it is sent to the knowledge motor (3).
This knowledge motor is actually the “brain” of our
system. Its main components are depicted in Figure 2.
KNOWLEDGE MOTOR
Knowledge Updater

Knowledge
Buffer

Memory Area
Knowledge
Base

Request Manager

Figure 2. Knowledge motor scheme
Firstly, the current information is temporarily
stored into the knowledge buffer, until new information is attained. At that time, previous information is
sent to the knowledge updater (KU), the new one
being stored into this knowledge buffer and so on.
This KU updates both the memory area and the
knowledge base.
The memory area is a neural network [10,11] that
will be applied to learn from data (in our problem, the
information received from the environment through the
perception subsystem). In this paper we consider the
unsupervised learning, in which the data is presented
to the network without any external information and
the network must discover by itself patterns, or
categories. In particular, we use an autoassociative
scheme, since the inputs themselves are used as
targets. In other words, the networks tries to learn the
identity function, which is a problem far to be trivial
as the network contains less neurons than the
input/output layers, and hence, the network must
perform dimensionality reduction. What the network
attempts is to subdivide the chromosome space into
clusters in order to associate each chromosome with a
specific neuron, the nearest one in our case. To this
end, we try to minimize the sum of the squared
within-groups residuals, which are basically the
distances of the chromosome locations to the
respective group centroids. When a new chromosome
is received as input, the whole structure is recomputed
and the group centroids are relocated accordingly.
This strategy can be performed by applying the Kmeans least-squares partitioning algorithm, a procedure

to divide a collection of n objects into K groups. The
basic algorithm consists of two main steps:
1. compute cluster centroids and use them as new
cluster seeds
2. assign each chromosome to the nearest centroid.
In our case, each neuron should receive the neuron
ID, the object's chromosome, the information to be
stored by the neuron, the time at which this
information is attained, and the learning rate. This last
parameter is introduced to describe the neuron's ability
to adapt to new information (and simultaneously, to
forget the previous one). Its meaning becomes clear by
simply noticing that, in our daily life, we can learn,
understand and remember certain things completely,
partially and sometimes not at all. In fact, certain
things can never be forgotten. This “unforgettable”
information is assigned to neurons whose learning rate
is set to 0 so that the information is permanently
stored. By this way we can deal with information that,
although extremely important, has been received only
once.
To update the memory area, we employ a K-means
procedure for competitive networks, which are formed
by an input and an output layer, connected by feed
forward connections. Each input pattern represents a
point in the configuration space (the space of inputs)
where we want to obtain classes. This type of
architecture is usually trained with a winner takes all
algorithm, so that only those weights associated with
the output neuron with largest value (the winner) are
updated. The procedure is based on the following
strategy: at the initial stage, all the neurons are
available to store new data. Therefore, the first k data
vectors are sequentially assigned to these neurons, i.e.,
data xi is learned by neuron i (1 i k). Simultaneously,
time for neuron i is initialized to the moment at which
data xi is learned. Once the next data xi+1 is received, it
is assigned to the neuron j such that d(xj , xk+1) d(xi ,
xk+1), i=1,...,k, i j. When this condition is satisfied
by several neurons simultaneously, the new data is
assigned to that storing the oldest information.
Interesting enough is the way in which the neuron
stores the new information: instead of replacing the old
data by the new one, what is actually stored is a
combination of both data. The basic idea behind this
formulation is to overcome the limitation of having
more data than neurons by allowing each neuron to
store more than one data at the same time.
The knowledge base is actually a based-on-rules
expert system, containing both facts and inference
rules. In addition to the information provided by the
updater, the facts include complex relationships among
the different elements (personal relationships, relative
positions, etc.) as well as personal information about
the actors, such as personal data, schedule, hobbies or
habits, in other words, about what we call actor's

Proceedings of the International Conference on Computer Graphics, Imaging and Visualization (CGIV’04)
0-7695-2178-9/04 $20.00 © 2004 IEEE

characteristic patterns. Additional subsystems for tasks
like learning, coherence control, action execution and
others have also been incorporated.
This deterministic expert system is then modified
through probabilistic rules: new data are used in order
to update the probability of a particular event. Thus,
the neuron does not exhibit a deterministic output but
a probabilistic one: what is actually computed is the
probability of a neuron to store a particular data at a
particular time. This probability is continuously updated in order to adapt our recalls to the most recent data.
This leads to the concept of reinforcement, based on
the fact that the repetition of a particular event over
time increases the probability to recall it. Of course,
some particular data are associated with high-relevance
events whose influence does not decrease over time. In
those cases, the neuron must be able to store this data
and maintain its probability over the time. The learning rate parameter introduced earlier is intended to
play this role.
Now, we can also modify this approach by
introducing a perturbation function. Fuzzy logic has
proved to be a natural scheme for this purpose.
Combination of this scheme and based-on-probability
expert systems constitutes a better approach to the
human recall process and, for this reason, it has been
incorporated into our scheme.
Finally, the request manager is the component
that, on the basis on the information received from the
previous modules, provides the information requested
by the goal definition subsystem described below.

3.3. Goal definition
The new information generated at the knowledge
motor is used to update actor's internal states (4). The
internal states subsystem stores information about
actor’s personality and his/her “emotional state” that
will determine, at its turn, actor's goals (5). The goal
subsystem is the component that updates, sorts and
finally stores actor's goals into a priority list. In
addition, the goal subsystem receives information from
the analyzer about those goals that cannot be attained
at a particular time. A typical case appears when an
actor is tired and looks for a seat to sit down but there
is not any seat available at that time. Thus, the
analyzer acts as a filter that modifies goals and
priorities according to current conditions.

3.4. Action planning and execution
Once the goals and priorities are defined, this
information is sent to the motion subsystem (6) to be
transformed into motion routines (just as the orders of
our brain are sent to our muscles) and then animated in
the virtual world (7). Currently, we have implemented
routines for path planning and obstacle avoidance. In

particular, we have employed a modification of the A*
path finding algorithm, based on the idea to prevent
path recalculation until a new obstacle is reached. If
such a new obstacle is dynamic (for instance, another
virtual actor walking), the actor waits until the path is
feasible again; otherwise, a new path is computed.
This simple procedure has yielded substantial savings
in time in all our experiments. In addition, sophisticated collision avoidance algorithms have been incorporated into this system (see the movies in Section 4).
Note that each actor knows nothing on the goals of
anyone else and, consequently, on the paths other
actors are going to follow. This represents a strong
difference with most video games, in which actors
behave and move according with patterns prescribed by
the animator exclusively.

4. Some illustrative examples
In this section some examples illustrating the
performance of our framework are briefly presented.
The examples are given by three different movies
available at the URL:
http://personales.unican.es/iglesias/CGIV2004/filename

where filename corresponds to the names of the movies
described below. In all the examples, we assume the
actors evolve in a virtual park, a carefully chosen
scenario that exhibits a lot of potential actor
interactions. We should remark, however, that the
human behavior is too much complex to be illustrated
here in all its generality and, therefore, we restrict
ourselves to a few behavioral features only.

4.1. The actors.mov movie
This movie is comprised of two parts associated
with the same scene as seen from two different viewpoints: aerial and on the surface. The scene involves
three virtual agents with different goals: Joan: 1. find a
bank 2. sit down 3. read a newspaper; Jenny: 1. find
someone 2. have a chat; Frank: 1. take a walk 2. find
an open place 3. make physical exercices.
The agents, randomly placed within the virtual
park, explore the environment and start to move: Joan
turns left towards the bank while Jenny goes towards
Joan in order to talk to her. Simultaneously, Frank is
taking a walk for a while and, after that, he looks for
an open environment (free of objects and people) in
order to make some physical exercices. Once Joan
reaches the bank, she sits down and reads the
newspaper. At that time, Jenny realizes Joan is likely
not willing to chat with her, so suddenly she decides
to look for another person to talk to, and she walks
around. Later on, she sees Frank and changes her way
in order to meet him, but Frank does not realize about
Jenny's wishes and keeps his search for an open place.
Once Jenny catches up with him, he turns left to be

Proceedings of the International Conference on Computer Graphics, Imaging and Visualization (CGIV’04)
0-7695-2178-9/04 $20.00 © 2004 IEEE

opposite one another and Jenny asks him for a chat.
However, he rejects the offering and they go away from
each other. Frank finds a nice place and starts his
exercices and Jenny looks for another actor to talk to.

4.2. The escape.mov movie
This movie illustrates the motion routines used in
this work, which are applied to two different escape
scenes. In both cases, a group of actors try to leave the
park escaping from a terrible storm: the actors avoid
obstacles and take into account both the paths of other
actors and the different trajectories towards the exit.

4.3. The competing.mov movie
One interesting situation appears when a group of
actors is competing in order to attain a particular goal.
This movie shows two different viewpoints of the
same scene: seven virtual actors are competing to sit
down on three banks (each used by only two people
simultaneously), thus forcing the actors to compete.

5. Conclusions
The core of this work is the realistic simulation of
human behavior by virtual actors living in a virtual 3D
world. The paper introduces a new framework whose
behavioral system includes several Artificial Intelligence techniques so that the actors can behave in an
intelligent and autonomous way. Instead of writting
scripts, we provide each actor with both the physical
and the behavioral systems, input some particular
values for each actor’s parameters and insert them
within the virtual world. As users, we are completely
unaware about what is actually going on. The only
data known “a priori” are actors’ goals, but it is even
unknown in advance whether or not the actors will
succeed in achieving them.

6. References
[1] Badler, N.I., B. Barsky and D. Zeltzer, Making Them
Move. Morgan Kaufmann, San Mateo, CA., 1991.
[2] Badler, N.I., C.B. Phillips and B.L. Webber, Simulating
Humans: Computer Graphics Animation and Control.
Oxford University Press, Oxford, 1993.
[3] B.M. Blumberg, and T.A. Galyean, “Multilevel
direction of autonomous creatures for real-time virtual
environments”. Proc. of SIGGRAPH'95, ACM, New York,
1995, pp. 47-54.
[4] R. Boulic, P. Becheiraz, L. Emering, and D. Thalmann,
“Integration of motion and control techniques for virtual
human and avatar real-time animation”. ACM Symposium

on Virtual Reality Software and Technology, ACM, New
York, 1997, pp. 111-118.
[5] E. Cerezo, A. Pina, and J.F. Seron, “Motion and behavioral modeling: state of art and new trends”. The Visual
Computer. Springer, Berlin, 1999, Vol. 15, pp. 124-146.
[6] N. Farenc, R. Boulic, and D. Thalmann, “An informed
environment dedicated to the simulation of virtual
humans in urban context”. Proc. of EUROGRAPHICS'99.
Computer Graphics Forum, 1999, pp. 309-318.
[7] J. Funge, X. Tu, and D. Terzopoulos, “Cognitive
modeling: knowledge, reasoning and planning for
intelligent characters”. Proc. of SIGGRAPH'99, ACM, New
York, 1999, pp. 29-38.
[8] J.P. Granieri, W. Becket, B.D. Reich, J. Crabtree, and N.I.
Badler, “Behavioral control for real-time simulated human
agents”. Symposium on Interactive 3D Graphics, ACM,
New York, 1995, pp. 173-180.
[9] R. Grzeszczuk, D. Terzopoulos, and G. Hinton,
“NeuroAnimator: fast neural network emulation and
control of physics-based models”. Proc. of SIGGRAPH'98,
ACM, New York, 1998, pp. 9-20.
[10] Haykin, S., Neural Networks. A Comprehensive Foundation. Macmillan Publishing, NJ., 1994.
[11] Hertz, J., A. Krogh and R.G. Palmer, Introduction t o
the Theory of Neural Computation. Addison Wesley,
Reading, MA., 1991.
[12] M. Kallmann, E. de Sevin, and D. Thalmann,
“Constructing Virtual Human Life Simulations”.
Deformable Avatars, Kluwer Pub., 2001, pp. 240-247.
[13] P. Maes, T. Darrell, B. Blumberg, and A. Pentland,
“The alive system: full-body interaction with autonomous agents”. Proc. of Computer Animation'95, IEEE
Computer Society Press, Menlo Park, CA, 1995, pp. 11-18.
[14] J.S. Monzani, A. Caicedo, and D. Thalmann,
“Integrating behavioral animation techniques”. Proc. o f
EUROGRAPHICS'2001, Computer Graphics Forum, 2001,
Vol. 20(3) pp. 309-318.
[15] A.S. Rao, and M.P. Georgeff, “Modeling rational
agents within a bdi-architecture”. Proc. of the Third Int.
Conference on Principles of Knowledge Representation
and Reasoning, Morgan Kaufmann, San Mateo. 1991.
[16] S. Raupp, and D. Thalmann, “Hierarchical Model for
Real Time Simulation of Virtual Human Crowds”, IEEE
Transactions on Visualization and Computer Graphics.
2001, Vol. 7(2) pp. 152-164.
[17] D. Thalmann, and J.S. Monzani: “Behavioural Animation of Virtual Humans: What Kind of Law and Rules?” Proc. Computer Animation 2002, IEEE Computer Society Press, Menlo Park, CA, 2002, pp. 154-163.

Proceedings of the International Conference on Computer Graphics, Imaging and Visualization (CGIV’04)
0-7695-2178-9/04 $20.00 © 2004 IEEE

