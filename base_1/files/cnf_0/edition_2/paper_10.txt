Dynamic Visualization of Transient Data Streams
Pak Chung Wong
PNNL
pak.wong@pnl.gov

Harlan Foote
PNNL
harlan.foote@pnl.gov

Dan Adams
PNNL
dan@pnl.gov

ABSTRACT
We introduce two dynamic visualization techniques using multidimensional scaling to analyze transient data streams such as
newswires and remote sensing imagery. While the time-sensitive
nature of these data streams requires immediate attention in many
applications, the unpredictable and unbounded characteristics of
this information can potentially overwhelm many scaling
algorithms that require a full re-computation for every update. We
present an adaptive visualization technique based on data
stratification to ingest stream information adaptively when influx
rate exceeds processing rate. We also describe an incremental
visualization technique based on data fusion to project new
information directly onto a visualization subspace spanned by the
singular vectors of the previously processed neighboring data. The
ultimate goal is to leverage the value of legacy and new
information and minimize re-processing of the entire dataset in full
resolution. We demonstrate these dynamic visualization results
using a newswire corpus and a remote sensing imagery sequence.
CR Categories: H.2.8 [Database Management]: Database
Applications—Data Mining; I.3.3 [Computer Graphics]:
Picture/Image Generation—Display algorithms; I.3.6 [Computer
Graphics]: Methodology and techniques—Interactive Techniques
Keywords: Dynamic Visualization, Text Visualization, Remote
Sensing Imagery, Transient Data Stream

1

INTRODUCTION

Advancements in telecommunications and high-speed networks
have recently created a new category of digital information known
as data streams [Babcock et al. 2002]. This time-varying
information has the unique characteristic of arriving continuously,
unpredictably, and unboundedly without any persistent patterns.
Data stream examples include newswires, Internet click streams,
network resource measurements, phone call records, and remote
sensing imagery. The increasing demands of immediate analyses
and actions on these transient data streams in many time-sensitive
applications such as Homeland Security have spawned a series of
investigations [Babu and Widom 2001; Cortes et al. 2000;
Domingos and Hulten 2000; O’Callaghan et al. 2002] to query,
mine, and model the information through non-traditional
approaches. This paper focuses on finding a visual-based solution
to the fast growing research area with demonstrations using text
and imagery streams.
Generally, visualizing transient data streams requires fusing a
large amount of previously analyzed information with a smaller
amount of new information. This new information is at least as

IEEE Symposium on Information Visualization 2003,
October 19-21, 2003, Seattle, Washington, USA
0-7803-8154-8/03/$17.00 ©2003 IEEE

Wendy Cowley
PNNL
wendy.cowley@pnl.gov

Jim Thomas
PNNL
jim.thomas@pnl.gov

important as its larger counterpart because the resultant
visualization is entirely dependent on the dataset and the user
parameters applied to it. Thus, the whole dataset must be
reprocessed in full resolution in order to capture the finest details.
In reality, this is a challenging task given the unbounded and
unpredictable nature of the streams.
Our first objective is to develop an adaptive visualization
technique that allows one to get the best understanding of the
transient data streams adaptively during critical moments when
influx rate exceeds processing rate. Our approach is built on the
concept of data stratification that intelligently reduces the data size
in exchange for substantial reduction of processing time. Although
we only use classical multidimensional scaling (MDS) [Cox and
Cox 1994] in our investigation, our adaptive technique will work
well with other scaling methods because we only modify the data,
not the scaling algorithms that process it.
Our second objective is to develop an incremental visualization
technique that allows one to project a certain amount of new
information incrementally onto an orthogonal subspace spanned by
the most important singular vectors of the previously processed
data. The design is based on a multiple sliding window concept that
uses dominant Eigenvectors obtained from a large data window to
accommodate the information from a smaller data window without
re-processing the entire dataset.
The primary visualization output of an MDS process is a lowdimensional scatterplot in which pairwise distances between any
points reflect the similarities of the items represented by the points.
Because a large part of our work is based on progressive
approximation and adaptation, error-tracking plays a vital role in
showing the viability of our work. We use both visual- and
computational-based means extensively to compare multiple
scatterplots simultaneously and report their discrepancies.
Our ultimate goal is to leverage the value of legacy and new
information and minimize re-processing the entire dataset in full
resolution. Our approach is to turn a prevailing and widespread
visualization tool (i.e., MDS), which was initially developed for
analyzing static data collections, into a dynamic data analysis tool
for transient data streams. This paper explains the motivations and
provides critical technologies to accomplish such a dynamic
analysis environment.

2

RELATED WORK

Although the study of data streams is relatively new to the
visualization community, it gradually has become one of the most
pressing and difficult data problems in today’s information
technology (IT) world. Recently, Babcock et al. [2002] presented
an overview paper that defines the topic, describes the background,
and introduces challenging issues of this young research area.
Among the hot research topics are dynamic query [Babu and
Widom 2001; O’ Callaghan et al. 2002] and data mining [Cortes et
al. 2000; Domingos and Hulten 2000] of the transient streams.
MDS has always been an important part of information
visualization studies. Wise et al. [1995] and Wise [1999] used
MDS to analyze large corpora. Bentley and Ward [1996] studied
the stress property of a class of MDS known as non-metric
multidimensional scaling [Cox and Cox 1994]. Wong and
Bergeron [1997] applied MDS in a high-dimensional brushing and
linking visualization environment. And more recently, Morrison et
al. [2002] reported a new MDS technique that algorithmically
outperforms all previous implementations. Many of these MDS-

Proceedings of the IEEE Symposium on Information Visualization 2003 (INFOVIS’03)
0-7695-2055-3/03 $ 17.00 © 2003 IEEE

based applications can potentially take advantage of our adaptive
technique and further improve performance.
This paper uses both text and imagery streams for
demonstrations. The text visualization community has largely been
influenced by two groundbreaking works: 1) Salton and McGill’s
Vector Space Model (VSM) [Salton and McGill 1983] that
represents the documents as numerical vectors, and 2) Deerwester
et al.’s Latent Semantic Indexing (LSI) [Deerwester et al. 1990]
that effectively projects the vectors into an Eigenspace based on a
classical MDS design. Many successful commercial text
visualization systems today—such as Aureka [2003] OmniViz
[2003], SPIRE [Wise 1999; Wise et al. 1995], Starlight [Risch et
al. 1997], and VxInsight [2003]—were developed based on these
two models.
In addition to document visualization, researchers use MDS to
analyze a large number of static images and query their features.
For example, Rodden et al. [1999] present a novel image
scatterplot without overlapping. Of particular note is that the prior
work presented here has assumed a static data collection, which is
very different from the dynamic data streams discussed in this
paper.

3

Document Corpus

The demo corpus has 3,298 news articles collected from open
sources during April 20-26, 1995. It has a strong theme associated
with the bombing of the U.S. Federal Building in Oklahoma, the
O.J. Simpson trial, and the French elections.
The first step in processing the corpus is to identify a set of
content-bearing words [Bookstein et al. 1998] from the documents.
Words separated by white spaces in a corpus are evaluated within
the context of the corpus to assess whether a word is interesting
enough to be a topic. The co-occurrence or lack of co-occurrence
of these words in documents is used to evaluate the strengths of the
words.
The second step is to construct the document vectors for the
corpus. A document vector, which is an array of real numbers,
contains the weighted strengths of the interesting words found in
the corresponding document. These vectors are normalized and the
result is a document matrix that represents the corpus. In our
example, a document vector contains 200 numbers. Because there
are 3,298 documents, the dimensions of the document matrix are
3,298×200. Details of our text engine can be found in [Wise 1999;
Wise et al. 1995].

3.2

169 spectral
bands

32x128

a

Figure 1: a) An illustration of the operation. b) A sketch of a
hyperspectral image set with 169 spectral bands ranging from
very short to very long bands. c) A color infrared (CIR)
imagery of the semi-desert area in Eastern Washington.

4

MULTIDIMENSIONAL SCALING

MDS is a prevailing technique used to visualize high-dimensional
datasets. There are a variety of proven MDS algorithms designed
for different analytical purposes. (Readers are directed to [Cox and
Cox 1994; MDS 2003] for a comprehensive overview.) Our
investigation focuses on a class of MDS known as classical scaling
[Cox and Cox 1994]. To show the flexibility of our design
approach, we also include an example in Section 6.3 using a leastsquares-based scaling technique known as Sammon Projection
[Sammon 1969].
Given a high-dimensional dataset (a set of similar data objects
represented by numerical vectors), MDS generates a lowdimensional configuration—like a 2-D scatterplot—such that the
pairwise distances between any points in the low-dimensional
space approximate the similarities between the vectors that
represent the points. For example, Figure 2 shows a scatterplot with
3,298 points (each point represents a document vector) generated
by a classical MDS process using the corpus described in Section
3.1. In this example, documents with similar themes are clustered
together as annotated.

O.J.
Simpson trial

Remote Sensing Imagery

The remote sensing imagery sequence used in our demonstration
was taken by an aircraft over the semi-desert area in Eastern
Washington. The aircraft was equipped with a hyperspectral sensor
that could take multiple images of the same locations
simultaneously in different spectral bands. Figure 1a illustrates the
basic concept of the scanning operation.
The processing of the remote imagery information is
straightforward. We want to extract features of the area by
analyzing the similarities of the image pixels from different
spectral bands. In our examples in Sections 6.4 and 8, the image in
each spectral band (or layer) has 32×128=4096 pixels, as illustrated
in Figure 1b. Figure 1c depicts a color infrared (CIR) image shot in
infrared band. A pixel vector, in this case, contains image
information of the same pixel position across the 169 spectral
bands. In other words, each pixel position establishes a pixel

b

c

DEMONSTRATION DATASET AND PRE-PROCESSING

We use a newswire corpus and a remote imagery sequence for
demonstrations. We describe the datasets and pre-processing steps
to generate the required vectors (which represent individual units)
and matrices (which represent the whole dataset) for MDS
analysis.

3.1

vector. Because there are 4,096 pixels in each image, the
dimensions of the pixel matrix are 4,096×169.

French
elections

Oklahoma
bombing

Figure 2: A document scatterplot generated by MDS.

5

ADAPTIVE VISUALIZATION USING STRATIFICATION

We present an adaptive visualization technique based on data
stratification to substantially reduce the processing time of the
streams and yet maintain the overall integrity of the MDS
visualization output. The data ingest scheme that supports the
technique is illustrated in Figure 3. If the primary data processing
route (the blue pipe) has overflowed, the data are re-directed to a

Proceedings of the IEEE Symposium on Information Visualization 2003 (INFOVIS’03)
0-7695-2055-3/03 $ 17.00 © 2003 IEEE

secondary one (the green pipe), which generates a coarser version
of visualization but at a much faster processing rate. And when the
green pipe has overflowed, too, the data go to the red one and so
on. The two data stratification strategies presented in this paper are
vector dimension reduction and vector sampling.

are shown in Figures 5b and 5c. Although the orientations and
spreads of the scatter points vary slightly in Figures 5b and 5c,
major features such as clustering and separation remain.

c
a
b
Figure 5: Scatterplots generated by MDS using document
vectors with sizes equal to a) 200, b) 100, and c) 50 terms.

Figure 3: An adaptive ingest scheme for stream visualization.

5.1

Vector Dimension Reduction

Our first stratification strategy is to cut down the dimensions of the
data vectors. The biggest challenge is to reduce the physical size of
the vectors but maintain most of their important contents. We
accomplish this by applying dyadic wavelets [Strang 1997; Mallat
1998] to decompose individual vectors (and thus compress them)
progressively. While the theory of wavelets is extensive, our
experiments show that the Haar wavelets perform well in all our
visualizations. Not surprisingly, the basic Haar also outperforms all
the other wavelet candidates in processing time, which is
considered a top priority for analyzing data streams [Gilbert et al.
2001].
Figure 4 shows an example of two consecutive wavelet
decompositions on a document vector randomly selected from the
demo corpus (described in Section 3.1.) Figure 4a is the original
vector with 200 terms. Figure 4b is the result of the first wavelet
decomposition with 100 terms. Figure 4c is the result of the second
wavelet decomposition with 50 terms. Because Haar belongs to the
dyadic wavelet family, one wavelet application will reduce the
vector dimension by 50%.

5.2

b
a
c
Figure 6: Scatterplots generated by MDS using a) 3298, b)
1649, and c) 824 document vectors.

a

b

c

The three visualizations in Figure 6 demonstrate that even
though we substantially reduce the number of vectors for the MDS
process, the shape or spread of the points remains more or less the
same. This phenomenon can be explained by the stability of the
two most important Eigenvectors generated by the highly related
document vectors. This property also lays the foundation of the
data fusion method discussed later in the paper.

6
Figure 4: a) A document vector with 200 terms. b) Result of
the first wavelet decomposition with 100 terms. c) Result of
the second decomposition with 50 terms.
While the example in Figure 4 shows the feature-preserving
property of wavelets on individual vectors, the next example
demonstrates the accuracy of the resultant vectors in generating
visualizations using MDS. We start with the same scatterplot
shown in Figure 2, which is generated using a full-resolution
matrix of the demo corpus. In order to give visual identities to the
scatter points, we apply a K-mean [Seber 1984] process to the 2D
scatterplot and subdivide the points into four clusters. Each cluster
receives a unique color (shown in Figure 5a as magenta, cyan,
grey, and yellow) for point identification throughout the discussion.
Using wavelets, we then progressively reduce the dimensions
of the document vectors from 200, to 100, and then to 50. Each
reduction is followed by an MDS process; the visualization results

Vector Sampling

Our second stratification strategy is to reduce the number of data
vectors based on sampling. We use a regular sampling technique to
obtain an even data distribution in our example. Other sampling
options such as a statistical-based distribution can also be applied.
We first repeat the initial two steps (i.e., generate scatterplot
using all 3,298 document vectors and assign color identities to each
scatter point) of the last example. Instead of reducing the
dimensions of the vectors, this time we progressively reduce the
number of document vectors by 50% every time using a regular
sampling method. Each sampling process is followed by another
MDS to project a scatterplot based on the sampled input. The
results are shown in Figure 6.

DATA STRATIFICATION OPTIONS AND RESULTS

In this section, we discuss the results of the two stratification
strategies and their impacts on the resultant visualizations. Our
discussion focuses on computation performance and the flexibility
in dealing with different data types and different scaling methods.

6.1

Scatterplot Matrix

To improve the visualization for comparison and evaluation, we
progressively combine the two approaches and concatenate their
results into a scatterplot matrix. The scatterplot matrix in Figure 7
shows the consequences of reducing document vectors (row)
versus reducing vector dimensions (column).
The results indicate that although the shape of the point
distribution changes to some extent, the overall integrity of the
visualizations such as clustering and separation remain intact. The
fact that the cluster borders remain clear and crisp in all nine matrix
panes indicates a very positive result of our approach. (We will revisit the fidelity issue in Section 7.)

Proceedings of the IEEE Symposium on Information Visualization 2003 (INFOVIS’03)
0-7695-2055-3/03 $ 17.00 © 2003 IEEE

squares of a continuous monotonic function. A particular strength
of a Sammon Projection over a classical MDS projection in
visualization is that the former usually has fewer overlapping
clusters due largely to its non-linear mapping approach.
Figure 8 shows a re-execution of Figure 7 using the Sammon
Projection technique. Although the visualization results look very
different from those in Figure 7, the impact on the stratification and
their results are very much like those in Figure 7. Most of the
scatter points are able to maintain their original positions and
orientations. The four point colors (red, green, blue, and orange),
which are assigned after a K-mean clustering process, clearly show
the integrity of the visualization after substantial dimension and
vector reductions.

Figure 7: A scatterplot-matrix demonstrates the impact of
reducing document vectors (row) versus reducing vector
dimensions (column) using classical scaling technique.

6.2

Computation Performance

Perhaps a more important goal of the stratification effort is to
substantially reduce the computation time of the MDS process.
While all our numerical programs are implemented locally using
C++ on a SUN Ultra 10, we choose to use a commercial package—
Mathematica 4.2 [Mathematica 2003] running on a Macintosh G4
with 1 GB memory—to report the computation performances. The
Eigenvalue function used in Mathematica is algorithmically
compatible to those championed by Netlib [2003].
Table 1 shows the benchmark results of our study. The top row
(in blue) shows the number of dimensions in the document vectors.
The left column (in green) shows the number of document vectors
included in the computation. The other nine cells are computation
time measured in wall clock seconds. The corresponding
scatterplot of each cell is shown in Figure 7.
Table 1: Execution times measured in wall clock seconds.
Vector Dimension
200
100
50
All (3268)
34.90s
9.50s
2.62s
Document
1/2 (1649)
14.80s
4.78s
1.52s
s
1/4 (824)
8.83s
2.58s
0.89s
The results in Table 1 show a 92.5% time reduction (from
34.9s to 2.62s) when we compress the vectors from 200 to 50
dimensions. The table further demonstrates a notable 97.5% time
reduction (from 34.9s to 0.89s) if we simultaneously reduce the
number of vectors from 3,298 to 824 in the computation.

6.3

Sammon Projection

So far we have focused only on the classical MDS [Cox and Cox
1994] in our investigation. To show the flexibility of our adaptive
visualization technique, we demonstrate a second scaling example
using a least-square MDS technique known as Sammon Projection
[Sammon 1969].
Classical MDS treats similarity between two vectors directly as
Euclidean distances whereas least-square MDS takes it as the least

Figure 8: A scatterplot matrix demonstrates the impact of
reducing document vectors (row) versus reducing vector
dimensions (column) using the Sammon Projection technique.

6.4

Remote Sensing Imagery

Our adaptive visualization technique can also be used to visualize
image streams such as hyperspectral remote sensing imagery. A
major motivation to include all spectral bands in the image analysis
is that subjects that appear identical in one spectral band (like
visible color) may be very different from each other if we look into
all possible spectral bands of the images. The goal of this example
is to show that we can apply the same stratification approaches to
analyze imagery streams.
Our next example uses the hyperspectral image set discussed in
Section 3.2. We first apply classical MDS to scaling the pixel
vectors followed by a K-mean process to assign unique colors to
eight scatter point clusters. We then stratify the vectors
progressively and generate the MDS visualization after each
reduction. Figure 9 shows the scatterplot matrix with results from
different degrees of stratifications.
In addition to the close proximity among the nine scatterplots
as shown in previous examples, this time we can use a different
approach to evaluate the accuracy of the results. If we map the
colors of individual pixels from Figure 9 back to Figure 1c, we
obtain the image shown in Figure 10. By comparing features in
Figure 1c to those in Figure 10, we see that all nine scatterplots
correctly identify different features of the original image and
separate them into different clusters.

Proceedings of the IEEE Symposium on Information Visualization 2003 (INFOVIS’03)
0-7695-2055-3/03 $ 17.00 © 2003 IEEE

We want to find a reliable computation method to evaluate the
similarity between two scatterplots so that we have a metric to
measure the fidelity of our approximations generated by
stratification and later our fusion technique. In statistics studies,
the class of techniques of matching two similar n-D configurations
and producing a measure of the match is commonly known as
Procrustes analysis [Cox and Cox 1997].

7.1

Figure 9: A scatterplot matrix demonstrates the effects of
reducing pixel vectors (row) versus reducing vector
dimensions (column) using remote sensing imagery.

Figure 10: Colors generated by the scatterplot clusters clearly
identify different features of the images shown in Figure 1c.

7

SCATTERPLOT SIMILARITY MATCHING

So far our discussion on scatterplot comparison has been based on
visual means. Visual-based comparisons are fast and convincing.
However, they need human attention and interpretation and thus
are not practical in some applications. Besides, visual-based
pairwise comparison is not always reliable if the scatterplots do not
reflect any visible patterns. For example, Figure 11 shows two
scatterplots filled with white noise. As we will reveal later, these
two scatterplots are very similar. But our eyes are fooled by the
lack of visible patterns that are required to register the images.

Procrustes Analysis

We implemented a Procrustes program that can match scatterplots
in any number of dimensions. We also assume that the one-to-one
correspondence information among the scatter points is known.
While the theory behind the analysis is beyond the scope of this
paper, we can comfortably summarize our implementation in four
basic steps. Given two 2-D scatterplots X and Y where X and Y are
(n u 2) matrices, the steps to match X to Y and report a measure of
the match are:
1. Translate the two scatterplots so that they both have their
centroids at the origin—by subtracting each point with its
mean coordinates of the scatterplot.
2. Rotate X to match Y by multiplying X with (XTYYTX)½
(YTX)-1 .
3. Dilate scatter points in X by multiplying each of them
with tr(XTYYTX)½/tr(XTX)T.
4. The matching index between X and Y =
1 – {tr(XTYYTX)½}2/{tr(XTX)tr(YTY)}.
The goal is to seek the isotropic dilation and the rigid
translation, reflection, and rotation required to match one
scatterplot with the other. The matching index calculated in Step 4
ranges from zero (best) to one (worst).
For example, we can match the scatterplot in Figure 11b to the
one in Figure 11a by a rotation of -36 degree (Step 2) followed by a
scaling of 2 (Step 3). The matching index (Step 4) of this
Procrustes analysis is 2.21008u10-30—which indicates the two
scatterplots are nearly identical.

7.2

Procrustes Analysis Results

Table 2 shows the results of Procrustes analyses that were carried
out on the corpus scatterplots in Figure 7. The very low index
values (from 0.016 to 0.14) in Table 2 indicate that all eight
scatterplots generated by stratified vectors are extremely similar to
the full resolution one using all 3,268 vectors with all 200
dimensions. These highly accurate results and the notable 97.5%
time reduction in generating one of them (reported in Table 1) are
strong evidence that the two demonstrated stratification approaches
are viable solutions in visualizing transient data streams.
Table 2: Matching indices between the eight document corpus
scatterplots and the original full resolution one shown in Figure 8.
All (3268)
1/2 (1649)
1/4 (824)

200
0.0 (SELF)
0.0162034
0.0329420

100
0.0224058
0.0513420
0.0620215

50
0.0841326
0.1114290
0.1417580

To further support our argument, we provide the matching
results of the remote sensing imagery scatterplots shown in Figure
9 in Table 3. The matching indices listed in Table 3 are even lower
than those listed in Table 2. Even the worst case (1/4 dimension,
1/4 vectors) accomplishes an identical matching index up to four
significant figures.
Table 3: Matching indices between the eight remote sensing imagery scatterplots and the full resolution one shown in Figure 10.

a

b

Figure 11: Two scatterplots filled with white noise.

Proceedings of the IEEE Symposium on Information Visualization 2003 (INFOVIS’03)
0-7695-2055-3/03 $ 17.00 © 2003 IEEE

All (4096)
1/2 (2048)
1/4 (1024)

169
0.0 (SELF)
0.000000279
0.000004299

84
0.000004106
0.000004136
0.000007314

42
0.0000565361
0.0000567618
0.0000577721

8

INCREMENTAL VISUALIZATION USING FUSION

Our first visualization technique focuses primarily on the use of
stratified vectors, which substitute the full-resolution ones to
generate fast and accurate MDS scatterplots. The stratification
effort alone, however, does not eliminate the requirement to reprocess the entire dataset whenever new items arrive. Our next
visualization technique, which is developed based on a data-fusion
concept, addresses the re-processing issue by projecting new items
directly onto an existing visualization without frequently reprocessing the entire dataset.

8.1

Robust Eigenvectors

In Section 5.2, we observed that the visualization subspaces
spanned by the two dominant Eigenvectors of our demo datasets
are extremely resilient for changes. All the follow-on examples
shown in Figures 6 to 9 indicate only minor distortions even after a
substantial amount of the input data is removed.
To further explore this characteristic, we use the hyperspectral
imagery (see Section 3.2 and Figure 1c) to study the similarity
between the Eigenvectors (and the corresponding scatterplots)
generated from local regions versus the entire dataset. To provide
identities to individual pixels, we use the image representation
shown in Figure 10 to represent the hyperspectral imagery instead
of the one in Figure 1c throughout this discussion.
Our first step is to generate a MDS scatterplot (Figure 12a)
using the pixel vectors from the entire hyperspectral imagery. We
then select and crop three smaller regions and generate three MDS
plots (Figures 12b to 12d) using only the pixel vectors from the
corresponding regions. These local regions are selected because
they contain diverse image features (i.e., purple, pink, and blue on
left; yellow, green, and red on right; and a mixture of everything in
the middle) as reflected by the pixel colors.
Our next step is to generate three more scatterplots (Figures
12e to 12g) using the corresponding pixel vectors found in Figures
12b to 12d. This time we use the Eigenvectors computed from the

entire hyperspectral imagery (instead of the local cropped
windows) to construct all three scatterplots. This can be done by
reusing the coordinates of the selected scatterpoints from Figure
12a, which is constructed using Eigenvectors from the entire
imagery. In other words, Figures 12b and 12e are generated using
same pixel vectors, as are Figures 12c and 12f and Figures 12d and
12g. However, Figures 12b to 12d use local Eigenvectors of the
cropped regions whereas the ones in Figures 12e to 12g use global
Eigenvectors of the entire imagery.
The resultant scatterplots in Figures 12b to 12g show that the
three corresponding pairs (i.e., Figures 12b and 12e, Figures 12c
and 12f, and Figures 12d and 12g) closely resemble each other.
This visual-based conclusion is consistent with the near zero
Procrustes matching indices shown in Table 4, which imply a close
similarity among the pairs.
Table 4: Procrustes matching indices of the three scatterplot pairs
shown in Figure 12.
Figures
Matching Index

12b vs. 12e
0.000718745

12c vs. 12f
0.0000381942

12d vs.12g
0.000683066

Because the first Eigenvector is the line though the centroid of
the scatter points along which the variance of the projections is
greatest (not necessarily the direction of the greatest ranges or
extent of the data) and the second Eigenvector is orthogonal to the
first one, these Eigenvectors tend to be very robust for changes
unless a substantial amount of disparate information is added. This
remarkable property becomes the foundation of our next
visualization technique on data streams.

8.2

Multiple Sliding Windows

Figure 13 illustrates an overview of our incremental visualization
technique using multiple sliding windows. After the Eigenvectors
of a long (blue) window are determined and a 2-D scatterplot is
generated, newly arrived individual vectors from the short (red)
window are projected directly onto the visualization subspace by
MDS
a

Crop

Crop

Crop
Extract points
from cropped
areas only

MDS

MDS

MDS

b

c
d
e
f
g
Figure 12: Scatterplot a) (top right) is generated from the demo imagery (top left). Scatterplots b) to d) (bottom left) are generated
from the corresponding cropped areas. Scatterplots e) to g) are generated by extracting the scatter points from a) that are found in
the corresponding cropping windows which generate scatterplots b) to d).

Proceedings of the IEEE Symposium on Information Visualization 2003 (INFOVIS’03)
0-7695-2055-3/03 $ 17.00 © 2003 IEEE

simply computing the dot-products between the incoming data
vectors with the Eigenvectors of the long window. So instead of
repeatedly processing the rather expensive (O(n3)) classical MDS
function or even the faster (O(nn)) version [Morrison et al. 2002]
whenever new information arrives, one can now obtain an almost
instant visualization update by carrying out a simple (O(m), m =
vector dimension, m << n) dot-product operation to determine the
point location of the new information in the scatterplot.
Sliding Direction
Short Window

Long Window
Data Stream

Table 5: Procrustes matching indices of the three scatterplots
shown in Figure 14
Figures
Matching Index

9

New vectors are
projected using the
Eigenvectors of the
long window

Figure 13: An illustration of our multiple sliding window
design in visualizing data streams.
We use the same hyperspectral imagery to demonstrate the
concept of our visualization technique. Figure 14a shows an ideal
case when 100% of the pixel vectors are used to generate the
scatterplot by MDS. In Figure 14b, only 75% of the pixel vectors
are projected onto the scatterplot by MDS. The other 25% are
projected by a dot-product function using the Eigenvectors of the
first 75%. Finally, only 50% of the pixel vectors are projected by
MDS. The other 50% are projected according to the Eigenvectors
of the first 50%.
While the scatterplots in Figures 14b to 14c look similar to the
full resolution one in Figure 14a, the low Procrustes indices in
Table 5 confirm that the three scatterplots are indeed close to each
other. These near-zero matching indices also validate our argument
that we can obtain a fast and accurate overview of the entire dataset
without the requirement of re-processing the entire dataset.

14a vs. 14c
0.00233882

COMBINED VISUALIZATION TECHNIQUE

Although the two visualization techniques presented in this paper
are intended to operate independently, we can combine them
together and get the best of both worlds. The newly combined
technique is capable of processing both individual items one at a
time (by data fusion) and large amounts of items all together (by
data stratification) efficiently and effectively.

9.1
Eigenvectors
determined by
the long window

14a vs. 14b
0.00123405

Error-Tracking Optimization

We have used Procrustes analysis as the primary computational
method to evaluate the errors between a full-resolution standard
scatterplot (e.g., Figure 14a) and ones based on multiple sliding
windows approach (Figures 14b and 14c.) A noticeable
enhancement to speed up the error-tracking process (and thus the
visualization process) is to replace the full-resolution standard
scatterplot with a fast and accurate substitute like the one using
stratified vectors as presented in Section 5.1.
The results in Table 1 show that we can save up to 92% of
computation time (from 34.9s to 2.62s) if we compress the
dimensions of 3,268 vectors by 75%. And the results in Table 3
show that a 75% reduced data matrix (dimension reduced from 169
to 42) can still be as accurate as the full resolution one. Because of
this faster error checking process, we can now afford to carry out
error estimation more frequently and thus improve the overall
quality of the analysis.

9.2

Dynamic Visualization Steps

Although the pre-processing steps of different data streams may
vary, we can summarize the operations of the combined
visualization technique in six major steps as follows:
1. When influx rate < processing rate, use MDS to reprocess the entire dataset when new information arrives.
2. When influx rate > processing rate, halt the MDS
process.

100%
MDS
a

75%

25%
Dot
Product

MDS
b

50%

c

50%
MDS

Dot
Product

Figure 14: a) The Eigenvectors of the scatterplot are computed using 100% of the pixel vectors. b) The Eigenvectors of the
scatterplot are computed from 75% of the pixel vectors. The other 25% are projected onto the scatterplot by dot-product. c) The
Eigenvectors of the scatterplot are computed from 50% of the pixel vectors. The other 50% are projected by dot-product.

Proceedings of the IEEE Symposium on Information Visualization 2003 (INFOVIS’03)
0-7695-2055-3/03 $ 17.00 © 2003 IEEE

3.
4.
5.
6.

Use the multiple sliding windows approach to update the
existing scatterplot with the new information. Repeat
Step 3 for a pre-defined number of updates.
Use the stratification approach to come up with a fast
overview of the entire dataset.
Use the stratified overview to evaluate the accumulated
error generated by the multiple sliding windows method
using Procrustes analysis.
If error threshold is reached, go to Step 1. Otherwise, go
to Step 3.

10 DISCUSSION AND FUTURE WORK
The general concept of scaling has been applied extensively to
visualize the similarities of high-dimensional information for many
years. In the case of corpus visualization, the combination of
representing individual documents as mathematical vectors and
projecting them onto a low-dimensional space using certain scaling
techniques has becomes the de facto approach for many corpora
visualization packages. Unfortunately, these packages are designed
to analyze static corpora only and thus cannot handle dynamic text
streams proficiently. The work presented in this paper provides
critical technology to tackle such a clear and present problem.
Decades of MDS research and development by biologists,
psychologists, statisticians, and now computational scientists have
successfully reduced the time complexity of MDS from O(n3) at
the beginning, to O(n2) [Chalmers 1996] in 1996, and to O(nn)
[Morrison 2002] in 2002. However, these significant results still
require the reprocessing of at least a portion of the dataset for every
update. When an individual item arrives, it is far better to use our
data fusion method, which takes only O(m) (m = vector dimension,
m << n) time to obtain an instant scatterplot update.
While our dynamic visualization approach appears to work
well on text and image streams, we have not included other data
streams in our study. Until we conduct a full investigation, we
cannot claim our approach is not without limitations.
We are in the process of integrating part of our work into an
ongoing system development effort focusing on text stream
visualization. We plan to evaluate the performance in a real-life
environment using live text streams and present the results in the
near future.

11 CONCLUSIONS
We have presented two dynamic visualization techniques to
analyze transient data streams. Using a newswire corpus and a
remote sensing imagery sequence, we demonstrate that our data
stratification approach can substantially speed up the visualization
process and yet maintain the high fidelity of the graphic results. We
also show that our data fusion approach can provide instant updates
of an MDS scatterplot without the requirement of reprocessing all
the information in full resolution. All our approximation results
have been validated by both visual and computational tests based
on Procrustes analysis. We believe the concepts of data
stratification and data fusion will play an important role in many
future data stream analysis tool designs.

ACKNOWLEDGMENTS
This research has been sponsored by the US Intelligence
Community and Advanced Research and Development Activity
(ARDA), with additional support from the Homeland Security
Initiative at the Pacific Northwest National Laboratory. Special
thanks go to George Chin, Kris Cook, Ted Divine, Sharon Eaton,
Mark Goodwin, Beth Hetzler, Jeff Hylden, Doug Lemon, Dave
McGee, Russ Rose, Bob Silva, and Alan Turner who provided
assistance of many forms throughout this research. The Pacific
Northwest National Laboratory is managed for the U.S.
Department of Energy by Battelle Memorial Institute under
Contract DE-AC06-76RL1830.

REFERENCES
AUREKA 2003. http://www.aurigin.com/aureka.html
BABCOCK, B., BABU, S., DATAR, M., MOTWANI, R., AND WIDOM, J. 2002.
Models and Issues in Data Stream Systems. Invited Paper in
Proceedings of the 2002 ACM Symposium on Principles of Database
Systems (PODS 2002), ACM Press, 1-16.
BABU, S. AND WIDOM, J. 2001. Continuous Queries over Data Streams.
SIGMOD Record, ACM Press, 109-120.
BENTLEY, C. L. AND WARD, M. O. 1996. Animating Multidimensional
Scaling to Visualize N-Dimensional Data Sets. In Proceedings IEEE
Symposium on Information Visualization ’96, IEEE CS Press, 72-73.
BOOKSTEIN, A., KLEIN, S. T., AND RAITA, T. 1998. Clumping Properties or
Content-Bearing Words. Journal of the American Society for
Information Science and Technology, 49, 2, 102-114.
CHALMERS, M. 1996. A Linear Iteration Time Layout Algorithm for
Visualising High-Dimensional Data. In Proceedings IEEE Visualization
’96, ACM Press, 127-132.
CORTES, C., FISHER, K., PREGIBON, D., ROGERS, A., AND SMITH, F. 2000.
Hancock: A Language for Extrating Signatures from Data Streams. In
KDD 2000 Proceedings, ACM Press, 9-17.
COX, T. F. AND COX, M. A. A. 1994. Multidimensional Scaling. Chapman &
Hall.
DEERWESTER, S., DUMAIS, S. T., FURNAS, G. W., LANDAUER, T. K., AND
HARSHMAN, R. 1990. Indexing by Latent Semantic Analysis. Journal of
the American Society for Information Science and Technology, 41, 6,
391-407.
DOMINGOS, P. AND HULTEN, G. 2000. Mining High-Speed Data Streams. In
KDD 2000 Proceedings, ACM Press, 71-80.
GILBERT, A. C., KOTIDIS, Y., MUTHUKRISHNAN, S., AND STRAUSS, M. T.
2001. Surfing Wavelets on Streams: One-Pass Summaries for
Approximation Aggregate Queries. In Proceedings of 27th Very Large
Data Bases (VLDB) Conference, 541-554.
MALLAT, S. 1998. A Wavelet Tour of Signal Processing. Academic Press.
MATHEMATICA 2003. http://www.wolfram.com/
MDS 2003. http://www.ncl.ac.uk/mds/
MORRISON, A., ROSS, G., AND CHALMERS, M. 2002. A Hybrid Layout
Algorithm for Sub-Quadratic Multidimensional Scaling, In Proceedings
IEEE Symposium on Information Visualization 2002, IEEE CS Press,
152-158.
NETLIB 2003. http://www.netlib.org/lapack/index.html
OMNIVIZ 2003. http://www.omniviz.com/
O’CALLAGHAN, L., MISHRA, N., MEYERSON, A., GUBA, S., AND
MOTWANI, R. 2002. Streaming-Data Algorithms for High-Quality
Clustering, In Proceedings of the 2002 International Conference on
Data Engineering (ICDE 2002), IEEE CS Press, 685-696.
RODDEN, K., BASALAJ, W., SINCLAIR, D., AND WOOD, K. 1999. Evaluating
a Visualisation of Image Similarity as a Tool for Image Browsing, In
Proceedings IEEE Symposium on Information Visualization 99, 36-43.
RISCH, J. S., REX, D. B., DOWSON, S. T., WALTERS, T. B., MAY, R. A., AND
MOON, B. D. 1997. The STARLIGHT Information Visualization
System. In Proceedings IEEE Conference on Information Visualization,
42-49, IEEE CS Press, 42-49.
SALTON, G. AND MCGILL, M. J. 1983. Introduction to Modern Information
Retrieval, McGraw-Hill, New York.
SAMMON, J. W. 1969. A Non-Linear Mapping for Data Structure Analysis.
IEEE Transactions on Computers, C-18, 5, IEEE CS Press, 401-409.
SEBER, G. A. F. 1984. Multivariate Observations. John Wiley & Sons.
STRANG, G. AND NGUYEN, T. 1997. Wavelets and Filter Banks, WellesleyCambridge Press.
VXINSIGHT 2003. http://www.cs.sandia.gov/projects/VxInsight.html
WISE, J. A. 1999. The Ecological Approach to Text Visualization. Journal
of the American Society for Information Science and Technology, 50, 9,
814-835.
WISE, J. A., THOMAS, J. J. PENNOCK, K., LANTRIP, D., POTTIER, M., SCHUR,
A., AND CROW, V. 1995. Visualizing the Non-Visual: Spatial Analysis
and Interaction with Information from Text Documents. In Proceedings
IEEE Symposium on Information Visualization ’95, 51-58.
WONG, P. C. AND BERGERON, R. D. 1997. Multivariate Visualization Using
Metric Scaling. In Proceedings IEEE Visualization ’97, IEEE CS Press,
111-118.

Proceedings of the IEEE Symposium on Information Visualization 2003 (INFOVIS’03)
0-7695-2055-3/03 $ 17.00 © 2003 IEEE

