A Model of Multi-Scale Perceptual Organization in Information Graphics
Martin Wattenberg
Collaborative User Experience Group
IBM Research
mwatten@us.ibm.com

Abstract
We propose a new method for assessing the perceptual
organization of information graphics, based on the premise that
the visual structure of an image should match the structure of the
data it is intended to convey. The core of our method is a new
formal model of one type of perceptual structure, based on
classical machine vision techniques for analyzing an image at
multiple resolutions. The model takes as input an arbitrary
grayscale image and returns a lattice structure describing the
visual organization of the image. We show how this model
captures several aspects of traditional design aesthetics, and we
describe a software tool that implements the model to help
designers analyze and refine visual displays. Our emphasis here is
on demonstrating the model’s potential as a design aid rather than
as a description of human perception, but given its initial promise
we propose a variety of ways in which the model could be
extended and validated.
CR Categories: H.5.2 [User Interfaces]: Screen design; H.1.2
[User/Machine Systems]: Software psychology.
Keywords: Visualization, Perceptual Organization, Scale Space,
Design Methodology

1

Introduction

The design of information visualization software remains a poorly
understood, hit-or-miss process. Part of the difficulty is that
models for how humans extract information from visual displays
remain incomplete. Indeed, seemingly minor design variations can
have dramatic effects on comprehensibility. As a result, creating
effective displays often requires expensive user tests, timeconsuming redesigns, and even a certain amount of guesswork.
Many researchers have recognized these problems and have
investigated guidelines and models for the perception of
information graphics [Ware 2000]. Much work has been done on
the efficacy of different visual encodings (e.g. [Cleveland 1980,
Mackinlay 1988]), resulting in useful rules about the use of color,
position, area, etc. to represent different types of variables.
Others, for example [Healey 1993], have investigated how models
of preattentive processing can be used in designing visualizations.
But these lines of research do not address a key element in the
efficacy of an information graphic: the degree to which its
perceptual organization reflects the organization of the nderlying
data. Many authors have stressed that to design successful

IEEE Symposium on Information Visualization 2003,
October 19-21, 2003, Seattle, Washington, USA
0-7803-8154-8/03/$17.00 ©2003 IEEE

Danyel Fisher
School of Information & CS
University of California, Irvine
danyelf@acm.org

information graphics one must take into account the effects of
perceptual grouping. For instance, [Kosslyn 1989] contains many
examples in which unintentional grouping effects lead to
confusing displays. It would therefore be useful to have a tool that
helped designers assess the perceptual organization of their
designs
Some attempts have been made to model perceptual organization
in information graphics. Tufte provides general guidelines, such
as the “Macro/Micro” principle [Tufte 1990]. But quantitative
models suitable for software implementation are rare. Several
authors have analyzed special classes of displays: [Tullis 1984]
analyzes alphanumeric screens; [Shneiderman et al. 1995]
investigate standard Visual Basic dialog boxes. The work of
[Saund 1990] on deriving perceptual structure in the context of
sketch editing is more ambitious, but still requires a vectorized
version of a graphic as input. Because it is not amenable to the
analysis of non-vector-based visualizations, it is problematic to
apply his method to the output of existing programs.
In this paper we introduce a new formal model of visual
organization which can be applied to a broad class of information
graphics. We present an algorithm that takes as input an arbitrary
grayscale image, and returns as output an analysis of the image’s
organization that links perceived structures at different scales. We
do not claim that this technique captures all or even most of the
aspects of human visual perception—that would be far beyond
any current system—but we do propose it as a potentially helpful
new model of a particular aspect of perceptual organization. We
then describe a prototype software tool that applies this model to
help designers see how an information graphic may be understood
by viewers. We demonstrate the utility of the model by exhibiting
a variety of examples in which it captures aspects of design
aesthetics; we also show how it can be used in the redesign of a
real-life visualization. Finally, we discuss directions for validating
and extending the model.

2 A Multi-Scale Model of Visual Organization
2.1 Motivation: Importance of Multiple Scales
Most information graphics display structure at several different
scales. That is, an image will contain large-scale organization as
well as many smaller details. Our hypothesis is that at all these
scales the visual structure should reflect the structure of the data
being conveyed, with large-scale organization reflecting a broad
overview or summary, and smaller details reflecting details of the
data. As [Bertin 1983] puts it:
A graphic should not show only the leaves; it should show the
branches as well as the entire tree. The eye can then go from
detail to totality and discover at once the general structure and
any exceptions to it.

This intuition about multiple scales is shared by many visual
designers. Typographers, for example, routinely speak of a visual
hierarchy in text layouts. Figure 1 shows a hand-drawn example
of such a hierarchy. (We have chosen a piece of text as an

Proceedings of the IEEE Symposium on Information Visualization 2003 (INFOVIS’03)
0-7695-2055-3/03 $ 17.00 © 2003 IEEE

example for analysis in the next section since it has several
natural, unambiguous scales: letter, word, line, and paragraph.)
Despite the general belief that multi-scale structure exists and is
important, that structure can prove surprisingly elusive. Even
experienced designers will resort to tricks such as looking at an
image from across a room or holding it upside down to get a
better sense of its organization. In many ways it would be helpful
to have a mathematical model that matched the standard
designer’s intuition. Such a model could be useful to designers,
for instance, who could apply it to early designs to see if the
structure matched what they wished to communicate. It could also
be helpful in automating some aspects of design—for instance, a
computer might try to use the model to optimize the
correspondence between visual structure and data structure. All
of these potential uses rely on a precise model that can
implemented algorithmically.

2.1.1 Human and Machine Vision
Psychologists have long studied perceptual organization and its
multi-scale aspects. A full review of the psychological literature
on this topic is beyond the scope of this paper, but we cite a few
reference points. Gestalt psychologists, starting with Wertheimer
[1924], have proposed a number of “laws” for how the brain
groups objects: by proximity, good continuation, and so on.
Multi-scale aspects of grouping have also been addressed in
several lines of research (e.g. [Palmer 1977], [Navon 1977]).
Many of these theories of grouping were qualitative, but
investigators have worked on creating quantitative or algorithmic
models as well. Typical examples from this large research area are
[Kubovy 1994], who treats grouping by proximity in dot lattices,
and the work of Li [1998] on neural network simulations of
cortical processing.
The quantitative psychological models cited above are,
unfortunately, highly specialized and not directly applicable to the
task of analyzing information graphics. (It’s a long way from dot
lattices to graphs, charts, and treemaps.) The field of machine
vision, however, provides a different and more immediately
fruitful perspective. Analyzing visual structure has long been
recognized as an important component of computer vision (see
[Witkin and Tenenbaum 1983]), and modern computer vision
frameworks typically are designed to be applied to arbitrary
images. In this paper we highlight one particular framework, scale
space theory, and through a series of examples suggest that it is
particularly suitable for the analysis of information graphics. A
natural future direction would be to reconnect this model with
psychological work through experimental validation.

2.2 Limits and Assumptions
Rather than attempting to model the full range of visual
experience, we focus on non-interactive motionless grayscale
images, and make no attempt to reconstruct a 3D scene. By
eliminating from consideration color, depth, motion, and
interactivity we simplify the domain considerably yet retain
significant generality, for example encompassing a significant
fraction of printed information graphics. Furthermore, even within
the domain of static grayscale images, we do not attempt to create
a complete model of visual grouping. Instead, as a first step, we
focus on a single type of structure. Obviously it would be
desirable to have a model that eventually did account for the
many other dimensions of visual perception, and in the final
section we discuss potential generalizations.

Figure 1. Visual hierarchy, hand-drawn, for a piece of text.
(The “Dr. Seuss” image.)

2.3 Our Model: Mathematical Definition
We now define our model. First we make precise the idea of
“scale.” Then we define a simple method of extracting structure at
a given scale. Finally we describe a technique for linking
structures found at different scales.

2.3.1

Scale Space

We base our model on the classical machine vision concept of
scale space. Scale space theory [Iijima 1959, Witkin 1983,
Koenderink 1984, Lindeberg 1994] is a formalism that describes
the structure of a signal at many different scales at once.1
To define scale space precisely, we need some notation. First, we
represent the input image as a function:
f: [0,L] × [0,L] → [0,1].
That is, we take f to be a function on a square of side L, where a
value of 0 corresponds to black, 1 to white, and values in between
correspond to shades of gray.
Given the function f, we then extend its domain to a 3dimensional “scale space” by a special family of functions fs
where s ≥ 0. First, let Gs be a Gaussian kernel with “width” s;
more formally, let
G s ( x, y ) =

2
2
2
1
e −( x + y ) / 2s
2π s 2

We define then fs by
fs =f*Gs
where * represents convolution. Informally, the function fs
represents the original image having been blurred by a factor of s.
Figure 2 (next page) shows fs for three different values of s. The
3-dimensional space formed by the spatial dimensions x,y and the
1

Proceedings of the IEEE Symposium on Information Visualization 2003 (INFOVIS’03)
0-7695-2055-3/03 $ 17.00 © 2003 IEEE

Despite the similar name and notation, scale space in this sense
is not directly related to the “space-scale diagrams” of Furnas
and Bederson [1995], an elegant application of Riemannian
geometry to zooming user interface design.

new scale dimension s is known as scale space, and by analyzing
the functions fs on this 3-dimensional scale space we can get at
important structures in the original 2-dimensional image.

Figure 2. fs for the Dr. Seuss image, where s=8, 16, 44.

2.3.2 Structure and segmentation
Having defined scale space we now need a notion of structure or
organization at a given scale. There are many possible ways to
define a structure. We choose to define structure by creating a
segmentation of the image at each scale. For a given scale s, we
follow Marr and Hildreth [1980] and consider the difference-ofgaussians edge detection function
gs = fs - f3s/2.
This function is one of the best studied edge detectors, and has
some correspondence to the responses of retinal neurons. It is a
close approximation of another classical edge detector, the
Laplacian operator, but numerically more stable. Figure 3 shows
the function gs for the Dr. Seuss image at three different scales.

Figure 3. Difference of Gaussians: fs-f3s/2 , s=8,16,44.
50% gray is zero; dark gray is negative; light gray is positive.
We can then naturally segment the square into regions where gs ≠
0. The connected components of these regions form the elements
of our segmentation. The sign of gs also has significance; it
corresponds, very roughly, to whether the segment is brighter or
darker than its neighbors.
Why use the difference-of-gaussians edge detector? It has several
advantages. First, simplicity: it is well-understood and efficient to

calculate. Second, unlike several other popular edge detectors
(e.g. [Canny 1986] or [Shen and Castan 1992]), the difference-ofgaussians method has the benefit of immediately producing closed
contours, thus creating a segmentation without additional steps.
Third, the sign of the function gs is useful in creating an
algorithmic version of the linking step below. Despite these
advantages, it is important to note some well-known drawbacks to
this technique: poor localization, rounded corners, and
oversensitivity [Parker 1997]. A different edge detector would
not, however, fundamentally alter the framework of our model.
Figure 4 shows the resulting segmentation at scales of 8, 16, and
44. In the top row the edges of segments are shown. In the bottom
row, each segment has been filled with a single gray tone
representing the average grayscale value of the pixels in the
segment, a technique we call a Gestalt cartoon. (This in itself is a
small but interesting visualization issue: informal tests showed
that for complex segmentations, users found these Gestalt
cartoons easier to interpret than an outline view.) Note how
closely the images in the bottom row match the intuitive handdrawn diagrams of Figure 1.
Edge detection is not the only way to locate structure at a given
scale. Probably the most common method—one used in many of
the original scale space papers—is to analyze local maxima and
minima of the function fs [Witken 1983, Koenderink 1984]. Often
this analysis is accompanied by some sort of watershed
segmentation [Lindeberg 1994, Leung et al. 2000]. We tried
several variants of this technique but found they produced poor
results, possibly due to the non-generic nature of typical
information graphics. Compared to images of natural scenes,
diagrams and visualizations have an unusual number of areas of
uniform brightness. In many cases we found that the graph of fs
contained ridges, valleys, and plateaus that were almost but not
quite level, leading to a proliferation of local extrema that did not
correspond to useful features in the image. This is why we chose
the edge-detection scheme described above.

2.3.3

Linking structures at different scales

As described so far, the model finds structure only at a single
scale. But the perceptual structure of an image includes not just
the structure at one scale, but the relationships between features at
different scales. In the scale space literature, linking features
between scales is often referred to as finding the deep structure of
an image [Koenderink 1984]. In this section we describe a novel
method of finding this deep structure that is particularly useful for
information graphics.
Consider the segmentations in Figure 5, shown as a series of
Gestalt cartoons. It is visually clear that the two blobs in the s=11
view correspond to the individual letters of the words “Dr.” and
“Seuss” respectively. The final part of our model is a method of
making this intuition precise.
Let S1 and S2 be two image segments found at scales s1≤s2

Figure 4. Algorithmically derived segmentation of the Dr.
Seuss image for s=8,16,44. Top: edges of segments. Bottom:
filled segments, or Gestalt cartoons.

Proceedings of the IEEE Symposium on Information Visualization 2003 (INFOVIS’03)
0-7695-2055-3/03 $ 17.00 © 2003 IEEE

Figure 5. Four scales of Dr. Seuss

respectively. We can naturally view S1 and S2 as embedded within
the 3D scale space, i.e. as the sets {s1} × S1 and {s2} × S2. We will
say S1 is linked to S2, denoted by S1 ≤ S2, if either S1 = S2 or there
is a path through scale space from a point on S1 to a point on S2,
such that gs maintains the same sign and s is monotonically
increasing. It is easy to verify that the relation “≤” defines a
partial order on the set of segments. It is also clear from the
definition that this partially ordered set breaks into two
disconnected components, one that corresponds to the subset of
segments where gs<0 , which we denote as L- and one we call L+
where gs>0. (It is possible for each of these two sets to have many
maximal elements.) In some cases, L- and L+ turn out to
correspond to foreground and background elements. For example,
in the Dr. Seuss image, the segments corresponding to the text are
represented in L- while the whitespace is represented in L+.
Figure 6 is a visualization of the results of connecting linked
segments in L- for the Dr. Seuss image.
The image shows a 3D view of scale space, with four separate
planes highlighted (corresponding to s=1,4,7,11). For each plane,
we show the segmentation for the corresponding s value, and for
each pair of linked segments in adjacent planes we have drawn a
line between the segments’ centroids. For simplicity, in this
diagram we only show L- , the segments with negative gs, since
they account for the main visual structure. The result is a tree
structure on the words that corresponds to the intuitive
hierarchical division of a phrase into words and words into letters.
The choice of a 3D display is a visualization exercise in its own
right. We tried various alternatives, such as abstract graphtheoretic views of the lattice and a layout of 2D thumbnails with
connections drawn between segments. In these cases, however,
users were uniformly confused about the connection between the
lattice structure and the image.
For completeness the L- lattice for the entire Dr. Seuss image is
shown in Figure 7. Again, the structure nicely corresponds to the
intuitive hierarchy of paragraphs, lines, words, and letters.

Figure 7. The linked structures in L- for the entire Dr. Seuss
image are shown in orange.
Although linking structures at different scales by following zerocrossings of various operators is common in scale space theory
[Lindeberg 1994], the particular linking described here is unusual,
and in fact is a key distinguishing feature of our model. Most
scale space segmentation algorithms seek a hierarchical
segmentation of an image, where the partial order is always a tree
structure. The segmentation described above, however, can
produce non-nested segments with non-tree lattices. In the context
of scene segmentation and object recognition—the conventional
applications of scale space theory—this is an undesirable
property. But as several authors have pointed out [Saund 1990,
Leung et al 2000], a non-tree lattice seems to model well the
visual experience of certain images. Indeed, given that the goal of
many information graphics is to portray complex
interrelationships, any model that led to pure trees would be of
limited applicability.
Figure 8 gives an example of an image whose visual structure is
not tree-like. The barbell image, at a small scale, is one
continuous object, at a slightly larger scale breaks into two main
parts, and at a large scale merges into one object again.

Figure 6. Linked segments in L- at different scales for part
of the Dr. Seuss image.

Proceedings of the IEEE Symposium on Information Visualization 2003 (INFOVIS’03)
0-7695-2055-3/03 $ 17.00 © 2003 IEEE

Figure 8. Image whose structure is not tree-like.
Left: original image. Right: structure of L-.

2.3.4

Related Methods

The general concept behind our construction, analyzing a signal at
multiple resolutions, is found in many fields. One closely related
technique of multiscale analysis is the continuous wavelet
transform. Indeed, the difference-of-Gaussian operator used in our
segmentation step is a close approximation to the Mexican Hat
wavelet [Antoine et al 1993]. Statisticians use convolution with
Gaussian kernels of varying radii in kernel density estimation
[Scott 1992], a non-parametric estimation technique; [Leung et al
2000] have applied scale space theory to statistical clustering
using a watershed-type segmentation technique. It is worth
keeping both these statistical connections in mind when later in
the paper we show how the model applies to a scatterplot. A third
technique that is closely related is the multiscale pyramid
representation [Burt and Adelson 1983]. Originally used for
image compression, it is interesting to note that this structure is
now used in at least one sophisticated model of visual perception
[Itti 2001].

successive approximations to fs, and connect any two segments
that share a sign and which overlap. Our implementation is
written in Java, and on a 700 MHz Pentium 3 PC requires up to a
minute to perform a full structural analysis on a 800 x 600 pixel
image at 15 scales. Once the analysis is performed, it is saved for
viewing as both a series of grayscale images and as a 3D VRML
file. This architecture lends itself naturally to a web-based tool,
which we hope to implement in a future version.

3.2 A Simple Example: Graphs and Grid Lines

To test our model, we built a software tool that applies the model
to arbitrary input images. The tool was used to create all the
images in this paper, with the exception of the hand-drawn
Figures 1, 11 and 12. As a demonstration of our model, we apply
it to three case studies, and show how it can be used in the
redesign of a real-life visualization.

Our first example shows Gestalt cartoons of two versions of a
simple graph (Figure 9). At top left is a graph with thin gridlines,
at top right is a graph with overpoweringly thick ones. The
segmented versions at scale s=4 are shown below. In the graph
with thick gridlines the graph itself is not segmented from the
background. This is an interesting indication of both the the
strength of our model and one of its limitations. A human can
segment the graph in the second diagram by using orientation
information, which our model ignores. Nonetheless, doing so
places an additional cognitive burden on the viewer, and in fact it
is a standard principle of information design that grid lines should
be significantly lighter than lines representing “foreground” data.
Thus the model indicates, correctly, that there is a problem with
the second graph. This situation—where a minor visual change
has a large effect on comprehensibility—is exactly where it is
useful to have a model.

3.1. The Software

3.3 A Famous Real-Life Example

The software tool contains the following
numerical
approximation of the model. We represented the image functions
fs as 2-dimensional arrays of floating-point values (one per pixel
in the original image), and computed fs for only a few discrete
values of s. To perform linking, we looked at each pair of

How does the model fare on a real-life example? Figure 10 shows
Gestalt cartoons for a complex scatterplot, the famous
astronomical Hertzprung-Russell diagram. This scatterplot, which
displays data on stars with temperature on the x-axis and absolute
magnitude on the y-axis, plays a central role in scientists’
conception of stellar evolution. The HR diagram at the top left of
Figure 10 is reproduced directly from [Spence and Garrison
1993], which contains a detailed discussion of this historically
significant information graphic.

3. Results and Applications of the Model

Figure 9. Gestalt cartoons showing differentiation of figure and
ground in a graph. Left: thin grid lines. Right: thick grid lines.

Proceedings of the IEEE Symposium on Information Visualization 2003 (INFOVIS’03)
0-7695-2055-3/03 $ 17.00 © 2003 IEEE

Figure 10. Original image and gestalt cartoons of the
Hertzprung Russell diagram.

Figure 11. Human expert partitioning of HR diagram. After
[Fix 1999].
The segmentations in the Gestalt cartoons capture the intuitive
experience of reading the diagram: the small-scale (s=4) view
emphasizes the vertical structures, while at s=8 and s=16 the
large-scale clusters stand out. The areas highlighted for s=16
correspond nicely to the standard organization given by human
experts. Figure 11 shows how an astronomer structures the
diagram.

Figure 13. L+ structure of original map design at scales up to
s=20. Some flaws: A, two items in different groups are
spuriously joined; B and C, a single group is spuriously
separated.

The regions labeled A and B in Figure 10 show another example
of how a non-tree structure can be an appropriate model. To the
left and below A there is single large segment, reflecting the
small-scale structure of a combined dense vertical and diagonal
cluster. But a larger scale, s=8, that segment has broken into two
parts, at B, corresponding the giants and main sequence regions in
Figure 11. Thus in this case our model produces a non-tree lattice
structure that corresponds to perceived visual organization. This
contrasts with many clustering methods and with conventional
scale-space segmentation techniques, which produce trees only.

3.4 A Treemap Redesign
Finally, we discuss how the model can inform the design of a
visualization. We take as our example the SmartMoney Market
Map [Wattenberg 1999], a treemap visualization [Shneiderman
1992] that displays data on several hundred publicly traded
stocks. The first author of this paper, who led the design of the
Market Map, has on many occasions heard the comment that the
borders between regions are not strong enough. His intuition,
however, was always that they were perfectly fine as is. Since this
is exactly the kind of design issue where a perceptual model
would be useful, we decided to apply our software tool. To make
a comparison, we created a stylized version of the current Market
Map and a redesigned version with darker and thicker borders.
(See Figure 12.)

Figure 14. L+ structure of redesigned map. Grouping is
almost perfect; only flaw is an “orphan” item at A.
When we fed these images into our model, the results were clear.
Figure 13 shows the structure derived for the current version.
Note that the lattice structure is complex, confusing, and does not
follow the underlying hierarchy of the data items. At point A in
the diagram, for example, two items in different groups are
spuriously joined. In Figure 14, the lattice structure is far simpler
simpler and close to a perfect tree. This dramatic result has led to
a reconsideration of the original design—exactly what we would
want from a perceptual model.

4. Future Directions and Extensions
Figure 12. Left: sketch of portion of Market Map. Right: A
redesign with stronger borders.

The model proposed in this paper is at its core a psychological
hypothesis and therefore cries out for experimental validation.

Proceedings of the IEEE Symposium on Information Visualization 2003 (INFOVIS’03)
0-7695-2055-3/03 $ 17.00 © 2003 IEEE

There are several natural directions to investigate. One tactic
would be to compare the structures generated by our model with
self-reports of users’ perceptions. A more pragmatic validation
would be to study whether, in using the software tool described
here, creators of information graphics are able to modify their
designs in a way that user studies show are beneficial.
Two obvious shortcomings of our model are that it applies only to
grayscale images and that it addresses only one type of grouping
mechanism. One of the reasons to choose scale-space analysis as
the basis for our method is that there is a rich body of research
extending the basic idea to more general aspects of image
structure. Theories that handle color or orientation have been
proposed (for example [Perona and Malik 1990, ter Haar Romeny
et al. 2001, Kalitzin et al. 1997]) and could be applied to our
model. Orientation-sensitive models have the potential to address
the fact that our method often confers insufficient saliency on
lines and curves, which can lead to unsatisfactory analyses for
graphics such as node-and-link diagrams. It may also be
advantageous to use a more sophisticated segmentation method
than the difference-of-gaussians edge detection employed here,
since in some complicated images the simple segmentation
algorithm described here can yield counterintuitive results.
Finally, it would be useful to investigate ways of optimizing the
numerical algorithm to run in an interactive timeframe.

5. Conclusion
We proposed a new technique for modeling multi-scale perceptual
organization in information graphics. The model is based on a
classical machine vision technique, scale space, with a novel
method of creating links between structures at different scales.
We demonstrated how a software implementation of this model
captures important aspects of design aesthetics for several
information graphics, and gave an example of how it may be used
to give input into questions of design. We believe there is
sufficient evidence of promise that it is worth extending and
validating the model.

6. Acknowledgements
Thanks to Ben Shneiderman for helpful comments on the purpose
of modeling perception, and to Dan Gruen for advice on cognitive
psychology. Thanks to Kushal Dave, Steve Rohall and Bernard
Kerr for comments on this manuscript, and to the IBM Research
CUE group for support and encouragement.

FURNAS, G. W., AND BEDERSON, B. 1995. Space-scale diagrams:
Understanding multiscale interfaces. Proceedings, CHI95, Human Factors
in Computing Systems.
HAAR ROMENY et al. 2001. Color Differential Structure. Scale-Space
2001: 353-361.

TER

HEALEY, C. G., et al., 1993. Harnessing Preattentive Processes for
Multivariate Data Visualization. Proceedings Graphics Interface '93), pp.
107-117.
IIJIMA, T. 1959. Basic theory of pattern observation, Papers of Technical
Group on Automata Control, IECE, Japan.
ITTI, L., KOCH, C. 2001. Computational Modeling of Visual Attention,
Nature Reviews Neuroscience, Vol. 2, No. 3, pp. 194-203.
KALITZIN, S. et al. 1997. Invertible orientation bundles on 2d scalar
images, Scale-Space Theories in Computer Vision, 77-88, SpringerVerlag.
KOENDERINK, J. J. 1984. The structure of images. Biological Cybernetics,
50:363--370, 1984.
KOSSLYN, S. M. 1989. Understanding Charts and Graphs. Applied
Cognitive Psychology 3:185-226.
KUBOVY, M. 1994. The perceptual organization of dot lattices.
Psychonomic Bulletin & Review, 1, 182-190.
LEUNG, Y. et al., 2000. Clustering by Scale-Space Filtering, IEEE Trans.
on Pattern Analysis and Machine Intelligence, 22:12.
LI, Z. 1998. A neural model of contour integration in the primary visual
cortex. Neural Computation, 10, 903-940.
LINDEBERG, T. 1994. Scale-Space Theory in Computer Vision, Kluwer,
Dordrecht.
MACKINLAY, J. D. 1988. Applying a Theory of Graphical Presentation to
the Graphic Design of User Interfaces. Proceedings of the ACM
SIGGRAPH Symposium on User Interface Software (UIST '88) 179-189.
MARR, D. AND HILDRETH, E. 1980. Theory of Edge Detection, Proc. R.
Soc. London, B 207, 187-217.
NAVON, D. 1977. Forest before trees: The precedence of global features in
visual perception. Cognitive Psychology 9: 353-383.
PALMER, S. E. 1977. Hierarchical structure in perceptual representation.
Cognitive Psychology, 9, 441-474.
PARKER, J.R. 1997. Algorithms for Image Processing and Computer
Vision, John Wiley & Sons.
PERONA, P., MALIK, J. 1990. Scale-space and edge detection using
anisotropic diffusion. IEEE Trans. on Pattern Analysis and Machine
Intelligence, vol. 12,no. 7, pp. 629-639.

Figure 10 reprinted with permission from The American
Statistician. Copyright 1993 by the American Statistical
Association. All rights reserved.

SARKER, S. 1999. Perceptual Organization in Computer Vision: Status,
Challenges, and Potential. Computer Vision and Image Understanding,
76,1 : 1-5.

7. References

SAUND, E. 1990. Symbolic Construction of a 2-D Scale-Space Image.
IEEE Transactions on Pattern Analysis and Machine Intelligence 12(8):
817-830.

ANTOINE et al. 1993. Image analysis with two-dimensional continuous
wavelet transform, Signal Processing, 1993, pp. 241-272.
BERTIN, J. 1983. The semiology of graphics. Univ. Wisconsin Press:
Madison, Wisc.
BURT, P.J, ADELSON, E.H, 1983. The Laplacian Pyramid as a Compact
Image Code, IEEE Trans. on Communications, pp. 532-540.
CANNY, J. 1986. A Computational Approach to Edge Detection, IEEE
Transactions on Pattern Analysis and Machine Intelligence, 8: (6) 679698.
CLEVELAND, W., 1980. The Elements of Graphing Data. Monterey, Calif.:
Wadsworth.
ELDER, J., GOLDBERG, M., 2002. Ecological statistics of Gestalt laws for
the perceptual organization of contours, Journal of Vision, 2, 324-353.
FIX, JOHN D. 1999. Astronomy: Journey to the Cosmic Frontier. New
York:McGraw-Hill. 1999: Second edition, Updated.

SCOTT, D. W. 1992. Multivariate Density Estimation. Wiley-Interscience.
SHEN J. AND CASTAN, S. 1992. An Optimal Linear Operator for Step Edge
Detection, Computer Vision, Graphics, and Image Processing, Vol. 34,
321-343.
SHNEIDERMAN, B. 1992. Tree Visualization with Tree-Maps: 2-d spacefilling approach. ACM Trans. Comput. Graph. 11, 1, 92-97.
SHNEIDERMAN, B., et al. 1995, Evaluating spatial and textual style of
displays, Proc. of Getting the Best from State-of-the-Art Display Systems
'95, London.
SPENCE, I., GARRISON, R.F. 1993 A remarkable scatterplot. The American
Statistician, 47, 12-19.
TUFTE, E. 1990. Envisioning Information. Graphics Press.
TULLIS, T. S. 1984. A Computer-Based Tool for Evaluating Alphanumeric
Displays. Proceedings of INTERACT'84.

Proceedings of the IEEE Symposium on Information Visualization 2003 (INFOVIS’03)
0-7695-2055-3/03 $ 17.00 © 2003 IEEE

WARE, C. 2000. Information Visualization: Perception for Design. San
Francisco: Morgan-Kaufmann.
WATTENBERG, M. 1999. Visualizing the Stock Market, CHI99 Extended
Abstracts.
WERTHEIMER, M. 1924/1950. Gestalt theory. In W.D. Ellis (Ed.), A
sourcebook of Gestalt psychology (pp. 1-11). New York: the Humanities
Press.
WITKIN, A. 1983. Scale-space filtering, Proc. Eighth Int. Joint Conf. on
Artificial Intelligence (IJCAI '83, Karlsruhe, Aug. 8--12, 1983.
WITKIN, A., TENENBAUM, J.M. 1983. On the role of structure in vision. In
Human and Machine Vision, A. Rosenfeld ed. Academic Press.

.

Proceedings of the IEEE Symposium on Information Visualization 2003 (INFOVIS’03)
0-7695-2055-3/03 $ 17.00 © 2003 IEEE

