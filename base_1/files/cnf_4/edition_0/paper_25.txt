Interference Microscopy Volume Illustration for Biomedical Data
Hanqi Guo 1,2

Xiaoru Yuan 1,2

∗

Jie Liu 1

†

Guihua Shan 3

Xuebin Chi 3

‡

Fei Sun 4

§

1) Key Laboratory of Machine Perception (Ministry of Education), and School of EECS, Peking University
2) Center for Computational Science and Engineering, Peking University
3) Computer Network Information Center, Chinese Academy of Sciences
4) Institute of Biophysics, Chinese Academy of Sciences
Differential Interference Contrast
Volume Rendering (DICVR)

Phase Contrast Volume
Rendering (PCVR)
Direct Volume
Rendering (DVR)

Figure 1: Visualization results of a mouse intestine microvilli data set with lens of DICVR (Differential Interference Contrast Volume Rendering)
and PCVR (Phase-Contrast Volume Rendering) in the context of DVR (Direct Volume Rendering). While both methods can enhance the structure
details of the noisy data, DICVR is able to clearly depict the small micro-filament structures in each microvillus.

A BSTRACT
In this paper, we propose a novel volume illustration technique
inspired by interference microscopy, which has been successfully
used in biological, medical and material science over decades. Our
approach simulates the optical phenomenon in interference microscopy that accounts light interference over transparent specimens, in order to generate contrast enhanced and illustrative volume visualization results. Specifically, we propose PCVR (PhaseContrast Volume Rendering) and DICVR (Differential Interference
Contrast Volume Rendering) corresponding to Phase-Contrast microscopy and Differential Interference Contrast (DIC) microscopy
respectively. Without complex transfer function design, our proposed method can enhance the image contrast and structure details
according to the subtle change of Optical Path Differences (OPD),
and illustrate the thickness change and occluded structures with interferometry metaphors. In addition, we also develop a user interface to enable slicing specimen sections in volume data. Focus+context lens are also included in the system for convenient data
navigation and exploration. As the proposed methods are based
upon widely applied microscopy techniques, they are intuitive for
domain experts to explore and analyze the volume data with the proposed methods. The feedbacks from domain users suggest our proposed techniques are useful volume visualization approaches complimentary to the traditional ones.
∗ e-mail:

{hanqi.guo,xiaoru.yuan}@pku.edu.cn
liujienju@gmail.com. Now at Content Tech, NVidia Corporation, participated in this work during his internship at Peking University.
‡ e-mail: {sgh,chi}@sccas.cn
§ e-mail: feisun@ibp.ac.cn
† e-mail:

IEEE Pacific Visualization Symposium 2012
28 February - 2 March, Songdo, Korea
978-1-4673-0866-3/12/$31.00 ©2012 IEEE

Keywords: Volume illustration, volume rendering, interference
microscopy, biomedical visualization, feature enhancement.
Index Terms:
I.3.3 [Computer Graphics]: Picture/Image
Generation—; I.3.8 [Computer Graphics]: Applications—;
1

I NTRODUCTION

One of the major challenges in volume visualization is how to effectively present sophisticated structures in the data. Direct Volume Rendering (DVR), which is a well-developed technique widely
used in many applications from medical diagnosis to scientific research and engineering, is capable of depicting the appearance and
the shape of the 3D volumetric data. However, the straightforward
approaches are not always the most effective way to convey important features in different data. For example, achieving good DVR
results relies much on data quality and Transfer Function (TF) design [16]. It is very difficult to generate high quality DVR images
if the data is noisy or hard to be classified by TFs.
Recently, visualization researchers have begun to learn from traditional imagery techniques that are developed long before the computer era. For example, in history, technical illustrations effectively
depict information by omitting or simplifying unimportant details
while enhancing the most significant features. In modern visualization techniques, illustration techniques have also been introduced to
the volume visualization domain [8]. Photographic techniques have
also been investigated by visualization researchers for applications
in volume illustrations, such as schlieren [27] and interferometry
experimental based methods [2] used in flow visualization.
In this paper, we propose Phase Contrast Volume Rendering
(PCVR) and Difference Interference Contrast Volume Rendering
(DICVR), inspired from interference microscopy practice. Microscopy is the technical field of using microscopes to view small
specimens. Optical and electron microscopy involve the reflection,
diffraction, refraction of light and other electromagnetic radiation

177

incidents, and the subsequent collection of the scattered radiation
to reconstruct an image. Since its invention over four centuries ago,
microscopy has undergone tremendous improvement for better depiction of subjects. Phase-contrast microscopy, developed by the
Dutch physicist Frits Zernike in the 1930s, is a widely used technique that can convert differences in refractive index as differences
in contrast. Based on phase-contrast microscopy, Nomarski further
invented Differential Interference Contrast (DIC) microscopy to enhance the contrast in transparent and unstained specimens. The volume visualization techniques we have developed in this paper simulate the above wave interference based microscopy approaches.
The general principle of light interference is that the coherent
wavefronts from light cancel or reinforce each other according to
the differential travel paths they traverse prior to their superposition. In the visualization model of PCVR and DICVR, Optical
Path Differences (OPD) defined by the integration of the paths of
the viewing rays traversing the volumetric object to be visualized.
These path differences then modulate the lighting intensity to generate the interference patterns, which are similar to the enhanced
effects that could be observed with phase-contrast and DIC microscopy. In Fig. 1, an example of interference inspired volume
illustration is demonstrated. The proposed methods help on enhancing the contrast and emphasizing boundary regions inside the
volume data, without complex TF design. We can interactively visualize volumetric data by leveraging commodity graphics hardware. Our method is simple, easy to implement and effective at
illustrating subtle but critical volumetric features. Although some
strip-like artifacts may be imported in the image, but they can illustrate the variations in the structures. The proposed methods also
generate comparable images with real microscopy images, which
are familiar to domain users.
The remainder of the paper is organized as follows. We briefly
discuss related work in Section 2 followed by an introduction to the
interference phenomena in Section 3. Then we describe PCVR and
DICVR thoroughly in Section 4 and Section 5 respectively. The
user interface design is presented in Section 6, followed by results
in Section 7. The feedback from domain scientists in Section 8.
Finally we conclude our work in Section 9.
2

R ELATED W ORK

Enhancing features in volumetric data visualization is an area of active research. The quality of a volume visualization result depends
on whether the technique emphasizes important features, subjugates non-critical information and deemphasize distraction as possible.
TFs [16], which convert the voxel data values to optical properties thus hide redundant data and highlight important features,
are one of the most important parameters in direct volume rendering. TF design can be categorized as data-centric and imagebased methods [20]. Image-based TFs are goal oriented, while datacentric TFs focus on the numerical properties of the volume data.
For example, The classification and visual effects of rendered image
can be enhanced by accounting derivative properties and leveraging
multidimensional transfer functions [13, 14]. However, TF design
is still very difficult for non-expert users.
Ebert and Rheingans introduced the concept of volume illustration [8] by modulating each voxel’s color and opacity according to
the local and global properties of the volume model. Perception of
structure, shape, orientation, and depth relationships in a volume
model are enhanced by the combination of direct volume rendering with non-photorealistic rendering techniques. Boundaries are
enhanced by opacity modification based on the gradient value. Oriented features such as silhouettes are enhanced by calculating the
dot product of the viewing direction and value gradient of the volume. The opacities of volume features oriented toward the viewers
are decreased to emphasize feature orientation. Depth-cueing is

178

3 I(t)

3 I(t)

Constructive Interference

Ψ

Ψ1

1
0

Deconstructive Interference

2

2

Ψ2
Ψ1

Ψ
1

2

4

6

−1

8

10

t

0

2

4

6

8

10

t

−1

Ψ2
−2

−2

−3

−3

(a)

(b)

Figure 2: The illustration of light interfence. Red and blue curves are
two coherent waves respectively, and the black curve is the interference results. (a) constructive interference; (b) destructive interference.

achieved by shifting color according to the distance between each
volume sampling point and the viewer. Svakhine et al. [26] further
created a flexible illustration system incorporating domain knowledge of illustration styles to generate images with an appearance
similar to medical illustrations.
Various NPR styles have been generated, such as pen-and-ink
style [28, 7], halo effects [25, 4] and stippling [18, 17]. Interrante
enhanced transparent surface shape and position with sparse textured ridge and valley lines [12]. Cs´ebfalvi [5] visualized the volume contours based on the magnitude of local gradient information
and the angle between viewing direction and gradient vector. Yuan
and Chen [29] illustrated surface features in a volume by combining direct volume rendering with image based iso-surface silhouette/contour detection and rendering. Halos around features were
introduced to reinforce the perception of depth relationship with
the scene [8, 25]. Later a GPU-based volumetric halo rendering
method was proposed by Bruckner and Gr¨oller [4]. Halos are defined through TFs to classify structures of interest based on data
value, direction and position. Luft et al. [19] enhanced the perceptual quality of images that contain depth information by a method
similar to an unsharp mask. Motivated by artwork, the difference
between the original depth buffer content from the rendering and a
low-pass filtered image copy was utilized to determine information
about spatially important areas and undergo local enhancement on
the contrast, color, and other parameters of the image. Svakhine et
al. [27] combined schlieren and shadowgraphy with silhouettes to
reduce visual clutters of oriented structural information.
There are also developments focused on simulating interference
effects [6, 10, 24]. Our work is not intended to fully simulate the
interference phenomena, but to provide new volume visualization
approaches with corresponding counterparts in microscopy domain
and for visualizing volume structures and features.
3

L IGHT I NTERFERENCE AND L IGHT R EFRACTION

Light interference, which is one of the most common physical phenomenon in daily life, has been applied in many scientific and engineering practice, including measurement and precise control, hologram, experimental flow visualization, etc. The physics of interference has been studied for more than 300 years. Formally, Interference is the interaction of two or more waves passing the same
point. Waves can enhance or cancel out each other depends on their
difference of phases or paths length, a.k.a OPD. Constructive interference (Fig. 2(a)) occurs when the waves add in phase, producing
a larger peak than either wave alone, whereas destructive interference (Fig. 2(b)) occurs when waves add out of phase, producing
smaller peaks than one of the waves alone. Two waves with same
amplitudes but exact reversed phases could totally cancel out each
other.
Consider the interference of two coherent monochromatic waves
with different amplitudes and initial phases:
√
ψn (x,t) = In cos(2π f t + φn (x)),
(1)

where I(x) is irradiance, f is the frequency and φn ((x)) is the phase
at position x, n = 1, 2. Since they have the same frequency f , the
irradiance of the combined wave is:
I(x) = |ψ |2 (x) = I1 + I2 + 2 I1 I2 cos δ (x),
(2)
where

2π d(x)
δ (x) = φ1 (x) − φ2 (x) =
,
(3)
λ
δ (x) is the phase difference arising from path length difference if
the initial phases are the same, and d(x) is the OPD at x. If I1 =
I2 = I0 then
δ (x)
π d(x)
I = I0 (1 + cos δ (x)) = 2I0 cos2
.
(4)
= 2I0 cos2
2
λ

Constructive interference occurs when the phase difference between the two waves is an even integer multiple of π . Destructive interference occurs when the phase difference between the two
waves is an odd integer multiple of π . The properties of wave interference are elegantly applied in phase-contrast microscopy to enhance images of almost transparent objects.
In optical media, due to the refraction of the light, the wave
length λ will be changed. Optical path (denoted as ∆) is defined
as the geometry length multiples the refraction rate n. In varying
refraction rate media, optical path along a ray is defined as the integral form:
∆ = n(x)ds,
(5)
L

where n(x) is the refraction rate at position x, so the OPD of the
two rays can be defined as the difference of optical paths:
d = ∆2 − ∆1 =

L2

n(x)ds −

n(x)ds.

Image
Plane

Filters
Digital
Camera
System

Diffracted
Light
Direct
Light

de Sénarmont
DIC Compensator

Transmitted
Light Biological
Microscope

Condenser
Normaski
Prism
Illumination
Pillar
Machanical
Stage

Objective

Specimen

Tugnsten
Halogen
Lamphouse

Observation

Objective

Objective
Normaski
Prism

Phase
Plate

Eyepices

Analyzer
Condenser

35-mm
Camera

Base

Condenser
Annulus

Camera
Port

(a)

Internal
Optical Train

(b)

Figure 3: The configuration of interference microscopes: (a) Phase´
contrast microscpe; (b) Transmitted and inverted de Senarmont
Differential Interference Contrast (DIC) Microscope. Image courtesy
from Nikon MicroscopyU, http://www.microscopyu.com

(a)

(b)

Figure 4: Phase-contrast microcope image: (a) microscopy
image of crystals of strontium chloride with standard brightfield; (b) image obtained by phase-contrast microscopy.
Image courtesy from Microscopy Primer (http://www.microscopyuk.org.uk/primer/special.htm).

(6)

L1

Based on the observation and practice on interference and refraction phenomenon, biologists and optical physicists began to invent new microscopy technologies to visualize the transparent specimens that are not easy to be observed with traditional brightfield or
darkfield microscopy. Such specimens are hard to be dyed, or living
cells will go bad after staining. Although the transparent materials
do not affect colors of light, but the light path and phase are changed
after the light traverses through the specimen. New generation of
microscopy is invented to visualize the unseen specimens with light
interference, such as phase contrast microscopy and differential interference contrast microscopy. In following sections, the detailed
principles and configurations of the both microscopy technologies
will be described.

due to structures and phase gradients present in the specimen. Undeviated and diffracted light collected by the objective is segregated
at the rear focal plane by a phase plate and then focused at the intermediate image plane to form the final phase-contrast image which
is observed in the eyepieces. Since the undeviated and diffracted
light have different phases, the final intensity of the light can be
computed by equation 2 if the absorbtion effect is neglected. In
general, the amplitudes of the undeviated and diffracted light are
not the same.
Fig. 4 illustrates two images with normal brightfield microscopy
and phase-contrast microscopy respectively. The specimen being
examined is crystals of strontium chloride. With the phase-contrast,
the details of the crystal surfaces are enhanced.

4

4.2

4.1 Phase-Contrast Microscopy
A modern phase-contrast microscope is illustrated in Fig. 3(a), together with a schematic illustration of the phase-contrast optical
train. The tungsten-halogen lamp produces partially coherent light.
The illumination is then directed through a collector lens and focused on a specialized annulus (labeled as condenser annulus) positioned in the substage condenser front focal plane. Light wavefronts passing through the annulus illuminate the specimen. Part of
the light passes through undeviated (denoted as D-wave) and another part (denoted as S-wave) are diffracted and retarded in phase

We apply the above phase-contrast enhancement to visualize structures in volume. We develop our visualization method by imitating
the way interference that is applied in phase-contrast microscopy.
In our visualization pipeline (Fig. 5), OPDs are defined by the integration of the density values along the viewing ray path of the
volume data. The DVR image is generated by standard raycasting
method, along with the data classification with transfer functions.
The optical path length These path differences then modulate the
lighting intensity to generate the interference patterns and enhance
the contrast.
The simplified physical model for PCVR is illustrated in
Fig. 6(a). Like most volume rendering techniques, PCVR and
DICVR are also based upon physical model of light transport. In
general, on each point in volume data, there are three types of
light interactions taken into account, including emission, absorption, and scattering. The most commonly used optical model is
called emission-absorption model [9]. PCVR further accounts the
optical path length and phase of the rays during the ray casting pass
based on the emission-absorption model.
The PCVR pipeline consists of several major steps. As illus-

P HASE -C ONTRAST
M ICROSCOPY
AND
P HASE C ONTRAST VOLUME R ENDERING
Phase-contrast microscopy was a revolution of optical technique
in history. It enhances the contrast obtained by the optical microscopies. Transparent specimens, such as living cells in culture, microorganism, thin tissue slices and fibers, which are almost invisible with regular microscopy without dyeing, can be easily observed
with the phase-contrast technique. By simulating the optical train of
phase-contrast microscopy, similar visual effects can be visualized
for volumetric data.

Phase-Contrast Volume Rendering

179

Transfer
Function

Volume
(Specimen)

Wave Length
& Phase

Modulated
PCVR

OPD Map

Modulated
DICVR

Direct Volume
Rendered Image

n(s) = 1 + f (D(s)),

Offset &
Difference

Differential
OPD Map

Image Plane

Figure 5: The pipline of interference microscopy volume illustration.
The OPD map and differential OPD map can be generated with GPUbased raycasting. The PCVR and DICVR results are achieved by
modulating DVR images with OPD map and differential OPD map
respectively.
Absorption, Non-Coherent Emission/Shading

S-Wave

Phase/Intensity
Changed

Interference with D-Wave (Phase = pi)
Image Plane

(a)
Absorption, Non-Coherent Emission/Shading

Two Parts
of
Polarized
Bundles

Phase/Intensity
Changed
Phase/Polarization
Shift

where the mapping f can be defined by users, or a linear mapping
by default. Part of the volume can be removed by setting f (D(s))
of particular volume range. It is similar to the common TF design
for regular volume rendering (TF for refractive index). On the other
hand, the optical path of the S-wave which passes through the volume is
t1
∆S =
1 + f (D(s))ds,
(10)
t0

where t0 and t1 are the in and out position of the ray on the volume
box. The optical path of D-wave is
∆D =

(b)
Figure 6: The simplified physical model for phase-contrast microscopy in PCVR (a) and DICVR (b).

trated in Fig. 5, the OPD image and DVR image can be first computed from volume data by volume ray casting on the GPU individually. Then the PCVR image is obtained by modulating DVR image
and transformed optical path length image according to Eq. 4.
4.2.1 Optical Path Difference Computation
As described above, OPDs are defined by the integration of the density values along the viewing ray direction. Here we make an analogy between the density of the volume and the refractive index. For
each sample point in the volume, the refractive index is n. Following the definition of optical path (Eq. 5), the optical path ∆ in
volume rendering is defined as
∆=

t1

n(s)ds.

(7)

t0

Since the refractive index n is always greater than the index in
vacuum 1, for convenience, we can define the index of refraction as
n(s) = 1 + D(s),
(8)
where D(s) is the volume density value at location s. Alternatively,
the index of refraction can also be defined as a mapping f from
density value:

180

t1

1ds.

(11)

t0

In this way, the OPD d of the S-wave and the D-wave can be computed as:
t1
d = ∆S − ∆D =
f (D(s))ds.
(12)
t0

The OPD can be effectively calculated by raycasting, which
accumulates f (D(s)) from the eye position towards the volume.
When each ray passes through the volumetric object, an integration computation is performed instead of volume composition in
regular direct volume rendering. To achieve the interactivity, we
resort to GPU for acceleration [15, 21, 22]. Specifically, we utilize a modified approach similar to what Kruger and Westermann
have proposed [15] for OPD computation. After the integration,
each ray returns a floating number. We effectively generate a high
dynamic range image through above computation. Interference or
phase-contrast computation can then be applied on the above image
to obtain the enhanced image with interference patterns. Notice that
the ray should not be early terminated as standard DVR often applies for acceleration. If the ray is terminated early, the OPD of the
rest part will not be integrated.
4.2.2

Inteference with Offset Ray

(9)

Interference Computation

After the calculation of OPD through volume ray casting, the light
intensity due to the interference effect in the phase-contrast process
can be computed by a cosine function, which can be effectively
evaluated in modern computer graphics hardware. The cosine function could also be substituted by other periodic function for more
volume illustration effects. The most important parameter being
defined in this stage is the frequency f . In general, we design the
value of f to make the range of integrated OPD around 1/4λ of
wavelength of the virtual interference light. The approach is widely
used in the phase-contrast microscopy applications. A higher frequency number can be applied to enhance the local details.
4.2.3

Modulation with Direct Volume Rendering

The image generated from the above phase-contrast computation
has only one amplitude component, which can further modulate
with DVR images for final result. The modulation is applied per
pixel in the rendered image space after the OPD d is obtained:
I ′ = 2µ cos2

πd
+ (1 − µ )I,
λ

(13)

where I and I ′ are the original and modulated luminance of the
pixel, and µ is the modulation factor, which is defined by users.
If µ = 1, which means full modulation, then Eq. 13 is
I ′ = 2 cos2

πd
.
λ

(14)

5

DIC M ICROSCOPY AND DIC VOLUME R ENDERING

DIC microscopy is another type of interference microscopy technique, which can enhance the contrast in transparent and unstained
specimens. Compared to phase-contrast, microscopy utilizes the
differential of OPDs to enhance features, instead of direct interference with OPD. DIC can help users analyzing the structures of
specimens, because it is more sensitive to variation than phasecontrast microscopy.
(a)

5.1

DIC Microscopy

Figure 7: Linked view of the specimen slicer

As shown in Fig. 3(b), the configuration of a DIC Microscope is
much more complicated than phase-contrast microscopy. In addition to interferometry, DIC also exploits polarization of lights to
enhance the contrast of the image. In the optical train, the semicoherent bundles of non-polarized white light from the lamp filament is divided into two orthogonally polarized parts, which are
mutually coherent. One of the two parts is slightly sheared at the
sample plane, so that there are small a OPD between the two parts
after they penetrated the specimens. After further optical processing, the two coherent parts are recomposited into one image. The
phase offset of the two parts can also be adjusted by users.
The image quality of DIC is often better than phase-contrast images when used in suitable occasions. DIC can emphasize the contrast of lines and edges, since the contrast is approximately proportional to the gradient of OPD. It also brings strong stereoscopic sensation and emboss effects. Although the image of DIC microscopy
is not topographically accurate image, DIC can play as an analytical method for sensitive measurement of the optical properties of
the specimen.
5.2

(b)

DIC Volume Rendering

Like PCVR procedure, we simulate the light train of DIC microscopy in order to enhance the contrast of the features in direct
volume rendering. Since the pipeline (Fig. 5) and the simplified
physical model of DICVR (Fig. 6(b)) is close to PCVR, we only
briefly present and introduce the different components of DICVR.
There are three major steps in DICVR, including OPD map generation, differential OPD map generation, and the modulation with
DVR. All the steps are performed on GPU, as described in Section 4.2.
In DICVR, differential OPD map is defined as the neighborhood
pixel difference of OPD map, which can be formularized as:

Click to add a DICVR lens
Wheel to change the size

DVR

Move the lens around

DICVR

DVR

(a)

(b)

Figure 8: The visualization result of Hepatitis B Virus (HBV) [1] CryoEM data with focus+context lenses.

6.1 Specimen Slicer
As we described above, both phase-contrast and DIC microscopy
are not good at viewing specimens that are too thick. Biologists
are accustomed to examining thin slices as the sample of the object,
which are fixed at the object stage. For this demand, we design
a specimen slicer for domain users to navigate the data and select
slices with proper thickness. As shown in Fig. 7, users can fix a
clipping orientation by rotating the box in the orthogonal view. The
posture of the box will be automatically aligned to axis if it is close
to axis directions. Then the two clipping planes for slicing can be
assigned by moving the callipers on the left side. This user interface
is helpful for selecting meaningful sections of the volume data.

where t0 , t1 are the entrance and exit point of the ray, and t0′ , t1′ are
the corresponding points of the offset ray, which passes through the
surrounding medium. Since the offset is very tiny, we can simply
assume that
t1 − t0 ≈ t1′ − t0′ .
(16)

6.2 Focus+Context Lenses
In our system, we also provide focus+context lenses to illustrate the
results. It often occurs that one image generated by single rendering method cannot reveal all aspects of the features. Inspired by
VolumeShop [3], we enable users to select a region on the image
space to visualize the data with selected microscopy techniques. In
practical, this function is very useful since several techniques can
be simultaneously applied on the same data. As shown in Fig. 8,
DVR can present a good overview on the outline and shape of the
data, and the microscopy volume visualization can better enhance
the detailed features on top of the context of DVR.

Then the differential OPD map can be defined as

6.3

d=

t1
t0

d≈

1 + f (D(s))ds −

t1
t0

f (D(s))ds −

t1′
t0′

t1′
t0′

1 + f (D(s))ds,

f (D(s))ds.

(15)

(17)

On GPU implementation, the differential OPD map can be obtained by adding a offset pass and difference pass after the generation of the OPD map (Fig. 5). The interference computation and
DVR modulation process is almost identical to the corresponding
steps in PCVR. Notice that the wave length and phase can also be
adjusted in DICVR for fine tuning.
6

U SER I NTERFACE D ESIGN

In this section, we briefly describe several featured components in
the user interface.

Multi-Wavelength Interference Microscopy Volume
Illustration
In some cases, only one fixed wavelength is not enough to present
multiple features that are interested. In our tool, users can select a
few locations on the display and specify the proper corresponding
frequency values to emphasize different features. The wavelength
λ then can be interpolated through out the whole image by GPU and
saved into an intermediate texture. A texture lookup for wavelength
λ is then employed to compute each pixel’s intensity after interference interaction. We call this approach as phase-contrast Volume
Rendering with Multi-wavelength (PCVR(MW)) in contrast to the
previously mentioned single wavelength method. As illustrated in
Fig. 9, user can define control points on the screen as shown in
Fig. 9(b). Each control point represents a wave length value λi .

181

Dataset
Resolution
DVR PCVR PCVRM DICVR DICVRM
Microvilli
1747 × 1742 × 221 273.2 584.1 590.0 380.3 388.9
rATCpnbeta
1603
28.7 35.2 38.3
38.4
43.6
Neuron Synapse
5122 × 192
85.3 117.1 119.0 125.4 128.4
Table 1: The average timings (in milliseconds) of our rendering
method with various models, including DVR, PCVR, multi-wavelength
PCVR, DICVR and multi-wavelength DICVR respectively.

(a)

(b)

(c)

(d)

Figure 9: PCVR with multiple wavelength modulated: (a) DVR image;
(b) The actual crystal structure of the data; (b) PCVR with unique
wavelength; (c) PCVR with multiple different wavelengths. The yellow
points in (c) are control points defining different wavelengths.

The wave lengths of non-defined region can be achieved by smooth
interpolation:
(18)
l(x) = ∑ ωi λi ,
i

where weights ω are defined as the transformation of the distances
to the control points:
1/(1 + d(x − xi ))
ωi =
.
(19)
∑i 1/(1 + d(x − xi ))
7 R ESULTS AND P ERFORMANCE
We have applied our methods on three biomedical datasets, including mouse intestine microvilli data, rATCpnbeta Cryo-EM reconstruction data, and neuron tomogram data of the C.elegans neuron
synapse. The data specifications are enumerated in Table 1.
7.1 Mouse Intestine Microvilli Data
As shown in Fig. 1, the mouse intestine microvilli data set is visualized with lens of PCVR and DICVR in the context of background
image rendered with DVR.
In this case, domain scientists mainly focus on three types of
structures, including the capping proteins, the membranes, as well
as the micro-filament matters inside the cells. The first two features can be identified with traditional DVR through 1D TF design.
However, the micro-filament structures are very hard to be distinguished from the surrounding matters using traditional methods. As
seen in the DICVR lens, micro-filament and thread like features can
be clearly illustrated. With PCVR lens, the structures with abrupt
density variation are enhanced. This case clearly demonstrate the
advantages of our proposed techniques over existing volume rendering.
7.2 rATCpnbeta Data
The group II chaperonin rATCpnbeta data [11], which is from CryoEM single particle reconstruction, is reconstructed at the the resolu˚ It is a chaperone with a axis-based five-folded symmetion of 8.4A.
try structure. It is challenging to directly visualize the reconstructed

182

volume data for reasons. The noise of the data is often very high,
so meaningful features are not easy to be classified by TFs. The
contrast of the rendered image is not ideal with traditional methods
since the structures belonging to the same feature is overlapped and
folded (Fig. 9(a), (b)). On the other hand, analyzing data on such
scale of wavelength is not available with real world microscopy.
Users can use existing microscopy metaphor and analytics methods
to investigate such volume data with our tool.
We have generated a group of visualization results for this data,
with different methods and wavelengths (Fig. 10). With shorter
wavelength, detailed structures can be enhanced but artifacts may
increase due to the noise. The initial phase, which corresponds to
the phase plate in real microscopes, can regulate the contrast of the
image.
7.3

Electron Tomogram Data of the C.elegans Neuron
Synapse
In Fig. 11, we demonstrate the rendering results of tomogram data
of the C.elegans neuron synapse [23] with our methods. The TF for
DVR is quite tricky to design because the distribution of features
is very concentrated to a small numerical range with high noise.
The result of DVR is occluded and noisy. By utilizing PCVR, the
contrast of inner structures are enhanced and visualized, although
there are a few artifacts in boundary areas. Especially, the nucleus
and the membranes are highlighted. In the DICVR result, the contrast is further enhanced, and the image brings strong stereoscopic
impression. The boundary of the features look like the valleys in
the image. In the neuron synapse data, one of the most important
features to be identified is the microtubules. The location of microtubules are much easier to be identified in both the rendering results
of DICVR and PCVR than that of DVR. As illustrated in
As the proposed methods are originated from biology and microscopy science and technology, it is very straightforward for domain users to comprehend and use. Although the standard DVR can
indeed help on data comprehension, the TF design for such data is
very difficult for domain users. The proposed methods are strong
complements to existing technologies.
7.4 Performance
The system is implemented in C++ and GLSL shading language.
We leverage the current commodity graphics hardware to perform
the computing and rendering. Table 1 shows the timing for the rendering of different datasets. For each data set, we measure the rendering time of DVR, PCVR, and DICVR. For PCVR and DICVR,
we also measure the performance of multi-wavelength rendering.
All experiments have been performed on a Dell Precision T3500
workstation with a Intel Xeon 2.40G Hz CPU, 8GB RAM, and an
NVidia GTX 470 graphics card with 1280MB video memory. All
images are generated at a screen resolution of 640×480 pixels. The
raycasting step size is fixed at 1 voxel. All data that are tested are
with 32-bit float precision.
As shown in the table, the performance of both PCVR and
DICVR are only slightly lower than DVR. Besides, the performance
difference between the single wavelength and multi-wavelength is
almost the same. In multi-wavelength mode, the wavelength interpolation process is all computed by GPU and only need to be done
once for each rendering. The main performance difference is due
to texture lookup for the wavelength of each pixel.

φ=0.5

φ=1.0

φ=0.0

φ=0.5

φ=1.5

λ=
4.
0

λ=
2.
0

λ=
1.

0

φ=0.0

(a)

(b)

Figure 10: The interference microscopy volume rendering of rATCpnbeta data with PCVR (a) and DICVR (b) in different wavelengths and phase.
The DVR image is shown in Fig. 9(a).

Microtube
Structures

Membrane

(a)

(b)

(c)

Figure 11: Visualization results for electron tomogram of neuron synapse data with different methods. Structures of microtubules are much
easier to be identified with methods we proposed: (a) DVR. The features are severely submerged with the surroundings; (b) PCVR. The contrast
of the image is enhanced. The outlines of inner features appear; (c) DICVR. The contrast of the image is enhanced by introducing emboss
effects that are brought by DICVR. Inner structures are clearly visualized.

8

D ISCUSSION AND D OMAIN E XPERTS ’ F EEDBACK

The aforementioned volume visualization results are generated and
tuned as joint efforts from both visualization experts and domain
scientists. In our experiments, domain scientists, mostly from biophysics research including one co-author of this paper, tried the
visualization system we implemented and gave very positive feedbacks. The scientists considered both PCVR and DICVR can be
utilized as complementary tools of DVR for data visualization and
very useful in many difficult visualization cases.
First of all, our techniques of DICVR and PCVR provide compatible rendering results to real microscopy images which is not
possible to be achieve through transfer function specification in
traditional volume rendering. As modern tomogram and scanning
techniques can obtain the density value at each sample point, it is
desirable to establish compatible approaches to relate the data with
traditional observational results from optical methods. Domain scientists received vigorous training on using microscopy techniques.
They are much more familiar with and sensitive to the style our
approaches can provide. Generation of microscopy-like images
with similar underlying physical principles could enable the crosscomparison between results from different acquisition sources.
Furthermore, domain scientists appreciated our approaches on

providing imagery results with strongly enhanced details. The difference is very apparent in the case of visualizing the mouse intestine microvilli data set using DICVR (Fig. 1). One co-author of this
paper used commercial visualization software such as Amira and a
few other advanced volume illustration systems to render the data
before. Due to the noisy nature of the microvilli data, previous approaches are not able to clearly identify the small micro-filament
structures embedded in each microvillus even with carefully tuned
transfer functions. Our proposed visualization techniques provides
results with clear illustration of the structures. This capability is
strongly recommended by the domain scientists. Domain scientists also suggest that our methods have potential to better depict
surfaces with small variation in the scale compatible to the wavelength employed, as similar applications are common for light interference. Although we haven’t test in this direction at this stage,
in the future, we would like to include data with aforementioned
properties in our research to further explore the potential of our approaches.
Both the interaction methods of focus+context lens and slicing
have been considered as very useful by the domain users, although
they are relatively simple from the view of visualization experts. In
biomedical study, most real acquired data sets are very noisy. Ren-

183

dering thick layers of volume may mix too much noise and overwhelm the desirable fine structures. Interactive selection of layer
thickness and convenient panning the layer window enable flexible
exploration of the data and help to discover structures inside the
data. The lens can further make the comparison between different
rendering styles simple.
We also notice the limitations of our methods. Unwanted strips
may appear in the visualization results due to the mismatched parameter configuration or the thickness of the specimen. The strips,
however, can also used as the indication of the thickness variation.
Balanced results could be achieved by proper wavelength setting or
using focus+context lens with the DVR background.
9

C ONCLUSION AND F UTURE W ORK

In this paper, we present novel visualization methods for illustrating
volumetric data inspired by interference microscopies, including
both phase-contrast and DIC microscopy. Our proposed methods
provides compatible rendering results to real microscopy images
which are easier to be comprehended by domain users. Our results
show that the methods are capable of illustrating and enhancing the
inner detailed structures in noisy data sets. Our work provides a
new way of visualize volume data capturing special lighting effects
of interferences. By further leveraging commodity graphics hardware, user interface with lens and slicing capabilities implemented
provides interactivities of the system.
One major future improvement is the selection of parameters.
Currently, the wavelengths and phases are interactively assigned by
users. In the future, we plan to further improve the usability of
our work by designing better ways of defining parameters in our
proposed visualization methods. Automatic mechanisms could be
employed to set good initial parameters. In addition, the manual
tuning is still useful because users can be conscious about the thickness variation of the data during the tuning process.
ACKNOWLEDGEMENTS
The authors wish to thank the anonymous reviewers for their insightful comments. We are grateful to Prof. Jean-Louis Bessereau
(IBENS, France) for his kindness of sharing the tomography data
of C.elegans neuron cell section. This work is supported by National Natural Science Foundation of China Project No. 60903062
and 61170204, Beijing Natural Science Foundation Project No.
4092021, 863 Program Project 2010AA012400, Chinese Ministry
of Education Key Project No. 109001, and Chinese Academy of
Sciences (KGCX1-YW-13).
R EFERENCES
[1] B. B¨ottcher, S. A. Wynne, and R. A. Crowther. Determination of
the fold of the core protein of hepatitis b virus by electron cryomicroscopy. Nature, 386:88–91, 1997.
[2] C. Brownlee, V. Pegoraro, S. Shankar, P. McCormick, and C. D.
Hansen. Physically-based interactive flow visualization based on
schlieren and interferometry experimental techniques. IEEE Trans.
Vis. Comput. Graph., 17(11):1574 –1586, 2011.
[3] S. Bruckner and M. E. Gr¨oller. VolumeShop: An interactive system
for direct volume illustration. In Proceedings of IEEE Visualization
2005, pages 671–678, 2005.
[4] S. Bruckner and M. E. Gr¨oller. Enhancing depth-perception with flexible volumetric halos. IEEE Trans. Vis. Comput. Graph., 13(6):1344–
1351, 2007.
[5] B. Cs´ebfalvi, L. Mroz, H. Hauser, A. K¨onig, and E. Gr¨oller. Fast visualization of object contours by non-photorealistic volume rendering.
Comput. Graph. Forum, 20(3):452–460, 2001.
[6] M. Dias. Ray tracing interference color. IEEE Comput. Graph. Appl.,
11(2):54–60, 1991.
[7] F. Dong, G. J. Clapworthy, H. Lin, and M. A. Krokos. Nonphotorealistic rendering of medical volume data. IEEE Comput. Graph. Appl.,
23(4):44–52, 2003.

184

[8] D. Ebert and P. Rheingans. Volume illustration: Non-photorealistic
rendering of volume models. In Proceedings of IEEE Visualization
2000, pages 195–202, 2000.
[9] K. Engel, M. Hadwiger, J. M. Kniss, C. Rezk-Salama, and
D. Weiskopf. Real-Time Volume Graphics. A. K. Peters, 2006.
[10] J. S. Gondek, G. W. Meyer, and J. G. Newman. Wavelength dependent
reflectance functions. In Proceedings of SIGGRAPH 1994, pages 213–
220, 1994.
[11] Y. Huo, Z. Hu, K. Zhang, L. Wang, Y. Zhai, Q. Zhou, G. Lander,
J. Zhu, Y. He, X. Pang, W. Xu, M. Bartlam, Z. Dong, and F. Sun.
Crystal structure of group II chaperonin in the open state. Structure,
18:1270–1279, 2010.
[12] V. Interrante, H. Fuchs, and S. Pizer. Enhancing transparent skin surfaces with ridge and valley lines. In Proceedings of IEEE Visualization
1995, pages 52–59, 1995.
[13] J. Kniss, G. Kindlmann, and C. Hansen. Interactive volume rendering using multi-dimensional transfer functions and direct manipulation widgets. In Proceedings of IEEE Visualization 2001, pages 255–
262, 2001.
[14] J. Kniss, G. Kindlmann, and C. Hansen. Multidimensional transfer
functions for interactive volume rendering. IEEE Trans. Vis. Comput.
Graph., 8(3):270–285, 2002.
[15] J. Kruger and R. Westermann. Acceleration techniques for GPU-based
volume rendering. In Proceedings of IEEE Visualization 2003, pages
38–45, 2003.
[16] M. Levoy. Display of surfaces from volume data. IEEE Comput.
Graph. Appl., 8(3):29–37, 1988.
[17] A. Lu, C. Morris, J. Taylor, D. S. Ebert, C. Hansen, P. Rheingans, and
M. Hartner. Illustrative interactive stipple rendering. IEEE Trans. Vis.
Comput. Graph., 9(2):127–138, 2003.
[18] A. Lu, C. J. Morris, D. S. Ebert, P. Rheingans, and C. Hansen. Nonphotorealistic volume rendering using stippling techniques. In Proceedings of IEEE Visualization 2002, pages 211–218, 2002.
[19] T. Luft, C. Colditz, and O. Deussen. Image enhancement by unsharp
masking the depth buffer. ACM Trans. Graph., 25(3):1206–1213,
2006.
[20] H. Pfister, W. E. Lorensen, C. L. Bajaj, G. L. Kindlmann, W. J.
Schroeder, L. S. Avila, K. Martin, R. Machiraju, and J. Lee. The
transfer function bake-off. IEEE Comput. Graph. Appl., 21(3):16–22,
2001.
[21] S. Roettger, S. Guthe, D. Weiskopf, T. Ertl, and W. Strasser. Smart
hardware-accelerated volume rendering. In VisSym ’03: Proceedings
of the symposium on Data visualisation 2003, pages 231–238, 2003.
[22] S. Stegmaier, M. Strengert, T. Klein, and T. Ertl. A simple and flexible
volume rendering framework for graphics-hardware-based raycasting.
In Proceedings of Eurographics / IEEE VGTC Workshop on Volume
Graphics 2005, pages 187–195, 2005.
[23] C. Stigloher, H. Zhan, M. Zhen, J. Richmond, and J.-L. Bessereau.
The presynaptic dense projection of the caenorhabiditis elegans
cholinergic neuromuscular junction localizes synaptic vesicles at the
active zone through SYD-2/Liprin and UNC-10/RIM-dependent interactions. The Journal of Neuroscience, 31(12):43884396, 2011.
[24] Y. Sun, F. D. Fracchia, T. W. Calvert, and M. S. Drew. Deriving spectra
from colors and rendering light interference. IEEE Comput. Graph.
Appl., 19(4):61–67, 1999.
[25] N. Svakhine and D. S. Ebert. Interactive volume illustration and feature halos. In Proceedings of Pacific Graphics 2003, pages 347–354,
2003.
[26] N. Svakhine, D. S. Ebert, and D. Stredney. Illustration motifs for
effective medical volume illustration. IEEE Comput. Graph. Appl.,
25(3):31–39, 2005.
[27] N. Svakhine, Y. Jang, D. S. Ebert, and K. P. Gaither. Illustration and
photography inspired visualization of flows and volumes. In Proceedings of IEEE Visualization 2005, page 87, 2005.
[28] S. Treavett and M. Chen. Pen-and-ink rendering in volume visualisation. In Proceedings of IEEE Visualization 2000, pages 203–210,
2000.
[29] X. Yuan and B. Chen. Illustrating surfaces in volume. In VisSym’04:
Proceedings of Joint IEEE/EG Symposium on Visualization, pages 9–
16, 2004.

