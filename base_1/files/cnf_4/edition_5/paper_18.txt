Adaptive Sampling in Three Dimensions for Volume Rendering on GPUs
Martin Kraus∗

Magnus Strengert†

Thomas Klein‡

Thomas Ertl§

¨ Stuttgart
Visualization and Interactive Systems Group, Universitat

A BSTRACT
Direct volume rendering of large volumetric data sets on programmable graphics hardware is often limited by the amount of available
graphics memory and the bandwidth from main memory to graphics memory. Therefore, several approaches to volume rendering
from compact representations of volumetric data have been published that avoid most of the data transfer between main memory
and the graphics programming unit (GPU) at the cost of additional
data decompression by the GPU. To reduce this performance cost,
adaptive sampling techniques were proposed; which are, however,
usually restricted to the sampling in view direction.
In this work, we present a GPU-based volume rendering algorithm with adaptive sampling in all three spatial directions; i.e., not
only in view direction but also in the two perpendicular directions
of the image plane. This approach allows us to reduce the number
of samples dramatically without compromising image quality; thus,
it is particularly well suited for many compressed representations of
volumetric data that require a computational expensive GPU-based
sampling of data.
Keywords: Scientific visualisation, visualisation of large data sets,
volume visualization, direct volume rendering
Index Terms: I.3.3 [Computer Graphics]: Picture/Image Generation; I.3.7 [Computer Graphics]: Three-Dimensional Graphics and
Realism
1

I NTRODUCTION

Programmable graphics hardware offers an enormous computational performance and is therefore particularly attractive for volume visualization—even on a single desktop PC. For this hardware
configuration, memory and bandwidth limitations are usually the
primary obstacles to real-time direct volume rendering of large volumetric meshes. As the bandwidth between main memory and the
GPU is usually too small to allow for transferring large volumetric
data sets for each frame at interactive rates, many GPU-based implementations are designed to store the volumetric data in graphics
memory in order to avoid this bandwidth bottleneck.
While this approach allows for interactive volume rendering, it
is limited to data sets that fit into graphics memory. To overcome
this problem, several approaches to GPU-based volume rendering
from compressed data have been published as programmable GPUs
are flexible enough for implementations of complex data structures,
which are well suited for more compact representations of volumetric data. Therefore, limited onboard memory can be traded
for rapidly growing computational performance of programmable
graphics hardware. While this approach avoids limitations of data
transfer and of graphics memory, it requires considerably more
computational performance of the GPU; on the one hand because
∗ e-mail:martin.kraus@vis.uni-stuttgart.de

† e-mail:magnus.strengert@vis.uni-stuttgart.de
‡ e-mail:thomas.klein@vis.uni-stuttgart.de
§ e-mail:thomas.ertl@vis.uni-stuttgart.de

Asia-Pacific Symposium on Visualisation 2007
5 - 7 February, Sydney, NSW, Australia
1-4244-0809-1/07/$20.00 © 2007 IEEE

larger volumetric grids are visualized, i.e., more sampling operations are required, and on the other hand because each sampling
operation is computationally more expensive as it requires access
to a complex data structure.
In order to improve the rendering performance, it is therefore
crucial to reduce the number of sampling operations; in particular
by adaptive sampling. However, the adaptive sampling techniques
of published GPU-based volume renderers are usually restricted to
varying the sampling rate on each view ray without adaptive sampling of the image plane. Although the latter is a well-known concept in ray tracing, the graphics pipelines of today’s GPUs were not
designed to support this approach; thus, it is not straightforward
to accomplish an efficient GPU-based implementation of adaptive
sampling of the image plane.
In fact, our approach never reduces the number of fragments generated by the rasterization unit. Instead it relies on an early depth
test of the employed graphics hardware to significantly reduce the
processing time of “skipped” sampling points on view rays. This is
less efficient than actually adapting the distance between sampling
points on view rays; however, it allows us to align the sampling
points on slices in a systematic way. This is crucial for the adaptive sampling of each slice, which has to replace the potentially
expensive sampling of the volumetric data structures by an efficient
approximation within the image plane. Again we employ an early
depth test to efficiently prevent the GPU from performing the sampling program if an approximation of a pixel’s data by pyramidal
filtering suffices.
Apart from adaptively reducing the number of data samples in
all three spatial dimensions, our approach offers the additional advantage of biquadratic B-spline filtering of sampled data instead of
bilinear interpolation of colors; thereby we avoid both, color blurring and bilinear interpolation artifacts.
After reviewing related work in Section 2, we discuss our algorithm and implementation in Section 3. Results are presented in
Section 4. We conclude this paper in Section 5 with a discussion of
future work.
2

R ELATED W ORK

Texture-based direct volume rendering was first published by
Cabral et al. [2]. It exploits hardware support for three-dimensional
textures by rasterizing a set of textured slices. While object-aligned
slices are aligned with the axes of a rectangular volumetric data set,
view-aligned slices are parallel to the image plane as illustrated in
Figure 1. For orthogonal projection, the distances between slices
are uniform for all view rays.
The texture data may already consist of colors and opacities
(pre-classification) or the data is mapped to colors and opacities after interpolation by application of a transfer function (postclassification). Colors and opacities are composited in the framebuffer to approximate the volume rendering integral for each pixel.
Thus, texture-based volume rendering computes the integrals of
all view rays at the same time. Engel et al. [4] have exploited
multi-texturing and dependent texture reads to implement preintegrated volume rendering in a texture-based volume renderer.
Pre-integrated volume rendering improves the image quality of preclassified volume rendering by determining the color and opacity of
each segment of a view ray between two adjacent sampling points

113

d

view
point

view
rays

0 1 2 3 4 5 6 7
image
plane

sampling
slices

Figure 1: Sampling on view-aligned slices for volume rendering

with the help of a lookup in a pre-computed table indexed by the
data values at the ends of the segment.
Ray casting algorithms invert the order in which samples are
processed by completely evaluating the volume rendering integral
for each view ray before processing the next ray. While recently
published GPU-based ray casters implemented this approach (e.g.,
the system by Stegmaier et al. [14]), earlier GPU-based implementations (e.g., by Roettger et al. [13] or Kr¨uger and Westermann [6])
could only evaluate a small part of each integral in a GPU-based
fragment program of limited length. The latter systems could be
characterized as “ray marchers,” which have to execute a fragment
program multiple times by rasterizing polygons that cover the projection of the volume data; e.g., by rasterizing a screen-filling polygon or the front faces of a convex bounding volume.
Usually, a GPU-based ray marcher stores the current sampling
point for each pixel and advances it along the corresponding view
ray. Therefore, the order of sampling operations is similar to slicebased volume rendering. However, ray marchers can choose the
starting point and the sampling distance independently for each
pixel; thus, they are better suited for adaptive sampling of view
rays as demonstrated by Roettger et al. [13]. Unfortunately, independently adapting the sampling distances on adjacent view rays
will usually destroy the contiguous front of sampling points; thus,
this approach is less appropriate for an adaptive sampling of slices.
Adaptive sampling on view rays is one of several well-known acceleration techniques for software volume ray casting [9]. Kr¨uger
and Westermann [6] have adapted empty-space skipping and early
ray termination for programmable graphics hardware by exploiting an early “fragment-depth test.” If a fragment program does
not modify the fragment’s depth, the depth test may be performed
before the fragment program is executed. Thus, if the fragment’s
depth fails the depth test, it is not necessary to executed the
fragment program for this particular fragment. We use the term
“fragment-depth test” instead of “depth test” or “z test” to distinguish it from a “pixel-depth test” or specifically the “depth bounds
test” [5], which compares user-defined bounds to the depth value
already stored in the framebuffer’s pixel at the location determined
by the incoming fragment’s coordinates. The pixel-depth test is independent of the depth of the incoming fragment; thus, it can be an
early test even if the depth of the incoming fragment is computed
by a fragment program. A pixel-depth test was employed by Neophytou and Mueller [10] for empty-space skipping and early ray
termination in GPU-based volume rendering using image-aligned
splatting.
Due to the limited amount of texture memory on graphics hardware, texture compression has been a research topic for many years.
New features of programmable graphics hardware, in particular dependent texture reads, have led to additional efforts to implement
random access to compact data representations in textures; a sur-

114

view
point

view
rays

4
3
2
1

0 1 2 3 4 5 6 7 8
image
plane

sampling
slices

Figure 2: Adaptive sampling on view rays according to an oracle,
which computes a sampling distance d (represented by gray levels)
for each sampling point. Filled black dots represent skipped sampling
points.

vey of many recent publications about GPU-based data structures
is given by Lefohn et al. [7].
The main focus of these publications has been on random access to GPU-based implementations of basic data structures. There
are considerably fewer publications about more efficient decoding
techniques that are less efficient for random access but more efficient if many elements are accessed. One example is “deferred filtering” proposed by Lefohn et al. [8]. If this technique is extended
to an adaptively sampled image plane, the size of the filter kernel
has to be adapted correspondingly. Fortunately, pyramidal algorithms introduced by Burt [1] for image filtering can be employed
for an appropriate sampling scheme as discussed in Section 3.2.
3

A DAPTIVE S AMPLING

IN

T HREE D IMENSIONS

The goal of our approach is to adaptively choose the employed sampling distance according to an oracle that returns a preferable sampling distance d for any point in space. Our algorithm does not
guarantee any actual sampling rates; instead, the sampling distance
d returned by the oracle for a sampling point is used to “skip” sampling points that are closer than this distance.
For an efficient GPU-based implementation, the oracle has to
be implementable in a fragment program. Since the oracle’s input consists only of a three-dimensional point, the returned sampling distance has to be valid for all sampling directions. We do
not place further restrictions on the oracle; thus, the oracle may
be view-dependent or view-independent, it may be precomputed or
computed on request, etc. However, it should be noted that our algorithm always samples both, the oracle and the volumetric data
for the same points. This is often beneficial since the computation
of the oracle might be considerably less expensive if performed together with a sampling operation of the visualized data for the same
point.
We present our algorithm and GPU-based implementation in
four steps: Section 3.1 discusses the skipping of sampling points
for adaptively sampled view rays. The technique is similar to the
skipping of sampling points with the help of an early fragmentdepth test by Kr¨uger and Westermann [6]. Similarly to the system
by Roettger et al. [13] an oracle is employed to suggest a preferred
sampling rate. The algorithm presented in Section 3.1 is actually
less efficient than adapting the distance between sampling points
as suggested by Roettger et al. [13]; however, it may be extended
for locally adaptive sampling of each slice because sampling points
are systematically aligned on slices. Section 3.2 discusses a variant
of our GPU-based implementation [15] of the pyramid algorithm
[1] for adaptive sampling and synthesizing an image that represents
the data on the 0th slice. The extension of this algorithm for mul-

Table 1: Actual values of lslice and 2lslice +1 for islice from 0 to 8.

islice
lslice

2lslice +1

level l

2

level l

1

level l

0

0
∞
∞

1
0
2

2
1
4

3
0
2

4
2
8

5
0
2

6
1
4

7
0
2

8
3
16

Figure 3: Adaptive sampling of a slice (lslice = lmax = 2). Gray levels
represent sampling distances returned by an oracle. Filled black dots
represent skipped sampling points.

tiple slices and the actual volume integration with the help of preintegrated transfer functions, is discussed in Section 3.3. This algorithm requires considerably less volumetric sampling operations
than previously published volume rendering algorithms since it employs the oracle’s results not only for an adaptive sampling of view
rays but also for an adaptive sampling of slices. Our GPU-based
implementation of the algorithm is discussed in Section 3.4.
3.1 Adaptively Skipping Sampling Points
To allow for an adaptive sampling of the image plane, we align all
sampling points on view-aligned slices; see Figure 2. The slices
start in front of the bounding volume and end behind the bounding
volume. The uniform distance between slices corresponds to the
distance between neighboring view rays. This allows us to specify
all sampling distances in units of this smallest sampling distance.
Samples outside the bounding volume are mapped to a default data
value, which should be mapped to a transparent color for volume
rendering.
Adaptive sampling is achieved by querying an oracle for a sampling distance d at each sampling point starting on the 0th slice,
i.e., the frontmost slice. The result is stored together with the data
sample for the same point in the framebuffer and updated with new
values of each sampling point on the same view ray unless the sampling point is skipped. Sampling points on the next slices that are
projected to the same pixel (i.e., that are on the same view ray) are
skipped in dependency of the stored distance d; however, at most
d − 1 sampling points are skipped; thus, the sampling rate does not
drop below the sampling rate required by the oracle if d is not less
than 1 in the units described above. However, instead of skipping
exactly d − 1 sampling points, our algorithm skips sampling points
until it reaches the next slice with an index that is divisible by an
appropriate power of 2 in order to align sampling points of different rays on the same slice as required for the adaptive sampling of
slices, which is discussed in Sections 3.2 and 3.3.
Figure 2 illustrates the skipping of sampling points. For the pur-

P ROJECT S LICE(islice ):
lslice ← max{l ∈ N0 | islice mod 2l = 0 ∧ l ≤ lmax }
for l ← lslice to 0 do
for x ← 0 to w/2l − 1 do
for y ← 0 to h/2l − 1 do
if l < lslice and lslice = lmax
or dl [x, y] < 2lslice +1 then
dl [x, y] ← S YNTHESIZE O RACLE(l, x, y)
sl [x, y] ← S YNTHESIZE DATA(l, x, y)
endif
if l = lmax or dl [x, y] < 2l+1 then
dl [x, y] ← S AMPLE O RACLE(l, x, y)
sl [x, y] ← S AMPLE DATA(l, x, y)
endif
if l = 0 and lslice = lmax
or dl [x, y] < 2lslice +1 then
ACCUMULATE C OLOR(x, y, islice )
endif
endfor y
endfor x
endfor l
Figure 4: Pseudo code for adaptive sampling of the islice -th slice.
See Figure 7 for the specification of S YNTHESIZE DATA, S YNTHESIZE O RACLE, S AMPLE DATA, and S AMPLE O RACLE; ACCUMULATE C OLOR
is specified in Figure 8..

pose of illustration, a view-independent oracle is assumed, which
returns only integer sampling distances d from 1 to 4 represented by
gray levels. Skipped sampling points are indicated by filled black
dots while the color of all other sampling points represents the result of the oracle at each point.
The condition for skipping a sampling point on the islice -th slice
is d ≥ 2lslice +1 where d is the distance stored in the framebuffer and
lslice = max{l ∈ N0 | islice mod 2l = 0 ∧ l ≤ lmax }
with a positive integer lmax that bounds the maximum actual sampling distance from above by d = 2lmax . The index of the last slice
should be divisible by 2lmax to ensure sufficient sampling at boundaries. Note that lslice is just the number of trailing zeros (bounded
from above by lmax ) in a binary representation of the index islice .
Specific numbers for lmax = ∞ are given in Table 1. One important
feature of this scheme is that the skipping condition relies exclusively on previously stored results of the oracle and the index of
the slice. This is crucial for an implementation that relies on early
pixel-depth tests.
3.2 Adaptive Sampling of the Zeroth Slice
The adaptive skipping of sampling points on view rays discussed in
the previous section reduces the number of sampling points quite
efficiently; in particular, it is not restricted to empty space skipping but may also reduce the sampling rate if the data is locally
bandwidth-limited. However, the number of samples can be further
reduced by adaptively sampling each slice. If the adaptive sampling
of a view ray results in a reduction by a certain factor, the combined effect of adaptively sampling in three dimensions reduces the
number of samples by the third power of this factor. This section
discusses the adaptive sampling of one slice (in fact, the 0th slice),

115

0

1
level l

level l

level l

2

1

1

0

2

0

3

1

2

1
0 1 16 s1 1,1
3 16 s1 1,0

7
56
4
0 y 23
1
0
0 1 2

3

s1 2,1 3 16
s1 2,0 9 16

s0 4,1
3

4

x

5

6

7

3
9
1
Figure 5: Synthesis of s0 [4, 1] = 16
s1 [1, 0] + 16
s1 [2, 0] + 16
s1 [1, 1] +
3
16 s1 [2, 1]. The gray dot indicates the texture coordinates for the corresponding bilinear texture lookup.

level l 1

1 16

3 16

level l

3 16

9 16

Figure 6: Employed synthesis scheme for pixel data of a finer level
(gray) from pixel data of a coarser level (black)

while the combination with the adaptive sampling on view rays is
described in the next Section 3.3.
The data required for the sampling of all view rays (of the finest
level) is stored in an image of w × h pixels. For the adaptive sampling of this image on the 0th slice, our algorithm employs a pyramidal synthesis [1, 15] on lmax + 1 levels. All pixels of the topmost
level lmax are sampled while pixels on lower levels are either synthesized or also sampled if the oracle requires a smaller sampling
distance. Figure 3 illustrates the adaptive sampling of the 0th slice
for lmax = 2. Pseudo code for the adaptive sampling of any slice
is given in Figure 4. For the 0th slice, the relevant function call is
P ROJECT S LICE(0); i.e., islice is equal to 0. In this case lslice is set
to lmax .
The pyramidal synthesis for the 0th slice starts from the coarsest level lmax of size w/2lmax × h/2lmax (assuming that w and h are
divisible by 2lmax ). On this topmost level lmax no sampling points
may be skipped; therefore, data values slmax [x, y] are sampled from
the volumetric data and sampling distances dlmax [x, y] are requested
from the oracle for all pixels (x, y) of level lmax . The coordinates of the sampling point for a pixel (x, y) on level l is determined by a mapping to pixel coordinates on level 0 and thereby
to a sampling point on the corresponding view ray. The subroutine S AMPLE DATA(l, x, y) samples the volumetric data at the threedimensional point corresponding to the pixel (x, y) of level l of the
current slice, while S AMPLE O RACLE(l, x, y) returns the sampling
distance for this point determined by an oracle. Pseudo code for

116

S YNTHESIZE DATA(l, x, y):
return
y
y
y
1
x
x
1
x
4 + ( 2 − 2 ) 4 + ( 2 − 2 ) sl+1
2 − 1, 2 − 1
y
y
y
3
x
x
1
x
+ 4 − ( 2 − 2 ) 4 + ( 2 − 2 ) sl+1 2 , 2 − 1
+ 14 + ( 2x − 2x ) 34 − ( 2y − 2y ) sl+1 2x − 1, 2y
+ 34 − ( 2x − 2x ) 34 − ( 2y − 2y ) sl+1 2x , 2y
S YNTHESIZE O RACLE(l, x, y):
return
y
y
y
1
x
x
1
x
4 + ( 2 − 2 ) 4 + ( 2 − 2 ) dl+1
2 − 1, 2 − 1
+ 34 − ( 2x − 2x ) 14 + ( 2y − 2y ) dl+1 2x , 2y − 1
+ 14 + ( 2x − 2x ) 34 − ( 2y − 2y ) dl+1 2x − 1, 2y
+ 34 − ( 2x − 2x ) 34 − ( 2y − 2y ) dl+1 2x , 2y
S AMPLE DATA(l, x, y):
return sampled scalar data at the position corresponding to
pixel 2l x + 12 − 12 , 2l y + 12 − 12 of level 0.
S AMPLE O RACLE(l, x, y):
return sampled oracle at the position corresponding to
pixel 2l x + 12 − 12 , 2l y + 12 − 12 of level 0.
Figure 7: Pseudo code for synthesizing data and sampling scalar
data and the oracle. The functions are employed in Figure 4.

these subroutines is presented in Figure 7.
For each pixel (x, y) of the next level l = lmax − 1, the algorithm
synthesizes (i.e., approximates) scalar data sl [x, y] and a sampling
distance dl [x, y] from the values on level l + 1 = lmax . Since the
actual distance between the sampling points corresponding to two
adjacent pixels of level l is 2l , sampling on this level l is necessary if the synthesized sampling distance suggested by the oracle
is less than 2l+1 . In this case the volumetric data is sampled and
the oracle’s sampling distance is computed and stored in sl [x, y] and
dl [x, y], respectively.
The synthesis of data and distances on finer levels is
specified by the function S YNTHESIZE DATA(l, x, y) and
An example is
S YNTHESIZE O RACLE(l, x, y), respectively.
presented in Figure 5. Unfortunately, the formal specification in
Figure 7 of these functions obscures the actually quite simple
scheme, which is visualized in Figure 6 in a different way to
emphasize the relation to the regular Doo-Sabin subdivision
scheme and the subdivision of biquadratic B-splines [3].
This synthesis scheme is particularly well suited for a GPUbased implementation since it can be implemented by the bilinear
interpolation of a single texture lookup with appropriate texture coordinates as indicated by the gray dot in Figure 5. More details
and applications to problems in image processing are discussed by
Strengert et al. [15].
3.3 Putting It Together
The pseudo code in Figure 4 already covers the adaptive sampling
of all slices. The main difference between the sampling of the 0th
slice discussed in Section 3.2 and the sampling of further slices is
the computation of lslice . While lslice is equal to lmax for the 0th
slice, it is computed as discussed in Section 3.1 for a general slice
index islice .
lslice determines the starting level for the loop over l in the pyramidal synthesis. For example, the 0th slice processes all levels,
while the 1st slice processes only the bottommost level 0. After
the first sampling on the 0th slice, level 1 is updated for the first
time on the 2nd slice and level 2 on the 4th slice, etc. In general, samples on level l are updated for the first time on the 2l -th

ACCUMULATE C OLOR(x, y, islice ):
if islice > 0 then
C[x, y] ← C[x, y] + (1 − α [x, y]) ×
Clut sprev [x, y], s0 [x, y], islice − iprev [x, y]
α [x, y] ← α [x, y] + (1 − α [x, y]) ×
αlut sprev [x, y], s0 [x, y], islice − iprev [x, y]
endif
sprev [x, y] ← s0 [x, y]
iprev [x, y] ← islice [x, y]
P ROJECT VOLUME(nslices ):
for x ← 0 to w − 1 do
for y ← 0 to h − 1 do
C[x, y] ← 0
α [x, y] ← 0
endfor y
endfor x
imax ← 2lmax nslices /2lmax
for islice ← 0 to imax do
P ROJECT S LICE(islice )
endfor islice
Figure 8: Pseudo code for the color accumulation employed in Figure 4 and the main loop over all slices for volume rendering.

slice. More samples for level l are unnecessary since the distance
between sampling points of adjacent pixels on level l is 2l in units
of the minimum distance between sampling points. Note that data
that has been synthesized from data of level l, is always replaced
by new samples on level l − 1 taken at smaller sampling distances
if required by the oracle.
The condition d < 2lslice +1 for actually performing the sampling
(see Section 3.1) becomes l < lslice and lslice = lmax or dl [x, y] <
2lslice +1 in Figure 4. The first part l < lslice ensures that we do
not synthesize new values from data of level lslice + 1, which is not
updated for this slice since the loop over l starts with lslice . The
remaining algorithm for sampling slices is exactly as in the case of
the 0th slice, which was discussed in Section 3.2.
Pseudo code for the actual volume rendering is presented in
Figure 8. The main function P ROJECT VOLUME(nslices ) initializes arrays of size w × h for accumulated, opacity-weighted colors C[x, y] and opacities α [x, y] to transparent black. As mentioned
in Section 3.1, the index of the last slice has to be divisible by
2lmax ; thus, the maximum slice index imax is increased accordingly
and the volume rendering is performed in a loop over all slices;
see Figure 4 for the adaptive sampling specified by the function
P ROJECT S LICE(islice ).
The volume rendering integral for each pixel on the finest level
0 is approximated by a front-to-back color accumulation performed
by the method ACCUMULATE C OLOR(x, y, islice ), which is also defined in Figure 8. For all but the 0th slice, colors C[x, y] and
opacities α [x, y] are determined by a lookup in a pre-integrated
table for opacity-weighted colors Clut (sfront , sback , d) and opacities
αlut (sfront , sback , d) for the color and opacity of a ray segment of
length d with data samples sfront and sback at its ends. After colors
are blended, the end point of the current segment and the data sample for this point is stored as the starting point of the next segment.
The presented algorithm was designed for an implementation on
GPUs supporting certain features as discussed in the next section.

P ROJECT S LICE(islice ):
lslice ← max{l ∈ N0 | islice mod 2l = 0 ∧ l ≤ lmax }
for l ← lslice to 0 do
for x ← 0 to w/2l − 1 do
for y ← 0 to h/2l − 1 do
if l < lslice then
¡synthesize all pixels!
dl [x, y] ← S YNTHESIZE O RACLE(l, x, y)
sl [x, y] ← S YNTHESIZE DATA(l, x, y)
endif
if dl [x, y] < 2l+1 then
¡sample and accumulate!
zl [x, y] ← 46 + imax − islice
else if dl [x, y] < 2lslice +1 then
¡only accumulate!
zl [x, y] ← 26 + imax − islice
else ¡neither sample nor accumulate!
zl [x, y] ← 06 + imax − islice
endif
if l = lmax or
3
6 + imax − islice < zl [x, y] then
dl [x, y] ← S AMPLE O RACLE(l, x, y)
sl [x, y] ← S AMPLE DATA(l, x, y)
endif
if l = 0 and lslice = lmax
or 16 + imax − islice < zl [x, y] then
ACCUMULATE C OLOR(x, y, islice )
endif
endfor y
endfor x
endfor l
Figure 9: Pseudo code for a variant of the algorithm presented in
Figure 4, which is suitable for an implementation based on an early
fragment-depth test.

3.4 Putting It Onto a GPU
For a GPU-based implementation of the algorithm presented in Figures 4, and 8, we pack the arrays sprev [x, y], islice [x, y], sl [x, y] and
dl [x, y] for all levels l from 0 to lmax in one 16-bits floating-point
texture image of size 32 w × h with RGBA components. In a second 16-bits floating-point texture image colors C[x, y] and α [x, y]
are accumulated. While these texture images are also used as renderbuffer images, additional read-only texture images are required
for the pre-integration table and the volumetric data.
Our implementation is based on a texture-based volume renderer
with view-aligned slices; thus, we can easily implement the loop
over all pixels (x, y) in Figure 4 by rasterizing slice polygons. The
loop over l is implemented by rasterizing several primitives into
different parts of the texture image according to the packing of the
image pyramid into the texture image. Thus, for each rasterized
primitive, l, lslice , and lmax are constant. The block of the innermost
loop in Figure 4 consists of three “if-endif”-blocks as indicated by
horizontal lines. We implement these three “if-endif”-blocks by
conditionally rasterizing the same primitive up to three times with
different fragment programs.

117

Since we store all levels of the image pyramid in one texture
image, we have to use the same image as texture image and as renderbuffer image. Simultaneously rendering into and reading from
an image is not a well specified operation; however, sending a
“fence” [5] without waiting for it after each primitive apparently
avoids all caching problems at an acceptable performance cost in
our implementation. Alternatively, a more complicate ping-pong
rendering scheme could be employed that switches the roles of two
texture/renderbuffer images after each primitive; see Strengert et al.
[15] for more details.
3.4.1 Implementation Based on Pixel-Depth Tests
Those terms of the “if”-conditions in the pseudo code presented in
Figure 4 that depend only on per-primitive constants (l, lslice , and
lmax ) are evaluated on the CPU and the remaining terms that depend
on dl [x, y] can be implemented by a potentially early pixel-depth
test. To this end, each updated entry of dl [x, y] has to be copied to a
depth buffer zl [x, y] of the same dimensions as the renderbuffer images. Then the conditions dl [x, y] < 2l+1 and dl [x, y] < 2lslice +1 can
be implemented with the help of a “depth bounds test” with (unnormalized) bounds from 0 to 2l+1 and 0 to 2lslice +1 , respectively.
In contrast to the fragment-depth test, a pixel-depth test could
always be performed before a fragment enters its fragment program since the pixel-depth test does not depend on the result of
the fragment program. Thus, a pixel-depth test can always be an
“early” test; in particular, the specification of the depth bounds test
[5] mentions the possibility of an implementation of an early test
in graphics hardware. Encouraged by the results reported by Neophytou and Mueller [10] with an early depth bounds test and some
tests of our own, we expected a significant performance gain from
the early rejection of fragments. Although we succeeded to implement the algorithm shown in Figure 4 on our target hardware, we
can only achieve the expected performance gain if our implementation never changes the bounds of the depth bounds test. Unfortunately, we were not able to implement our algorithm without these
changes of the bounds, which presumably deactivate the early test
of the implementation of the depth bounds test of our target hardware. Therefore, we were not able to exploit an early pixel-depth
test for an efficient implementation of the algorithm presented in
Figure 4.
3.4.2 Implementation Based on Fragment-Depth Tests
Thus, we had to revise our algorithm for an implementation based
on an early fragment-depth test; i.e., a standard OpenGL depth test
with comparison relation “less” on our target hardware. This test
can conditionally avoid the execution of the fragment program that
samples the volumetric data. In the revised pseudo code, which is
presented in Figure 9, the depth buffer required for the fragmentdepth test is denoted by zl [x, y]. Results obtained with our implementation of this algorithm are reported in Section 4.
In this implementation, fragments pass the depth test if their
depth is less than the depth value stored in the depth buffer zl [x, y].
Certain limitations of the early fragment-depth test of our target
hardware required us to write only decreasing depth values. Therefore, we use a scheme in which a group of three depth values is
reserved for each slice index islice . The three (unnormalized) depth
values are 06 + imax − islice , 26 + imax − islice , and 46 + imax − islice .
This scheme ensures that any depth value written for slice islice is
less than any depth value written for a previous slice.
The first of the three fragment programs marked by horizontal
lines in Figure 9 is executed for all pixels in this algorithm. Actually, we use two different fragment programs: one for l = lslice ,
which consists only of the second “if-endif”-block to write depth
values to zl [x, y], and a second fragment program for l < lslice , which
includes the synthesis of data. Since we have to write depth values
for all pixels, we cannot exploit the early fragment-depth test for

118

Table 2: Results for the aneurysm data set on a 512 × 512 viewport.

algorithm
distance oracle

tex.-based
min.

# fragments
# sampling ops
time in secs

49 M
99 M
0.87

adaptive sampling
min.
|∇α | > ε
162 M
56 M
0.79

61 M
1M
0.23

Table 3: Results for the abdomen data set on a 512 × 512 viewport.

algorithm
distance oracle

tex.-based
min.

# fragments
# sampling ops
time in secs

37 M
74 M
0.76

adaptive sampling
min.
|∇α | > ε
122 M
42 M
0.68

61 M
9M
0.38

this fragment program. Therefore, a significant number of additional synthesis operations is performed in the algorithm presented
in Figure 9, which are avoided by the algorithm of Figure 4. However, it should be noted that this first fragment program does not
perform the potentially expensive sampling of the volumetric data
but only the synthesis of data, which we implemented by a single
bilinear interpolated texture lookup.
The depth value written to zl [x, y] determines whether both of the
next two fragment programs for sampling and color accumulation
are performed ( 64 + imax − islice ), only the last fragment program for
color accumulation ( 26 + imax − islice ), or none of the two programs
( 06 + imax − islice ). As the timings presented in Section 4 show, the
early rejection of fragments is very effective in our test cases. Thus,
we can actually avoid the potentially expensive sampling of volumetric data structures.
4 R ESULTS
We tested the implementation described in Section 3.4 on a LinuxPC equipped with an Intel Pentium 4 processor (3.4 GHz) and an
NVIDIA 7800 GTX 512 graphics adapter with 512 MB of video
memory. For comparison with a pre-integrated texture-based volume rendering system we employed cartesian data sets that are
stored in three-dimensional texture maps. Therefore, the sampling
of the volume data is performed by a simple hardware-accelerated
trilinear texture lookup. The time required for this 3D texture sampling is far less than the time required to access complex, GPUbased data structures (see for example Lefohn et al. [7]); thus, the
timings of our current implementation are not representative for
actual applications. However, the timings prove that many of the
potentially costly sampling operations are in fact avoided by early
depth tests.
Table 2 summarizes our results for a 512 × 512 × 512 × 8 bits
data set of an aneurysm (courtesy of Michael Meißner, Viatronix
Inc., USA). For comparison, the first column shows measurements
for a pre-integrated, texture-based volume renderer with the same
number of slices. Figure 10a shows the volume rendering. The
second column presents statistics for our algorithm with an oracle that always returns the minimum sampling distance; i.e., the
rendering is at full resolution. The resulting visualization is visually indistinguishable from Figure 10a and was, therefore, not
included. The results for this oracle were included to present the
worst-case overhead of our algorithm. The third column shows
our algorithm with adaptive sampling according to an ad-hoc oracle that is pre-computed and stored with the data set in the same
three-dimensional texture map. Roughly speaking, it estimates the
distance to the nearest voxel that features a gradient magnitude of

the opacity greater than some threshold. The resulting visualization
is presented in Figure 10b and achieves almost the same quality
as the reference rendering with considerably fewer sampling operations. lmax was set to 3 in our examples; i.e., the maximum
sampling distance is 8.
The first row of data lists the number of fragments generated
during the rendering. Since our algorithm has to rasterize up to
three primitives for each level, it generates considerably more fragments. The second row shows the number of required sampling
operations of the volumetric data (i.e., texture lookups), which is
twice the number of fragments for the texture-based volume renderer because of the pre-integration but includes only the sampling
operations that pass the depth test for our adaptive sampling system.
Note that not all of the rejected fragments are rejected early; however, the timings indicate that many of them are rejected before the
sampling operation was performed. The last row specifies timings
in seconds.
Our second example is a resampled 512 × 512 × 512 × 8 bits
version of an abdomen data set (the original data set is also courtesy of Michael Meißner). The pre-integrated texture-based volume
rendering is shown in Figure 11a, while the adaptively sampled rendering is presented in Figure 11b. Measurements are summarized in
Table 3. Since this data set contains fewer empty regions, our adaptive sampling algorithm requires more sampling operations than for
the aneurysm data set but still significantly less than the texturebased volume renderer.
5

C ONCLUSIONS

AND

F UTURE W ORK

We implemented an efficient GPU-based volume rendering algorithm on current graphics hardware with adaptive sampling in view
direction and in the two perpendicular directions of the image plane.
The adaptive sampling rate is determined by an almost arbitrary oracle. Our measurements show that we can avoid expensive sampling operations of complex volumetric data structures with the
help of an early fragment-depth test. Thus, our main contribution
is a GPU-friendly algorithm (Sections 3.3 and 3.4) that combines
adaptive sampling in view direction (Section 3.1) with a pyramidal
synthesis for adaptive sampling of slice images (Section 3.2).
Adaptive sampling according to an oracle in general, and our
algorithm in particular, is especially beneficial if the sampling operation is computational expensive; for example, for random access
to compressed volumetric data and/or if the volume data features
a complex boundary, and/or if there is a strong local variation of
the required sampling rate, and/or if the sampling quality should be
continuously adaptable, and/or if a high-resolution display results
in excessive oversampling, etc. In the latter case of excessive oversampling, our current implementation avoids superfluous sampling;
however, it requires additional synthesis operations. To reduce this
effect efficiently, we can skip all slices with indices islice mod 2l = 0
with an appropriate power l.
In fact, the main disadvantage of our current implementation as
described in Section 3.4.2 are the superfluous synthesis operations
and the required writing of a depth value for each pixel, which we
can not avoid due to limitations of our target hardware. We experimented with several variants of our algorithm before we concluded
that the early depth tests offered by current graphics hardware via
the OpenGL API are not yet flexible enough for an efficient implementation of our algorithm as described in Section 3.4.1. However,
we are confident that future graphics hardware and/or programming
APIs will support more general and more flexible early fragment
tests since they are an important means of limiting the performance
costs of complex fragment programs. In particular, recently published APIs for general computations on GPUs by ATI [12] and
NVIDIA [11] suggest that today’s GPUs are capable of the functionality required for an implementation of the algorithm presented
in Section 3.4.1. Thus, we hope to achieve performance gains cor-

responding to the amount of skipped sampling points soon.
Future work also includes improvements of our volume rendering algorithm regarding boundaries of the data and of the view frustum, the use of shells instead of slices for perspective projection,
early ray termination, and applications to compressed GPU-based
volumetric data structures and the design of appropriate oracles.
R EFERENCES
[1] P. J. Burt. Fast filter transforms for image processing. Computer
Graphics and Image Processing, 16:20–51, 1981.
[2] B. Cabral, N. Cam, and J. Foran. Accelerated volume rendering
and tomographic reconstruction using texture mapping hardware. In
Proceedings 1994 Symposium on Volume Visualization, pages 91–98,
1994.
[3] E. Catmull and J. Clark. Recursively generated b-spline surfaces on
arbitrary topological meshes. Computer Aided Design, 10(6):350–
355, 1978.
[4] K. Engel, M. Kraus, and T. Ertl. High-quality pre-integrated volume
rendering using hardware-accelerated pixel shading. In W. Mark and
A. Schilling, editors, Proceedings Graphics Hardware 2001, pages
9–16. ACM Press, 2001.
[5] M. J. Kilgard. NVIDIA OpenGL Extension Specifications. NVIDIA
Corporation, 2004.
[6] J. Kr¨uger and R. Westermann. Linear algebra operators for gpu implementation of numerical algorithms. ACM Transactions on Graphics,
22(3):908–916, 2003.
[7] A. E. Lefohn, J. Kniss, R. Strzodka, S. Sengupta, and J. D. Owens.
Glift: Generic, efficient, random-access gpu data structures. ACM
Transactions on Graphics, 25(1), 2006.
[8] A. E. Lefohn, J. M. Kniss, C. D. Hansen, and R. T. Whitaker. A
streaming narrow-band algorithm: Interactive deformation and visualization of level sets. IEEE Transactions on Visualization and Computer Graphics, 10(4):422–433, 2004.
[9] M. Levoy. Efficient ray tracing of volume data. ACM Transactions on
Graphics, 9(3):245–261, 1990.
[10] N. Neophytou and K. Mueller. Gpu accelerated image aligned splatting. In Proceedings Volume Graphics 2005, pages 197–205, 2005.
[11] Nvidia Corporation.
Nvidia cuda homepage.
Web site:
http://www.nvidia.com/cuda, 2006.
[12] M. Peercy, M. Segal, and D. Gerstmann. A performance-oriented
data-parallel virtual machine for gpus. Sketches, ACM SIGGRAPH
2006, 2006.
[13] S. Roettger, S. Guthe, D. Weiskopf, T. Ertl, and W. Strasser.
Smart hardware-accelerated volume rendering. In Proceedings Joint
Eurographics-IEEE TCVG Symposium on Visualization (VisSym ’03),
pages 231–238, 2003.
[14] S. Stegmaier, M. Strengert, T. Klein, and T. Ertl. A simple and flexible volume rendering framework for graphics-hardware–based raycasting. In Proceedings International Workshop on Volume Graphics
’05, pages 187–195, 2005.
[15] M. Strengert, M. Kraus, and T. Ertl. Pyramid methods in gpu-based
image processing. accepted for publication at VMV 2006.

119

(a)

(b)

Figure 10: Volume rendering of the aneurysm data set: (a) Texture-based volume rendering for comparison. (b) Our adaptive sampling according
to a pre-computed ad-hoc oracle.

(a)

(b)

Figure 11: Abdomen data set: (a) texture-based and (b) with our adaptive sampling algorithm.

120

